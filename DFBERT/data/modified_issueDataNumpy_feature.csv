num,label,code_len,con_num,keyword_num,keyword_fix,username,permission,ds
23344,0,0,275,0,0,charris,1,"title:TYP: Add type annotations for comparison operators to MaskedArray. description:Backport of #23328.The comparison operators seem to be missing annotations; whereas pretty much every other operator is annotated.This causes pytype to conclude that the output of, say, `__gt__` is a regular ndarray, which isn't true.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
23343,0,0,275,0,0,charris,0,"title:TYP: Mark ``d`` argument to fftfreq and rfftfreq as optional in type stubs. description:Backport of #23327.The type stubs incorrectly mark this argument as mandatory. It has a default argument, per the docs: https://numpy.org/doc/stable/reference/generated/numpy.fft.fftfreq.htmlhttps://numpy.org/doc/stable/reference/generated/numpy.fft.rfftfreq.html<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
23342,0,0,275,0,0,charris,0,"title:TYP: Remove duplicate CLIP/WRAP/RAISE in __init__.pyi. description:Backport of #23326.These constants are defined twice in this file, to which pytype objects (mypy appears to tolerate this.)<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
23335,0,90,274,0,1,tylerjereddy,1,"title:BUG: ma with structured dtype description:Fixes #22041* add regression test and fix for creating a masked array with a structured dtype; the test is simply for lack of error in the repoducer* the concern expressed by core team in matching issue was that `astropy` might be negatively affected; I ran full `astropy` (hash: `c9ad7c56`) test suite locally with this feature branch and it seemed ""ok,"" just 1 unrelated network failure in the network-requiring tests (`test_ftp_tls_auto`):```1 failed, 21430 passed, 3490 skipped, 176 xfailed, 23275 warnings in 430.18s (0:07:10)```
"
23328,0,0,262,0,0,hawkinsp,0,"title:TYP: Add type annotations for comparison operators to MaskedArray. description:The comparison operators seem to be missing annotations; whereas pretty much every other operator is annotated.This causes pytype to conclude that the output of, say, `__gt__` is a regular ndarray, which isn't true.
"
23327,0,0,262,0,0,hawkinsp,0,"title:TYP: Mark ``d`` argument to fftfreq and rfftfreq as optional in type stubs description:The type stubs incorrectly mark this argument as mandatory. It has a default argument, per the docs: https://numpy.org/doc/stable/reference/generated/numpy.fft.fftfreq.htmlhttps://numpy.org/doc/stable/reference/generated/numpy.fft.rfftfreq.html
"
23326,0,0,262,0,0,hawkinsp,0,"title:TYP: Remove duplicate CLIP/WRAP/RAISE in __init__.pyi. description:These constants are defined twice in this file, to which pytype objects. (mypy appears to tolerate this.)
"
23324,1,41,264,0,0,snooppr,0,"title:BUG: numpy v1.23.5 latest version that works on windows 7 description:### Describe the issue:numpy v1.23.5 latest version that works on windows 7I tried all other versions (1.24; 1.24.1; 1.24.2) they are all installed, but when importing the numpy python module, it closes with an error, on the screen. Other versions of numpy work. Python3.8.10 32bit OS Windows 7 64bit.Since numpy 1.24 support for Windows7 has been dropped?![1](https://user-images.githubusercontent.com/61022210/222724611-fa38d098-17a8-4b54-8b38-d814585b9872.jpg)### Reproduce the code example:```pythonimport numpy```### Error message:```shellsee screenshot```### Runtime information:import numpy crash### Context for the issue:_No response_
"
23318,0,0,292,0,1,ngoldbaum,0,"title:BUG: Fix reference counting error in arraydescr_new description:Since `tp_alloc` is called a few lines above this, this call to `PyObject_Init` will generate a reference leak. It turns out the default implementation of `tp_alloc` in CPython [calls `PyObject_Init` implicitly](https://github.com/python/cpython/blob/71db5dbcd714b2e1297c43538188dd69715feb9a/Objects/typeobject.c#L1314).
"
23307,1,2129,286,0,1,djhoese,0,"title:BUG: np.size is no longer an instance of FunctionType (nightly/dev build) description:### Describe the issue:I have a package that has a CI environment that installs numpy and many other packages from their current unstable/dev versions (nightly builds) and runs the tests. A couple months ago (I think) we started running into a failure where one of our dependencies (holoviews) started crashing when performing the check `isinstance(np.size, types.FunctionType)`. We are not installing a dev version of holoviews. It seems to be tied to numpy's dev version.### Reproduce the code example:```pythonimport numpy as npimport typesassert isinstance(np.size, types.FunctionType)```### Error message:```shellN/A```### Runtime information:```[{'numpy_version': '1.25.0.dev0+831.g3b5eff00e',  'python': '3.9.13 | packaged by conda-forge | (main, May 27 2022, '            '16:56:21) \n'            '[GCC 10.3.0]',  'uname': uname_result(system='Linux', node='janet', release='6.0.12-76060006-generic', version='#202212290932~1674139725~22.04~ca93ccf SMP PREEMPT_DYNAMIC Thu J', machine='x86_64')}, {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2'],                      'not_found': ['AVX512F',                                    'AVX512CD',                                    'AVX512_KNL',                                    'AVX512_KNM',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}, {'architecture': 'Haswell',  'filepath': '/home/davidh/miniconda3/envs/satpy_py39_unstable2/lib/python3.9/site-packages/numpy.libs/libopenblas64_p-r0-15028c96.3.21.so',  'internal_api': 'openblas',  'num_threads': 12,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.21'}]```### Context for the issue:I'm not sure how many packages have code like this, but holoviews has this bit of code:https://github.com/holoviz/holoviews/blob/4e83af3e6af0e19fa6c7e226791011372916fc70/holoviews/plotting/bokeh/hex_tiles.py#L26-L30```python    aggregator = param.ClassSelector(        default=np.size, class_=(types.FunctionType, tuple), doc=""""""      Aggregation function or dimension transform used to compute bin      values. Defaults to np.size to count the number of values      in each bin."""""")```And the `param` library does this check between that `class_` tuple and the `default` object (in this case `np.size`):https://github.com/holoviz/param/blob/cd1b4ae50c01c14c0eb22721e41a9c8fb1e8f738/param/__init__.py#L1381-L1385```        if is_instance:            if not (isinstance(val, class_)):                raise ValueError(                    ""%s parameter %r value must be an instance of %s, not %r."" %                    (param_cls, self.name, class_name, val))```I am not a holoviews developer, just use it for one small portion of my package (Satpy). As far as I can tell `np.size` is defined as a function here:https://github.com/numpy/numpy/blob/486878b37fc7439a3b2b87747f50db9b62fea8eb/numpy/core/fromnumeric.py#L3194-L3195So I'm lost as to where/how this is not being satisfied. I've seen the failure on Python 3.9 environments. I have not tried other versions of Python.
"
23303,0,286,28,0,0,kgabor,0,"title:BUG: meshgrid returns a list while a tuple is expected based on the documentation description:### Describe the issue:The documentation suggests that the return type is a _tuple_ of arrays.> For vectors x1, x2,闂? xn with lengths Ni=len(xi), returns (N1, N2, N3,..., Nn) shaped arrays if indexing=闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨鏇㈡⒑缁嬫鍎愰拑鍗炃庨崶褝韬鐐叉椤︽挳寮崼婵冩斀?or (N2, N1, N3,..., Nn) shaped arrays if indexing=闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨鏇㈡⒑缁嬫鍎愰柨鏇樺灲瀵鏁愭径濞⑩晠鏌ㄩ弮鍌滄憘婵☆偄鍟埞?with the elements of xi repeated to fill the matrix along the first dimension for x1, the second for x2 and so on.However the return type is a _list_. This makes a difference if the result is directly used in indexing as a whole.### Reproduce the code example:```pythonR = np.arange(9).reshape(3,3)M = np.meshgrid([0,1,2],[0,1,2], indexing='ij')# Expected behavior is (3, 3)R[M].shape(2, 3, 3, 3)R[tuple(M)].shape  (3, 3)# ===M = np.meshgrid([0,1,2],[0,1,2], sparse=True, indexing='ij')R[M] # ErrorR[tuple(M)].shape(3, 3)```### Error message:_No response_### Runtime information:1.24.03.11.0 | packaged by conda-forge | (main, Oct 25 2022, 06:24:40) [GCC 10.4.0]### Context for the issue:_No response_
"
23292,0,0,292,0,1,ngoldbaum,0,"title:BUG: sorting checks `NPY_NEEDS_PYAPI` instead of `NPY_ITEM_REFCOUNT` description:The sorting routines release the GIL with `NPY_BEGIN_THREADS_DESCR` and that macro checks if `NPY_NEEDS_PYAPI` is set. However, the check for whether to call `PyErr_Occurred()` in these sorting routines see if `NPY_ITEM_REFCOUNT` is set.Up until now this hasn't been a big deal since e.g. object dtype has both flags set. However `stringdtype` doesn't hold references to python objects and has `NPY_ITEM_REFCOUNT` set without `NPY_NEEDS_PYAPI`, so it seg faults on the call to `PyErr_Occurred` right now.The fix is to make the flag checks in the threading macro and the flag check for whether to call `PyErr_Occurred` consistent.
"
23279,0,0,292,0,1,seberg,1,"title:BUG: Allow no-op clearing of void dtypes description:Some void dtypes think they contain objects but don't.  Instead of playing whack-a-mole to see if that can be fixed, simply make the clearing a no-op here for them.User dtypes are weirder, it should be OK to pass through.Fixes the error message and use write-unraisable.Closes gh-23277
"
23277,0,318,252,0,0,mhvk,1,"title:BUG: clearing of array data too aggressive after gh-22924 description:### Describe the issue:#22924 introduced failures in astropy (and likely in pandas). It is almost certainly to do with zero-length object dtype arrays; pure numpy example below.### Reproduce the code example:```pythonimport numpy as npnp.recarray((0,), dtype=""O"") # rec.array([],#           dtype=|V8)exit()```### Error message:```shellTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>RuntimeError: Internal error, tried to fetch clear function for the user dtype '' without fields or subarray (legacy support).```### Runtime information:1.25.0.dev0+802.g5f04e748b3.11.1 (main, Dec 31 2022, 10:23:59) [GCC 12.2.0]### Context for the issue:See https://github.com/numpy/numpy/pull/22924#issuecomment-1444854769 and below.
"
23269,0,0,274,0,1,tylerjereddy,0,"title:BUG: masked array proper deepcopies description:Fixes #22556Fixes #21022* add regression test and fix for gh-22556, where we were relying on the array `copy` arg to deepcopy a compound object type; I thought about performance issues here, but if you are already in the land of `object` and you are explicitly opting in to `deepcopy`, it seems like performance might be wishful thinking anyway* add regression test and fix for gh-21022--this one was weirder but seems possible to sidestep by not trying to assign a shape of `()` to something that already has shape `()` and a non-writeable `shape` attribute
"
23258,0,1530,299,0,0,andyfaff,0,"title:BUG: ma.apply_along_axis is broken after commit 138bba5  description:### Describe the issue:A scipy CI entry has recently acquired segfaults. The CI entry installs numpy from the git repo. I did a manual bisection and figured out that commit 138bba5 onwards causes issues. xref https://github.com/scipy/scipy/issues/18025.### Reproduce the code example:```pythondef my_func(a):    """"""Average first and last element of a 1-D array""""""    return (a[0] + a[-1]) * 0.5import numpy as npb = np.ma.array([1.0, 3.0])np.ma.apply_along_axis(my_func, 0, b)```### Error message:```shelluncaught target signal 11 (Segmentation fault) - core dumped```### Runtime information:```1.25.0.dev0+742.g138bba5ff3.11.2 (main, Feb  8 2023, 14:49:25) [GCC 11.3.0]WARNING: `threadpoolctl` not found in system! Install it by `pip install threadpoolctl`. Once installed, try `np.show_runtime` again for more detailed build information[{'numpy_version': '1.25.0.dev0+742.g138bba5ff',  'python': '3.11.2 (main, Feb  8 2023, 14:49:25) [GCC 11.3.0]',  'uname': uname_result(system='Linux', node='a9b6a04e7c66', release='5.15.49-linuxkit', version='#1 SMP PREEMPT Tue Sep 13 07:51:32 UTC 2022', machine='x86_64')}, {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3', 'SSE41', 'POPCNT', 'SSE42'],                      'not_found': ['AVX',                                    'F16C',                                    'FMA3',                                    'AVX2',                                    'AVX512F',                                    'AVX512CD',                                    'AVX512_KNL',                                    'AVX512_KNM',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}]None```### Context for the issue:_No response_
"
23246,1,1367,19,0,1,JulianoLagana,0,"title:BUG: `numpy.random.randint` inconsistently raises `ValueError`s description:### Describe the issue:`numpy.random.randint` samples `[1]` happily with these parameters```np.random.randint(1.1, 2.9, size=1)```but raises a `{ValueError} low >= high` for```np.random.randint([1.1], [2.9], size=1)```### Reproduce the code example:```pythonimport numpy as np# No problemsnp.random.randint(1.1, 2.9, size=1)# Raises errornp.random.randint([1.1], [2.9], size=1)```### Error message:```shellTraceback (most recent call last):  File ""/Users/juliano/Code/wood-analysis/test.py"", line 7, in <module>    np.random.randint([1.1], [2.9], size=1)  File ""mtrand.pyx"", line 765, in numpy.random.mtrand.RandomState.randint  File ""_bounded_integers.pyx"", line 1262, in numpy.random._bounded_integers._rand_int64  File ""_bounded_integers.pyx"", line 686, in numpy.random._bounded_integers._rand_int64_broadcastValueError: low >= high```### Runtime information:```>>> import sys, numpy; print(numpy.__version__); print(sys.version)1.24.13.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)]``````>>> print(numpy.show_runtime())[{'simd_extensions': {'baseline': ['NEON', 'NEON_FP16', 'NEON_VFPV4', 'ASIMD'],                      'found': ['ASIMDHP', 'ASIMDDP'],                      'not_found': ['ASIMDFHM']}}, {'architecture': 'armv8',  'filepath': '/Users/juliano/Code/wood-analysis/.venv/lib/python3.10/site-packages/numpy/.dylibs/libopenblas64_.0.dylib',  'internal_api': 'openblas',  'num_threads': 8,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.21'}]None```### Context for the issue:_No response_
"
23244,1,2280,197,1,1,DanielHabenicht,0,"title:BUG: `np.multiply.outer` hangs in multiprocessing description:### Describe the issue:Executing multiple (more than 1) `np.multiply` calls with a sufficiently big dataset causes a job in multiprocessing to hang. ### Reproduce the code example:```pythonfrom multiprocessing import Pool, cpu_countimport numpy as npfrom tqdm import tqdmdef task(num):    # Just some setup from the codebase the bug seen the first time    # you might have to increase these for the bug to show.    T = 10000    N = 100    K0 = np.zeros((N, N))    K1 = np.zeros((N, N))    Kd = np.zeros((N, N))    np.fill_diagonal(K0, 0)    np.fill_diagonal(K1, 1)    np.fill_diagonal(Kd, 0)    # Commenting out either of these remove the program hanging    test1 = np.multiply.outer(K0, np.ones(T))    test2 = np.multiply.outer(K1, np.ones(T))if __name__ == ""__main__"":    with Pool(processes=cpu_count() - 1) as p:        # Bug only shows if queing more Jobs than CPU Counts        jobs = [p.apply_async(func=task, args=[num]) for num in range(cpu_count() + 2)]        for job in tqdm(jobs):            job.get()```### Error message:```shellNone, program hangs.```### Runtime information:```bash>>> print(numpy.__version__)1.24.2>>> print(sys.version)3.10.9 (main, Jan 11 2023, 15:12:53) [GCC 10.2.1 20210110]>>> print(numpy.show_runtime())[{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2'],                      'not_found': ['AVX512F',                                    'AVX512CD',                                    'AVX512_KNL',                                    'AVX512_KNM',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}, {'architecture': 'Haswell',  'filepath': '/workspaces/LDIMBench/.venv/lib/python3.10/site-packages/numpy.libs/libopenblas64_p-r0-15028c96.3.21.so',  'internal_api': 'openblas',  'num_threads': 1,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.21'}]None```The code was executing in a [Devcontainer](https://github.com/TUMT2022/LDIMBenchmark/blob/main/.devcontainer/devcontainer.json) on a Windows 11 machine.### Context for the issue:I already had a look at https://github.com/numpy/numpy/issues/17752 and https://github.com/numpy/numpy/issues/5752 but adding the environment variables did not help. I tried: ```bashexport OMP_NUM_THREADS=1 MKL_NUM_THREADS=1 OPENBLAS_NUM_THREADS=1;```
"
23242,1,249,10,0,0,nrkarp,0,"title:BUG: np.copyto() fails silently with slices description:### Describe the issue:np.copyto() does not appear to support slicing. No problem if that's the design decision, but it should then throw a warning if slices are supplied as inputs.Appears much like Issue #11623, which was closed with a brief explanation about assigning to temporary arrays. I have no doubt that that answer is technically correct, but to someone who is not intimate with numpy's source code it's not obvious why copyto() shouldn't be able to do what ""A[my_slice] = B[my_slice]"" does.### Reproduce the code example:```pythonimport numpy as npA = np.arange(16).reshape(8, 2)B = np.ones((8, 2), dtype=int)my_slice = [1, 3, 5]np.copyto(A[my_slice], B[my_slice])A  # remains unchanged by np.copyto()```### Error message:```shell(There is no error message: that is the problem.)```### Runtime information:import sys, numpy; print(numpy.__version__); print(sys.version)1.22.33.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) [GCC 10.3.0]### Context for the issue:This no longer affects my work: there are many workarounds. But it took many, many hours of debugging to figure out why my code was failing, since numpy is normally pretty good at complaining when it can't handle inputs.
"
23234,1,0,292,1,0,seberg,0,"title:BUG?: New SIMD quicksort code may have some issues description:A quick heads-up that the x86-simd-sort code (I downloaded HEAD from Github) may have an issue sorting large arrays.I noticed incorrect results when integrating this into our [vqsort benchmark](https://github.com/google/highway/pull/1140). Happy to discuss in [HN comments](https://news.ycombinator.com/item?id=34810610) or here._Originally posted by @jan-wassenberg in https://github.com/numpy/numpy/issues/22315#issuecomment-1434766714_---Another thing is that I am not sure that stability guarantees for NaNs has been discussed enough (comment above that one).
"
23233,0,0,86,0,0,ganesh-k13,1,"title:BUG: Use raw strings for paths `__config__.py.in` description:### Changes* `\U` leads to strings being treated as unicode, hence we escape it with raw strings* Changed bool parameters to real bools instead of string `""True""` and `""False""`* Small refactor in `_cleanup` to make it consistent with SciPyTaken from https://github.com/scipy/scipy/pull/17936/related: #23165
"
23231,1,1901,10,0,0,Greesh-N,0,"title:BUG: setting an array element with a sequence and the requested array has an inhomogeneous shape after 1 dimensions. description:### Describe the issue:The below piece of code which is taking sum of a simple Neural Network Model stops working with numpy version 1.24 (was working with numpy version 1.21.0). Can someone please suggest what is the change in numpy which is causing this issue to occur.### Reproduce the code example:```pythonimport torch.nn.functional as Fimport torch.optim as optimimport numpy as npclass Net(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.linear1 = nn.Linear(60, 100)        self.linear2 = nn.Linear(100, 10)    def forward(self, x):        x = self.linear1(x)        x = self.linear2(x)        return xdef Sum(agg_model, models):    state_dicts = [model.state_dict() for model in models]    state_dict = agg_model.state_dict()    for key in models[0].state_dict():        model_state=[state[key] for state in state_dicts]        print(f""{model_state}"")        state_dict[key] = np.sum(model_state, axis=0)     agg_model.load_state_dict(state_dict)    return agg_modelif __name__ == '__main__':    model = []    for i in range(2):        model.append(Net())    agg_model = Net()    Sum(agg_model, model)```### Error message:```shellTraceback (most recent call last):  File ""/home/ggreeshma/patrick-changes2/openfl/openfl-tutorials/experimental/error_reproduce.py"", line 33, in <module>    Sum(agg_model, model)  File ""/home/ggreeshma/patrick-changes2/openfl/openfl-tutorials/experimental/error_reproduce.py"", line 24, in Sum    state_dict[key] = np.sum(model_state, axis=0)   File ""<__array_function__ internals>"", line 200, in sum  File ""/home/ggreeshma/miniconda3/envs/openfl-practice/lib/python3.8/site-packages/numpy/core/fromnumeric.py"", line 2324, in sum    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,  File ""/home/ggreeshma/miniconda3/envs/openfl-practice/lib/python3.8/site-packages/numpy/core/fromnumeric.py"", line 86, in _wrapreduction    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.```### Runtime information:Numpy version:1.24.0python:3.8### Context for the issue:_No response_
"
23221,0,0,275,0,1,charris,0,"title:DOC: Fix matplotlib error in documentation description:Backport of #23212As noted by Kyle Sunden, this was deprecated and has been removed, using the method is the correct way of doing it in newer matplotlib.Closes gh-23209Co-authored-by: Kyle Sunden ksunden@users.noreply.github.com<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
23220,1,28922,297,0,1,peytondmurray,0,"title:BUG: Numpy fails to build due to simd_qsort bad include description:### Describe the issue:The `main` branch of numpy currently fails to build (51ecf84013a6c8325f9dd0571a48794fc0e448a4).  Here's the build log.```Using pip 23.0 from /home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib/python3.11/site-packages/pip (python 3.11)/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib/python3.11/site-packages/pip/_vendor/packaging/version.py:111: DeprecationWarning: Creating a LegacyVersion has been deprecated and will be removed in the next major release  warnings.warn(Processing /home/pdmurray/Desktop/workspace/numpy  Installing build dependencies: started  Running command pip subprocess to install build dependencies  Collecting setuptools==59.2.0    Using cached setuptools-59.2.0-py3-none-any.whl (952 kB)  Collecting wheel==0.38.1    Using cached wheel-0.38.1-py3-none-any.whl (35 kB)  Collecting Cython<3.0,>=0.29.30    Using cached Cython-0.29.33-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)  Installing collected packages: wheel, setuptools, Cython  Successfully installed Cython-0.29.33 setuptools-59.2.0 wheel-0.38.1  Installing build dependencies: finished with status 'done'  Getting requirements to build wheel: started  Running command Getting requirements to build wheel  /tmp/pip-build-env-01a46gnq/overlay/lib/python3.11/site-packages/pkg_resources/_vendor/pyparsing.py:87: DeprecationWarning: module 'sre_constants' is deprecated    import sre_constants  Running from numpy source directory.  setup.py:67: DeprecationWarning:    `numpy.distutils` is deprecated since NumPy 1.23.0, as a result    of the deprecation of `distutils` itself. It will be removed for    Python >= 3.12. For older Python versions it will remain present.    It is recommended to use `setuptools < 60.0` for those Python versions.    For more details, see:      https://numpy.org/devdocs/reference/distutils_status_migration.html    import numpy.distutils.command.sdist  running egg_info  running build_src  INFO: build_src  writing numpy.egg-info/PKG-INFO  writing dependency_links to numpy.egg-info/dependency_links.txt  writing entry points to numpy.egg-info/entry_points.txt  writing top-level names to numpy.egg-info/top_level.txt  reading manifest file 'numpy.egg-info/SOURCES.txt'  reading manifest template 'MANIFEST.in'  no previously-included directories found matching 'doc/build'  no previously-included directories found matching 'doc/source/generated'  no previously-included directories found matching 'benchmarks/results'  no previously-included directories found matching 'benchmarks/html'  no previously-included directories found matching 'benchmarks/numpy'  warning: no previously-included files matching '*.pyo' found anywhere in distribution  warning: no previously-included files matching '*.pyd' found anywhere in distribution  warning: no previously-included files matching '*.swp' found anywhere in distribution  warning: no previously-included files matching '*.bak' found anywhere in distribution  warning: no previously-included files matching '*~' found anywhere in distribution  adding license file 'LICENSE.txt'  adding license file 'LICENSES_bundled.txt'  writing manifest file 'numpy.egg-info/SOURCES.txt'  Getting requirements to build wheel: finished with status 'done'  Preparing metadata (pyproject.toml): started  Running command Preparing metadata (pyproject.toml)  /tmp/pip-build-env-01a46gnq/overlay/lib/python3.11/site-packages/pkg_resources/_vendor/pyparsing.py:87: DeprecationWarning: module 'sre_constants' is deprecated    import sre_constants  Running from numpy source directory.  setup.py:67: DeprecationWarning:    `numpy.distutils` is deprecated since NumPy 1.23.0, as a result    of the deprecation of `distutils` itself. It will be removed for    Python >= 3.12. For older Python versions it will remain present.    It is recommended to use `setuptools < 60.0` for those Python versions.    For more details, see:      https://numpy.org/devdocs/reference/distutils_status_migration.html    import numpy.distutils.command.sdist  running dist_info  running build_src  INFO: build_src  creating /tmp/pip-modern-metadata-i3borso9/numpy.egg-info  writing /tmp/pip-modern-metadata-i3borso9/numpy.egg-info/PKG-INFO  writing dependency_links to /tmp/pip-modern-metadata-i3borso9/numpy.egg-info/dependency_links.txt  writing entry points to /tmp/pip-modern-metadata-i3borso9/numpy.egg-info/entry_points.txt  writing top-level names to /tmp/pip-modern-metadata-i3borso9/numpy.egg-info/top_level.txt  writing manifest file '/tmp/pip-modern-metadata-i3borso9/numpy.egg-info/SOURCES.txt'  reading manifest file '/tmp/pip-modern-metadata-i3borso9/numpy.egg-info/SOURCES.txt'  reading manifest template 'MANIFEST.in'  no previously-included directories found matching 'doc/build'  no previously-included directories found matching 'doc/source/generated'  no previously-included directories found matching 'benchmarks/results'  no previously-included directories found matching 'benchmarks/html'  no previously-included directories found matching 'benchmarks/numpy'  warning: no previously-included files matching '*.pyo' found anywhere in distribution  warning: no previously-included files matching '*.pyd' found anywhere in distribution  warning: no previously-included files matching '*.swp' found anywhere in distribution  warning: no previously-included files matching '*.bak' found anywhere in distribution  warning: no previously-included files matching '*~' found anywhere in distribution  adding license file 'LICENSE.txt'  adding license file 'LICENSES_bundled.txt'  writing manifest file '/tmp/pip-modern-metadata-i3borso9/numpy.egg-info/SOURCES.txt'  creating '/tmp/pip-modern-metadata-i3borso9/numpy.dist-info'  Preparing metadata (pyproject.toml): finished with status 'done'Building wheels for collected packages: numpy  Building wheel for numpy (pyproject.toml): started  Running command Building wheel for numpy (pyproject.toml)  /tmp/pip-build-env-01a46gnq/overlay/lib/python3.11/site-packages/pkg_resources/_vendor/pyparsing.py:87: DeprecationWarning: module 'sre_constants' is deprecated    import sre_constants  Running from numpy source directory.  setup.py:67: DeprecationWarning:    `numpy.distutils` is deprecated since NumPy 1.23.0, as a result    of the deprecation of `distutils` itself. It will be removed for    Python >= 3.12. For older Python versions it will remain present.    It is recommended to use `setuptools < 60.0` for those Python versions.    For more details, see:      https://numpy.org/devdocs/reference/distutils_status_migration.html    import numpy.distutils.command.sdist  numpy/random/_bounded_integers.pxd.in has not changed  numpy/random/_sfc64.pyx has not changed  numpy/random/_mt19937.pyx has not changed  numpy/random/mtrand.pyx has not changed  numpy/random/_philox.pyx has not changed  numpy/random/_generator.pyx has not changed  numpy/random/_pcg64.pyx has not changed  numpy/random/_bounded_integers.pyx.in has not changed  numpy/random/_bounded_integers.pyx has not changed  numpy/random/bit_generator.pyx has not changed  numpy/random/_common.pyx has not changed  Cythonizing sources  INFO: blas_opt_info:  INFO: blas_armpl_info:  INFO: customize UnixCCompiler  INFO:   libraries armpl_lp64_mp not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  INFO: blas_mkl_info:  INFO:   libraries mkl_rt not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  INFO: blis_info:  INFO:   libraries blis not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  INFO: openblas_info:  INFO:   libraries openblas not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  INFO: accelerate_info:  INFO:   NOT AVAILABLE  INFO:  INFO: atlas_3_10_blas_threads_info:  INFO: Setting PTATLAS=ATLAS  INFO:   libraries tatlas not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  INFO: atlas_3_10_blas_info:  INFO:   libraries satlas not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  INFO: atlas_blas_threads_info:  INFO: Setting PTATLAS=ATLAS  INFO:   libraries ptf77blas,ptcblas,atlas not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  INFO: atlas_blas_info:  INFO:   libraries f77blas,cblas,atlas not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  /home/pdmurray/Desktop/workspace/numpy/numpy/distutils/system_info.py:2077: UserWarning:      Optimized (vendor) Blas libraries are not found.      Falls back to netlib Blas library which has worse performance.      A better performance should be easily gained by switching      Blas library.    if self._calc_info(blas):  INFO: blas_info:  INFO: C compiler: gcc -Wsign-compare -g -Og -Wall -O0 -fPIC  creating /tmp/tmpumi5p7sc/tmp  creating /tmp/tmpumi5p7sc/tmp/tmpumi5p7sc  INFO: compile options: '-I/usr/local/include -I/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/include -c'  INFO: gcc: /tmp/tmpumi5p7sc/source.c  INFO: gcc /tmp/tmpumi5p7sc/tmp/tmpumi5p7sc/source.o -L/usr/lib64 -lblas -o /tmp/tmpumi5p7sc/a.out  /usr/bin/ld: /tmp/tmpumi5p7sc/tmp/tmpumi5p7sc/source.o: in function `main':  /tmp/tmpumi5p7sc/source.c:6: undefined reference to `cblas_ddot'  collect2: error: ld returned 1 exit status  INFO: gcc /tmp/tmpumi5p7sc/tmp/tmpumi5p7sc/source.o -L/usr/lib64 -lcblas -lblas -o /tmp/tmpumi5p7sc/a.out  INFO:   FOUND:  INFO:     libraries = ['cblas', 'blas', 'blas']  INFO:     library_dirs = ['/usr/lib64']  INFO:     include_dirs = ['/usr/local/include', '/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/include']  INFO:     language = c  INFO:     define_macros = [('HAVE_CBLAS', None)]  INFO:  INFO:   FOUND:  INFO:     define_macros = [('NO_ATLAS_INFO', 1), ('HAVE_CBLAS', None)]  INFO:     libraries = ['cblas', 'blas', 'blas']  INFO:     library_dirs = ['/usr/lib64']  INFO:     include_dirs = ['/usr/local/include', '/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/include']  INFO:     language = c  INFO:  non-existing path in 'numpy/distutils': 'site.cfg'  INFO: lapack_opt_info:  INFO: lapack_armpl_info:  INFO:   libraries armpl_lp64_mp not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  INFO: lapack_mkl_info:  INFO:   libraries mkl_rt not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  INFO: openblas_lapack_info:  INFO:   libraries openblas not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  INFO: openblas_clapack_info:  INFO:   libraries openblas,lapack not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  INFO: flame_info:  INFO:   libraries flame not found in ['/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib', '/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/']  INFO:   NOT AVAILABLE  INFO:  INFO: atlas_3_10_threads_info:  INFO: Setting PTATLAS=ATLAS  INFO:   libraries tatlas,tatlas not found in /home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib  INFO:   libraries tatlas,tatlas not found in /usr/local/lib  INFO:   libraries tatlas,tatlas not found in /usr/lib64  INFO:   libraries tatlas,tatlas not found in /usr/lib  INFO:   libraries tatlas,tatlas not found in /usr/lib/  INFO: <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>  INFO:   NOT AVAILABLE  INFO:  INFO: atlas_3_10_info:  INFO:   libraries satlas,satlas not found in /home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib  INFO:   libraries satlas,satlas not found in /usr/local/lib  INFO:   libraries satlas,satlas not found in /usr/lib64  INFO:   libraries satlas,satlas not found in /usr/lib  INFO:   libraries satlas,satlas not found in /usr/lib/  INFO: <class 'numpy.distutils.system_info.atlas_3_10_info'>  INFO:   NOT AVAILABLE  INFO:  INFO: atlas_threads_info:  INFO: Setting PTATLAS=ATLAS  INFO:   libraries ptf77blas,ptcblas,atlas not found in /home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib  INFO:   libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib  INFO:   libraries ptf77blas,ptcblas,atlas not found in /usr/lib64  INFO:   libraries ptf77blas,ptcblas,atlas not found in /usr/lib  INFO:   libraries ptf77blas,ptcblas,atlas not found in /usr/lib/  INFO: <class 'numpy.distutils.system_info.atlas_threads_info'>  INFO:   NOT AVAILABLE  INFO:  INFO: atlas_info:  INFO:   libraries f77blas,cblas,atlas not found in /home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib  INFO:   libraries f77blas,cblas,atlas not found in /usr/local/lib  INFO:   libraries f77blas,cblas,atlas not found in /usr/lib64  INFO:   libraries f77blas,cblas,atlas not found in /usr/lib  INFO:   libraries f77blas,cblas,atlas not found in /usr/lib/  INFO: <class 'numpy.distutils.system_info.atlas_info'>  INFO:   NOT AVAILABLE  INFO:  INFO: lapack_info:  INFO:   FOUND:  INFO:     libraries = ['lapack', 'lapack']  INFO:     library_dirs = ['/usr/lib64']  INFO:     language = f77  INFO:  INFO:   FOUND:  INFO:     libraries = ['lapack', 'lapack', 'cblas', 'blas', 'blas']  INFO:     library_dirs = ['/usr/lib64']  INFO:     language = c  INFO:     define_macros = [('NO_ATLAS_INFO', 1), ('HAVE_CBLAS', None)]  INFO:     include_dirs = ['/usr/local/include', '/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/include']  INFO:  Warning: attempted relative import with no known parent package  /tmp/pip-build-env-01a46gnq/overlay/lib/python3.11/site-packages/setuptools/_distutils/dist.py:275: UserWarning: Unknown distribution option: 'define_macros'    warnings.warn(msg)  running bdist_wheel  running build  running config_cc  INFO: unifing config_cc, config, build_clib, build_ext, build commands --compiler options  running config_fc  INFO: unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options  running build_src  INFO: build_src  INFO: building py_modules sources  INFO: building library ""npymath"" sources  WARN: Could not locate executable armflang  INFO:   adding 'build/src.linux-x86_64-3.11/numpy/core/src/npymath' to include_dirs.  INFO: None - nothing done with h_files = ['build/src.linux-x86_64-3.11/numpy/core/src/npymath/npy_math_internal.h']  INFO: building library ""npyrandom"" sources  INFO: building extension ""numpy.core._multiarray_tests"" sources  INFO: building extension ""numpy.core._multiarray_umath"" sources  INFO:   adding 'build/src.linux-x86_64-3.11/numpy/core/src/multiarray' to include_dirs.  INFO:   adding 'build/src.linux-x86_64-3.11/numpy/core/src/common' to include_dirs.  INFO:   adding 'build/src.linux-x86_64-3.11/numpy/core/src/umath' to include_dirs.  INFO: numpy.core - nothing done with h_files = ['build/src.linux-x86_64-3.11/numpy/core/src/multiarray/arraytypes.h', 'build/src.linux-x86_64-3.11/numpy/core/src/common/npy_sort.h', 'numpy/core/src/common/npy_partition.h', 'numpy/core/src/common/npy_binsearch.h', 'build/src.linux-x86_64-3.11/numpy/core/src/umath/funcs.inc', 'build/src.linux-x86_64-3.11/numpy/core/src/umath/loops.h', 'build/src.linux-x86_64-3.11/numpy/core/src/umath/loops_utils.h', 'build/src.linux-x86_64-3.11/numpy/core/src/umath/matmul.h', 'numpy/core/src/umath/clip.h', 'build/src.linux-x86_64-3.11/numpy/core/src/common/templ_common.h', 'build/src.linux-x86_64-3.11/numpy/core/include/numpy/config.h', 'build/src.linux-x86_64-3.11/numpy/core/include/numpy/_numpyconfig.h', 'build/src.linux-x86_64-3.11/numpy/core/include/numpy/__multiarray_api.h', 'build/src.linux-x86_64-3.11/numpy/core/include/numpy/__ufunc_api.h']  INFO: building extension ""numpy.core._umath_tests"" sources  INFO: building extension ""numpy.core._rational_tests"" sources  INFO: building extension ""numpy.core._struct_ufunc_tests"" sources  INFO: building extension ""numpy.core._operand_flag_tests"" sources  INFO: building extension ""numpy.core._simd"" sources  INFO:   adding 'build/src.linux-x86_64-3.11/numpy/core/src/_simd' to include_dirs.  INFO: numpy.core - nothing done with h_files = ['build/src.linux-x86_64-3.11/numpy/core/src/_simd/_simd_inc.h', 'build/src.linux-x86_64-3.11/numpy/core/src/_simd/_simd_data.inc']  INFO: building extension ""numpy.fft._pocketfft_internal"" sources  INFO: building extension ""numpy.linalg.lapack_lite"" sources  INFO: building extension ""numpy.linalg._umath_linalg"" sources  INFO: building extension ""numpy.random._mt19937"" sources  INFO: building extension ""numpy.random._philox"" sources  INFO: building extension ""numpy.random._pcg64"" sources  INFO: building extension ""numpy.random._sfc64"" sources  INFO: building extension ""numpy.random._common"" sources  INFO: building extension ""numpy.random.bit_generator"" sources  INFO: building extension ""numpy.random._generator"" sources  INFO: building extension ""numpy.random._bounded_integers"" sources  INFO: building extension ""numpy.random.mtrand"" sources  INFO: building data_files sources  INFO: build_src: building npy-pkg config files  running build_py  copying build/src.linux-x86_64-3.11/numpy/__config__.py -> build/lib.linux-x86_64-3.11-pydebug/numpy  copying build/src.linux-x86_64-3.11/numpy/distutils/__config__.py -> build/lib.linux-x86_64-3.11-pydebug/numpy/distutils  UPDATING build/lib.linux-x86_64-3.11-pydebug/numpy/_version.py  set build/lib.linux-x86_64-3.11-pydebug/numpy/_version.py to '1.25.0.dev0+678.g51ecf8401'  running build_clib  INFO: customize UnixCCompiler  INFO: customize UnixCCompiler using new_build_clib  INFO: CCompilerOpt.__init__[813] : load cache from file -> /home/pdmurray/Desktop/workspace/numpy/build/temp.linux-x86_64-3.11-pydebug/ccompiler_opt_cache_clib.py  INFO: CCompilerOpt.__init__[824] : hit the file cache  running build_ext  INFO: customize UnixCCompiler  INFO: customize UnixCCompiler using new_build_ext  INFO: CCompilerOpt.__init__[813] : load cache from file -> /home/pdmurray/Desktop/workspace/numpy/build/temp.linux-x86_64-3.11-pydebug/ccompiler_opt_cache_ext.py  INFO: CCompilerOpt.__init__[824] : hit the file cache  INFO: customize UnixCCompiler  INFO: customize UnixCCompiler using new_build_ext  INFO: building 'numpy.core._multiarray_umath' extension  INFO: compiling C++ dispatch-able sources  INFO: CCompilerOpt.parse_targets[1853] : looking for '@targets' inside ->  numpy/core/src/npysort/simd_qsort.dispatch.cpp  INFO: CCompilerOpt._parse_target_tokens[2048] : policy 'KEEP_BASELINE' is ON  INFO: CCompilerOpt._parse_target_tokens[2048] : policy 'MAXOPT' is ON  INFO: CCompilerOpt._parse_policy_maxopt[2157] : debug mode is detected, policy 'maxopt' is skipped.  INFO: CCompilerOpt.parse_targets[1853] : looking for '@targets' inside ->  numpy/core/src/npysort/simd_qsort_16bit.dispatch.cpp  INFO: CCompilerOpt._parse_target_tokens[2048] : policy 'KEEP_BASELINE' is ON  INFO: CCompilerOpt._parse_target_tokens[2048] : policy 'MAXOPT' is ON  INFO: CCompilerOpt._parse_policy_maxopt[2157] : debug mode is detected, policy 'maxopt' is skipped.  INFO: C compiler: g++ -Wsign-compare -g -Og -Wall -O0 -fPIC  INFO: compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=1 -DHAVE_CBLAS -I/usr/local/include -I/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/include -Ibuild/src.linux-x86_64-3.11/numpy/core/src/multiarray -Ibuild/src.linux-x86_64-3.11/numpy/core/src/common -Ibuild/src.linux-x86_64-3.11/numpy/core/src/umath -Inumpy/core/include -Ibuild/src.linux-x86_64-3.11/numpy/core/include/numpy -Ibuild/src.linux-x86_64-3.11/numpy/distutils/include -Ibuild/src.linux-x86_64-3.11/numpy/core/src/npysort -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/src/_simd -I/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/include -I/home/pdmurray/.pyenv/versions/3.11.0-debug/include/python3.11d -Ibuild/src.linux-x86_64-3.11/numpy/core/src/common -Ibuild/src.linux-x86_64-3.11/numpy/core/src/npymath -c'  extra options: '-std=c++11 -D__STDC_VERSION__=0 -fno-exceptions -fno-rtti -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mavx -mf16c -mfma -mavx2 -mavx512f -mno-mmx -mavx512cd -mavx512vl -mavx512bw -mavx512dq'  INFO: g++: build/src.linux-x86_64-3.11/numpy/core/src/npysort/simd_qsort.dispatch.avx512_skx.cpp  In file included from build/src.linux-x86_64-3.11/numpy/core/src/npysort/simd_qsort.dispatch.avx512_skx.cpp:21:  /home/pdmurray/Desktop/workspace/numpy/numpy/core/src/npysort/simd_qsort.dispatch.cpp:11:14: fatal error: x86-simd-sort/src/avx512-32bit-qsort.hpp: No such file or directory     11 |     #include ""x86-simd-sort/src/avx512-32bit-qsort.hpp""        |              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  compilation terminated.  error: Command ""g++ -Wsign-compare -g -Og -Wall -O0 -fPIC -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=1 -DHAVE_CBLAS -I/usr/local/include -I/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/include -Ibuild/src.linux-x86_64-3.11/numpy/core/src/multiarray -Ibuild/src.linux-x86_64-3.11/numpy/core/src/common -Ibuild/src.linux-x86_64-3.11/numpy/core/src/umath -Inumpy/core/include -Ibuild/src.linux-x86_64-3.11/numpy/core/include/numpy -Ibuild/src.linux-x86_64-3.11/numpy/distutils/include -Ibuild/src.linux-x86_64-3.11/numpy/core/src/npysort -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/src/_simd -I/home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/include -I/home/pdmurray/.pyenv/versions/3.11.0-debug/include/python3.11d -Ibuild/src.linux-x86_64-3.11/numpy/core/src/common -Ibuild/src.linux-x86_64-3.11/numpy/core/src/npymath -c build/src.linux-x86_64-3.11/numpy/core/src/npysort/simd_qsort.dispatch.avx512_skx.cpp -o build/temp.linux-x86_64-3.11-pydebug/build/src.linux-x86_64-3.11/numpy/core/src/npysort/simd_qsort.dispatch.avx512_skx.o -MMD -MF build/temp.linux-x86_64-3.11-pydebug/build/src.linux-x86_64-3.11/numpy/core/src/npysort/simd_qsort.dispatch.avx512_skx.o.d -std=c++11 -D__STDC_VERSION__=0 -fno-exceptions -fno-rtti -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mavx -mf16c -mfma -mavx2 -mavx512f -mno-mmx -mavx512cd -mavx512vl -mavx512bw -mavx512dq"" failed with exit status 1  INFO:  ########### EXT COMPILER OPTIMIZATION ###########  INFO: Platform      :    Architecture: x64    Compiler    : gcc  CPU baseline  :    Requested   : 'min'    Enabled     : SSE SSE2 SSE3    Flags       : -msse -msse2 -msse3    Extra checks: none  CPU dispatch  :    Requested   : 'max -xop -fma4'    Enabled     : SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_KNL AVX512_KNM AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL    Generated   :                :    AVX512_SKX  : SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD    Flags       : -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mavx -mf16c -mfma -mavx2 -mavx512f -mno-mmx -mavx512cd -mavx512vl -mavx512bw -mavx512dq    Extra checks: AVX512BW_MASK AVX512DQ_MASK    Detect      : AVX512_SKX                : numpy/core/src/npysort/simd_qsort.dispatch.cpp                :    AVX512_ICL  : SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_SKX AVX512_CLX AVX512_CNL    Flags       : -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mavx -mf16c -mfma -mavx2 -mavx512f -mno-mmx -mavx512cd -mavx512vl -mavx512bw -mavx512dq -mavx512vnni -mavx512ifma -mavx512vbmi -mavx512vbmi2 -mavx512bitalg -mavx512vpopcntdq    Extra checks: none    Detect      : AVX512_ICL                : numpy/core/src/npysort/simd_qsort_16bit.dispatch.cpp  INFO: CCompilerOpt.cache_flush[857] : write cache to path -> /home/pdmurray/Desktop/workspace/numpy/build/temp.linux-x86_64-3.11-pydebug/ccompiler_opt_cache_ext.py  INFO:  ########### CLIB COMPILER OPTIMIZATION ###########  INFO: Platform      :    Architecture: x64    Compiler    : gcc  CPU baseline  :    Requested   : 'min'    Enabled     : SSE SSE2 SSE3    Flags       : -msse -msse2 -msse3    Extra checks: none  CPU dispatch  :    Requested   : 'max -xop -fma4'    Enabled     : SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_KNL AVX512_KNM AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL    Generated   : none  INFO: CCompilerOpt.cache_flush[857] : write cache to path -> /home/pdmurray/Desktop/workspace/numpy/build/temp.linux-x86_64-3.11-pydebug/ccompiler_opt_cache_clib.py  error: subprocess-exited-with-error    闂?Building wheel for numpy (pyproject.toml) did not run successfully.  闂?exit code: 1  闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗霉閿濆懏鎯堟い銉︾閵囧嫰骞橀崡鐐典患缂佺偓鍎冲锟犲蓟閺囥垹閱囨繝闈涙祩濡倝姊虹紒妯肩畵闁绘牕銈搁獮鍐ㄎ旈崨顔芥珳闁硅偐琛ラ崜婵嬫倶閸垻纾? See above for output.    note: This error originates from a subprocess, and is likely not a problem with pip.  full command: /home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/bin/python3.11 /home/pdmurray/.pyenv/versions/3.11.0-debug/envs/numpy/lib/python3.11/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py build_wheel /tmp/tmp1j0c78t6  cwd: /home/pdmurray/Desktop/workspace/numpy  Building wheel for numpy (pyproject.toml): finished with status 'error'  ERROR: Failed building wheel for numpyFailed to build numpyERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects```</details>And the relevant part:```INFO: g++: build/src.linux-x86_64-3.11/numpy/core/src/npysort/simd_qsort.dispatch.avx512_skx.cppIn file included from build/src.linux-x86_64-3.11/numpy/core/src/npysort/simd_qsort.dispatch.avx512_skx.cpp:21:/home/pdmurray/Desktop/workspace/numpy/numpy/core/src/npysort/simd_qsort.dispatch.cpp:11:14: fatal error: x86-simd-sort/src/avx512-32bit-qsort.hpp: No such file or directory   11 |     #include ""x86-simd-sort/src/avx512-32bit-qsort.hpp""```I really hope I'm not just missing a dependency somewhere...sorry in advance if that's the case!### Reproduce the code example:```python`pip install -v .````### Runtime information:```python>>> print(sys.version)3.11.0 (main, Dec  8 2022, 14:07:23) [GCC 12.2.0]``````bash$ uname -rmsLinux 6.1.11-arch1-1 x86_64```I can't install the development version of numpy to give runtime information, but if I do `pip install numpy` to get the latest release wheel, then I can:```python>>> print(np.show_runtime())[{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2'],                      'not_found': ['AVX512F',                                    'AVX512CD',                                    'AVX512_KNL',                                    'AVX512_KNM',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}, {'filepath': '/usr/lib/libgomp.so.1.0.0',  'internal_api': 'openmp',  'num_threads': 24,  'prefix': 'libgomp',  'user_api': 'openmp',  'version': None}, {'architecture': 'Zen',  'filepath': '/home/pdmurray/.pyenv/versions/3.11.0/lib/python3.11/site-packages/numpy.libs/libopenblas64_p-r0-15028c96.3.21.so',  'internal_api': 'openblas',  'num_threads': 24,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.21'}]None```### Context for the issue:I'm trying to build the development version so that I can finish work on #23173.
"
23216,0,0,292,0,0,seberg,0,"title:CI: Ensure submodules are initialized on MacOS CI description:For some reason this didn't show up on the original PR or was missed but is now making CI fail after the sorting merge.
"
23212,0,0,292,0,1,seberg,0,"title:DOC: Fix matplotlib error in documentation description:As noted by Kyle Sunden, this was deprecated and has been removed, using the method is the correct way of doing it in newer matplotlib.Closes gh-23209Co-authored-by: Kyle Sunden <ksunden@users.noreply.github.com>---Lets unbreak CI.  @charris it was intentional that you put the other fixup into the maintenance branch?
"
23207,0,0,275,0,1,charris,0,"title:BUG: datetime64/timedelta64 comparisons return NotImplemented description:Backport of #23201.Closes #17017* BUG: datetime64/timedelta64 comparisons return NotImplemented* typo fixup* Update numpy/core/src/multiarray/scalartypes.c.srcCo-authored-by: Sebastian Berg <sebastian@sipsolutions.net>* Update numpy/core/src/multiarray/scalartypes.c.src---------Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net><!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
23206,0,129,275,0,1,charris,0,"title:BUG: fix for f2py string scalars (#23194) description:Backport of #23194.Closes  #23192in previous version, any string scalar was converted to a string array of dimension len, i.e., a definition```fortrancharacter(len=N) :: X``` effectively became```fortrancharacter(len=NNN), dimension(NNN) :: X```from the point of few of the numpy (python) interface:```pythonX.shape == (NNN,)X.dtype == '|SNNN'```<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
23201,0,0,284,0,0,jbrockmendel,0,"title:BUG: datetime64/timedelta64 comparisons return NotImplemented description:Closes #17017
"
23196,1,3099,12,0,1,bsen,0,"title:BUG: `np.nonzero` outputs too large indices for boolean matrices description:### Describe the issue:When calling `np.nonzero` on some boolean matrices, sometimes the returned indices are larger than it should be possible.(for example 1152921504606852819 , when they should be smaller than 12000).The code example below reproduces this bug.In the below script, note that one could set `FORK` to False and the bug is still thrown but it takes longer (for me it was maximally 17000 around iterations for a similar script.)I tried this on two different machines, both running 20.04.1-Ubuntu with around 32 GB of RAM.It happens with different numpy versions, including the latest one (1.24.2) and different ways of installing numpy (conda, pip and poetry).When using `FORK = True` in the script below, the error is shown for me after 20 iterations already (output 20 in stdout). If not, it has proven effective to `Ctrl + C` and try again.### Reproduce the code example:```pythonimport osimport numpy as npFORK = Truedef main():    np.random.seed(4321)    if FORK:        pid = os.fork()        np.random.seed(4321)        if pid > 0:            np.random.seed(1234)            pid = os.fork()            if pid > 0:                np.random.seed(123)                pid = os.fork()                if pid > 0:                    np.random.seed(321)                    if pid > 0:                        np.random.seed(12)                        pid = os.fork()                        if pid > 0:                            np.random.seed(21)                            pid = os.fork()                            if pid > 0:                                np.random.seed(1)    count = 0    while True:        count += 1        if count % 10 == 0:            print(count)        random_num_one = np.random.randint(6000, 8000)        random_num_two = np.random.randint(10000, 12000)        self_offsets = np.zeros((random_num_one, random_num_two, 2))        random_arr = np.random.random((random_num_one, random_num_two))        mask = random_arr >= 0.5        ys_rel, xs_rel = np.nonzero(mask)        if np.max(xs_rel) > random_num_two:            raise Exception(f""This should not happen: {np.max(xs_rel)} > {random_num_two}"")        if np.max(ys_rel) > random_num_one:            raise Exception(f""This should not happen: {np.max(ys_rel)} > {random_num_one}"")if __name__ == ""__main__"":    main()```### Error message:```shellTraceback (most recent call last):  File ""scripts/minimal_new.py"", line 52, in <module>    main()  File ""scripts/minimal_new.py"", line 45, in main    raise Exception(f""numpy does not work: {np.max(xs)} > {random_num_two}"")Exception: This should not happen: 1152921504606852819 > 10326```### Runtime information:Ouput of `import sys, numpy; print(numpy.__version__); print(sys.version)````1.24.23.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0]```Output of `print(numpy.show_runtime())````[{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2'],                      'not_found': ['AVX512F',                                    'AVX512CD',                                    'AVX512_KNL',                                    'AVX512_KNM',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}, {'architecture': 'Haswell',  'filepath': '/home/benr/.cache/pypoetry/virtualenvs/projectname-6Jmumlav-py3.8/lib/python3.8/site-packages/numpy.libs/libopenblas64_p-r0-15028c96.3.21.so',  'internal_api': 'openblas',  'num_threads': 16,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.21'}]```Operating system ```Linux 5.15.0-58-generic #64~20.04.1-Ubuntu```### Context for the issue:The usage is in the context of data loading for the analysis of images (semantic segmentation).I cannot work without getting the indices where this kind of matrices are nonzero, I'm bound to use workarounds.
"
23194,0,129,83,0,1,2sn,0,"title:BUG: fix for f2py string scalars description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->proposed fix for #23192in previous version, any string scalar was converted to a string array of dimension len, i.e., a definition```fortrancharacter(len=N) :: X``` effectively became```fortrancharacter(len=NNN), dimension(NNN) :: X```from the point of few of the numpy (python) interface:```pythonX.shape == (NNN,)X.dtype == '|SNNN'```
"
23192,0,1494,83,0,1,2sn,0,"title:BUG: f2py 1.24 - string scalars fail description:### Describe the issue:Since NumPy Version 1.24 string scalars seem to fail.  I have a code that defines a character variable of length 8,```fortrancharacter*8 &       nameprob```which in the `puf` file becomes```fortrancharacter*8 :: nameprob```as it should.  After compilation, however, when I access the variable though its module (`data`) or its common block (`namcom`), either way I get```ipythonIn [6]: k.kd._kepler.data.nameprobOut[6]: array([b'xxx     ', b'xxxz    ', b'        ', b'xxx_0   ', b'        ',       b'xxxz    ', b'        ', b''], dtype='|S8')In [9]: k.kd._kepler.namecom.nameprobOut[9]: array([b'xxx     ', b'xxxz    ', b'        ', b'xxx_0   ', b'        ',       b'xxxz    ', b'        ', b''], dtype='|S8')```an array of length 8 of character of length 8.  It seems `8` has been wrongly used twice, as char length and as array length - despite the variable is a scalar.  For another variable defined as `character*16` there are 16 units of `!S16` type.  Etc.  What is returned is just extra stuff from memory.  When a dimension is specified, e.g., ```fortrancharacter*2 dimension(121) :: izsym```all is fine```ipythonarray([b'pn', b'nt', b' h', b'he', b'li', b'be', b' b', b' c', b' n',       b' o', b' f', b'ne', b'na', b'mg', b'al', b'si', b' p', b' s',       b'cl', b'ar', b' k', b'ca', b'sc', b'ti', b' v', b'cr', b'mn',       b'fe', b'co', b'ni', b'cu', b'zn', b'ga', b'ge', b'as', b'se',       b'br', b'kr', b'rb', b'sr', b' y', b'zr', b'nb', b'mo', b'tc',       b'ru', b'rh', b'pd', b'ag', b'cd', b'in', b'sn', b'sb', b'te',       b' i', b'xe', b'cs', b'ba', b'la', b'ce', b'pr', b'nd', b'pm',       b'sm', b'eu', b'gd', b'tb', b'dy', b'ho', b'er', b'tm', b'yb',       b'lu', b'hf', b'ta', b' w', b're', b'os', b'ir', b'pt', b'au',       b'hg', b'tl', b'pb', b'bi', b'po', b'at', b'rn', b'fr', b'ra',       b'ac', b'th', b'pa', b' u', b'np', b'pu', b'am', b'cm', b'bk',       b'cf', b'es', b'fm', b'md', b'no', b'lr', b'rf', b'db', b'sg',       b'bh', b'hs', b'mt', b'ds', b'rg', b'cn', b'nh', b'fl', b'mc',       b'lv', b'ts', b'og', b'ue'], dtype='|S2')```and I get the desired array.  Only scalar `character` variables seem to be converted to arraysI should add that this is an interface module that is linked to library with the actual code (so I can use all Fortran statements w/o interfering with `f2py`.  But I think it is not relevant, and I assume a very easy-to-fix small bug.  Hopefully.In NumPy Version 1.23.5 this issue is not present.### Reproduce the code example:```python(see above)```### Error message:```shellN/A```### Runtime information:1.24.23.11.1 (main, Jan 21 2023, 21:33:07) [GCC 12.2.1 20221121 (Red Hat 12.2.1-4)][{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2',                                'AVX512F',                                'AVX512CD',                                'AVX512_SKX'],                      'not_found': ['AVX512_KNL',                                    'AVX512_KNM',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}, {'architecture': 'SkylakeX',  'filepath': '/home/alex/Python_3.11.1/lib/python3.11/site-packages/numpy.libs/libopenblas64_p-r0-15028c96.3.21.so',  'internal_api': 'openblas',  'num_threads': 16,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.21'}, {'architecture': 'SkylakeX',  'filepath': '/home/alex/Python_3.11.1/lib/python3.11/site-packages/scipy.libs/libopenblasp-r0-41284840.3.18.so',  'internal_api': 'openblas',  'num_threads': 16,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.18'}, {'filepath': '/usr/lib64/libgomp.so.1.0.0',  'internal_api': 'openmp',  'num_threads': 16,  'prefix': 'libgomp',  'user_api': 'openmp',  'version': None}, {'architecture': 'SkylakeX',  'filepath': '/usr/lib64/libopenblaso-r0.3.21.so',  'internal_api': 'openblas',  'num_threads': 16,  'prefix': 'libopenblas',  'threading_layer': 'openmp',  'user_api': 'blas',  'version': '0.3.21'}]None### Context for the issue:The code expects a variable, and now returned are other parts of memory that could cause segmentation faults.Also, the data type is not what is expected, so the python code breaks (in this case, it was used to concatenate a list of strings, but one was an array with arbitrary data from memory, and the GUI function that was passed to (to set as Window title) was not happy about some of the characters, such as `\x00`.Could you please also point me where in f2py this issue may occur?Initially I was happy when I read in the NumPy 1.24 release notes that there have been some improvements to handling of strings - to try them out - but now it seems the change also had some side effect and broke at least my string declarations.:-(PS - Is there a more detailed statement / example what has changes and is the new functionality of `f2py` for strings?
"
23179,0,764,252,0,1,mhvk,0,"title:BUG/ENH: Fix fast index loops for 1-el array / allow scalar value description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->Fixes #23178 and also ensures that regular scalar values take the fast path for the index loops (like `np.add.at`).EDIT: new timings:```In [2]: import numpy as np; c = np.zeros(1000, complex); r = c.view(float); i = np.repeat(np.arange(999, 1, -1, dtype=np.intp), 100); np.__version__Out[2]: '1.25.0.dev0+597.gc4c0bbd36'In [3]: %timeit np.add.at(r, i, np.ones(1))324 缂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌熼悙顒€澧柣鏂挎閹便劌顪冪拠韫婵?闂?3.97 缂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌熼悙顒€澧柣鏂挎閹便劌顪冪拠韫婵?per loop (mean 闂?std. dev. of 7 runs, 1,000 loops each)In [4]: %timeit np.add.at(r, i, np.ones(()))324 缂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌熼悙顒€澧柣鏂挎閹便劌顪冪拠韫婵?闂?2.88 缂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌熼悙顒€澧柣鏂挎閹便劌顪冪拠韫婵?per loop (mean 闂?std. dev. of 7 runs, 1,000 loops each)In [5]: %timeit np.add.at(r, i, 1.)317 缂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌熼悙顒€澧柣鏂挎閹便劌顪冪拠韫婵?闂?690 ns per loop (mean 闂?std. dev. of 7 runs, 1,000 loops each)In [6]: %timeit np.add.at(r, i, 1)8.55 ms 闂?39.1 缂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌熼悙顒€澧柣鏂挎閹便劌顪冪拠韫婵?per loop (mean 闂?std. dev. of 7 runs, 100 loops each)```Last one is slow because of the need for casting (maybe can be special-cased too, but for another time!)EDIT2: for comparison on the same machine,```In [3]: %timeit np.bincount(i)264 缂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌熼悙顒€澧柣鏂挎閹便劌顪冪拠韫婵?闂?1.48 缂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌熼悙顒€澧柣鏂挎閹便劌顪冪拠韫婵?per loop (mean 闂?std. dev. of 7 runs, 1,000 loops each)```
"
23178,0,1941,252,0,0,mhvk,0,"title:BUG: New indexed loops give segmentation fault for 1-element 1-d values description:### Describe the issue:New indexed loops give segmentation fault for 1-element 1-d values.My guess is that the step size `isb` for `value` for this case should be set to 0.### Reproduce the code example:```pythonimport numpy as npr = np.zeros(1000)i = np.repeat(np.arange(999, 1, -1, dtype=np.intp), 100)np.add.at(r, i, np.ones(1))```### Error message:```shell# Segmentation faultgdb --args python3 ~/x.py -g --pythonProgram received signal SIGSEGV, Segmentation fault.0x00007ffff6f71775 in DOUBLE_add_indexed (__NPY_UNUSED_TAGGEDcontext=<optimized out>, args=<optimized out>, dimensions=<optimized out>, steps=<optimized out>,     __NPY_UNUSED_TAGGEDfunc=<optimized out>) at numpy/core/src/umath/loops_arithm_fp.dispatch.c.src:177177             *indexed = *indexed @OP@ *(@type@ *)value;```### Runtime information:```In [1]: import sys, numpy; print(numpy.__version__); print(sys.version)1.25.0.dev0+597.gc4c0bbd363.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110]In [2]: print(numpy.show_runtime())WARNING: `threadpoolctl` not found in system! Install it by `pip install threadpoolctl`. Once installed, try `np.show_runtime` again for more detailed build information[{'numpy_version': '1.25.0.dev0+597.gc4c0bbd36',  'python': '3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]',  'uname': uname_result(system='Linux', node='swan.astro.utoronto.ca', release='5.10.0-20-amd64', version='#1 SMP Debian 5.10.158-2 (2022-12-13)', machine='x86_64')}, {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3', 'SSE41', 'POPCNT', 'SSE42', 'AVX'],                      'not_found': ['F16C',                                    'FMA3',                                    'AVX2',                                    'AVX512F',                                    'AVX512CD',                                    'AVX512_KNL',                                    'AVX512_KNM',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}]None```### Context for the issue:Found while trying to add complex loops.
"
23174,0,0,9,0,1,Developer-Ecosystem-Engineering,0,"title:BUG: Fix Apple silicon builds by working around clang partial load bug in 闂?""Resolve the issue in https://github.com/numpy/numpy/pull/21056 by using volatile. When partially loading a vector register for a divide operation description: the remaining elements are set to 1 to avoid divide-by-zero.  The partial load is paired with a partial store after the divide operation.  clang notices that the entire register is not needed for the store and optimizes out the fill of 1 to the remaining elements.  This causes either a divide-by-zero or 0/0 with invalid exception that we were trying to avoid by filling."
23155,1,3095,72,0,1,abhinit21,0,"title:BUG: numpy.ufunc size changed, may indicate binary incompatibility. Expected 232 from C header, got 216 from PyObject description:### Describe the issue:I am using `python3.10`### Reproduce the code example:```pythonimport numpy as npfrom sklearn.feature_extraction.text import TfidfVectorizercorpus = ['This is the first document.', 'This document is the second document.']vectorizer = TfidfVectorizer()X = vectorizer.fit_transform(corpus)vectorizer.get_feature_names_out()```### Error message:```shellValueError                                Traceback (most recent call last)~\AppData\Local\Temp\ipykernel_7056\80431149.py in <module>      1 import pandas as pd      2 ----> 3 from utils.matching import get_matches_df, get_merged_matches      4 from utils.processing import preprocess~\Forest\tejaDataClean\notebooks\utils\matching.py in <module>      2 from fuzzywuzzy import fuzz      3 ----> 4 from sklearn.feature_extraction.text import TfidfVectorizer      5 from sklearn.neighbors import NearestNeighbors      6 from ftfy import fix_text~\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\__init__.py in <module>     80     from . import _distributor_init  # noqa: F401     81     from . import __check_build  # noqa: F401---> 82     from .base import clone     83     from .utils._show_versions import show_versions     84 ~\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\base.py in <module>     15 from . import __version__     16 from ._config import get_config---> 17 from .utils import _IS_32BIT     18 from .utils._set_output import _SetOutputMixin     19 from .utils._tags import (~\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\__init__.py in <module>     17 from scipy.sparse import issparse     18 ---> 19 from .murmurhash import murmurhash3_32     20 from .class_weight import compute_class_weight, compute_sample_weight     21 from . import _joblibsklearn\utils\murmurhash.pyx in init sklearn.utils.murmurhash()ValueError: numpy.ufunc size changed, may indicate binary incompatibility. Expected 232 from C header, got 216 from PyObject```### Runtime information:```import sysimport numpyprint(numpy.__version__)print(sys.version)```>1.24.1>3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]Output of `print(numpy.show_runtime())````[{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2'],                      'not_found': ['AVX512F',                                    'AVX512CD',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}, {'architecture': 'Haswell',  'filepath': 'C:\\Users\\KARTHIKEYA\\Forest\\tejaDataClean\\venv\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll',  'internal_api': 'openblas',  'num_threads': 8,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.21'}]None```### Context for the issue:_No response_
"
23151,0,1624,214,0,0,FrancescElies,0,"title:Typing: pyright assert_allclose reportUnknownMemberType  description:### Describe the issue:Maybe related to #23137 #23144  https://github.com/microsoft/pyright/discussions/4536Should `assert_allclose` and `allclose` bee seen the same way from pyright's perspective?### Reproduce the code example:```python# pyright: strictimport numpy as nppout = np.array([1, 2, 3], dtype=np.int32)ref = np.array([1, 2, 3], dtype=np.int32)atol = 4e-4np.allclose(pout, ref, rtol=0, atol=atol)np.testing.assert_allclose(pout, ref, rtol=0, atol=atol, err_msg=""oops"")```To reproduce you can either get the latest numpy master or `1.24.1` and apply patch from #23144 to the typings folder created by `pyright --createstub numpy`### Error message:```shell闂?pyright mytest.pyNo configuration file found.No pyproject.toml file found.Assuming Python platform WindowsSearching for source filesFound 1 source filepyright 1.1.292C:\s\mytest\strict\mytest.py  C:\s\mytest\strict\mytest.py:10:1 - error: Type of ""assert_allclose"" is partially unknown  闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀閸屻劎鎲稿澶嬪仼闁绘垹鐡旈弫鍡涙煕閺囥劌浜為柛鏃撶畱椤啴濡堕崱妤冪懆闂佺锕ラ幃鍌氼嚕缁嬫鍚嬪璺猴功妤犲洭姊洪崘鍙夋儓闁哥喍鍗抽獮妤佸垔椤╂潉 of ""assert_allclose"" is ""Overload[(actual: _SupportsArray[dtype[Unknown]] | _NestedSequence[_SupportsArray[dtype[Unknown]]] | bool | int | float | complex | _NestedSequence[bool | int | float | complex], desired: _SupportsArray[dtype[Unknown]] | _NestedSequence[_SupportsArray[dtype[Unknown]]] | bool | int | float | complex | _NestedSequence[bool | int | float | complex], rtol: float = ..., atol: float = ..., equal_nan: bool = ..., err_msg: str = ..., verbose: bool = ...) -> None, (actual: _SupportsArray[dtype[Unknown]] | _NestedSequence[_SupportsArray[dtype[Unknown]]] | bool | int | _NestedSequence[bool | int], desired: _SupportsArray[dtype[Unknown]] | _NestedSequence[_SupportsArray[dtype[Unknown]]] | bool | int | _NestedSequence[bool | int], rtol: float = ..., atol: float = ..., equal_nan: bool = ..., err_msg: str = ..., verbose: bool = ...) -> None]"" (reportUnknownMemberType)1 error, 0 warnings, 0 informationsCompleted in 0.917sec``````### Runtime information:```pythonIn [3]: print(np.show_runtime())WARNING: `threadpoolctl` not found in system! Install it by `pip install threadpoolctl`. Once installed, try `np.show_runtime` again for more detailed build information[{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2'],                      'not_found': ['AVX512F',                                    'AVX512CD',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}]```### Context for the issue:_No response_
"
23149,0,0,275,0,1,charris,0,"title:BUG: Add missing <type_traits> header. description:`std::is_scalar` is defined in `type_traits`, which is missing from the includes.Fixes a compilation failure.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
23148,0,0,275,0,1,charris,0,"title:BUG: Fix integer / float scalar promotion description:Backport of #23079.Integer true division converted the other type directly to the output. This is correct if both operands are integers, but since the output of integer division is double precision, it is incorrect when the other operand is a float32 or float16.The solution is that we must convert to the same type (as always) and only the output type is adjusted, but not the inputs.This means that `integer / float` will correctly defer to the float which leads to correct promotion.---This fixes an issue found by CuPy in https://github.com/cupy/cupy/pull/7340#discussion_r1084845887<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
23147,0,1475,275,0,1,charris,0,"title:BUG: Fix for npyv__trunc_s32_f32 (VXE) description:Backport of #23077.np.sin(), np.cos() are giving erroneous result for float32 (VXE). This PR is fixing ` npyv__trunc_s32_f32(npyv_f32 a)` to resolve the issue.np.sin() reproduce (without fix)```python>>> c = np.array( [-25.091976, 90.14286], dtype=np.float32)>>> np.sin(c)array([0.04075377, 0.5707917 ], dtype=float32)>>> >>> c = np.array( [90.14286], dtype=np.float32)>>> np.sin(c)array([0.8210949], dtype=float32)>>>>>> c = np.array( [-25.091976,  90.14286,   46.39879], dtype=np.float32)>>> np.sin(c)array([ 0.04075377, -0.5707917 ,  0.6632113 ], dtype=float32)  ```After the fix: ```python>>> import numpy as np>>> c = np.array( [-25.091976, 90.14286], dtype=np.float32)>>> np.sin(c)array([0.04075377, 0.8210949 ], dtype=float32)>>> c = np.array( [90.14286], dtype=np.float32)>>> np.sin(c)array([0.8210949], dtype=float32)>>> c = np.array( [-25.091976,  90.14286,   46.39879], dtype=np.float32)>>> np.sin(c)array([0.04075377, 0.8210949 , 0.6632113 ], dtype=float32)>>>```Test failure without fix - ```pythonFAILED ../../core/tests/test_umath.py::TestAVXFloat32Transcendental::test_sincos_float32 - AssertionError: Arrays are not almost equal up to 2 ULP (max difference is 2.13071e+09 ULP)FAILED ../../core/tests/test_umath.py::TestAVXFloat32Transcendental::test_strided_float32 - AssertionError: X and Y are not equal to 2 ULP (max is 6.79208e+06)FAILED ../../core/tests/test_umath_accuracy.py::TestAccuracy::test_validate_fp16_transcendentals[cos] - AssertionError: Arrays are not almost equal up to 1 ULP (max difference is 30720 ULP)FAILED ../../core/tests/test_umath_accuracy.py::TestAccuracy::test_validate_fp16_transcendentals[sin] - AssertionE```<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
23137,0,2069,214,0,0,FrancescElies,0,"title:BUG: np.allclose pyright reportUnknownMemberType description:### Describe the issue:We are currently evaluating mypy and pyright in our codebase and we found pyright to complain about `np.allclose` in where maybe it shouldn't.I am aware that strict mode in _mypy_ and _pyright_ doesn't mean the same, but I wondered where this unknown (see error below) was coming from, in my naive view that script has nothing unknown to it in terms of types, but things are probably more complex under the surface.I have been suggested that The type _dtype_ is a generic class that accepts a single type argument. Since none is provided, its type is _dtype[Unknown]_. That's the origin of the Unknown type that _pyright_ is telling you about here. This isn't a bug in _pyright_. It's an omission in the _numpy_ code, and it would need to be addressed there.Is this a bug in numpy typing defs? ### Reproduce the code example:```python# pyright: strictimport numpy as npnp.allclose(np.array([1.0, 2.0, 3.0]), np.array([1.0, 2.0, 3.0]))```### Error message:```shell闂?mypy --strict allclose.pySuccess: no issues found in 1 source file闂?mypy -Vmypy 0.991 (compiled: yes)```But pyright throws the following```闂?pyright allclose.pyNo configuration file found.No pyproject.toml file found.stubPath C:\s\mytest\numpy\typings is not a valid directory.Assuming Python platform WindowsSearching for source filesFound 1 source filepyright 1.1.291C:\s\mytest\numpy\allclose.py  C:\s\mytest\numpy\allclose.py:4:1 - error: Type of ""allclose"" is partially unknown    Type of ""allclose"" is ""(a: _SupportsArray[dtype[Unknown]] | _NestedSequence[_SupportsArray[dtype[Unknown]]] | bool | int | float | complex | str | bytes | _NestedSequence[bool | int | float | complex | str | bytes], b: _SupportsArray[dtype[Unknown]] | _NestedSequence[_SupportsArray[dtype[Unknown]]] | bool | int | float | complex | str | bytes | _NestedSequence[bool | int | float | complex | str | bytes], rtol: float = ..., atol: float = ..., equal_nan: bool = ...) -> bool"" (reportUnknownMemberType)1 error, 0 warnings, 0 informationsCompleted in 0.931sec```### Runtime information:```In [3]: print(np.show_runtime())WARNING: `threadpoolctl` not found in system! Install it by `pip install threadpoolctl`. Once installed, try `np.show_runtime` again for more detailed build information[{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2'],                      'not_found': ['AVX512F',                                    'AVX512CD',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}]```### Context for the issue:For more context see [here](https://github.com/microsoft/pyright/discussions/4536), also tried asking in the [chat](https://gitter.im/numpy/numpy?at=63d8cdd0d00f0d494734b649) too.
"
23128,0,0,262,0,1,hawkinsp,0,"title:BUG: Add missing <type_traits> header. description:`std::is_scalar` is defined in `type_traits`, which is missing from the includes.Fixes a compilation failure.
"
23115,0,4044,21,0,1,robbmcleod,0,"title:BUG: `PyArray_SimpleNew` with partial zero-dim array segfaults in `numpy >= 1.23` description:### Describe the issue:In the C-API, consider the case where one of the dimensions is zero, e.g. `{0, 512,  512}` and one allocates an array with `PyArray_SimpleNew` or similar. In NumPy <= 1.22 this works fine. In NumPy >= 1.23 this seg-faults. When I ran Valgrind on it, it was claiming that only a block of 1 byte was allocated and I was doing an invalid write. Valgrind run  when compiled against NumPy 1.22 sees no issues. I don't see anything in the release notes that indicate this might be intended and I don't remember a discussion about this on the mailing list, but it would have been awhile ago. My code example is not self-contained, because it's C-API, nor have I checked this outside of my virtual machine. If this issue is new to you, I can prepare a toy Python package.### Reproduce the code example:```pythonnpy_intp dims[3] = {0, 512, 512};PyObject *ray = PyArray_SimpleNew(3, dims, NPY_UINT16);npy_uint16 *data = (npy_uint16 *)PyArray_DATA((PyArrayObject *)ray);for(npy_int64 I=0; I < 512; I++ {   data[I] = 3.1416;}```### Error message:Valgrind output provided. GDB output is not super helpful because it is a multi-threaded VM.```shell==3273== Thread 33:==3273== Invalid write of size 2==3273==    at 0x4AB429AB: bshuf_shuffle_bit_eightelem_SSE (in /home/eunice/dev/framestream/framestream/core.cpython-310-x86_64-linux-gnu.so)==3273==    by 0x4AB42A4B: bshuf_untrans_bit_elem_SSE (in /home/eunice/dev/framestream/framestream/core.cpython-310-x86_64-linux-gnu.so)==3273==    by 0x4AB414C0: bshuf_decompress_lz4_block (in /home/eunice/dev/framestream/framestream/core.cpython-310-x86_64-linux-gnu.so)==3273==    by 0x4AB42DAE: bshuf_blocked_wrap_fun (in /home/eunice/dev/framestream/framestream/core.cpython-310-x86_64-linux-gnu.so)==3273==    by 0x4AB37FC5: DecompressBSLZ4Op<unsigned char>::run(vm::FrameItem*) (decompress_bslz4.cpp:90)==3273==    by 0x4AB16BFC: vm::Task::run() (thread.cpp:137)==3273==    by 0x4AB17268: vm::StreamThread::go() (thread.cpp:216)==3273==    by 0x4AB4117D: vm::Thread::threadProc(void*) (thread_base.cpp:42)==3273==    by 0x49F1B42: start_thread (pthread_create.c:442)==3273==    by 0x4A82BB3: clone (clone.S:100)==3273==  Address 0x42b5eade is 13 bytes after a block of size 1 alloc'd==3273==    at 0x4848899: malloc (in /usr/libexec/valgrind/vgpreload_memcheck-amd64-linux.so)==3273==    by 0x58CEA13: default_malloc (in /home/eunice/mambaforge/envs/azorus_1.2/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-x86_64-linux-gnu.so)==3273==    by 0x58CF1AE: PyDataMem_UserNEW (in /home/eunice/mambaforge/envs/azorus_1.2/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-x86_64-linux-gnu.so)==3273==    by 0x592DA74: PyArray_NewFromDescr_int (in /home/eunice/mambaforge/envs/azorus_1.2/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-x86_64-linux-gnu.so)==3273==    by 0x592F558: PyArray_New (in /home/eunice/mambaforge/envs/azorus_1.2/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-x86_64-linux-gnu.so)==3273==    by 0x4AB331EF: Matrix<unsigned short>::Matrix(long, long, long) (matrix.hpp:223)==3273==    by 0x4AB18BD0: vm::Operation::prepare(vm::FrameItem*) (operation.cpp:226)==3273==    by 0x4AB37D7B: DecompressBSLZ4Op<unsigned char>::prepare(vm::FrameItem*) (decompress_bslz4.cpp:49)==3273==    by 0x4AB16B6D: vm::Task::prepare(vm::FrameItem*) (thread.cpp:107)==3273==    by 0x4AB1BA49: vm::ThreadPool::queueItem(vm::FrameItem*) (thread.cpp:402)==3273==    by 0x4AB1C0E7: pyFSJob_submit(vm::FSJob*, _object*) (job.cpp:264)==3273==    by 0x2638D8: method_vectorcall_VARARGS (descrobject.c:311)==3273== --3273-- VALGRIND INTERNAL ERROR: Valgrind received a signal 11 (SIGSEGV) - exiting--3273-- si_code=1;  Faulting address: 0x0;  sp: 0x1011261dd0```### Runtime information:This is a Windows output, Linux output is similar. Faults occur on both platforms.```Python 3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)] on win32Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> import numpy>>> print(numpy.show_runtime())[{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2',                                'AVX512F',                                'AVX512CD',                                'AVX512_SKX',                                'AVX512_CLX'],                      'not_found': ['AVX512_CNL', 'AVX512_ICL']}}, {'filepath': 'C:\\Anaconda3\\envs\\azorus_1.2\\Library\\bin\\libblas.dll',  'internal_api': 'mkl',  'num_threads': 12,  'prefix': 'libblas',  'threading_layer': 'intel',  'user_api': 'blas',  'version': '2021.4-Product'}]```### Context for the issue:I can resolve the problem by putting in checks for zero-valued dimensions but being able to use a constant number of dimensions (3 in my case) is useful for avoiding many branches in C-code (and hence helps performance). Having to check the dimensions and provide different computing paths for each case leads to a lot of boilerplate.
"
23112,1,0,292,0,0,seberg,0,"title:BUG: Move `NPY_END_ALLOW_THREADS` to earlier in `from_text` description:Probably doesn't matter in practice, but saw it while looking a bit at gh-23037.  There is a small chance that it is related.
"
23098,0,192,86,0,1,ganesh-k13,0,"title:BUG: Handle arrays in `conf_data` description:### What's the bug?* `configuration_data` does not support `lists` as the data argument* ref: https://mesonbuild.com/Reference-manual_functions.html#arguments12* Hence, it expands the list leading to more than 2 args if we have more elementsFound this after I installed `ccache` when I was porting this to SciPy### Error before fix:```numpy/meson.build:167:12: ERROR: configuration_data.set takes exactly 2 arguments, but got 3.```### Output after fix```In [6]: np.show_config(mode='dicts')['Compilers']['c++']['commands']Out[6]: 'ccache, c++'```Part of: https://github.com/numpy/numpy/pull/22769
"
23095,0,2008,7,0,0,liusitan,0,"title:BUG: Building with python<3.9 should error out early in the build process with a clear message description:### Describe the issue:I can not compile numpy from the source code in commit 1bb932f69e0974f11c98b6036529a014aa8dfaf2 . ### Reproduce the code example:```pythongit clone git@github.com:numpy/numpy.gitgit submodule update --initpython -m pip install -r test_requirements.txtpython runtests.py -v```### Error message:```shellerror: Command ""x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -Werror=vla -Werror=nonnull -Werror=pointer-arith -Wlogical-op -Werror=unused-function -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -Ibuild/src.linux-x86_64-3.8/numpy/core/src/multiarray -Ibuild/src.linux-x86_64-3.8/numpy/core/src/common -Ibuild/src.linux-x86_64-3.8/numpy/core/src/umath -Inumpy/core/include -Ibuild/src.linux-x86_64-3.8/numpy/core/include/numpy -Ibuild/src.linux-x86_64-3.8/numpy/distutils/include -Ibuild/src.linux-x86_64-3.8/numpy/core/src/npysort -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/src/_simd -I/usr/include/python3.8 -Ibuild/src.linux-x86_64-3.8/numpy/core/src/common -Ibuild/src.linux-x86_64-3.8/numpy/core/src/npymath -c numpy/core/src/multiarray/arrayfunction_override.c -o build/temp.linux-x86_64-3.8/numpy/core/src/multiarray/arrayfunction_override.o -MMD -MF build/temp.linux-x86_64-3.8/numpy/core/src/multiarray/arrayfunction_override.o.d -msse -msse2 -msse3"" failed with exit status 1when I trace back:it bloated at here. numpy/core/src/multiarray/arrayfunction_override.c: At top level:numpy/core/src/multiarray/arrayfunction_override.c:693:40: error: 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨搴ㄦ煕閵夈儺鍤熺紒杈ㄦ尰閹峰懘宕滈崣澹劑姊洪幖鐐测偓妤呭箰閸濇湉LAGS_HAVE_VECTORCALL闂?undeclared here (not in a function); did you mean 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨搴ㄦ煕閵夈儺鍤熺紒杈ㄦ尰閹峰懘宕滈崣澹劑姊洪幖鐐测偓妤呭箰閸濇湉LAGS_HAVE_VERSION_TAG闂?  693 |      .tp_flags = (Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_VECTORCALL      |                                        ^~~~~~~~~~~~~~~~~~~~~~~~~~      |                                        Py_TPFLAGS_HAVE_VERSION_TAG```### Runtime information:Python: Python 3.8.10### Context for the issue:_No response_
"
23094,0,0,292,0,1,ngoldbaum,0,"title:BUG: fix type in resolve_descriptors_function typedef description:Currently this typedef differs from the ""real"" typedef in `array_method.h`: https://github.com/numpy/numpy/blob/930addb6dace3988268112ab56fe638d2941a7c3/numpy/core/src/multiarray/array_method.h#L90-L95 This PR fixes it to match.
"
23093,0,0,292,0,1,seberg,0,"title:BUG: Fixup f2py's handling a very little bit description:This clears the error holding only to the type.  Since in the other path the errmessage seemed completely uninitialized, I opted to just ignore it entirely and keep the old error.I could fathom to use error chaining here, but overall, I am not even sure that chaining makes even sense for these errors.  This fix is meant to be minimal (the second one, I just noticed randomly), it does not make this code clean.
"
23090,0,0,292,0,1,seberg,0,"title:BUG: Fix crash when using complex double scalars with NEP 50 description:Not adding a test since there is already a test that crashes due to this, it just isn't used with weak promotion and right now I am hoping I may be able to make the test suite runnable enabling it.
"
23079,0,0,292,0,1,seberg,0,"title:BUG: Fix `integer / float` scalar promotion description:Integer true division converted the other type directly to the output. This is correct if both operands are integers, but since the output of integer division is double precision, it is incorrect when the other operand is a float32 or float16.The solution is that we must convert to the same type (as always) and only the output type is adjusted, but not the inputs.This means that `integer / float` will correctly defer to the float which leads to correct promotion.---This fixes an issue found by CuPy in https://github.com/cupy/cupy/pull/7340#discussion_r1084845887
"
23077,0,1475,24,0,1,pradghos,0,"title:BUG: Fix for npyv__trunc_s32_f32 (VXE) description:np.sin(), np.cos() are giving erroneous result for float32 (VXE). This PR is fixing ` npyv__trunc_s32_f32(npyv_f32 a)` to resolve the issue.np.sin() reproduce (without fix)```python>>> c = np.array( [-25.091976, 90.14286], dtype=np.float32)>>> np.sin(c)array([0.04075377, 0.5707917 ], dtype=float32)>>> >>> c = np.array( [90.14286], dtype=np.float32)>>> np.sin(c)array([0.8210949], dtype=float32)>>>>>> c = np.array( [-25.091976,  90.14286,   46.39879], dtype=np.float32)>>> np.sin(c)array([ 0.04075377, -0.5707917 ,  0.6632113 ], dtype=float32)  ```After the fix: ```python>>> import numpy as np>>> c = np.array( [-25.091976, 90.14286], dtype=np.float32)>>> np.sin(c)array([0.04075377, 0.8210949 ], dtype=float32)>>> c = np.array( [90.14286], dtype=np.float32)>>> np.sin(c)array([0.8210949], dtype=float32)>>> c = np.array( [-25.091976,  90.14286,   46.39879], dtype=np.float32)>>> np.sin(c)array([0.04075377, 0.8210949 , 0.6632113 ], dtype=float32)>>>```Test failure without fix - ```pythonFAILED ../../core/tests/test_umath.py::TestAVXFloat32Transcendental::test_sincos_float32 - AssertionError: Arrays are not almost equal up to 2 ULP (max difference is 2.13071e+09 ULP)FAILED ../../core/tests/test_umath.py::TestAVXFloat32Transcendental::test_strided_float32 - AssertionError: X and Y are not equal to 2 ULP (max is 6.79208e+06)FAILED ../../core/tests/test_umath_accuracy.py::TestAccuracy::test_validate_fp16_transcendentals[cos] - AssertionError: Arrays are not almost equal up to 1 ULP (max difference is 30720 ULP)FAILED ../../core/tests/test_umath_accuracy.py::TestAccuracy::test_validate_fp16_transcendentals[sin] - AssertionE``` cc @Andreas-Krebbel @potula-chandra @andrewsi-z 
"
23071,0,81,268,0,0,rgommers,1,"title:`debug` CI job is crashing description:This has happened a couple of times now ([example log](https://github.com/numpy/numpy/actions/runs/3981562601/jobs/6825432906)). Will show up like:```./tools/travis-test.sh: line 82:  4665 Aborted                 (core dumped) ```The Ubuntu CI image was changed a few days ago in gh-23026. And gh-23037 (for MSVC) may perhaps be related.
"
23070,0,0,268,0,0,rgommers,0,"title:Cygwin CI job fails with `f2py` errors description:See for example [this CI log](https://github.com/numpy/numpy/actions/runs/3981840176/jobs/6825839167). Failures: =========================== short test summary info ============================FAILED ../../f2py/tests/test_compile_function.py::test_f2py_init_compile[extra_args0]FAILED ../../f2py/tests/test_compile_function.py::test_compile_from_strings[program test_f2py\nend program test_f2py0]FAILED ../../f2py/tests/test_compile_function.py::test_compile_from_strings[program test_f2py\nend program test_f2py1]FAILED ../../tests/test_public_api.py::test_import_lazy_import[testing] - Blo...ERROR ../../f2py/tests/test_character.py::TestMiscCharacter::test_gh18684 - B...ERROR ../../f2py/tests/test_character.py::TestMiscCharacter::test_gh6308 - Bl...ERROR ../../f2py/tests/test_character.py::TestMiscCharacter::test_gh4519 - Bl...ERROR ../../f2py/tests/test_character.py::TestMiscCharacter::test_gh3425 - Bl...ERROR ../../f2py/tests/test_character.py::TestMiscCharacter::test_character_bc[new]ERROR ../../f2py/tests/test_character.py::TestMiscCharacter::test_character_bc[old]ERROR ../../f2py/tests/test_crackfortran.py::TestCrackFortran::test_gh2848 - ...ERROR ../../f2py/tests/test_string.py::TestDocStringArguments::test_example= 4 failed, 27912 passed, 203 skipped, 1306 deselected, 35 xfailed, 1 xpassed, 8 errors in 546.40s (0:09:06) Cc @DWesl have you seen this before? May be due to the 22 Jan Cygwin release, not sure.
"
23066,0,0,268,0,1,rgommers,0,"title:BUG: fix broken numpy.distutils Fortran handling description:The `Path` and `COMMON_FIXED_EXTENSIONS` variables were not defined at all. This code is untested, and SciPy doesn't build with NumPy `main` before this fix. The issue was introduced a few days ago in gh-22885.
"
23039,0,0,292,0,0,seberg,0,"title:BUG: Implement `ArrayFunctionDispatcher.__get__` description:While functions should not normally need this, Python functions do provide it (C functions do not, but we are a fatter object anyway).By implementing `__get__` we also ensure that `inspect.isroutine()` passes.  And by that we ensure that Sphinx considers these a `py:function:` role.Closes gh-23032
"
23035,1,69,3,0,0,sprasad14,0,"title:BUG: Not able to build Numpy 1.24.1 for AArch64 description:### Describe the issue:The following errors are reported while generating numpy/core/_multiarray_umath.cpython-38-aarch64-linux-gnu.so using aarch64-buildroot-linux-gnu-gcc.Is there a way to avoid including AVX512 .s files from the compilation?numpy/core/src/umath/svml/linux/avx512/svml_z0_acos_d_la.s:19: Error: unknown mnemonic `pushq' -- `pushq %rbp'numpy/core/src/umath/svml/linux/avx512/svml_z0_acos_d_la.s:21: Error: unknown mnemonic `movq' -- `movq %rsp,%rbp'numpy/core/src/umath/svml/linux/avx512/svml_z0_acos_d_la.s:24: Error: unknown mnemonic `andq' -- `andq $-64,%rsp'numpy/core/src/umath/svml/linux/avx512/svml_z0_acos_d_la.s:25: Error: unknown mnemonic `subq' -- `subq $192,%rsp'numpy/core/src/umath/svml/linux/avx512/svml_z0_acos_d_la.s:26: Error: unknown mnemonic `vmovups' -- `vmovups __svml_dacos_data_internal(%rip),%zmm7'numpy/core/src/umath/svml/linux/avx512/svml_z0_acos_d_la.s:27: Error: unknown mnemonic `vmovups' -- `vmovups 64+__svml_dacos_data_internal(%rip),%zmm8'numpy/core/src/umath/svml/linux/avx512/svml_z0_acos_d_la.s:30: Error: unknown mnemonic `vmovups' -- `vmovups 128+__svml_dacos_data_internal(%rip),%zmm11'.......### Reproduce the code example:```pythonI do not have any code since the build itself is a failure.```### Error message:_No response_### Runtime information:1.24.1### Context for the issue:I am building python-numpy package for buildroot linux for ARM 64-bit platform
"
23033,0,2940,277,0,0,neutrinoceros,0,"title:BUG: numpy dev breaks `scipy.stats` description:### Describe the issue:The current state of the dev branch (1.25.0.dev0+403.g0013550dc) breaks `scipy.stats` completely.### Reproduce the code example:```pythonimport scipy.stats```### Error message:```shell-tracebackTraceback (most recent call last):  File ""/Users/robcleme/dev/friends/AMICAL/t.py"", line 1, in <module>    import scipy.stats  File ""/Users/robcleme/.pyenv/versions/amical-dev/lib/python3.10/site-packages/scipy/stats/__init__.py"", line 467, in <module>    from ._stats_py import *  File ""/Users/robcleme/.pyenv/versions/amical-dev/lib/python3.10/site-packages/scipy/stats/_stats_py.py"", line 46, in <module>    from . import distributions  File ""/Users/robcleme/.pyenv/versions/amical-dev/lib/python3.10/site-packages/scipy/stats/distributions.py"", line 8, in <module>    from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen)  File ""/Users/robcleme/.pyenv/versions/amical-dev/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py"", line 27, in <module>    from scipy import integrate  File ""/Users/robcleme/.pyenv/versions/amical-dev/lib/python3.10/site-packages/scipy/integrate/__init__.py"", line 91, in <module>    from ._quadrature import *  File ""/Users/robcleme/.pyenv/versions/amical-dev/lib/python3.10/site-packages/scipy/integrate/_quadrature.py"", line 31, in <module>    trapezoid = _copy_func(trapezoid)  File ""/Users/robcleme/.pyenv/versions/amical-dev/lib/python3.10/site-packages/scipy/integrate/_quadrature.py"", line 24, in _copy_func    g = types.FunctionType(f.__code__, f.__globals__, name=f.__name__,AttributeError: 'numpy._ArrayFunctionDispatcher' object has no attribute '__code__'. Did you mean: '__call__'?```### Runtime information:```1.25.0.dev0+403.g0013550dc3.10.8 (main, Nov 13 2022, 10:42:10) [Clang 14.0.0 (clang-1400.0.29.202)]WARNING: `threadpoolctl` not found in system! Install it by `pip install threadpoolctl`. Once installed, try `np.show_runtime` again for more detailed build information[{'numpy_version': '1.25.0.dev0+403.g0013550dc',  'python': '3.10.8 (main, Nov 13 2022, 10:42:10) [Clang 14.0.0 '            '(clang-1400.0.29.202)]',  'uname': uname_result(system='Darwin', node='ipag-8102.u-ga.fr', release='22.2.0', version='Darwin Kernel Version 22.2.0: Fri Nov 11 02:08:47 PST 2022; root:xnu-8792.61.2~4/RELEASE_X86_64', machine='x86_64')}, {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2'],                      'not_found': ['AVX512F',                                    'AVX512CD',                                    'AVX512_KNL',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}]None```### Context for the issue:discovered today while running tests for a package that depends on both scipy and numpy, using nightly builds for bothhttps://github.com/SAIL-Labs/AMICAL/commit/8e7ebf05bf034218d1d78304542d29f4109ad534/checks?check_suite_id=10430628610
"
23031,0,0,275,0,1,charris,0,"title:BUG: use ``_Alignof`` rather than ``offsetof()`` on most compilers description:Backport of #23016.WG14 N2350 made very clear that it is an UB having type definitions within ""offsetof"" [1]. This patch enhances the implementation of macro _ALIGN to use builtin ""_Alignof"" to avoid undefined behavior on when using std=c11 or newerclang 16+ has started to flag this [2]Fixes build when using -std >= gnu11 and using clang16+Older compilers gcc < 4.9 or clang < 8 has buggy _Alignof even though it may support C11, exclude those compilers too[1] https://www.open-std.org/jtc1/sc22/wg14/www/docs/n2350.htm [2] https://reviews.llvm.org/D133574Signed-off-by: Khem Raj <raj.khem@gmail.com>* Apply suggestions from code reviewSigned-off-by: Khem Raj <raj.khem@gmail.com>Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net><!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
23016,0,0,300,0,1,kraj,0,"title:BUG: use ``_Alignof`` rather than ``offsetof()`` on most compilers description:WG14 N2350 made very clear that it is an UB having type definitions within ""offsetof"" [1]. This patch enhances the implementation of macro _ALIGN to use builtin ""_Alignof"" to avoid undefined behavior on when using std=c11 or newerclang 16+ has started to flag this [2]Fixes build when using -std >= gnu11 and using clang16+Older compilers gcc < 4.9 or clang < 8 has buggy _Alignof even though it may support C11, exclude those compilers too[1] https://www.open-std.org/jtc1/sc22/wg14/www/docs/n2350.htm [2] https://reviews.llvm.org/D133574Signed-off-by: Khem Raj <raj.khem@gmail.com><!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
23008,0,0,262,0,0,hawkinsp,0,"title:BUG: Use _Alignof to compute alignment. description:It is undefined behavior to have a type declaration inside `offsetof`, see:https://github.com/llvm/llvm-project/commit/e327b52766ed497e4779f4e652b9ad237dfda8e6This code will fail to compile under upcoming versions of clang.If we have a C11-compliant compiler, use `_Alignof` instead.
"
22999,1,3174,293,0,0,MarcoGorelli,0,"title:BUG: can't install nightly numpy on mac? description:### Describe the issue:I'm seeing the following from the pandas CI:```Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (22.3.1)Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (65.5.0)Collecting setuptools  Downloading setuptools-65.7.0-py3-none-any.whl (1.2 MB)     闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸婂潡鏌ㄩ弮鍌涙珪缂佺姵鍎抽埞鎴︽偐閸欏鎮欓梺缁樺笒閻忔岸濡甸崟顖氱鐎广儱鐗嗛崢鈥愁渻閵堝骸澧柛姘儔婵＄敻宕熼姘棟濠电偛妫涢崑鎾诲煝閸儲鈷戦柛婵嗗閻掕法绱掔紒妯肩疄鐎规洘妞介崺鈧い鎺嶉檷娴滄粓鏌熼悜妯虹仴妞ゅ浚浜弻锟犲川椤旇偐绁峰銈庡弨濞夋洟骞戦崟顖涘仏闁哄鍨甸～鐘绘⒒娴ｅ憡鍟為柨姘舵煟鎺抽崝搴ㄥ箲閵忕姭妲堟繛鍡樺姉缁夊爼姊洪崨濠冨瘷闁告劑鍔庨崢鎺楁⒑鐠囨彃顒㈡い鏃€鐗犲畷浼村冀椤撶喎浜梺缁樻尭鐎垫帡宕甸弴鐔翠簻闁规壋鏅涢悞鐑樼箾鐏忔牗娅婇柡灞诲€濆畷顐﹀Ψ閿旇姤鐦庨梻浣告啞钃遍柟鐟版搐椤繒绱掑Ο鑲╂嚌闂佹悶鍎滈崒婊冨毈缂傚倸鍊风粈渚€顢栭崱娑欏亱闁绘ɑ鐪归埀顑跨閳诲酣骞囬鍌滅嵁闂備礁缍婇崑濠囧储妤ｅ啫鍌ㄩ柟闂寸劍閳锋垿姊洪銈呬粶闁兼椿鍨遍弲鍫曞箻椤旂晫鍘告繛杈剧悼閹虫挻鎱ㄩ崼鈶╁亾閸偅绶查悗姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑?1.2/1.2 MB 32.2 MB/s eta 0:00:00Collecting wheel  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)Installing collected packages: wheel, setuptools  Attempting uninstall: setuptools    Found existing installation: setuptools 65.5.0    Uninstalling setuptools-65.5.0:      Successfully uninstalled setuptools-65.5.0Successfully installed setuptools-65.7.0 wheel-0.38.4Looking in indexes: https://pypi.anaconda.org/scipy-wheels-nightly/simpleCollecting numpy  Downloading https://pypi.anaconda.org/scipy-wheels-nightly/simple/numpy/1.25.0.dev0%2B363.gbb2769e12/numpy-1.25.0.dev0%2B363.gbb2769e12.tar.gz (10.9 MB)     闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸婂潡鏌ㄩ弮鍌涙珪缂佺姵鍎抽埞鎴︽偐閸欏鎮欓梺缁樺笒閻忔岸濡甸崟顖氱鐎广儱鐗嗛崢鈥愁渻閵堝骸澧柛姘儔婵＄敻宕熼姘棟濠电偛妫涢崑鎾诲煝閸儲鈷戦柛婵嗗閻掕法绱掔紒妯肩疄鐎规洘妞介崺鈧い鎺嶉檷娴滄粓鏌熼悜妯虹仴妞ゅ浚浜弻锟犲川椤旇偐绁峰銈庡弨濞夋洟骞戦崟顖涘仏闁哄鍨甸～鐘绘⒒娴ｅ憡鍟為柨姘舵煟鎺抽崝搴ㄥ箲閵忕姭妲堟繛鍡樺姉缁夊爼姊洪崨濠冨瘷闁告劑鍔庨崢鎺楁⒑鐠囨彃顒㈡い鏃€鐗犲畷浼村冀椤撶喎浜梺缁樻尭鐎垫帡宕甸弴鐔翠簻闁规壋鏅涢悞鐑樼箾鐏忔牗娅婇柡灞诲€濆畷顐﹀Ψ閿旇姤鐦庨梻浣告啞钃遍柟鐟版搐椤繒绱掑Ο鑲╂嚌闂佹悶鍎滈崒婊冨毈缂傚倸鍊风粈渚€顢栭崱娑欏亱闁绘ɑ鐪归埀顑跨閳诲酣骞囬鍌滅嵁闂備礁缍婇崑濠囧储妤ｅ啫鍌ㄩ柟闂寸劍閳锋垿姊洪銈呬粶闁兼椿鍨遍弲鍫曞箻椤旂晫鍘告繛杈剧悼閹虫挻鎱ㄩ崼鈶╁亾閸偅绶查悗姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑?10.9/10.9 MB 30.1 MB/s eta 0:00:00  Installing build dependencies: started  Installing build dependencies: finished with status 'error'  error: subprocess-exited-with-error    闂?pip subprocess to install build dependencies did not run successfully.  闂?exit code: 1  闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗霉閿濆懏鎯堟い銉︾閵囧嫰骞橀崡鐐典患缂佺偓鍎冲锟犲蓟閺囥垹閱囨繝闈涙祩濡倝姊虹紒妯肩畵闁绘牕銈搁獮鍐ㄎ旈崨顔芥珳闁硅偐琛ラ崜婵嬫倶閸垻纾? [3 lines of output]      Looking in indexes: https://pypi.anaconda.org/scipy-wheels-nightly/simple      ERROR: Could not find a version that satisfies the requirement setuptools==59.2.0 (from versions: none)      ERROR: No matching distribution found for setuptools==59.2.0      [end of output]    note: This error originates from a subprocess, and is likely not a problem with pip.error: subprocess-exited-with-error闂?pip subprocess to install build dependencies did not run successfully.闂?exit code: 1闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗霉閿濆懏鎯堟い銉︾閵囧嫰骞橀崡鐐典患缂佺偓鍎冲锟犲蓟閺囥垹閱囨繝闈涙祩濡倝姊虹紒妯肩畵闁绘牕銈搁獮鍐ㄎ旈崨顔芥珳闁硅偐琛ラ崜婵嬫倶閸垻纾? See above for output.note: This error originates from a subprocess, and is likely not a problem with pip.Error: Process completed with exit code 1.```Note that this happens even if I pin `setuptools` to `59.2.0` (again, only on mac):```Successfully installed setuptools-59.2.0Looking in indexes: https://pypi.anaconda.org/scipy-wheels-nightly/simpleCollecting numpy  Downloading https://pypi.anaconda.org/scipy-wheels-nightly/simple/numpy/1.25.0.dev0%2B363.gbb2769e12/numpy-1.25.0.dev0%2B363.gbb2769e12.tar.gz (10.9 MB)     闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸婂潡鏌ㄩ弮鍌涙珪缂佺姵鍎抽埞鎴︽偐閸欏鎮欓梺缁樺笒閻忔岸濡甸崟顖氱鐎广儱鐗嗛崢鈥愁渻閵堝骸澧柛姘儔婵＄敻宕熼姘棟濠电偛妫涢崑鎾诲煝閸儲鈷戦柛婵嗗閻掕法绱掔紒妯肩疄鐎规洘妞介崺鈧い鎺嶉檷娴滄粓鏌熼悜妯虹仴妞ゅ浚浜弻锟犲川椤旇偐绁峰銈庡弨濞夋洟骞戦崟顖涘仏闁哄鍨甸～鐘绘⒒娴ｅ憡鍟為柨姘舵煟鎺抽崝搴ㄥ箲閵忕姭妲堟繛鍡樺姉缁夊爼姊洪崨濠冨瘷闁告劑鍔庨崢鎺楁⒑鐠囨彃顒㈡い鏃€鐗犲畷浼村冀椤撶喎浜梺缁樻尭鐎垫帡宕甸弴鐔翠簻闁规壋鏅涢悞鐑樼箾鐏忔牗娅婇柡灞诲€濆畷顐﹀Ψ閿旇姤鐦庨梻浣告啞钃遍柟鐟版搐椤繒绱掑Ο鑲╂嚌闂佹悶鍎滈崒婊冨毈缂傚倸鍊风粈渚€顢栭崱娑欏亱闁绘ɑ鐪归埀顑跨閳诲酣骞囬鍌滅嵁闂備礁缍婇崑濠囧储妤ｅ啫鍌ㄩ柟闂寸劍閳锋垿姊洪銈呬粶闁兼椿鍨遍弲鍫曞箻椤旂晫鍘告繛杈剧悼閹虫挻鎱ㄩ崼鈶╁亾閸偅绶查悗姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑?10.9/10.9 MB 12.1 MB/s eta 0:00:00  Installing build dependencies: started  Installing build dependencies: finished with status 'error'  error: subprocess-exited-with-error    闂?pip subprocess to install build dependencies did not run successfully.  闂?exit code: 1  闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗霉閿濆懏鎯堟い銉︾閵囧嫰骞橀崡鐐典患缂佺偓鍎冲锟犲蓟閺囥垹閱囨繝闈涙祩濡倝姊虹紒妯肩畵闁绘牕銈搁獮鍐ㄎ旈崨顔芥珳闁硅偐琛ラ崜婵嬫倶閸垻纾? [3 lines of output]      Looking in indexes: https://pypi.anaconda.org/scipy-wheels-nightly/simple      ERROR: Could not find a version that satisfies the requirement setuptools==59.2.0 (from versions: none)      ERROR: No matching distribution found for setuptools==59.2.0      [end of output]```### Reproduce the code example:```python# note: pinning setuptools to 59.2.0 made no differencepython -m pip install --upgrade pip setuptools wheel  python -m pip install -i https://pypi.anaconda.org/scipy-wheels-nightly/simple numpy```### Error message:_No response_### Runtime information:the error happens before numpy can be installed, but here's some extra debug info:  macOS  12.6.2  21G320Python 3.11.1### Context for the issue:This is one of the pandas CI jobs: https://github.com/pandas-dev/pandas/actions/runs/3901907570/jobs/6664321626
"
22989,0,0,275,0,0,charris,0,"title:BUG: Ensure correct loop order in sin, cos, and arctan2 description:Backport of #22986.These were incorrect afer being vectorized.  The commit additional tests these (not arctan2 admittedly) and adds a check to generate_umath to make it a bit less likely that future additions add this type of thing.Note that the check allows duplicated loops so long they are correctly ordered the *first* time.  This makes results correct, but duplicated loops are not nice anyways and it would be nice to remove them.We could drop them manually in hindsight even?  In any case, that should not be backported, so it is not includedhere.Closes gh-22984<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22986,0,0,292,0,0,seberg,0,"title:BUG: Ensure correct loop order in sin, cos, and arctan2 description:These were incorrect afer being vectorized.  The commit additional tests these (not arctan2 admittedly) and adds a check to generate_umath to make it a bit less likely that future additions add this type of thing.Note that the check allows duplicated loops so long they are correctly ordered the *first* time.  This makes results correct, but duplicated loops are not nice anyways and it would be nice to remove them.We could drop them manually in hindsight even?  In any case, that should not be backported, so it is not includedhere.Closes gh-22984
"
22976,0,0,275,0,1,charris,0,"title:BUG, SIMD: Fix spurious invalid exception for sin/cos on arm64/clang description:Backport of #22954.closes #22933This includes the fixes prefixing `asm` with underscores  in #22921.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22975,1,1867,256,0,0,rikardn,0,"title:BUG: difference in multivariate_normal samples between numpy 1.23.5 and 1.24.1 at same seed description:### Describe the issue:In some cases sampling from a multivariate normal distribution give different samples between using numpy 1.23.5 and numpy 1.24.1 using the same rng and seed. The example with n = 7 or below will give the same samples between the numpy versions, but having n = 8 (or higher) the samples will be different, which is unexpected.### Reproduce the code example:```pythonimport numpy as nprng = np.random.default_rng(8978)sigma = [[ 3.77384e-04,  1.78985e-04, -9.45976e-06,  6.95925e-04,  9.76862e-05,   6.55149e-04,  1.04747e-05,  1.16840e-04,  1.68096e-04, -5.09766e-05], [ 1.78985e-04,  1.21699e-04,  4.11940e-06,  2.20735e-04,  1.60894e-04,   3.55346e-04,  6.13028e-05,  1.04650e-04,  3.06187e-04, -5.86387e-05], [-9.45976e-06,  4.11940e-06,  5.79782e-05,  1.94285e-04,  1.97596e-05,   5.93476e-04,  1.85140e-04,  8.77500e-05, -4.21243e-05,  2.21459e-06], [ 6.95925e-04,  2.20735e-04,  1.94285e-04,  3.86191e-03,  2.42335e-04,   5.52113e-03,  1.11664e-03,  3.50275e-04, -8.96832e-04, -9.95807e-04], [ 9.76862e-05,  1.60894e-04,  1.97596e-05,  2.42335e-04,  1.19349e-03,   1.31357e-03,  2.34006e-04, -3.59009e-06,  2.26896e-03, -9.60314e-04], [ 6.55149e-04,  3.55346e-04,  5.93476e-04,  5.52113e-03,  1.31357e-03,   5.80533e-02,  7.33231e-04,  1.02913e-03,  1.68334e-03,  2.39945e-03], [ 1.04747e-05,  6.13028e-05,  1.85140e-04,  1.11664e-03,  2.34006e-04,   7.33231e-04,  1.78939e-03,  3.31691e-04,  8.53473e-05, -1.04420e-03], [ 1.16840e-04,  1.04650e-04,  8.77500e-05,  3.50275e-04, -3.59009e-06,   1.02913e-03,  3.31691e-04,  7.87703e-04, -5.82814e-04,  6.88541e-04], [ 1.68096e-04,  3.06187e-04, -4.21243e-05, -8.96832e-04,  2.26896e-03,   1.68334e-03,  8.53473e-05, -5.82814e-04,  1.86714e-02,  1.17500e-03], [-5.09766e-05, -5.86387e-05,  2.21459e-06, -9.95807e-04, -9.60314e-04,   2.39945e-03, -1.04420e-03,  6.88541e-04,  1.17500e-03,  1.43419e-02]]mu = [ 0.0352093,   0.0192129,   0.0227801,   0.0433142,  -0.00279093,  0.983126, -0.0570624,   0.0438765,   0.0806757,   0.983166  ]mu = np.array(mu)sigma = np.array(sigma)# If n set to 7 or below the samples will be the samen = 8x = rng.multivariate_normal(mu[0:n], sigma[0:n, 0:n], size=1)print(x)```### Error message:_No response_### Runtime information:1.24.13.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0][{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2'],                      'not_found': ['AVX512F',                                    'AVX512CD',                                    'AVX512_KNL',                                    'AVX512_KNM',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}]NoneOperating system: LinuxArch: x64### Context for the issue:The issue breaks reproducibility of simulation results between the two numpy versions.
"
22970,0,0,275,0,1,charris,0,"title:BUG: Fix fill violating read-only flag. (#22959) description:Backport of #22959.- See #22922- `PyArray_FillWithScalar` checks if destination is writeable before attempting to fill it- A relevant test is added as a method of `TestRegression`Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net><!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22969,0,0,275,0,1,charris,0,"title:TST: Add fixture to avoid issue with randomizing test order. description:Backport of #22931.Adds a missing test fixture to prevent cross-talk between polynomial printing test classes when the test order is randomized with pytest-randomly.Addresses the immediate issue #22825 though there is another, deeper issue with polynomial printing thread safety. Therefore #22825 should either be left open or a follow-up issue opened.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22968,0,0,275,1,1,charris,0,"title:BUG: np.loadtxt cannot load text file with quoted fields separated by whitespace description:Backport of #22906- Resolves issue https://github.com/numpy/numpy/issues/22899- Fixed a bug in parsing line containing quoted fields separated by white spaces- Added doctest <!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22959,0,0,41,0,1,panosz,0,"title:BUG: Fix fill violating read-only flag. description:- See #22922- `PyArray_FillWithScalar` checks if destination is writeable before attempting to fill it- A relevant test is added as a method of `TestRegression`<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22954,0,0,164,0,1,seiko2plus,1,"title:BUG, SIMD: Fix spurious invalid exception for sin/cos on arm64/clang description:closes #22933 
"
22953,1,1024,221,0,0,danielmunioz,0,"title:BUG: Different results after using multi_dot vs functools.reduce for a chain of matrix multiplications description:### Describe the issue:Using multidot as opposed to simply doing a chain of matrix multiplications on a list of arrays yields different results, usually the results differ only on one of the elements of the resulting array (index [2, 1] in the code example).I'm not sure why this is cause, theoretically all multi_dot does is change the order of operations so technically there shouldn't be any difference on just doing `np.dot(np.dot(A, B), C)` (or as suggested in the docs `reduce(np.dot, (A, B, C))`) vs `multi_dot((A, B, C))` right?### Reproduce the code example:```pythonimport numpy as npfrom functools import reducearrays = (    np.array([[-1. , -1. ], [-1. , -1. ], [-1. , -0.5]], dtype=np.float32),    np.array([[-1.0000000e+00, -1.0000000e+00], [-1.7014118e+38, -1.0000000e+00]], dtype=np.float32),    np.array([[-1., -2.], [-1., -1.]], dtype=np.float32),)print(np.linalg.multi_dot(arrays))print(reduce(np.dot, arrays))assert (np.linalg.multi_dot(arrays) != reduce(np.dot, arrays)).all()```### Error message:```shell[[-1.7014118e+38           -inf] [-1.7014118e+38           -inf] [-8.5070592e+37           -inf]][[-1.7014118e+38           -inf] [-1.7014118e+38           -inf] [-8.5070592e+37 -1.7014118e+38]]---------------------------------------------------------------------------AssertionError                            Traceback (most recent call last)Cell In[61], line 13     11 print(np.linalg.multi_dot(arrays))     12 print(reduce(np.dot, arrays))---> 13 assert (np.linalg.multi_dot(arrays) != reduce(np.dot, arrays)).all()AssertionError:```### Runtime information:1.23.03.8.10 (default, Nov 14 2022, 12:59:47) [GCC 9.4.0]### Context for the issue:_No response_
"
22951,1,168,291,0,0,cmutel,0,"title:BUG: Architecture-inconsistent behaviour casting negative integers to unsigned integers (MacOS ARM) description:### Describe the issue:Converting a negative integer with dtype `float`, `float32`, or `float64` to `uint32` or `uint64` gives zero on MacOS ARM machines. * Tested on Numpy 1.23 and 1.24. * Tested on multiple MacOS ARM machines.* Expected behaviour is to wrap around the maximum unsigned integer, which is what is done on x64 machines* Wrap around *also works* when converting to `uint8` and `unint16`This exact operation is discussed in the [1.24 release notes](https://numpy.org/devdocs/release/1.24.0-notes.html#conversion-of-out-of-bound-python-integers), and the *provided example does work*. However, it fails when the input has dtype `float`, and conversion is to 32- or 64-bit unsigned integers.### Reproduce the code example:```pythonimport numpy as npnp.array(-1).astype(np.uint32)>>> array(4294967295, dtype=uint32)np.array(-1, dtype=float).astype(np.uint32)>>> array(0, dtype=uint32)```### Error message:_No response_### Runtime information:1.23.23.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:07:06) [Clang 13.0.1 ]-and-1.24.13.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33)[Clang 13.0.1 ][{'simd_extensions': {'baseline': ['NEON', 'NEON_FP16', 'NEON_VFPV4', 'ASIMD'],                      'found': ['ASIMDHP', 'ASIMDDP'],                      'not_found': ['ASIMDFHM']}}]### Context for the issue:This breaks correct matrix building for the [Brightway life cycle assessment framework](https://github.com/brightway-lca/).
"
22950,1,362,0,0,0,gnathand,0,"title:QUESTION (BUG?): stride of 0 for dimension of size 1 after use of newaxis. Arbitrary strides for dimensions of 1 more generally. description:### Describe the issue:When using newaxis to add a dimension to an array, the stride of that dimension is set to 0. This is inconsistent with the behaviour of resize(), and results in arr.stride != arr.data.strides.It is unclear whether this is actually a bug. The following documentation suggests it is _not_:_""Even for contiguous arrays a stride for a given dimension arr.strides[dim] may be arbitrary if arr.shape[dim] == 1 or the array has no elements.""_ https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flags.htmlHowever, it feels counter-intuitive, and it is not hard to imagine how somebody could naively rely upon a particular value of stride. If this is intentional, it may be worth additional clarification, and probably somewhere more conspicuous.### Reproduce the code example:```pythonx1 = np.array([[1,2,3]])x2 = np.array([1,2,3])x2.resize((1,3))x3 = np.array([1,2,3])[np.newaxis,:]x1.shape, x2.shape, x3.shape                       # ((1, 3), (1, 3), (1, 3))x1.strides, x2.strides, x3.strides                 # ((24, 8), (24, 8), (0, 8))x1.data.strides, x2.data.strides, x3.data.strides  # ((24, 8), (24, 8), (24, 8))```### Error message:_No response_### Runtime information:1.23.53.10.8 (main, Nov  4 2022, 09:21:25) [GCC 12.2.0]### Context for the issue:_No response_
"
22945,1,1173,7,0,0,jlevin,0,"title:BUG: numpy.linalg.svd returns wrong results in certain architecture on numpy 1.19.3 and later description:### Describe the issue:In numpy 1.19.3 or later, when using np.linalg.svd on a certain architecture, the 2nd and 3rd columns of the `u` result array and the 2nd and 3rd rows of the `vh` result arrays are switched.### Reproduce the code example:```pythonimport numpy as nparray = np.array([[-4.0, -2.0, -2.0], [-2.0, -4.0, -2.0], [-2.0, -2.0, -4.0]])expected_u = np.array(    [        [-5.77350269e-01, 8.16496581e-01, -5.04179082e-17],        [-5.77350269e-01, -4.08248290e-01, -7.07106781e-01],        [-5.77350269e-01, -4.08248290e-01, 7.07106781e-01],    ])expected_vh = np.array(    [        [0.57735027, 0.57735027, 0.57735027],        [-0.81649658, 0.40824829, 0.40824829],        [-0.0, 0.70710678, -0.70710678],    ])(u, _, vh) = np.linalg.svd(array, full_matrices=False)np.testing.assert_almost_equal(expected_u, u)np.testing.assert_almost_equal(expected_vh, vh)```### Error message:```shellMismatched elements: 6 / 9 (66.7%)Max absolute difference: 1.11535507Max relative difference: 1.60871119e+16 x: array([[-5.7735027e-01,  8.1649658e-01, -5.0417908e-17],       [-5.7735027e-01, -4.0824829e-01, -7.0710678e-01],       [-5.7735027e-01, -4.0824829e-01,  7.0710678e-01]]) y: array([[-5.7735027e-01, -5.0754703e-17,  8.1649658e-01],       [-5.7735027e-01, -7.0710678e-01, -4.0824829e-01],       [-5.7735027e-01,  7.0710678e-01, -4.0824829e-01]])Exited with code exit status 1```### Runtime information:1.19.33.9.13 (main, May 27 2022, 22:45:39) [GCC 9.4.0]Note: This behavior is also occurring with numpy 1.24.1### Context for the issue:The behavior is observed in CircleCI with the following info:Docker with Python using cimg/python:3.9.13Model name:闂傚倸鍊搁崐鎼佸磹瀹勬噴褰掑炊閵娧呭骄闂佸壊鍋嗛崰鎾汇€呴崣澶堜簻闁圭儤鍨甸埀顒€顭烽幆宀勫醇閻旂繝绨婚梺鎸庢婵倝寮查悗宄?R) Xeon(R) Platinum 8124M CPU @ 3.00GHzBranch featuring bug: https://github.com/lace/entente/tree/numpy-bugFailure in CI: https://app.circleci.com/pipelines/github/lace/entente/1829/workflows/8973da1a-38f4-46a3-8dc5-63a8a1e4ee17/jobs/5937CI config: [https://github.com/lace/entente/blob/numpy-bug/.circleci/config.yml](https://github.com/lace/entente/blob/numpy-bug/.circleci/config.yml#L18)Not reproducible on MacOS or Linux native.Not reproducible on MacOS or Linux with same Docker image.Not reproducible in Numpy 1.19.2.
"
22933,0,2294,292,1,1,seberg,0,"title:BUG,TST: Tests report spurious invalid values on M1 for `sin`, `cos`, ... description:@seiko2plus we should to follow up on this for 1.24.1 since this is backported.  I am getting these on M1:```FAILED numpy/core/tests/test_umath.py::TestSpecialFloats::test_unary_spurious_fpexception[data10-escape10-f-cos] - AssertionError: Got warnings: [<warnings.WarningMessage object at 0x16a...FAILED numpy/core/tests/test_umath.py::TestSpecialFloats::test_unary_spurious_fpexception[data10-escape10-f-sin] - AssertionError: Got warnings: [<warnings.WarningMessage object at 0x16e...FAILED numpy/core/tests/test_umath.py::TestSpecialFloats::test_unary_spurious_fpexception[data11-escape11-f-cos] - AssertionError: Got warnings: [<warnings.WarningMessage object at 0x16e...FAILED numpy/core/tests/test_umath.py::TestSpecialFloats::test_unary_spurious_fpexception[data11-escape11-f-sin] - AssertionError: Got warnings: [<warnings.WarningMessage object at 0x176...FAILED numpy/core/tests/test_umath.py::TestSpecialFloats::test_unary_spurious_fpexception[data12-escape12-f-cos] - AssertionError: Got warnings: [<warnings.WarningMessage object at 0x176...FAILED numpy/core/tests/test_umath.py::TestSpecialFloats::test_unary_spurious_fpexception[data12-escape12-f-sin] - AssertionError: Got warnings: [<warnings.WarningMessage object at 0x176...FAILED numpy/core/tests/test_umath.py::TestSpecialFloats::test_unary_spurious_fpexception[data13-escape13-f-cos] - AssertionError: Got warnings: [<warnings.WarningMessage object at 0x176...FAILED numpy/core/tests/test_umath.py::TestSpecialFloats::test_unary_spurious_fpexception[data13-escape13-f-sin] - AssertionError: Got warnings: [<warnings.WarningMessage object at 0x176...FAILED numpy/core/tests/test_umath.py::TestSpecialFloats::test_unary_spurious_fpexception[data14-escape14-f-cos] - AssertionError: Got warnings: [<warnings.WarningMessage object at 0x176...FAILED numpy/core/tests/test_umath.py::TestSpecialFloats::test_unary_spurious_fpexception[data14-escape14-f-sin] - AssertionError: Got warnings: [<warnings.WarningMessage object at 0x177...FAILED numpy/core/tests/test_umath.py::TestSpecialFloats::test_unary_spurious_fpexception[data15-escape15-f-cos] - AssertionError: Got warnings: [<warnings.WarningMessage object at 0x176...FAILED numpy/core/tests/test_umath.py::TestSpecialFloats::test_unary_spurious_fpexception[data15-escape15-f-sin] - AssertionError: Got warnings: [<warnings.WarningMessage object at 0x176...```Unless the fix is very simple, I suspect xfailing the test on apple is just as well, though._Originally posted by @seberg in https://github.com/numpy/numpy/issues/22771#issuecomment-1359181707_Full build log of the run: https://github.com/numpy/numpy/files/10284840/build.log
"
22931,0,0,270,0,1,rossbar,1,"title:TST: Add fixture to avoid issue with randomizing test order. description:Adds a missing test fixture to prevent cross-talk between polynomial printing test classes when the test order is randomized with `pytest-randomly`.Addresses the immediate issue #22825 though there is another, deeper issue with polynomial printing thread safety. Therefore #22825 should either be left open or a follow-up issue opened.
"
22922,0,143,297,0,0,blowekamp,0,"title:BUG: fill violating read-only flag description:### Describe the issue:Behavior of numpy 1.24.1 changed to `fill` on read-only arrays.### Reproduce the code example:```pythonimport numpy as npa = np.zeros(11)a.setflags(write=False)a.fill(0)```### Error message:```shellA ValueError exception expected but is no longer raised.```### Runtime information:1.24.13.11.0 (v3.11.0:deaf509e8f, Oct 24 2022, 14:43:23) [Clang 13.0.0 (clang-1300.0.29.30)]WARNING: `threadpoolctl` not found in system! Install it by `pip install threadpoolctl`. Once installed, try `np.show_runtime` again for more detailed build information[{'simd_extensions': {'baseline': ['NEON', 'NEON_FP16', 'NEON_VFPV4', 'ASIMD'],                      'found': ['ASIMDHP', 'ASIMDDP'],                      'not_found': ['ASIMDFHM']}}]NoneThis changed in behavior has occurred on all our CI systems, windows, Mac and linux. And with python versions 3.7 to 3.11### Context for the issue:Our regression test suit is failing. It provides an opportunity for data to unexpectedly change, and invalid states in the software could be entered with undefined behavior.
"
22919,0,7988,147,0,1,mlondschien,0,"title:BUG: `rng.multivariate_normal` returns different results for different architectures description:### Describe the issue:On osx-arm64, running the following```pythonimport numpy as npSigma = np.full((5, 5), 0.7)np.fill_diagonal(Sigma, 1)rng = np.random.default_rng(12)X = rng.multivariate_normal(np.zeros(5), Sigma, 1)print(X)```prints```[[ 0.7989866   0.26512508 -0.43169361 -0.72572551  0.12306469]]```Running the same code on linux64 prints```[[ 0.36925409  0.06273453 -0.92231155 -0.1340844   0.65416457]]```This is equally an issue for scipy:```pythonfrom scipy.stats import multivariate_normalX = multivariate_normal(mean=np.zeros(5), cov=Sigma, seed=12).rvs(1)print(X)```prints```[-0.04337636 -1.19324783  0.23303855 -0.47834447 -0.57976733]```on osx-arm64 and```[-0.29356888 -0.19370035 -0.7717682   0.30701745 -1.10967747]```on linux-64.Output of `conda list` on osx-arm64:```# packages in environment at /Users/mlondschien/mambaforge/envs/numpy:## Name                    Version                   Build  Channelbzip2                     1.0.8                h3422bc3_4    conda-forgeca-certificates           2022.12.7            h4653dfc_0    conda-forgelibblas                   3.9.0           16_osxarm64_openblas    conda-forgelibcblas                  3.9.0           16_osxarm64_openblas    conda-forgelibcxx                    14.0.6               h2692d47_0    conda-forgelibffi                    3.4.2                h3422bc3_5    conda-forgelibgfortran               5.0.0           11_3_0_hd922786_27    conda-forgelibgfortran5              11.3.0              hdaf2cc0_27    conda-forgeliblapack                 3.9.0           16_osxarm64_openblas    conda-forgelibopenblas               0.3.21          openmp_hc731615_3    conda-forgelibsqlite                 3.40.0               h76d750c_0    conda-forgelibzlib                   1.2.13               h03a7124_4    conda-forgellvm-openmp               15.0.6               h7cfbb63_0    conda-forgencurses                   6.3                  h07bb92c_1    conda-forgenumpy                     1.24.0          py311ha92fb03_0    conda-forgeopenssl                   3.0.7                h03a7124_1    conda-forgepip                       22.3.1             pyhd8ed1ab_0    conda-forgepython                    3.11.0          h93c2e33_0_cpython    conda-forgepython_abi                3.11                    3_cp311    conda-forgereadline                  8.1.2                h46ed386_0    conda-forgescipy                     1.9.3           py311h0bcca16_2    conda-forgesetuptools                65.6.3             pyhd8ed1ab_0    conda-forgetk                        8.6.12               he1e0b03_0    conda-forgetzdata                    2022g                h191b570_0    conda-forgewheel                     0.38.4             pyhd8ed1ab_0    conda-forgexz                        5.2.6                h57fd34a_0    conda-forge```Output of `conda list` on linux-64:```# packages in environment at /home/mlondschien/miniforge3/envs/numpy:## Name                    Version                   Build  Channel_libgcc_mutex             0.1                 conda_forge    conda-forge_openmp_mutex             4.5                       2_gnu    conda-forgebzip2                     1.0.8                h7f98852_4    conda-forgeca-certificates           2022.12.7            ha878542_0    conda-forgeld_impl_linux-64          2.39                 hcc3a1bd_1    conda-forgelibblas                   3.9.0           16_linux64_openblas    conda-forgelibcblas                  3.9.0           16_linux64_openblas    conda-forgelibffi                    3.4.2                h7f98852_5    conda-forgelibgcc-ng                 12.2.0              h65d4601_19    conda-forgelibgfortran-ng            12.2.0              h69a702a_19    conda-forgelibgfortran5              12.2.0              h337968e_19    conda-forgelibgomp                   12.2.0              h65d4601_19    conda-forgeliblapack                 3.9.0           16_linux64_openblas    conda-forgelibnsl                    2.0.0                h7f98852_0    conda-forgelibopenblas               0.3.21          pthreads_h78a6416_3    conda-forgelibsqlite                 3.40.0               h753d276_0    conda-forgelibstdcxx-ng              12.2.0              h46fd767_19    conda-forgelibuuid                   2.32.1            h7f98852_1000    conda-forgelibzlib                   1.2.13               h166bdaf_4    conda-forgencurses                   6.3                  h27087fc_1    conda-forgenumpy                     1.24.0                   pypi_0    pypiopenssl                   3.0.7                h0b41bf4_1    conda-forgepip                       22.3.1             pyhd8ed1ab_0    conda-forgepython                    3.11.0          ha86cf86_0_cpython    conda-forgepython_abi                3.11                    3_cp311    conda-forgereadline                  8.1.2                h0f457ee_0    conda-forgescipy                     1.9.3                    pypi_0    pypisetuptools                65.6.3             pyhd8ed1ab_0    conda-forgetk                        8.6.12               h27826a3_0    conda-forgetzdata                    2022g                h191b570_0    conda-forgewheel                     0.38.4             pyhd8ed1ab_0    conda-forgexz                        5.2.6                h166bdaf_0    conda-forge```</details>### Reproduce the code example:```pythonimport numpy as npSigma = np.full((5, 5), 0.7)np.fill_diagonal(Sigma, 1)rng = np.random.default_rng(12)X = rng.multivariate_normal(np.zeros(5), Sigma, 1)print(X)from scipy.stats import multivariate_normalX = multivariate_normal(mean=np.zeros(5), cov=Sigma, seed=12).rvs(1)print(X)```### Error message:_No response_### Runtime information:On osx-arm64:```Python 3.11.0 | packaged by conda-forge | (main, Oct 25 2022, 06:21:25) [Clang 14.0.4 ] on darwinType ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> import sys, numpy; print(numpy.__version__); print(sys.version)1.24.03.11.0 | packaged by conda-forge | (main, Oct 25 2022, 06:21:25) [Clang 14.0.4 ]>>> print(numpy.show_runtime())[{'simd_extensions': {'baseline': ['NEON', 'NEON_FP16', 'NEON_VFPV4', 'ASIMD'],                      'found': ['ASIMDHP', 'ASIMDDP'],                      'not_found': ['ASIMDFHM']}}, {'architecture': 'VORTEX',  'filepath': '/Users/mlondschien/mambaforge/envs/numpy/lib/libopenblas.0.dylib',  'internal_api': 'openblas',  'num_threads': 10,  'prefix': 'libopenblas',  'threading_layer': 'openmp',  'user_api': 'blas',  'version': '0.3.21'}, {'filepath': '/Users/mlondschien/mambaforge/envs/numpy/lib/libomp.dylib',  'internal_api': 'openmp',  'num_threads': 10,  'prefix': 'libomp',  'user_api': 'openmp',  'version': None}]None```(I needed to install `threadpoolctl` for the second result. This did not change the original issue.)On linux-64:```Python 3.11.0 | packaged by conda-forge | (main, Oct 25 2022, 06:24:40) [GCC 10.4.0] on linuxType ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> import sys, numpy>>> print(numpy.__version__); print(sys.version)1.24.03.11.0 | packaged by conda-forge | (main, Oct 25 2022, 06:24:40) [GCC 10.4.0]>> print(numpy.show_runtime())[{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2'],                      'not_found': ['AVX512F',                                    'AVX512CD',                                    'AVX512_KNL',                                    'AVX512_KNM',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}, {'architecture': 'Haswell',  'filepath': '/home/mlondschien/miniforge3/envs/numpy/lib/libopenblasp-r0.3.21.so',  'internal_api': 'openblas',  'num_threads': 8,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.21'}]None```(Also after installing `threadpoolctl`)### Context for the issue:Reproducibility is extremely important for scientific research.
"
22906,0,0,6,1,1,dmbelov,0,"title:BUG: np.loadtxt cannot load text file with quoted fields separated by whitespace description:- Resolves issue https://github.com/numpy/numpy/issues/22899- Fixed a bug in parsing line containing quoted fields separated by white spaces- Added doctest <!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22903,1,1824,3,0,0,MGloder,0,"title:BUG: np.where float division by zero error in incorrect data type description:### Describe the issue:If there are three columns, c1,c2,c3, and for c1 it is an object datatype, and float for c2 and c3. In this case, if we use np.where() to filter out numbers by using c3 as a condition, and do the calculation on c1/c2/c3, then, the np.where will throw a `ZeroDivisionError: float division by zero`### Reproduce the code example:```pythonimport numpy as npimport pandas as pdtest_df = pd.DataFrame(columns=['c1', 'c2', 'c3'],                       data=[(08888888.000002, 2, 3), (0, 2, 3), (1, 2, 0), (1, 2, 3)])test_df['c1'] = test_df['c1'].astype('object')test_df['another_new_col'] = np.where(    test_df['c3'] > 0,    test_df['c1'] / test_df['c2'] / test_df['c3'],    10)test_df.info()print(test_df)```### Error message:```shellTraceback (most recent call last):  File ""/Users/xu_yan/Library/Application Support/JetBrains/PyCharmCE2021.3/scratches/scratch.py"", line 10, in <module>    test_df['c1'] / test_df['c2'] / test_df['c3'],  File ""/Users/xu_yan/Project/venv/lib/python3.8/site-packages/pandas/core/ops/common.py"", line 69, in new_method    return method(self, other)  File ""/Users/xu_yan/Project/venv/lib/python3.8/site-packages/pandas/core/arraylike.py"", line 116, in __truediv__    return self._arith_method(other, operator.truediv)  File ""/Users/xu_yan/Project/venv/lib/python3.8/site-packages/pandas/core/series.py"", line 5526, in _arith_method    result = ops.arithmetic_op(lvalues, rvalues, op)  File ""/Users/xu_yan/Project/venv/lib/python3.8/site-packages/pandas/core/ops/array_ops.py"", line 224, in arithmetic_op    res_values = _na_arithmetic_op(left, right, op)  File ""/Users/xu_yan/Project/venv/lib/python3.8/site-packages/pandas/core/ops/array_ops.py"", line 166, in _na_arithmetic_op    result = func(left, right)  File ""/Users/xu_yan/Project/venv/lib/python3.8/site-packages/pandas/core/computation/expressions.py"", line 239, in evaluate    return _evaluate(op, op_str, a, b)  # type: ignore[misc]  File ""/Users/xu_yan/Project/venv/lib/python3.8/site-packages/pandas/core/computation/expressions.py"", line 69, in _evaluate_standard    return op(a, b)ZeroDivisionError: float division by zero```### Runtime information:1.20.33.8.8rc1 (v3.8.8rc1:dfd7d6893b, Feb 16 2021, 15:09:27) [Clang 6.0 (clang-600.0.57)]### Context for the issue:if we change c1 to float, then everything works
"
22900,0,1132,1,0,1,l-johnston,0,"title:BUG: NEP 42 user dtype has type number set to -1 and this causes various failures. description:### Describe the issue:Custom user dtypes in the new NEP 42 DTypeMeta have a type number set to -1 and this leads to various failures.In the 'experimental_public_dtype_api.c', the code is:```c/* invalid type num. Ideally, we get away with it! */    DType->type_num = -1;```Well, it seems we can't get away with it. For the code example, I can provide an example from my package [microohm](https://github.com/l-johnston/microohm).### Reproduce the code example:```pythonimport numpy as npimport numpy.core._dtype as _dtypefrom microohm import QuantityDTypearr = np.array([1.0, 2.0], dtype=QuantityDType(""m""))print(arr.dtype.num)print(f""{arr.dtype.kind!r}"")_dtype._name_get(arr.dtype)```### Error message:```shellRuntimeError                              Traceback (most recent call last)Cell In[11], line 1----> 1 _dtype._name_get(arr.dtype)File ~/github/microohm/.venv/lib/python3.11/site-packages/numpy/core/_dtype.py:355, in _name_get(dtype)    353     name = dtype.type.__name__    354 else:--> 355     name = _kind_name(dtype)    357 # append bit counts    358 if _name_includes_bit_suffix(dtype):File ~/github/microohm/.venv/lib/python3.11/site-packages/numpy/core/_dtype.py:28, in _kind_name(dtype)     26     return _kind_to_stem[dtype.kind]     27 except KeyError as e:---> 28     raise RuntimeError(     29         ""internal dtype error, unknown kind {!r}""     30         .format(dtype.kind)     31     ) from NoneRuntimeError: internal dtype error, unknown kind '\x00'```### Runtime information:1.25.0.dev0+272.gbf20c55a23.11.1 (main, Dec  9 2022, 10:58:57) [GCC 11.3.0][{'numpy_version': '1.25.0.dev0+272.gbf20c55a2',  'python': '3.11.1 (main, Dec  9 2022, 10:58:57) [GCC 11.3.0]',  'uname': uname_result(system='Linux', node='curro2', release='5.15.0-56-generic', version='#62-Ubuntu SMP Tue Nov 22 19:54:14 UTC 2022', machine='x86_64')}, {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2',                                'AVX512F',                                'AVX512CD',                                'AVX512_SKX'],                      'not_found': ['AVX512_KNL',                                    'AVX512_KNM',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}, {'architecture': 'SkylakeX',  'filepath': '/usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so',  'internal_api': 'openblas',  'num_threads': 8,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.20'}]None### Context for the issue:This causes failures in downstream libraries like Pandas, etc.
"
22899,0,3415,6,0,1,dmbelov,0,"title:BUG: np.loadtxt cannot load text file with quoted fields separated by whitespace description:### Describe the issue:## Description`np.loadtxt` cannot load text file with quoted fields separated by whitespace (**multiple** "" "" instead of one "" "").  It raises ValueError.  See example for details. ## Bug FixThis bug (typo?) can be fix by just fixing one line (we checked that the fix below works, but I cannot submit pull request)Here is the block from `numpy/core/src/multiarray/textreading/tokenize.cpp` function `tokenizer_core` that contains the bug:```c++// lines 214 -- 228        case TOKENIZE_QUOTED_CHECK_DOUBLE_QUOTE:            if (*pos == config->quote) {                /* Copy the quote character directly from the config: */                if (copy_to_field_buffer(ts,                        &config->quote, &config->quote+1) < 0) {                    return -1;                }                ts->state = TOKENIZE_QUOTED;                pos++;            }            else {                /* continue parsing as if unquoted */// BUG: The line below contains bug                ts->state = TOKENIZE_UNQUOTED;// BUG Fix: One should replace TOKENIZE_UNQUOTED by ts->unquoted_state similar to the code on lines 121-144                 ts->state = ts->unquoted_state;            }            break;```Note that `UNQUOTED` state was replaced by `ts->unquoted_state` in the block on lines 121 -- 144, but one, probably, forgot to do the same in the block on lines 214 -- 228.### Reproduce the code example:```pythonimport numpy as npfrom io import StringIO# The code below raises ValueErrors = StringIO('""alpha, #42""         10.0\n""beta, #64"" 2.0\n')dtype = np.dtype([(""label"", ""U12""), (""value"", float)])np.loadtxt(s, dtype=dtype, delimiter=None, quotechar='""')# The code works if we swap positions of unquoted and quoted fieldss = StringIO('10     ""alpha, #42""\n2.0 ""beta, #64""\n')dtype = np.dtype([(""value"", float), (""label"", ""U12"")])np.loadtxt(s, dtype=dtype, delimiter=None, quotechar='""')```### Error message:```shellValueError                                Traceback (most recent call last)Cell In[13], line 3      1 s = StringIO('""alpha, #42""         10.0\n""beta, #64"" 2.0\n')      2 dtype = np.dtype([(""label"", ""U12""), (""value"", float)])----> 3 np.loadtxt(s, dtype=dtype, delimiter=None, quotechar='""')File ~/miniconda3/lib/python3.10/site-packages/numpy/lib/npyio.py:1318, in loadtxt(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)   1315 if isinstance(delimiter, bytes):   1316     delimiter = delimiter.decode('latin1')-> 1318 arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,   1319             converters=converters, skiplines=skiprows, usecols=usecols,   1320             unpack=unpack, ndmin=ndmin, encoding=encoding,   1321             max_rows=max_rows, quote=quotechar)   1323 return arrFile ~/miniconda3/lib/python3.10/site-packages/numpy/lib/npyio.py:979, in _read(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)    976     data = _preprocess_comments(data, comments, encoding)    978 if read_dtype_via_object_chunks is None:--> 979     arr = _load_from_filelike(    980         data, delimiter=delimiter, comment=comment, quote=quote,    981         imaginary_unit=imaginary_unit,    982         usecols=usecols, skiplines=skiplines, max_rows=max_rows,    983         converters=converters, dtype=dtype,    984         encoding=encoding, filelike=filelike,    985         byte_converters=byte_converters)    987 else:    988     # This branch reads the file into chunks of object arrays and then    989     # casts them to the desired actual dtype.  This ensures correct    990     # string-length and datetime-unit discovery (like `arr.astype()`).    991     # Due to chunking, certain error reports are less clear, currently.    992     if filelike:ValueError: the number of columns changed from 2 to 1 at row 1; use `usecols` to select a subset and avoid this error```### Runtime information:1.23.43.10.8 (main, Nov  4 2022, 13:48:29) [GCC 11.2.0]### Context for the issue:This bug prevents us from using the newly-written `np.loadtxt` from loading our text files with quotes.  We have continue to use a wrapper around `pandas.read_csv`.  Note that the newly-written `np.loadtxt` is 3-8 times faster (!) than `pandas.read_csv`.  Obviously, we would like to start using higher performant function.This is an easy bugfix (just one line), it would be great if you would be able to add it to the nearest NumPy release.
"
22897,0,1541,286,0,1,rsokl,0,"title:BUG: 1.24.0 introduces inconsistent `array(arr, copy=False)` behavior based on byte order and dtype declaration  description:### Describe the issue:Starting in numpy 1.24.0 `array(big_end_arr, copy=False, dtype=big_end_arr.dtype)` will return a view instead a reference, whereas `array(big_end_arr, copy=False)` returns a reference. This specifically impacts big-endian byte orderings.### Reproduce the code example:```pythonfrom numpy import arraylil_a = array(0, dtype=""<f8"")lil_b_impl_dtype = array(lil_a, copy=False)lil_b_expl_dtype = array(lil_a, copy=False, dtype=""<f8"")assert lil_a is lil_b_impl_dtypeassert lil_a is lil_b_expl_dtypebig_a = array(0, dtype="">f8"")big_b_impl_dtype = array(big_a, copy=False)big_b_expl_dtype = array(big_a, copy=False, dtype="">f8"")assert big_a is big_b_impl_dtypeassert big_b_expl_dtype.base is big_aassert big_a is big_b_expl_dtype  # FAILS```### Error message:_No response_### Runtime information:```[{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2',                                'AVX512F',                                'AVX512CD',                                'AVX512_SKX',                                'AVX512_CLX',                                'AVX512_CNL',                                'AVX512_ICL'],                      'not_found': []}}, {'architecture': 'SkylakeX',  'filepath': 'C:\\Users\\rsokl\\miniconda3\\envs\\py310\\Lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll',  'internal_api': 'openblas',  'num_threads': 8,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.21'}]None```### Context for the issue:[MyGrad](https://github.com/rsokl/MyGrad) CI caught this error using Hypothesis. See [this test](https://github.com/rsokl/MyGrad/blob/79b55fbbfdaf502d964cf63f882479960f61b3f5/tests/test_tensor_creation.py#L349-L384)
"
22895,1,685,299,0,1,JudahSchwartz,0,"title:BUG: memory leak after creating arrays description:### Describe the issue:In a process the defines and then runs a method that creates many numpy arrays, some of the memory is not released.With the following code example everything should be garbage collected by the time ""stop the program?"" is displayed, but even manually calling gc.collect leaves almost a gigabyte in memory that isnt cleaned up Result of `ps aux````USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDroot         1 25.6  8.0 1232924 905788 pts/0  Ssl+ 14:36   1:21 /usr/bin/qemu-x86_64 /usr/local/bin/python /jfile/test.py```Results of docker stats```CONTAINER ID   NAME              CPU %     MEM USAGE / LIMIT    MEM %     NET I/O       BLOCK I/O     PIDS058ae47c2ac9   exciting_edison   0.00%     876.5MiB / 10.7GiB   8.00%     1.02kB / 0B   0B / 16.4kB   6```### Reproduce the code example:```pythondef get_arr():    arr = ['a', 'b', 'c']    for i in range(23):        arr += arr    return arrdef my_method():    import numpy as np    arr = get_arr()    [np.asarray(elt) for elt in arr]my_method()x = input(""stop the program?"")```### Error message:_No response_### Runtime information:numpy.__version__ > 1.24.1sys.version > 3.10.9 (main, Dec  8 2022, 01:46:27) [GCC 10.2.1 20210110]numpy.show_runtime() [{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3', 'SSE41', 'POPCNT', 'SSE42'],                      'not_found': ['AVX',                                    'F16C',                                    'FMA3',                                    'AVX2',                                    'AVX512F',                                    'AVX512CD',                                    'AVX512_KNL',                                    'AVX512_KNM',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}, {'architecture': 'Core2',  'filepath': '/usr/local/lib/python3.10/site-packages/numpy.libs/libopenblas64_p-r0-15028c96.3.21.so',  'internal_api': 'openblas',  'num_threads': 5,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.21'}]None### Context for the issue:This example is simply to reproduce the issue but this is causing our explanation to have very high unnecessary usage of memory
"
22887,0,0,275,0,0,charris,0,"title:BUG: Use whole file for encoding checks with ``charset_normalizer``.  description:Backport or #22872.* BUG: Use whole file for encoding checks [f2py]* DOC: Add a code commentCo-authored-by: melissawm <melissawm@gmail.com>* TST: Add a conditional unicode f2py test* MAINT: Add chardet as a test requirement* ENH: Cleanup and switch f2py to charset_normalizer* MAINT: Remove chardet for charset_normalizer* TST: Simplify UTF-8 encoding [f2py]Co-authored-by: melissawm <melissawm@gmail.com><!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22884,0,0,275,0,1,charris,0,"title:BUG: Fix integer overflow in in1d for mixed integer dtypes #22877 description:Backport of #22878.* TST: Mixed integer types for in1d* BUG: Fix mixed dtype overflows for in1d (#22877)* BUG: Type conversion for integer overflow check* MAINT: Fix linting issues in in1d* MAINT: ar1 overflow check only for non-empty array* MAINT: Expand bounds of overflow check* TST: Fix integer overflow in mixed boolean test* TST: Include test for overflow on mixed dtypes* MAINT: Less conservative overflow checks<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22879,0,0,292,0,1,ngoldbaum,0,"title:BUG: Fixes for numpy.testing.overrides description:Followup for #22533. Adds a missing return statement to `get_overridable_numpy_ufuncs` (oops!) and imports `numpy.testing.overrides` into `numpy.testing` so e.g. tab completion on `numpy.testing` works for `overrides`.This should probably be backported for numpy 1.24.1.
"
22878,0,401,293,0,1,MilesCranmer,0,"title:BUG: Fix integer overflow in in1d for mixed integer dtypes #22877 description:This fixes #22877 raised by @TonyXiang8787. The bug, introduced by #12065, results in integer overflows occurring in the following line: https://github.com/numpy/numpy/blob/2b9851ba4f8cc436266d913eb5db75fc702e1eed/numpy/lib/arraysetops.py#L683-L684 when mixed dtype input was passed to `in1d`.The fix is to simply test for these in advance of the `kind='table'` method being used:```python        #  2. Check overflows for (ar2 - ar2_min); dtype=ar2.dtype        range_safe_from_overflow = ar2_range <= np.iinfo(ar2.dtype).max        #  3. Check overflows for (ar1 - ar2_min); dtype=ar1.dtype        range_safe_from_overflow &= int(ar1_max) - int(ar2_min) <= np.iinfo(ar1.dtype).max        range_safe_from_overflow &= int(ar1_min) - int(ar2_min) >= np.iinfo(ar1.dtype).min```I also added some unittests to evaluate this behavior.cc @seberg 
"
22877,0,1379,298,0,1,TonyXiang8787,0,"title:BUG: `numpy.isin` does not function correctly with two arrays with different integer type description:### Describe the issue:The function `numpy.isin` sometimes returns the wrong answer, if the integer type of the two arrays (to be compared) are not the same.The example below shows a `int8` array with one zero and a `int64` array with two values. It should return one `True`. However, it returns `False`.### Reproduce the code example:```python>>> import numpy as np>>> np.isin(np.zeros(1, dtype=np.int8), np.array([-128, 0], dtype=np.int64), kind='table')array([False])```### Error message:_No response_### Runtime information:Numpy version```>>> print(numpy.__version__)1.24.0```Sys version```>>> print(sys.version)3.11.1 (main, Dec  7 2022, 01:11:34) [GCC 11.3.0]```Numpy runtime```[{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],                      'found': ['SSSE3',                                'SSE41',                                'POPCNT',                                'SSE42',                                'AVX',                                'F16C',                                'FMA3',                                'AVX2'],                      'not_found': ['AVX512F',                                    'AVX512CD',                                    'AVX512_KNL',                                    'AVX512_KNM',                                    'AVX512_SKX',                                    'AVX512_CLX',                                    'AVX512_CNL',                                    'AVX512_ICL']}}, {'architecture': 'Haswell',  'filepath': 'PATH_DELETED_DUE_TO_PRIVACY/.venv/lib/python3.11/site-packages/numpy.libs/libopenblas64_p-r0-15028c96.3.21.so',  'internal_api': 'openblas',  'num_threads': 20,  'prefix': 'libopenblas',  'threading_layer': 'pthreads',  'user_api': 'blas',  'version': '0.3.21'}]```### Context for the issue:The problem seems to only occur in version 1.24.
"
22872,0,0,291,0,0,HaoZeke,1,"title:BUG: Use whole file for encoding checks with ``charset_normalizer``. description:Closes #22871.The issue is that the current behavior uses only the first `32` bytes. The current variation (reading in the whole file) should be fine, fortran files are rarely large enough for this to be a practical bottleneck (tentatively).**EDIT**: Now this has a slightly larger changelog- [x] Switch from `chardet` to `charset_normalizer`- [x] Rework to keep old behavior (bytes read) without `charset_normalizer`The rationale here is that if there are encoding errors, attempting to determine the encoding with `startswith` doesn't need more than the old number of bytes anyway.`charset_normalizer` will use the whole file to check the encoding.
"
22871,0,3068,224,0,1,mancellin,0,"title:BUG: f2py cannot handle non-ascii characters in comments since 1.24 description:### Describe the issue:F2py works fine in version 1.23 when an utf8-encoded Fortran file has non-ascii characters in comments, but gives an error in 1.24. The error message recommends installing `chardet` but it does not seem to fix the issue.### Reproduce the code example:```$ cat test.f90 subroutine foo(x)  real(8), intent(in) :: x  print*, x ! 闂傚倸鍊搁崐鎼佸磹妞嬪海鐭嗗〒姘ｅ亾鐎规洏鍎抽埀顒婄秵閸犳牜绮诲鎵佸亾閸忓浜鹃梺鍛婃处閸嬪棝顢欓幋婵愭富闁靛牆绻掔壕鍧楁煟濠靛啯娈?闂?l'闂傚倸鍊搁崐鎼佸磹瀹勬噴褰掑炊椤掆偓绾惧鏌熼悧鍫熺凡闁稿被鍔庨幉绋款吋婢跺浠奸梺缁樺灱濡嫮绮婚鈧弻锝夊閳哄倹顏?la valeur de xend subroutine$ conda create -n numpy1.23 numpy=1.23[...]$ conda create -n numpy1.24 numpy=1.24[...]$ conda activate numpy1.23$ f2py -m test test.f90Reading fortran codes...	Reading file 'test.f90' (format:free)Post-processing...	Block: test			Block: fooPost-processing (stage 2)...Building modules...    Building module ""test""...    Generating possibly empty wrappers""    Maybe empty ""test-f2pywrappers.f""        Constructing wrapper function ""foo""...          foo(x)    Wrote C/API module ""test"" to file ""./testmodule.c""$ conda activate numpy1.24$ f2py -m test test.f90Reading fortran codes...Traceback (most recent call last):[...]```### Error message:```Traceback (most recent call last):  File ""/opt/mancellin/mambaforge/envs/numpy1.24/lib/python3.11/site-packages/numpy/f2py/crackfortran.py"", line 393, in readfortrancode    l = fin.readline()        ^^^^^^^^^^^^^^  File ""/opt/mancellin/mambaforge/envs/numpy1.24/lib/python3.11/fileinput.py"", line 292, in readline    line = self._readline()           ^^^^^^^^^^^^^^^^  File ""/opt/mancellin/mambaforge/envs/numpy1.24/lib/python3.11/fileinput.py"", line 372, in _readline    return self._readline()           ^^^^^^^^^^^^^^^^  File ""/opt/mancellin/mambaforge/envs/numpy1.24/lib/python3.11/encodings/ascii.py"", line 26, in decode    return codecs.ascii_decode(input, self.errors)[0]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 59: ordinal not in range(128)During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/opt/mancellin/mambaforge/envs/numpy1.24/bin/f2py"", line 10, in <module>    sys.exit(main())             ^^^^^^  File ""/opt/mancellin/mambaforge/envs/numpy1.24/lib/python3.11/site-packages/numpy/f2py/f2py2e.py"", line 704, in main    run_main(sys.argv[1:])  File ""/opt/mancellin/mambaforge/envs/numpy1.24/lib/python3.11/site-packages/numpy/f2py/f2py2e.py"", line 441, in run_main    postlist = callcrackfortran(files, options)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File ""/opt/mancellin/mambaforge/envs/numpy1.24/lib/python3.11/site-packages/numpy/f2py/f2py2e.py"", line 342, in callcrackfortran    postlist = crackfortran.crackfortran(files)               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File ""/opt/mancellin/mambaforge/envs/numpy1.24/lib/python3.11/site-packages/numpy/f2py/crackfortran.py"", line 3298, in crackfortran    readfortrancode(files, crackline)  File ""/opt/mancellin/mambaforge/envs/numpy1.24/lib/python3.11/site-packages/numpy/f2py/crackfortran.py"", line 395, in readfortrancode    raise Exception(Exception: readfortrancode: reading test.f90#0 failed with'ascii' codec can't decode byte 0xc3 in position 59: ordinal not in range(128).It is likely that installing chardet package will help f2py determine the input file encoding correctly.```### Runtime information:>>> import sys, numpy; print(numpy.__version__); print(sys.version)1.24.03.11.0 | packaged by conda-forge | (main, Oct 25 2022, 06:24:40) [GCC 10.4.0]### Context for the issue:I can't build the Fortran dependency of my package with Numpy 1.24. See also https://github.com/capytaine/capytaine/issues/273
"
22868,0,0,275,0,1,charris,0,"title:BUG: Fortify string casts against floating point warnings description:Backport of #22855.Backport of #22874.This removes the check for floating point warnings, which is enough in practice.  (In principle ufuncs or structured dtypes can chain casts in a way that causes us to check anyway.)It also checks for isfinite in the scalar repr code so the warnings shouldn't be set to begin with.Closes gh-22843Fixes  gh-22855<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22867,0,0,275,0,1,charris,0,"title:BUG, SIMD: Fix memory overlap in ufunc comparison loops description:Backport of #22851.closes #22841, relates #21483<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22866,0,0,275,0,1,charris,0,"title:BUG: Polynomials now copy properly (#22669) description:Backport of #22670.On line 502, self.symbol.copy() was called, whichcauses an AttributeError, since self.symbol is astring, so it doesn't have a copy() method. To fix it,I simply removed the copy() and directly assigned the string.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22865,0,2691,19,0,0,ctgk,0,"title:BUG: `deepcopy(np.polynomial.Polynomial(...))` fails description:### Describe the issue:numpy==1.24.0 fails to run `deepcopy(np.polynomial.Polynomial(...))` whereas a previous version (numpy==1.23.0) passes.It seems to be that the cause is using `copy` method of `self.symbol`, which is not defined as it is `str` object.Failure using numpy==1.24.0```$ pip install numpy==1.24.0Collecting numpy==1.24.0  Downloading numpy-1.24.0-cp310-cp310-macosx_11_0_arm64.whl (13.8 MB)     闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸婂潡鏌ㄩ弮鍌涙珪缂佺姵鍎抽埞鎴︽偐閸欏鎮欓梺缁樺笒閻忔岸濡甸崟顖氱鐎广儱鐗嗛崢鈥愁渻閵堝骸澧柛姘儔婵＄敻宕熼姘棟濠电偛妫涢崑鎾诲煝閸儲鈷戦柛婵嗗閻掕法绱掔紒妯肩疄鐎规洘妞介崺鈧い鎺嶉檷娴滄粓鏌熼悜妯虹仴妞ゅ浚浜弻锟犲川椤旇偐绁峰銈庡弨濞夋洟骞戦崟顖涘仏闁哄鍨甸～鐘绘⒒娴ｅ憡鍟為柨姘舵煟鎺抽崝搴ㄥ箲閵忕姭妲堟繛鍡樺姉缁夊爼姊洪崨濠冨瘷闁告劑鍔庨崢鎺楁⒑鐠囨彃顒㈡い鏃€鐗犲畷浼村冀椤撶喎浜梺缁樻尭鐎垫帡宕甸弴鐔翠簻闁规壋鏅涢悞鐑樼箾鐏忔牗娅婇柡灞诲€濆畷顐﹀Ψ閿旇姤鐦庨梻浣告啞钃遍柟鐟版搐椤繒绱掑Ο鑲╂嚌闂佹悶鍎滈崒婊冨毈缂傚倸鍊风粈渚€顢栭崱娑欏亱闁绘ɑ鐪归埀顑跨閳诲酣骞囬鍌滅嵁闂備礁缍婇崑濠囧储妤ｅ啫鍌ㄩ柟闂寸劍閳锋垿姊洪銈呬粶闁兼椿鍨遍弲鍫曞箻椤旂晫鍘告繛杈剧悼閹虫挻鎱ㄩ崼鈶╁亾閸偅绶查悗姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑?13.8/13.8 MB 3.6 MB/s eta 0:00:00Installing collected packages: numpySuccessfully installed numpy-1.24.0$ pythonPython 3.10.3 (main, May  7 2022, 14:13:10) [Clang 13.1.6 (clang-1316.0.21.2)] on darwinType ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> from copy import deepcopy; import numpy as np>>> deepcopy(np.polynomial.Polynomial([1, 1, 1]))Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""/Users/.../.pyenv/versions/3.10.3/lib/python3.10/copy.py"", line 161, in deepcopy    rv = reductor(4)  File ""/Users/.../.pyenv/versions/tmp-3.10.3/lib/python3.10/site-packages/numpy/polynomial/_polybase.py"", line 502, in __getstate__    ret['symbol'] = self.symbol.copy()AttributeError: 'str' object has no attribute 'copy'```No error using numpy==1.23.0```$ pip install numpy==1.23Collecting numpy==1.23  Downloading numpy-1.23.0-cp310-cp310-macosx_11_0_arm64.whl (13.3 MB)     闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸婂潡鏌ㄩ弮鍌涙珪缂佺姵鍎抽埞鎴︽偐閸欏鎮欓梺缁樺笒閻忔岸濡甸崟顖氱鐎广儱鐗嗛崢鈥愁渻閵堝骸澧柛姘儔婵＄敻宕熼姘棟濠电偛妫涢崑鎾诲煝閸儲鈷戦柛婵嗗閻掕法绱掔紒妯肩疄鐎规洘妞介崺鈧い鎺嶉檷娴滄粓鏌熼悜妯虹仴妞ゅ浚浜弻锟犲川椤旇偐绁峰銈庡弨濞夋洟骞戦崟顖涘仏闁哄鍨甸～鐘绘⒒娴ｅ憡鍟為柨姘舵煟鎺抽崝搴ㄥ箲閵忕姭妲堟繛鍡樺姉缁夊爼姊洪崨濠冨瘷闁告劑鍔庨崢鎺楁⒑鐠囨彃顒㈡い鏃€鐗犲畷浼村冀椤撶喎浜梺缁樻尭鐎垫帡宕甸弴鐔翠簻闁规壋鏅涢悞鐑樼箾鐏忔牗娅婇柡灞诲€濆畷顐﹀Ψ閿旇姤鐦庨梻浣告啞钃遍柟鐟版搐椤繒绱掑Ο鑲╂嚌闂佹悶鍎滈崒婊冨毈缂傚倸鍊风粈渚€顢栭崱娑欏亱闁绘ɑ鐪归埀顑跨閳诲酣骞囬鍌滅嵁闂備礁缍婇崑濠囧储妤ｅ啫鍌ㄩ柟闂寸劍閳锋垿姊洪銈呬粶闁兼椿鍨遍弲鍫曞箻椤旂晫鍘告繛杈剧悼閹虫挻鎱ㄩ崼鈶╁亾閸偅绶查悗姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑?13.3/13.3 MB 5.9 MB/s eta 0:00:00Installing collected packages: numpySuccessfully installed numpy-1.23.0$ pythonPython 3.10.3 (main, May  7 2022, 14:13:10) [Clang 13.1.6 (clang-1316.0.21.2)] on darwinType ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> from copy import deepcopy; import numpy as np>>> deepcopy(np.polynomial.Polynomial([1, 1, 1]))Polynomial([1., 1., 1.], domain=[-1,  1], window=[-1,  1])```### Reproduce the code example:```pythonfrom copy import deepcopy; import numpy as npf = np.polynomial.Polynomial([1, 1, 1])deepcopy(f)```### Error message:```shellTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""/Users/.../.pyenv/versions/3.10.3/lib/python3.10/copy.py"", line 161, in deepcopy    rv = reductor(4)  File ""/Users/.../.pyenv/versions/tmp-3.10.3/lib/python3.10/site-packages/numpy/polynomial/_polybase.py"", line 502, in __getstate__    ret['symbol'] = self.symbol.copy()AttributeError: 'str' object has no attribute 'copy'```### Runtime information:```python>>> import sys; import numpy as np>>> print(np.__version__)1.24.0>>> print(sys.version)3.10.3 (main, May  7 2022, 14:13:10) [Clang 13.1.6 (clang-1316.0.21.2)]>>> print(np.show_runtime())WARNING: `threadpoolctl` not found in system! Install it by `pip install threadpoolctl`. Once installed, try `np.show_runtime` again for more detailed build information[{'simd_extensions': {'baseline': ['NEON', 'NEON_FP16', 'NEON_VFPV4', 'ASIMD'],                      'found': ['ASIMDHP', 'ASIMDDP'],                      'not_found': ['ASIMDFHM']}}]None```### Context for the issue:_No response_
"
22862,1,1526,292,0,1,ngoldbaum,0,"title:BUG: test_public_api failure description:### Describe the issue:When I run the tests on the current main branch, I get a test failure in `numpy/tests/test_public_api.py::test_all_modules_are_expected`.I'm running the tests with:```$ python runtests.py -v -t numpy/tests/test_public_api.py```And I get the following error:```_________________________ test_all_modules_are_expected _________________________    def test_all_modules_are_expected():        """"""        Test that we don't add anything that looks like a new public module by        accident.  Check is based on filenames.        """"""            modnames = []        for _, modname, ispkg in pkgutil.walk_packages(path=np.__path__,                                                       prefix=np.__name__ + '.',                                                       onerror=None):            if is_unexpected(modname) and modname not in SKIP_LIST:                # We have a name that is new.  If that's on purpose, add it to                # PUBLIC_MODULES.  We don't expect to have to add anything to                # PRIVATE_BUT_PRESENT_MODULES.  Use an underscore in the name!                modnames.append(modname)            if modnames:>           raise AssertionError(f'Found unexpected modules: {modnames}')E           AssertionError: Found unexpected modules: ['numpy.ma.bench']_          = FileFinder('/home/nathan/Documents/numpy/build/testenv/lib/python3.10/site-packages/numpy')ispkg      = Falsemodname    = 'numpy.version'modnames   = ['numpy.ma.bench']numpy/tests/test_public_api.py:348: AssertionError```### Reproduce the code example:```pythonN/A```### Error message:_No response_### NumPy/Python version information:```>>> import sys, numpy; print(numpy.__version__, sys.version)1.25.0.dev0+246.g2f64274d3 3.10.8 (main, Nov  8 2022, 10:29:11) [GCC 11.3.0]```### Context for the issue:This is happening on my local development install of numpy. As far as I can see it isn't happening on CI.
"
22861,0,0,9,1,0,Developer-Ecosystem-Engineering,0,"title:BUG, SIMD: Restore behavior converting non bool input to 0x00/0xff description:This resolves https://github.com/numpy/numpy/issues/22845 by restoring prior behavior to convert non bool input
"
22855,0,0,292,0,0,seberg,0,"title:BUG: Fortify string casts against floating point warnings description:This removes the check for floating point warnings, which is enough in practice.  (In principle ufuncs or structured dtypes can chain casts in a way that causes us to check anyway.)It also checks for isfinite in the scalar repr code so the warnings shouldn't be set to begin with.Closes gh-22843---Edit removed round-tripping check.  It is broken for complex longdouble and may sometimes fail for longdouble as well.  And thus, I guess should be checked more explicitly and not in the same test.
"
22854,1,1488,15,0,1,Alexander-Serov,0,"title:BUG: histogram(x, bins='auto') fails for unknown reason on a simple input dataset description:### Describe the issue:A simple code snippet below calculating bins for a given input fails while trying to allocate 12.7 PiB of RAM. Probably related to my floats precision, but is definitely not the expected result.I would be most grateful if anyone could suggest a workaround while this bug is being fixed.### Reproduce the code example:```pythonimport numpy as npx = np.array([6.3, 6.3, 7.399999999999999, 7.399999999999999, 7.399999999999999, 7.399999999999999, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.4, 7.407142857142857, 7.407142857142857, 7.4125, 7.4125])np.histogram(x, density=True, bins=""auto"")```### Error message:```shellTraceback (most recent call last):  File ""/Users/user/miniforge3/envs/clients/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3433, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File ""<ipython-input-3-f76ea541d063>"", line 25, in <module>    np.histogram(x, density=True, bins=""auto"")  File ""<__array_function__ internals>"", line 180, in histogram  File ""/Users/user/miniforge3/envs/clients/lib/python3.8/site-packages/numpy/lib/histograms.py"", line 793, in histogram    bin_edges, uniform_bins = _get_bin_edges(a, bins, range, weights)  File ""/Users/user/miniforge3/envs/clients/lib/python3.8/site-packages/numpy/lib/histograms.py"", line 446, in _get_bin_edges    bin_edges = np.linspace(  File ""<__array_function__ internals>"", line 180, in linspace  File ""/Users/user/miniforge3/envs/clients/lib/python3.8/site-packages/numpy/core/function_base.py"", line 135, in linspace    y = _nx.arange(0, num, dtype=dt).reshape((-1,) + (1,) * ndim(delta))numpy.core._exceptions._ArrayMemoryError: Unable to allocate 12.7 PiB for an array with shape (1781062197026280,) and data type float64```### NumPy/Python version information:1.23.3 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:49:06) [Clang 14.0.6 ]### Context for the issue:_No response_
"
22851,0,0,164,0,1,seiko2plus,0,"title:BUG, SIMD: Fix memory overlap in ufunc comparison loops description:closes #22841, relates #21483
"
22850,0,0,239,0,0,oscargus,0,"title:BUG: FreeBSD issue with `csinl` in 1.24 description:### Describe the issue:It seems like 1.24 requires `csinl`, which FreeBSD doesn't support out of the box, see https://wiki.freebsd.org/Numerics### Reproduce the code example:I do not really know where it comes from. It became an issue running the Matplotlib CI on FreeBSD (and is readily solved by restricting to numpy<1.24).Edit: this is a runtime issue. It compiles fine, but then, upon loading(?) it errors out as it cannot find `csinl`.### Error message:_No response_### NumPy/Python version information:1.24### Context for the issue:I understand that this may not be a highly prioritized issue, but thought it was worth reporting in case it can be solved in an easy way. (And to some extent it should probably be solved in FreeBSD...)
"
22848,0,0,275,0,1,charris,0,"title:BUG, SIMD: Fix the bitmask of the boolean comparison description:Backport of #22846.closes #22840, relates #21483<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22847,0,0,275,0,1,charris,0,"title:BUG: Ensure correct behavior for rows ending in delimiter in loadtxt  description:Backport of #22836If a row ends in a delimiter, `add_fields` can be called twice without any field actually being parsed.  This causes issues with the field buffer setup.Basically, I tried to be too smart, and now it needs a small fixup...closes gh-22833<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22845,0,817,274,0,1,tylerjereddy,0,"title:BUG: (main branch only; 1.24.0 fine) bizzare boolean product issue description:I did see a number of `bool_` comparison related issues open, but they seem to be fine here for NumPy `1.24.0`, while in my case it is the `main` branch that is a problem and the stable release is working just fine.I've been looking at some of the failures in SciPy + NumPy `main` branch after the recent release (which confusingly seems to be named/versioned `1.24.0.dev0+1413.gca2575655` in my tests, but clearly causes a number of issues in https://github.com/scipy/scipy/issues/17630#issuecomment-1358008148). Before deciding to release the next RC for SciPy `1.10.0` I wanted to drill down on one of the test failures to make sure I couldn't just easily shim around these, but it looks like this stuff is going to be too tricky because there are tons of them. Maybe not so serious since it just on the unreleased `main` branch so perhaps I'll move forward for now.Here is a specific reproducer with `*.npy` files available from `np.save` in this tarball:  [arrays.tar.gz](https://github.com/numpy/numpy/files/10273085/arrays.tar.gz)```pythonimport numpy as npprint(""np.__version__:"", np.__version__)with open(""q.npy"", ""rb"") as q_file:    q = np.load(q_file)with open(""r.npy"", ""rb"") as r_file:    r = np.load(r_file)print(""q, q.shape, q.dtype:"", q, q.shape, q.dtype)print(""r, r.shape, r.dtype:"", r, r.shape, r.dtype)print(""q * r:"", q * r)```The results from `main` and `1.24.0`, respectively, follow:```np.__version__: 1.24.0.dev0+1413.gca2575655q, q.shape, q.dtype: [ True False False ... False False False] (10000,) boolr, r.shape, r.dtype: [ True  True  True ...  True  True  True] (10000,) boolq * r: [False False False ... False False False]``````np.__version__: 1.24.0q, q.shape, q.dtype: [ True False False ... False False False] (10000,) boolr, r.shape, r.dtype: [ True  True  True ...  True  True  True] (10000,) boolq * r: [ True False False ... False False False]```If you focus on the first element in the result array, the stable release looks much more sensible. This manifested as a single (first) element difference in the expected value of the test result for `scipy/stats/tests/test_sampling.py::TestDiscreteGuideTable::test_ppf[u0]`. In fact, the actual value is just fine, but that means `stats.binom.ppf(u, n, p)` may be broken with NumPy `main` at the moment (cc: @mdhaber @tupui ), and naturally these kinds of issues seem to cascade around in a way that I probably can't patch manually, so I'll probably wait for some fixes in NumPy if you agree this is a problem.
"
22844,1,2197,291,1,0,xkszltl,0,"title:BUG: Mis-handling of NaN in power(). description:### Describe the issue:NaN is supposed to be very infective.Anything compute with NaN should result in NaN.But currently `np.power()` think `nan^0=1`.### Reproduce the code example:```python# macOS# python3 --version && python3 -m pip show numpy && python3 -c 'import numpy as np; print(np.power(np.nan, 0.0))'Python 3.10.8Name: numpyVersion: 1.23.5Summary: NumPy is the fundamental package for array computing with Python.Home-page: https://www.numpy.orgAuthor: Travis E. Oliphant et al.Author-email: License: BSDLocation: /usr/local/lib/python3.10/site-packagesRequires: Required-by: imagecodecs, imageio, opencv-python, rawpy, scipy, tifffile1.0# Debian 11# python3 --version && python3 -m pip show numpy && python3 -c 'import numpy as np; print(np.power(np.nan, 0.0))'Python 3.9.2Name: numpyVersion: 1.23.4Summary: NumPy is the fundamental package for array computing with Python.Home-page: https://www.numpy.orgAuthor: Travis E. Oliphant et al.Author-email: License: BSDLocation: /usr/local/lib/python3.9/dist-packagesRequires: Required-by: keras2onnx, onnx, onnxconverter-common, onnxmltools, onnxruntime, opencv-python, rawpy, scikit-learn, scipy, skl2onnx1.0# CentOS 7# python3 --version && python3 -m pip show numpy && python3 -c 'import numpy as np; print(np.power(np.nan, 0.0))'Python 3.6.8Name: numpyVersion: 1.19.5Summary: NumPy is the fundamental package for array computing with Python.Home-page: https://www.numpy.orgAuthor: Travis E. Oliphant et al.Author-email: License: BSDLocation: /usr/local/lib64/python3.6/site-packagesRequires: Required-by: keras2onnx, onnx, onnxconverter-common, onnxmltools, onnxruntime, opencv-python, rawpy, scikit-learn, scipy, skl2onnx, torchvision, transformers1.0# CentOS 7 with SCL# scl enable rh-python38 ""python3 --version && python3 -m pip show numpy && python3 -c 'import numpy as np; print(np.power(np.nan, 0.0))'""Python 3.8.13Name: numpyVersion: 1.23.4Summary: NumPy is the fundamental package for array computing with Python.Home-page: https://www.numpy.orgAuthor: Travis E. Oliphant et al.Author-email: License: BSDLocation: /home/xkszltl/.local/lib/python3.8/site-packagesRequires: Required-by: keras2onnx, onnx, onnxconverter-common, onnxmltools, opencv-python, rawpy, scikit-learn, scipy, skl2onnx1.0```### NumPy/Python version information:- numpy 1.23.5 and python 3.10.8, macOS- numpy 1.23.4 and python 3.9, Debian 11- numpy 1.23.4 and python 3.8, CentOS 7- numpy 1.19 and python 3.6, CentOS 7Not version-specific.This has been an issue for long, someone filed here originally but not very conclusive.- https://github.com/numpy/numpy/issues/8931It also mentioned platform/impl dependent, but at least that's not what I found.
"
22843,0,164,4,0,0,corynezinstitchfix,0,"title:BUG: (1.24.0) np.array(np.nan).astype(str) warns RuntimeWarning: invalid value encountered in cast description:### Describe the issue:Since 1.24.0, `np.array(np.nan).astype(str)` warns `RuntimeWarning: invalid value encountered in cast` when I believe it should not. ### Reproduce the code example:```pythonimport numpy as npnp.array(np.nan).astype(str)```### Error message:```shell/.../test.py:2: RuntimeWarning: invalid value encountered in cast  np.array(np.nan).astype(str)```### NumPy/Python version information:1.24.0 3.9.10 (main, Jun 28 2022, 22:06:41)[Clang 13.1.6 (clang-1316.0.21.2.5)]### Context for the issue: I noticed this because the built-in Pandas functionality to convert a categorical series to a string, `pd.Series([""a"", ""b"", ""c"", ""a""], dtype=""category"").astype(str)`, has started giving the same warning (I believe from [this](https://github.com/pandas-dev/pandas/blob/main/pandas/core/arrays/categorical.py#L542) line of code)Note to anyone else experiencing the same, it can be worked around by casting to an object first: `pd.Series([""a"", ""b"", ""c"", ""a""], dtype=""category"").astype(object).astype(str)`
"
22842,0,2561,36,0,1,WillianFuks,0,"title:BUG: ufunc 'isfinite' not supported for datetime64 data on version 1.24.0 description:### Describe the issue:Starting from `numpy==1.24.0` matplotlib can't process input data of type `datetime64` anymore.### Reproduce the code example:```pythonimport pandas as pdimport matplotlib.pyplot as pltd = pd.DataFrame({'x0': 1, 'x1': 3}, index=pd.date_range(start='2020-01-01', periods=10))ax = plt.subplot(1, 1, 1)ax.fill_between(d.index, d['x0'], d['x1'])  # raises```### Error message:```shellTraceback (most recent call last)Cell In[5], line 1----> 1 ax.fill_between(d.index, d['x0'], d['x1'])File ~/Documents/repos/tfcausalimpact/.env310/lib/python3.10/site-packages/matplotlib/__init__.py:1423, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs)   1420 @functools.wraps(func)   1421 def inner(ax, *args, data=None, **kwargs):   1422     if data is None:-> 1423         return func(ax, *map(sanitize_sequence, args), **kwargs)   1425     bound = new_sig.bind(ax, *args, **kwargs)   1426     auto_label = (bound.arguments.get(label_namer)   1427                   or bound.kwargs.get(label_namer))File ~/Documents/repos/tfcausalimpact/.env310/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5367, in Axes.fill_between(self, x, y1, y2, where, interpolate, step, **kwargs)   5365 def fill_between(self, x, y1, y2=0, where=None, interpolate=False,   5366                  step=None, **kwargs):-> 5367     return self._fill_between_x_or_y(   5368         ""x"", x, y1, y2,   5369         where=where, interpolate=interpolate, step=step, **kwargs)File ~/Documents/repos/tfcausalimpact/.env310/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5272, in Axes._fill_between_x_or_y(self, ind_dir, ind, dep1, dep2, where, interpolate, step, **kwargs)   5268         kwargs[""facecolor""] = \   5269             self._get_patches_for_fill.get_next_color()   5271 # Handle united data, such as dates-> 5272 ind, dep1, dep2 = map(   5273     ma.masked_invalid, self._process_unit_info(   5274         [(ind_dir, ind), (dep_dir, dep1), (dep_dir, dep2)], kwargs))   5276 for name, array in [   5277         (ind_dir, ind), (f""{dep_dir}1"", dep1), (f""{dep_dir}2"", dep2)]:   5278     if array.ndim > 1:File ~/Documents/repos/tfcausalimpact/.env310/lib/python3.10/site-packages/numpy/ma/core.py:2360, in masked_invalid(a, copy)   2332 def masked_invalid(a, copy=True):   2333     """"""   2334     Mask an array where invalid values occur (NaNs or infs).   2335    (...)   2357    2358     """"""-> 2360     return masked_where(~(np.isfinite(getdata(a))), a, copy=copy)TypeError: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''```### NumPy/Python version information:1.24.0 3.10.9 (main, Dec  7 2022, 01:12:00) [GCC 9.4.0]### Context for the issue:All plotting functionality from our packages that rely on dated index data stopped working. The solution for now was to drop numpy version to `1.23.4`, not sure if there's some workaround but for what we researched nothing seemed to fix it so far.
"
22841,0,450,291,0,0,knutdrand,0,"title:np.logical_xor.accumulate fails on 1.24 on mac description:### Describe the issue:.Accumulate on logical_xor gives wrong result on newest version. I suspect the same for bitwise_xor.### Reproduce the code example:```pythonimport numpy as npa = np.array([False, False,  True, False, False, False, False,  True, False, False,  True, False, False,  True, False, False, False, False, False, False])np.logical_xor.accumulate(a)array([False, False,  True,  True, False, False, False,  True,  True,       False,  True,  True, False,  True,  True, False, False, False,       False, False])# Should be [False, False,  True,  True, True, True, True, False,,,,]```### Error message:_No response_### NumPy/Python version information:numpy=1.24python 3.8, mac version 12.5.1### Context for the issue:_No response_
"
22840,0,229,263,0,0,phofl,0,"title:REGR: Comparing boolean array to True returns incorrect uint8 value with more than 32 values on 1.24.0 description:### Describe the issue:When having an array with more than 31 boolean values and doing an equality comparison the underlying value seems off. Applying ``view(""uint8"")`` to the result returns 254 for every element instead of one. It works fine if ``n<= 31``Discovered in https://github.com/pandas-dev/pandas/issues/50347### Reproduce the code example:```pythonimport numpy as npn = 32na = np.array([True] * n)(na == True).view(""uint8"")```### Error message:```shell[254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254 254]```### NumPy/Python version information:1.24.0 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:49:06) [Clang 14.0.6 ]### Context for the issue:This seems off to me
"
22836,0,0,292,0,1,seberg,0,"title:BUG: Ensure correct behavior for rows ending in delimiter in loadtxt description:If a row ends in a delimiter, `add_fields` can be called twice without any field actually being parsed.  This causes issues with the field buffer setup.Basically, I tried to be too smart, and now it needs a small fixup...closes gh-22833
"
22835,0,10804,296,0,0,bnavigator,0,"title:BUG: TestNanFunctions_Median.test_keepdims_out description:### Describe the issue:The random matrices for `TestNanFunctions_Median.test_keepdims_out` fail to slice ocassionally while building numpy 1.24 for openSUSE Tumbleweed.### Reproduce the code example:```pythonimport numpy as npnp.test(extra_argv=['-k', 'test_keepdims_out'])```### Error message:```shell[ 2386s] _________________ TestNanFunctions_Median.test_keepdims_out[1] _________________[ 2386s] [gw7] linux -- Python 3.8.16 /usr/bin/python3.8[ 2386s] [ 2386s] self = <numpy.lib.tests.test_nanfunctions.TestNanFunctions_Median object at 0x7f07bc2c7520>[ 2386s] axis = 1[ 2386s] [ 2386s]     @pytest.mark.parametrize([ 2386s]         argnames='axis',[ 2386s]         argvalues=[[ 2386s]             None,[ 2386s]             1,[ 2386s]             (1, ),[ 2386s]             (0, 1),[ 2386s]             (-3, -1),[ 2386s]         ][ 2386s]     )[ 2386s]     def test_keepdims_out(self, axis):[ 2386s]         d = np.ones((3, 5, 7, 11))[ 2386s]         # Randomly set some elements to NaN:[ 2386s]         w = np.random.random((4, 200)) * np.array(d.shape)[:, None][ 2386s]         w = w.astype(np.intp)[ 2386s]         d[tuple(w)] = np.nan[ 2386s]         if axis is None:[ 2386s]             shape_out = (1,) * d.ndim[ 2386s]         else:[ 2386s]             axis_norm = normalize_axis_tuple(axis, d.ndim)[ 2386s]             shape_out = tuple([ 2386s]                 1 if i in axis_norm else d.shape[i] for i in range(d.ndim))[ 2386s]         out = np.empty(shape_out)[ 2386s] >       result = np.nanmedian(d, axis=axis, keepdims=True, out=out)[ 2386s] [ 2386s] axis       = 1[ 2386s] axis_norm  = (1,)[ 2386s] d          = array([[[[ 1., nan,  1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ..., nan,  1.,  1.],[ 2386s]          [nan,  1.,  1., ....1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ...,  1., nan,  1.]]]])[ 2386s] out        = array([[[[-8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26, -8.63673875e-...73875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26]]]])[ 2386s] self       = <numpy.lib.tests.test_nanfunctions.TestNanFunctions_Median object at 0x7f07bc2c7520>[ 2386s] shape_out  = (3, 1, 7, 11)[ 2386s] w          = array([[ 0,  1,  1,  1,  2,  1,  0,  0,  1,  1,  1,  1,  2,  2,  2,  0,[ 2386s]          2,  1,  0,  0,  2,  0,  2,  1,  2,  0...,  9,[ 2386s]          3,  4,  1, 10,  2, 10,  3,  6,  3,  7,  7, 10,  5,  3,  7,  0,[ 2386s]          6,  0,  9,  9,  8,  6,  0,  1]])[ 2386s] [ 2386s] ../../../BUILDROOT/python-numpy-1.24.0-124.1.x86_64/usr/lib64/python3.8/site-packages/numpy/lib/tests/test_nanfunctions.py:834: [ 2386s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ [ 2386s] <__array_function__ internals>:200: in nanmedian[ 2386s]     ???[ 2386s]         args       = (array([[[[ 1., nan,  1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ..., nan,  1.,  1.],[ 2386s]          [nan,  1.,  1., ..., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ...,  1., nan,  1.]]]]),)[ 2386s]         dispatcher = <function _nanmedian_dispatcher at 0x7f07c61a59d0>[ 2386s]         implementation = <function nanmedian at 0x7f07c61a5af0>[ 2386s]         kwargs     = {'axis': 1, 'keepdims': True, 'out': array([[[[-8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]           -8.6367387...3875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26]]]])}[ 2386s]         public_api = <function nanmedian at 0x7f07c61a5b80>[ 2386s]         relevant_args = (array([[[[ 1., nan,  1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ..., nan,  1.,  1.],[ 2386s]          [nan,  1.,  1., ...3875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26]]]]))[ 2386s] ../../../BUILDROOT/python-numpy-1.24.0-124.1.x86_64/usr/lib64/python3.8/site-packages/numpy/lib/nanfunctions.py:1217: in nanmedian[ 2386s]     return function_base._ureduce(a, func=_nanmedian, keepdims=keepdims,[ 2386s]         a          = array([[[[ 1., nan,  1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ..., nan,  1.,  1.],[ 2386s]          [nan,  1.,  1., ....1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ...,  1., nan,  1.]]]])[ 2386s]         axis       = 1[ 2386s]         keepdims   = True[ 2386s]         out        = array([[[[-8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26, -8.63673875e-...73875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26]]]])[ 2386s]         overwrite_input = False[ 2386s] ../../../BUILDROOT/python-numpy-1.24.0-124.1.x86_64/usr/lib64/python3.8/site-packages/numpy/lib/function_base.py:3752: in _ureduce[ 2386s]     r = func(a, **kwargs)[ 2386s]         a          = array([[[[ 1., nan,  1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ..., nan,  1.,  1.],[ 2386s]          [nan,  1.,  1., ....1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ...,  1., nan,  1.]]]])[ 2386s]         axis       = (1,)[ 2386s]         func       = <function _nanmedian at 0x7f07c61a58b0>[ 2386s]         index_out  = (slice(None, None, None), 0, slice(None, None, None), slice(None, None, None))[ 2386s]         keepdims   = True[ 2386s]         kwargs     = {'axis': 1, 'out': array([[[-8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]          -8.63673875e-26, -8.63673875e-...3673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]          -8.63673875e-26, -8.63673875e-26]]]), 'overwrite_input': False}[ 2386s]         nd         = 4[ 2386s]         out        = array([[[[-8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26, -8.63673875e-...73875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]           -8.63673875e-26, -8.63673875e-26]]]])[ 2386s] ../../../BUILDROOT/python-numpy-1.24.0-124.1.x86_64/usr/lib64/python3.8/site-packages/numpy/lib/nanfunctions.py:1094: in _nanmedian[ 2386s]     return _nanmedian_small(a, axis, out, overwrite_input)[ 2386s]         a          = array([[[[ 1., nan,  1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ..., nan,  1.,  1.],[ 2386s]          [nan,  1.,  1., ....1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ...,  1.,  1.,  1.],[ 2386s]          [ 1.,  1.,  1., ...,  1., nan,  1.]]]])[ 2386s]         axis       = 1[ 2386s]         out        = array([[[-8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]          -8.63673875e-26, -8.63673875e-26, -8.63673875e-26...63673875e-26,[ 2386s]          -8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]          -8.63673875e-26, -8.63673875e-26]]])[ 2386s]         overwrite_input = False[ 2386s] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ [ 2386s] [ 2386s] a = masked_array([ 2386s]   data=[[[[1.0, --, 1.0, ..., 1.0, 1.0, 1.0],[ 2386s]           [1.0, 1.0, 1.0, ..., --, 1.0, 1.0],[ 2386s]           [-...se, False, ..., False, False, False],[ 2386s]           [False, False, False, ..., False,  True, False]]]],[ 2386s]   fill_value=1e+20)[ 2386s] axis = 1[ 2386s] out = array([[[-8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]          -8.63673875e-26, -8.63673875e-26, -8.63673875e-26...63673875e-26,[ 2386s]          -8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]          -8.63673875e-26, -8.63673875e-26]]])[ 2386s] overwrite_input = False[ 2386s] [ 2386s]     def _nanmedian_small(a, axis=None, out=None, overwrite_input=False):[ 2386s]         """"""[ 2386s]         sort + indexing median, faster for small medians along multiple[ 2386s]         dimensions due to the high overhead of apply_along_axis[ 2386s]     [ 2386s]         see nanmedian for parameter usage[ 2386s]         """"""[ 2386s]         a = np.ma.masked_array(a, np.isnan(a))[ 2386s]         m = np.ma.median(a, axis=axis, overwrite_input=overwrite_input)[ 2386s]         for i in range(np.count_nonzero(m.mask.ravel())):[ 2386s] >           warnings.warn(""All-NaN slice encountered"", RuntimeWarning,[ 2386s]                           stacklevel=4)[ 2386s] E           RuntimeWarning: All-NaN slice encountered[ 2386s] [ 2386s] a          = masked_array([ 2386s]   data=[[[[1.0, --, 1.0, ..., 1.0, 1.0, 1.0],[ 2386s]           [1.0, 1.0, 1.0, ..., --, 1.0, 1.0],[ 2386s]           [-...se, False, ..., False, False, False],[ 2386s]           [False, False, False, ..., False,  True, False]]]],[ 2386s]   fill_value=1e+20)[ 2386s] axis       = 1[ 2386s] i          = 0[ 2386s] m          = masked_array([ 2386s]   data=[[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],[ 2386s]          [1.0, 1.0, 1.0, 1.0, 1.0, 1.0...         [False, False, False, False, False, False, False, False, False,[ 2386s]           False, False]]],[ 2386s]   fill_value=1e+20)[ 2386s] out        = array([[[-8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]          -8.63673875e-26, -8.63673875e-26, -8.63673875e-26...63673875e-26,[ 2386s]          -8.63673875e-26, -8.63673875e-26, -8.63673875e-26,[ 2386s]          -8.63673875e-26, -8.63673875e-26]]])[ 2386s] overwrite_input = False[ 2386s] [ 2386s] ../../../BUILDROOT/python-numpy-1.24.0-124.1.x86_64/usr/lib64/python3.8/site-packages/numpy/lib/nanfunctions.py/home/abuild/rpmbuild/BUILDROOT/python-numpy-1.24.0-124.1.x86_64/usr/lib64/python3.8/site-packages/numpy/_pytesttester.py:143: DeprecationWarning: [ 2386s] [ 2386s]   `numpy.distutils` is deprecated since NumPy 1.23.0, as a result[ 2386s]   of the deprecation of `distutils` itself. It will be removed for[ 2386s]   Python >= 3.12. For older Python versions it will remain present.[ 2386s]   It is recommended to use `setuptools < 60.0` for those Python versions.[ 2386s]   For more details, see:[ 2386s]     https://numpy.org/devdocs/reference/distutils_status_migration.html [ 2386s] [ 2386s] [ 2386s]   from numpy.distutils import cpuinfo[ 2386s] :1111: RuntimeWarning[ 2386s] =========================== short test summary info ============================[ 2386s] FAILED lib/tests/test_nanfunctions.py::TestNanFunctions_Median::test_keepdims_out[1][ 2386s] = 1 failed, 23068 passed, 2238 skipped, 35 xfailed, 3 xpassed in 436.92s (0:07:16) =```### NumPy/Python version information:1.24.0 3.10.9 (main, Dec 08 2022, 14:49:06) [GCC]### Context for the issue:This is a flaky issue. Sometimes the test passes, sometimes not. On different parametrizations.
"
22834,0,0,275,0,1,charris,0,"title:BUG, SIMD: Fix invalid value encountered in several ufuncs  description:Backport of #22771.closes #22461, #22772, #22797- Fix invalid value encountered in rint/trunc/ceil/floor on armhf/neon- Fix invalid value encountered in rint/trunc/ceil/floor on x86/SSE2- Fix invalid value encountered in expm1 when SVML/AVX512 enabled- Fix invalid value encountered in cos/sin on aarch64 & ppc64lefor more clarification check the linked issues above<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22833,0,1883,0,0,0,horsti371,0,"title:BUG: numpy.loadtxt crash for texts of specific length an trailing whitespace description:### Describe the issue:Loading data using numpy.loadtxt crashes in some specific cases. E.g., loading a string like`""1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 11111 11111 11111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 111 111 111 111 111 111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 1 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11111 11 11 11111 11 11 11 11 11 22 33 11 ""`fails on Windows and Ubuntu. This seems to depend on the length of the string and the trailing whitespace. When changing the end of the text above to `""... 22 33 1 ""`or`""... 22 33 11""`or `""... 22 33 111""`or `""... 22 33 111 ""`loading succeeds. This happens for NumPy 1.23.0 and 1.24.0 but not for NumPy 1.22.0### Reproduce the code example:```pythonfrom io import StringIOimport numpytext = ""1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 11111 11111 11111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 111 111 111 111 111 111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 1111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 1 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11111 11 11 11111 11 11 11 11 11 11 11 11 ""string_io = StringIO(text)numpy.loadtxt(string_io)```### Error message:```shellOn Windows, python crashes without any error message when loading the string a second time. On Ubuntu, the following error message occurs immediately:python3: malloc.c:2617: sysmalloc: Assertion `(old_top == initial_top (av) && old_size == 0) || ((unsigned long) (old_size) >= MINSIZE && prev_inuse (old_top) && ((unsigned long) old_end & (pagesize - 1)) == 0)' failed.Aborted (core dumped)```### NumPy/Python version information:Ubuntu:1.24.0 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]Windows:1.23.0 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]### Context for the issue:Can't load arbitrary text-based vectors.
"
22832,0,0,275,0,1,charris,0,"title:BUG: Fix refcounting errors found using pytest-leaks description:Backport of #22798.These are the clear errors I found based on pytest-leaks.  One day it would be nice to fix up pytest-leaks to better support newer versions of pytest and cleaning up fixtures...<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22830,0,0,275,0,0,charris,0,"title:BLD: CIRRUS_TAG redux description:Backport of #22824.Another attempt to close #22730.In this PR if the tag name begins with `v` and doesn't contain `dev0` then it will get uploaded to staging.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22829,1,872,299,0,0,tomMoral,0,"title:BUG: masked_invalid does not accept pandas.Series description:### Describe the issue:Before version 1.24, `numpy.masked_invalid` was converting its input to a numpy array, which allowed to pass array-like input.Changes in  #22046 breaks this, which makes for instance some function in matplotlib fails with pandas series (for instance `fill_betweenx`.I don't know if this is an intended change to only support `np.array` here, but I just wanted to document this.I will also report to the `matplotlib` developpers.### Reproduce the code example:```pythonimport numpy as npimport pandas as pdnp.ma.masked_invalid(pd.Series([1, 2, 3]))```### Error message:```shell---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)Cell In[3], line 1----> 1 np.ma.masked_invalid(pd.Series([1, 2, 3]))File ~/.local/miniconda/envs/test_benchopt/lib/python3.11/site-packages/numpy/ma/core.py:2360, in masked_invalid(a, copy)   2332 def masked_invalid(a, copy=True):   2333     """"""   2334     Mask an array where invalid values occur (NaNs or infs).   2335    (...)   2357    2358     """"""-> 2360     return masked_where(~(np.isfinite(getdata(a))), a, copy=copy)TypeError: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''```### NumPy/Python version information:This starts to fail with numpy 1.24. Working with previous version.### Context for the issue:_No response_
"
22827,0,4212,296,0,1,bnavigator,0,"title:BUG: more numpy.distutils.log.* in test_all_modules_are_expected_2 description:### Describe the issue:While packaging numpy for openSUSE Tumbleweed, this test fails with finding additional modules### Reproduce the code example:```pythonimport numpy as npnp.test(extra_argv=['-k', 'test_all_modules_are_expected_2'])```### Error message:```shellNumPy version 1.24.0NumPy relaxed strides checking option: TrueNumPy CPU features:  SSE SSE2 SSE3 SSSE3* SSE41* POPCNT* SSE42* AVX* F16C* FMA3* AVX2* AVX512F? AVX512CD? AVX512_SKX? AVX512_CLX? AVX512_CNL? AVX512_ICL?F                                                                                                                                                    [100%]========================================================================= FAILURES =========================================================================_____________________________________________________________ test_all_modules_are_expected_2 ______________________________________________________________    def test_all_modules_are_expected_2():        """"""        Method checking all objects. The pkgutil-based method in        `test_all_modules_are_expected` does not catch imports into a namespace,        only filenames.  So this test is more thorough, and checks this like:                import .lib.scimath as emath            To check if something in a module is (effectively) public, one can check if        there's anything in that namespace that's a public function/object but is        not exposed in a higher-level namespace.  For example for a `numpy.lib`        submodule::                mod = np.lib.mixins            for obj in mod.__all__:                if obj in np.__all__:                    continue                elif obj in np.lib.__all__:                    continue                    else:                    print(obj)            """"""            def find_unexpected_members(mod_name):            members = []            module = importlib.import_module(mod_name)            if hasattr(module, '__all__'):                objnames = module.__all__            else:                objnames = dir(module)                for objname in objnames:                if not objname.startswith('_'):                    fullobjname = mod_name + '.' + objname                    if isinstance(getattr(module, objname), types.ModuleType):                        if is_unexpected(fullobjname):                            if fullobjname not in SKIP_LIST_2:                                members.append(fullobjname)                return members            unexpected_members = find_unexpected_members(""numpy"")        for modname in PUBLIC_MODULES:            unexpected_members.extend(find_unexpected_members(modname))            if unexpected_members:>           raise AssertionError(""Found unexpected object(s) that look like ""                                 ""modules: {}"".format(unexpected_members))E           AssertionError: Found unexpected object(s) that look like modules: ['numpy.distutils.log.logging', 'numpy.distutils.log.warnings']find_unexpected_members = <function test_all_modules_are_expected_2.<locals>.find_unexpected_members at 0x7ffb9acda200>modname    = 'numpy.version'unexpected_members = ['numpy.distutils.log.logging', 'numpy.distutils.log.warnings']../../../BUILDROOT/python-numpy-1.24.0-0.x86_64/usr/lib64/python3.10/site-packages/numpy/tests/test_public_api.py:418: AssertionError================================================================= short test summary info ==================================================================FAILED tests/test_public_api.py::test_all_modules_are_expected_2 - AssertionError: Found unexpected object(s) that look like modules: ['numpy.distutils.l...1 failed, 22652 deselected in 3.01sFalse```### NumPy/Python version information:1.24.0 3.10.9 (main, Dec 08 2022, 14:49:06) [GCC]### Context for the issue:```diffIndex: numpy-1.24.0/numpy/tests/test_public_api.py===================================================================--- numpy-1.24.0.orig/numpy/tests/test_public_api.py+++ numpy-1.24.0/numpy/tests/test_public_api.py@@ -351,6 +351,8 @@ def test_all_modules_are_expected(): SKIP_LIST_2 = [     'numpy.math',     'numpy.distutils.log.sys',+    'numpy.distutils.log.logging',+    'numpy.distutils.log.warnings,     'numpy.doc.constants.re',     'numpy.doc.constants.textwrap',     'numpy.lib.emath',```should fix the issue
"
22826,0,1036,256,0,0,mwaskom,0,"title:BUG: Regression in interaction between numpy.ma and pandas with 1.24.0 description:### Describe the issue:Hello, this just popped up [in my tests](https://github.com/mwaskom/seaborn/actions/runs/3728877621/jobs/6324262230) with the 1.24.0 release:### Reproduce the code example:```pythonimport numpy as np, pandas as pdnp.ma.masked_invalid(pd.Series([1., 2.]))```### Error message:```shell---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)Cell In [35], line 2      1 import numpy as np, pandas as pd----> 2 np.ma.masked_invalid(pd.Series([1., 2.]))File ~/miniconda/envs/py310/lib/python3.10/site-packages/numpy/ma/core.py:2360, in masked_invalid(a, copy)   2332 def masked_invalid(a, copy=True):   2333     """"""   2334     Mask an array where invalid values occur (NaNs or infs).   2335    (...)   2357    2358     """"""-> 2360     return masked_where(~(np.isfinite(getdata(a))), a, copy=copy)TypeError: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''```### NumPy/Python version information:1.24.0 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]Pandas is 1.5.2### Context for the issue:The issue seems to be with `getdata`, which is pulling out the ~index~ block manager rather than the values:```pythonnp.ma.getdata(pd.Series([1., 2.]))``````SingleBlockManagerItems: RangeIndex(start=0, stop=2, step=1)NumericBlock: 2 dtype: float64```Reporting to numpy rather than pandas as the error emerged with the numpy 1.24.0 update; perhaps it's an issue on the pandas side though.
"
22825,0,3105,297,0,1,h-vetinari,0,"title:BUG: polynomial string options setting is not context safe description:While [building](https://github.com/conda-forge/numpy-feedstock/pull/285) numpy 1.24.0 for conda-forge, we ran into the following errors. All three errors seem to be related to perhaps overzealously prettifying the serialization of polynomials, so for now we skipped those tests on osx+pypy. Details below.```=================================== FAILURES ===================================__________________________ TestPrintOptions.test_str ___________________________[gw2] darwin -- Python 3.8.13 $PREFIX/bin/pythonself = <numpy.polynomial.tests.test_printing.TestPrintOptions object at 0x00007f9c0008d600>    def test_str(self):        p = poly.Polynomial([1/2, 1/7, 1/7*10**8, 1/7*10**9])>       assert_equal(str(p), '0.5 + 0.14285714 x + 14285714.28571429 x**2 '                             '+ (1.42857143e+08) x**3')E       AssertionError:E       Items are not equal:E        ACTUAL: '0.5 + 0.14285714闂傚倸鍊搁崐宄懊归崶褏鏆﹂柛顭戝亝閸欏繘鏌熼鍡忓亾闁哄绉归弻銊モ攽閸℃ê顎涘┑?+ 14285714.28571429闂傚倸鍊搁崐宄懊归崶褏鏆﹂柛顭戝亝閸欏繘鏌熼鍡忓亾闁哄绉归弻銊モ攽閸℃ê顎涘┑鐐存尭椤兘寮诲☉銏╂晝闁绘ɑ褰冩慨鏇㈡⒑?+ (1.42857143e+08)闂傚倸鍊搁崐宄懊归崶褏鏆﹂柛顭戝亝閸欏繘鏌熼鍡忓亾闁哄绉归弻銊モ攽閸℃ê顎涘┑鐐存尭椤兘寮诲☉銏╂晝闁挎繂娲ㄩ鐓庘攽?E        DESIRED: '0.5 + 0.14285714 x + 14285714.28571429 x**2 + (1.42857143e+08) x**3'p          = Polynomial([5.00000000e-01, 1.42857143e-01, 1.42857143e+07, 1.42857143e+08], domain=[-1,  1], window=[-1,  1], symbol='x')self       = <numpy.polynomial.tests.test_printing.TestPrintOptions object at 0x00007f9c0008d600>[...]/lib/pypy3.8/site-packages/numpy/polynomial/tests/test_printing.py:483: AssertionError_____________________ TestPrintOptions.test_switch_to_exp ______________________[gw2] darwin -- Python 3.8.13 $PREFIX/bin/pythonself = <numpy.polynomial.tests.test_printing.TestPrintOptions object at 0x00007f9c0008d0c0>    def test_switch_to_exp(self):        for i, s in enumerate(SWITCH_TO_EXP):            with printoptions(precision=i):                p = poly.Polynomial([1.23456789*10**-i                                     for i in range(i//2+3)])>               assert str(p).replace('\n', ' ') == sE               AssertionError: assert '1.0 + (1.0e-... (1.0e-02)闂傚倸鍊搁崐宄懊归崶褏鏆﹂柛顭戝亝閸欏繘鏌熼鍡忓亾闁哄绉归弻銊モ攽閸℃ê顎涘┑鐐存尭椤兘寮诲☉銏╂晝闁绘ɑ褰冩慨鏇㈡⒑? == '1.0 + (1.0e-...1.0e-02) x**2'E                 - 1.0 + (1.0e-01) x + (1.0e-02) x**2E                 ?                ^             ^ ^^^E                 + 1.0 + (1.0e-01)闂傚倸鍊搁崐宄懊归崶褏鏆﹂柛顭戝亝閸欏繘鏌熼鍡忓亾闁哄绉归弻銊モ攽閸℃ê顎涘┑?+ (1.0e-02)闂傚倸鍊搁崐宄懊归崶褏鏆﹂柛顭戝亝閸欏繘鏌熼鍡忓亾闁哄绉归弻銊モ攽閸℃ê顎涘┑鐐存尭椤兘寮诲☉銏╂晝闁绘ɑ褰冩慨鏇㈡⒑缂佹ɑ鎯堢紓宥勭窔閹繝顢曢敃鈧悙濠囨煏婵犲繒鐣遍柡鍡橆殜濮?                ?                ^             ^ ^i          = 0p          = Polynomial([1.23456789, 0.12345679, 0.01234568], domain=[-1,  1], window=[-1,  1], symbol='x')s          = '1.0 + (1.0e-01) x + (1.0e-02) x**2'self       = <numpy.polynomial.tests.test_printing.TestPrintOptions object at 0x00007f9c0008d0c0>[...]/lib/pypy3.8/site-packages/numpy/polynomial/tests/test_printing.py:517: AssertionError_______________________ TestPrintOptions.test_non_finite _______________________[gw2] darwin -- Python 3.8.13 $PREFIX/bin/pythonself = <numpy.polynomial.tests.test_printing.TestPrintOptions object at 0x00007f9c0008cf00>    def test_non_finite(self):        p = poly.Polynomial([nan, inf])>       assert str(p) == 'nan + inf x'E       AssertionError: assert 'nan + inf闂傚倸鍊搁崐宄懊归崶褏鏆﹂柛顭戝亝閸欏繘鏌熼鍡忓亾闁哄绉归弻銊モ攽閸℃ê顎涘┑? == 'nan + inf x'E         - nan + inf xE         ?          ^E         + nan + inf闂傚倸鍊搁崐宄懊归崶褏鏆﹂柛顭戝亝閸欏繘鏌熼鍡忓亾闁哄绉归弻銊モ攽閸℃ê顎涘┑鐐存尭椤兘寮?        ?          ^p          = Polynomial([nan, inf], domain=[-1,  1], window=[-1,  1], symbol='x')self       = <numpy.polynomial.tests.test_printing.TestPrintOptions object at 0x00007f9c0008cf00>[...]/lib/pypy3.8/site-packages/numpy/polynomial/tests/test_printing.py:521: AssertionError```@mattip speculated:> Weird. So PyPy is prettifying the polynomial where CPython does not? Perhaps some terminal discovery routine is behaving differently, so PyPy renders a utf-8 terminal and CPython renders ascii?
"
22824,0,0,299,0,0,andyfaff,0,"title:BLD: CIRRUS_TAG redux description:Another attempt to close #22730.In this PR if the tag name begins with `v` and doesn't contain `dev0` then it will get uploaded to staging.
"
22823,1,1141,299,0,0,HydrogenSulfate,0,"title:BUG: wrong dtype computing with 0-D teensor description:### Describe the issue:I guess result dtype should be same as input dtype, but code below is not.```pythonimport numpy as npx = np.array([0.04399043, -0.26885903])y = np.array([-0.99222845, -0.1244299])x = x.astype(""float32"")y = y.astype(""float32"")z = np.dot(x, y)print(z.ndim) # 0print(z.shape) # ()print(z.dtype) # float32print((z**2).dtype) # float64```and when `z` is reshaped to `[1]`, dtype is consistent with input as expected```pythonimport numpy as npx = np.array([0.04399043, -0.26885903])y = np.array([-0.99222845, -0.1244299])x = x.astype(""float32"")y = y.astype(""float32"")z = np.dot(x, y).reshape([1]) # reshape to [1]print(z.ndim) # 1print(z.shape) # (1,)print(z.dtype) # float32print((z**2).dtype) # float32``` ### Reproduce the code example:```pythonimport numpy as npx = np.array([0.04399043, -0.26885903])y = np.array([-0.99222845, -0.1244299])x = x.astype(""float32"")y = y.astype(""float32"")z = np.dot(x, y)print(z.ndim) # 0print(z.shape) # ()print(z.dtype) # float32print((z**2).dtype) # float64``````pythonimport numpy as npx = np.array([0.04399043, -0.26885903])y = np.array([-0.99222845, -0.1244299])x = x.astype(""float32"")y = y.astype(""float32"")z = np.dot(x, y).reshape([1]) # reshape to [1]print(z.ndim)print(z.shape)print(z.dtype)print((z**2).dtype)```### Error message:_No response_### NumPy/Python version information:1.21.6 could reproduce this BUG.### Context for the issue:_No response_
"
22812,1,328,16,0,0,AlexanderKeijzer,0,"title:BUG: Inversion operator (~) removes array in single element bool array description:### Describe the issue:The inversion operator (~) removes the numpy array in single element bool array and turns the result into a python boolean.### Reproduce the code example:```pythonimport numpy as npcriteria = np.array([False])print(""Result of ~[False]:"")print(~criteria)print(""Expectation:"")print(np.array([True]))```### Error message:_No response_### NumPy/Python version information:1.23.4 3.8.8 (default, Apr 13 2021, 19:58:26) [GCC 7.3.0]### Context for the issue:This causes issues when using this operation when indexing as follows:```import numpy as np# Note, in a real usecase this element length is not consistently 1data = np.array([2])criteria = np.array([False])selection = data[~criteria]```Instead of indexing with (array) [True] we now index with just True which adds an extra dimension, which is inconsistent compared to the same code where the element length is bigger than 1.
"
22811,0,3131,9,0,1,jtoledo1974,0,"title:Fails to import with numpy 1.23.5 after compiling on raspbian arm with clang 13  for python 3.11 description:### Steps to reproduce:Pip install build from source as there is no wheel for python 3.11```(homeassistant-shadow) homeassistant@lazaro:/srv/homeassistant-shadow$ pip install numpyLooking in indexes: https://pypi.org/simple, https://www.piwheels.org/simpleCollecting numpy  Downloading numpy-1.23.5.tar.gz (10.7 MB)     闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸婂潡鏌ㄩ弮鍌涙珪缂佺姵鍎抽埞鎴︽偐閸欏鎮欓梺缁樺笒閻忔岸濡甸崟顖氱鐎广儱鐗嗛崢鈥愁渻閵堝骸澧柛姘儔婵＄敻宕熼姘棟濠电偛妫涢崑鎾诲煝閸儲鈷戦柛婵嗗閻掕法绱掔紒妯肩疄鐎规洘妞介崺鈧い鎺嶉檷娴滄粓鏌熼悜妯虹仴妞ゅ浚浜弻锟犲川椤旇偐绁峰銈庡弨濞夋洟骞戦崟顖涘仏闁哄鍨甸～鐘绘⒒娴ｅ憡鍟為柨姘舵煟鎺抽崝搴ㄥ箲閵忕姭妲堟繛鍡樺姉缁夊爼姊洪崨濠冨瘷闁告劑鍔庨崢鎺楁⒑鐠囨彃顒㈡い鏃€鐗犲畷浼村冀椤撶喎浜梺缁樻尭鐎垫帡宕甸弴鐔翠簻闁规壋鏅涢悞鐑樼箾鐏忔牗娅婇柡灞诲€濆畷顐﹀Ψ閿旇姤鐦庨梻浣告啞钃遍柟鐟版搐椤繒绱掑Ο鑲╂嚌闂佹悶鍎滈崒婊冨毈缂傚倸鍊风粈渚€顢栭崱娑欏亱闁绘ɑ鐪归埀顑跨閳诲酣骞囬鍌滅嵁闂備礁缍婇崑濠囧储妤ｅ啫鍌ㄩ柟闂寸劍閳锋垿姊洪銈呬粶闁兼椿鍨遍弲鍫曞箻椤旂晫鍘告繛杈剧悼閹虫挻鎱ㄩ崼鈶╁亾閸偅绶查悗姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑?10.7/10.7 MB 8.4 MB/s eta 0:00:00  Installing build dependencies ... done  Getting requirements to build wheel ... done  Preparing metadata (pyproject.toml) ... doneBuilding wheels for collected packages: numpy  Building wheel for numpy (pyproject.toml) ... done  Created wheel for numpy: filename=numpy-1.23.5-cp311-cp311-linux_armv7l.whl size=10681800 sha256=38fff5fe9473a06d14419d01d7e1321906d59765930bd20be43ce30f42e282b6  Stored in directory: /home/homeassistant/.cache/pip/wheels/32/6f/c1/c2fda686f19bc32d64822ae92e3dc4922f9a999c703d998abcSuccessfully built numpyInstalling collected packages: numpySuccessfully installed numpy-1.23.5```### Error message:```shellTraceback (most recent call last):  File ""/srv/homeassistant-shadow/lib/python3.11/site-packages/numpy/core/__init__.py"", line 23, in <module>    from . import multiarray  File ""/srv/homeassistant-shadow/lib/python3.11/site-packages/numpy/core/multiarray.py"", line 10, in <module>    from . import overrides  File ""/srv/homeassistant-shadow/lib/python3.11/site-packages/numpy/core/overrides.py"", line 6, in <module>    from numpy.core._multiarray_umath import (ImportError: /srv/homeassistant-shadow/lib/python3.11/site-packages/numpy/core/_multiarray_umath.cpython-311-arm-linux-gnueabihf.so: undefined symbol: __mulodi4During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""/srv/homeassistant-shadow/lib/python3.11/site-packages/numpy/__init__.py"", line 140, in <module>    from . import core  File ""/srv/homeassistant-shadow/lib/python3.11/site-packages/numpy/core/__init__.py"", line 49, in <module>    raise ImportError(msg)ImportError:IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!Importing the numpy C-extensions failed. This error can happen formany reasons, often due to issues with your setup or how NumPy wasinstalled.We have compiled some common reasons and troubleshooting tips at:    https://numpy.org/devdocs/user/troubleshooting-importerror.htmlPlease note and check the following:  * The Python version is: Python3.11 from ""/srv/homeassistant-shadow/bin/python""  * The NumPy version is: ""1.23.5""and make sure that they are the versions you expect.Please carefully study the documentation linked above for further help.Original error was: /srv/homeassistant-shadow/lib/python3.11/site-packages/numpy/core/_multiarray_umath.cpython-311-arm-linux-gnueabihf.so: undefined symbol: __mulodi4```### Additional information:Both python and numpy where compiled on the raspberry pi 4 running bullseye using clang-13In particular, for compiling python the following was run```export CC=/usr/bin/clang-13export CXX=/usrbin/clang++-13export LDFLAGS="" -fuse-ld=lld""ln -s /usr/bin/llvm-arm-13 /usr/local/bin/llv-armln -s /usr/bin/llvm-profdata-13 /usr/local/bin/llvm-profdata./configure --prefix /usr/local/cpython-3.11 --with-lto=full --enable-optimizations ```python -m test passes correctly.The error showed up inside a venv created with the previously compiled and installed python 3.11.I'm running another build to get the build log and will attach it when it's done.
"
22810,1,134,80,0,0,bieganski,0,"title:BUG: unexpected behavior when testing equality on numpy types description:### Describe the issue:Following code does not raise any exception. It looks like something wrong with `==` operator.### Reproduce the code example:```pythonimport numpy as npkeys = {np.int8: 1}.keys()assert not np.dtype(""int8"") in keysassert     np.dtype(""int8"") in list(keys)```### Error message:_No response_### NumPy/Python version information:1.22.3 3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]### Context for the issue:_No response_
"
22798,0,0,292,0,1,seberg,0,"title:BUG: Fix refcounting errors found using pytest-leaks description:These are the clear errors I found based on pytest-leaks.  One day it would be nice to fix up pytest-leaks to better support newer versions of pytest and cleaning up fixtures...
"
22797,0,1306,164,0,0,seiko2plus,0,"title:BUG: invalid value encountered in rint/floor/ceil/trunc on X86(SSE2) and ARMHF(NEON) description:### Describe the issue:Passing any nonfinite float32 value to (rint, floor, ceil, trunc) will raise an invalid FP exception if SSE41 isn't enabled or not supported by the CPU (old x86). The same issue also exists on armhf.Another case that appeared after #22750, passing float64 qNaN to (rint, floor, ceil, trunc) will also raise an invalid FP exception. ### Reproduce the code example:```pythonexport NPY_DISABLE_CPU_FEATURES=""SSE41""Python 3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0] on linuxType ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> import numpy as np>>> np.seterr(all='raise'){'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}>>> np.trunc(np.float32(-np.inf))Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>FloatingPointError: invalid value encountered in trunc>>> np.trunc(np.float32(np.nan))Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>FloatingPointError: invalid value encountered in trunc>>> np.trunc(np.float32(np.inf))Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>FloatingPointError: invalid value encountered in trunc>>> np.rint(np.float32(np.inf))Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>FloatingPointError: invalid value encountered in rint>>> np.ceil(np.float32(np.inf))Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>FloatingPointError: invalid value encountered in ceil>>> np.floor(np.float32(np.inf))Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>FloatingPointError: invalid value encountered in floor>>>```### Error message:_No response_### NumPy/Python version information:1.23.5 3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]### Context for the issue:_No response_edit:armhf
"
22796,0,5372,271,1,0,WarrenWeckesser,1,"title:BUG: Bad behavior of float128 and complex256 on an m2 Mac description:With numpy built from the main development branch (simply running `pip3 install .` in the source directory) on an m2 Macbook (macOS Ventura 13.0), there is a test of `np.pad` using `dtype` `complex256` that crashes Python.  It looks like there is something wrong with the types `float128` and `complex256`:```% ipythonPython 3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]Type 'copyright', 'credits' or 'license' for more informationIPython 8.7.0 -- An enhanced Interactive Python. Type '?' for help.In [1]: import numpy as npIn [2]: np.__version__Out[2]: '1.25.0.dev0+179.g1a21e72a2'````float128` is only 8 bytes:```In [3]: np.float128(3).itemsizeOut[3]: 8```Something is wrong:```In [4]: np.float128(3)Out[4]: 0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001681872397518720604```If I understand https://github.com/numpy/numpy/issues/22290 correctly, the types `np.float128` and `np.complex256` shouldn't even exist for this build.### NumPy/Python version information:1.25.0.dev0+179.g1a21e72a2 3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]
"
22795,0,0,275,0,1,charris,0,"title:BUG: Ensure arguments to ``npy_floatstatus_..._barrier()`` can be dereferenced description:Backport of #22791.The argument to these functions is dereferenced, even if the value is thrown away. AddressSanitizer reports an error on the dereference for these functions when running the NumPy test suite.* In the case of `ctors.c` this is a use after free.* In the case of `array_assign_array.c` this is an out-of-bounds heap access.Since I don't think it matters exactly *which* pointer we choose for the `floatstatus` code, changed to use another level of indirection. It's unclear to me whether this is a legal fix or not, or whether we need to work harder to find a valid pointer that points within one of the arrays. This depends deeply on the semantics of `volatile` in C and I'm not 100% sure.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22793,0,0,275,0,1,charris,0,"title:BUG: Fix infinite recursion in longdouble/large integer scalar ops description:Backport of #22789.A small bug snuck in when implementing NEP 50 weak-scalar logic, and unfortunately the tests didn't cover that specific path :/.closes gh-22787<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22791,0,0,262,0,1,hawkinsp,0,"title:BUG: Ensure arguments to npy_floatstatus_..._barrier() can be dereferenced description:The argument to these functions is dereferenced, even if the value is thrown away. AddressSanitizer reports an error on the dereference for these functions when running the NumPy test suite.* In the case of `ctors.c` this is a use after free.* In the case of `array_assign_array.c` this is an out-of-bounds heap access.Since I don't think it matters exactly *which* pointer we choose for the `floatstatus` code, changed to use another level of indirection. It's unclear to me whether this is a legal fix or not, or whether we need to work harder to find a valid pointer that points within one of the arrays. This depends deeply on the semantics of `volatile` in C and I'm not 100% sure.This change would need to be backported to the 1.24.x branch.
"
22790,0,2693,262,0,0,hawkinsp,0,"title:BUG: Stack buffer overflow in nditer_api/dtype_transfer in 1.24.x branch description:### Describe the issue:Running `core/tests/test_nditer` under AddressSanitizer reveals a stack buffer overflow:Here's a slightly redacted report from AddressSanitizer, from running that test from commit `1ad784dddbe181e23ada5acf919b54a67976e0dc`:```SanitizerErrorAddressSanitizer: stack-buffer-overflow [third_party/py/numpy/core/src/multiarray/dtype_transfer.c:2239]:33 in _strided_to_strided_field_transfer (.../bin/third_party/py/numpy/core/tests/test_nditer)Details===================================================================8282==ERROR: AddressSanitizer: stack-buffer-overflow on address 0x7fbd6497c248 at pc 0x55c85285244e bp 0x7ffc378cd450 sp 0x7ffc378cd448READ of size 8 at 0x7fbd6497c248 thread T0    #0 0x55c85285244d in _strided_to_strided_field_transfer [third_party/py/numpy/core/src/multiarray/dtype_transfer.c:2239](third_party/py/numpy/core/src/multiarray/dtype_transfer.c):33    #1 0x55c852898675 in npyiter_copy_from_buffers [third_party/py/numpy/core/src/multiarray/nditer_api.c:2068](third_party/py/numpy/core/src/multiarray/nditer_api.c):17    #2 0x55c8528a113e in NpyIter_Deallocate [third_party/py/numpy/core/src/multiarray/nditer_constr.c:687](third_party/py/numpy/core/src/multiarray/nditer_constr.c):17    #3 0x55c8528a7c12 in npyiter_dealloc [third_party/py/numpy/core/src/multiarray/nditer_pywrap.c:1160](third_party/py/numpy/core/src/multiarray/nditer_pywrap.c):14    #4 0x55c852809aae in array_dealloc [third_party/py/numpy/core/src/multiarray/arrayobject.c:451](third_party/py/numpy/core/src/multiarray/arrayobject.c):9    #5 0x55c85410770c in _Py_DECREF [third_party/python_runtime/v3_9/Include/object.h:447](third_party/python_runtime/v3_9/Include/object.h):9    #6 0x55c85410770c in frame_dealloc [third_party/python_runtime/v3_9/Objects/frameobject.c:585](third_party/python_runtime/v3_9/Objects/frameobject.c):9    #7 0x55c8540e8d11 in _Py_DECREF [third_party/python_runtime/v3_9/Include/object.h:447](third_party/python_runtime/v3_9/Include/object.h):9    #8 0x55c8540e8d11 in function_code_fastcall [third_party/python_runtime/v3_9/Objects/call.c:338](third_party/python_runtime/v3_9/Objects/call.c):9    #9 0x55c8541dc388 in do_call_core third_party/python_runtime/v3_9/Python/ceval.c    #10 0x55c8541dc388 in _PyEval_EvalFrameDefault [third_party/python_runtime/v3_9/Python/ceval.c:3582](third_party/python_runtime/v3_9/Python/ceval.c):22...Address 0x7fbd6497c248 is located in stack of thread T0 at offset 72 in frame    #0 0x55c85289814f in npyiter_copy_from_buffers [third_party/py/numpy/core/src/multiarray/nditer_api.c:1897]  This frame has 4 object(s):    [32, 40) 'transfersize' (line 1909)    [64, 72) 'buffer' (line 1915) <== Memory access at offset 72 overflows this variable    [96, 104) 'src_stride' (line 1952)    [128, 136) 'buf_stride' (line 2067)```It looks like `_strided_to_strided_field_transfer` expects `args` to have two entries:https://github.com/numpy/numpy/blob/6205f3f6bf7599894fe3fe98b3aaa1ef3d6ef4a5/numpy/core/src/multiarray/dtype_transfer.c#L2239but it is passed a pointer to a single `char *` on the stack here:https://github.com/numpy/numpy/blob/6205f3f6bf7599894fe3fe98b3aaa1ef3d6ef4a5/numpy/core/src/multiarray/nditer_api.c#L2070### Reproduce the code example:```pythonRun the `test_nditer` test under AddressSanitizer.```### Error message:```shellSee above.```### NumPy/Python version information:Commit 1ad784dddbe181e23ada5acf919b54a67976e0dc from the `maintenance/1.24.x` branch, under Python 3.9 on Linux.### Context for the issue:_No response_
"
22789,0,0,292,0,1,seberg,0,"title:BUG: Fix infinite recursion in longdouble/large integer scalar ops description:A small bug snuck in when implementing NEP 50 weak-scalar logic, and unfortunately the tests didn't cover that specific path :/.closes gh-22787
"
22787,0,5151,290,0,0,effigies,0,"title:BUG: Comparison of longdouble and int causes stack overflow on Windows (pre-release) description:### Describe the issue:In the 1.24 prerelease builds, I'm seeing a very consistent stack overflow error on Windows CI tests. It occurs when comparing a `longdouble` to a Python integer.Note that this is a process crash, not a Python exception. Running the reproduction in a Python shell simply crashes out of the shell, but when running with pytest, I get a notification of `Windows fatal exception: stack overflow`.I've just now gotten an environment up where I'm able to test things locally on Windows and build numpy. I've verified that https://github.com/numpy/numpy/pull/21875 introduced the failure below, as reverting that behavior allows the test below to run (fail) as expected.### Reproduce the code example:```pythonimport numpy as npdef test_1_passes():    # This actually should fail, but passes under rc2    assert np.longdouble(2**64) == 2**64 - 1def test_2_crashes():    # This should fail as well, but instead crashes    assert np.longdouble(2**64) == 2**64if __name__ == ""__main__"":    print(""Start"")    test_1_passes()    print(""Test 1 passed"")    test_2_crashes()    print(""Test 2 passed"")```### Error message:With Python:```console$ python min_test.pyStartTest 1 passed$ ```With pytest:```console$ pytest -v min_test.py========================================================== test session starts ==========================================================platform win32 -- Python 3.10.8, pytest-7.2.0, pluggy-1.0.0 -- C:\Users\marki\Miniconda3\envs\numpy-build\python.execachedir: .pytest_cachehypothesis profile 'default' -> database=DirectoryBasedExampleDatabase('C:\\Users\\marki\\Projects\\nipy\\nibabel\\.hypothesis\\examples')rootdir: C:\Users\marki\Projects\nipy\nibabelplugins: hypothesis-6.61.0, cov-4.0.0, doctestplus-0.12.1, httpserver-1.0.6collected 2 itemsmin_test.py::test_1_passes PASSED                                                                                                  [ 50%]min_test.py::test_2_crashes Windows fatal exception: stack overflowCurrent thread 0x00004c48 (most recent call first):  File ""C:\Users\marki\Projects\nipy\nibabel\min_test.py"", line 7 in test_2_crashes  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\python.py"", line 195 in pytest_pyfunc_call  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_callers.py"", line 39 in _multicall  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_manager.py"", line 80 in _hookexec  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_hooks.py"", line 265 in __call__  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\python.py"", line 1789 in runtest  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\runner.py"", line 167 in pytest_runtest_call  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_callers.py"", line 39 in _multicall  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_manager.py"", line 80 in _hookexec  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_hooks.py"", line 265 in __call__  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\runner.py"", line 260 in <lambda>  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\runner.py"", line 339 in from_call  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\runner.py"", line 259 in call_runtest_hook  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\runner.py"", line 220 in call_and_report  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\runner.py"", line 131 in runtestprotocol  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\runner.py"", line 112 in pytest_runtest_protocol  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_callers.py"", line 39 in _multicall  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_manager.py"", line 80 in _hookexec  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_hooks.py"", line 265 in __call__  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\main.py"", line 349 in pytest_runtestloop  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_callers.py"", line 39 in _multicall  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_manager.py"", line 80 in _hookexec  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_hooks.py"", line 265 in __call__  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\main.py"", line 324 in _main  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\main.py"", line 270 in wrap_session  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\main.py"", line 317 in pytest_cmdline_main  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_callers.py"", line 39 in _multicall  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_manager.py"", line 80 in _hookexec  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\pluggy\_hooks.py"", line 265 in __call__  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\config\__init__.py"", line 167 in main  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\site-packages\_pytest\config\__init__.py"", line 190 in console_main  File ""C:\Users\marki\Miniconda3\envs\numpy-build\Scripts\pytest.exe\__main__.py"", line 7 in <module>  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\runpy.py"", line 86 in _run_code  File ""C:\Users\marki\Miniconda3\envs\numpy-build\lib\runpy.py"", line 196 in _run_module_as_main```### NumPy/Python version information:`1.24.0rc2 3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]`### Context for the issue:We have a function [`as_int()`](https://nipy.org/nibabel/reference/nibabel.casting.html#nibabel.casting.as_int) that aims to be more precise than `int()` on longdoubles, which uses the `int(x) == x` check to see if it needs to do more work.xref https://github.com/nipy/nibabel/issues/1147
"
22783,1,0,299,0,0,MatteoRaso,0,"title:BUG: Quantile now casts properly (#22766) description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22772,0,693,164,0,0,seiko2plus,0,"title:BUG: invalid value encountered in expm1 when AVX512 enabled description:### Describe the issue:Invalid value encountered in expm1 if `NaN` set when SVML/AVX512 enabled and only double precision affected### Reproduce the code example:```pythonsde -- pythonPython 3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0] on linuxType ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> import numpy as np>>> np.seterr(all='raise'){'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}>>> np.lib.utils._opt_info()'SSE SSE2 SSE3 SSSE3* SSE41* POPCNT* SSE42* AVX* F16C* FMA3* AVX2* AVX512F* AVX512CD* AVX512_SKX* AVX512_CLX* AVX512_CNL* AVX512_ICL*'>>> np.expm1(np.array([np.nan], dtype='d'))Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>FloatingPointError: invalid value encountered in expm1```### Error message:```shellFloatingPointError: invalid value encountered in expm1```### NumPy/Python version information:1.25.0.dev0+167.g4ca8204c5 3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]### Context for the issue:_No response_
"
22771,0,0,164,0,1,seiko2plus,0,"title:BUG, SIMD: Fix invalid value encountered in several ufuncs description:closes #22461, #22772, #22797- Fix invalid value encountered in rint/trunc/ceil/floor on armhf/neon- Fix invalid value encountered in rint/trunc/ceil/floor on x86/SSE2- Fix invalid value encountered in expm1 when SVML/AVX512 enabled- Fix invalid value encountered in cos/sin on aarch64 & ppc64lefor more clarification check the linked issues above
"
22762,0,580,293,0,0,MarcoGorelli,0,"title:BUG: OverFlowError when putting np.datetime64('NaT', 'Y') and np.datetime64('NaT', 'ps') in the same set description:### Describe the issue:I can't put these two NaT objects in the same Python setThere used to be a DeprectionWarning for this:```DeprecationWarning: elementwise comparison failed; this will raise an error in the future.```though I don't see why - what elementwise comparison needs doing when putting two objects in the same Python set?### Reproduce the code example:```pythonimport numpy as npnat_1 = np.datetime64('NaT', 'Y')nat_2 = np.datetime64('NaT', 'ps'){nat_1, nat_2}```### Error message:```shell$ python t.pyTraceback (most recent call last):  File ""t.py"", line 5, in <module>    {nat_1, nat_2}OverflowError: Integer overflow getting a common metadata divisor for NumPy datetime metadata [Y] and [ps].```### NumPy/Python version information:```>>> import sys, numpy; print(numpy.__version__, sys.version)1.25.0.dev0+165.g6f9237e91 3.8.15 (default, Oct 12 2022, 19:15:16)[GCC 11.2.0]```### Context for the issue:pandas CI with the nightly wheel broke: https://github.com/pandas-dev/pandas/issues/50124
"
22761,0,0,275,0,1,charris,0,"title:BUG: Fix deepcopy cleanup on error description:Backport of #22753.The deepcopy cleanup on error did not clean up everything in all code paths.  Our test do exercise the path, but leak checking is necessary to see the issue.Making a single PR, since it is a bit larger change.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22759,0,0,275,0,1,charris,0,"title:BUG, SIMD: Fix rounding large numbers >= 2^52 on SSE2 description:Backport of #22750.  Before SSE41, there were no native instructions for rounding  operations on double precision. We usually emulate it by assuming  that the `MXCR` register is set to rounding, adding a  large number `2^52` to `X` and then subtracting it back to  eliminate any excess precision as long as `|X|` is less than `2^52`  otherwise returns `X.`  The current emulated intrinsics `npyv_[rint,floor, ceil, trunc]_f64`  was not checking whether `|x|` equal or large `2^52` which leads  to losing accuracy on large numbers.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22757,0,0,275,0,1,charris,0,"title:CI: fix CIRRUS_TAG check when tagging. Closes #22730. description:Backport of #22752.Closes #22730.* CI: fix CIRRUS_TAG check when tagging* CI: cirrus upload on tag+maintenance* MAINT: Break a long line.Co-authored-by: Charles Harris <charlesr.harris@gmail.com><!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22753,0,0,292,0,1,seberg,0,"title:BUG: Fix deepcopy cleanup on error description:The deepcopy cleanup on error did not clean up everything in all code paths.  Our test do exercise the path, but leak checking is necessary to see the issue.Making a single PR, since it is a bit larger change.---Found using valgrind, will double check the failed test and rerun valgrind fully eventually, but a slightly careful look on the cleanup paths be nice.
"
22752,0,0,299,0,1,andyfaff,0,"title:CI: fix CIRRUS_TAG check when tagging. Closes #22730 description:@charrisCloses #22730.
"
22750,0,0,164,0,1,seiko2plus,0,"title:BUG, SIMD: Fix rounding large numbers on SSE2 description:closes #22170   Before SSE41, there were no native instructions for rounding  operations on double precision. We usually emulate it by assuming  that the `MXCR` register is set to rounding, adding a  large number `2^52` to `X` and then subtracting it back to  eliminate any excess precision as long as `|X|` is less than `2^52`  otherwise returns `X.`  The current emulated intrinsics `npyv_[rint, floor, ceil, trunc]_f64`  was not checking whether `|x|` equal or large `2^52` which leads  to losing accuracy on large numbers.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22748,0,0,275,0,0,charris,0,"title:BUG: ``keepdims=True`` is ignored if ``out`` is not ``None`` in ``numpy.median`` description:Backport of #22721.Closes #22714, #22544.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22746,0,0,275,0,1,charris,0,"title:BUG: Fix some valgrind errors (and probably harmless warnings) description:Backport of #22724.Small refcounting fixups found using valgrind. More may be coming, but probably no point in waiting with these.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22744,1,517,277,0,1,neutrinoceros,0,"title:BUG: broken comparison between ndarray subclass (unyt) and strings description:### Describe the issue:19ba7c4529a17a10abf0d52615011336a0deb606 ([#22707](https://github.com/numpy/numpy/pull/22707)) broke string comparison between `unyt.unyt_quantity` object (fancy 0d numpy arrays with unit data), and strings.The following minimal example used to be fine, but it crashes on the main branch of `numpy`### Reproduce the code example:```pythonimport unyt as una = 1 * un.cmassert a != ""hello""```### Error message:```shell-tracebackTraceback (most recent call last):  File ""/Users/robcleme/dev/numpy/t.py"", line 4, in <module>    assert a != ""hello""           ^^^^^^^^^^^^  File ""/Users/robcleme/.pyenv/versions/numpy-dev/lib/python3.11/site-packages/unyt/array.py"", line 1850, in __array_ufunc__    new_dtype = np.dtype(""f"" + str(inp1.dtype.itemsize))                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^TypeError: data type 'f20' not understood```### NumPy/Python version information:Python 3.11.0### Context for the issue:This change of behaviour breaks `yt`, see https://github.com/yt-project/yt/issues/4241~I note that we haven't captured this regression via `unyt`'s on CI, so I'll add a test there.~ (edit: this is https://github.com/yt-project/unyt/pull/333)It is unclear to me why this is happening, and I am not sure which of `numpy` or `unyt` this bug should be fixed in.Ping @ngoldbaum for information
"
22724,0,0,292,0,1,seberg,0,"title:BUG: Fix some valgrind errors (and probably harmless warnings) description:Small refcounting fixups found using valgrind.  More may be coming, but probably no point in waiting with these.
"
22721,0,0,290,0,0,byrdie,0,"title:BUG: ``keepdims=True`` is ignored if ``out`` is not ``None`` in ``numpy.median``. description:Closes #22544, #22714<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22715,1,2188,37,0,0,hulmakerik,0,"title:BUG: RecursionError with np.meshgrid description:### Describe the issue:I encountered the error below that does not make sense. It occurred during generating synthetic dateset with blender within a docker container. Unfortunately I can't provide more info. I don't even know if it is possible to reproduce it.### Reproduce the code example:```pythonk = np.array([[-1, 1, 0], [1, 1, 0], [1, -1, 0], [-1, -1, 0]], dtype=float)pw = k * 4.8 * 0.3  # edit seberg, was:  k * self.cam.h * 0.3    # self.cam.h: float = 4.8n = len(pw)ij = np.array(np.meshgrid(np.arange(n), np.arange(n)))  # ij meshgrid```### Error message:```shelltransformer.py"", line 95, in _estimate_px_per_m    ij = np.array(np.meshgrid(np.arange(n), np.arange(n)))  # ij meshgrid  File ""<__array_function__ internals>"", line 180, in meshgrid  File ""/home/user/blender-3.3.1-linux-x64/3.3/python/lib/python3.10/site-packages/numpy/lib/function_base.py"", line 4987, in meshgrid    output = np.broadcast_arrays(*output, subok=True)  File ""<__array_function__ internals>"", line 180, in broadcast_arrays  File ""/home/user/blender-3.3.1-linux-x64/3.3/python/lib/python3.10/site-packages/numpy/lib/stride_tricks.py"", line 546, in broadcast_arrays    return [_broadcast_to(array, shape, subok=subok, readonly=False)  File ""/home/user/blender-3.3.1-linux-x64/3.3/python/lib/python3.10/site-packages/numpy/lib/stride_tricks.py"", line 546, in <listcomp>    return [_broadcast_to(array, shape, subok=subok, readonly=False)  File ""/home/user/blender-3.3.1-linux-x64/3.3/python/lib/python3.10/site-packages/numpy/lib/stride_tricks.py"", line 345, in _broadcast_to    if any(size < 0 for size in shape):  File ""/home/user/blender-3.3.1-linux-x64/3.3/python/lib/python3.10/site-packages/numpy/lib/stride_tricks.py"", line 345, in <genexpr>    if any(size < 0 for size in shape):RecursionError: maximum recursion depth exceeded in comparisonTraceback (most recent call last):  File ""/home/user/.config/blender/3.3/scripts/addons/HumGen3D/core/HG_CALLBACK.py"", line 85, in HG_Callback    _context_specific_updates(self, sett, hg_rig, ui_phase)  File ""/home/user/.config/blender/3.3/scripts/addons/HumGen3D/core/HG_CALLBACK.py"", line 160, in _context_specific_updates    _refresh_body_scaling(self, sett, hg_rig)  File ""/home/user/.config/blender/3.3/scripts/addons/HumGen3D/core/HG_CALLBACK.py"", line 194, in _refresh_body_scaling    slider_value = bones[bone_group[0]].scale[0] * 3 - 2.5KeyError: 'bpy_prop_collection[key]: key ""spine.002"" not found'```### NumPy/Python version information:1.23.5 3.10.2 (main, Apr 26 2022, 10:33:12) [GCC 9.3.1 20200408 (Red Hat 9.3.1-2)]### Context for the issue:Low priority, unable to reproduce, does not occur periodically
"
22714,0,1666,290,0,1,byrdie,0,"title:BUG: `numpy.median()` does not respect `keepdims=True` when the `out` argument is specified description:### Describe the issue:`numpy.median()` is ignoring `keepdims=True` when the `out` argument is set. If `out` has the same number of dimensions as the input, an error is raised. If `out` has the number of dimensions consistent with `keepdims=False` no error is raised.I'm happy to try and open a PR to fix this issue if we decide that this is indeed a bug.### Reproduce the code example:```pythonimport numpy as npnp.median(np.random.random((11, 12, 13)), axis=~0, out=np.empty((11, 12, 1)), keepdims=True)```### Error message:```shellTraceback (most recent call last):  File ""C:\Users\royts\AppData\Local\Programs\Python\Python310\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code    exec(code_obj, self.user_global_ns, self.user_ns)  File ""<ipython-input-10-a37955de53f7>"", line 1, in <module>    np.median(np.random.random((11, 12, 13)), axis=~0, out=np.empty((11, 12, 1)), keepdims=True)  File ""<__array_function__ internals>"", line 180, in median  File ""C:\Users\royts\AppData\Local\Programs\Python\Python310\lib\site-packages\numpy\lib\function_base.py"", line 3816, in median    r, k = _ureduce(a, func=_median, axis=axis, out=out,  File ""C:\Users\royts\AppData\Local\Programs\Python\Python310\lib\site-packages\numpy\lib\function_base.py"", line 3725, in _ureduce    r = func(a, **kwargs)  File ""C:\Users\royts\AppData\Local\Programs\Python\Python310\lib\site-packages\numpy\lib\function_base.py"", line 3870, in _median    rout = mean(part[indexer], axis=axis, out=out)  File ""<__array_function__ internals>"", line 180, in mean  File ""C:\Users\royts\AppData\Local\Programs\Python\Python310\lib\site-packages\numpy\core\fromnumeric.py"", line 3432, in mean    return _methods._mean(a, axis=axis, dtype=dtype,  File ""C:\Users\royts\AppData\Local\Programs\Python\Python310\lib\site-packages\numpy\core\_methods.py"", line 180, in _mean    ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)ValueError: output parameter for reduction operation add has the wrong number of dimensions: Found 3 but expected 2```### NumPy/Python version information:1.23.5 3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]### Context for the issue:_No response_
"
22711,0,142,300,0,0,Neumann-A,0,"title:BUG: meson.build not working with MSVC description:### Describe the issue:The meson buildsystem numpy has doesn't work with MSVC on windows since the defines ```#mesondefine NPY_SIZEOF_COMPLEX_FLOAT#mesondefine NPY_SIZEOF_COMPLEX_DOUBLE#mesondefine NPY_SIZEOF_COMPLEX_LONGDOUBLE```won't be defined. Yielding the following error:`numpy\core\include\numpy/npy_common.h(430): fatal error C1189: #error:  npy_cdouble definition is not compatible with C99 complex definition !         Please contact NumPy maintainers and give detailed information about your         compiler and platform`### Reproduce the code example:```python-```### Error message:```shell-```### NumPy/Python version information:-### Context for the issue:_No response_
"
22704,1,3413,239,0,0,oyvindronningstad,0,"title:BUG: Inconsistent rounding when converting float32 to float16 description:### Describe the issue:numpy does some rounding to the nearest value when converting from float32 to float16. When rounding to the nearest value the convention is to round the midpoint up (like in decimal, where 0.5 is rounded up to 1). In numpy the midpoint seems to be rounded down sometimes, but not others. Here is the output from the below program:```0x34200000 is rounded to 0x0002, but should be rounded to 0x0003.The bits 0x341fffff as float32 converted to float16 is the bits 0x0002.The bits 0x34200000 as float32 converted to float16 is the bits 0x0002.The bits 0x34200001 as float32 converted to float16 is the bits 0x0003.The bits 0x0002 as float16 converted to float32 is the bits 0x34000000.The bits 0x0003 as float16 converted to float32 is the bits 0x34400000.0x34600000 is rounded correctly to 0x0004.The bits 0x345fffff as float32 converted to float16 is the bits 0x0003.The bits 0x34600000 as float32 converted to float16 is the bits 0x0004.The bits 0x34600001 as float32 converted to float16 is the bits 0x0004.The bits 0x0003 as float16 converted to float32 is the bits 0x34400000.The bits 0x0004 as float16 converted to float32 is the bits 0x34800000.0x40001000 is rounded to 0x4000, but should be rounded to 0x4001.The bits 0x40000fff as float32 converted to float16 is the bits 0x4000.The bits 0x40001000 as float32 converted to float16 is the bits 0x4000.The bits 0x40001001 as float32 converted to float16 is the bits 0x4001.The bits 0x4000 as float16 converted to float32 is the bits 0x40000000.The bits 0x4001 as float16 converted to float32 is the bits 0x40002000.0x40003000 is rounded correctly to 0x4002.The bits 0x40002fff as float32 converted to float16 is the bits 0x4001.The bits 0x40003000 as float32 converted to float16 is the bits 0x4002.The bits 0x40003001 as float32 converted to float16 is the bits 0x4002.The bits 0x4001 as float16 converted to float32 is the bits 0x40002000.The bits 0x4002 as float16 converted to float32 is the bits 0x40004000.```### Reproduce the code example:```pythonimport numpydef short_to_float16(short_num):	float16_num = numpy.frombuffer(numpy.ushort(short_num).tobytes(), dtype=numpy.float16)[0]	float32_num = float16_num.astype(numpy.float32)	int_num = numpy.frombuffer(float32_num.tobytes(), dtype=numpy.uintc)[0]	print(f""The bits 0x{short_num:04x} as float16 converted to float32 is the bits 0x{int_num:08x}."")	return float16_numdef int_to_float32(int_num):	float32_num = numpy.frombuffer(numpy.uintc(int_num).tobytes(), dtype=numpy.float32)[0]	float16_num = float32_num.astype(numpy.float16)	short_num = numpy.frombuffer(float16_num.tobytes(), dtype=numpy.ushort)[0]	print(f""The bits 0x{int_num:08x} as float32 converted to float16 is the bits 0x{short_num:04x}."")	return float32_numprint(""0x34200000 is rounded to 0x0002, but should be rounded to 0x0003."")int_to_float32(0x341FFFFF)int_to_float32(0x34200000)int_to_float32(0x34200001)short_to_float16(0x0002)short_to_float16(0x0003)print()print(""0x34600000 is rounded correctly to 0x0004."")int_to_float32(0x345FFFFF)int_to_float32(0x34600000)int_to_float32(0x34600001)short_to_float16(0x0003)short_to_float16(0x0004)print()print(""0x40001000 is rounded to 0x4000, but should be rounded to 0x4001."")int_to_float32(0x40000FFF)int_to_float32(0x40001000)int_to_float32(0x40001001)short_to_float16(0x4000)short_to_float16(0x4001)print()print(""0x40003000 is rounded correctly to 0x4002."")int_to_float32(0x40002FFF)int_to_float32(0x40003000)int_to_float32(0x40003001)short_to_float16(0x4001)short_to_float16(0x4002)```### Error message:No exceptions encountered### NumPy/Python version information:```>>> import sys, numpy; print(numpy.__version__, sys.version)1.23.5 3.10.6 (main, Nov  2 2022, 18:53:38) [GCC 11.3.0]```### Context for the issue:I am creating some code in C that converts float32 to float16, and wanted to test it against the output of numpy. This bug affects me insofar as it makes it harder to generate correct test vectors for my code.
"
22695,0,1685,21,0,0,tammoippen,0,"title:BUG: SIGSEGV on PyPy3.7-7.3.9 and numpy 1.21.6 description:### Describe the issue:Running with the precompiled numpy from pypi, i get segvaults converting datetime64 into python datetimes for pypy3.7.```sh$ pypy3.7 -m pip install numpyCollecting numpy  Using cached numpy-1.21.6-pp37-pypy37_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.2 MB)Installing collected packages: numpySuccessfully installed numpy-1.21.6$ pypy3 -c 'import numpy as np; np.datetime64(""2022-01-01T12:00:00"").item()'fish: Job 1, 'pypy3 -c 'import numpy as np; n闂? terminated by signal SIGSEGV (Address boundary error)```When building the numpy lib from source, there is no such error.```sh$ pypy3.7 -m install --no-binary numpy numpyCollecting numpy  Using cached numpy-1.21.6.zip (10.3 MB)  Installing build dependencies ... done  Getting requirements to build wheel ... done  Preparing metadata (pyproject.toml) ... doneBuilding wheels for collected packages: numpy  Building wheel for numpy (pyproject.toml) ... done  Created wheel for numpy: filename=numpy-1.21.6-pp37-pypy37_pp73-linux_x86_64.whl size=6869664 sha256=1fd83a9bfbc319edb988cb1288d9654776b1c2baf98ec927fc9e723a5f1ca470  Stored in directory: /home/tammo/.cache/pip/wheels/5c/47/f4/e65038499db16c1998bd745b8101da1b1f8a9cc4131df49549Successfully built numpyInstalling collected packages: numpy$ pypy3 -c 'import numpy as np; np.datetime64(""2022-01-01T12:00:00"").item()'$ # no SIGSEGV```### Reproduce the code example:```pythonimport numpynumpy.datetime64(""2022-01-01T12:00:00"").item()```### Error message:```shell$ pypy3 -c 'import numpy as np; np.datetime64(""2022-01-01T12:00:00"").item()'fish: Job 1, 'pypy3 -c 'import numpy as np; n闂? terminated by signal SIGSEGV (Address boundary error)```### NumPy/Python version information:```sh$ pypy3.7 -c 'import sys, numpy; print(numpy.__version__, sys.version)'1.21.6 3.7.13 (7e0ae751533460d5f89f3ac48ce366d8642d1db5, Mar 29 2022, 06:03:31)[PyPy 7.3.9 with GCC 10.2.1 20210130 (Red Hat 10.2.1-11)]```### Context for the issue:I am maintaining [plotille](https://github.com/tammoippen/plotille) and want to support printing numpy arrays of datetimes as well. My strategy right now is to transform them into native python objects. This is the only combination failing right now: i removed it for now, but would like to test it as well.Here is a failing run: https://github.com/tammoippen/plotille/actions/runs/3574303228/jobs/6009404104
"
22676,0,0,292,0,0,seberg,0,"title:BUG: Ensure string aliases `""int0""`, etc. remain valid for now description:int0 and uint0 were accidentally dropped, the others just added as a test.We did successfully remove many Numeric types before, so these could probably be deprecated (it is a bit more annoying to do).These could probably just be removed, ~even scipy only noticed it in a single test~ scikit-learn only noticed it in a single test (scipy probably not at all)..  But maybe not in 1.24Closes gh-22672
"
22673,0,1241,283,0,0,Carreau,0,"title:BUG: `scipy.special` import broken with numpy 1.24.0rc1 description:### Describe the issue:NumPy Rc seem to break some of SciPy ? it might be a SciPy issue, but as it's the numpy RC.. I prefer to open it here.### Reproduce the code example:```pythonconda create -n rc python==3.10conda activate rcpip install scipy numpy --prepython -c 'from scipy.spatial.distance import euclidean' ```### Error message:```shellTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""/Users/bussonniermatthias/miniforge3/envs/dl/lib/python3.10/site-packages/scipy/spatial/__init__.py"", line 111, in <module>    from ._geometric_slerp import geometric_slerp  File ""/Users/bussonniermatthias/miniforge3/envs/dl/lib/python3.10/site-packages/scipy/spatial/_geometric_slerp.py"", line 9, in <module>    from scipy.spatial.distance import euclidean  File ""/Users/bussonniermatthias/miniforge3/envs/dl/lib/python3.10/site-packages/scipy/spatial/distance.py"", line 121, in <module>    from ..special import rel_entr  File ""/Users/bussonniermatthias/miniforge3/envs/dl/lib/python3.10/site-packages/scipy/special/__init__.py"", line 649, in <module>    from . import _ufuncsImportError: dlopen(/Users/bussonniermatthias/miniforge3/envs/dl/lib/python3.10/site-packages/...     ...scipy/special/_ufuncs.cpython-310-darwin.so, 0x0002): symbol not found in flat namespace (_npy_asinh)```### NumPy/Python version information:```1.24.0rc1 3.10.0 | packaged by conda-forge | (default, Nov 20 2021, 02:27:15) [Clang 11.1.0 ]```
"
22672,0,168,282,0,0,ogrisel,0,"title:BUG:  TypeError: data type 'int0' not understood description:### Describe the issue:I think dtype was meant to be deprecated (as per #15334) but apparently the dtype disappeared without notice since last night's nightly build.### Reproduce the code example:```pythonimport numpy as npnp.dtype(""int0"")```### Error message:```shellTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>TypeError: data type 'int0' not understood```### NumPy/Python version information:1.25.0.dev0+11.ga872fd73e### Context for the issue:_No response_
"
22670,0,0,299,0,1,MatteoRaso,0,"title:BUG: Polynomials now copy properly (#22669) description:On line 502, self.symbol.copy() was called, whichcauses an AttributeError, since self.symbol is astring, so it doesn't have a copy() method. To fix it, I simply removed the copy() and directly assigned the string.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22669,0,503,0,0,1,ncsaba,0,"title:BUG: deep copying polybase broken description:### Describe the issue:The issue is at line 502 in _polybase.py:ret['symbol'] = self.symbol.copy()Pronblem is that self.symbol is a string and has no copy method. Instead should be assigned directly as it is immutable:ret['symbol'] = self.symbol### Reproduce the code example:```python>>> from numpy.polynomial import Polynomial>>> x = Polynomial([1, 2, 3])>>> from copy import deepcopy>>> deepcopy(x)```### Error message:```shellTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""/usr/lib/python3.8/copy.py"", line 161, in deepcopy    rv = reductor(4)  File ""/hdd/tmp/tempvenv/lib/python3.8/site-packages/numpy/polynomial/_polybase.py"", line 502, in __getstate__    ret['symbol'] = self.symbol.copy()AttributeError: 'str' object has no attribute 'copy'```### NumPy/Python version information:1.24.0rc1 3.8.10 (default, Jun 22 2022, 20:18:18) [GCC 9.4.0]### Context for the issue:Easy fix in the bug description.
"
22652,0,135,34,0,0,aschaffer,0,"title:BUG: Quantile function on complex numbers doesn't error description:### Describe the issue:Complex numbers are unordered. The complex set, 闂? is isomorphic with 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸婂潡鏌ㄩ弴鐐测偓鎼佸礄閻樻祴鏀介柛灞剧矤閻掗箖鏌ｉ妶鍥т壕缂佺粯绻冪换婵嬪磼濞戞ɑ顏℃俊? which is an unordered vector space. On the other hand, quantiles are the inverse of the cumulative distribution function, CDF. Which is monotonic. It must be, for its inverse to exist.Consequentially, it makes no mathematical sense to apply quantiles to an unordered set, like a complex input array. Some order can be introduced (e.g., lexicographic) but it is artificial, without a sound mathematical support.However, both sorting and quantiles functions work in numpy (see example below). Instead, an exception should be thrown.### Reproduce the code example:```pythonimport numpy as nparr_c = np.array([0.5+3.0j, 2.1+0.5j, 1.6+2.3j], dtype=np.dtype('complex128'))np.quantile(arr_c, 0.5)```### Error message:_No response_### NumPy/Python version information:1.23.3 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) [GCC 10.3.0]### Context for the issue:_No response_
"
22625,0,0,275,1,0,charris,0,"title:BUG: Histogramdd breaks on big arrays in Windows  description:Backport of #22561.Resolved the issue with line change from int to np.intp in numpy/numpy/lib/histograms.pyNew test function was added called test_big_arrays on numpy/lib/tests/test_histograms.pyResolved https://github.com/numpy/numpy/issues/22288Pydata Sprint NYC 2022
"
22597,0,0,275,1,0,charris,0,"title:BUG: Decrement ref count in gentype_reduce if allocated memory not used description:Backport of #22557.Resolves https://github.com/numpy/numpy/issues/21495Done as part of PyData NYC 2022.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22594,0,0,275,0,1,charris,0,"title:BUG: Fix bounds checking for `random.logseries` description:Backport of #22450.Logseries previously did not enforce bounds to be strictly exclusive for the upper bound, where it leads to incorrect behavior.The NOT_NAN check is removed, since it was never used: The current bounded version always excludes NaNs.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22585,1,210,18,0,0,lakshya-4gp,0,"title:BUG: inverse of a array causing crash description:### Describe the issue:I'm trying np.linalg.inv with a 3x3 matrix (represents a camera's intrinsic matrix) which is causing kernel to crash in jupyter notebook.To overcome the same, I've downgraded from 1.23.4 to 1.22.4, in which it works fine.Issue comes for following array:array([[514.13902522,   0.        , 640.        ],       [  0.        , 514.13902522, 360.        ],       [  0.        ,   0.        ,   1.        ]])Issue in Version: 1.23.4 ### Reproduce the code example:```pythonimport numpy as npA = np.array([[514.13902522,   0.        , 640.        ],       [  0.        , 514.13902522, 360.        ],       [  0.        ,   0.        ,   1.        ]])np.linalg.inv(A)```### Error message:_No response_### NumPy/Python version information:1.23.4### Context for the issue:_No response_
"
22582,1,1590,224,0,0,maksymar,0,"title:BUG: `numpy.percentile` with `inverted_cdf` method (maybe?) returns an incorrect result description:### Describe the issue:I am looking for the nearest-rank method implementation ([wiki](https://en.wikipedia.org/wiki/Percentile#The_nearest-rank_method)) in `numpy.percentile`, but there are none. The method that produced the closest results is an `inverted_cdf`, but there are some strange discrepancies.My simple example is an array of 100 increasing numbers from 0 to 99. Obviously `nearest-rank` percentiles would result an array of linearly growing numbers as well. With the exception of p=0 and p=1 both that return the same result, which is the minimum element in the array.Unexpectedly `inverted_cdf` returns not exactly linear result for percentile values of 7, 14, 28, 55, 56.Below you can see an example for p=7:```[... 5, 6, 7, 8, 9, ...] - input percentile values[... 4, 5, 6, 7, 8, ...] - expected result           ?[... 4, 5, 7, 7, 8, ...] - actual result```I would like to know if that's because...1. I misunderstood `inverted_cdf` method and it should not be equal to `nearest-rank` or2. `inverted_cdf` indeed calculates a wrong result.### Reproduce the code example:```pythonimport numpy as npmethod='inverted_cdf'def nearest_rank_percentile(arr, p):    # Nearest rank method, see https://en.wikipedia.org/wiki/Percentile#The_nearest-rank_method    ceil_div = lambda a, b: a // b + (0 if a % b == 0 else 1)    ordinal_rank = ceil_div(p * len(arr), 100)    i = max(0, ordinal_rank-1)    return sorted(arr)[i]def verify(arr, p):    r1 = np.percentile(arr, p, method=method)    r2 = nearest_rank_percentile(arr, p)    if r1 == r2:        print(f'[ OK ] p={p} result {r1}')    else:        print(f'[FAIL] p={p} result {r1}!={r2}')arr = list(range(0, 100))# Iterate over percentiles in the range of [0, 100].for p in range(0, 101):    verify(arr, p)```### Error message:```shellOutput:[ OK ] p=0 result 0[ OK ] p=1 result 0[ OK ] p=2 result 1...[ OK ] p=5 result 4[ OK ] p=6 result 5[FAIL] p=7 result 7!=6[ OK ] p=8 result 7[ OK ] p=9 result 8...[ OK ] p=12 result 11[ OK ] p=13 result 12[FAIL] p=14 result 14!=13[ OK ] p=15 result 14[ OK ] p=16 result 15...[ OK ] p=26 result 25[ OK ] p=27 result 26[FAIL] p=28 result 28!=27[ OK ] p=29 result 28[ OK ] p=30 result 29...[ OK ] p=53 result 52[ OK ] p=54 result 53[FAIL] p=55 result 55!=54[FAIL] p=56 result 56!=55[ OK ] p=57 result 56[ OK ] p=58 result 57...```### NumPy/Python version information:```sys version: 3.9.6 (default, Aug  5 2022, 15:21:02) [Clang 14.0.0 (clang-1400.0.29.102)]numpy version: 1.23.3```### Context for the issue:_No response_
"
22576,0,1840,268,0,1,rgommers,0,"title:BUG: fix issue with broken assert statement in `templ_common.h.src` description:`assert()` only takes one argument. This was recently introduced, in commit 4156ae260 (gh-21793).It looks like this code is not exercised in CI. I only stumbled over it because I'm working with an incomplete config header, so `HAVE___BUILTIN_MUL_OVERFLOW` was not defined.Full error:```In file included from ../numpy/core/src/common/npy_hashtable.c:15:../numpy/core/src/common/templ_common.h.src: In function 'npy_mul_sizes_with_overflow':../numpy/core/src/common/templ_common.h.src:61:80: error: macro ""assert"" passed 2 arguments, but takes just 1   61 |     assert(a >= 0 && b >= 0, ""this function only supports non-negative numbers"");      |                                                                                ^In file included from /home/rgommers/mambaforge/envs/numpy-dev/include/python3.9/Python.h:48,                 from ../numpy/core/include/numpy/npy_common.h:5,                 from ../numpy/core/src/common/templ_common.h.src:6,                 from ../numpy/core/src/common/npy_hashtable.c:15:/home/rgommers/mambaforge/envs/numpy-dev/x86_64-conda-linux-gnu/sysroot/usr/include/assert.h:52: note: macro ""assert"" defined here   52 | # define assert(expr)  (__ASSERT_VOID_CAST (0))      | In file included from ../numpy/core/src/common/npy_hashtable.c:15:../numpy/core/src/common/templ_common.h.src:61:5: error: 'assert' undeclared (first use in this function)   61 |     assert(a >= 0 && b >= 0, ""this function only supports non-negative numbers"");      |     ^~~~~~In file included from ../numpy/core/src/common/npy_hashtable.c:15:../numpy/core/src/common/templ_common.h.src:7:1: note: 'assert' is defined in header '<assert.h>'; did you forget to '#include <assert.h>'?    6 | #include ""numpy/npy_common.h""  +++ |+#include <assert.h>    7 | In file included from ../numpy/core/src/common/npy_hashtable.c:15:../numpy/core/src/common/templ_common.h.src:61:5: note: each undeclared identifier is reported only once for each function it appears in   61 |     assert(a >= 0 && b >= 0, ""this function only supports non-negative numbers"");      |     ^~~~~~```
"
22575,0,0,33,1,1,LuYunChi,0,"title:BUG: fix unexpected return of np.pad with mode=wrap description:`np.pad` with `mode=""wrap""` returns unexpected result that original data is not strictly looped in padding. This may happen in some occassions when padding widths in the same dimension are unbalanced (see added testcase in `test_arraypad.py` and the related issue). The reason is the function `pad` makes iterative calls of `_set_wrap_both()` in the above situation, yet `period` for padding is not correctly computed in each iteration.The bug is fixed by guaranteeing that `period` is always a multiple of original data size, and also be the possible maximum for computation efficiency.Closes [#22464](https://github.com/numpy/numpy/issues/22464#issue-1417891134)
"
22574,1,0,33,1,1,LuYunChi,0,"title:BUG: fix unexpected return of np.pad with mode=wrap description:`np.pad` with `mode=""wrap""` returns unexpected result that original data is not strictly looped in padding. This may happen in some occassions when padding widths in the same dimension are unbalanced (see added testcase in `test_arraypad.py` and the related issue). The reason is the function `pad` makes iterative calls of `_set_wrap_both()` in the above situation, yet `period` for padding is not correctly computed in each iteration.The bug is fixed by guaranteeing that `period` is always a multiple of original data size, and also be the possible maximum for computation efficiency.Closes [#22464](https://github.com/numpy/numpy/issues/22464#issue-1417891134)
"
22572,1,9335,0,0,0,Songningw99,0,"title:BUG: f2py compile fail, require C99 standard description:### Describe the issue:After I ran `f2py -c test_sub.f90 test_sub.pyf`, I got an error compiling the codes:```....../tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.c:707:5: error: 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨澶愭⒑闁偛鑻晶顖涙叏婵犲倹璐＄紒顔界濞煎繘鍩￠崘褏鐟濆┑鐐存尰閸╁啴宕戦幘瀛樺弿?loop initial declarations are only allowed in C99 mode     for (int i = 0; i < rank; ++i) {     ^/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.c:707:5: note: use option -std=c99 or -std=gnu99 to compile your codeerror: Command ""gcc -pthread -B /data/keeling/a/songning/miniconda3/envs/default/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/keeling/a/songning/miniconda3/envs/default/include -fPIC -O2 -isystem /data/keeling/a/songning/miniconda3/envs/default/include -fPIC -DNPY_DISABLE_OPTIMIZATION=1 -I/tmp/tmphlgqv6nk/src.linux-x86_64-3.8 -I/data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/core/include -I/data/keeling/a/songning/miniconda3/envs/default/include/python3.8 -c /tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.c -o /tmp/tmphlgqv6nk/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.o -MMD -MF /tmp/tmphlgqv6nk/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.o.d"" failed with exit status 1```I don't find an entrance to pass `-std=c99`, is there any specific reason that the `int i = 0` parameter is place inside for statement here rather than make the statement before `for`? I don't remember seeing this error in the earlier version. ```# f2py -v1.23.4```My codes if it's needed:test_sub.f90: ```subroutine test_sub(a)    use:: ISO_FORTRAN_ENV    use:: IEEE_ARITHMETIC, only: ieee_support_nan, ieee_is_nan, &                                            ieee_quiet_nan, ieee_value    implicit none    real(real32), dimension(:), intent(in):: a    integer(int32):: n=len(a)    do i = 1:n         write(*, *) i, ieee_is_nan(a(i))    end doend subroutine test_sub```test_sub.pyf: ```!    -*- f90 -*-! Note: the context of this file is case sensitive.python module test_sub ! in     interface  ! in :test_sub        subroutine test_sub(a) ! in :test_sub:test_sub.f90            real(kind=real32) dimension(:),intent(in) :: a        end subroutine test_sub    end interface end python module test_sub! This file was auto-generated with f2py (version:1.22.4).! See:! https://web.archive.org/web/20140822061353/http://cens.ioc.ee/projects/f2py2e```### Reproduce the code example:```python!f2py -c test_sub.f90 test_sub.pyf```### Error message:```shellrunning buildrunning config_ccINFO: unifing config_cc, config, build_clib, build_ext, build commands --compiler optionsrunning config_fcINFO: unifing config_fc, config, build_clib, build_ext, build commands --fcompiler optionsrunning build_srcINFO: build_srcINFO: building extension ""test_sub"" sourcescreating /tmp/tmphlgqv6nk/src.linux-x86_64-3.8INFO: f2py options: []INFO: f2py: test_sub.pyfReading fortran codes...        Reading file 'test_sub.pyf' (format:free)Post-processing...        Block: test_sub                        Block: test_subPost-processing (stage 2)...Building modules...    Building module ""test_sub""...    Generating possibly empty wrappers""    Maybe empty ""test_sub-f2pywrappers2.f90""    Maybe empty ""test_sub-f2pywrappers.f""                Creating wrapper for Fortran subroutine ""test_sub""(""test_sub"")...        Constructing wrapper function ""test_sub""...getctype: ""real(kind=real32)"" is mapped to C ""float"" (to override define dict(real = dict(real32=""<C typespec>"")) in /data/jtrapp/a/songning/f_cape/.f2py_f2cmap file).getctype: ""real(kind=real32)"" is mapped to C ""float"" (to override define dict(real = dict(real32=""<C typespec>"")) in /data/jtrapp/a/songning/f_cape/.f2py_f2cmap file).getctype: ""real(kind=real32)"" is mapped to C ""float"" (to override define dict(real = dict(real32=""<C typespec>"")) in /data/jtrapp/a/songning/f_cape/.f2py_f2cmap file).          test_sub(a)    Wrote C/API module ""test_sub"" to file ""/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/test_submodule.c""    Fortran 90 wrappers are saved to ""/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/test_sub-f2pywrappers2.f90""INFO:   adding '/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.c' to sources.INFO:   adding '/tmp/tmphlgqv6nk/src.linux-x86_64-3.8' to include_dirs.copying /data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/f2py/src/fortranobject.c -> /tmp/tmphlgqv6nk/src.linux-x86_64-3.8copying /data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/f2py/src/fortranobject.h -> /tmp/tmphlgqv6nk/src.linux-x86_64-3.8INFO:   adding '/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/test_sub-f2pywrappers.f' to sources.INFO:   adding '/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/test_sub-f2pywrappers2.f90' to sources.INFO: build_src: building npy-pkg config files/data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.  warnings.warn(running build_extINFO: customize UnixCCompilerINFO: customize UnixCCompiler using build_extINFO: get_default_fcompiler: matching types: '['arm', 'gnu95', 'intel', 'lahey', 'pg', 'nv', 'absoft', 'nag', 'vast', 'compaq', 'intele', 'intelem', 'gnu', 'g95', 'pathf95', 'nagfor', 'fujitsu']'INFO: customize ArmFlangCompilerWARN: Could not locate executable armflangINFO: customize Gnu95FCompilerINFO: Found executable /usr/bin/gfortranINFO: customize Gnu95FCompilerINFO: customize Gnu95FCompiler using build_extINFO: building 'test_sub' extensionINFO: compiling C sourcesINFO: C compiler: gcc -pthread -B /data/keeling/a/songning/miniconda3/envs/default/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/keeling/a/songning/miniconda3/envs/default/include -fPIC -O2 -isystem /data/keeling/a/songning/miniconda3/envs/default/include -fPICcreating /tmp/tmphlgqv6nk/tmpcreating /tmp/tmphlgqv6nk/tmp/tmphlgqv6nkcreating /tmp/tmphlgqv6nk/tmp/tmphlgqv6nk/src.linux-x86_64-3.8INFO: compile options: '-DNPY_DISABLE_OPTIMIZATION=1 -I/tmp/tmphlgqv6nk/src.linux-x86_64-3.8 -I/data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/core/include -I/data/keeling/a/songning/miniconda3/envs/default/include/python3.8 -c'INFO: gcc: /tmp/tmphlgqv6nk/src.linux-x86_64-3.8/test_submodule.cINFO: gcc: /tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.cIn file included from /data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948:0,                 from /data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,                 from /data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/core/include/numpy/arrayobject.h:5,                 from /tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.h:13,                 from /tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.c:2:/data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning ""Using deprecated NumPy API, disable it with "" ""#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION"" [-Wcpp] #warning ""Using deprecated NumPy API, disable it with "" \  ^In file included from /data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948:0,                 from /data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/core/include/numpy/ndarrayobject.h:12,                 from /data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/core/include/numpy/arrayobject.h:5,                 from /tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.h:13,                 from /tmp/tmphlgqv6nk/src.linux-x86_64-3.8/test_submodule.c:23:/data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning ""Using deprecated NumPy API, disable it with "" ""#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION"" [-Wcpp] #warning ""Using deprecated NumPy API, disable it with "" \  ^/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/test_submodule.c:144:12: warning: 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨澶愭⒑?py_size闂?defined but not used [-Wunused-function] static int f2py_size(PyArrayObject* var, ...)            ^/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.c: In function 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨澶愭⒑闁偛鑻晶顖涙叏婵犲倹璐＄紒顔藉哺閺屽棗顓奸崱妤€澹勯梻渚€鈧偛鎳忛崕宸乫irst_negative_dimension闂?/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.c:707:5: error: 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨澶愭⒑闁偛鑻晶顖涙叏婵犲倹璐＄紒顔界濞煎繘鍩￠崘褏鐟濆┑鐐存尰閸╁啴宕戦幘瀛樺弿?loop initial declarations are only allowed in C99 mode     for (int i = 0; i < rank; ++i) {     ^/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.c:707:5: note: use option -std=c99 or -std=gnu99 to compile your codeerror: Command ""gcc -pthread -B /data/keeling/a/songning/miniconda3/envs/default/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /data/keeling/a/songning/miniconda3/envs/default/include -fPIC -O2 -isystem /data/keeling/a/songning/miniconda3/envs/default/include -fPIC -DNPY_DISABLE_OPTIMIZATION=1 -I/tmp/tmphlgqv6nk/src.linux-x86_64-3.8 -I/data/keeling/a/songning/miniconda3/envs/default/lib/python3.8/site-packages/numpy/core/include -I/data/keeling/a/songning/miniconda3/envs/default/include/python3.8 -c /tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.c -o /tmp/tmphlgqv6nk/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.o -MMD -MF /tmp/tmphlgqv6nk/tmp/tmphlgqv6nk/src.linux-x86_64-3.8/fortranobject.o.d"" failed with exit status 1```### NumPy/Python version information:1.23.4 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) [GCC 10.3.0]### Context for the issue:_No response_
"
22571,0,0,197,0,0,DanielHabenicht,0,"title:DOC: Mention numpy types in `isnat` error message description:Enhance error message of `isnat` function with proper types instead of previous ambigous message.closes gh-22570<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22570,0,411,197,0,0,DanielHabenicht,0,"title:BUG: Error message for `isnat` is misleading description:### Describe the issue:The Error message for the `isnat` Message is misleading when using normal python types: https://github.com/numpy/numpy/blob/2ad596fc8d015dd3f5ee30bedf068c2c3daf60d2/numpy/core/src/umath/ufunc_type_resolution.c#L653Maybe: `""ufunc 'isnat' is only defined for np.datetime64 and np.timedelta64. You provided: 'timedelta'""`Or even go as far as adding another Error Message if python `datetime` or `timedelta` is provided. Happy to provide a PR!### Reproduce the code example:```pythonimport numpy as npfrom datetime import datetimetest = datetime.fromisoformat(""2022-03-15 00:00:00"")np.isnat(test)```### Error message:```shellTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>TypeError: ufunc 'isnat' is only defined for datetime and timedelta.```### NumPy/Python version information:```bash>>> import sys, numpy; print(numpy.__version__, sys.version)1.23.4 3.8.10 (default, Jun 22 2022, 20:18:18) [GCC 9.4.0]```### Context for the issue:Seems like other people had the same problem before but did not raise it:https://stackoverflow.com/questions/48194470/numpy-isnat-returns-value-error-on-datetime-objectshttps://stackoverflow.com/questions/65358421/ufunc-isnat-is-only-defined-for-datetime-and-timedelta
"
22566,0,0,292,0,1,seberg,0,"title:BUG: Fix use and errorchecking of ObjectType use description:This should be replaced really, it is pretty bad API use, and doesn't work well (up to being incorrect probably).But working on other things (trying to make promotion strict and thus saner), I realized that the use was always wrong: we cannot pass 0 since 0 means `bool`, what was always meant was passing no-type.So fixing this, and adding the error check everywhere.  Checking for `PyErr_Occurred()` may have been necessary at some point, but is not anymore.Closes gh-14247---Wasn't sure its worthwhile to cover the failure path in all of the occurances.  In principle, I don't even _like_ this pattern, but truly fixing this is probably for another day.(I suspect I would need something like a `PyArray_ManyWithSameDescriptorFromAny`)
"
22561,0,0,35,0,0,navpreetnp7,0,"title:BUG: Histogramdd breaks on big arrays in Windows description:Resolved the issue with line change from int to np.intp in numpy/numpy/lib/histograms.pyNew test function was added called test_big_arrays on numpy/lib/tests/test_histograms.py<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->Resolved #22288 Pydata Sprint NYC 2022
"
22557,0,0,5,0,0,aayushagrawal135,0,"title:BUG: Decrement ref count in gentype_reduce if allocated memory not used description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->Resolves #21495Done as part of PyData NYC 2022.
"
22556,0,680,0,0,0,ogliver,0,"title:BUG: Changing element of deepcopy of masked array alters element of original array description:### Describe the issue:Altering an element of a deepcopy of a masked array alters the element of the original array.### Reproduce the code example:```pythonimport copyimport numpy as npsource = np.ma.array( [ 0,[0,1,2] ] ,dtype=object)deepcopy = copy.deepcopy(source)print()print('Before altering deepcopy:')print(f'source:   {source}')print(f'deepcopy: {deepcopy}')deepcopy[1].append('this should not appear in source')print()print('After altering deepcopy:')print(f'source:   {source}')print(f'deepcopy: {deepcopy}')# output:# Before altering deepcopy:# source:   [0 list([0, 1, 2])]# deepcopy: [0 list([0, 1, 2])]# After altering deepcopy:# source:   [0 list([0, 1, 2, 'this should not appear in source'])]# deepcopy: [0 list([0, 1, 2, 'this should not appear in source'])]```### Error message:_No response_### NumPy/Python version information:import sys, numpy; print(numpy.__version__, sys.version)1.23.3 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:50:36) [MSC v.1929 64 bit (AMD64)]### Context for the issue:_No response_
"
22544,0,1986,34,0,0,aschaffer,0,"title:BUG: When quantile output is specified; i.e., `out `is not None` and `keepdims = True` the `out.shape` is wrong. description:### Describe the issue: When output is specified for quantile(); i.e., `out `is not None` and `keepdims = True` the `out.shape` is wrong; it is in fact different than the returned output shape.In the example below, the exception assumes a shape of (5, 6, 2, 4) instead of the expected (5, 6, 2, 1, 4). Which should be the correct one when `keepdims=True闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞尖€愁潖濞差亶鏁嗛柍褜鍓涚划鏃堟偨缁嬭法锛? according to documentation, because then  a dimension of 1闂?is introduced in place of axis along which calculation is done.Moreover:     (1) the same out=q_out_5624闂?works with keepdims闂?both True or False;     (2) the return shape, however, is as expected: (5, 6, 2, 1, 4) for keepdims=True ; (5, 6, 2, 4) for keepdims=False;### Reproduce the code example:```pythonimport numpy as nparr234 = np.array([1,2,2,40,1,1,2,1,0,10,3,3,40,15,3,7,5,4,7,3,5,1,0,9]).reshape(2, 3, 4)qs56 = np.array([x/30.0 for x in range(0, 30)]).reshape(5, 6)out_keepdims = np.quantile(arr234, qs56, axis=1, keepdims=True)out_no_keepdims = np.quantile(arr234, qs56, axis=1, keepdims=False)print(""correct out shape:"", out_keepdims.shape)# correct out shape: (5, 6, 2, 1, 4)print(""incorrect out shape:"", out_no_keepdims.shape)# incorrect out shape: (5, 6, 2, 4)# The incorrect (no keepdims out) succeeds:np.quantile(arr234, qs56, axis=1, out=out_no_keepdims, keepdims=True)# But the correct output fails:np.quantile(arr234, qs56, axis=1, out=out_keepdims, keepdims=True)```### Error message:```shellTraceback (most recent call last):     File ""<stdin>"", line 1, in <module>     File ""<__array_function__ internals>"", line 180, in quantile     File ""~/miniconda3/envs/dev_22_12_11_4_3_8/lib/python3.8/site-packages/numpy/lib/function_base.py"", line 4412, in quantile     return _quantile_unchecked(     File ""~/miniconda3/envs/dev_22_12_11_4_3_8/lib/python3.8/site-packages/numpy/lib/function_base.py"", line 4424, in _quantile_unchecked     r, k = _ureduce(a,     File ""~/miniconda3/envs/dev_22_12_11_4_3_8/lib/python3.8/site-packages/numpy/lib/function_base.py"", line 3725, in _ureduce     r = func(a, **kwargs)     File ""~/miniconda3/envs/dev_22_12_11_4_3_8/lib/python3.8/site-packages/numpy/lib/function_base.py"", line 4593, in _quantile_ureduce_func     result = _quantile(arr,     File ""~/miniconda3/envs/dev_22_12_11_4_3_8/lib/python3.8/site-packages/numpy/lib/function_base.py"", line 4710, in _quantile     result = _lerp(previous,     File ""~/miniconda3/envs/dev_22_12_11_4_3_8/lib/python3.8/site-packages/numpy/lib/function_base.py"", line 4529, in _lerp     lerp_interpolation = asanyarray(add(a, diff_b_a * t, out=out))     ValueError: operands could not be broadcast together with shapes (5,6,2,4) (5,6,2,4) (5,6,2,1,4)```### NumPy/Python version information:>>> import sys, numpy; print(numpy.__version__, sys.version)1.23.3 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) [GCC 10.3.0]### Context for the issue:_No response_
"
22528,1,1699,34,0,0,ikamensh,0,"title:BUG: value of a variable depends on unrelated code description:### Describe the issue:I have a code where value of variable takes unexpected value, and this behaviour disappears if I change unrelated variable from numpy array to an integer. Removing if/else block in a specific location also removes incorrect behavior.See example above, and try uncommenting a print statement on line #47. This changes the behavior of the program. Furthermore, there are few sensitive lines where changes make the bug disappear.This might be CPython bug, but I couldn't reproduce it without numpy so far, so reporting it here.### Reproduce the code example:```pythonimport numpy as npdef step(action):    if action == 0:  # removing this useless if/else makes the bug go away.        return 1    elif action == 1:        return 1class DummyEnvWorker:    """"""Dummy worker used in sequential vector environments.""""""    def __init__(self) -> None:        self._result = None    def step(self, action):        self._result = step(action)        return self.recv()    def reset(self):        self._result = 1        return self.recv()    def recv(        self,    ):        assert self._result is not None, ""must reset environment.""        return self._resultworker = DummyEnvWorker()worker.reset()action = np.ndarray([1])            # replace with `action = 1` and bug disappears.print(worker._result)               # worker._result is 1result = worker.step(action)        # worker._result is None ?!```### Error message:```shellSTDOUT: 1STDERR:Traceback (most recent call last):  File ""/Users/kai7rng/PycharmProjects/py11/main.py"", line 50, in <module>    result = worker.step(action)             ^^^^^^^^^^^^^^^^^^^  File ""/Users/kai7rng/PycharmProjects/py11/main.py"", line 32, in step    return self.recv()           ^^^^^^^^^^^  File ""/Users/kai7rng/PycharmProjects/py11/main.py"", line 41, in recv    assert self._result is not None, ""must reset environment.""AssertionError: must reset environment.```### NumPy/Python version information:Tried in two environments:```>>> import sys, numpy; print(numpy.__version__, sys.version)1.23.4 3.11.0 (v3.11.0:deaf509e8f, Oct 24 2022, 14:43:23) [Clang 13.0.0 (clang-1300.0.29.30)]>>> import sys, numpy; print(numpy.__version__, sys.version)1.23.4 3.8.5 (default, Sep  4 2020, 02:22:02) [Clang 10.0.0 ]```### Context for the issue:I have a simple code where calling .reset() sets `worker._result` to be not None. When calling step(), worker._result must be set. In the example code I indeed correctly reset and then call step. Yet worker._result variable appears to be None; although one line before it was printed as 1.This issue occured in production code, and I have reduced it to minimal example such that removing any more code makes the issue not visible. It's an inconsistent behavior that I'd expect from multithreaded application or such, yet I don't use threads.
"
22507,0,3016,282,0,1,albanD,0,"title:BUG: `array_dlpack_deleter` does not take the GIL before calling into CPython API description:### Describe the issue:For numpy >= 1.23.4, the repro below fails for latest PyTorch.Downgrading numpy to 1.21 for example makes the error go away.It is not clear to me if array_dlpack_deleter should always be called with the GIL already held or not?If so, what should we do if the python interpreter is already dead by the time where we would like to call this deleter?### Reproduce the code example:```pythonimport torchx = torch.zeros(10)data_np = x.detach().cpu().numpy()rev = torch.utils.dlpack.from_dlpack(data_np)```### Error message:```shellFatal Python error: Python memory allocator called without holding the GIL                                           Python runtime state: finalizing (tstate=0x779540)Current thread 0x00007ffff7c75740 (most recent call first):<no Python frame>Thread 1 ""python"" received signal SIGABRT, Aborted.__pthread_kill_implementation (threadid=<optimized out>, signo=signo@entry=6, no_tid=no_tid@entry=0) at pthread_kill.c:44                           (gdb) bt#0  __pthread_kill_implementation (threadid=<optimized out>, signo=signo@entry=6, no_tid=no_tid@entry=0)    at pthread_kill.c:44#1  0x00007ffff7d1b5d3 in __pthread_kill_internal (signo=6, threadid=<optimized out>) at pthread_kill.c:78#2  0x00007ffff7cced16 in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26#3  0x00007ffff7ca27f3 in __GI_abort () at abort.c:79#4  0x00000000005154c1 in fatal_error (prefix=prefix@entry=0x0,     msg=msg@entry=0x6153e8 ""Python memory allocator called without holding the GIL"", status=status@entry=-1)    at Python/pylifecycle.c:2183#5  0x0000000000517f2a in Py_FatalError (    msg=msg@entry=0x6153e8 ""Python memory allocator called without holding the GIL"") at Python/pylifecycle.c:2193#6  0x000000000046c9b5 in _PyMem_DebugCheckGIL () at Objects/obmalloc.c:2295#7  0x000000000046ce85 in _PyMem_DebugFree (ctx=0x72a350 <_PyMem_Debug+48>, ptr=0x7c2f80) at Objects/obmalloc.c:2317#8  0x000000000046dc21 in PyMem_Free (ptr=<optimized out>) at Objects/obmalloc.c:629#9  0x000000000059e090 in _PyFaulthandler_Fini () at ./Modules/faulthandler.c:1413#10 0x00000000005154a9 in fatal_error (prefix=prefix@entry=0x0,     msg=msg@entry=0x6153e8 ""Python memory allocator called without holding the GIL"", status=status@entry=-1)    at Python/pylifecycle.c:2166#11 0x0000000000517f2a in Py_FatalError (    msg=msg@entry=0x6153e8 ""Python memory allocator called without holding the GIL"") at Python/pylifecycle.c:2193#12 0x000000000046c9b5 in _PyMem_DebugCheckGIL () at Objects/obmalloc.c:2295#13 0x000000000046ce85 in _PyMem_DebugFree (ctx=0x72a350 <_PyMem_Debug+48>, ptr=0x7fffea6097b0)    at Objects/obmalloc.c:2317#14 0x000000000046dc21 in PyMem_Free (ptr=<optimized out>) at Objects/obmalloc.c:629#15 0x00007fff41216d4a in array_dlpack_deleter ()   from /home/albandes/local/pytorch/3.8_debug_source_env/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-x86_64-linux-gnu.so#16 0x00007fffe2a6abbc in c10::deleteInefficientStdFunctionContext(void*) ()   from /home/albandes/local/pytorch/3.8_debug_source/torch/lib/libc10.so#17 0x00007fffe97091f6 in c10::StorageImpl::~StorageImpl() ()   from /home/albandes/local/pytorch/3.8_debug_source/torch/lib/libtorch_python.so#18 0x00007fffe2a812f9 in c10::TensorImpl::~TensorImpl() ()   from /home/albandes/local/pytorch/3.8_debug_source/torch/lib/libc10.so```### NumPy/Python version information:1.23.4 3.8.13+ (heads/3.8:69cf0203ab, May 17 2022, 10:58:18) [GCC 11.3.1 20220421 (Red Hat 11.3.1-2)]### Context for the issue:Original report from user: https://github.com/pytorch/pytorch/issues/88082
"
22501,1,172,88,0,0,chinoll,0,"title:BUG: Exit when converting tif images to numpy arrays description:### Describe the issue:I opened a tif image using PIL, and when it was converted to a numpy array, python exited straight away without any error reporting### Reproduce the code example:```pythonfrom PIL import Imageimport numpy as npimg = Image.open(""image.tif"") #image size:500x800,image mode=Limg = np.array(img)```### Error message:```shellNo error message, exit directly```### NumPy/Python version information:1.23.4 3.9.5 (default, May 18 2021, 14:42:02) [MSC v.1916 64 bit (AMD64)]### Context for the issue:_No response_
"
22492,1,356,0,0,0,Corey0606,0,"title:BUG: numpy.arange return wrong result description:### Describe the issue:I found np.arange return incorrect result at step =0.005 it is amazing. error example as following code. thank you for your support### Reproduce the code example:```pythonimport numpy as npresult_len1 = len(np.arange(1250, 1350+0.001, 0.001))result_len2 = len(np.arange(1250, 1350+0.05, 0.05))result_len3 = len(np.arange(1250, 1350+0.005, 0.005))```### Error message:```shellresult_len1 = 100001result_len2 = 2001result_len3 = 20002I found step=0.001 no error. but step=0.005 it is return error result. (1350.005 is error return)```### NumPy/Python version information:latest version also have this errror### Context for the issue:i use np.arrange to create sweep list. this error raise an  expection in my program
"
22478,0,0,292,0,0,seberg,0,"title:BUG: -unsigned_int(0) no overflow warning description:There is no reason `-np.uint8(0)`, etc. should give a warning.Also removes a compile time warning (on clang at least).  The reason for this was checking which integer operations are missing the warnings.It seems the only one is now the `**` operator but adding it there should be a separate PR, and needs a bit of thought.
"
22296,0,0,0,1,1,clearspear,0,"title:BUG: Memory leaks in numpy.nested_iters description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->Bug fix for this issue: https://github.com/numpy/numpy/issues/19400 as part of the Grace Hopper OSD NumPy sprint
"
22288,0,670,1,0,0,scseeman,0,"title:BUG: Histogramdd breaks on big arrays in Windows description:### Describe the issue:numpy.histogramdd fails with large arrays on Windows 10 64-bit. This is likely due to a bizarre behavior on Windows64 where the default integer dtype returns as int32 causing numpy.prod to overflow### Reproduce the code example:```python>>> import numpy as np>>> sample = np.zeros([100000000, 3])>>> xbins = 400>>> ybins = 400>>> zbins = np.arange(16000)>>> hist = np.histogramdd(sample=sample, bins=(xbins, ybins, zbins))```### Error message:```shellTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""<__array_function__ internals>"", line 180, in histogramdd  File ""C:\Users\stephanies\AppData\Local\Continuum\miniconda3\envs\numpy_only\lib\site-packages\numpy\lib\histograms.py"", line 1095, in histogramdd    hist = np.bincount(xy, weights, minlength=nbin.prod())  File ""<__array_function__ internals>"", line 180, in bincountValueError: 'minlength' must not be negative```### NumPy/Python version information:1.23.3 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:29:51) [MSC v.1929 64 bit (AMD64)]### Context for the issue:This is a platform issue preventing the generation of large histograms. The same code above works fine on a linux machine>>> import numpy as np>>> sample = np.zeros([100000000, 3])>>> xbins = 400>>> ybins = 400>>> zbins = np.arange(16000)>>> hist = np.histogramdd(sample=sample, bins=(xbins, ybins, zbins))>>> hist[0].shape(400, 400, 15999)
"
22262,0,874,2,0,0,dchackett,0,"title:BUG: np.dot incorrect for more than 2^30 complex elements description:### Describe the issue:`np.dot` gives the wrong answer when applied to compute dot products of 1d complex arrays with length greater than 2^30 elements. Notes:* Based on CPU usage as observed in `top`, `np.dot` used multiple threads while `(x**2).sum()` used only one. * Error onset always at 2^30+1, for different random seeds. * Difference between results for 2^30 and 2^30+1 is too large to be round-off error iteratively piling up. * Complex dtype is important: error does not occur for float dtype for 2^30+1, 2^31+1, or 2^32+1. * Tested for complex128, have not looked at complex64.* Besides provided example, similarly fails for two different vectors.Running on `Ubuntu 18.04.3 LTS`, reproduced on different machines w/ CPUs `Intel(R) Xeon(R) CPU E5-2680` and `Intel(R) Xeon(R) Gold 5218 CPU`. Probably MKL for multithreaded backend:```>>> np.show_config()blas_mkl_info:    libraries = ['mkl_rt', 'pthread']    library_dirs = # ...    define_macros = [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)]    include_dirs = # ...# ... similar for blas_opt_info, lapack_mkl_info, lapack_opt_info ...```### Reproduce the code example:```pythonimport numpy as npx = np.random.rand(2**30+1) + 1j * np.random.rand(2**30+1)# with 2^30 elementsy = x[:-1]norm_dot = np.dot(y,y)norm_sqsum = (y**2).sum()assert np.isclose(norm_dot.real, norm_sqsum.real) and np.isclose(norm_dot.imag, norm_sqsum.imag) # passes# include one more elementcorrect = norm_dot + x[-1]**2norm_sqsum = (x**2).sum()norm_dot = np.dot(x,x)assert np.isclose(correct.real, norm_sqsum.real) and np.isclose(correct.imag, norm_sqsum.imag) # passesassert np.isclose(norm_dot.real, norm_sqsum.real) and np.isclose(norm_dot.imag, norm_sqsum.imag) # fails```### Error message:_No response_### NumPy/Python version information:1.21.2 3.9.10 | packaged by conda-forge | (main, Feb  1 2022, 21:24:37) [GCC 9.4.0]### Context for the issue:This is a dangerous silent failure.
"
22258,1,923,289,0,0,Micky774,0,"title:BUG: Build fails when trying to set `--cpu-baseline` to anything above `POPCNT` description:### Describe the issue:When trying to build non-standard baseline, the build fails stating that it cannot find certain symbols. Specifically it fails for `SSE42, FMA3__AVX2`.### Reproduce the code example:```pythonThese fail:CFLAGS='--march='native' python runtests.py --buildpython setup.py build -j9 --cpu-baseline='native'python setup.py build -j9 --cpu-baseline='AVX2'python setup.py build -j9 --cpu-baseline='SSE42'This works:python setup.py build -j9 --cpu-baseline='POPCNT'```### Error message:```shell_simd.c:(.text+0x267): undefined reference to `simd_create_module_FMA3__AVX2`/home/micky774/anaconda3/envs/numpy-dev/compiler_compat/ld: _simd.c:(.text+0x30d): undefined reference to `simd_create_module_SSE42`/home/micky774/anaconda3/envs/numpy-dev/compiler_compat/ld: build/lib.linux-x86_64-3.9/numpy/core/_simd.cpython-39-x86_64-linux-gnu.so: hidden symbol `simd_create_module_FMA3__AVX2` isn't defined/home/micky774/anaconda3/envs/numpy-dev/compiler_compat/ld: final link failed: bad valuecollect2: error: ld returned 1 exit status```### NumPy/Python version information:```1.24.0.dev0+787.g62c689c9b 3.9.12 (main, Jun  1 2022, 11:38:51)[GCC 7.5.0]```### Context for the issue:This prevents debugging cpu-baseline related code, e.g. https://github.com/numpy/numpy/pull/22137.
"
22257,1,2512,284,0,1,stumpylog,0,"title:BUG: Possible regression in CPU supported features for aarch64 description:### Describe the issue:While investigating paperless-ngx/paperless-ngx/issues/1364, it was noticed between `numpy==1.22.3` and `numpy==1.23.1`, the supported SIMD extensions reported by `numpy.show_config()` changed, with `1.23.1` not finding the ASIMDFHM feature.The device is a ROCK64, with a Cortex A53, Armv8, which I believe should have all th features implied by ASIMDFHM (basing on [the list here](https://numpy.org/devdocs/reference/simd/build-options.html#on-armv8-a64)).I thought #21749 would fix this, but the issue persists with 1.23.2### Reproduce the code example:```pythonimport numpynumpy.show_config()```### Error message:#### 1.22.3 Config```numpy.show_config()openblas64__info:libraries = ['openblas64_', 'openblas64_']library_dirs = ['/usr/local/lib']language = cdefine_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None)]runtime_library_dirs = ['/usr/local/lib']blas_ilp64_opt_info:libraries = ['openblas64_', 'openblas64_']library_dirs = ['/usr/local/lib']language = cdefine_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None)]runtime_library_dirs = ['/usr/local/lib']openblas64__lapack_info:libraries = ['openblas64_', 'openblas64_']library_dirs = ['/usr/local/lib']language = cdefine_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None), ('HAVE_LAPACKE', None)]runtime_library_dirs = ['/usr/local/lib']lapack_ilp64_opt_info:libraries = ['openblas64_', 'openblas64_']library_dirs = ['/usr/local/lib']language = cdefine_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None), ('HAVE_LAPACKE', None)]runtime_library_dirs = ['/usr/local/lib']Supported SIMD extensions in this NumPy install:baseline = NEON,NEON_FP16,NEON_VFPV4,ASIMDfound =not found = ASIMDHP,ASIMDDP```#### 1.23.1 Config```numpy.show_config()openblas64__info:libraries = ['openblas64_', 'openblas64_']library_dirs = ['/usr/local/lib']language = cdefine_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None)]runtime_library_dirs = ['/usr/local/lib']blas_ilp64_opt_info:libraries = ['openblas64_', 'openblas64_']library_dirs = ['/usr/local/lib']language = cdefine_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None)]runtime_library_dirs = ['/usr/local/lib']openblas64__lapack_info:libraries = ['openblas64_', 'openblas64_']library_dirs = ['/usr/local/lib']language = cdefine_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None), ('HAVE_LAPACKE', None)]runtime_library_dirs = ['/usr/local/lib']lapack_ilp64_opt_info:libraries = ['openblas64_', 'openblas64_']library_dirs = ['/usr/local/lib']language = cdefine_macros = [('HAVE_CBLAS', None), ('BLAS_SYMBOL_SUFFIX', '64_'), ('HAVE_BLAS_ILP64', None), ('HAVE_LAPACKE', None)]runtime_library_dirs = ['/usr/local/lib']Supported SIMD extensions in this NumPy install:baseline = NEON,NEON_FP16,NEON_VFPV4,ASIMDfound =not found = ASIMDHP,ASIMDDP,ASIMDFHM```### NumPy/Python version information:numpy==1.23.1 / numpy==1.23.2### Context for the issue:The training of some classifiers goes from a few minutes, to never completing.
"
22250,0,435,0,0,0,Dominik1123,0,"title:BUG: The error message of `np.concatenate` is missing the word ""except"" when shapes of arrays don't match description:### Describe the issue:The error message for `np.concatenate`, when the shapes of the involved arrays don't match, misses the word ""except"". Currently, the error message reads> all the input array dimensions for the concatenation axis must match exactly, [...]but it should be (and has been [in the past](https://github.com/numpy/numpy/commit/70a15c1740))> all the input array dimensions **except** for the concatenation axis must match exactly, [...]The following code locations are affected:* [`numpy/core/src/multiarray/multiarraymodule.c#L439`](https://github.com/numpy/numpy/blob/71155e9331cd30dbb37732a74fca5f23ab734aa4/numpy/core/src/multiarray/multiarraymodule.c#L439)* [`numpy/core/tests/test_shape_base.py#L263`](https://github.com/numpy/numpy/blob/71155e9331cd30dbb37732a74fca5f23ab734aa4/numpy/core/tests/test_shape_base.py#L263)### Reproduce the code example:```pythonimport numpy as npa = np.zeros((2, 3))b = np.zeros((4, 5))np.concatenate([a, b], axis=0)```### Error message:```shellTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""<__array_function__ internals>"", line 180, in concatenateValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 5```### NumPy/Python version information:1.23.3 3.9.0 (default, Oct 22 2020, 07:15:04) [GCC 7.3.0]### Context for the issue:_No response_
"
22249,1,9,292,0,0,DimitriPapadopoulos,0,"title:BUG: CI: `ubuntu-18.04` runner image is deprecated description:### Describe the issue:This part of CI appears to rely on the `ubuntu-18.04` image label:https://github.com/numpy/numpy/blob/71155e9331cd30dbb37732a74fca5f23ab734aa4/.github/workflows/build_test.yml#L78-L81However, this runner image is deprecated:[The Ubuntu 18.04 Actions runner image will begin deprecation on 8/8/22 and will be fully unsupported by 4/1/2023](https://github.com/actions/runner-images/issues/6002)Alternatives:* `ubuntu-20.04`* `ubuntu-latest` (currently an alias of `ubuntu-20.04`)Ubuntu 20.04 ships with [`g++-7`](https://packages.ubuntu.com/search?keywords=g%2B%2B-7) and [`g++-8`](https://packages.ubuntu.com/search?keywords=g%2B%2B-8) only. As far as I can see, [`g++-6`](https://packages.ubuntu.com/search?keywords=g%2B%2B-6) is available on Ubuntu 18.04 but not on Ubuntu 20.04.### Reproduce the code example:```python-```### Error message:_No response_### NumPy/Python version information:-### Context for the issue:_No response_
"
22241,1,206,77,0,0,zxdawn,0,"title:BUG: `np.arange()` sometimes includes the maximum value description:### Describe the issue:Sometimes the `np.arange()` includes the right value.### Reproduce the code example:```pythonimport numpy as npprint(np.arange(60., 90., 0.04, dtype='float'))print(np.arange(60., 90.04, 0.04, dtype='float'))```### Error message:```shell[60., ......, 89.92, 89.96][60., ......, 89.92, 89.96, 90.  , 90.04]]```### NumPy/Python version information:1.22.4 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:05:37) [Clang 13.0.1 ]### Context for the issue:This will lead to an unexpected array range.
"
22236,0,0,292,0,1,seberg,0,"title:BUG: Fix incorrect refcounting in new `asarray` path description:The new path to preserve dtypes provided by creating a view got the reference counting wrong, because it also hit the incref path that was needed for returning the identity.This fixes up gh-21995Closes gh-22233@charris I keep forgetting how (should note it somewhere :)). Could you retrigger the nightlies, since this seems to affect downstream CI quite annoyingly.
"
22233,0,180,283,0,0,larsoner,0,"title:BUG: Drastic memory usage increase in recent builds description:### Describe the issue:Recently in MNE-Python our CIs started dying due to memory overconsumption on both- Linux: https://github.com/mne-tools/mne-python/runs/8253676336?check_suite_focus=true- Windows: https://dev.azure.com/mne-tools/mne-python/_build/results?buildId=21722&view=logs&j=305851a9-a7bb-55db-0042-7e2b6f48aa1c&t=4d37777d-f36a-53aa-9217-6386d15dddcd&l=2570On my local Linux machine doing the following as a test with `git bisect --first-parent`:```$ mprof run pytest -m ""not ultraslowtest"" mne/tests/ --tb=short --cov=mne --cov-report=xml --cov-report=html -vv && mprof plot```takes ~12GB of memory usage on `main` and also 45357de4cf83340bd05d279673f68a7fd42b2308:![bad_45357de4cf83340bd05d279673f68a7fd42b2308](https://user-images.githubusercontent.com/2365790/189228170-ad1e3d19-aba8-4711-8706-b92e0d9b2f2c.png)but only a much more reasonable ~2.5GB of max memory usage on db550d57ee72e097b50d776cce108c64c80c181b:![good_db550d57ee72e097b50d776cce108c64c80c181b](https://user-images.githubusercontent.com/2365790/189224079-dd532964-1c1d-4bb6-bb2b-75bb63d24ef4.png)So I think this is due to #21995.MNE does use SciPy, Numba, scikit-learn, dipy, etc. that could be interacting with NumPy in some bad way, too. I could at least rule out `numba`, `dipy`, and `scikit-learn` by uninstalling them and seeing the same overconsumption, though (some tests will just be skipped or our library with just use slower code paths this way).I'm happy to work on isolating this further if it's not clear why this might be happening just from having it pinned down to the PR/commit.### Reproduce the code example:```python<not easily reproduced / not yet isolated>```### Error message:_No response_### NumPy/Python version information:See commit numbers above### Context for the issue:_No response_
"
22232,1,2332,0,0,0,tmvannoort,0,"title:BUG: No module named 'numpy.core._multiarray_umath' on Ubuntu mate + Python 3.9.5 description:### Describe the issue:No module named 'numpy.core._multiarray_umath' on Ubuntu mate + python 3.9.5Installed Python: apt-get install python3.9install numpy:  apt-get install python3-numpyoperating system: Ubuntu mate on Odroid c4 /usr/lib$ ls -lrt |grep pythondrwxr-xr-x  3 root root    4096 Nov 22  2018 python3drwxr-xr-x 27 root root   24576 Sep  8 11:29 python2.7drwxr-xr-x 31 root root   20480 Sep  8 17:41 python3.8drwxr-xr-x 30 root root   12288 Sep  8 17:41 python3.9### Reproduce the code example:```pythonPython 3.9.5 (default, Nov 23 2021, 15:27:38) [GCC 9.3.0] on linuxType ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> import numpy as np```### Error message:```shellPython 3.9.5 (default, Nov 23 2021, 15:27:38) [GCC 9.3.0] on linuxType ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> import numpyTraceback (most recent call last):  File ""/usr/lib/python3/dist-packages/numpy/core/__init__.py"", line 17, in <module>    from . import multiarray  File ""/usr/lib/python3/dist-packages/numpy/core/multiarray.py"", line 14, in <module>    from . import overrides  File ""/usr/lib/python3/dist-packages/numpy/core/overrides.py"", line 7, in <module>    from numpy.core._multiarray_umath import (ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""/usr/lib/python3/dist-packages/numpy/__init__.py"", line 142, in <module>    from . import core  File ""/usr/lib/python3/dist-packages/numpy/core/__init__.py"", line 47, in <module>    raise ImportError(msg)ImportError: IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!Importing the numpy c-extensions failed.- Try uninstalling and reinstalling numpy.- If you have already done that, then:  1. Check that you expected to use Python3.9 from ""/usr/bin/python3.9"",     and that you have no directories in your PATH or PYTHONPATH that can     interfere with the Python and numpy version ""1.17.4"" you're trying to use.  2. If (1) looks fine, you can open a new issue at     https://github.com/numpy/numpy/issues.  Please include details on:     - how you installed Python     - how you installed numpy     - your operating system     - whether or not you have multiple versions of Python installed     - if you built from source, your compiler versions and ideally a build log- If you're working with a numpy git repository, try `git clean -xdf`  (removes all files not under version control) and rebuild numpy.Note: this error has many possible causes, so please don't comment onan existing issue about this - open a new one instead.Original error was: No module named 'numpy.core._multiarray_umath'```### NumPy/Python version information:Python 3.9.5 (default, Nov 23 2021, 15:27:38) [GCC 9.3.0] on linuxType ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> import numpyTraceback (most recent call last):  File ""/usr/lib/python3/dist-packages/numpy/core/__init__.py"", line 17, in <module>    from . import multiarray  File ""/usr/lib/python3/dist-packages/numpy/core/multiarray.py"", line 14, in <module>    from . import overrides  File ""/usr/lib/python3/dist-packages/numpy/core/overrides.py"", line 7, in <module>    from numpy.core._multiarray_umath import (ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""/usr/lib/python3/dist-packages/numpy/__init__.py"", line 142, in <module>    from . import core  File ""/usr/lib/python3/dist-packages/numpy/core/__init__.py"", line 47, in <module>    raise ImportError(msg)ImportError: IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!Importing the numpy c-extensions failed.- Try uninstalling and reinstalling numpy.- If you have already done that, then:  1. Check that you expected to use Python3.9 from ""/usr/bin/python3.9"",     and that you have no directories in your PATH or PYTHONPATH that can     interfere with the Python and numpy version ""1.17.4"" you're trying to use.  2. If (1) looks fine, you can open a new issue at     https://github.com/numpy/numpy/issues.  Please include details on:     - how you installed Python     - how you installed numpy     - your operating system     - whether or not you have multiple versions of Python installed     - if you built from source, your compiler versions and ideally a build log- If you're working with a numpy git repository, try `git clean -xdf`  (removes all files not under version control) and rebuild numpy.Note: this error has many possible causes, so please don't comment onan existing issue about this - open a new one instead.Original error was: No module named 'numpy.core._multiarray_umath'### Context for the issue:Trying to make a python script which uses numpy work on Odroid C4 - with Ubuntu mate 
"
22231,1,682,108,0,0,RussiaVk,0,"title:BUG: AttributeError: module 'nt' has no attribute '_add_dll_directory' description:### Describe the issue:numpy cant running on pypy even just import### Reproduce the code example:```pythonimport numpy```### Error message:```shellFile ""C:\Program Files\pypy-c-jit-102746-9515a976b2ea-win64\site-packages\numpy\__init__.py"", line 124, in <module>    from numpy.__config__ import show as show_config  File ""C:\Program Files\pypy-c-jit-102746-9515a976b2ea-win64\site-packages\numpy\__config__.py"", line 12, in <module>    os.add_dll_directory(extra_dll_dir)  File ""C:\Program Files\pypy-c-jit-102746-9515a976b2ea-win64\lib-python\3\os.py"", line 1109, in add_dll_directory    cookie = nt._add_dll_directory(path)AttributeError: module 'nt' has no attribute '_add_dll_directory'```### NumPy/Python version information:numpy  version:`1.23.2`python version:```3.8.10 (9515a976b2ea, Jul 18 2021, 14:53:23)[PyPy 7.3.6-alpha0 with MSC v.1929 64 bit (AMD64)]```### Context for the issue:_No response_
"
22230,0,226,86,1,0,ganesh-k13,0,"title:BUG: Better report integer division overflow (backport) description:Backport of #21507 and #21727.### Handle SIMD division overflowMerge before: https://github.com/numpy/numpy/pull/21507Part of: https://github.com/numpy/numpy/issues/21506Raising this separately to not blow up the original PR on scalars.### Changes:  #21727Before:```py>>> import numpy as np>>> np.array([np.iinfo(np.int32).min]*10, dtype=np.int32) // np.int32(-1)<stdin>:1: RuntimeWarning: divide by zero encountered in floor_dividearray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)```### Changes:  #21507- Handle overflow cases- Testcases for sameRelated: https://github.com/numpy/numpy/issues/21506Finishes: https://github.com/numpy/numpy/pull/19260cc: @seberg @rafaelcfsousa 
"
22224,0,0,275,0,1,charris,0,"title:BUG: Fix the implementation of numpy.array_api.vecdot description:Backport of #21928.* Fix the implementation of numpy.array_api.vecdotSee https://data-apis.org/array-api/latest/API_specification/generated/signatures.linear_algebra_functions.vecdot.html* Use moveaxis + matmul instead of einsum in vecdot<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22223,0,0,275,0,0,charris,0,"title:TST: ensure ``np.equal.reduce`` raises a ``TypeError`` description:Backport of #21981.Closes #20929Added a couple of tests to ensure that np.equal.reduce raises TypeError, and the developers are notified if the API changes.I am not very sure if I should be creating a new method for this test. Please let me know if I can add the tests in any existing method.Thanks!<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22222,0,586,275,1,1,charris,0,"title:TYP,BUG: Reduce argument validation in C-based ``__class_getitem__``  description:Backport of #22212.Closes https://github.com/numpy/numpy/issues/22185The `__class_getitem__` implementations would previously perform basic validation of the passed value, _i.e._ it would check whether a tuple of the appropriate length was passed (_e.g._ `np.dtype.__class_getitem__` would expect a single item or a length-1 tuple). As noted in aforementioned issue: this approach can cause issues when (a. 2 or more parameters are involved and (b. a subclasses is created one or more parameters are declared constant (_e.g._ a fixed dtype & variably shaped array).This PR fixes aforementioned issue by removing any and all runtime argument validation, thus mimicking the behavior of the standard library. While we could alternatively fix this by adding more special casing (_e.g._ only disable validation when `cls is not np.ndarray`), I'm not convinced this would be worth the additional complexity, especially since the standard library also has zero runtime validation for all of its `Py_GenericAlias`-based implementations of `__class_getitem__`.Examples---------The issue prior to this PR:``` pythonIn [1]: import numpy as np   ...: from typing import TypeVar, AnyIn [2]: ShapeType = TypeVar(""ShapeType"")# Variable shaped & fixed dtypeIn [3]: class FooArray(np.ndarray[ShapeType , np.dtype[np.int64]]): ...# Uhoh, __class_getitem__ still expects both a shape and dtype parameterIn [4]: FooArray[Any]---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)Input In [4], in <cell line: 1>()----> 1 FooArray[Any]TypeError: Too few arguments for FooArray```
"
22221,0,0,275,0,1,charris,0,"title:TST,BUG: Use fork context to fix MacOS savez test description:Backport of #22204.Why the test failed * Since Python 3.8, the default start method for multiprocessing has been changed from `fork` to `spawn` on macOS * The default start method is still `fork` on other Unix platforms[1], causing inconsistency on memory sharing model * It will cause a memory-sharing problem for the test `test_large_zip` on macOS as the memory sharing model between `spawn` and `fork` is differentThe fix * Change the start method for this test back to `fork` under this testcase context * In this test case context, [the bug](/python/cpython/issues/77906) that caused default start method changed to `spawn` for macOS will not be triggered * It is context limited, so this change will not affect default start method other than `test_large_zip` * All platforms have the **same memory sharing model** now * After the change, `test_large_zip` is passed on macOS1. https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methodsCloses gh-22203.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22220,0,0,275,0,0,charris,0,"title:BUG: change overloads to play nice with pyright. description:Backport of #22193.It seems Pyright just chooses the first matching type whenever there is ambiguity in type resolution, which leads to a `NoReturn` for `numpy.cross` in certain situations (See #22146.) As far as I can tell, there is no agreed-upon behavior or guidelines for dealing with ambiguity in type resolution, so this is valid behavior on Pyright's side (see microsoft/pyright#2521 for a discussion on this topic.)I suppose the ideal solution would be to resolve the ambiguity, but AFAIK there is no way to do that for constructs like `numpy.array([1, 2, 3])` on the numpy side, short of asking every user to include a dtype in these cases. I would love to be proven wrong though.I think the second best solution is to have the more general overload also be the first one that matches, so that we make as few assumptions as possible about what might happen inside the function when given an `NDArray[Any]`. The other overloads were just changed so that they match the one for `numpy.cross`.I would also consider changing the overload order in functions elsewhere in the library, if it makes sense.I am very open to suggestions if someone has a better idea on how to deal with this.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22215,0,0,275,0,1,charris,0,"title:BUG: Support using libunwind for backtrack description:Backport of #22152.Some system (e.g. musl) do not have ""execinfo.h"", and the backtrackingis provided by libunwind.Fix: #22084<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22214,0,0,275,0,1,charris,0,"title:BUG: Expose heapsort algorithms in a shared header description:Backport of #22024.Fix #22011<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22212,0,586,139,1,1,BvB93,1,"title:TYP,BUG: Reduce argument validation in C-based ``__class_getitem__`` description:Closes https://github.com/numpy/numpy/issues/22185The `__class_getitem__` implementations would previously perform basic validation of the passed value, _i.e._ it would check whether a tuple of the appropriate length was passed (_e.g._ `np.dtype.__class_getitem__` would expect a single item or a length-1 tuple). As noted in aforementioned issue: this approach can cause issues when (a. 2 or more parameters are involved and (b. a subclasses is created one or more parameters are declared constant (_e.g._ a fixed dtype & variably shaped array).This PR fixes aforementioned issue by removing any and all runtime argument validation, thus mimicking the behavior of the standard library. While we could alternatively fix this by adding more special casing (_e.g._ only disable validation when `cls is not np.ndarray`), I'm not convinced this would be worth the additional complexity, especially since the standard library also has zero runtime validation for all of its `Py_GenericAlias`-based implementations of `__class_getitem__`.Examples---------The issue prior to this PR:``` pythonIn [1]: import numpy as np   ...: from typing import TypeVar, AnyIn [2]: ShapeType = TypeVar(""ShapeType"")# Variable shaped & fixed dtypeIn [3]: class FooArray(np.ndarray[ShapeType , np.dtype[np.int64]]): ...# Uhoh, __class_getitem__ still expects both a shape and dtype parameterIn [4]: FooArray[Any]---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)Input In [4], in <cell line: 1>()----> 1 FooArray[Any]TypeError: Too few arguments for FooArray```
"
22209,1,219,263,0,0,phofl,0,"title:BUG: RuntimeWarning inconsistent between uint16 and uint32 description:### Describe the issue:Having negative floats when casting to ``uint32`` raises a ``RuntimeWarning`` but ``uint16`` silently overflows. This occurred in the pandas test suite### Reproduce the code example:```pythonx = np.array([-2.9792401]).astype(""uint32"")[0]x = np.array([-2.9792401]).astype(""uint16"")[65534]```### Error message:```shellRuntimeWarning: invalid value encountered in cast  x = np.array([-2.9792401]).astype(""uint32"")```### NumPy/Python version information:1.24.0.dev0+703.gb2fbc4349 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:14) [Clang 12.0.1 ]### Context for the issue:I am not sure if there is something I am missing, but I think both should show the warning?
"
22208,1,324,144,0,0,shenmishajing,0,"title:BUG: np.sum get wrong result when use float16 description:### Describe the issue:when set dtype == np.float16 of np.array, we can get wrong result from np.sum, np.dot etc.When we run code like follows, we get<img width=""256"" alt=""闂傚倸鍊搁崐鎼佸磹瀹勬噴褰掑炊椤掑﹦绋忔繝銏ｅ煐閸旀洜绮诲鑸靛€堕柣鎰絻閳锋梹銇勯埡浣哥骇缂佺粯绻冪换婵嬪磼濠婂喚鏉搁梻?022-09-06 16 31 34"" src=""https://user-images.githubusercontent.com/32559715/188587073-c9023151-aae9-4129-b5d4-84c5ccc807ca.png"">it works when n<=2040, but something goes wrong when n equals to 2050, after n grows bigger than 2100, it looks like the 1 of array is ignored.### Reproduce the code example:```pythonimport numpy as np    for n in [10, 100, 1000, 2000, 2040] + list(range(2050, 2100, 10)) + [2100, 2500, 3000, 5000, 10000]:        data = [0 for i in range(n)]        data[0] = 1        data = np.array(data, dtype = np.float16)        print(n, np.sum(data), np.sum(1 - data), np.sum(data + (1 - data)))```### NumPy/Python version information:1.22.4 3.9.12 (main, Jun  1 2022, 11:38:51) [GCC 7.5.0]### Context for the issue:_No response_
"
22207,1,323,7,0,0,pokecheater,0,"title:BUG: <isinstance does not work properly on nested numpy arrays.> description:### Describe the issue:Hey Numpy-Team,just as the description tells you, here is some code to reproduce.Thanks in advance and for this awesome library <3Greetz### Reproduce the code example:```pythonimport numpy as nptest = np.float32(1)print(test.dtype)print(isinstance(test, np.floating)) # will eval to Truetest = np.float32([[1]])print(test.dtype)print(isinstance(test, np.floating)) # will eval to False# but dtype is in both cases float32 so my expectation is that both should eval to True.```### Error message:_No response_### NumPy/Python version information:1.22.4MacOSX M1Python 3.8.9### Context for the issue:_No response_
"
22204,0,0,54,0,1,vxst,0,"title:TST,BUG: Use fork context to fix MacOS savez test description:Why the test failed * Since Python 3.8, the default start method for multiprocessing has been changed from `fork` to `spawn` on macOS * The default start method is still `fork` on other Unix platforms[1], causing inconsistency on memory sharing model * It will cause a memory-sharing problem for the test `test_large_zip` on macOS as the memory sharing model between `spawn` and `fork` is differentThe fix * Change the start method for this test back to `fork` under this testcase context * In this test case context, [the bug](/python/cpython/issues/77906) that caused default start method changed to `spawn` for macOS will not be triggered * It is context limited, so this change will not affect default start method other than `test_large_zip` * All platforms have the **same memory sharing model** now * After the change, `test_large_zip` is passed on macOS1. https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods
"
22203,0,5563,54,0,0,vxst,0,"title:BUG: Test failed in macOS Monterey due to a bug in default multiprocessing module description:### Describe the issue:In a full test,(numpy.test('full')), using pthread model(the default) with Darwin kernel:lib/tests/test_io.py::TestSaveTxt::test_large_zip test is FAILED due to an AttributeError.```FAILED  - AttributeError: Can't pickle local object 'TestSaveTxt.test_large_zip.<locals>.check_large_zip'```The failed function is:```    def dump(obj, file, protocol=None):        '''Replacement for pickle.dump() using ForkingPickler.'''>       ForkingPickler(file, protocol).dump(obj)E       AttributeError: Can't pickle local object 'TestSaveTxt.test_large_zip.<locals>.check_large_zip'file       = <_io.BytesIO object at 0x16fc39ae0>obj        = <Process name='Process-1' parent=1569 initial>protocol   = None/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/reduction.py:60: AttributeError```The stack trace at multiprocessing is```/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py:121: in start    self._popen = self._Popen(self)        self       = <Process name='Process-1' parent=1569 initial>/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py:224: in _Popen    return _default_context.get_context().Process._Popen(process_obj)        process_obj = <Process name='Process-1' parent=1569 initial>/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py:284: in _Popen    return Popen(process_obj)        Popen      = <class 'multiprocessing.popen_spawn_posix.Popen'>        process_obj = <Process name='Process-1' parent=1569 initial>/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py:32: in __init__    super().__init__(process_obj)        __class__  = <class 'multiprocessing.popen_spawn_posix.Popen'>        process_obj = <Process name='Process-1' parent=1569 initial>        self       = <multiprocessing.popen_spawn_posix.Popen object at 0x16fbbb070>/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_fork.py:19: in __init__    self._launch(process_obj)        process_obj = <Process name='Process-1' parent=1569 initial>        self       = <multiprocessing.popen_spawn_posix.Popen object at 0x16fbbb070>/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py:47: in _launch    reduction.dump(process_obj, fp)        fp         = <_io.BytesIO object at 0x16fc39ae0>        prep_data  = {'authkey': b'\xe7\xf6K\x8ceo\xe6se\x82\x11#q\xa9\xde\x19SX\x917\xf0M\x07\xa9-\xfd\x15\xa8~\xc5\x98\x14', 'dir': '/Use...s', 'init_main_from_path': '/Users/vxst/vxst_env_verified/py39_sci_test/tests/0_numpy.py', 'log_to_stderr': False, ...}        process_obj = <Process name='Process-1' parent=1569 initial>        resource_tracker = <module 'multiprocessing.resource_tracker' from '/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/resource_tracker.py'>        self       = <multiprocessing.popen_spawn_posix.Popen object at 0x16fbbb070>        tracker_fd = 19```Test hardwares include M1 Max with 32 core GPU and 64GB memory and M1 with 16GB memory.Test python version include cpython 3.8 and cpython 3.9.Four configurations all fail in the same manner.### Reproduce the code example:```pythonpy.test numpy/lib/tests/test_io.py```### Error message:```shell../../../Library/Python/3.9/lib/python/site-packages/numpy/lib/tests/test_io.py:598:_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py:121: in start    self._popen = self._Popen(self)/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py:224: in _Popen    return _default_context.get_context().Process._Popen(process_obj)/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py:284: in _Popen    return Popen(process_obj)/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py:32: in __init__    super().__init__(process_obj)/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_fork.py:19: in __init__    self._launch(process_obj)/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py:47: in _launch    reduction.dump(process_obj, fp)_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _obj = <Process name='Process-1' parent=38364 initial>, file = <_io.BytesIO object at 0x1055a08b0>, protocol = None    def dump(obj, file, protocol=None):        '''Replacement for pickle.dump() using ForkingPickler.'''>       ForkingPickler(file, protocol).dump(obj)E       AttributeError: Can't pickle local object 'TestSaveTxt.test_large_zip.<locals>.check_large_zip'/opt/homebrew/Cellar/python@3.9/3.9.13_4/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/reduction.py:60: AttributeError```### NumPy/Python version information:1.21.6 at both Python 3.8 and Python 3.9 environments, built by homebrew.```1.21.6 3.9.13 (main, Aug 28 2022, 18:56:22)[Clang 13.1.6 (clang-1316.0.21.2.5)]```and```1.21.6 3.8.13 (default, Aug 28 2022, 18:53:35)[Clang 13.1.6 (clang-1316.0.21.2.5)]```The system uname is:```Darwin Mac 21.6.0 Darwin Kernel Version 21.6.0: Wed Aug 10 14:28:23 PDT 2022; root:xnu-8020.141.5~2/RELEASE_ARM64_T6000 arm64 arm Darwin```### Context for the issue:It cause numpy.test('full') to fail on macOS.
"
22201,1,19813,125,0,1,Volker-Weissmann,0,"title:BUG: Installation failed, when installed as dependency of pythonfuzz description:### Describe the issue:I'm not sure if this is an issue with numpy or pythonfuzz.`pip install numpy` works fine, but `pip install pythonfuzz` fails with> error: Command ""gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -march=x86-64 -mtune=generic -O3 -pipe -fno-plt -fexceptions -Wp,-D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fstack-clash-protection -fcf-protection -g -ffile-prefix-map=/build/python/src=/usr/src/debug -flto=auto -ffat-lto-objects -march=x86-64 -mtune=generic -O3 -pipe -fno-plt -fexceptions -Wp,-D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fstack-clash-protection -fcf-protection -g -ffile-prefix-map=/build/python/src=/usr/src/debug -flto=auto -march=x86-64 -mtune=generic -O3 -pipe -fno-plt -fexceptions -Wp,-D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fstack-clash-protection -fcf-protection -g -ffile-prefix-map=/build/python/src=/usr/src/debug -flto=auto -fPIC -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DSCIPY_MKL_H -DHAVE_CBLAS -I/opt/intel/oneapi/mkl/latest -I/opt/intel/oneapi/mkl/latest/include -I/opt/intel/oneapi/mkl/latest/lib -Ibuild/src.linux-x86_64-3.1/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.1/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.1/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.1/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/usr/include/python3.10 -Ibuild/src.linux-x86_64-3.1/numpy/core/src/common -Ibuild/src.linux-x86_64-3.1/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.1/numpy/core/src/common -Ibuild/src.linux-x86_64-3.1/numpy/core/src/npymath -c build/src.linux-x86_64-3.1/numpy/core/src/multiarray/scalartypes.c -o build/temp.linux-x86_64-cpython-310/build/src.linux-x86_64-3.1/numpy/core/src/multiarray/scalartypes.o -MMD -MF build/temp.linux-x86_64-cpython-310/build/src.linux-x86_64-3.1/numpy/core/src/multiarray/scalartypes.o.d"" failed with exit status 1### Reproduce the code example:```pythonpip install pythonfuzz```### Error message:```shellbuilding 'numpy.core._multiarray_umath' extension      compiling C sources      C compiler: gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -march=x86-64 -mtune=generic -O3 -pipe -fno-plt -fexceptions -Wp,-D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fstack-clash-protection -fcf-protection -g -ffile-prefix-map=/build/python/src=/usr/src/debug -flto=auto -ffat-lto-objects -march=x86-64 -mtune=generic -O3 -pipe -fno-plt -fexceptions -Wp,-D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fstack-clash-protection -fcf-protection -g -ffile-prefix-map=/build/python/src=/usr/src/debug -flto=auto -march=x86-64 -mtune=generic -O3 -pipe -fno-plt -fexceptions -Wp,-D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fstack-clash-protection -fcf-protection -g -ffile-prefix-map=/build/python/src=/usr/src/debug -flto=auto -fPIC            compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DSCIPY_MKL_H -DHAVE_CBLAS -I/opt/intel/oneapi/mkl/latest -I/opt/intel/oneapi/mkl/latest/include -I/opt/intel/oneapi/mkl/latest/lib -Ibuild/src.linux-x86_64-3.1/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.1/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.1/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.1/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/usr/include/python3.10 -Ibuild/src.linux-x86_64-3.1/numpy/core/src/common -Ibuild/src.linux-x86_64-3.1/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.1/numpy/core/src/common -Ibuild/src.linux-x86_64-3.1/numpy/core/src/npymath -c'      gcc: build/src.linux-x86_64-3.1/numpy/core/src/multiarray/scalartypes.c      numpy/core/src/multiarray/scalartypes.c.src: In function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻銈夋偂鎼粹槅鏆㈡繛瀛樼矌缁岀牫codetype_repr闂?      numpy/core/src/multiarray/scalartypes.c.src:475:5: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€ら幗鐥燾ode_AsUnicode闂?is deprecated [-Wdeprecated-declarations]        475 |     ip = dptr = Py@Name@_AS_@NAME@(self);            |     ^~      In file included from /usr/include/python3.10/unicodeobject.h:1046,                       from /usr/include/python3.10/Python.h:83,                       from numpy/core/src/multiarray/scalartypes.c.src:3:      /usr/include/python3.10/cpython/unicodeobject.h:580:45: note: declared here        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(            |                                             ^~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€荤紒璺衡€漜ode_get_wstr_length闂?is deprecated [-Wdeprecated-declarations]        476 |     len = Py@Name@_GET_SIZE(self);            |     ^~~      /usr/include/python3.10/cpython/unicodeobject.h:446:26: note: declared here        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€ら幗鐥燾ode_AsUnicode闂?is deprecated [-Wdeprecated-declarations]        476 |     len = Py@Name@_GET_SIZE(self);            |     ^~~      /usr/include/python3.10/cpython/unicodeobject.h:580:45: note: declared here        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(            |                                             ^~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€荤紒璺衡€漜ode_get_wstr_length闂?is deprecated [-Wdeprecated-declarations]        476 |     len = Py@Name@_GET_SIZE(self);            |     ^~~      /usr/include/python3.10/cpython/unicodeobject.h:446:26: note: declared here        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:481:5: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€ら幗鐥燾ode_FromUnicode闂?is deprecated [-Wdeprecated-declarations]        481 |     new = Py@Name@_From@Name@@extra@(ip, len);            |     ^~~      /usr/include/python3.10/cpython/unicodeobject.h:551:42: note: declared here        551 | Py_DEPRECATED(3.3) PyAPI_FUNC(PyObject*) PyUnicode_FromUnicode(            |                                          ^~~~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src: In function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻銈夋偂鎼粹槅鏆㈡繛瀛樼矌缁岀牫codetype_str闂?      numpy/core/src/multiarray/scalartypes.c.src:475:5: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€ら幗鐥燾ode_AsUnicode闂?is deprecated [-Wdeprecated-declarations]        475 |     ip = dptr = Py@Name@_AS_@NAME@(self);            |     ^~      /usr/include/python3.10/cpython/unicodeobject.h:580:45: note: declared here        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(            |                                             ^~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€荤紒璺衡€漜ode_get_wstr_length闂?is deprecated [-Wdeprecated-declarations]        476 |     len = Py@Name@_GET_SIZE(self);            |     ^~~      /usr/include/python3.10/cpython/unicodeobject.h:446:26: note: declared here        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€ら幗鐥燾ode_AsUnicode闂?is deprecated [-Wdeprecated-declarations]        476 |     len = Py@Name@_GET_SIZE(self);            |     ^~~      /usr/include/python3.10/cpython/unicodeobject.h:580:45: note: declared here        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(            |                                             ^~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:476:5: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€荤紒璺衡€漜ode_get_wstr_length闂?is deprecated [-Wdeprecated-declarations]        476 |     len = Py@Name@_GET_SIZE(self);            |     ^~~      /usr/include/python3.10/cpython/unicodeobject.h:446:26: note: declared here        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:481:5: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€ら幗鐥燾ode_FromUnicode闂?is deprecated [-Wdeprecated-declarations]        481 |     new = Py@Name@_From@Name@@extra@(ip, len);            |     ^~~      /usr/include/python3.10/cpython/unicodeobject.h:551:42: note: declared here        551 | Py_DEPRECATED(3.3) PyAPI_FUNC(PyObject*) PyUnicode_FromUnicode(            |                                          ^~~~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src: In function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮夐梺閫炲苯澧俊顐㈠暙閻ｇ兘骞樼€癸负鍔庢竟鏇烆潡缁夋攨_reduce闂?      numpy/core/src/multiarray/scalartypes.c.src:1849:9: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€ら幗鐥燾ode_AsUnicode闂?is deprecated [-Wdeprecated-declarations]       1849 |         buffer = PyUnicode_AS_DATA(self);            |         ^~~~~~      /usr/include/python3.10/cpython/unicodeobject.h:580:45: note: declared here        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(            |                                             ^~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:1850:9: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€荤紒璺衡€漜ode_get_wstr_length闂?is deprecated [-Wdeprecated-declarations]       1850 |         buflen = PyUnicode_GET_DATA_SIZE(self);            |         ^~~~~~      /usr/include/python3.10/cpython/unicodeobject.h:446:26: note: declared here        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:1850:9: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€ら幗鐥燾ode_AsUnicode闂?is deprecated [-Wdeprecated-declarations]       1850 |         buflen = PyUnicode_GET_DATA_SIZE(self);            |         ^~~~~~      /usr/include/python3.10/cpython/unicodeobject.h:580:45: note: declared here        580 | Py_DEPRECATED(3.3) PyAPI_FUNC(Py_UNICODE *) PyUnicode_AsUnicode(            |                                             ^~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:1850:9: warning: 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€荤紒璺衡€漜ode_get_wstr_length闂?is deprecated [-Wdeprecated-declarations]       1850 |         buflen = PyUnicode_GET_DATA_SIZE(self);            |         ^~~~~~      /usr/include/python3.10/cpython/unicodeobject.h:446:26: note: declared here        446 | static inline Py_ssize_t _PyUnicode_get_wstr_length(PyObject *op) {            |                          ^~~~~~~~~~~~~~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src: In function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮夐梺閫炲苯澧慨濠傛贡缁碍娼忛埡鍐劸闂佹悶鍨婚惃鐚抋rrtype_hash闂?      numpy/core/src/multiarray/scalartypes.c.src:3311:27: error: incompatible type for argument 1 of 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3311 |     return _Py_HashDouble((double) ((Py@name@ScalarObject *)obj)->obval);            |                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~            |                           |            |                           double      In file included from /usr/include/python3.10/Python.h:77:      /usr/include/python3.10/pyhash.h:10:38: note: expected 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€栭悺鐞積ct *闂?{aka 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻銈夋偂鎼粹槅鏆㈡繛瀛樼矌绾剧尯uct _object *闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮堕梺?but argument is of type 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姇閳诲酣濮€閳ヨ尙绠氬┑顔藉笚濞兼紴闂?        10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                                      ^~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:3311:12: error: too few arguments to function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3311 |     return _Py_HashDouble((double) ((Py@name@ScalarObject *)obj)->obval);            |            ^~~~~~~~~~~~~~      /usr/include/python3.10/pyhash.h:10:23: note: declared here         10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                       ^~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src: In function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姍瀹曠娀寮介銈囩劸闂佺绉跺敮t_arrtype_hash闂?      numpy/core/src/multiarray/scalartypes.c.src:3319:31: error: incompatible type for argument 1 of 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3319 |     hashreal = _Py_HashDouble((double)            |                               ^~~~~~~~            |                               |            |                               double       3320 |             (((PyC@name@ScalarObject *)obj)->obval).real);            |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~      /usr/include/python3.10/pyhash.h:10:38: note: expected 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€栭悺鐞積ct *闂?{aka 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻銈夋偂鎼粹槅鏆㈡繛瀛樼矌绾剧尯uct _object *闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮堕梺?but argument is of type 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姇閳诲酣濮€閳ヨ尙绠氬┑顔藉笚濞兼紴闂?        10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                                      ^~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:3319:16: error: too few arguments to function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3319 |     hashreal = _Py_HashDouble((double)            |                ^~~~~~~~~~~~~~      /usr/include/python3.10/pyhash.h:10:23: note: declared here         10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                       ^~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:3325:31: error: incompatible type for argument 1 of 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3325 |     hashimag = _Py_HashDouble((double)            |                               ^~~~~~~~            |                               |            |                               double       3326 |             (((PyC@name@ScalarObject *)obj)->obval).imag);            |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~      /usr/include/python3.10/pyhash.h:10:38: note: expected 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€栭悺鐞積ct *闂?{aka 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻銈夋偂鎼粹槅鏆㈡繛瀛樼矌绾剧尯uct _object *闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮堕梺?but argument is of type 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姇閳诲酣濮€閳ヨ尙绠氬┑顔藉笚濞兼紴闂?        10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                                      ^~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:3325:16: error: too few arguments to function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3325 |     hashimag = _Py_HashDouble((double)            |                ^~~~~~~~~~~~~~      /usr/include/python3.10/pyhash.h:10:23: note: declared here         10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                       ^~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src: In function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻銈夋偂鎼粹槅鏆㈡繛瀛樼矋椤ゅ崿gdouble_arrtype_hash闂?      numpy/core/src/multiarray/scalartypes.c.src:3311:27: error: incompatible type for argument 1 of 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3311 |     return _Py_HashDouble((double) ((Py@name@ScalarObject *)obj)->obval);            |                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~            |                           |            |                           double      /usr/include/python3.10/pyhash.h:10:38: note: expected 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€栭悺鐞積ct *闂?{aka 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻銈夋偂鎼粹槅鏆㈡繛瀛樼矌绾剧尯uct _object *闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮堕梺?but argument is of type 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姇閳诲酣濮€閳ヨ尙绠氬┑顔藉笚濞兼紴闂?        10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                                      ^~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:3311:12: error: too few arguments to function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3311 |     return _Py_HashDouble((double) ((Py@name@ScalarObject *)obj)->obval);            |            ^~~~~~~~~~~~~~      /usr/include/python3.10/pyhash.h:10:23: note: declared here         10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                       ^~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src: In function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姍瀹曠娀寮介銏㈢瓘濡炪倐鏅滈弨鐚無uble_arrtype_hash闂?      numpy/core/src/multiarray/scalartypes.c.src:3319:31: error: incompatible type for argument 1 of 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3319 |     hashreal = _Py_HashDouble((double)            |                               ^~~~~~~~            |                               |            |                               double       3320 |             (((PyC@name@ScalarObject *)obj)->obval).real);            |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~      /usr/include/python3.10/pyhash.h:10:38: note: expected 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€栭悺鐞積ct *闂?{aka 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻銈夋偂鎼粹槅鏆㈡繛瀛樼矌绾剧尯uct _object *闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮堕梺?but argument is of type 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姇閳诲酣濮€閳ヨ尙绠氬┑顔藉笚濞兼紴闂?        10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                                      ^~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:3319:16: error: too few arguments to function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3319 |     hashreal = _Py_HashDouble((double)            |                ^~~~~~~~~~~~~~      /usr/include/python3.10/pyhash.h:10:23: note: declared here         10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                       ^~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:3325:31: error: incompatible type for argument 1 of 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3325 |     hashimag = _Py_HashDouble((double)            |                               ^~~~~~~~            |                               |            |                               double       3326 |             (((PyC@name@ScalarObject *)obj)->obval).imag);            |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~      /usr/include/python3.10/pyhash.h:10:38: note: expected 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€栭悺鐞積ct *闂?{aka 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻銈夋偂鎼粹槅鏆㈡繛瀛樼矌绾剧尯uct _object *闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮堕梺?but argument is of type 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姇閳诲酣濮€閳ヨ尙绠氬┑顔藉笚濞兼紴闂?        10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                                      ^~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:3325:16: error: too few arguments to function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3325 |     hashimag = _Py_HashDouble((double)            |                ^~~~~~~~~~~~~~      /usr/include/python3.10/pyhash.h:10:23: note: declared here         10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                       ^~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src: In function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮夐梺閫炲苯澧俊顐㈠暙閻ｅ嘲顫濋懜闈涒偓鍧楁煟鎼达紕鈹哸rrtype_hash闂?      numpy/core/src/multiarray/scalartypes.c.src:3341:27: error: incompatible type for argument 1 of 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3341 |     return _Py_HashDouble(npy_half_to_double(((PyHalfScalarObject *)obj)->obval));            |                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~            |                           |            |                           double      /usr/include/python3.10/pyhash.h:10:38: note: expected 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮庨柛銉ヮ嚟缁辨挻鎷呴崜鍙壭ㄩ梺鎼炲€栭悺鐞積ct *闂?{aka 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻銈夋偂鎼粹槅鏆㈡繛瀛樼矌绾剧尯uct _object *闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮堕梺?but argument is of type 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姇閳诲酣濮€閳ヨ尙绠氬┑顔藉笚濞兼紴闂?        10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                                      ^~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src:3341:12: error: too few arguments to function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮岄梺閫炲苯澧柟铏姉閸掓帞鈧綆鍟熼崶顒佸€块柛锔界摣shDouble闂?      3341 |     return _Py_HashDouble(npy_half_to_double(((PyHalfScalarObject *)obj)->obval));            |            ^~~~~~~~~~~~~~      /usr/include/python3.10/pyhash.h:10:23: note: declared here         10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);            |                       ^~~~~~~~~~~~~~      numpy/core/src/multiarray/scalartypes.c.src: In function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻銈夋偂鎼粹槅鏆㈡繛瀛樼矋椤ゅ崿gdouble_arrtype_hash闂?      numpy/core/src/multiarray/scalartypes.c.src:3312:1: warning: control reaches end of non-void function [-Wreturn-type]       3312 | }            | ^      numpy/core/src/multiarray/scalartypes.c.src: In function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮夐梺閫炲苯澧慨濠傛贡缁碍娼忛埡鍐劸闂佹悶鍨婚惃鐚抋rrtype_hash闂?      numpy/core/src/multiarray/scalartypes.c.src:3312:1: warning: control reaches end of non-void function [-Wreturn-type]       3312 | }            | ^      numpy/core/src/multiarray/scalartypes.c.src: In function 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻锛勪沪鐠囨彃濮夐梺閫炲苯澧俊顐㈠暙閻ｅ嘲顫濋懜闈涒偓鍧楁煟鎼达紕鈹哸rrtype_hash闂?      numpy/core/src/multiarray/scalartypes.c.src:3342:1: warning: control reaches end of non-void function [-Wreturn-type]       3342 | }            | ^      error: Command ""gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -march=x86-64 -mtune=generic -O3 -pipe -fno-plt -fexceptions -Wp,-D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fstack-clash-protection -fcf-protection -g -ffile-prefix-map=/build/python/src=/usr/src/debug -flto=auto -ffat-lto-objects -march=x86-64 -mtune=generic -O3 -pipe -fno-plt -fexceptions -Wp,-D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fstack-clash-protection -fcf-protection -g -ffile-prefix-map=/build/python/src=/usr/src/debug -flto=auto -march=x86-64 -mtune=generic -O3 -pipe -fno-plt -fexceptions -Wp,-D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fstack-clash-protection -fcf-protection -g -ffile-prefix-map=/build/python/src=/usr/src/debug -flto=auto -fPIC -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DSCIPY_MKL_H -DHAVE_CBLAS -I/opt/intel/oneapi/mkl/latest -I/opt/intel/oneapi/mkl/latest/include -I/opt/intel/oneapi/mkl/latest/lib -Ibuild/src.linux-x86_64-3.1/numpy/core/src/umath -Ibuild/src.linux-x86_64-3.1/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.1/numpy/core/src/common -Inumpy/core/include -Ibuild/src.linux-x86_64-3.1/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/usr/include/python3.10 -Ibuild/src.linux-x86_64-3.1/numpy/core/src/common -Ibuild/src.linux-x86_64-3.1/numpy/core/src/npymath -Ibuild/src.linux-x86_64-3.1/numpy/core/src/common -Ibuild/src.linux-x86_64-3.1/numpy/core/src/npymath -c build/src.linux-x86_64-3.1/numpy/core/src/multiarray/scalartypes.c -o build/temp.linux-x86_64-cpython-310/build/src.linux-x86_64-3.1/numpy/core/src/multiarray/scalartypes.o -MMD -MF build/temp.linux-x86_64-cpython-310/build/src.linux-x86_64-3.1/numpy/core/src/multiarray/scalartypes.o.d"" failed with exit status 1      [end of output]```### NumPy/Python version information:1.23.2 3.10.6 (main, Aug  3 2022, 17:39:45) [GCC 12.1.1 20220730]$ gcc --version                                                                        gcc (GCC) 12.2.0Copyright (C) 2022 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.### Context for the issue:_No response_
"
22200,1,4601,126,0,0,rubyFeedback,0,"title:BUG: Numpy can't find c++ compiler description:### Describe the issue:Somehow numpy complains about my g++ compiler not working. This is not a true statementfrom numpy - I compile everything from source and it all works.I suggest that numpy either changes its internal behaviour, or does not claim that my gcc/g++compiler do not work. They both work, so there must be another issue that numpy either doesnot see or swallows.```    /usr/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.  warnings.warn(running buildrunning config_ccINFO: unifing config_cc, config, build_clib, build_ext, build commands --compiler optionsrunning config_fcINFO: unifing config_fc, config, build_clib, build_ext, build commands --fcompiler optionsrunning build_srcINFO: build_srcINFO: building py_modules sourcesINFO: building library ""npymath"" sourcesWARN: Could not locate executable armflang/home/Temp/rbt/numpy-1.23.2/numpy/distutils/fcompiler/gnu.py:276: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.  if LooseVersion(v) >= ""4"":/usr/lib/python3.10/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated.     Use packaging.version instead.  other = LooseVersion(other)/home/Temp/rbt/numpy-1.23.2/numpy/distutils/ccompiler.py:662: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.  version = LooseVersion(version)c++: warning: gcc: linker input file unused because linking not donec++: error: gcc: linker input file not found: No such file or directoryTraceback (most recent call last):  File ""/home/Temp/rbt/numpy-1.23.2/setup.py"", line 493, in <module>    setup_package()  File ""/home/Temp/rbt/numpy-1.23.2/setup.py"", line 485, in setup_package    setup(**metadata)  File ""/home/Temp/rbt/numpy-1.23.2/numpy/distutils/core.py"", line 169, in setup    return old_setup(**new_attr)  File ""/usr/lib/python3.10/site-packages/setuptools/__init__.py"", line 87, in setup    return distutils.core.setup(**attrs)  File ""/usr/lib/python3.10/site-packages/setuptools/_distutils/core.py"", line 177, in setup    return run_commands(dist)  File ""/usr/lib/python3.10/site-packages/setuptools/_distutils/core.py"", line 193, in run_commands    dist.run_commands()  File ""/usr/lib/python3.10/site-packages/setuptools/_distutils/dist.py"", line 968, in run_commands    self.run_command(cmd)  File ""/usr/lib/python3.10/site-packages/setuptools/dist.py"", line 1217, in run_command        super().run_command(command)  File ""/usr/lib/python3.10/site-packages/setuptools/_distutils/dist.py"", line 987, in run_command    cmd_obj.run()  File ""/home/Temp/rbt/numpy-1.23.2/numpy/distutils/command/install.py"", line 60, in run    r = self.setuptools_run()  File ""/home/Temp/rbt/numpy-1.23.2/numpy/distutils/command/install.py"", line 52, in setuptools_run    distutils_install.run(self)  File ""/usr/lib/python3.10/site-packages/setuptools/_distutils/command/install.py"", line 695, in run    self.run_command('build')  File ""/usr/lib/python3.10/site-packages/setuptools/_distutils/cmd.py"", line 317, in run_command    self.distribution.run_command(command)  File ""/usr/lib/python3.10/site-packages/setuptools/dist.py"", line 1217, in run_command    super().run_command(command)  File ""/usr/lib/python3.10/site-packages/setuptools/_distutils/dist.py"", line 987, in run_command    cmd_obj.run()  File ""/home/Temp/rbt/numpy-1.23.2/numpy/distutils/command/build.py"", line 62, in run    old_build.run(self)  File ""/usr/lib/python3.10/site-packages/setuptools/_distutils/command/build.py"", line 131, in run    self.run_command(cmd_name)  File ""/usr/lib/python3.10/site-packages/setuptools/_distutils/cmd.py"", line 317, in run_command    self.distribution.run_command(command)  File ""/usr/lib/python3.10/site-packages/setuptools/dist.py"", line 1217, in run_command    super().run_command(command)  File ""/usr/lib/python3.10/site-packages/setuptools/_distutils/dist.py"", line 987, in run_command    cmd_obj.run()  File ""/home/Temp/rbt/numpy-1.23.2/numpy/distutils/command/build_src.py"", line 144, in run    self.build_sources()  File ""/home/Temp/rbt/numpy-1.23.2/numpy/distutils/command/build_src.py"", line 155, in build_sources    self.build_library_sources(*libname_info)  File ""/home/Temp/rbt/numpy-1.23.2/numpy/distutils/command/build_src.py"", line 288, in build_library_sources    sources =  self.generate_sources(sources, (lib_name, build_info))  File ""/home/Temp/rbt/numpy-1.23.2/numpy/distutils/command/build_src.py"", line 378, in generate_sources    source = func(extension, build_dir)  File ""/home/Temp/rbt/numpy-1.23.2/numpy/core/setup.py"", line 758, in get_mathlib_info    raise RuntimeError(RuntimeError: Broken toolchain: cannot link a simple C++ program. note: A compiler with support for C++11 language features is required.```PS: These templates are a bit annoying to use. I get that you want it separated, but a side effect is that in firefox these textview entries I am using right now appear much smaller than normally, whereas in the free form github issue I have more room to work with. With bad eyesight this is an issue, IMO.Sorry for the bad line wrapping above, but it was initially not possible to use it - now with a second edit it is much easier.So for the TL;DR variant:    RuntimeError: Broken toolchain: cannot link a simple C++ program. note: A compiler with support for    C++11 language features is required.^^^ this is bogus. My toolchain works perfectly well. The compiler is at /usr/bin/gcc as a symlink towards/home/Programs/Gcc/12.2.0/bin/gcc.. For reference purpose I compiled mesa from source a few daysago without problem, and yesterday node (nodejs) from source too and it all works fine. numpy shows ""WARN: Could not locate executable armflang"" but I don't know ... armflang? Is that forARM? I have an AMD 64 bit here. No idea why it tries to find some armflang binary.### Reproduce the code example:```pythonx```### Error message:```shellx```### NumPy/Python version information:x### Context for the issue:x
"
22198,1,17315,0,0,0,orjgre,0,"title:BUG: Segfault during import in python embedded application description:### Describe the issue:After upgrading to Ubuntu 22.04 and Python 3.10 I get a segfault when importing numpy in c++.This was working fine before the upgrade. I've tried creating a reproducible sample, but when creating a new project and copying over all the relevant classes numpy import works fine.As far as I can tell this happens when import hashlib during some open ssl md5 initialization. Import numpy in a normal python interpreter works fine.See attachment for verbose module loading.[verbose_module_load.txt](https://github.com/numpy/numpy/files/9477016/verbose_module_load.txt)### Reproduce the code example:```pythonPy_SetProgramName(reinterpret_cast<const wchar_t*>(""CA""));Py_Initialize();if (PyRun_SimpleString(""import sys"") < 0) {    fail(""Could not import sys module!"");}auto import = []() {    import_array();    return 0L;};if (import() < 0) {    fail(""Could not initialize numpy!"");}```### Error message:  Backtrace(?)  ```shell<unknown> 0x0000000000000000py_evp_fromname 0x00007fffc58e6f71_hashlib_openssl_md5_impl 0x00007fffc58e6dc8_hashlib_openssl_md5 0x00007fffc58e6dc8cfunction_vectorcall_FASTCALL_KEYWORDS 0x00007fffe9353599_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a0458_PyEval_EvalFrameDefault 0x00007fffe92a0458_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ffPyEval_EvalCode 0x00007fffe93e91aebuiltin_exec_impl 0x00007fffe93e973dbuiltin_exec 0x00007fffe93e973dcfunction_vectorcall_FASTCALL 0x00007fffe9358653do_call_core 0x00007fffe929e766_PyEval_EvalFrameDefault 0x00007fffe929e766_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a39b8_PyEval_EvalFrameDefault 0x00007fffe92a39b8_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a1eee_PyEval_EvalFrameDefault 0x00007fffe92a1eee_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114object_vacall 0x00007fffe930e054_PyObject_CallMethodIdObjArgs 0x00007fffe930e3bfimport_find_and_load 0x00007fffe9416d64PyImport_ImportModuleLevelObject 0x00007fffe9416d64import_name 0x00007fffe92a2705_PyEval_EvalFrameDefault 0x00007fffe92a2705_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ffPyEval_EvalCode 0x00007fffe93e91aebuiltin_exec_impl 0x00007fffe93e973dbuiltin_exec 0x00007fffe93e973dcfunction_vectorcall_FASTCALL 0x00007fffe9358653do_call_core 0x00007fffe929e766_PyEval_EvalFrameDefault 0x00007fffe929e766_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a39b8_PyEval_EvalFrameDefault 0x00007fffe92a39b8_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a1eee_PyEval_EvalFrameDefault 0x00007fffe92a1eee_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114object_vacall 0x00007fffe930e054_PyObject_CallMethodIdObjArgs 0x00007fffe930e3bfimport_find_and_load 0x00007fffe9416d64PyImport_ImportModuleLevelObject 0x00007fffe9416d64import_name 0x00007fffe92a2705_PyEval_EvalFrameDefault 0x00007fffe92a2705_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ffPyEval_EvalCode 0x00007fffe93e91aecfunction_vectorcall_FASTCALL 0x00007fffe9358653do_call_core 0x00007fffe929e766_PyEval_EvalFrameDefault 0x00007fffe929e766_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a39b8_PyEval_EvalFrameDefault 0x00007fffe92a39b8_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a1eee_PyEval_EvalFrameDefault 0x00007fffe92a1eee_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114object_vacall 0x00007fffe930e054_PyObject_CallMethodIdObjArgs 0x00007fffe930e3bfimport_find_and_load 0x00007fffe9416d64PyImport_ImportModuleLevelObject 0x00007fffe9416d64<unknown> 0x00007fffc4c9a4d6<unknown> 0x00007fffc4c875f5PyModule_ExecDef 0x00007fffe935477e_imp_exec_dynamic.lto_priv.0 0x00007fffe9414043cfunction_vectorcall_O 0x00007fffe935852edo_call_core 0x00007fffe929e766_PyEval_EvalFrameDefault 0x00007fffe929e766_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a39b8_PyEval_EvalFrameDefault 0x00007fffe92a39b8_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a1eee_PyEval_EvalFrameDefault 0x00007fffe92a1eee_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114object_vacall 0x00007fffe930e054_PyObject_CallMethodIdObjArgs 0x00007fffe930e3bfimport_find_and_load 0x00007fffe9416d64PyImport_ImportModuleLevelObject 0x00007fffe9416d64builtin___import__ 0x00007fffe93ea0cecfunction_call 0x00007fffe9353063_PyObject_MakeTpCall 0x00007fffe930dd9c_PyObject_VectorcallTstate abstract.h:112_PyObject_VectorcallTstate abstract.h:99_PyObject_CallFunctionVa 0x00007fffe930f429_PyObject_CallFunctionVa 0x00007fffe930fd01PyObject_CallFunction 0x00007fffe930fd01PyImport_Import 0x00007fffe941771ePyImport_ImportModule 0x00007fffe94178fe<unknown> 0x00007fffc4cbac7aPyModule_ExecDef 0x00007fffe935477e_imp_exec_dynamic.lto_priv.0 0x00007fffe9414043cfunction_vectorcall_O 0x00007fffe935852edo_call_core 0x00007fffe929e766_PyEval_EvalFrameDefault 0x00007fffe929e766_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a39b8_PyEval_EvalFrameDefault 0x00007fffe92a39b8_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a1eee_PyEval_EvalFrameDefault 0x00007fffe92a1eee_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114object_vacall 0x00007fffe930e054_PyObject_CallMethodIdObjArgs 0x00007fffe930e3bfimport_find_and_load 0x00007fffe9416d64PyImport_ImportModuleLevelObject 0x00007fffe9416d64import_name 0x00007fffe92a2705_PyEval_EvalFrameDefault 0x00007fffe92a2705_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ffPyEval_EvalCode 0x00007fffe93e91aebuiltin_exec_impl 0x00007fffe93e973dbuiltin_exec 0x00007fffe93e973dcfunction_vectorcall_FASTCALL 0x00007fffe9358653do_call_core 0x00007fffe929e766_PyEval_EvalFrameDefault 0x00007fffe929e766_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a39b8_PyEval_EvalFrameDefault 0x00007fffe92a39b8_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a1eee_PyEval_EvalFrameDefault 0x00007fffe92a1eee_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114object_vacall 0x00007fffe930e054_PyObject_CallMethodIdObjArgs 0x00007fffe930e3bfimport_find_and_load 0x00007fffe9416d64PyImport_ImportModuleLevelObject 0x00007fffe9416d64builtin___import__ 0x00007fffe93ea0cecfunction_call 0x00007fffe9353063_PyObject_Call 0x00007fffe930ee1cdo_call_core 0x00007fffe929e766_PyEval_EvalFrameDefault 0x00007fffe929e766_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114object_vacall 0x00007fffe930e054_PyObject_CallMethodIdObjArgs 0x00007fffe930e3bfPyImport_ImportModuleLevelObject 0x00007fffe9416c05import_name 0x00007fffe92a2705_PyEval_EvalFrameDefault 0x00007fffe92a2705_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ffPyEval_EvalCode 0x00007fffe93e91aebuiltin_exec_impl 0x00007fffe93e973dbuiltin_exec 0x00007fffe93e973dcfunction_vectorcall_FASTCALL 0x00007fffe9358653do_call_core 0x00007fffe929e766_PyEval_EvalFrameDefault 0x00007fffe929e766_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a39b8_PyEval_EvalFrameDefault 0x00007fffe92a39b8_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a1eee_PyEval_EvalFrameDefault 0x00007fffe92a1eee_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114object_vacall 0x00007fffe930e054_PyObject_CallMethodIdObjArgs 0x00007fffe930e3bfimport_find_and_load 0x00007fffe9416d64PyImport_ImportModuleLevelObject 0x00007fffe9416d64builtin___import__ 0x00007fffe93ea0cecfunction_call 0x00007fffe9353063_PyObject_Call 0x00007fffe930ee1cdo_call_core 0x00007fffe929e766_PyEval_EvalFrameDefault 0x00007fffe929e766_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114object_vacall 0x00007fffe930e054_PyObject_CallMethodIdObjArgs 0x00007fffe930e3bfPyImport_ImportModuleLevelObject 0x00007fffe9416c05import_name 0x00007fffe92a2705_PyEval_EvalFrameDefault 0x00007fffe92a2705_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ffPyEval_EvalCode 0x00007fffe93e91aebuiltin_exec_impl 0x00007fffe93e973dbuiltin_exec 0x00007fffe93e973dcfunction_vectorcall_FASTCALL 0x00007fffe9358653do_call_core 0x00007fffe929e766_PyEval_EvalFrameDefault 0x00007fffe929e766_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a39b8_PyEval_EvalFrameDefault 0x00007fffe92a39b8_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a1eee_PyEval_EvalFrameDefault 0x00007fffe92a1eee_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114object_vacall 0x00007fffe930e054_PyObject_CallMethodIdObjArgs 0x00007fffe930e3bfimport_find_and_load 0x00007fffe9416d64PyImport_ImportModuleLevelObject 0x00007fffe9416d64builtin___import__ 0x00007fffe93ea0cecfunction_call 0x00007fffe9353063_PyObject_Call 0x00007fffe930ee1cdo_call_core 0x00007fffe929e766_PyEval_EvalFrameDefault 0x00007fffe929e766_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114object_vacall 0x00007fffe930e054_PyObject_CallMethodIdObjArgs 0x00007fffe930e3bfimport_find_and_load 0x00007fffe9416d64PyImport_ImportModuleLevelObject 0x00007fffe9416d64builtin___import__ 0x00007fffe93ea0cecfunction_call 0x00007fffe9353063_PyObject_Call 0x00007fffe930ee1cdo_call_core 0x00007fffe929e766_PyEval_EvalFrameDefault 0x00007fffe929e766_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114PyObject_Vectorcall abstract.h:123call_function 0x00007fffe92a062e_PyEval_EvalFrameDefault 0x00007fffe92a062e_PyEval_EvalFrame pycore_ceval.h:46_PyEval_Vector 0x00007fffe93ee1ff_PyObject_VectorcallTstate abstract.h:114object_vacall 0x00007fffe930e054_PyObject_CallMethodIdObjArgs 0x00007fffe930e3bfimport_find_and_load 0x00007fffe9416d64PyImport_ImportModuleLevelObject 0x00007fffe9416d64builtin___import__ 0x00007fffe93ea0cecfunction_call 0x00007fffe9353063_PyObject_MakeTpCall 0x00007fffe930dd9c_PyObject_VectorcallTstate abstract.h:112_PyObject_VectorcallTstate abstract.h:99_PyObject_CallFunctionVa 0x00007fffe930f429_PyObject_CallFunctionVa 0x00007fffe930fd01PyObject_CallFunction 0x00007fffe930fd01PyImport_Import 0x00007fffe941771ePyImport_ImportModule 0x00007fffe94178fe```</details>### NumPy/Python version information:1.21.5 3.10.4 (main, Jun 29 2022, 12:14:53) [GCC 11.2.0]### Context for the issue:_No response_
"
22196,1,204,2,0,0,shantzhou,0,"title:Multidimensional and one-dimensional solutions are inconsistent description:### Describe the issue:<img width=""807"" alt=""image"" src=""https://user-images.githubusercontent.com/48147228/188078703-07e0172e-caf5-4214-8887-f03312454c18.png"">### Reproduce the code example:```pythonimport numpy as npk = np.random.rand(3,64).astype(np.float32)n1 = k/np.linalg.norm(k, 2, axis=1, keepdims=True)n2 = k[0]/np.linalg.norm(k[0])n3 = k[1]/np.linalg.norm(k[1])print(n1[1]-n3)```### Error message:_No response_### NumPy/Python version information:1.22.4### Context for the issue:_No response_
"
22195,0,0,275,0,1,charris,0,"title:BUG: Fix circleci build description:Backport of #22194.Pin towncrier to 21.9.0.[skip azp][skip github][skip travis]<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22194,0,0,275,0,1,charris,0,"title:BUG: Fix circleci build description:CircleCI tests are failing, see https://app.circleci.com/pipelines/github/numpy/numpy/15515/workflows/814a07d2-fbc4-4c31-afcb-ef9f73c40efb/jobs/27626, The problem seems to be towncrier related, so start by pinning towncrier to 21.9.0.[skip azp][skip github][skip travis]<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22193,0,0,6,0,0,iantra,0,"title:BUG: change overloads to play nice with pyright. description:It seems Pyright just chooses the first matching type whenever there is ambiguity in type resolution, which leads to a `NoReturn` for `numpy.cross` in certain situations (See #22146.) As far as I can tell, there is no agreed-upon behavior or guidelines for dealing with ambiguity in type resolution, so this is valid behavior on Pyright's side (see microsoft/pyright#2521 for a discussion on this topic.)I suppose the ideal solution would be to resolve the ambiguity, but AFAIK there is no way to do that for constructs like `numpy.array([1, 2, 3])` on the numpy side, short of asking every user to include a dtype in these cases. I would love to be proven wrong though.I think the second best solution is to have the more general overload also be the first one that matches, so that we make as few assumptions as possible about what might happen inside the function when given an `NDArray[Any]`. The other overloads were just changed so that they match the one for `numpy.cross`.I would also consider changing the overload order in functions elsewhere in the library, if it makes sense.I am very open to suggestions if someone has a better idea on how to deal with this.
"
22192,1,591,0,0,0,gsiisg,0,"title:BUG: np.minimum and np.clip with float32 and small epsilon description:### Describe the issue:- np.minimum is not giving the correct result if the input is float32 and epsilon is very small- this behavior is observed when using np.clip(input, eps, 1-eps) as well- this behavior is found when scikit-learn's log_loss was returning:""RuntimeWarning: divide by zero encountered in log""When the input have 1.0, the clip in log_loss still returned 1.0 instead of 0.9999999... therefore when taking log(1-p), when p=1.0, it gives nan.### Reproduce the code example:```pythonimport numpy as np# should print:# with eps=1e-7 np.float32 array, max is 0.9999999# with eps=1e-8 np.float32 array, max is 1.0# with eps=1e-8 np.float64 array, max is 0.99999999eps=1e-7result = np.minimum(np.array([1],dtype=np.float32),1-eps)print('with eps=1e-7 np.float32 array, max is', max(result))eps=1e-8result = np.minimum(np.array([1],dtype=np.float32),1-eps)print('with eps=1e-8 np.float32 array, max is', max(result))eps=1e-8result = np.minimum(np.array([1],dtype=np.float64),1-eps)print('with eps=1e-8 np.float64 array, max is', max(result))```### Error message:_No response_### NumPy/Python version information:1.21.5 3.9.12 (main, Apr  5 2022, 01:53:17) [Clang 12.0.0 ]### Context for the issue:trying to debug why I am getting nan in scikit-learn's log_loss function, turns out clipping was returning non-clipped values for 1-eps, getting 1.0 for y_pred.  When taking the log(1-p), where p = 1.0, gives division by zero warning, resulting in nan.
"
22191,1,293,0,0,0,Knightly123,0,"title:BUG: stack function will convert the float value to str if the input data has both float and str description:### Describe the issue:if the input data is a list which has float value and str value, then use stack function, the line which has both float value and str value will convert to str.**suggest**:        pass in the dtype into asanyarray function in below line:       arrays = [asanyarray(arr, dtype=dtype) for arr in arrays]### Reproduce the code example:```pythone.g., the input list is:       list1 =         [[1.0, 34.4, 56.6],         [2.0, 'abc', 35.1],         [3.0, 234, 45.9]]then:      data = empty((3,3), dtype=object)      np.stack(list1, out=data, dtype = object)result:  the second row's values will be converted to str.```### Error message:_No response_### NumPy/Python version information:mian branch, 1.24### Context for the issue:_No response_
"
22190,1,235,83,0,0,LaihoE,0,"title:BUG: Segmentation fault when using shared memory buffer description:### Describe the issue:Segfaults when assigning an array to the same variable that created a shared memory block. Obviously not the correct way of using it but relatively easy mistake to make.### Reproduce the code example:```pythonimport numpy as npfrom multiprocessing import shared_memoryshm = shared_memory.SharedMemory(create=True, size=8)shm = np.ndarray((1,), dtype=np.int64, buffer=shm.buf)print(shm)```### Error message:```shellSegmentation fault (core dumped)```### NumPy/Python version information:1.23.1 3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]### Context for the issue:_No response_
"
22187,1,126,0,0,0,TigerHou2,0,"title:BUG: WSL is missing full `longdouble` support (WSL, not NumPy probably) description:### Describe the issue:### Basic InformationPlatform: WSL Ubuntu-20.04Native OS: Windows 10, Version 10.0.19044 Build 19044Using Python 3.10.6 from conda-forge within a conda environmentNumPy 1.23.2 installed using `pip install numpy`### The Issue`np.finfo(np.longdouble).eps` reports `1.084202172485504434e-19` which suggests support for 80-bit extended precision, but `1+np.finfo(np.longdouble).eps == 1` returns `True`.I was under the impression that nominally one of two things should occur:a. On systems where `double` and `longdouble` have the same precision, for example Windows with MSVC, both `np.finfo(np.double).eps` and `np.finfo(np.longdouble).eps` should return `2.220446049250313e-16`, orb. On systems where `double` and `longdouble` do not have the same precision (i.e. if 80-bit FPs are supported), `np.finfo(np.longdouble).eps` should return `1.084202172485504434e-19` but then `1+np.finfo(np.longdouble).eps == 1` should return `False`.In my case there seem to be mixed messages, so I can't tell whether extended precision is actually supported or not. ### Reproduce the code example:```pythonimport numpy as npnp.finfo(np.longdouble).eps1 + np.finfo(np.longdouble).eps1 + np.finfo(np.longdouble).eps == 1```### Error message:_No response_### NumPy/Python version information:1.23.2 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:36:39) [GCC 10.4.0]### Context for the issue:I am trying to use [PINT](https://github.com/nanograv/PINT), an astronomy-related repo for modeling pulsar signals, for academic research. This requires precision on the order of nanoseconds across timescales of years, which necessitates extended precision as part of many key functions.
"
22185,0,998,5,0,1,colehaus,0,"title:BUG: ndarray subclasses always require both type arguments at runtime description:### Describe the issue:For ordinary generic classes, (e.g. `class Foo(Generic[A, B])`) subclasses can fix one or more of the generic parameters (e.g. `class FooSubclass(Foo[Any, A])`. After doing so, any reference to the type only has to supply the remaining free `TypeVar`s (e.g. `FooSubclass[float]` instead of `FooSubclass[Any, float]`. This doesn't seem to work with `ndarray`. No matter how many generic parameters are fixed at subclass definition time, future references to the subclass type throw an error at runtime when not given two types.### Reproduce the code example:```pythonfrom typing import Any, Generic, TypeAlias, TypeVarimport numpy as npA = TypeVar(""A"")B = TypeVar(""B"")class Foo(Generic[A, B]): ... # Define two parameter generic analogous to ndarrayclass FooSubclass(Foo[Any, A]): ... # Define partially saturated subclassclass Subclass(np.ndarray[Any, A]): ... # Define partially saturated subclassx: TypeAlias = Foo[Any, A] # Define partially saturated TypeAlias. No problemy: TypeAlias = x[float] # Use partially saturated TypeAlias. No problemz: TypeAlias = FooSubclass[float] # Use partially saturated subclass. No problem a: TypeAlias = np.ndarray[Any, A] # Define partially saturated TypeAlias. No problemb: TypeAlias = a[float] # Use partially saturated TypeAlias. No problemc: TypeAlias = Subclass[float] # Use partially saturated subclass. Problem```### Error message:```shellTraceback (most recent call last):  File ""temp.py"", line 19, in <module>    c: TypeAlias = Subclass[float]TypeError: Too few arguments for Subclass```### NumPy/Python version information:1.22.4 3.10.1 (main, Dec  6 2021, 18:38:26) [GCC 10.3.0]### Context for the issue:My initial motive was subclassing `ndarray` and using the subclass type to witness validations (e.g. that the matrix is a covariance matrix) (see the ""smart constructor"" pattern). But more broadly, this bug seems like it would affect almost anyone who is trying to subclass `ndarray` and also use Python's typing features.
"
22184,1,1195,12,0,0,AIQuantRobot,0,"title:Unable to allocate 8.09 TiB for an array with shape (280, 3000, 21, 3000, 21) and data type float64 description:### Describe the issue:slice element by specific dimension### Reproduce the code example:```pythonimport numpy as np<<@jit(nopython=True)def slidingWindow(a,window):	'''	Make an ndarray with a sliding window of the first dimension(axis = 0)	Parameters	----------	a : array_like		Array to add sliding window to	window : int		Size of sliding window	Returns	-------	Array that is a view of the original array with a added dimension of size w.	'''	if window < 1:		raise Exception('Arg: window must be at least 1.')	if window > a.shape[0]:		raise Exception('Arg: window cannot bigger than a.shape[0]')	shape = (a.shape[0] - window + 1,) + a.shape[1:] + (window,)	strides = a.strides + (a.strides[0],)	return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)M1 = np.random.randn(300,3000)M1_3D_n = slidingWindow(M1,21)argsortTensor = np.argsort(M1_3D_n,axis=2)ans = M1_3D_n[argsortTensor_n]>>```### Error message:```shell<<M1_3D_n[argsortTensor_n]Traceback (most recent call last):  File ""C:\Users\isaac\AppData\Local\Temp/ipykernel_588/3800740768.py"", line 1, in <module>    M1_3D_n[argsortTensor_n]MemoryError: Unable to allocate 8.09 TiB for an array with shape (280, 3000, 21, 3000, 21) and data type float64>>```### NumPy/Python version information:print(np.__version__, sys.version)1.20.3 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]### Context for the issue:How can I get the required sorted element in the specific dimensionThank you!!!
"
22175,1,297,13,0,0,paoloalba,0,"title:BUG: inconsistent behaviour of broadcasting with addition assignment operator description:### Describe the issue:numpy throws an exception when trying to sum two arrays with compatible/broadcastable shapes when using addition assignment operator.### Reproduce the code example:```pythonimport numpy as npa1 = np.array([1.0])a2 = np.array([12.0, 4])ccc = 0ccc += a1print(a1.shape, a2.shape, ccc.shape)ccc += a2# ccc = ccc + a2 this line works as expected```### Error message:```shellValueError: non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (2,)```### NumPy/Python version information:1.22.4 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]### Context for the issue:_No response_
"
22171,0,0,299,0,0,MatteoRaso,0,"title:DOC: Note symmetry requirement in `multivariate_normal` error description:闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻娑樷攽閸℃浠遍梺鍝勵儐閻楃娀寮婚敐澶樻晢闁逞屽墴閹即鈥旂粊瀹產l more descriptive (closes #22140)Issue #22140 says that numpy.random.multivariate_normal incorrectly warns that a non-symmetric positive-semidefinite matrix isn't positive-semidefinite. In the replies, there was some ambiguity over whether it was possible for a positive-semidefinite matrix to be non-symmetric, with reliable sources saying that symmetry is a common condition to add but not actually necessary. To solve this problem, two different members of the Numpy organization decided that the warning and error message ""covariance is not positive-semidefinite"" should be changed to ""covariance is not symmetric positive-semidefinite"". However, this change was never actually made yet.Since this change only required me to change a few strings instead of actually changing the code, I've decided to skip the CI jobs.[skip ci]<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22170,0,1669,205,1,0,Apteryks,0,"title:BUG: test_rint_big_int fails on Core 2 Duo CPU due to precision description:### Describe the issue:Building Numpy 1.23.1 with GNU Guix on an old Core 2 Duo (Intel Q6700) CPU, I stumbled on the `test_rint_big_int` failure (see below for the error message).The error seems to be related to precision, perhaps specific to this x86_64 architecture ### Reproduce the code example:```pythonIt seems to be reproducible every time I build on this Core 2 Duo machine.```Reproducible by disabling CPU feature `SSE41` on runtime via:```Bashexport NPY_DISABLE_CPU_FEATURES=""SSE41""```### Error message:```shell=================================== FAILURES ===================================______________________________ test_rint_big_int _______________________________[gw0] linux -- Python 3.9.13 /gnu/store/ir68khi30jzdlcn9sjw0anlgsgsjfjfi-python-3.9.13/bin/python3    def test_rint_big_int():        # np.rint bug for large integer values on Windows 32-bit and MKL        # https://github.com/numpy/numpy/issues/6685        val = 4607998452777363968        # This is exactly representable in floating point        assert_equal(val, int(float(val)))        # Rint should not change the value>       assert_equal(val, np.rint(val))E       AssertionError: E       Items are not equal:E        ACTUAL: 4607998452777363968E        DESIRED: 4.6079984527773635e+18val        = 4607998452777363968/gnu/store/bg6dygk3x2dpc15s40k61hy37nzhaiw2-python-numpy-1.23.1/lib/python3.9/site-packages/numpy/core/tests/test_umath.py:3875: AssertionError=========================== short test summary info ============================FAILED ../../core/tests/test_umath.py::test_rint_big_int - AssertionError: = 1 failed, 17805 passed, 1370 skipped, 35 xfailed, 7 xpassed in 474.41s (0:07:54) =error: in phase 'check': uncaught exception:%exception #<&invoke-error program: ""./runtests.py"" arguments: (""-vv"" ""--no-build"" ""--mode=fast"" ""-j"" ""4"" ""--"" ""-n"" ""4"" ""-k"" ""not test_float_remainder_overflow and not test_pareto"") exit-status: 1 term-signal: #f stop-signal: #f> phase `check' failed after 476.8 seconds```### NumPy/Python version information:1.23.1### Context for the issue:Occurs while running the test suite during packaging.EDIT(Sayed): Reproduce
"
22160,1,1514,0,0,1,simonkenny,0,"title:BUG: genfromtxt will cast all columns to the largest length if all columns are string type description:### Describe the issue:When using the genfromtxt function with dtype = None, if all columns are strings the function will generate an output array where all dtypes are the maximum length.Row 2307 numpy/lib/npyio.py correctly calculates the minimum string length required for each column.```python        # Update string types to be the right length        sized_column_types = column_types[:]        for i, col_type in enumerate(column_types):            if np.issubdtype(col_type, np.character):                n_chars = max(len(row[i]) for row in data)                **sized_column_types[i] = (col_type, n_chars)**```Row 2313  numpy/lib/npyio.py then ignores this and treats the columns as uniform because the base type is str for all columns, with no reference to sized_column_types.```python            # If the dtype is uniform (before sizing strings)            base = {                c_type                for c, c_type in zip(converters, column_types)                if c._checked}            **if len(base) == 1:**                uniform_type, = base                (ddtype, mdtype) = (uniform_type, bool)```This can be fixed by changing line 2319 in numpy/lib/npio.py from```python            if len(base) == 1:```to```python            if len(base) == 1 and base != {np.str_}: ```### Reproduce the code example:```pythontxt = ['a|a|aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa','b|bc|bbbbbbbbbbbbbbbbbbbbbbbbb']a = np.genfromtxt(txt,dtype=None,delimiter='|',unpack=True,encoding='utf8')for col in a:    print(col.dtype)Output:<U33<U33<U33```This is avoided if this direct case is avoided, by having multiple types or including names. ```pythontxt = ['1|a|aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa','1|bc|bbbbbbbbbbbbbbbbbbbbbbbbb']a = np.genfromtxt(txt,dtype=None,delimiter='|',unpack=True,encoding='utf8')for col in a:    print(col.dtype)Output:int32<U2<U33```or```pythontxt = ['a|a|aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa','a|bc|bbbbbbbbbbbbbbbbbbbbbbbbb']a = np.genfromtxt(txt,dtype=None,delimiter='|',unpack=True,encoding='utf8',names=['col1','col2','col3'])for col in a:    print(col.dtype)Output:<U1<U2<U33```### Error message:_No response_### NumPy/Python version information:1.22.4 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]### Context for the issue:When importing a file with one large column of ~160 characters, and 10 other short columns (2-5 characters) it is significantly increasing the memory requirement as it allocates 160 characters for all columns.
"
22158,1,1697,4,0,0,javierttgg,0,"title:BUG: numpy.linalg.eigh slower than numpy.linalg.eig when broadcasting small matrices description:### Describe the issue:Thank you for this amazing and crucial package. I noted that [`np.linalg.eigh`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eigh.html) is notably faster than [`np.linalg.eig`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html) when applying them to one array. However, `eigh` becomes slower than `eig` when broadcasting several small matrices ( $2\times 2$ is the most noticeable case).  As noted in the code example, this issue stops happening when using bigger matrices e.g. $100\times 100$.Is this a expected behavior in spite of `eigh` already using the fact that the matrices are symmetric?Thanks in advance.### Reproduce the code example:```pythonimport numpy as npfrom time import perf_counterdef compare_times(fun1, fun2, arr):    """""" prints execution_time(fun1(arr)) / prints execution_time(fun1(arr)) """"""    # fun1 execution time    s = perf_counter()    fun1(a)    t1 = (perf_counter() - s)        # fun2 execution time    s = perf_counter()    fun2(a)    t2 = (perf_counter() - s)        print(f'\t\ttime({fun1.__name__}) / time({fun2.__name__}) = {t1 / t2}')if __name__ == ""__main__"":    print(""1) small symmetric matrices: 2x2"")    d = 2    print(""\t1.1) using only one array"")    a = np.random.rand(d, d)    a = a.T.dot(a) # force symmetry    compare_times(np.linalg.eig, np.linalg.eigh, a) # gives ~ 3        print(""\t1.2) using 200 arrays"")    a = np.random.rand(200, d, d)    a = a.transpose(0, 2, 1) @ a    compare_times(np.linalg.eig, np.linalg.eigh, a) # gives ~ 0.9        print(""\t1.2) using 1000 arrays"")    a = np.random.rand(1000, d, d)    a = a.transpose(0, 2, 1) @ a    compare_times(np.linalg.eig, np.linalg.eigh, a) # gives ~ 0.7            print(""\n2) bigger symmetric matrices: 100x100"")    d = 100    print(""\t2.1) using only one array"")    a = np.random.rand(d, d)    a = a.T.dot(a) # force symmetry    compare_times(np.linalg.eig, np.linalg.eigh, a) # gives ~ 4        print(""\t2.2) using 200 arrays"")    a = np.random.rand(200, d, d)    a = a.transpose(0, 2, 1) @ a    compare_times(np.linalg.eig, np.linalg.eigh, a) # gives ~ 4        print(""\t1.3) using 1000 arrays"")    a = np.random.rand(1000, d, d)    a = a.transpose(0, 2, 1) @ a    compare_times(np.linalg.eig, np.linalg.eigh, a) # gives ~ 4```### Error message:_No response_### NumPy/Python version information:1.21.5 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]### Context for the issue:_No response_
"
22157,1,11,294,0,0,th0ma7,0,"title:BUG: numpy fails to cross-compiling with setuptools >= 64.x description:### Describe the issue:While preparing python 3.10.6 update I've took care to update all build requirements, including setuptools.It hapens that it made numpy to fail to build starting with setuptools >= 64.x (also fails on 65.x).Full build logs can be found here: https://github.com/SynoCommunity/spksrc/runs/7917533394?check_suite_focus=trueAssociated SynoCommunity PR: https://github.com/SynoCommunity/spksrc/pull/5395Note: Associated setuptools bug created https://github.com/pypa/setuptools/issues/3549### Reproduce the code example:```pythonn/a```### Error message:_No response_### NumPy/Python version information:n/a### Context for the issue:_No response_
"
22152,0,0,63,0,1,RinCat,0,"title:BUG: Support using libunwind for backtrack description:Some system (e.g. musl) do not have ""execinfo.h"", and the backtrackingis provided by libunwind.Fix: #22084<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22146,0,181,38,0,0,danielpmorton,0,"title:BUG: Overloaded return types with np.cross NoReturn leads to type-checking issues description:### Describe the issue:np.cross appears to have a return type of `NoReturn` when dealing with `_ArrayLikeBool_co` type, and this `NoReturn` type is incompatible with type checking in Pylance, and VSCode determines that all code after a call to np.cross is unreachable. This has been mentioned in a Pylance issue here (https://github.com/microsoft/pylance-release/issues/3195), but they recommended mentioning it with NumPy. ### Reproduce the code example:```pythonimport numpy as npx = np.array([1,2,3])y = np.array([2,3,4])z = np.cross(x, y)# This code is determined as unreachable by VSCode due to a NoReturn typeprint(z)```### Error message:_No response_### NumPy/Python version information:1.23.2 3.9.12 (main, Jun 12 2022, 13:39:05)[GCC 9.4.0]### Context for the issue:My code uses np.cross in many places, as well as extensive type-checking. It would be very nice if the return types could be cleaned up to improve compatibility with VSCode/Pylance/Pyright, because right now all of my code is grayed-out 
"
22140,0,378,0,0,0,drpepper19,0,"title:BUG:  np.random.multivariate_normal gives ""RuntimeWarning: covariance is not positive-semidefinite"" when it is description:### Describe the issue:np.random.multivariate_normal when run with a non-symmetric PD / PSD covariance matrix gives ""RuntimeWarning: covariance is not positive-semidefinite"". Even though it is PSD. It should warn ""RuntimeWarning: covariance is not symmetric"".### Reproduce the code example:```pythonimport numpy as npcov=np.eye(2)cov[0,1]=.5print(cov)print(""symmetric?"", (cov==cov.T).all())print(""PSD if eigvals all non-negative:"", np.linalg.eig(cov)[0])np.random.multivariate_normal(np.zeros(cov.shape[0]), cov, size=1)```### Error message:```shellRuntimeWarning: covariance is not positive-semidefinite.  np.random.multivariate_normal(np.zeros(cov.shape[0]), cov, size=1)```### NumPy/Python version information:('1.23.0', '3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]')
"
22126,1,480,287,0,0,kratsg,0,"title:BUG: Incorrect documentation for np.stack axis argument description:### Describe the issue:If you look at the current docstring (https://github.com/numpy/numpy/blob/4ee7b891ee9c3e5d0a805471eb03fb09f5cd65df/numpy/core/shape_base.py#L382-L398) - it seems to indicate that `axis` should be an `Optional[int]` type.All the current overloads indicate that `axis` should be `SupportsIndex` (https://github.com/numpy/numpy/blob/4ee7b891ee9c3e5d0a805471eb03fb09f5cd65df/numpy/core/shape_base.pyi#L63-L89). The documentation appears to be incorrect that `axis` is an optional type (must be specified).### Reproduce the code example:```pythonimport numpy as npa = np.array([1,2,3])np.stack([a, a], axis=None)```### Error message:```shellTraceback (most recent call last):  File ""test.py"", line 6, in <module>    np.stack([a,a], axis=axis)  File ""<__array_function__ internals>"", line 180, in stack  File ""/Users/kratsg/.pyenv/versions/pyhf-dev/lib/python3.8/site-packages/numpy/core/shape_base.py"", line 429, in stack    axis = normalize_axis_index(axis, result_ndim)TypeError: an integer is required (got type NoneType)```### NumPy/Python version information:1.22.3 3.8.6 (default, Oct 28 2020, 19:59:21) [Clang 10.0.1 (clang-1001.0.46.4)]### Context for the issue:_No response_
"
22123,0,0,0,0,1,LeonaTaric,0,"title:BUG: Large distances between start and stop in np.linspace() result in non-finite values description:if abs(stop - start) may greater then max(float64) thenresult = 2 * linspace(start / 2, stop / 2, ...)bug fix. see #21585 
"
22113,1,2282,7,0,0,ElrondL,0,"title:BUG: <AttributeError: 'MachAr' object has no attribute '_str_smallest_normal'> description:### Describe the issue:Similar to an earlier problem on AttributeError: 'MachAr' object has no attribute '_str_smallest_normal', but this time for float.32 on MacOS### Reproduce the code example:```pythonimport numpy as npnumpy.finfo('float32').eps```### Error message:```shellimport seaborn/Users/.../opt/anaconda3/lib/python3.9/site-packages/numpy/core/getlimits.py:492: UserWarning:Signature b'\xcd\xcc\xcc\xbd' for <class 'numpy.float32'> does not match any known type: falling back to type probe functionTraceback (most recent call last):  File ""..."", line 1, in <cell line: 1>    import seaborn  File ""/Users/.../opt/anaconda3/lib/python3.9/site-packages/seaborn/__init__.py"", line 2, in <module>    from .rcmod import *  # noqa: F401,F403  File ""/Users/.../opt/anaconda3/lib/python3.9/site-packages/seaborn/rcmod.py"", line 7, in <module>    from . import palettes  File ""/Users/.../opt/anaconda3/lib/python3.9/site-packages/seaborn/palettes.py"", line 9, in <module>    from .utils import desaturate, get_color_cycle  File ""/Users/.../opt/anaconda3/lib/python3.9/site-packages/seaborn/utils.py"", line 10, in <module>    from scipy import stats  File ""/Users/.../opt/anaconda3/lib/python3.9/site-packages/scipy/stats/__init__.py"", line 441, in <module>    from .stats import *  File ""/Users/.../opt/anaconda3/lib/python3.9/site-packages/scipy/stats/stats.py"", line 37, in <module>    from scipy.spatial.distance import cdist  File ""/Users/.../opt/anaconda3/lib/python3.9/site-packages/scipy/spatial/__init__.py"", line 101, in <module>    from ._procrustes import procrustes  File ""/Users/.../opt/anaconda3/lib/python3.9/site-packages/scipy/spatial/_procrustes.py"", line 9, in <module>    from scipy.linalg import orthogonal_procrustes  File ""/Users/.../opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/__init__.py"", line 206, in <module>    from .matfuncs import *  File ""/Users/.../opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/matfuncs.py"", line 24, in <module>    feps = np.finfo(single).eps  File ""/Users/.../opt/anaconda3/lib/python3.9/site-packages/numpy/core/getlimits.py"", line 485, in __new__    obj = object.__new__(cls)._init(dtype)  File ""/Users/.../opt/anaconda3/lib/python3.9/site-packages/numpy/core/getlimits.py"", line 512, in _init    self._str_smallest_normal = machar._str_smallest_normal.strip()AttributeError: 'MachAr' object has no attribute '_str_smallest_normal'```### NumPy/Python version information:1.22.3/3.9.13### Context for the issue:_No response_
"
22111,0,0,9,0,0,Developer-Ecosystem-Engineering,0,"title:BUG: Missed a case in the diff merge for #22110 description:When merging #22110, one of the cases was missed.
"
22110,0,0,9,0,0,Developer-Ecosystem-Engineering,0,"title:BUG: Address failures in aarch64 gcc builds due to #22096 description:gcc was unhappy with #22096 due to `numpy/core/src/common/simd/neon/conversion.h:93:22: error: incompatible type for argument 1 of 闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻鐔虹磼濡櫣鐟ㄧ紓浣疯兌楠炴潿p1q_u8闂?93 | return vuzp1q_u8(a, b); | ^ | | | npyv_b16 {aka uint16x8_t}`We cast it to resolve the rigorous type checking gcc is using. 
"
22107,0,0,275,0,1,charris,0,"title:BUG: Fix skip condition for test_loss_of_precision[complex256] description:Backport of#22083.The check code needs to use another constant to check for an affected GLIBC on PPC.See #15763Fixes #15243<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22104,1,305,25,0,0,sam-s,0,"title:BUG: np.polynomial.Polynomial.fit produces wrong results description:### Describe the issue:`np.polynomial.Polynomial.fit` produces polynomials that do _not_ fit the data.as the code example shows, the result is very different from that of `np.polyfit`### Reproduce the code example:```pythonimport npx = [0,1,2,3,4]y = [i*i for i in x] p1 = np.polyfit(x,y,2)# ==> x^2np.isclose(y,np.poly1d(p1)(x)).all() # ==> Truep2 = np.polynomial.Polynomial.fit(x,y,2)# ==> 4+8x+4x^2 = (2(x+1))^2np.polynomial.polynomial.polyval(x,p2.coef)# ==> array([  4.,  16.,  36.,  64., 100.])```### Error message:_No response_### NumPy/Python version information:1.23.1 3.10.4 (main, Jun 29 2022, 12:14:53) [GCC 11.2.0]### Context for the issue:https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html recommends using `np.polynomial.Polynomial.fit` instead of `np.polyfit`
"
22092,1,113,0,0,1,randall-romero,0,"title:BUG: np.vander overflows description:### Describe the issue:np.vander can silently overflow for large matricesVander returns an array of dtype='int32', which can easily overflow. For example, when computing Vandermonde matrix for array [1,2,3,...,11] one of the entries returned by np.vander is negative, which clearly it makes no sense in this case.### Reproduce the code example:```pythonimport numpy as np# Returns False, despite it must be true!(np.vander(np.arange(1,12)) > 0).all()```### Error message:_No response_### NumPy/Python version information:1.21.5 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]### Context for the issue:I was just preparing a class to illustrate how ill-conditioned  Vandermonde matrices are, how it can worsen as the matrix gets bigger. This class is for teaching numerical methods to economists.  [for my own purposes, it can be fixed using [1,2,3,...11] as floats instead of integers]
"
22091,1,75,26,0,0,rkishony,0,"title:BUG: np.abs(np.int64(-9223372036854775808))  is negative description:### Describe the issue:np.abs(np.int64(-9223372036854775808))  ->  -9223372036854775808### Reproduce the code example:```pythonnp.abs(np.int64(-9223372036854775808))  # -> -9223372036854775808```### Error message:_No response_### NumPy/Python version information:1.23.0 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:03:09) [Clang 13.0.1 ]### Context for the issue:_No response_
"
22086,1,16934,245,0,1,Indranil012,0,"title:BUG: installation error for numpy 1.23.1 on Termux description:### Describe the issue:Failed building wheel for numpy 1.23.1 on termux.numpy 1.22.0 installed successfully.### Reproduce the code example:```pythonpip install numpy```### Error message:```shell~ pip install --upgrade numpyRequirement already satisfied: numpy in /data/data/com.termux/files/usr/lib/python3.10/site-packages (1.22.0)Collecting numpy  Using cached numpy-1.23.1.tar.gz (10.7 MB)  Installing build dependencies ... done  Getting requirements to build wheel ... done  Preparing metadata (pyproject.toml) ... doneBuilding wheels for collected packages: numpy  Building wheel for numpy (pyproject.toml) ... error  error: subprocess-exited-with-error  闂?Building wheel for numpy (pyproject.toml) did not run successfully.  闂?exit code: 1  闂傚倸鍊搁崐鎼佸磹妞嬪海鐭嗗ù锝呮惈椤ユ碍銇勯幘鍗炵仼缁炬儳娼￠弻鏇㈠醇濠靛浂妫ら梺缁樼箓閻栧ジ骞冨Δ鍛櫜閹肩补鍓濋悘鍫㈢磽? [264 lines of output]      Running from numpy source directory.      setup.py:86: DeprecationWarning:        `numpy.distutils` is deprecated since NumPy 1.23.0, as a result        of the deprecation of `distutils` itself. It will be removed for        Python >= 3.12. For older Python versions it will remain present.        It is recommended to use `setuptools < 60.0` for those Python versions.        For more details, see:          https://numpy.org/devdocs/reference/distutils_status_migration.html        import numpy.distutils.command.sdist      Processing numpy/random/_bounded_integers.pxd.in      Processing numpy/random/_bounded_integers.pyx.in      Processing numpy/random/_common.pyx      Processing numpy/random/_generator.pyx      Processing numpy/random/_mt19937.pyx      Processing numpy/random/_pcg64.pyx      Processing numpy/random/_philox.pyx      Processing numpy/random/_sfc64.pyx      Processing numpy/random/bit_generator.pyx      Processing numpy/random/mtrand.pyx      Cythonizing sources      INFO: blas_opt_info:      INFO: blas_armpl_info:      INFO: customize UnixCCompiler      INFO:   libraries armpl_lp64_mp not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: blas_mkl_info:      INFO:   libraries mkl_rt not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: blis_info:      INFO:   libraries blis not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: openblas_info:      INFO:   libraries openblas not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: accelerate_info:      INFO:   NOT AVAILABLE      INFO:      INFO: atlas_3_10_blas_threads_info:      INFO: Setting PTATLAS=ATLAS      INFO:   libraries tatlas not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: atlas_3_10_blas_info:      INFO:   libraries satlas not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: atlas_blas_threads_info:      INFO: Setting PTATLAS=ATLAS      INFO:   libraries ptf77blas,ptcblas,atlas not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: atlas_blas_info:      INFO:   libraries f77blas,cblas,atlas not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      /data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/distutils/system_info.py:2077: UserWarning:          Optimized (vendor) Blas libraries are not found.          Falls back to netlib Blas library which has worse performance.          A better performance should be easily gained by switching          Blas library.        if self._calc_info(blas):      INFO: blas_info:      INFO:   libraries blas not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      /data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/distutils/system_info.py:2077: UserWarning:          Blas (http://www.netlib.org/blas/) libraries not found.          Directories to search for the libraries can be specified in the          numpy/distutils/site.cfg file (section [blas]) or by setting          the BLAS environment variable.        if self._calc_info(blas):      INFO: blas_src_info:      INFO:   NOT AVAILABLE      INFO:      /data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/distutils/system_info.py:2077: UserWarning:          Blas (http://www.netlib.org/blas/) sources not found.          Directories to search for the sources can be specified in the          numpy/distutils/site.cfg file (section [blas_src]) or by setting          the BLAS_SRC environment variable.        if self._calc_info(blas):      INFO:   NOT AVAILABLE      INFO:      non-existing path in 'numpy/distutils': 'site.cfg'      INFO: lapack_opt_info:      INFO: lapack_armpl_info:      INFO:   libraries armpl_lp64_mp not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: lapack_mkl_info:      INFO:   libraries mkl_rt not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: openblas_lapack_info:      INFO:   libraries openblas not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: openblas_clapack_info:      INFO:   libraries openblas,lapack not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: flame_info:      INFO:   libraries flame not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: atlas_3_10_threads_info:      INFO: Setting PTATLAS=ATLAS      INFO:   libraries tatlas,tatlas not found in /data/data/com.termux/files/usr/lib      INFO: <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>      INFO:   NOT AVAILABLE      INFO:      INFO: atlas_3_10_info:      INFO:   libraries satlas,satlas not found in /data/data/com.termux/files/usr/lib      INFO: <class 'numpy.distutils.system_info.atlas_3_10_info'>      INFO:   NOT AVAILABLE      INFO:      INFO: atlas_threads_info:      INFO: Setting PTATLAS=ATLAS      INFO:   libraries ptf77blas,ptcblas,atlas not found in /data/data/com.termux/files/usr/lib      INFO: <class 'numpy.distutils.system_info.atlas_threads_info'>      INFO:   NOT AVAILABLE      INFO:      INFO: atlas_info:      INFO:   libraries f77blas,cblas,atlas not found in /data/data/com.termux/files/usr/lib      INFO: <class 'numpy.distutils.system_info.atlas_info'>      INFO:   NOT AVAILABLE      INFO:      INFO: lapack_info:      INFO:   libraries lapack not found in ['/data/data/com.termux/files/usr/lib']      INFO:   NOT AVAILABLE      INFO:      /data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/distutils/system_info.py:1902: UserWarning:          Lapack (http://www.netlib.org/lapack/) libraries not found.          Directories to search for the libraries can be specified in the          numpy/distutils/site.cfg file (section [lapack]) or by setting          the LAPACK environment variable.        return getattr(self, '_calc_info_{}'.format(name))()      INFO: lapack_src_info:      INFO:   NOT AVAILABLE      INFO:      /data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/distutils/system_info.py:1902: UserWarning:          Lapack (http://www.netlib.org/lapack/) sources not found.          Directories to search for the sources can be specified in the          numpy/distutils/site.cfg file (section [lapack_src]) or by setting          the LAPACK_SRC environment variable.        return getattr(self, '_calc_info_{}'.format(name))()      INFO:   NOT AVAILABLE      INFO:      INFO: numpy_linalg_lapack_lite:      INFO:   FOUND:      INFO:     language = c      INFO:     define_macros = [('HAVE_BLAS_ILP64', None), ('BLAS_SYMBOL_SUFFIX', '64_')]      INFO:      Warning: attempted relative import with no known parent package      /data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py:275: UserWarning: Unknown distribution option: 'define_macros'        warnings.warn(msg)      running bdist_wheel      running build      running config_cc      INFO: unifing config_cc, config, build_clib, build_ext, build commands --compiler options      running config_fc      INFO: unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options      running build_src      INFO: build_src      INFO: building py_modules sources      creating build      creating build/src.linux-aarch64-3.10      creating build/src.linux-aarch64-3.10/numpy      creating build/src.linux-aarch64-3.10/numpy/distutils      INFO: building library ""npymath"" sources      WARN: Could not locate executable armflang      WARN: Could not locate executable gfortran      WARN: Could not locate executable f95      WARN: Could not locate executable ifort      WARN: Could not locate executable ifc      WARN: Could not locate executable lf95      WARN: Could not locate executable pgfortran      WARN: Could not locate executable nvfortran      WARN: Could not locate executable f90      WARN: Could not locate executable f77      WARN: Could not locate executable fort      WARN: Could not locate executable efort      WARN: Could not locate executable efc      WARN: Could not locate executable g77      WARN: Could not locate executable g95      WARN: Could not locate executable pathf95      WARN: Could not locate executable nagfor      WARN: Could not locate executable frt      WARN: don't know how to compile Fortran code on platform 'posix'      creating build/src.linux-aarch64-3.10/numpy/core      creating build/src.linux-aarch64-3.10/numpy/core/src      creating build/src.linux-aarch64-3.10/numpy/core/src/npymath      INFO: conv_template:> build/src.linux-aarch64-3.10/numpy/core/src/npymath/npy_math_internal.h      INFO:   adding 'build/src.linux-aarch64-3.10/numpy/core/src/npymath' to include_dirs.      INFO: conv_template:> build/src.linux-aarch64-3.10/numpy/core/src/npymath/ieee754.c      INFO: conv_template:> build/src.linux-aarch64-3.10/numpy/core/src/npymath/npy_math_complex.c      INFO: None - nothing done with h_files = ['build/src.linux-aarch64-3.10/numpy/core/src/npymath/npy_math_internal.h']      INFO: building library ""npyrandom"" sources      INFO: building extension ""numpy.core._multiarray_tests"" sources      creating build/src.linux-aarch64-3.10/numpy/core/src/multiarray      INFO: conv_template:> build/src.linux-aarch64-3.10/numpy/core/src/multiarray/_multiarray_tests.c      INFO: building extension ""numpy.core._multiarray_umath"" sources      Traceback (most recent call last):        File ""/data/data/com.termux/files/usr/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py"", line 363, in <module>          main()        File ""/data/data/com.termux/files/usr/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py"", line 345, in main          json_out['return_val'] = hook(**hook_input['kwargs'])        File ""/data/data/com.termux/files/usr/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py"", line 261, in build_wheel          return _build_backend().build_wheel(wheel_directory, config_settings,        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 230, in build_wheel          return self._build_with_temp_dir(['bdist_wheel'], '.whl',        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 215, in _build_with_temp_dir          self.run_setup()        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 267, in run_setup          super(_BuildMetaLegacyBackend,        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 158, in run_setup          exec(compile(code, __file__, 'exec'), locals())        File ""setup.py"", line 493, in <module>          setup_package()        File ""setup.py"", line 485, in setup_package          setup(**metadata)        File ""/data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/distutils/core.py"", line 169, in setup          return old_setup(**new_attr)        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/__init__.py"", line 153, in setup          return distutils.core.setup(**attrs)        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/_distutils/core.py"", line 148, in setup          dist.run_commands()        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py"", line 967, in run_commands          self.run_command(cmd)        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py"", line 986, in run_command          cmd_obj.run()        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/wheel/bdist_wheel.py"", line 299, in run          self.run_command('build')        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/_distutils/cmd.py"", line 313, in run_command          self.distribution.run_command(command)        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py"", line 986, in run_command          cmd_obj.run()        File ""/data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/distutils/command/build.py"", line 62, in run          old_build.run(self)        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/_distutils/command/build.py"", line 135, in run          self.run_command(cmd_name)        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/_distutils/cmd.py"", line 313, in run_command          self.distribution.run_command(command)        File ""/data/data/com.termux/files/usr/tmp/pip-build-env-kgfmqn3p/overlay/lib/python3.10/site-packages/setuptools/_distutils/dist.py"", line 986, in run_command          cmd_obj.run()        File ""/data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/distutils/command/build_src.py"", line 144, in run          self.build_sources()        File ""/data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/distutils/command/build_src.py"", line 161, in build_sources          self.build_extension_sources(ext)        File ""/data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/distutils/command/build_src.py"", line 318, in build_extension_sources          sources = self.generate_sources(sources, ext)        File ""/data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/distutils/command/build_src.py"", line 378, in generate_sources          source = func(extension, build_dir)        File ""/data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/core/setup.py"", line 513, in generate_config_h          check_math_capabilities(config_cmd, ext, moredefs, mathlibs)        File ""/data/data/com.termux/files/usr/tmp/pip-install-it2r5hri/numpy_4ccd1d6a6dfd4714af11cbdb029cb697/numpy/core/setup.py"", line 176, in check_math_capabilities          raise SystemError(""One of the required function to build numpy is not""      SystemError: One of the required function to build numpy is not available (the list is ['sin', 'cos', 'tan', 'sinh', 'cosh', 'tanh', 'fabs', 'floor', 'ceil', 'sqrt', 'log10', 'log', 'exp', 'asin', 'acos', 'atan', 'fmod', 'modf', 'frexp', 'ldexp']).      [end of output]  note: This error originates from a subprocess, and is likely not a problem with pip.  ERROR: Failed building wheel for numpyFailed to build numpyERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects```### NumPy/Python version information:numpy 1.23.1 , python 3.10.6Android, termux 0.118
"
22085,0,0,63,0,1,RinCat,0,"title:BUG: Disable execinfo.h for non-glibc systems description:Backtracing provided by other libraries (e.g. libunwind) onnon-glibc systems does not have execinfo.h.Fix: #22084
"
22084,0,281,63,0,0,RinCat,0,"title:BUG: unable to build with musl, 'execinfo.h' file not found description:### Describe the issue:Unable to build with musl since 'execinfo.h' not exists.### Reproduce the code example:```pythonN/A```### Error message:```shellINFO: clang: numpy/core/src/multiarray/temp_elide.cnumpy/core/src/multiarray/temp_elide.c:85:10: fatal error: 'execinfo.h' file not found#include <execinfo.h>                    ^~~~~~~~~~~~1 error generated.``````### NumPy/Python version information:1.23
"
22083,0,0,300,0,1,Flamefire,0,"title:BUG: Fix skip condition for test_loss_of_precision[complex256] description:The check code needs to use another constant to check for an affected GLIBC on PPC.See #15763Fixes #15243
"
22077,0,160,44,0,0,florentbr,0,"title:BUG: ndarray.base returns memoryview object instead of base object description:### Describe the issue:The method `ndarray.base` used to return the base object.I don't know when the regression occurred but as of release 1.23.1,  `ndarray.base` now returns a memory view object (`<memory at 0x000001C6AD0EFDC0>`).The documentation also states that it should return the base object:> ndarray.base>    Base object if memory is from some other object.### Reproduce the code example:```pythonimport numpy as npimport arraybuffer = array.array('B', (1,2,3,4))ys = np.frombuffer(buffer, np.int8)assert ys.base is buffer  # fails here!```### Error message:_No response_### NumPy/Python version information:1.23.1 3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]
"
22073,0,3154,282,0,0,GideonBear,0,"title:BUG: numpy.test() fails at test_linear_interpolation_formula_symmetric description:### Describe the issue:When I run `numpy.test()` a failure is encountered in `test_linear_interpolation_formula_symmetric`. I don't know if this is actually a bug, but I thought I should add this as an issue. I've run the test twice now and it gives the same result.I've searched for this on GitHub, Stack Overflow and Google, but got no results.OS is Linux Mint 19.3 Cinnamon.### Reproduce the code example:```pythonimport numpynumpy.test()```### Error message:```shell============================================================================================== FAILURES ==============================================================================================________________________________________________________________________ TestLerp.test_linear_interpolation_formula_symmetric ________________________________________________________________________self = <numpy.lib.tests.test_function_base.TestLerp object at 0x7fe580065190>    @hypothesis.given(t=st.floats(allow_nan=False, allow_infinity=False,>                                 min_value=0, max_value=1),                      a=st.floats(allow_nan=False, allow_infinity=False,                                  min_value=-1e300, max_value=1e300),                      b=st.floats(allow_nan=False, allow_infinity=False,                                  min_value=-1e300, max_value=1e300))f          = <function given.<locals>.run_test_as_given.<locals>.wrapped_test at 0x7fe5802cf790>self       = <numpy.lib.tests.test_function_base.TestLerp object at 0x7fe580065190>venv/lib/python3.8/site-packages/numpy/lib/tests/test_function_base.py:3568: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = <numpy.lib.tests.test_function_base.TestLerp object at 0x7fe580065190>, t = 0.5, a = 0.2500000000000003, b = 1.0    @hypothesis.given(t=st.floats(allow_nan=False, allow_infinity=False,                                  min_value=0, max_value=1),                      a=st.floats(allow_nan=False, allow_infinity=False,                                  min_value=-1e300, max_value=1e300),                      b=st.floats(allow_nan=False, allow_infinity=False,                                  min_value=-1e300, max_value=1e300))    def test_linear_interpolation_formula_symmetric(self, t, a, b):        # double subtraction is needed to remove the extra precision of t < 0.5        left = nfb._lerp(a, b, 1 - (1 - t))        right = nfb._lerp(b, a, 1 - t)>       assert left == rightE       assert 0.6250000000000001 == 0.6250000000000002a          = 0.2500000000000003b          = 1.0left       = 0.6250000000000001right      = 0.6250000000000002self       = <numpy.lib.tests.test_function_base.TestLerp object at 0x7fe580065190>t          = 0.5venv/lib/python3.8/site-packages/numpy/lib/tests/test_function_base.py:3577: AssertionError--------------------------------------------------------------------------------------------- Hypothesis ---------------------------------------------------------------------------------------------Falsifying example: test_linear_interpolation_formula_symmetric(    t=0.5,    a=0.2500000000000003,    b=1.0,    self=<numpy.lib.tests.test_function_base.TestLerp at 0x7fe580065190>,)You can reproduce this example by temporarily adding @reproduce_failure('6.53.0', b'AXicY2BgOMAABwekGNAAIwAmtgGc') as a decorator on your test case```### NumPy/Python version information:1.23.1 3.8.0 (default, Dec  9 2021, 17:53:27) [GCC 8.4.0]
"
22070,1,230,0,0,0,Ruth-wj,0,"title:BUG: escape sequence in string passed to repeat description:### Describe the issue:Due to me being a numpty and forgetting basic python syntax, I tried to do the following to scale a list by a factor.```multiplied_strings = np.repeat(['string_1', 'string_2'], 3)```all well and good. But hypothesis raised the following example which highlighted some strange behaviour when escape characters are included in the strings.```multiplied_strings = np.repeat(['0', '0\x00'], 3)```this example produces a list of 6 `0` elements. ### Reproduce the code example:```pythonimport numpy as npmultiplied_strings = np.repeat(['0', '0\x00'], 3)print(multiplied_strings)```### Error message:```shellN/A```### NumPy/Python version information:1.22.4 3.8.10 (default, Jun 22 2022, 20:18:18) [GCC 9.4.0]
"
22069,0,403,0,0,0,ItayVortex,0,"title:BUG: passing None as like to arange description:### Describe the issue:Calling `arange` with `like=None` gives an error:```TypeError: The `like` argument must be an array-like that implements the `__array_function__` protocol.```The documentation specify that `like=None` is the default value - https://numpy.org/doc/stable/reference/generated/numpy.arange.html### Reproduce the code example:```pythonFor example:numpy.arange(100, like=None)TypeError: The `like` argument must be an array-like that implements the `__array_function__` protocol.```But, calling `np.arange(100)` works fine.```### Error message:_No response_### NumPy/Python version information:1.21.0 3.9.5 (default, Nov 23 2021, 15:27:38) [GCC 9.3.0]
"
22063,1,286,281,0,0,jakirkham,0,"title:BUG: Using `min` with `axis` on empty array sometimes works? description:### Describe the issue:Noticed recently that some case where `min` is called on an empty array work depending on how `axis` is specified. In particular if the `axis` specified is non-zero it will work (even when the array is still empty).### Reproduce the code example:```pythonimport numpynumpy.zeros((0, 3)).min(axis=0)  # raises ValueErrornumpy.zeros((0, 3)).min(axis=1)  # array([], dtype=float64) ?numpy.zeros((0, 3)).min()        # raises ValueError```### Error message:_No response_### NumPy/Python version information:```1.22.4 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:52) [Clang 13.0.1 ]```
"
22061,1,329,296,0,0,eendebakpt,0,"title:BUG: Improve Numpy startup time description:### Describe the issue:Analysing the import time of numpy using [importtime-waterfal](https://github.com/asottile/importtime-waterfall) shows some parts can be improved. The import time varies with the platform (windows/linux) and whether numpy is installed in development mode or as a regular install.- [x] For development mode a bottleneck is the import of `numpy.version` which calls the expensive `git_pieces_from_vcs`. This can take 200-400 ms. [see notes in comments]- [x] For windows a bottleneck is the usage of `platform.system()` in ` _add_newdocs_scalars`. A PR to improve this is #22081- [x] In `numpy.compact._pep440` some regular expressions are compiled, but they are not used in the numpy import. They could be replaced with something like:```_legacy_version_component_re = Nonedef _parse_version_parts(s):    nonlocal _legacy_version_component_re     if _legacy_version_component_re  is None:         _legacy_version_component_re = re.compile(    r""(\d+ | [a-z]+ | \.| -)"", re.VERBOSE,)    for part in _legacy_version_component_re.split(s):         ....```PR https://github.com/numpy/numpy/pull/22081- [ ] `numpy.core._multiarray_umath` takes quite long to import (12 ms). There is some initialization going on (see `PyInit__multiarray_umath`), but without profiling it is not clear what is taking the time- [ ] In `numpy.core.ma` there is an import of `inspect` which is only used for the `cleandoc` method.- [x] In `numpy.core._internal` the `platform` module is imported and a call to `platform.python_implementation()` is made (#22163)### NumPy/Python version information:Not relevant
"
22055,0,138,274,0,0,m-aguena,0,"title:BUG: error in string array generated with arange function description:### Describe the issue:Arrays created with `np.arange(n, dtype=str)` for `n`>2 raise an error.### Reproduce the code example:```pythonimport numpy as npnp.arange(3, dtype=str)```### Error message:```shellFile ""<stdin>"", line 1, in <module>ValueError: no fill-function for data-type.```### NumPy/Python version information:1.23.1, 3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]
"
22054,1,248,45,0,0,zlispositive,0,"title:BUG: a vectorize function run twice for an scalar input (expected to only run once) description:### Describe the issue:For an vectorized function, the number of times the pre-vectorized method is run is not the same as the length of the input array. Running the `func_v1` in the sample code shows **2** ""Computation started"". Running the `func_v2` in the sample code shows **4** ""Computation started"". ### Reproduce the code example:```pythonimport numpy as npimport logginglogging.basicConfig(level=logging.DEBUG)def func(x):    logging.debug(f""Computation started"")    return xfunc_v1 = np.vectorize(func)func_v2 = np.vectorize(func_v1)func_v1(1)func_v2(1)```### Error message:_No response_### NumPy/Python version information:1.22.3 3.8.13 (default, Mar 28 2022, 06:16:26) [Clang 12.0.0 ]
"
22046,0,0,291,0,1,cmarmo,0,"title:BUG: Make `mask_invalid` consistent with `mask_where` if `copy` is set to `False` description:This pull requests makes `mask_invalid` consistent with `mask_where` when `copy` is set to `False`.Fixes #19332.I'd rather make the two functions consistent than change the documentation.Also from the documentation> Only applies to arrays with a dtype where NaNs or infs make senseI added a test checking that an error is thrown when `isinfinite` is not applicable.Thanks for considering it.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22044,1,538,0,0,0,geoanan,0,"title:BUG: Inconsistent floating point calc between Windows and Linux using matmul function description:### Describe the issue:I have a simple script testing the `matmul `function.When I run the script on a Windows machine (Windows 10 64-bit) and a RedHat (RedHat 7 64-bit) machine, the results are different.Windows 10 resultsEntry [0, 1] = 0.000000000000001346809783922148Entry [1, 1] = 1.000000000000000000000000000000Entry [2, 1] = 0.000000000000000000513348854551Entry [3, 1] = -0.000000000000000056419554088194Entry [4, 1] = 0.000000000000000012992244502267RedHat 7 resultsEntry [0, 1] = 0.000000000000000000000000000000Entry [1, 1] = 1.000000000000000000000000000000Entry [2, 1] = 0.000000000000000000000000000000Entry [3, 1] = 0.000000000000000000000000000000Entry [4, 1] = 0.000000000000000000000000000000Should the values not be the same?### Reproduce the code example:```pythonimport numpy as npdef matrix_multiply_check():    default_matrix = np.full((100, 100), 1.234567890123, np.float64)    for i in range(ARRAY_DIM):        for j in range(i, ARRAY_DIM):            default_matrix[i, j] = 4.5678912345    inverse_matrix = np.linalg.inv(default_matrix)    return np.matmul(inverse_matrix, default_matrix)if __name__ == ""__main__"":    result_matrix = matrix_multiply_check()        for x in range(5):        print(""Entry ["" + str(x) + "", 1] = "" ""%.30f"" % result_matrix[x, 1])```### Error message:_No response_### NumPy/Python version information:Numpy version 1.19.5python version 3.8.8
"
22041,0,656,93,0,0,parched,0,"title:BUG: Masked array creation fails with structured array description:### Describe the issue:When trying to create a mask array with a structured dtype a `TypeError` is thrown. However, the same code with `np.array` instead of `np.ma.array` works fine.I suspect [this](https://github.com/numpy/numpy/blob/45bc13e6d922690eea43b9d807d476e0f243f836/numpy/ma/core.py#L2868) might just need to catch `TypeError` too.### Reproduce the code example:```pythonimport numpy as npnp.ma.array((1, (b"""", b"""")), dtype=[(""x"", np.int_), (""y"", [(""i"", np.void), (""j"", np.void)])])```### Error message:```shellTraceback (most recent call last):  File ""<string>"", line 1, in <module>  File ""venv\lib\site-packages\numpy\ma\core.py"", line 6610, in array    return MaskedArray(data, mask=mask, dtype=dtype, copy=copy,  File ""venv\lib\site-packages\numpy\ma\core.py"", line 2865, in __new__    [getmaskarray(np.asanyarray(m, dtype=_data.dtype))  File ""venv\lib\site-packages\numpy\ma\core.py"", line 2865, in <listcomp>    [getmaskarray(np.asanyarray(m, dtype=_data.dtype))TypeError: a bytes-like object is required, not 'int'```### NumPy/Python version information:numpy: 1.23.0python: 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
"
22038,0,0,275,0,0,charris,0,"title:BUG: Avoid errors on NULL during deepcopy description:Backport of #21996.Closes #8706, #21883Addresses concerns raised in the two linked issues by:* Casting `NULL` objects to `Py_None` within `_deepcopy_call` to avoid issues within CPython's `deepcopy`* Setting `_deepcopy_call` to return an `int` code for error/success, which is then checked in `array_deepcopy`<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22037,0,1522,275,0,1,charris,0,"title:BUG: Use `Popen` to silently invoke f77 -v description:Backport of #21959.The line changed here fetches the output of `gfortran -v`, which on my machine looks like this:```Using built-in specs.COLLECT_GCC=C:\\Users\\osthege\\AppData\\Local\\Continuum\\miniconda3\\envs\\numpydev\\Library\\mingw-w64\\bin\\gfortran.exeCOLLECT_LTO_WRAPPER=C:/Users/osthege/AppData/Local/Continuum/miniconda3/envs/numpydev/Library/mingw-w64/bin/../lib/gcc/x86_64-w64-mingw32/5.3.0/lto-wrapper.exeTarget: x86_64-w64-mingw32Configured with: ../gcc-5.3.0/configure --prefix=/mingw64 --with-local-prefix=/mingw64/local --build=x86_64-w64-mingw32 --host=x86_64-w64-mingw32 --target=x86_64-w64-mingw32 --with-native-system-header-dir=/mingw64/x86_64-w64-mingw32/include --libexecdir=/mingw64/lib --with-gxx-include-dir=/mingw64/include/c++/5.3.0 --enable-bootstrap --with-arch=x86-64 --with-tune=generic --enable-languages=c,lto,c++,objc,obj-c++,fortran,ada --enable-shared --enable-static --enable-libatomic --enable-threads=posix --enable-graphite --enable-fully-dynamic-string --enable-libstdcxx-time=yes --disable-libstdcxx-pch --disable-libstdcxx-debug --enable-version-specific-runtime-libs --disable-isl-version-check --enable-lto --enable-libgomp --disable-multilib --enable-checking=release --disable-rpath --disable-win32-registry --disable-nls --disable-werror --disable-symvers --with-libiconv --with-system-zlib --with-gmp=/mingw64 --with-mpfr=/mingw64 --with-mpc=/mingw64 --with-isl=/mingw64 --with-pkgversion='Rev5, Built by MSYS2 project' --with-bugurl=https://sourceforge.net/projects/msys2 --with-gnu-as --with-gnu-ldThread model: posixgcc version 5.3.0 (Rev5, Built by MSYS2 project)```Prior to the change, the output was fetched from `stdout`, but it was actually coming through `stderr`. (Probably a regression.)I changed it aggregate from both `stdout` and `stderr`, which restores the previously intended behavior of `Gnu95FCompiler.get_target` to identify the target architecture, which in my case is `x86_64-w64-mingw32`.Closes #21942<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22036,0,0,275,0,1,charris,0,"title:BUG: Fix subarray to object cast ownership details description:Backport of #21925.This would be the minimal fix for gh-21911 (and an older issue somewhere).  However, it would also set a precedence that subarray to object casts will create copies.That is likely fine, since those casts usually crashed for a while and in many places a copy is OK.  It was also always broken from an ownership perspective.However, for code that used this and assigned to the result, things would obviously change.There are three options:1. Less-minimal fix, because we want view behavior here (and fix it).2. Keep it as it is (it was so unreliable that failures are hopefully minimal, and why would one *cast* to object to then assign?).3. We could tag on a warning, I don't think the warning ""flag"" is used right now.  I.e. print out a `UserWarning` that this is a copy, but may have been a view whenever the array may be written to.  (This may not be quite reliable for buffer users like cython, but not sure.)<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22028,1,564,285,0,1,bethac07,0,"title:BUG: <np.sin and/or np.pi returning slightly different results on different os's> description:### Describe the issue:When trying to run tests on a local Macbook (OSX 11.6.7) and on a GitHub Actions runner (set up to build on `ubuntu-latest`, config file [here](https://github.com/CellProfiler/centrosome/blob/master/.github/workflows/pythonpackage.yml)), we were perplexed by a test that was failing on GH but passing locally. Basically, we're getting tiny differences in the output of some simple math using np.pi and np.sin, and it led to a rounding difference that led to a test failure. Both machines are running Python 3.8.13 and Numpy 1.23.1. We can fix our test by simply adding some rounding, but it seemed to me an unexpected behavior so I wanted to report it here. Please let me know if I can provide any more info!Mac```1.9999999999999998 float642.0 float642.220446049250313e-16 float64```Linux```1.9999999999999996 float641.9999999999999998 float642.220446049250313e-16 float64```### Reproduce the code example:```pythonimport npangle = float(30) * np.pi / 180.0length = 8sin =  np.sin(angle) * length / 2y = np.finfo(float).eps + np.sin(angle) * length / 2eps = np.finfo(float).epsfor eachfloat in [sin,y,eps]:    print(eachfloat, eachfloat.dtype)```### Error message:_No response_### NumPy/Python version information:Mac:```1.23.1 3.8.13 (default, May  8 2022, 17:53:05) [Clang 13.0.0 (clang-1300.0.29.30)]```Linux:```1.23.1 3.8.13 (default, Jun 20 2022, 14:28:56)[GCC 9.4.0]```
"
22024,0,0,300,0,1,serge-sans-paille,0,"title:BUG: Expose string_heapsort algorithm in a shared header description:Fix #22011
"
22019,0,695,260,0,0,manopapad,0,"title:BUG: ndarray.squeeze/transpose type signatures disallow None for first argument  description:### Describe the issue:The type signatures for `ndarray.squeeze` and `ndarray.transpose` don't allow passing `None` for the first argument, but the actual code allows it.### Reproduce the code example:```pythonimport numpy as npprint(np.ones((1,2,3)).squeeze(None).shape)print(np.ones((1,2,3)).transpose(None).shape)```### Error message:```shell~/Desktop> python a.py(2, 3)(3, 2, 1)~/Desktop> mypy a.pya.py:2: error: Argument 1 to ""squeeze"" of ""ndarray"" has incompatible type ""None""; expected ""Union[SupportsIndex, Tuple[SupportsIndex, ...]]""a.py:3: error: No overload variant of ""transpose"" of ""ndarray"" matches argument type ""None""a.py:3: note: Possible overload variants:a.py:3: note:     def transpose(self, Union[SupportsIndex, Sequence[SupportsIndex]]) -> ndarray[Any, dtype[floating[_64Bit]]]a.py:3: note:     def transpose(self, *axes: SupportsIndex) -> ndarray[Any, dtype[floating[_64Bit]]]```### NumPy/Python version information:1.22.3 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:06:49)[Clang 12.0.1 ]
"
22016,0,0,284,0,0,mattip,1,"title:BUG: Revert using __array_ufunc__ for MaskedArray description:This reverts PRs #21977 (which itself was a redo of #10622), #21993 and #21999. Please review the comments to all 4 PRs and also make sure this passes on astropy before re-submitting.I also re-opened issues #4959 and #15200.Sorry for the mess, I hope I did the revert correctly.
"
22014,0,0,150,0,0,bashtage,0,"title:BUG/ENH: Allow bit generators to supply their own constructor description:Allow bit generators to supply their own constructors to enable Generatorobjects using arbitrary bit generators to be supportedcloses #22012<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
22012,0,448,150,0,0,bashtage,0,"title:BUG: np.random.Generator cannot be unpickled using 3rd party bit generators description:### Describe the issue:The unpickling mechanism uses a hard-coded list of bit generators when unpickling a generator instance.  Because of this, it cannot  be used with 3rd party bit generators, or, if the name of the 3rd party bit generator is the same as the NumPy bit generator, it will unpickle using a different class than the original bit generator class### Reproduce the code example:```pythonimport numpy as npimport randomgen as rgimport pickle# Generator(MT64)g = np.random.Generator(rg.MT64())pickle.loads(pickle.dumps(g))```### Error message:```shellTraceback (most recent call last):  File ""C:\git\randomgen\exp.py"", line 7, in <module>    pickle.loads(pickle.dumps(g))  File ""c:\git\numpy\numpy\random\_pickle.py"", line 52, in __generator_ctor    raise ValueError(ValueError: MT64  is not a known NumPy BitGenerator class.```### NumPy/Python version information:1.24.0.dev0+559.g5ba36b700 3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]
"
22011,0,1913,47,0,0,stephenmsachs,0,"title:BUG: Build error with Intel Compiler `undefined reference to int string_heapsort_` on v1.23.0++ description:### Describe the issue:Numpy will not build with the Intel compielr commencing tag v1.23.0 while v1.22.4 builds fine.The final link step throws an error.### Reproduce the code example:```python# Intel OneaPI compilers need to be loaded in the environment# Easiest way to reproduce is to use Spack `spack install py-numpy@1.23.0%intel`# By hand installation to reproduce:git clone https://github.com/numpy/numpy.gitcd numpy/git checkout v1.23.0git submodule update --initpip install .```### Error message:```shellbuild/temp.linux-x86_64-3.9/numpy/core/src/npysort/quicksort.o: In function `int _INTERNALffdc6c67::string_quicksort_<npy::string_tag, char>(char*, long, void*)':  /home/ec2-user/numpy/numpy/core/src/npysort/quicksort.cpp:352: undefined reference to `int string_heapsort_<npy::string_tag, char>(char*, long, void*)'  build/temp.linux-x86_64-3.9/numpy/core/src/npysort/quicksort.o: In function `int _INTERNALffdc6c67::string_quicksort_<npy::unicode_tag, unsigned int>(unsigned int*, long, void*)':  /home/ec2-user/numpy/numpy/core/src/npysort/quicksort.cpp:352: undefined reference to `int string_heapsort_<npy::unicode_tag, unsigned int>(unsigned int*, long, void*)'  build/temp.linux-x86_64-3.9/numpy/core/src/npysort/quicksort.o: In function `int _INTERNALffdc6c67::string_aquicksort_<npy::string_tag, char>(char*, long*, long, void*)':  /home/ec2-user/numpy/numpy/core/src/npysort/quicksort.cpp:448: undefined reference to `int string_aheapsort_<npy::string_tag, char>(char*, long*, long, void*)'  build/temp.linux-x86_64-3.9/numpy/core/src/npysort/quicksort.o: In function `int _INTERNALffdc6c67::string_aquicksort_<npy::unicode_tag, unsigned int>(unsigned int*, long*, long, void*)':  /home/ec2-user/numpy/numpy/core/src/npysort/quicksort.cpp:448: undefined reference to `int string_aheapsort_<npy::unicode_tag, unsigned int>(unsigned int*, long*, long, void*)'  ld: build/lib.linux-x86_64-3.9/numpy/core/_multiarray_umath.cpython-39-x86_64-linux-gnu.so: hidden symbol `_Z16string_heapsort_IN3npy11unicode_tagEjEiPT0_lPv' isn't defined  ld: final link failed: Bad value```### NumPy/Python version information:Python 3.9.13numpy v1.23.0 - main
"
22009,0,153,296,0,1,eendebakpt,0,"title:BUG: fix np.average for Fraction elements description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->This PR allows calculation of the average of a numpy array with elements of type `fractions.Fraction`.```Pythonfrom numpy import npfrom fractions import Fractionarr = np.array([Fraction(1, 5), Fraction(3, 5)]))np.average(arr) # works with this PR```Fixes #21988
"
22006,0,13581,282,0,0,mdhaber,0,"title:BUG: SciPy test failures due to changes in NumPy main or Python 3.11 description:### Describe the issue:Some SciPy tests involving masked arrays have been failing since ~7/15 (e.g. see CI in scipy/scipy#16610). It looks like some of the failures are resolved by gh-21977, but there are some that remain.```python3=================================== FAILURES ===================================______________________ TestCorr.test_kendalltau_seasonal _______________________../testenv/lib/python3.11/site-packages/scipy/stats/tests/test_mstats_basic.py:405: in test_kendalltau_seasonal    assert_almost_equal(output['global p-value (indep)'], 0.008, 3)        output     = {'chi2 total': 0.9138890055275067, 'chi2 trend': 0.03518368100765739, 'global p-value (dep)': 0.9592698679548645, 'global p-value (indep)': 0.9415878180349753, ...}        self       = <scipy.stats.tests.test_mstats_basic.TestCorr object at 0x7f75a3bf2650>        x          = masked_array(  data=[[--, 4.0, 3.0, --],        [--, 3.0, 2.0, 6.0],        [4.0, 5.0, 5.0, 11.0],        [2.0, 3.... False, False, False],        [False, False, False, False],        [False, False,  True, False]],  fill_value=1e+20)/home/runner/.local/lib/python3.11/site-packages/numpy/ma/testutils.py:189: in assert_almost_equal    raise AssertionError(msg)E   AssertionError: E   Items are not equal:E    ACTUAL: 0.9415878180349753E    DESIRED: 0.008        actual     = 0.9415878180349753        decimal    = 3        desired    = 0.008        err_msg    = ''        msg        = '\nItems are not equal:\n ACTUAL: 0.9415878180349753\n DESIRED: 0.008'        verbose    = True_______________________ TestTtest_rel.test_fully_masked ________________________../testenv/lib/python3.11/site-packages/scipy/stats/tests/test_mstats_basic.py:1217: in test_fully_masked    assert_array_equal(p, (np.nan, np.nan))        outcome    = masked_array(  data=[[--, -0.4495544480666782],        [--, 0.6433801600172545],        [--, 0.08038096427837299]],  mask=[[ True, False],        [ True, False],        [ True, False]],  fill_value=1e+20)        p          = 1.0        pair       = ([nan, nan], [1.0, 2.0])        self       = <scipy.stats.tests.test_mstats_basic.TestTtest_rel object at 0x7f75a2eedb50>        t          = masked/home/runner/.local/lib/python3.11/site-packages/numpy/ma/testutils.py:225: in assert_array_equal    assert_array_compare(operator.__eq__, x, y,        err_msg    = ''        verbose    = True        x          = 1.0        y          = (nan, nan)/home/runner/.local/lib/python3.11/site-packages/numpy/ma/testutils.py:213: in assert_array_compare    return np.testing.assert_array_compare(comparison,        comparison = <built-in function eq>        err_msg    = ''        fill_value = True        header     = 'Arrays are not equal'        m          = False        verbose    = True        x          = masked_array(data=1.,             mask=False,       fill_value=1e+20)        y          = masked_array(data=[nan, nan],             mask=False,       fill_value=1e+20)/opt/hostedtoolcache/Python/3.11.0-beta.4/x64/lib/python3.11/contextlib.py:81: in inner    return func(*args, **kwds)E   AssertionError: E   Arrays are not equalE   E   x and y nan location mismatch:E    x: array(1.)E    y: array([nan, nan])        args       = (<built-in function eq>, array(1.), array([nan, nan]))        func       = <function assert_array_compare at 0x7f75b19c16c0>        kwds       = {'err_msg': '', 'header': 'Arrays are not equal', 'verbose': True}        self       = <contextlib._GeneratorContextManager object at 0x7f75b19a91d0>_______________________ TestTtest_ind.test_fully_masked ________________________../testenv/lib/python3.11/site-packages/scipy/stats/tests/test_mstats_basic.py:1316: in test_fully_masked    assert_array_equal(p, (np.nan, np.nan))        outcome    = masked_array(  data=[[--, -0.4495544480666782],        [--, 0.6433801600172545],        [--, 0.08038096427837299]],  mask=[[ True, False],        [ True, False],        [ True, False]],  fill_value=1e+20)        p          = 1.0        pair       = (masked_array(data=[--, --, --],             mask=[ True,  True,  True],       fill_value=1e+20,            dtype=f...1600172545,                   0.08038096427837299],             mask=[False, False, False],       fill_value=1e+20))        self       = <scipy.stats.tests.test_mstats_basic.TestTtest_ind object at 0x7f75a3837150>        t          = masked/home/runner/.local/lib/python3.11/site-packages/numpy/ma/testutils.py:225: in assert_array_equal    assert_array_compare(operator.__eq__, x, y,        err_msg    = ''        verbose    = True        x          = 1.0        y          = (nan, nan)/home/runner/.local/lib/python3.11/site-packages/numpy/ma/testutils.py:213: in assert_array_compare    return np.testing.assert_array_compare(comparison,        comparison = <built-in function eq>        err_msg    = ''        fill_value = True        header     = 'Arrays are not equal'        m          = False        verbose    = True        x          = masked_array(data=1.,             mask=False,       fill_value=1e+20)        y          = masked_array(data=[nan, nan],             mask=False,       fill_value=1e+20)/opt/hostedtoolcache/Python/3.11.0-beta.4/x64/lib/python3.11/contextlib.py:81: in inner    return func(*args, **kwds)E   AssertionError: E   Arrays are not equalE   E   x and y nan location mismatch:E    x: array(1.)E    y: array([nan, nan])        args       = (<built-in function eq>, array(1.), array([nan, nan]))        func       = <function assert_array_compare at 0x7f75b19c16c0>        kwds       = {'err_msg': '', 'header': 'Arrays are not equal', 'verbose': True}        self       = <contextlib._GeneratorContextManager object at 0x7f75b19a91d0>______________________ TestTtest_1samp.test_fully_masked _______________________../testenv/lib/python3.11/site-packages/scipy/stats/tests/test_mstats_basic.py:1403: in test_fully_masked    assert_array_equal(p, expected)        expected   = (nan, nan)        outcome    = masked_array(data=[--, --, --],             mask=[ True,  True,  True],       fill_value=1e+20,            dtype=float64)        p          = 1.0        pair       = ((nan, nan), 0.0)        self       = <scipy.stats.tests.test_mstats_basic.TestTtest_1samp object at 0x7f75a35bfa50>        sup        = <numpy.testing._private.utils.suppress_warnings object at 0x7f75996c5150>        t          = masked/home/runner/.local/lib/python3.11/site-packages/numpy/ma/testutils.py:225: in assert_array_equal    assert_array_compare(operator.__eq__, x, y,        err_msg    = ''        verbose    = True        x          = 1.0        y          = (nan, nan)/home/runner/.local/lib/python3.11/site-packages/numpy/ma/testutils.py:213: in assert_array_compare    return np.testing.assert_array_compare(comparison,        comparison = <built-in function eq>        err_msg    = ''        fill_value = True        header     = 'Arrays are not equal'        m          = False        verbose    = True        x          = masked_array(data=1.,             mask=False,       fill_value=1e+20)        y          = masked_array(data=[nan, nan],             mask=False,       fill_value=1e+20)/opt/hostedtoolcache/Python/3.11.0-beta.4/x64/lib/python3.11/contextlib.py:81: in inner    return func(*args, **kwds)E   AssertionError: E   Arrays are not equalE   E   x and y nan location mismatch:E    x: array(1.)E    y: array([nan, nan])        args       = (<built-in function eq>, array(1.), array([nan, nan]))        func       = <function assert_array_compare at 0x7f75b19c16c0>        kwds       = {'err_msg': '', 'header': 'Arrays are not equal', 'verbose': True}        self       = <contextlib._GeneratorContextManager object at 0x7f75b19a91d0>_________________________ test_chisquare_masked_arrays _________________________../testenv/lib/python3.11/site-packages/scipy/stats/tests/test_stats.py:3579: in test_chisquare_masked_arrays    mat.assert_array_almost_equal(g, expected_g, decimal=15)        chi2       = <scipy.stats._continuous_distns.chi2_gen object at 0x7f75ad58ae50>        chisq      = masked_array(data=[24.0, 0.5],             mask=[False, False],       fill_value=1e+20)        expected_chisq = array([24. ,  0.5])        expected_g = array([22.18070978,  0.50534308])        g          = array([nan, nan])        mask       = array([[0, 1],       [0, 1],       [0, 0],       [0, 0],       [1, 0]])        mobs       = masked_array(  data=[[8, --],        [8, --],        [16, 3],        [32, 4],        [--, 5]],  mask=[[False,  T...,        [False,  True],        [False, False],        [False, False],        [ True, False]],  fill_value=999999)        obs        = array([[ 8, -1],       [ 8, -1],       [16,  3],       [32,  4],       [-1,  5]])        p          = array([nan, nan])/home/runner/.local/lib/python3.11/site-packages/numpy/ma/testutils.py:265: in assert_array_almost_equal    assert_array_compare(compare, x, y, err_msg=err_msg, verbose=verbose,        compare    = <function assert_array_almost_equal.<locals>.compare at 0x7f758bbc84a0>        decimal    = 15        err_msg    = ''        verbose    = True        x          = array([nan, nan])        y          = array([22.18070978,  0.50534308])/home/runner/.local/lib/python3.11/site-packages/numpy/ma/testutils.py:213: in assert_array_compare    return np.testing.assert_array_compare(comparison,        comparison = <function assert_array_almost_equal.<locals>.compare at 0x7f758bbc84a0>        err_msg    = ''        fill_value = True        header     = 'Arrays are not almost equal'        m          = False        verbose    = True        x          = masked_array(data=[nan, nan],             mask=False,       fill_value=1e+20)        y          = masked_array(data=[22.18070978,  0.50534308],             mask=False,       fill_value=1e+20)/opt/hostedtoolcache/Python/3.11.0-beta.4/x64/lib/python3.11/contextlib.py:81: in inner    return func(*args, **kwds)E   AssertionError: E   Arrays are not almost equalE   E   x and y nan location mismatch:E    x: array([nan, nan])E    y: array([22.18071 ,  0.505343])        args       = (<function assert_array_almost_equal.<locals>.compare at 0x7f758bbc84a0>, array([nan, nan]), array([22.18070978,  0.50534308]))        func       = <function assert_array_compare at 0x7f75b19c16c0>        kwds       = {'err_msg': '', 'header': 'Arrays are not almost equal', 'verbose': True}        self       = <contextlib._GeneratorContextManager object at 0x7f75b19a91d0>============================= slowest 10 durations =============================16.80s call     build/testenv/lib/python3.11/site-packages/scipy/stats/tests/test_continuous_basic.py::test_kappa4_array_gh1358212.20s call     build/testenv/lib/python3.11/site-packages/scipy/stats/tests/test_continuous_basic.py::test_cont_basic[500-200-skewnorm-arg91]9.72s call     build/testenv/lib/python3.11/site-packages/scipy/optimize/tests/test_direct.py::TestDIRECT::test_segmentation_fault[False]7.68s call     build/testenv/lib/python3.11/site-packages/scipy/sparse/linalg/_isolve/tests/test_iterative.py::test_precond_inverse[case1]7.33s call     build/testenv/lib/python3.11/site-packages/scipy/_lib/tests/test_import_cycles.py::test_modules_importable5.79s call     build/testenv/lib/python3.11/site-packages/scipy/optimize/tests/test_lsq_linear.py::TestTRF::test_large_rank_deficient5.76s call     build/testenv/lib/python3.11/site-packages/scipy/optimize/tests/test_lsq_linear.py::TestBVLS::test_large_rank_deficient4.71s call     build/testenv/lib/python3.11/site-packages/scipy/stats/tests/test_continuous_basic.py::test_cont_basic[500-200-truncweibull_min-arg100]3.93s call     build/testenv/lib/python3.11/site-packages/scipy/optimize/tests/test_optimize.py::TestOptimizeSimple::test_minimize_callback_copies_array[fmin]3.68s call     build/testenv/lib/python3.11/site-packages/scipy/optimize/_trustregion_constr/tests/test_report.py::test_gh12922=========================== short test summary info ============================FAILED ../testenv/lib/python3.11/site-packages/scipy/stats/tests/test_mstats_basic.py::TestCorr::test_kendalltau_seasonalFAILED ../testenv/lib/python3.11/site-packages/scipy/stats/tests/test_mstats_basic.py::TestTtest_rel::test_fully_maskedFAILED ../testenv/lib/python3.11/site-packages/scipy/stats/tests/test_mstats_basic.py::TestTtest_ind::test_fully_maskedFAILED ../testenv/lib/python3.11/site-packages/scipy/stats/tests/test_mstats_basic.py::TestTtest_1samp::test_fully_maskedFAILED ../testenv/lib/python3.11/site-packages/scipy/stats/tests/test_stats.py::test_chisquare_masked_arrays= 5 failed, 36748 passed, 2162 skipped, [1211](https://github.com/scipy/scipy/runs/7379137176?check_suite_focus=true#step:7:1212)4 deselected, 139 xfailed, 7 xpassed in 538.49s (0:08:58) =```</details>I am having trouble creating a MWE involving only NumPy because I haven't been successful at building NumPy main. I hope someone with (any relatively modern version of) SciPy and NumPy main can help me find one. This test below passes in NumPy 1.21.2, but I believe it will fail with NumPy main. Can someone confirm and tell me what the value of `res` is in NumPy main?### Reproduce the code example:```pythonimport numpy as npfrom numpy import mafrom scipy.stats import mstatsoutcome = ma.masked_array(np.random.randn(3, 2), mask=[[1, 0], [1, 0], [1, 0]])res = mstats.ttest_rel(outcome[:, 0], outcome[:, 1])# I don't think it is good practice to compare a masked element to a NaN,# but this is what was in the SciPy test.np.testing.assert_array_equal(res, (np.nan, np.nan))# In any case, if this no longer passes, why not? # What is the value of `res` using NumPy main?print(res)```### Error message:```shell-```### NumPy/Python version information:1.21.2 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]
"
21999,0,0,256,0,1,bsipocz,1,"title:BUG: Fix masked median bug description:This is the rebased and followed-up version of https://github.com/numpy/numpy/pull/10909closes #10757
"
21996,0,0,6,0,0,jcusick13,0,"title:BUG: Avoid errors on NULL during deepcopy description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->Closes #8706, #21883Addresses concerns raised in the two linked issues by:* Casting `NULL` objects to `Py_None` within `_deepcopy_call` to avoid issues within CPython's `deepcopy`* Setting `_deepcopy_call` to return an `int` code for error/success, which is then checked in `array_deepcopy`
"
21995,0,0,293,0,1,eirrgang,0,"title:BUG: Distinguish exact vs. equivalent dtype for C type aliases. description:For `asarray` and for the `dtype` equality operator,equivalent dtype aliases were considered exact matches.This change ensures that the returned array has a descriptorthat exactly matches the requested dtype.Note: Intended behavior of `np.dtype('i') == np.dtype('l')`is to test compatibility, not identity. This change does notaffect the behavior of `PyArray_EquivTypes()`, and the`__eq__` operator for `dtype` continues to map to`PyArray_EquivTypes()`.Fixes #1468.
"
21993,0,0,263,0,1,rcomer,0,"title:BUG: fix ma.minimum.reduce with axis keyword description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->Fixes the problem reported at https://github.com/numpy/numpy/pull/21977#issuecomment-1186082534.The `reduce` method here effectively calls itself with an unmasked `MaskedArray` (mask=nomask) and then expects either a `MaskedArray` or a scalar.  This change ensures that an ordinary `ndarray` is converted to a `MaskedArray`, following the pattern already used in `mean` and `var` in this module.When `t` was an `ndarray`, we called `elif m` on a boolean array, triggering the ""ambiguous truth value"" error.https://github.com/numpy/numpy/blob/bdec32181605c8179fd79624d14c1cf019de75af/numpy/ma/core.py#L6883-L6886
"
21981,0,0,294,0,0,Saransh-cpp,0,"title:TST: ensure ``np.equal.reduce`` raises a ``TypeError`` description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->Closes #20929 Added a couple of tests to ensure that `np.equal.reduce` raises `TypeError`, and the developers are notified if the API changes.I am not very sure if I should be creating a new method for this test. Please let me know if I can add the tests in any existing method.Thanks!
"
21979,0,0,292,0,1,seberg,0,"title:BUG: Fix experimental dtype slot numbers description:Unfortunately, I forgot to move them around when introducing ensure_canonical,but the code relies on the order for simplicitly currently...Which doesn't matter, just means that the DType part of the experimental ufuncAPI is completely unusable in 1.23 right now.----Pretty big ooops by me, since I really thought I could tell peple in my SciPy talk that the super minimal unitdtype example will work with NumPy 1.23... And now I need this (so it will work with `main` only).
"
21978,0,1718,3,0,0,dabacon,0,"title:BUG: Missing type override for einsum case description:### Describe the issue:`np.einsum` appears to be missing type information for the case where it is used without a string as the first parameter (i.e. when you pass in something like an array and a list of indices).  My understanding is that these overrides appear here https://github.com/numpy/numpy/blob/v1.23.0/numpy/core/einsumfunc.pyi where one can see the missing case.### Reproduce the code example:```pythonimport numpy as nps = np.array([[1, 1], [1, 1]])t = np.einsum(s, [0, 0])```### Error message:```shellRunning this through mypy 0.782 yields:main.py:5: error: No overload variant of ""einsum"" matches argument types ""ndarray[Any, dtype[Any]]"", ""List[int]""        np.einsum(s, [0, 0])        ^main.py:5: note: Possible overload variants:main.py:5: note:     def einsum(str, *operands: Union[_SupportsArray[dtype[bool_]], _NestedSequence[_SupportsArray[dtype[bool_]]], bool, _NestedSequence[bool]], out: None = ..., dtype: Union[Type[bool], Type[bool_], dtype[bool_], _SupportsDType[dtype[bool_]], Literal['?'], Literal['=?'], Literal['<?'], Literal['>?'], Literal['bool'], Literal['bool_'], Literal['bool8'], None] = ..., order: Union[Literal['K'], Literal['A'], Literal['C'], Literal['F'], None] = ..., casting: Union[Literal['no'], Literal['equiv'], Literal['safe'], Literal['same_kind']] = ..., optimize: Union[None, bool, Literal['greedy'], Literal['optimal'], Sequence[Any]] = ...) -> Anymain.py:5: note:     def einsum(str, *operands: Union[_SupportsArray[dtype[Union[bool_, unsignedinteger[Any]]]], _NestedSequence[_SupportsArray[dtype[Union[bool_, unsignedinteger[Any]]]]], bool, _NestedSequence[bool]], out: None = ..., dtype: <union: 55 items> = ..., order: Union[Literal['K'], Literal['A'], Literal['C'], Literal['F'], None] = ..., casting: Union[Literal['no'], Literal['equiv'], Literal['safe'], Literal['same_kind']] = ..., optimize: Union[None, bool, Literal['greedy'], Literal['optimal'], Sequence[Any]] = ...) -> Anymain.py:5: note:     <3 more similar overloads not shown, out of 8 total overloads>``````### NumPy/Python version information:1.22.4 3.9.12 (main, Jun  7 2022, 13:04:54) [GCC 11.2.0]
"
21972,0,211,300,0,0,bmerry,0,"title:BUG: incorrect type annotations for np.angle description:### Describe the issue:The type annotation for `np.angle` seems to assume the return value is a scalar, but if given an array it returns an array. This causes false positives from mypy.### Reproduce the code example:```pythonimport numpy as npa = np.array([1.0 + 2.0j, 3.0 + 4.0j], dtype=np.dtype(complex))ang = np.angle(a)print(ang[0])```### Error message:```shellangle.py:5: error: Value of type ""complexfloating[Any, Any]"" is not indexable```### NumPy/Python version information:1.23.1 3.8.10 (default, Mar 15 2022, 12:22:08) [GCC 9.4.0]
"
21971,0,714,54,0,0,ml31415,0,"title:BUG: hash of nan varies within a loop description:### Describe the issue:I recently came across this oddity and I'm not sure if it's a numpy bug or rather a python bug - or even intended behavior. See the code sample, hashing a nan value inside a numpy array returns different values when inside a loop. To my understanding, this should at least return the same value within the same interpreter process. Hashing of `np.nan` itself, not fetched from an array, also seems to behave like this and also `None`.Hashes of other float values remain constant even on interpreter restarts and that would be the behavior I'd probably prefer for `nan` in general.### Reproduce the code example:```pythonimport numpy as npx = np.array([np.nan])for _ in range(10):    print(hash(x[0]), hash(x[0]))>>> 8758714064237 87587140642378758714064251 87587140642518758714064597 87587140645978758714064575 87587140645758758714064251 87587140642518758714064597 87587140645978758714064575 87587140645758758714064251 87587140642518758714064597 87587140645978758714064575 8758714064575python -c""import numpy as np; print(hash(np.nan))"">>> 8728020720275python -c""import numpy as np; print(hash(np.nan))"">>> 8733073938067python -c""import numpy as np; print(hash(100.22323))"">>> 514733334946775140python -c""import numpy as np; print(hash(100.22323))"">>> 514733334946775140```### Error message:_No response_### NumPy/Python version information:1.22.4 3.10.4 (main, Apr  2 2022, 09:04:19) [GCC 11.2.0]
"
21970,1,13975,19,0,1,root-11,0,"title:BUG: Python 3.11b4 install description:### Describe the issue:pip install numpy fails with Python3.11b4.### Reproduce the code example:```pythonpip install numpy```### Error message:```shell(tablite311) D:\github\tablite>pip install -r requirements.txtCollecting tqdm>=4.63.0  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)Collecting graph-theory>=2022.3.9.54615  Using cached graph-theory-2022.3.9.54615.tar.gz (50 kB)  Installing build dependencies ... done  Getting requirements to build wheel ... done  Preparing metadata (pyproject.toml) ... doneCollecting numpy>=1.22.3  Downloading numpy-1.23.1.tar.gz (10.7 MB)     闂傚倸鍊搁崐鎼佸磹閻戣姤鍊块柨鏃傛櫕缁犳儳鈹戦悩鍙夋悙闁绘帒鐏氶妵鍕箳瀹ュ牆鍘″銈庡墮閸氬濡甸崟顖氭婵炲棛鍋撻埢鍫ユ⒑閸濆嫮鐒跨紒缁樼箞瀹曟椽鍩€椤掍降浜滈柟鐑樺灥椤忣亪鏌￠崨顔肩祷妞ゎ叀娉曢幑鍕偖閺夋垵顫犻梻浣告啞閿氶柣掳鍔庨幑銏犫槈濞嗘劗绉堕梺鍛婃寙閸愩劎鍘掗梺璇插椤旀牠宕伴弽顓熷亯闁绘挸瀵掗崵鏇熴亜閹扳晛鐒烘繛灏栨櫊閺屻倝宕妷锔芥瘎闂佸憡蓱閹瑰洤顫忕紒妯肩懝闁搞儜鍌滃嚬缂傚倷绀侀鍡涙偋閻樻眹鈧礁鈻庨幇顒傜獮闂佸綊鍋婇崢楣冨储閹间焦鈷戦梺顐ゅ仜閼活垱鏅堕幘顔界厸濞达絿鎳撴慨鍫⑩偓鍨緲鐎氼厾鎹㈠┑瀣妞ゆ劑鍨婚鍝勨攽閻樺灚鏆╅柛瀣█楠炴捇顢旈崱妤冪瓘闂佽姤锚椤︿粙宕甸弴銏＄厱妞ゆ劧绲剧粈鈧梺鍝勵儎閻掞箓骞堥妸銉庣喖宕归鎯у缚闂備胶绮幐鎼佸疮閺夋埈娼栨繛宸憾閺佸啴鏌ㄥ┑鍡樼ォ闁诲繐宕—鍐Χ閸℃鍙嗗銈忓閺佽顕ｆ繝姘櫢闁绘灏欓崝锕€顪冮妶鍡楃瑨閻庢凹鍙冨鏌ュ箵閹烘繄鍞甸柣鐘烘鐏忋劑宕濋悢鍏肩厱婵☆垵娅ｉ幗鐘电磼缂佹鈯曟繛鐓庣箻瀹曟粏顦查柛鈺佺焸閹鈻撻崹顔界亪闂佺粯鐗滈崢褔顢氶敐澶樻晝闁靛繆鏅滈崓鐢告⒑閻撳孩鎲搁柡浣规倐瀹曘垽骞樼紒妯锋嫽婵炴挻鑹惧ú銈嗙濠靛牏纾奸悗锝庡亞婢у灚銇勯姀锛勬噭鐎垫澘瀚伴獮鍥敇閻樻彃绠伴梻鍌欑窔閳ь剛鍋涢懟顖涙櫠閹绢喗鐓涘ù锝囨嚀婵牏鈧灚婢樼€氼厾鎹㈠┑瀣妞ゆ劑鍨婚鍝勨攽閻樺灚鏆╅柛瀣█楠炴捇顢旈崱妤冪瓘闂佽姤锚椤︿粙宕甸弴銏＄厱妞ゆ劧绲剧粈鈧梺鍝勵儎閻掞箓骞堥妸銉庣喖宕归鎯у缚闂備胶绮幐鎼佸疮閺夋埈娼栨繛宸憾閺佸啴鏌ㄥ┑鍡樼ォ闁诲繐宕—鍐Χ閸℃鍙嗗銈忓閺佽顕ｆ繝姘櫢闁绘灏欓崝锕€顪冮妶鍡楃瑨閻庢凹鍙冨鏌ュ箵閹烘繄鍞甸柣鐘烘鐏忋劑宕濋悢鍏肩厱婵☆垵娅ｉ幗鐘电磼缂佹鈯曟繛鐓庣箻瀹曟粏顦查柛鈺佺焸閹鈻撻崹顔界亪闂佺粯鐗滈崢褔顢氶敐澶樻晝闁靛繆鏅滈崓鐢告⒑閻撳孩鎲搁柡浣规倐瀹曘垽骞樼紒妯锋嫽婵炴挻鑹惧ú銈嗙濠靛牏纾奸悗锝庡亞婢у灚銇勯姀锛勬噭鐎垫澘瀚伴獮鍥敇閻樻彃绠伴梻鍌欑窔閳ь剛鍋涢懟顖涙櫠閹绢喗鐓涘ù锝囨嚀婵牏鈧灚婢樼€氼厾鎹㈠┑瀣妞ゆ劑鍨婚鍝勨攽閻樺灚鏆╅柛瀣█楠炴捇顢旈崱妤冪瓘闂佽姤锚椤︿粙宕甸弴銏＄厱妞ゆ劧绲剧粈鈧梺鍝勵儎閻掞箓骞堥妸銉庣喖宕归鎯у缚闂備胶绮幐鎼佸疮閺夋埈娼栨繛宸憾閺佸啴鏌ㄥ┑鍡樼ォ闁诲繐宕—鍐Χ閸℃鍙嗗銈忓閺佽顕ｆ繝姘櫢闁绘灏欓崝锕€顪冮妶鍡楃瑨閻庢凹鍙冨鏌ュ箵閹烘繄鍞甸柣鐘烘鐏忋劑宕濋悢鍏肩厱婵☆垵娅ｉ幗鐘电磼缂佹鈯曟繛鐓庣箻瀹曟粏顦查柛鈺佺焸閹鈻撻崹顔界亪闂佺粯鐗滈崢褔顢氶敐澶樻晝闁靛繆鏅滈崓鐢告⒑閻撳孩鎲搁柡浣规倐瀹曘垽骞樼紒妯锋嫽婵炴挻鑹惧ú銈嗙濠靛牏纾奸悗锝庡亞婢у灚銇勯姀锛勬噭鐎垫澘瀚伴獮鍥敇閻樻彃绠伴梻鍌欑窔閳ь剛鍋涢懟顖涙櫠閹绢喗鐓涘ù锝囨嚀婵牏鈧灚婢樼€氼厾鎹㈠┑瀣妞ゆ劑鍨婚鍝勨攽閻樺灚鏆╅柛瀣█楠炴捇顢旈崱妤冪瓘闂佽姤锚椤︿粙宕甸弴銏＄厱妞ゆ劧绲剧粈鈧梺鍝勵儎閻掞箓骞堥妸銉庣喖宕归鎯у缚闂備胶绮幐鎼佸疮閺夋埈娼栨繛宸憾閺佸啴鏌ㄥ┑鍡樼ォ闁诲繐宕—鍐Χ閸℃鍙嗗銈忓閺佽顕ｆ繝姘櫢闁绘灏欓崝锕€顪冮妶鍡楃瑨閻庢凹鍙冨鏌ュ箵閹烘繄鍞甸柣鐘烘鐏忋劑宕濋悢鍏肩厱婵☆垵娅ｉ幗鐘电磼缂佹鈯曟繛鐓庣箻瀹曟粏顦查柛鈺佺焸閹鈻撻崹顔界亪闂佺粯鐗滈崢褔顢氶敐澶樻晝闁靛繆鏅滈崓鐢告⒑閻撳孩鎲搁柡浣规倐瀹曘垽骞樼紒妯锋嫽婵炴挻鑹惧ú銈嗙濠靛牏纾奸悗锝庡亞婢у灚銇勯姀锛勬噭鐎垫澘瀚伴獮鍥敇閻樻彃绠伴梻鍌欑窔閳ь剛鍋涢懟顖涙櫠閹绢喗鐓涘ù锝囨嚀婵牏鈧灚婢樼€氼厾鎹㈠┑瀣妞ゆ劑鍨婚鍝勨攽閻樺灚鏆╅柛瀣█楠炴捇顢旈崱妤冪瓘闂佽姤锚椤︿粙宕甸弴銏＄厱妞ゆ劧绲剧粈鈧梺?10.7/10.7 MB 4.1 MB/s eta 0:00:00  Installing build dependencies ... done  Getting requirements to build wheel ... done  Preparing metadata (pyproject.toml) ... doneCollecting h5py>=3.6.0  Downloading h5py-3.7.0.tar.gz (392 kB)     闂傚倸鍊搁崐鎼佸磹閻戣姤鍊块柨鏃傛櫕缁犳儳鈹戦悩鍙夋悙闁绘帒鐏氶妵鍕箳瀹ュ牆鍘″銈庡墮閸氬濡甸崟顖氭婵炲棛鍋撻埢鍫ユ⒑閸濆嫮鐒跨紒缁樼箞瀹曟椽鍩€椤掍降浜滈柟鐑樺灥椤忣亪鏌￠崨顔肩祷妞ゎ叀娉曢幑鍕偖閺夋垵顫犻梻浣告啞閿氶柣掳鍔庨幑銏犫槈濞嗘劗绉堕梺鍛婃寙閸愩劎鍘掗梺璇插椤旀牠宕伴弽顓熷亯闁绘挸瀵掗崵鏇熴亜閹扳晛鐒烘繛灏栨櫊閺屻倝宕妷锔芥瘎闂佸憡蓱閹瑰洤顫忕紒妯肩懝闁搞儜鍌滃嚬缂傚倷绀侀鍡涙偋閻樻眹鈧礁鈻庨幇顒傜獮闂佸綊鍋婇崢楣冨储閹间焦鈷戦梺顐ゅ仜閼活垱鏅堕幘顔界厸濞达絿鎳撴慨鍫⑩偓鍨緲鐎氼厾鎹㈠┑瀣妞ゆ劑鍨婚鍝勨攽閻樺灚鏆╅柛瀣█楠炴捇顢旈崱妤冪瓘闂佽姤锚椤︿粙宕甸弴銏＄厱妞ゆ劧绲剧粈鈧梺鍝勵儎閻掞箓骞堥妸銉庣喖宕归鎯у缚闂備胶绮幐鎼佸疮閺夋埈娼栨繛宸憾閺佸啴鏌ㄥ┑鍡樼ォ闁诲繐宕—鍐Χ閸℃鍙嗗銈忓閺佽顕ｆ繝姘櫢闁绘灏欓崝锕€顪冮妶鍡楃瑨閻庢凹鍙冨鏌ュ箵閹烘繄鍞甸柣鐘烘鐏忋劑宕濋悢鍏肩厱婵☆垵娅ｉ幗鐘电磼缂佹鈯曟繛鐓庣箻瀹曟粏顦查柛鈺佺焸閹鈻撻崹顔界亪闂佺粯鐗滈崢褔顢氶敐澶樻晝闁靛繆鏅滈崓鐢告⒑閻撳孩鎲搁柡浣规倐瀹曘垽骞樼紒妯锋嫽婵炴挻鑹惧ú銈嗙濠靛牏纾奸悗锝庡亞婢у灚銇勯姀锛勬噭鐎垫澘瀚伴獮鍥敇閻樻彃绠伴梻鍌欑窔閳ь剛鍋涢懟顖涙櫠閹绢喗鐓涘ù锝囨嚀婵牏鈧灚婢樼€氼厾鎹㈠┑瀣妞ゆ劑鍨婚鍝勨攽閻樺灚鏆╅柛瀣█楠炴捇顢旈崱妤冪瓘闂佽姤锚椤︿粙宕甸弴銏＄厱妞ゆ劧绲剧粈鈧梺鍝勵儎閻掞箓骞堥妸銉庣喖宕归鎯у缚闂備胶绮幐鎼佸疮閺夋埈娼栨繛宸憾閺佸啴鏌ㄥ┑鍡樼ォ闁诲繐宕—鍐Χ閸℃鍙嗗銈忓閺佽顕ｆ繝姘櫢闁绘灏欓崝锕€顪冮妶鍡楃瑨閻庢凹鍙冨鏌ュ箵閹烘繄鍞甸柣鐘烘鐏忋劑宕濋悢鍏肩厱婵☆垵娅ｉ幗鐘电磼缂佹鈯曟繛鐓庣箻瀹曟粏顦查柛鈺佺焸閹鈻撻崹顔界亪闂佺粯鐗滈崢褔顢氶敐澶樻晝闁靛繆鏅滈崓鐢告⒑閻撳孩鎲搁柡浣规倐瀹曘垽骞樼紒妯锋嫽婵炴挻鑹惧ú銈嗙濠靛牏纾奸悗锝庡亞婢у灚銇勯姀锛勬噭鐎垫澘瀚伴獮鍥敇閻樻彃绠伴梻鍌欑窔閳ь剛鍋涢懟顖涙櫠閹绢喗鐓涘ù锝囨嚀婵牏鈧灚婢樼€氼厾鎹㈠┑瀣妞ゆ劑鍨婚鍝勨攽閻樺灚鏆╅柛瀣█楠炴捇顢旈崱妤冪瓘闂佽姤锚椤︿粙宕甸弴銏＄厱妞ゆ劧绲剧粈鈧梺鍝勵儎閻掞箓骞堥妸銉庣喖宕归鎯у缚闂備胶绮幐鎼佸疮閺夋埈娼栨繛宸憾閺佸啴鏌ㄥ┑鍡樼ォ闁诲繐宕—鍐Χ閸℃鍙嗗銈忓閺佽顕ｆ繝姘櫢闁绘灏欓崝锕€顪冮妶鍡楃瑨閻庢凹鍙冨鏌ュ箵閹烘繄鍞甸柣鐘烘鐏忋劑宕濋悢鍏肩厱婵☆垵娅ｉ幗鐘电磼缂佹鈯曟繛鐓庣箻瀹曟粏顦查柛鈺佺焸閹鈻撻崹顔界亪闂佺粯鐗滈崢褔顢氶敐澶樻晝闁靛繆鏅滈崓鐢告⒑閻撳孩鎲搁柡浣规倐瀹曘垽骞樼紒妯锋嫽婵炴挻鑹惧ú銈嗙濠靛牏纾奸悗锝庡亞婢у灚銇勯姀锛勬噭鐎垫澘瀚伴獮鍥敇閻樻彃绠伴梻鍌欑窔閳ь剛鍋涢懟顖涙櫠閹绢喗鐓涘ù锝囨嚀婵牏鈧灚婢樼€氼厾鎹㈠┑瀣妞ゆ劑鍨婚鍝勨攽閻樺灚鏆╅柛瀣█楠炴捇顢旈崱妤冪瓘闂佽姤锚椤︿粙宕甸弴銏＄厱妞ゆ劧绲剧粈鈧梺鍝勵儎閻掞箓骞堥妸銉庣喖宕归鎯у缚闂備胶绮幐鎼佸疮閺夋埈娼栨繛宸憾閺佸啴鏌ㄥ┑鍡樼ォ闁诲繐宕—鍐Χ閸℃鍙嗗銈忓閺佽顕ｆ繝姘櫢闁绘灏欓崝锕€顪冮妶鍡楃瑨閻庢凹鍙冨鏌ュ箵閹烘繄鍞甸柣鐘烘鐏忋劑宕濋悢鍏肩厱婵☆垵娅ｉ幗鐘电磼缂佹鈯曟繛鐓庣箻瀹曟粏顦查柛鈺佺焸閹鈻撻崹顔界亪闂佺粯鐗滈崢褔顢氶敐澶樻晝闁靛繆鏅滈崓鐢告⒑閻撳孩鎲搁柡浣规倐瀹曘垽骞樼紒妯锋嫽婵炴挻鑹惧ú銈嗙濠靛牏纾奸悗锝庡亞婢у灚銇勯姀锛勬噭鐎垫澘瀚伴獮鍥敇閻樻彃绠伴梻鍌欑窔閳ь剛鍋涢懟顖涙櫠閹绢喗鐓涘ù锝囨嚀婵牏鈧灚婢樼€氼厾鎹㈠┑瀣妞ゆ劑鍨婚鍝勨攽閻樺灚鏆╅柛瀣█楠炴捇顢旈崱妤冪瓘闂佽姤锚椤︿粙宕甸弴銏＄厱妞ゆ劧绲剧粈鈧梺?392.4/392.4 KB 6.2 MB/s eta 0:00:00  Installing build dependencies ... error  error: subprocess-exited-with-error  闂?pip subprocess to install build dependencies did not run successfully.  闂?exit code: 1  闂傚倸鍊搁崐鎼佸磹妞嬪海鐭嗗ù锝呮惈椤ユ碍銇勯幘鍗炵仼缁炬儳娼￠弻鏇㈠醇濠靛浂妫ら梺缁樼箓閻栧ジ骞冨Δ鍛櫜閹肩补鍓濋悘鍫㈢磽? [246 lines of output]      Ignoring Cython: markers 'python_version < ""3.8""' don't match your environment       Ignoring Cython: markers 'python_version == ""3.8""' don't match your environment      Collecting setuptools        Using cached setuptools-63.1.0-py3-none-any.whl (1.2 MB)      Collecting wheel        Using cached wheel-0.37.1-py2.py3-none-any.whl (35 kB)      Collecting oldest-supported-numpy        Downloading oldest_supported_numpy-2022.5.28-py3-none-any.whl (3.9 kB)             Collecting pkgconfig        Downloading pkgconfig-1.5.5-py3-none-any.whl (6.7 kB)      Collecting Cython>=0.29.15        Using cached Cython-0.29.30-py2.py3-none-any.whl (985 kB)      Collecting numpy        Using cached numpy-1.23.1.tar.gz (10.7 MB)        Installing build dependencies: started        Installing build dependencies: finished with status 'done'        Getting requirements to build wheel: started        Getting requirements to build wheel: finished with status 'done'        Preparing metadata (pyproject.toml): started        Preparing metadata (pyproject.toml): finished with status 'done'      Building wheels for collected packages: numpy        Building wheel for numpy (pyproject.toml): started        Building wheel for numpy (pyproject.toml): finished with status 'error'        error: subprocess-exited-with-error             Building wheel for numpy (pyproject.toml) did not run successfully.        exit code: 1             [209 lines of output]        setup.py:71: RuntimeWarning: NumPy 1.23.1 may not yet support Python 3.11.          warnings.warn(        Running from numpy source directory.        setup.py:86: DeprecationWarning:               `numpy.distutils` is deprecated since NumPy 1.23.0, as a result          of the deprecation of `distutils` itself. It will be removed for          Python >= 3.12. For older Python versions it will remain present.          It is recommended to use `setuptools < 60.0` for those Python versions.          For more details, see:            https://numpy.org/devdocs/reference/distutils_status_migration.html                    import numpy.distutils.command.sdist        Processing numpy/random\_bounded_integers.pxd.in        Processing numpy/random\bit_generator.pyx        Processing numpy/random\mtrand.pyx        Processing numpy/random\_bounded_integers.pyx.in        Processing numpy/random\_common.pyx        Processing numpy/random\_generator.pyx        Processing numpy/random\_mt19937.pyx        Processing numpy/random\_pcg64.pyx        Processing numpy/random\_philox.pyx        Processing numpy/random\_sfc64.pyx        Cythonizing sources        INFO: blas_opt_info:        INFO: blas_armpl_info:        INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils        INFO: customize MSVCCompiler        INFO:   libraries armpl_lp64_mp not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        INFO: blas_mkl_info:        INFO:   libraries mkl_rt not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        INFO: blis_info:        INFO:   libraries blis not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        INFO: openblas_info:        INFO:   libraries openblas not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO: get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'        INFO: customize GnuFCompiler        WARN: Could not locate executable g77        WARN: Could not locate executable f77        INFO: customize IntelVisualFCompiler        WARN: Could not locate executable ifort        WARN: Could not locate executable ifl        INFO: customize AbsoftFCompiler        WARN: Could not locate executable f90        INFO: customize CompaqVisualFCompiler        WARN: Could not locate executable DF        INFO: customize IntelItaniumVisualFCompiler        WARN: Could not locate executable efl        INFO: customize Gnu95FCompiler        WARN: Could not locate executable gfortran        WARN: Could not locate executable f95        INFO: customize G95FCompiler        WARN: Could not locate executable g95        INFO: customize IntelEM64VisualFCompiler        INFO: customize IntelEM64TFCompiler        WARN: Could not locate executable efort        WARN: Could not locate executable efc        INFO: customize PGroupFlangCompiler        WARN: Could not locate executable flang        WARN: don't know how to compile Fortran code on platform 'nt'        INFO:   NOT AVAILABLE        INFO:        INFO: accelerate_info:        INFO:   NOT AVAILABLE        INFO:        INFO: atlas_3_10_blas_threads_info:        INFO: Setting PTATLAS=ATLAS        INFO:   libraries tatlas not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        INFO: atlas_3_10_blas_info:        INFO:   libraries satlas not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        INFO: atlas_blas_threads_info:        INFO: Setting PTATLAS=ATLAS        INFO:   libraries ptf77blas,ptcblas,atlas not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        INFO: atlas_blas_info:        INFO:   libraries f77blas,cblas,atlas not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        C:\Users\madsenbj\AppData\Local\Temp\pip-install-0kiwsyjc\numpy_64c164ee42234498a81011430be1e918\numpy\distutils\system_info.py:2077: UserWarning:            Optimized (vendor) Blas libraries are not found.            Falls back to netlib Blas library which has worse performance.            A better performance should be easily gained by switching            Blas library.          if self._calc_info(blas):        INFO: blas_info:        INFO:   libraries blas not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        C:\Users\madsenbj\AppData\Local\Temp\pip-install-0kiwsyjc\numpy_64c164ee42234498a81011430be1e918\numpy\distutils\system_info.py:2077: UserWarning:            Blas (http://www.netlib.org/blas/) libraries not found.            Directories to search for the libraries can be specified in the            numpy/distutils/site.cfg file (section [blas]) or by setting            the BLAS environment variable.          if self._calc_info(blas):        INFO: blas_src_info:        INFO:   NOT AVAILABLE        INFO:        C:\Users\madsenbj\AppData\Local\Temp\pip-install-0kiwsyjc\numpy_64c164ee42234498a81011430be1e918\numpy\distutils\system_info.py:2077: UserWarning:            Blas (http://www.netlib.org/blas/) sources not found.            Directories to search for the sources can be specified in the            numpy/distutils/site.cfg file (section [blas_src]) or by setting            the BLAS_SRC environment variable.          if self._calc_info(blas):        INFO:   NOT AVAILABLE        INFO:        non-existing path in 'numpy\\distutils': 'site.cfg'        INFO: lapack_opt_info:        INFO: lapack_armpl_info:        INFO:   libraries armpl_lp64_mp not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        INFO: lapack_mkl_info:        INFO:   libraries mkl_rt not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        INFO: openblas_lapack_info:        INFO:   libraries openblas not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        INFO: openblas_clapack_info:        INFO:   libraries openblas,lapack not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        INFO: flame_info:        INFO:   libraries flame not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        INFO: atlas_3_10_threads_info:        INFO: Setting PTATLAS=ATLAS        INFO:   libraries tatlas,tatlas not found in c:\Data\venv\tablite311\lib        INFO:   libraries tatlas,tatlas not found in C:\        INFO: <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>        INFO:   NOT AVAILABLE        INFO:        INFO: atlas_3_10_info:        INFO:   libraries satlas,satlas not found in c:\Data\venv\tablite311\lib        INFO:   libraries satlas,satlas not found in C:\        INFO: <class 'numpy.distutils.system_info.atlas_3_10_info'>        INFO:   NOT AVAILABLE        INFO:        INFO: atlas_threads_info:        INFO: Setting PTATLAS=ATLAS        INFO:   libraries ptf77blas,ptcblas,atlas not found in c:\Data\venv\tablite311\lib        INFO:   libraries ptf77blas,ptcblas,atlas not found in C:\        INFO: <class 'numpy.distutils.system_info.atlas_threads_info'>        INFO:   NOT AVAILABLE        INFO:        INFO: atlas_info:        INFO:   libraries f77blas,cblas,atlas not found in c:\Data\venv\tablite311\lib        INFO:   libraries f77blas,cblas,atlas not found in C:\        INFO: <class 'numpy.distutils.system_info.atlas_info'>        INFO:   NOT AVAILABLE        INFO:        INFO: lapack_info:        INFO:   libraries lapack not found in ['c:\\Data\\venv\\tablite311\\lib', 'C:\\']        INFO:   NOT AVAILABLE        INFO:        C:\Users\madsenbj\AppData\Local\Temp\pip-install-0kiwsyjc\numpy_64c164ee42234498a81011430be1e918\numpy\distutils\system_info.py:1902: UserWarning:            Lapack (http://www.netlib.org/lapack/) libraries not found.            Directories to search for the libraries can be specified in the            numpy/distutils/site.cfg file (section [lapack]) or by setting            the LAPACK environment variable.          return getattr(self, '_calc_info_{}'.format(name))()        INFO: lapack_src_info:        INFO:   NOT AVAILABLE        INFO:        C:\Users\madsenbj\AppData\Local\Temp\pip-install-0kiwsyjc\numpy_64c164ee42234498a81011430be1e918\numpy\distutils\system_info.py:1902: UserWarning:            Lapack (http://www.netlib.org/lapack/) sources not found.            Directories to search for the sources can be specified in the            numpy/distutils/site.cfg file (section [lapack_src]) or by setting            the LAPACK_SRC environment variable.          return getattr(self, '_calc_info_{}'.format(name))()        INFO:   NOT AVAILABLE        INFO:        INFO: numpy_linalg_lapack_lite:        INFO:   FOUND:        INFO:     language = c        INFO:     define_macros = [('HAVE_BLAS_ILP64', None), ('BLAS_SYMBOL_SUFFIX', '64_')]        INFO:        Warning: attempted relative import with no known parent package        c:\Users\madsenbj\AppData\Local\Programs\Python\Python311\Lib\distutils\dist.py:274: UserWarning: Unknown distribution option: 'define_macros'          warnings.warn(msg)        running bdist_wheel        running build        running config_cc        INFO: unifing config_cc, config, build_clib, build_ext, build commands --compiler options        running config_fc        INFO: unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options        running build_src        INFO: build_src        INFO: building py_modules sources        creating build        creating build\src.win-amd64-3.11        creating build\src.win-amd64-3.11\numpy        creating build\src.win-amd64-3.11\numpy\distutils        INFO: building library ""npymath"" sources        error: Microsoft Visual C++ 14.0 or greater is required. Get it with ""Microsoft C++ Build Tools"": https://visualstudio.microsoft.com/visual-cpp-build-tools/        [end of output]             note: This error originates from a subprocess, and is likely not a problem with pip.        ERROR: Failed building wheel for numpy      Failed to build numpy      ERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects      WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.      You should consider upgrading via the 'c:\Data\venv\tablite311\Scripts\python.exe -m pip install --upgrade pip' command.      [end of output]  note: This error originates from a subprocess, and is likely not a problem with pip.error: subprocess-exited-with-error闂?pip subprocess to install build dependencies did not run successfully.闂?exit code: 1闂傚倸鍊搁崐鎼佸磹妞嬪海鐭嗗ù锝呮惈椤ユ碍銇勯幘鍗炵仼缁炬儳娼￠弻鏇㈠醇濠靛浂妫ら梺缁樼箓閻栧ジ骞冨Δ鍛櫜閹肩补鍓濋悘鍫㈢磽? See above for output.```### NumPy/Python version information:python 3.11b4any numpy.
"
21959,0,1522,284,0,1,michaelosthege,0,"title:BUG: Use `Popen` to silently invoke f77 -v description:The line changed here fetches the output of `gfortran -v`, which on my machine looks like this:```Using built-in specs.COLLECT_GCC=C:\\Users\\osthege\\AppData\\Local\\Continuum\\miniconda3\\envs\\numpydev\\Library\\mingw-w64\\bin\\gfortran.exeCOLLECT_LTO_WRAPPER=C:/Users/osthege/AppData/Local/Continuum/miniconda3/envs/numpydev/Library/mingw-w64/bin/../lib/gcc/x86_64-w64-mingw32/5.3.0/lto-wrapper.exeTarget: x86_64-w64-mingw32Configured with: ../gcc-5.3.0/configure --prefix=/mingw64 --with-local-prefix=/mingw64/local --build=x86_64-w64-mingw32 --host=x86_64-w64-mingw32 --target=x86_64-w64-mingw32 --with-native-system-header-dir=/mingw64/x86_64-w64-mingw32/include --libexecdir=/mingw64/lib --with-gxx-include-dir=/mingw64/include/c++/5.3.0 --enable-bootstrap --with-arch=x86-64 --with-tune=generic --enable-languages=c,lto,c++,objc,obj-c++,fortran,ada --enable-shared --enable-static --enable-libatomic --enable-threads=posix --enable-graphite --enable-fully-dynamic-string --enable-libstdcxx-time=yes --disable-libstdcxx-pch --disable-libstdcxx-debug --enable-version-specific-runtime-libs --disable-isl-version-check --enable-lto --enable-libgomp --disable-multilib --enable-checking=release --disable-rpath --disable-win32-registry --disable-nls --disable-werror --disable-symvers --with-libiconv --with-system-zlib --with-gmp=/mingw64 --with-mpfr=/mingw64 --with-mpc=/mingw64 --with-isl=/mingw64 --with-pkgversion='Rev5, Built by MSYS2 project' --with-bugurl=https://sourceforge.net/projects/msys2 --with-gnu-as --with-gnu-ldThread model: posixgcc version 5.3.0 (Rev5, Built by MSYS2 project)```Prior to the change, the output was fetched from `stdout`, but it was actually coming through `stderr`. (Probably a regression.)I changed it aggregate from both `stdout` and `stderr`, which restores the previously intended behavior of `Gnu95FCompiler.get_target` to identify the target architecture, which in my case is `x86_64-w64-mingw32`.Closes #21942<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21952,0,0,275,0,1,charris,0,"title:BUG: Fix KeyError in crackfortran operator support description:Backport of #21890.Closes #21889 by simply using the safer `.get()` variant which returns `None` instead of a `KeyError`. This in turn allows the rest of the check to pass due to `not None` evaluating to `True` and keeping the rest of the intended logic.Note that there isn't actually any handling of `operator()` or even `implementedby` in the rest of F2PY yet (it was an enhancement done for `sphinx-fortran` I think).<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21951,0,0,275,0,1,charris,0,"title:BUG: Reorder extern ""C"" to only apply to function declarations in npy_math.h description:Backport of #21946.That way incompatible included headers are not affected.Fix #21802<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21950,1,596,0,0,0,aschelle,0,"title:BUG: Non-normalized eigenvectors in linalg.eigh for complex hermitian matrix on osx-arm64 description:### Describe the issue:The `linalg.eigh` function should return the 'normalized eigenvectors' of a symmetric or hermitian matrix. Below I used a simple symmetric matrix and calculated the determinant (which should be 1) and whether the two eigenvectors are normalized.  - When using `dtype=float` for the matrix, the results are correct. - When using `dtype=complex` for the matrix, the eigenvectors are not normalized.I did run the below code on several machines and **only** got the bug on my macbook m1 on arm64. When emulating the `osx-64` numpy package, the result is correct. The concrete versions, which I checked, are listed below.### Reproduce the code example:```pythonimport numpy as np# Forcing `matrix` to be of dtype=complexmatrix = np.array([[0,1+0j],[1,0]])eigenvectors = np.linalg.eigh(matrix)[1]# Check if `The array v of (column) eigenvectors is unitary`print(1 - abs(np.linalg.det(eigenvectors)))# Check explicitly if eigenvectors are normalizedprint(1 - eigenvectors[:,0].T.conj()@eigenvectors[:,0])print(1 - eigenvectors[:,1].T.conj()@eigenvectors[:,1])# All outputs should be close to 0```### Error message:```shell# OUTPUT on osx-arm64-1.216802553763662(-0.9999999999999998-2.2371143170757382e-17j)(-1.707106781186547-3.251767952832691e-17j)```### NumPy/Python version information:### Versions where the bug occurred - 1.23.0 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:05:37) [Clang 13.0.1 ]   numpy from conda-forge, `osx-arm64` - 1.21.5 3.10.4 (main, Mar 31 2022, 03:37:37) [Clang 12.0.0 ]    numpy from anaconda channel, `osx-arm64`### Other versions where the bug did not occur - 1.22.3 3.10.4 (main, Mar 31 2022, 03:38:35) [Clang 12.0.0 ]     Emulation of `osx-64` on M1 - 1.21.4 3.7.3 (default, Jan 22 2021, 20:04:44) [GCC 8.3.0]    x86_64 linux system
"
21946,0,0,300,0,1,serge-sans-paille,0,"title:BUG: Reorder extern ""C"" to only apply to function declarations in npy_math.h description:That way incompatible included headers are not affected.Fix #21802
"
21942,0,2338,284,0,1,michaelosthege,0,"title:BUG: `numpy.distutils.system_info.get_info(""blas_opt"")` has unsuppressable stdout side effects description:### Describe the issue:Aesara uses `numpy.distutils.system_info.get_info(""blas_opt"")` to obtain some compiler settings upon import.However, every this prints the GCC configuration to `stdout` which is incredibly annoying.We tried to capture/suppress the `stdout/stderr` output (see below), but it doesn't work.Related issues/PRs:* https://github.com/conda-forge/aesara-feedstock/issues/54* https://github.com/aesara-devs/aesara/issues/1005* https://github.com/aesara-devs/aesara/pull/980### Reproduce the code example:```pythonfrom contextlib import redirect_stderr, redirect_stdoutimport ioimport sysimport numpy.distutils.system_infoclass NumpyCompatibleStdoutStringIO(io.StringIO):    """"""Used as a temporary replacement of sys.stdout to capture Numpy's output.    We want to simply use io.StringIO, but this doesn't work because    Numpy expects the .encoding attribute to be a string. For io.StringIO,    this attribute is set to None and cannot be modified, hence the need for    this subclass.    (See forward_bytes_to_stdout in numpy.distutils.exec_command.)    """"""    encoding = sys.stdout.encoding# Neither of the following two work:# stdout_sio, stderr_sio = io.StringIO(), io.StringIO()stdout_sio, stderr_sio = NumpyCompatibleStdoutStringIO(), NumpyCompatibleStdoutStringIO()with redirect_stdout(stdout_sio), redirect_stderr(stderr_sio):    numpy.distutils.system_info.get_info(""blas_opt"")```### Error message:No error, but unwanted stdout:```shellUsing built-in specs.COLLECT_GCC=gccCOLLECT_LTO_WRAPPER=C:/Users/osthege/AppData/Local/Continuum/miniconda3/envs/pm3v4/Library/mingw-w64/bin/../lib/gcc/x86_64-w64-mingw32/5.3.0/lto-wrapper.exeTarget: x86_64-w64-mingw32Configured with: ../gcc-5.3.0/configure --prefix=/mingw64 --with-local-prefix=/mingw64/local --build=x86_64-w64-mingw32 --host=x86_64-w64-mingw32 --target=x86_64-w64-mingw32 --with-native-system-header-dir=/mingw64/x86_64-w64-mingw32/include --libexecdir=/mingw64/lib --with-gxx-include-dir=/mingw64/include/c++/5.3.0 --enable-bootstrap --with-arch=x86-64 --with-tune=generic --enable-languages=c,lto,c++,objc,obj-c++,fortran,ada --enable-shared --enable-static --enable-libatomic --enable-threads=posix --enable-graphite --enable-fully-dynamic-string --enable-libstdcxx-time=yes --disable-libstdcxx-pch --disable-libstdcxx-debug --enable-version-specific-runtime-libs --disable-isl-version-check --enable-lto --enable-libgomp --disable-multilib --enable-checking=release --disable-rpath --disable-win32-registry --disable-nls --disable-werror --disable-symvers --with-libiconv --with-system-zlib --with-gmp=/mingw64 --with-mpfr=/mingw64 --with-mpc=/mingw64 --with-isl=/mingw64 --with-pkgversion='Rev5, Built by MSYS2 project' --with-bugurl=https://sourceforge.net/projects/msys2 --with-gnu-as --with-gnu-ldThread model: posixgcc version 5.3.0 (Rev5, Built by MSYS2 project)```### NumPy/Python version information:1.19.2 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]
"
21939,0,1011,20,0,1,posita,0,"title:BUG: _ComparisonOp doesn't support numeric interoperability? description:### Describe the issue:This (sort of) came up in https://github.com/python/mypy/issues/3186#issuecomment-1176593668 recently, but `_ComparisonOp`'s current form likely frustrates numeric interoperability. From [here](https://github.com/thai-phi/numpy_backup/blob/5d0517163889cb9519c3e2731b3737276d27cfa7/numpy/typing/_callable.py#L323-L327):``` python    class _ComparisonOp(Protocol[_T1, _T2]):        @overload        def __call__(self, __other: _T1) -> bool_: ...        @overload        def __call__(self, __other: _T2) -> _ArrayOrScalar[bool_]: ...```This may be well beyond the scope of what is possible with NumPy or Mypy (in which case, this should probably be closed as WONTFIX), but it does present a challenge. As long as one confines oneself to scalars on either side of the comparison, I'm pretty sure `numpy` will never return an array. I don't think that notion is sufficiently captured by the above.### Reproduce the code example:```python# test_comparison.pyimport numpy as npfrom fractions import Fractionassert np.int64(0) < Fraction(1) is True  # type error, but runs okay```### Error message:```shelltest_comparison.py:5: error: No overload variant of ""__call__"" of ""_ComparisonOp"" matches argument type ""Fraction""  [call-overload]test_comparison.py:5: note: Possible overload variants:test_comparison.py:5: note:     def __call__(self, Union[int, float, complex, number[Any], bool_]) -> bool_test_comparison.py:5: note:     def __call__(self, Union[_SupportsArray[dtype[Union[bool_, number[Any]]]], _NestedSequence[_SupportsArray[dtype[Union[bool_, number[Any]]]]], bool, int, float, complex, _NestedSequence[Union[bool, int, float, complex]]]) -> ndarray[Any, dtype[bool_]]Found 1 error in 1 file (checked 1 source file)```### NumPy/Python version information:1.23.0 3.10.5 (main, Jun  7 2022, 08:51:33) [Clang 13.0.0 (clang-1300.0.29.30)]
"
21930,0,464,300,0,0,twoertwein,0,"title:TYP: ndarray is declared to be hashable but it is not hashable description:### Describe the issue:`ndarray` inherits `__hash__` from `object` but the implementation sets `__hash__` to `None`. The type anntoations should reflect that.```pyclass ndarray(...):     # this is also how typeshed declares list as not hashable: https://github.com/python/typeshed/blob/be2921648cc03407c5ddf42374a5afd23f594c24/stdlib/builtins.pyi#L990     __hash__: ClassVar[None]  # type: ignore[assignment]    ...```### Reproduce the code example:```pythonimport numpy as npnp.zeros(1).__hash__ is None  # Truereveal_type(np.zeros(1).__hash__)```### Error message:```shellmypy: ""def () -> builtins.int""pyright: Type of ""np.zeros(1).__hash__"" is ""() -> int""```### NumPy/Python version information:1.23.0
"
21929,1,170,3,0,0,muditbac,0,"title:BUG: np.argmax on map generator returning 0, always  description:### Describe the issue:np.argmax on map/generator returning 0, always. Not sure if this is expected or not. If expected should we return error instead of erogenous result. 0 is misleading### Reproduce the code example:```pythona= [5,4,3,6,34,56,3]import numpy as npnp.argmax(a) # outputs 5np.argmax(map(lambda x: x, a)) # outputs 0np.argmax(list(map(lambda x: x, a))) # outputs 5```### Error message:_No response_### NumPy/Python version information:'1.22.4'
"
21928,0,0,298,0,1,asmeurer,0,"title:BUG: Fix the implementation of numpy.array_api.vecdot description:See https://data-apis.org/array-api/latest/API_specification/generated/signatures.linear_algebra_functions.vecdot.html<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21925,0,0,292,0,1,seberg,0,"title:BUG: Fix subarray to object cast ownership details description:This would be the minimal fix for gh-21911 (and an older issue somewhere).  However, it would also set a precedence that subarray to object casts will create copies.That is likely fine, since those casts usually crashed for a while and in many places a copy is OK.  It was also always broken from an ownership perspective.However, for code that used this and assigned to the result, things would obviously change.There are three options:1. Less-minimal fix, because we want view behavior here (and fix it).2. Keep it as it is (it was so unreliable that failures are hopefully minimal, and why would one *cast* to object to then assign?).3. We could tag on a warning, I don't think the warning ""flag"" is used right now.  I.e. print out a `UserWarning` that this is a copy, but may have been a view whenever the array may be written to.  (This may not be quite reliable for buffer users like cython, but not sure.)
"
21920,0,21,248,0,0,mkoeppe,0,"title:BUG: Build of numpy 1.23.0 fails on debian-stretch description:### Describe the issue:On `debian-stretch` (gcc-6_6.3.0-18+deb9u1_amd64), building numpy 1.23.0 from source fails, see details in https://trac.sagemath.org/ticket/34110#comment:4This is a regression from numpy 1.22.4.### Reproduce the code example:```pythonpip install .```### Error message:_No response_### NumPy/Python version information:1.23.0
"
21917,0,640,272,0,0,takagi,0,"title:`numpy.unique` returns wrong results on float16 ndarrays containing `nan` description:### Describe the issue:With the change in NumPy 1.23 that introduced `equal_nan` parameter, `numpy.unique` seems to wrongly operate on float16 arrays when the arrays have one or more `nan`.```py>>> import numpy as np>>> np.array([2, 1, 2], dtype='e'); np.unique(a)array([1., 2.], dtype=float16)  # Okay>>> a = np.array([2, 1, 2, np.nan], dtype='e'); np.unique(a)array([1.], dtype=float16)  # should be array([1., 2., np.nan])>>> a = np.array([2, 1, 2, np.nan, np.nan], dtype='e'); np.unique(a)array([1.], dtype=float16)  # should be array([1., 2., np.nan])>>> a = np.array([2, 1, 2, np.nan, np.nan], dtype='e'); np.unique(a, equal_nan=False)array([ 1.,  2., nan, nan], dtype=float16)  # Okay```### Reproduce the code example:```pythonimport numpy as npa = np.array([2, 1, 2, np.nan], dtype='e')np.unique(a)```### Error message:```shellarray([1.], dtype=float16)```### NumPy/Python version information:1.23.0 3.10.0 (default, Oct 15 2021, 11:40:42) [GCC 7.5.0]
"
21914,1,275,175,0,0,LaurentRDC,0,"title:BUG: `hstack` / `vstack` / `dstack` returns a different datatype than its inputs for input datatypes >u2, >u4, and >u8 description:### Describe the issue:The functions `numpy.hstack`, `numpy.vstack`, and `numpy.dstack` return an array with a different datatype than its inputs, when the inputs are of certain datatypes. See the example below.This occurs for an iterable of arrays of type `np.dtype('>u2')`, `np.dtype('>u4')`, and `np.dtype('>u8')`, but curiously not for arrays of type `np.dtype('>u1')`### Reproduce the code example:```pythonimport numpy as nparrays = [np.zeros(shape=(2,3,4), dtype=np.dtype('>u2')) for _ in range(3)]first, *_ = arraysprint('Initial dtype: ', first.dtype) # np.dtype('>u2')stacked = np.dstack(arrays)print('Stacked dtype: ', stacked.dtype) # np.dtype('uint16')```### Error message:_No response_### NumPy/Python version information:This bug occurs with at least two versions:numpy=1.22.4 python=3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:58:50) [GCC 10.3.0]numpy=1.23.0 python=3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:58:50) [GCC 10.3.0]
"
21911,0,502,26,0,0,rkishony,0,"title:BUG: Kernel dies upon np.array of a list with mixed custom types description:### Describe the issue:The `np.array()` function causes the kernel to die when operating on a list containing a list and an array with a custom type. ### Reproduce the code example:```pythonimport numpy as npdtype_ = np.dtype([('', np.int32, 2)])arr = np.zeros((3, ), dtype=dtype_)np.array([arr, [1, 2, 3]], dtype=object)```### Error message:```shellIn pycharm, I get Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)```In Juyter Notebook:```Kernel RestartingThe kernel for developer_tools/demos/Untitled.ipynb appears to have died. It will restart automatically.``````### NumPy/Python version information:1.23.0 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:03:09) [Clang 13.0.1 ]
"
21905,0,0,0,0,1,deego,0,"title:DOC: Fix the interpolation formulae for quantile and percentile description:闂傚倸鍊搁崐鎼佸磹閻戣姤鍤勯柛顐ｆ礀绾惧鏌曟繛鐐珔缁炬儳娼￠弻娑樷攽閸℃せ鏋欏┑鐐叉▕娴滄粎绮婚悙鐢电＜鐎瑰壊鍠楅悞?) and percentile().Fix the interpolation formulae in the docs which led to absurd results.  For quantile() and percentile().Example, for median of a = [1,2,10,11], you expect to obtain i+g=2.5 for method = linear (or weibull, or hazen, or median_unbiased or normal_unbiased).Instead, you obtain a /negative/ index.The correted formula is:i + g = q * (n - alpha - beta + 1 ) + alphaNotice among other things that n belongs in the numerator, not the denominator! As a check, the corrected formula does lead to the correct index 2.5 for each of the cases above.MYSTERY: Surely the original formula was the result of a small typo/thinko?  Then, why does the correction look so completely different?RESOLUTION OF MYSTERY: Take our formula, massage it, and swap q with (i+g), and you end up with the original formula.In other words, the original author of the doc. simply confused their percentile with their index halfway through the creation of the doc. Then, they massaged it to isolate (i+g) on the left.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21900,1,457,300,0,0,bmerry,0,"title:BUG: typing doesn't handle type aliases via Python types description:### Describe the issue:numpy 1.20 [encouraged](https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations) specifying plain `bool` as a dtype as an equivalent to `np.bool_`, but these aliases don't behave the same as the explicit numpy versions. mypy infers the dtype as ""Any"" instead. See the example below, where I expected both lines to output the same type.### Reproduce the code example:```pythonimport numpy as npdef what_the() -> None:    reveal_type(np.arange(10, dtype=bool))    reveal_type(np.arange(10, dtype=np.bool_))```### Error message:```shellNo error, but output from mypy 0.961:show_type2.py:4: note: Revealed type is ""numpy.ndarray[Any, numpy.dtype[Any]]""show_type2.py:5: note: Revealed type is ""numpy.ndarray[Any, numpy.dtype[numpy.bool_]]""``````### NumPy/Python version information:1.23.0 3.10.5 (main, Jun 11 2022, 16:53:24) [GCC 9.4.0]
"
21899,1,1103,8,0,0,hugolytics,0,"title:BUG: No module named 'numpy.core._multiarray_umath' on Mac OS 12.4 (21F79), python 3.10.3 description:### Describe the issue:I installed Numpy with poetry in a separate virtualenvWhen I just install everything it works fine.I get this error somewhat randomly, the most consistent is that it happens after a few days of installing.I can resolve the error by deleting the .venv and reinstalling the packages.But the problem resurfaces every few days.I have no problem with this setup on other machines, nor on docker or gitpod.So there is something specific about my setup.### Reproduce the code example:```pythonimport pandas as pd```### Error message:```shellFile "".../src/app/models/submissions.py"", line 31, in <module>    import pandas as pd  File "".../.venv/lib/python3.10/site-packages/pandas/__init__.py"", line 16, in <module>    raise ImportError(ImportError: Unable to import required dependencies:numpy: IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!Importing the numpy C-extensions failed. This error can happen formany reasons, often due to issues with your setup or how NumPy wasinstalled.We have compiled some common reasons and troubleshooting tips at:    https://numpy.org/devdocs/user/troubleshooting-importerror.htmlPlease note and check the following:  * The Python version is: Python3.10 from ""/Users/hugoevers/Library/Mobile Documents/com~apple~CloudDocs/Projecten/VScode projects/CA_data_platform/.venv/bin/python""  * The NumPy version is: ""1.23.0""and make sure that they are the versions you expect.Please carefully study the documentation linked above for further help.Original error was: No module named 'numpy.core._multiarray_umath'```### NumPy/Python version information:  * The Python version is: Python3.10 from "".../.venv/bin/python3""  * The NumPy version is: ""1.23.0""
"
21898,1,707,300,0,0,bmerry,0,"title:BUG: type checking broken with np.sinc description:### Describe the issue:There seems to be something whacky with the type annotations for np.sinc that causes mypy to later think that an array is a boolean array when clearly it is not. See the reproducing code below. This seems to have started with numpy 1.22 (presumably due to the more accuracy dtype annotations). Changing `np.sinc` to `np.sin` or `np.exp` makes the problem disappear, which is why I assume it is specific to `sinc`.### Reproduce the code example:```pythonimport numpy as npdef what_the() -> None:    idx = np.arange(16, dtype=float)    c = idx * np.sinc(idx)    c /= np.sum(c)```### Error message:```shellError message from mypy 0.961:show_type.py:6: error: Invalid self argument ""ndarray[Any, dtype[bool_]]"" to attribute function ""__itruediv__"" with type ""Callable[[ndarray[Any, dtype[floating[_NBit1]]], Union[_SupportsArray[dtype[Union[bool_, integer[Any], floating[Any]]]], _NestedSequence[_SupportsArray[dtype[Union[bool_, integer[Any], floating[Any]]]]], bool, int, float, _NestedSequence[Union[bool, int, float]]]], ndarray[Any, dtype[floating[_NBit1]]]]""```Note the `bool_` on the first line.```### NumPy/Python version information:1.23.0 3.10.5 (main, Jun 11 2022, 16:53:24) [GCC 9.4.0]
"
21897,1,75,0,0,0,huangjun80235,0,"title:BUG: <numpy==1.19.5 5 // np.geomspace(1, 5, 3)=5 2 0> description:### Describe the issue:5 // np.geomspace(1, 5, 3)array([5., 2., 0.])### Reproduce the code example:```pythonimport numpy as np5 // np.geomspace(1, 5, 3)array([5., 2., 0.])```### Error message:_No response_### NumPy/Python version information:numpy==1.19.5
"
21893,1,5038,294,0,0,benbovy,0,"title:BUG: f2py generated signature file and automatic arrays  description:### Describe the issue:Let's consider the following subroutine in a `test.f90` file that declares an automatic array from two variables(*):```f90subroutine test (nx, ny, arr)  implicit none  integer, intent(in) :: nx  integer, intent(in) :: ny  integer, dimension(nx*ny) :: arrreturnend subroutine test```It used to work with numpy 1.22.0 or earlier, despite the `Warning: cross-dependence between variables ""ny"" and ""nx""` and the weird shape checks as shown in the generated `test.pyf` signature file below:```f90!    -*- f90 -*-! Note: the context of this file is case sensitive.python module test ! in     interface  ! in :test        subroutine test(nx,ny,arr) ! in :test:src/test.f90            integer, optional,intent(in),check(shape(arr, 0) == nx * ny),depend(ny,arr) :: nx=shape(arr, 0) / nx            integer, optional,intent(in),check(shape(arr, 0) == nx * ny),depend(nx,arr) :: ny=shape(arr, 0) / nx            integer dimension(nx * ny) :: arr        end subroutine test    end interface end python module test! This file was auto-generated with f2py (version:1.22.0).! See:! https://web.archive.org/web/20140822061353/http://cens.ioc.ee/projects/f2py2e```However, with numpy 1.22.1 or later, it generates a `test.pyf` with ""swapped"" nx / ny:```f90!    -*- f90 -*-! Note: the context of this file is case sensitive.python module test ! in     interface  ! in :test        subroutine test(nx,ny,arr) ! in :test:src/test.f90            integer, optional,intent(in),check(shape(arr, 0) == nx * ny),depend(ny,arr) :: nx=shape(arr, 0) / ny            integer, optional,intent(in),check(shape(arr, 0) == nx * ny),depend(arr,nx) :: ny=shape(arr, 0) / nx            integer dimension(nx * ny) :: arr        end subroutine test    end interface end python module test! This file was auto-generated with f2py (version:1.22.1).! See:! https://web.archive.org/web/20140822061353/http://cens.ioc.ee/projects/f2py2e```Which causes the following recursion error when trying to generate the Python extension from the signature file:```Reading fortran codes...        Reading file 'test.pyf' (format:free)Post-processing...        Block: test                        Block: testTraceback (most recent call last):  File ""/Users/me/env/bin/f2py"", line 8, in <module>    sys.exit(main())  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/f2py2e.py"", line 693, in main    run_main(sys.argv[1:])  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/f2py2e.py"", line 430, in run_main    postlist = callcrackfortran(files, options)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/f2py2e.py"", line 333, in callcrackfortran    postlist = crackfortran.crackfortran(files)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 3209, in crackfortran    postlist = postcrack(grouplist[0])  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 1926, in postcrack    g = postcrack(g, tab=tab + '\t')  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 1945, in postcrack    block['body'] = analyzebody(block, args, tab=tab)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2107, in analyzebody    b = postcrack(b, as_, tab=tab + '\t')  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 1945, in postcrack    block['body'] = analyzebody(block, args, tab=tab)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2107, in analyzebody    b = postcrack(b, as_, tab=tab + '\t')  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 1941, in postcrack    block['vars'] = analyzevars(block)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2458, in analyzevars    params = get_parameters(vars, get_useparameters(block))  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2329, in get_parameters    for n in get_sorted_names(vars):  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2257, in get_sorted_names    depend_dict = _calc_depend_dict(vars)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2250, in _calc_depend_dict    _get_depend_dict(n, vars, depend_dict)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2236, in _get_depend_dict    or _get_depend_dict(word, vars, deps):  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2236, in _get_depend_dict    or _get_depend_dict(word, vars, deps):  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2236, in _get_depend_dict    or _get_depend_dict(word, vars, deps):  [Previous line repeated 979 more times]  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2228, in _get_depend_dict    if '=' in vars[name] and not isstring(vars[name]):  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/auxfuncs.py"", line 77, in isstring    return _isstring(var) and not isarray(var)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/auxfuncs.py"", line 72, in _isstring    return 'typespec' in var and var['typespec'] == 'character' and \RecursionError: maximum recursion depth exceeded in comparison```The difference between the two generated signature files seems to be a result of #20721.(*) Do you think the issue here could be considered as a regression? Or is the example here wrong and we should not declare dimensions of automatic arrays from two or more variables? Not sure about this as I'm not a Fortran expert and haven't found much info about this practice, although I'd be surprised that compilers let us do it if it wasn't valid. ### Reproduce the code example:```pythonsee f90 / pyf source above```### Error message:```shellSee recursion error above.```### NumPy/Python version information:Numpy 1.22.0 / 1.22.1Python 3.9
"
21892,0,5007,294,0,0,benbovy,0,"title:BUG: f2py generated signature file and automatic arrays  description:### Describe the issue:Let's consider the following subroutine in a `test.f90` file that declares an automatic array from two variables(*):```f90subroutine test (nx, ny, arr)  implicit none  integer, intent(in) :: nx  integer, intent(in) :: ny  integer, dimension(nx*ny) :: arrreturnend subroutine test```It used to work with numpy 1.22.0 or earlier, despite the `Warning: cross-dependence between variables ""ny"" and ""nx""` and the weird shape checks as shown in the generated `test.pyf` signature file below:```f90!    -*- f90 -*-! Note: the context of this file is case sensitive.python module test ! in     interface  ! in :test        subroutine test(nx,ny,arr) ! in :test:src/test.f90            integer, optional,intent(in),check(shape(arr, 0) == nx * ny),depend(ny,arr) :: nx=shape(arr, 0) / nx            integer, optional,intent(in),check(shape(arr, 0) == nx * ny),depend(nx,arr) :: ny=shape(arr, 0) / nx            integer dimension(nx * ny) :: arr        end subroutine test    end interface end python module test! This file was auto-generated with f2py (version:1.22.0).! See:! https://web.archive.org/web/20140822061353/http://cens.ioc.ee/projects/f2py2e```However, with numpy 1.22.1 or later, it generates a `test.pyf` with ""swapped"" nx / ny:```f90!    -*- f90 -*-! Note: the context of this file is case sensitive.python module test ! in     interface  ! in :test        subroutine test(nx,ny,arr) ! in :test:src/test.f90            integer, optional,intent(in),check(shape(arr, 0) == nx * ny),depend(ny,arr) :: nx=shape(arr, 0) / ny            integer, optional,intent(in),check(shape(arr, 0) == nx * ny),depend(arr,nx) :: ny=shape(arr, 0) / nx            integer dimension(nx * ny) :: arr        end subroutine test    end interface end python module test! This file was auto-generated with f2py (version:1.22.1).! See:! https://web.archive.org/web/20140822061353/http://cens.ioc.ee/projects/f2py2e```Which causes the following recursion error when trying to generate the Python extension from the signature file:```Reading fortran codes...        Reading file 'test.pyf' (format:free)Post-processing...        Block: test                        Block: testTraceback (most recent call last):  File ""/Users/me/env/bin/f2py"", line 8, in <module>    sys.exit(main())  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/f2py2e.py"", line 693, in main    run_main(sys.argv[1:])  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/f2py2e.py"", line 430, in run_main    postlist = callcrackfortran(files, options)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/f2py2e.py"", line 333, in callcrackfortran    postlist = crackfortran.crackfortran(files)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 3209, in crackfortran    postlist = postcrack(grouplist[0])  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 1926, in postcrack    g = postcrack(g, tab=tab + '\t')  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 1945, in postcrack    block['body'] = analyzebody(block, args, tab=tab)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2107, in analyzebody    b = postcrack(b, as_, tab=tab + '\t')  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 1945, in postcrack    block['body'] = analyzebody(block, args, tab=tab)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2107, in analyzebody    b = postcrack(b, as_, tab=tab + '\t')  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 1941, in postcrack    block['vars'] = analyzevars(block)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2458, in analyzevars    params = get_parameters(vars, get_useparameters(block))  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2329, in get_parameters    for n in get_sorted_names(vars):  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2257, in get_sorted_names    depend_dict = _calc_depend_dict(vars)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2250, in _calc_depend_dict    _get_depend_dict(n, vars, depend_dict)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2236, in _get_depend_dict    or _get_depend_dict(word, vars, deps):  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2236, in _get_depend_dict    or _get_depend_dict(word, vars, deps):  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2236, in _get_depend_dict    or _get_depend_dict(word, vars, deps):  [Previous line repeated 979 more times]  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/crackfortran.py"", line 2228, in _get_depend_dict    if '=' in vars[name] and not isstring(vars[name]):  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/auxfuncs.py"", line 77, in isstring    return _isstring(var) and not isarray(var)  File ""/Users/me/env/lib/python3.9/site-packages/numpy/f2py/auxfuncs.py"", line 72, in _isstring    return 'typespec' in var and var['typespec'] == 'character' and \RecursionError: maximum recursion depth exceeded in comparison```The difference between the two generated signature files seems to be a result of #20721.(*) Do you think the issue here could be considered as a regression? Or is the example here wrong and we should not declare dimensions of automatic arrays from two or more variables? Not sure about this as I'm not a Fortran expert and haven't found much info about this practice, although I'd be surprised that compilers let us do it if it wasn't valid. ### Reproduce the code example:```python# see f90 / pyf source above```### Error message:_No response_### NumPy/Python version information:Numpy 1.22.0 / 1.22.1Python 3.9
"
21890,0,0,291,0,1,HaoZeke,0,"title:BUG: Fix KeyError in crackfortran operator support description:Closes #21889 by simply using the safer `.get()` variant which returns `None` instead of a `KeyError`. This in turn allows the rest of the check to pass due to `not None` evaluating to `True` and keeping the rest of the intended logic.Note that there isn't actually any handling of `operator()` or even `implementedby` in the rest of F2PY yet (it was an enhancement done for `sphinx-fortran` I think).
"
21889,0,1808,296,0,0,bnavigator,0,"title:BUG: f2py crackfortran: missing dict key 'implementedby' description:### Describe the issue:We have a user report at https://github.com/python-control/Slycot/issues/177 who tried to build Slycot with NumPy 1.23.0 which fails with the f2py error below.Using a system NumPy 1.21.5  or `pip install 'numpy<1.23.0' scikit-build; pip install -v --no-build-isolation slycot` does not throw the error.### Reproduce the code example:```pythondocker container run -it ubuntu bash# in docker container:apt updateapt install python3 python3-dev gcc gfortran libopenblas-dev python3-pip cmakepip install -v slycot```### Error message:```shellTraceback (most recent call last):    File ""/usr/local/bin/f2py3"", line 8, in <module>      sys.exit(main())    File ""/tmp/pip-build-env-ve213n4q/overlay/local/lib/python3.10/dist-packages/numpy/f2py/f2py2e.py"", line 704, in main      run_main(sys.argv[1:])    File ""/tmp/pip-build-env-ve213n4q/overlay/local/lib/python3.10/dist-packages/numpy/f2py/f2py2e.py"", line 441, in run_main      postlist = callcrackfortran(files, options)    File ""/tmp/pip-build-env-ve213n4q/overlay/local/lib/python3.10/dist-packages/numpy/f2py/f2py2e.py"", line 342, in callcrackfortran      postlist = crackfortran.crackfortran(files)    File ""/tmp/pip-build-env-ve213n4q/overlay/local/lib/python3.10/dist-packages/numpy/f2py/crackfortran.py"", line 3265, in crackfortran      postlist = postcrack(grouplist[0])    File ""/tmp/pip-build-env-ve213n4q/overlay/local/lib/python3.10/dist-packages/numpy/f2py/crackfortran.py"", line 1967, in postcrack      g = postcrack(g, tab=tab + '\t')    File ""/tmp/pip-build-env-ve213n4q/overlay/local/lib/python3.10/dist-packages/numpy/f2py/crackfortran.py"", line 1986, in postcrack      block['body'] = analyzebody(block, args, tab=tab)    File ""/tmp/pip-build-env-ve213n4q/overlay/local/lib/python3.10/dist-packages/numpy/f2py/crackfortran.py"", line 2150, in analyzebody      not b['body'] and not b['implementedby']:  KeyError: 'implementedby'  gmake[2]: *** [slycot/CMakeFiles/_wrapper.dir/build.make:79: slycot/_wrappermodule.c] Error 1  gmake[1]: *** [CMakeFiles/Makefile2:170: slycot/CMakeFiles/_wrapper.dir/all] Error 2  gmake: *** [Makefile:136: all] Error 2```### NumPy/Python version information:1.23.0 3.10.4 (main, Apr  2 2022, 09:04:19) [GCC 11.2.0]
"
21883,0,400,294,0,0,mdickinson,0,"title:BUG: numpy.ndarray.__deepcopy__ returned a result with an exception set description:### Describe the issue:It looks as though there's a code path in which `ndarray.__deepcopy__` sets an exception but fails to return `NULL`, confusing Python as a result. This was reported upstream on the CPython bug tracker at https://github.com/python/cpython/issues/94390, but looks as though it's likely a problem with NumPy.#8706 looks relevant here. Specifically, I suspect that `itemp` is `NULL` in [this](https://github.com/numpy/numpy/blob/4d057e633408c04c15292ccc9cd11d96e33a90f5/numpy/core/src/multiarray/methods.c#L1636) call, resulting in the `PyObject_CallFunctionObjArgs` argument list being cut short.I wasn't able to reproduce with an empty array of dtype object created directly with `np.empty`; it's not clear to me when such an array gets filled with NULLs and when it gets filled with pointers to `Py_None`.### Reproduce the code example:```pythonimport numpy as npnp.empty_like([slice(3)]).__deepcopy__({})```### Error message:```shellTypeError: deepcopy() missing 1 required positional argument: 'x'The above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>SystemError: <method '__deepcopy__' of 'numpy.ndarray' objects> returned a result with an exception set```### NumPy/Python version information:1.22.4 3.10.5 (main, Jun  7 2022, 08:51:33) [Clang 13.0.0 (clang-1300.0.29.30)]
"
21878,1,533,0,0,0,Alazia,0,"title:BUG: Does np.cumsum() have a maximum limit闂?""### Describe the issue:```python import matplotlib.pyplot as pltimport numpy as npnp.random.seed(0)nums=np.random.randint(10000 description:1000000"
21810,0,0,275,0,1,charris,0,"title:BUG: lib: A loadtxt error message had two values reversed. description:Backport of #29794.Fix the reversed arguments to the call of PyErr_Format() that generatesthe exception for an invalid index in usecols.Also fix the format characters in several other calls of PyErr_Format()where the arguments are Py_ssize_t.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21807,0,0,291,0,0,HaoZeke,0,"title:ENH: Handle the value attribute in F2Py wrappers description:Closes #21665. The implementation essentially takes advantage of the existing machinery which is very similar to the handling of `intent(c)`.This should cover everything which is allowed by the standard since:> Character values, substrings, assumed-size arrays, and adjustable arrays cannot be passed by value. [[source](https://www.intel.com/content/www/us/en/develop/documentation/fortran-compiler-oneapi-dev-guide-and-reference/top/language-reference/a-to-z-reference/a-to-b/attributes/attributes-reference-and-value.html)]Might need a release note, but then again maybe not.
"
21806,1,2554,0,0,0,Mocchaso,0,"title:Numpy building error: gcc: build/src.linux-x86_64-3.10/numpy/core/src/umath/loops.c description:I'm trying to install Numpy v1.22.4 via `pip`, next via compiling source code.  I encountered below error when I executed `$ python setup.py build`.```error: Command ""gcc -pthread -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -fPIC -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DHAVE_CBLAS -DNO_ATLAS_INFO=-1 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/umath -Inumpy/core/include -Ibuild/src.linux-x86_64-3.10/numpy/core/include/numpy -Ibuild/src.linux-x86_64-3.10/numpy/distutils/include -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/src/_simd -I/var/www/project/my-product/.venv/include -I/usr/local/include/python3.10 -Ibuild/src.linux-x86_64-3.10/numpy/core/src/common -Ibuild/src.linux-x86_64-3.10/numpy/core/src/npymath -c build/src.linux-x86_64-3.10/numpy/core/src/umath/loops.c -o build/temp.linux-x86_64-cpython-310/build/src.linux-x86_64-3.10/numpy/core/src/umath/loops.o -MMD -MF build/temp.linux-x86_64-cpython-310/build/src.linux-x86_64-3.10/numpy/core/src/umath/loops.o.d -msse -msse2 -msse3"" failed with exit status 1```<br>I recently posted a question about this error on StackOverflow.  *Ref: https://stackoverflow.com/questions/72518989/numpy-building-error-gcc-build-src-linux-x86-64-3-10-numpy-core-src-umath-loop  *`The things I tried`, `My development environment information`, `Commands I executed` are described on this question.I received the following comment there.```Ok, so your processor does not support AVX-512 (but it support AVX-2 so it would be a good idea to add it using -mavx2 compilation flag). This means that something is built with the support of AVX-512 and then the GCC assembler complains because it is unexpected (the compiler generated AVX-512 assembly instructions). Assuming the problem does not comes from Numpy (the 1.22.4 should be quite stable now), it may be due to a dependent library compiled with AVX-512 (eg. glibc, libm, etc.), some bad old files compiled for AVX-512 that are still in a cache, etc. Hard to say more about this.```I'm continuing my investigation in accordance with above comment, but I cannot find out how to investigate about this.Could you please tell me how to investigate about this error and AVX-512? # Remarks* Entire execution log of `$ python setup.py build`: [build_log.txt](https://github.com/numpy/numpy/files/8948807/build_log.txt)  *I extracted this log by executing `$ python setup.py build 2>&1 | tee build_log.txt`* Then I executed the following commands, but all with almost identical results.  * Cleaning caches.    ```    $ sudo yum clean all    $ pip cache purge    ```  * Changing arguments of `$ python setup.py build`.    Ref: https://numpy.org/devdocs/reference/simd/build-options.html    ```    $ python setup.py build --cpu-baseline=""avx2 fma3"" install --user        $ python setup.py build --cpu-baseline=""native"" bdist    $ python setup.py build --cpu-baseline=native --cpu-dispatch=none bdist    $ python setup.py build --cpu-baseline=""avx f16c"" bdist        $ python setup.py build --cpu-baseline=""vsx2"" bdist            $ python setup.py build --cpu-dispatch=""max -avx512f -avx512cd \    -avx512_knl -avx512_knm -avx512_skx -avx512_clx -avx512_cnl -avx512_icl"" \    bdist        $ NPY_DISABLE_SVML=1 python setup.py build --cpu-dispatch=""max -avx512f -avx512cd \    -avx512_knl -avx512_knm -avx512_skx -avx512_clx -avx512_cnl -avx512_icl"" bdist        $ python setup.py build --cpu-baseline=""native"" --cpu-dispatch=""none""    ```
"
21802,0,12518,281,0,0,tacaswell,0,"title:Compilation failure with py311 (and py312) on OSX 12.4 with M1 description:macOS 12.4, Xcode 3.12```% clang --versionApple clang version 13.1.6 (clang-1316.0.21.2.5)Target: arm64-apple-darwin21.5.0Thread model: posixInstalledDir: /Library/Developer/CommandLineTools/usr/bin% python --versionPython 3.11.0b3+```Built Python from source on top of home-brew .I strongly suspect that is is actually a bug in CPython, but am starting here in the hopes that @serge-sans-paille can identify a more minimal example to go to upstream with.-----```     creating build/temp.macosx-12.4-arm64-3.11/numpy/core/src/npysort      INFO: compile options: '-DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/src/multiarray -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/src/common -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/src/umath -Inumpy/core/include -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/include/numpy -Ibuild/src.macosx-12.4-arm64-3.11/numpy/distutils/include -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/src/npysort -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/src/_simd -I/Users/tcaswell/.virtualenvs/bleeding/include -I/Users/tcaswell/.pybuild/bleeding/include/python3.11 -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/src/common -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/src/npymath -c'      extra options: '-I/System/Library/Frameworks/vecLib.framework/Headers -std=c++11 -D__STDC_VERSION__=0 -fno-exceptions -fno-rtti'      INFO: g++: numpy/core/src/npysort/mergesort.cpp      INFO: g++: numpy/core/src/npysort/quicksort.cpp      INFO: g++: numpy/core/src/npysort/timsort.cpp      INFO: g++: numpy/core/src/npysort/heapsort.cpp      INFO: g++: numpy/core/src/npysort/radixsort.cpp      INFO: g++: numpy/core/src/npysort/binsearch.cpp      INFO: g++: numpy/core/src/multiarray/textreading/tokenize.cpp      INFO: g++: numpy/core/src/npysort/selection.cpp      INFO: g++: numpy/core/src/umath/clip.cpp      In file included from numpy/core/src/npysort/selection.cpp:18:      In file included from numpy/core/include/numpy/npy_math.h:8:      In file included from numpy/core/include/numpy/npy_common.h:5:      In file included from /Users/tcaswell/.pybuild/bleeding/include/python3.11/Python.h:38:      In file included from /Users/tcaswell/.pybuild/bleeding/include/python3.11/pyport.h:27:      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:56:1: error: templates must have C++ linkage      template <class _Tp> struct __libcpp_is_integral                     { enum { value = 0 }; };      ^~~~~~~~~~~~~~~~~~~~      numpy/core/include/numpy/npy_math.h:5:1: note: extern ""C"" language linkage specification begins here      extern ""C"" {      ^      In file included from numpy/core/src/npysort/selection.cpp:18:      In file included from numpy/core/include/numpy/npy_math.h:8:      In file included from numpy/core/include/numpy/npy_common.h:5:      In file included from /Users/tcaswell/.pybuild/bleeding/include/python3.11/Python.h:38:      In file included from /Users/tcaswell/.pybuild/bleeding/include/python3.11/pyport.h:27:      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:57:29: error: explicit specialization of undeclared template struct '__libcpp_is_integral'      template <>          struct __libcpp_is_integral<bool>               { enum { value = 1 }; };                                  ^                   ~~~~~~      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:58:29: error: explicit specialization of non-template struct '__libcpp_is_integral'      template <>          struct __libcpp_is_integral<char>               { enum { value = 1 }; };                                  ^                   ~~~~~~      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:58:29: error: redefinition of '__libcpp_is_integral'      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:57:29: note: previous definition is here      template <>          struct __libcpp_is_integral<bool>               { enum { value = 1 }; };                                  ^      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:59:29: error: explicit specialization of non-template struct '__libcpp_is_integral'      template <>          struct __libcpp_is_integral<signed char>        { enum { value = 1 }; };                                  ^                   ~~~~~~~~~~~~~      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:59:29: error: redefinition of '__libcpp_is_integral'      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:57:29: note: previous definition is here      template <>          struct __libcpp_is_integral<bool>               { enum { value = 1 }; };                                  ^      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:60:29: error: explicit specialization of non-template struct '__libcpp_is_integral'      template <>          struct __libcpp_is_integral<unsigned char>      { enum { value = 1 }; };                                  ^                   ~~~~~~~~~~~~~~~      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:60:29: error: redefinition of '__libcpp_is_integral'      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:57:29: note: previous definition is here      template <>          struct __libcpp_is_integral<bool>               { enum { value = 1 }; };                                  ^      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:62:29: error: explicit specialization of non-template struct '__libcpp_is_integral'      template <>          struct __libcpp_is_integral<wchar_t>            { enum { value = 1 }; };                                  ^                   ~~~~~~~~~      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:62:29: error: redefinition of '__libcpp_is_integral'      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:57:29: note: previous definition is here      template <>          struct __libcpp_is_integral<bool>               { enum { value = 1 }; };                                  ^      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:68:29: error: explicit specialization of non-template struct '__libcpp_is_integral'      template <>          struct __libcpp_is_integral<char16_t>           { enum { value = 1 }; };                                  ^                   ~~~~~~~~~~      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:68:29: error: redefinition of '__libcpp_is_integral'      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:57:29: note: previous definition is here      template <>          struct __libcpp_is_integral<bool>               { enum { value = 1 }; };                                  ^      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:69:29: error: explicit specialization of non-template struct '__libcpp_is_integral'      template <>          struct __libcpp_is_integral<char32_t>           { enum { value = 1 }; };                                  ^                   ~~~~~~~~~~      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:69:29: error: redefinition of '__libcpp_is_integral'      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:57:29: note: previous definition is here      template <>          struct __libcpp_is_integral<bool>               { enum { value = 1 }; };                                  ^      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:71:29: error: explicit specialization of non-template struct '__libcpp_is_integral'      template <>          struct __libcpp_is_integral<short>              { enum { value = 1 }; };                                  ^                   ~~~~~~~      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:71:29: error: redefinition of '__libcpp_is_integral'      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:57:29: note: previous definition is here      template <>          struct __libcpp_is_integral<bool>               { enum { value = 1 }; };                                  ^      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:72:29: error: explicit specialization of non-template struct '__libcpp_is_integral'      template <>          struct __libcpp_is_integral<unsigned short>     { enum { value = 1 }; };                                  ^                   ~~~~~~~~~~~~~~~~      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:72:29: error: redefinition of '__libcpp_is_integral'      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:57:29: note: previous definition is here      template <>          struct __libcpp_is_integral<bool>               { enum { value = 1 }; };                                  ^      /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/cstddef:73:29: error: explicit specialization of non-template struct '__libcpp_is_integral'      template <>          struct __libcpp_is_integral<int>                { enum { value = 1 }; };                                  ^                   ~~~~~      fatal error: too many errors emitted, stopping now [-ferror-limit=]      20 errors generated.      INFO: g++: numpy/core/src/umath/string_ufuncs.cpp      error: Command ""g++ -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/opt/homebrew/opt/openblas/include -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/src/multiarray -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/src/common -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/src/umath -Inumpy/core/include -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/include/numpy -Ibuild/src.macosx-12.4-arm64-3.11/numpy/distutils/include -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/src/npysort -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -Inumpy/core/src/_simd -I/Users/tcaswell/.virtualenvs/bleeding/include -I/Users/tcaswell/.pybuild/bleeding/include/python3.11 -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/src/common -Ibuild/src.macosx-12.4-arm64-3.11/numpy/core/src/npymath -c numpy/core/src/npysort/selection.cpp -o build/temp.macosx-12.4-arm64-3.11/numpy/core/src/npysort/selection.o -MMD -MF build/temp.macosx-12.4-arm64-3.11/numpy/core/src/npysort/selection.o.d -I/System/Library/Frameworks/vecLib.framework/Headers -std=c++11 -D__STDC_VERSION__=0 -fno-exceptions -fno-rtti"" failed with exit status 1      INFO:      ########### EXT COMPILER OPTIMIZATION ###########      INFO: Platform      :        Architecture: aarch64        Compiler    : gcc            CPU baseline  :        Requested   : 'min'        Enabled     : NEON NEON_FP16 NEON_VFPV4 ASIMD        Flags       : none        Extra checks: none            CPU dispatch  :        Requested   : 'max -xop -fma4'        Enabled     : ASIMDHP ASIMDDP ASIMDFHM        Generated   : none      INFO: CCompilerOpt.cache_flush[857] : write cache to path -> /Users/tcaswell/source/p/numpy/numpy/build/temp.macosx-12.4-arm64-3.11/ccompiler_opt_cache_ext.py      INFO:      ########### CLIB COMPILER OPTIMIZATION ###########      INFO: Platform      :        Architecture: aarch64        Compiler    : gcc            CPU baseline  :        Requested   : 'min'        Enabled     : NEON NEON_FP16 NEON_VFPV4 ASIMD        Flags       : none        Extra checks: none            CPU dispatch  :        Requested   : 'max -xop -fma4'        Enabled     : ASIMDHP ASIMDDP ASIMDFHM        Generated   : none      INFO: CCompilerOpt.cache_flush[857] : write cache to path -> /Users/tcaswell/source/p/numpy/numpy/build/temp.macosx-12.4-arm64-3.11/ccompiler_opt_cache_clib.py      [end of output]```
"
21796,0,0,12,0,1,postmalloc,0,"title:BUG: Fix comparison for empty structured arrays description:Fixes #21739When empty structured arrays with nontrivially shaped fields arecompared, the reshape operation invoked fails. Instead of reshapingusing -1, computing the new dimension manually solves the problem. 
"
21795,0,0,293,0,0,hmaarrfk,0,"title:ENH: Ensure that assertion of unsigned dtypes does not return results description:that wrapped around.Closes #21768- Alternatively, this can be recast as a `DEV`, or `MAINT` PR.- If you could point me to other tests or the text, I'm glad to add one.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21794,0,0,271,0,1,WarrenWeckesser,0,"title:BUG: lib: A loadtxt error message had two values reversed. description:Fix the reversed arguments to the call of PyErr_Format() that generatesthe exception for an invalid index in usecols.Also fix the format characters in several other calls of PyErr_Format()where the arguments are Py_ssize_t.
"
21784,1,985,265,0,0,mroeschke,0,"title:BUG?: `.fill(np.nan)`an `int64` array raises ValueError on main description:### Describe the issue:We're seeing a change filling a 0-len int64 array on our numpy dev build in pandas: https://github.com/pandas-dev/pandas/runs/6919574372?check_suite_focus=trueIs this an intended change?Maybe related to https://github.com/numpy/numpy/pull/21437### Reproduce the code example:```pythonIn [2]: import numpy as npIn [3]: np.__version__Out[3]: '1.22.4'In [4]: subarr = np.empty(0, dtype=np.dtype(""int64""))In [5]: subarr.fill(np.nan)In [6]: subarrOut[6]: array([], dtype=int64)```vs ```pythonIn [1]: np.__version__Out[1]: '1.24.0.dev0+270.g0eb6865d2'In [2]: subarr = np.empty(0, dtype=np.dtype(""int64""))In [3]: subarr.fill(np.nan)---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)Input In [3], in <cell line: 1>()----> 1 subarr.fill(np.nan)ValueError: cannot convert float NaN to integer```### Error message:```shell---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)Input In [3], in <cell line: 1>()----> 1 subarr.fill(np.nan)ValueError: cannot convert float NaN to integer```### NumPy/Python version information:```In [1]: np.__version__Out[1]: '1.24.0.dev0+270.g0eb6865d2'```(Python 3.9.12 if that matters)
"
21770,0,824,252,0,0,mhvk,0,"title:BUG: MaskedArray with bytes dtype cannot be compared if fill_value is set description:### Describe the issue:Astropy is having a number of test failures as a result of #21041. Some are just due to the new `FutureWarning`, which are fine. But some are due to something rather strange - that `MaskedArray` comparisons depend on whether `fill_value` is set.### Reproduce the code example:```pythonimport numpy as npma = np.ma.MaskedArray(['a', 'b'])ma > ma# masked_array(data=[False, False],#              mask=False,#        fill_value=True)ma# masked_array(data=['a', 'b'],#              mask=False,#        fill_value='N/A',#             dtype='<U1')ma > ma# ---------------------------------------------------------------------------# TypeError                                 Traceback (most recent call last)# Input In [6], in <cell line: 1>()# ----> 1 ma > ma# TypeError: '>' not supported between instances of 'MaskedArray' and 'MaskedArray'The real problem in the above is that showing `ma` actually sets its `_fill_value` and that somehow causes problems. (Explicitly setting `._fill_value` also gives a `TypeError` - and in `astropy` it is explicitly set.)```ma._fill_value = Nonema > ma# masked_array(data=[False, False],#              mask=False,#        fill_value=True)``````### Error message:_No response_### NumPy/Python version information:1.24.0.dev0+185.g4cb688938 3.10.5 (main, Jun  8 2022, 09:26:22) [GCC 11.3.0]
"
21768,0,1932,293,0,0,hmaarrfk,0,"title:BUG: assert_allclose dot not report correct metrics when unsigned integer overflow happens description:### Describe the issue:Comparing two unsigned integers seems to be correct using `assert_allclose` though the subsequent metrics reported do not take into account potential wrap around.```pythonimport numpy as npfrom numpy.testing import assert_allclosea = np.asarray((10, 10), dtype='uint8')b = np.asarray((9, 14), dtype='uint8')assert_allclose(a, b, atol=5)  # Worksassert_allclose(a, b, atol=3)  # fails with the wrong metrics```Reports:```AssertionError:Not equal to tolerance rtol=1e-07, atol=3Mismatched elements: 1 / 2 (50%)Max absolute difference: 252Max relative difference: 18. x: array([10, 10], dtype=uint8) y: array([ 9, 14], dtype=uint8)```WIth a `Max absolute difference: 252`. However, the maximum absolute difference is `4`.### Reproduce the code example:```pythonimport numpy as npfrom numpy.testing import assert_allclosea = np.asarray((10, 10), dtype='uint8')b = np.asarray((9, 14), dtype='uint8')assert_allclose(a, b, atol=5)  # Worksassert_allclose(a, b, atol=3)  # fails with the wrong metrics```### Error message:```shell---------------------------------------------------------------------------AssertionError                            Traceback (most recent call last)<ipython-input-5-544491560568> in <cell line: 6>()      4 b = np.asarray((9, 14), dtype='uint8')      5 assert_allclose(a, b, atol=5)  # Works----> 6 assert_allclose(a, b, atol=3)  # fails with the wrong metrics    [... skipping hidden 1 frame]~/mambaforge/envs/mcam_dev/lib/python3.9/site-packages/numpy/testing/_private/utils.py in assert_array_compare(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)    842                                 verbose=verbose, header=header,    843                                 names=('x', 'y'), precision=precision)--> 844             raise AssertionError(msg)    845     except ValueError:    846         import tracebackAssertionError:Not equal to tolerance rtol=1e-07, atol=3Mismatched elements: 1 / 2 (50%)Max absolute difference: 252Max relative difference: 18. x: array([10, 10], dtype=uint8) y: array([ 9, 14], dtype=uint8)``````### NumPy/Python version information:1.21.6 3.9.13 (main, Jun  6 2022, 07:35:46)[GCC 10.3.0]
"
21764,0,0,59,0,1,LostBenjamin,0,"title:BUG: Fix a potential variable misuse bug description:Hi,This pull request is a fix to a potential variable misuse bug at `numpy/distutils/misc_util.py`. Please check the changes.Best,Jingxuan
"
21761,0,0,275,0,1,charris,0,"title:BUG: Fix small reference leaks found with pytest-leaks description:Backport of #21759.This fixes a few small issues found with pytest-leaks. The remaining issues (many) seem either related to fixtures (pytest-leaks needs some fixes to clean up after pytest better), or related to dynamic compilation.There are a lot of ""leaks"" reported in the f2py tests, but I expect they are also just similar problems, so ignoring them. (Since valgrind did not report them, these are unlikely to be serious memory leaks anyway.)<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21759,0,0,292,0,1,seberg,0,"title:BUG: Fix small reference leaks found with pytest-leaks description:This fixes a few small issues found with pytest-leaks.  The remaining issues (many) seem either related to fixtures (pytest-leaks needs some fixes to clean up after pytest better), or related to dynamic compilation.There are a lot of ""leaks"" reported in the f2py tests, but I expect they are also just similar problems, so ignoring them.  (Since valgrind did not report them, these are unlikely to be serious memory leaks anyway.)
"
21757,0,0,275,1,1,charris,0,"title:BUG: Do not skip value-based promotion path for large Python integers description:When we have:1. Only Python scalars (int, float, complex) as inputs2. One of the integers is too large for the default integer dtypeThe ""new"" promotion path (which existed for a long time internally!)would not produce the same result as the legacy value-based path.However, my logic failed to check for the second part, so it did notrun the legacy path in this odd little case.This fixes the issue reported in:https://github.com/numpy/numpy/issues/13754#issuecomment-1155126639<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21756,1,2142,283,0,0,larsoner,0,"title:BUG: linalg.svd broken on M1 / arm64 description:### Describe the issue:SVD ""fails to converge"". Same thing happens when I uses `scipy.linalg.svd` regardless of whether I use `lapack_driver='gesvd'` or `lapack_driver='gesdd'`.Likely an OpenBLAS issue as I have:```/Users/larsoner/opt/miniconda3/envs/mne//lib/libopenblasp-r0.3.20.dylib```as the BLAS lib.### Reproduce the code example:```pythonimport numpy as npx = np.ones((41, 50))np.linalg.svd(x)```### Error message:```shell** On entry to DLASCL parameter number  4 had an illegal value ** On entry to DLASCL parameter number  4 had an illegal valueTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""<__array_function__ internals>"", line 5, in svd  File ""/Users/larsoner/opt/miniconda3/envs/mne/lib/python3.10/site-packages/numpy/linalg/linalg.py"", line 1660, in svd    u, s, vh = gufunc(a, signature=signature, extobj=extobj)  File ""/Users/larsoner/opt/miniconda3/envs/mne/lib/python3.10/site-packages/numpy/linalg/linalg.py"", line 97, in _raise_linalgerror_svd_nonconvergence    raise LinAlgError(""SVD did not converge"")numpy.linalg.LinAlgError: SVD did not converge```### NumPy/Python version information:```1.21.6 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:39:37) [Clang 12.0.1 ]```Also:```>>> np.show_config()blas_info:    libraries = ['cblas', 'blas', 'cblas', 'blas']    library_dirs = ['/Users/larsoner/opt/miniconda3/envs/mne/lib']    include_dirs = ['/Users/larsoner/opt/miniconda3/envs/mne/include']    language = c    define_macros = [('HAVE_CBLAS', None)]blas_opt_info:    define_macros = [('NO_ATLAS_INFO', 1), ('HAVE_CBLAS', None)]    libraries = ['cblas', 'blas', 'cblas', 'blas']    library_dirs = ['/Users/larsoner/opt/miniconda3/envs/mne/lib']    include_dirs = ['/Users/larsoner/opt/miniconda3/envs/mne/include']    language = clapack_info:    libraries = ['lapack', 'blas', 'lapack', 'blas']    library_dirs = ['/Users/larsoner/opt/miniconda3/envs/mne/lib']    language = f77lapack_opt_info:    libraries = ['lapack', 'blas', 'lapack', 'blas', 'cblas', 'blas', 'cblas', 'blas']    library_dirs = ['/Users/larsoner/opt/miniconda3/envs/mne/lib']    language = c    define_macros = [('NO_ATLAS_INFO', 1), ('HAVE_CBLAS', None)]    include_dirs = ['/Users/larsoner/opt/miniconda3/envs/mne/include']Supported SIMD extensions in this NumPy install:    baseline = NEON,NEON_FP16,NEON_VFPV4,ASIMD    found = ASIMDHP    not found = ASIMDDP```
"
21755,0,0,292,1,1,seberg,0,"title:BUG: Do not skip value-based promotion path for large Python integers description:When we have:1. Only Python scalars (int, float, complex) as inputs2. One of the integers is too large for the default integer dtypeThe ""new"" promotion path (which existed for a long time internally!)would not produce the same result as the legacy value-based path.However, my logic failed to check for the second part, so it did notrun the legacy path in this odd little case.This fixes the issue reported in:https://github.com/numpy/numpy/issues/13754#issuecomment-1155126639
"
21754,0,0,275,0,1,charris,0,"title:BUG, SIMD: Fix detecting NEON/ASIMD on aarch64 description:Backport of #21749.closes #21747TODO:- [x] checking arm64 builds<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21749,0,0,164,0,1,seiko2plus,0,"title:BUG, SIMD: Fix detecting NEON/ASIMD on aarch64 description:closes #21747TODO:- [x] checking arm64 builds
"
21748,0,0,24,0,1,pradghos,0,"title:BUG: Fix for npyv_orc_b8 and npyv_xnor_b8 for s390x (z13) description:- Implement npyv_orc_b8 and npyv_xnor_b8 for z13.  Since, `__builtin_s390_vec_orc` and `__builtin_s390_vec_eqv` require z14 or higher.
"
21741,1,4607,296,0,0,wilsonzlin,0,"title:BUG: Build from source using Intel oneAPI compiler fails with IndexError in distutils/ccompiler.py due to last_cmdline being empty description:### Describe the issue:When building a wheel of [NumPy 1.22.4](https://github.com/numpy/numpy/releases/download/v1.22.4/numpy-1.22.4.tar.gz) from source using Intel oneAPI and `icc`, the build appears to complete but then fail at the end due to trying to access an unexpected empty list in `distutils/ccompiler.py`.## site.cfg```[mkl]library_dirs = /oneapi/mkl/latest/lib/intel64include_dirs = /oneapi/mkl/latest/includelibraries = mkl_rt```## Final stdout output```########### EXT COMPILER OPTIMIZATION ###########INFO: Platform      :  Architecture: x64  Compiler    : iccCPU baseline  :  Requested   : 'native'  Enabled     : SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL  Flags       : -xICELAKE-CLIENT  Extra checks: AVX512F_REDUCE AVX512BW_MASK AVX512DQ_MASKCPU dispatch  :  Requested   : 'none'  Enabled     : none  Generated   : noneINFO: CCompilerOpt.cache_flush[825] : write cache to path -> /tmpdir/numpy/build/temp.linux-x86_64-3.10/ccompiler_opt_cache_ext.pyINFO:########### CLIB COMPILER OPTIMIZATION ###########INFO: Platform      :  Architecture: x64  Compiler    : iccCPU baseline  :  Requested   : 'native'  Enabled     : SSE SSE2 SSE3 SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL  Flags       : -xICELAKE-CLIENT  Extra checks: AVX512F_REDUCE AVX512BW_MASK AVX512DQ_MASKCPU dispatch  :  Requested   : 'none'  Enabled     : none  Generated   : noneINFO: CCompilerOpt.cache_flush[825] : write cache to path -> /tmpdir/numpy/build/temp.linux-x86_64-3.10/ccompiler_opt_cache_clib.py```### Reproduce the code example:```pythonpip install Cython setuptools wheelsource '/oneapi/compiler/latest/env/vars.sh' && NPY_BLAS_ORDER=MKL NPY_LAPACK_ORDER=MKL python setup.py build -j $(getconf _NPROCESSORS_ONLN) --cpu-baseline=native --cpu-dispatch=none --compiler=intelem --fcompiler=intelem bdist_wheel```### Error message:```shellTraceback (most recent call last):  File ""/tmpdir/numpy/setup.py"", line 461, in <module>    setup_package()  File ""/tmpdir/numpy/setup.py"", line 453, in setup_package    setup(**metadata)  File ""/tmpdir/numpy/numpy/distutils/core.py"", line 169, in setup    return old_setup(**new_attr)  File ""/python3.10/site-packages/setuptools/__init__.py"", line 153, in setup    return distutils.core.setup(**attrs)  File ""/python3.10/distutils/core.py"", line 148, in setup    dist.run_commands()  File ""/python3.10/distutils/dist.py"", line 966, in run_commands    self.run_command(cmd)  File ""/python3.10/distutils/dist.py"", line 985, in run_command    cmd_obj.run()  File ""/tmpdir/numpy/numpy/distutils/command/build.py"", line 61, in run    old_build.run(self)  File ""/python3.10/distutils/command/build.py"", line 135, in run    self.run_command(cmd_name)  File ""/python3.10/distutils/cmd.py"", line 313, in run_command    self.distribution.run_command(command)  File ""/python3.10/distutils/dist.py"", line 985, in run_command    cmd_obj.run()  File ""/tmpdir/numpy/numpy/distutils/command/build_ext.py"", line 332, in run    self.build_extensions()  File ""/python3.10/distutils/command/build_ext.py"", line 447, in build_extensions    self._build_extensions_parallel()  File ""/python3.10/distutils/command/build_ext.py"", line 469, in _build_extensions_parallel    fut.result()  File ""/python3.10/concurrent/futures/_base.py"", line 439, in result    return self.__get_result()  File ""/python3.10/concurrent/futures/_base.py"", line 391, in __get_result    raise self._exception  File ""/python3.10/concurrent/futures/thread.py"", line 58, in run    result = self.fn(*self.args, **self.kwargs)  File ""/tmpdir/numpy/setup.py"", line 235, in build_extension    build_ext.build_extension(self, ext)  File ""/tmpdir/numpy/numpy/distutils/command/build_ext.py"", line 502, in build_extension    c_objects += self.compiler.compile(  File ""/tmpdir/numpy/numpy/distutils/ccompiler.py"", line 89, in <lambda>    m = lambda self, *args, **kw: func(self, *args, **kw)  File ""/tmpdir/numpy/numpy/distutils/ccompiler.py"", line 361, in CCompiler_compile    list(res)  # access result to raise errors  File ""/python3.10/concurrent/futures/_base.py"", line 609, in result_iterator    yield fs.pop().result()  File ""/python3.10/concurrent/futures/_base.py"", line 439, in result    return self.__get_result()  File ""/python3.10/concurrent/futures/_base.py"", line 391, in __get_result    raise self._exception  File ""/python3.10/concurrent/futures/thread.py"", line 58, in run    result = self.fn(*self.args, **self.kwargs)  File ""/tmpdir/numpy/numpy/distutils/ccompiler.py"", line 307, in single_compile    if not _needs_build(obj, cc_args, extra_postargs, pp_opts):  File ""/tmpdir/numpy/numpy/distutils/ccompiler.py"", line 64, in _needs_build    last_cmdline = lines[-1]IndexError: list index out of range```### NumPy/Python version information:**Python:** 3.10.5 (main, Jun 13 2022, 09:04:34) [GCC 11.2.0]**ICC:** 2021.6.0 20220226**Linux:** 5.4.17-2136.307.3.1.el8uek.x86_64
"
21739,0,2158,129,0,0,Gattocrucco,0,"title:BUG: `==` and `!=` fail on empty structured array if there is a nontrivially shaped field description:### Describe the issue:In some corner cases an empty structured array does not compare equal to itself in the testing routines.### Reproduce the code example:```pythonimport numpy as npa = np.zeros(0, [('a', '<f8', (1,))])np.testing.assert_equal(a, a) # oknp.testing.assert_array_equal(a, a) # oka = np.zeros(1, [('a', '<f8', (1, 1))])np.testing.assert_equal(a, a) # oknp.testing.assert_array_equal(a, a) # oka = np.zeros(0, [('a', '<f8', (1, 1))])np.testing.assert_equal(a, a) # failsnp.testing.assert_array_equal(a, a) # fails```### Error message:```shellValueError                                Traceback (most recent call last)File ~/Documents/Programmi/python3102venv/lib/python3.10/site-packages/numpy/testing/_private/utils.py:792, in assert_array_compare(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)    790     return--> 792 val = comparison(x, y)    794 if isinstance(val, bool):ValueError: cannot reshape array of size 0 into shape (0,newaxis)During handling of the above exception, another exception occurred:ValueError                                Traceback (most recent call last)Input In [30], in <cell line: 12>()      9 np.testing.assert_array_equal(a, a) # ok     11 a = np.zeros(0, [('a', '<f8', (1, 1))])---> 12 np.testing.assert_equal(a, a) # fails     13 np.testing.assert_array_equal(a, a)    [... skipping hidden 2 frame]File ~/Documents/Programmi/python3102venv/lib/python3.10/site-packages/numpy/testing/_private/utils.py:852, in assert_array_compare(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)    848 header = f'error during assertion:\n\n{efmt}\n\n{header}'    850 msg = build_err_msg([x, y], err_msg, verbose=verbose, header=header,    851                     names=('x', 'y'), precision=precision)--> 852 raise ValueError(msg)ValueError: error during assertion:Traceback (most recent call last):  File ""/Users/giacomo/Documents/Programmi/python3102venv/lib/python3.10/site-packages/numpy/testing/_private/utils.py"", line 792, in assert_array_compare    val = comparison(x, y)ValueError: cannot reshape array of size 0 into shape (0,newaxis)Arrays are not equal x: array([], dtype=[('a', '<f8', (1, 1))]) y: array([], dtype=[('a', '<f8', (1, 1))])```### NumPy/Python version information:1.21.5 3.10.2 (v3.10.2:a58ebcc701, Jan 13 2022, 14:50:16) [Clang 13.0.0 (clang-1300.0.29.30)]
"
21738,0,0,292,0,0,seberg,0,"title:BUG: `empty_like` should fill object references with `None` description:Pandas ran into this in [here](https://github.com/pandas-dev/pandas/pull/47097/files#r895218281).  Normally we fill empty object arrays with `None`.NumPy supports it being filled with `NULL` just fine (and sometimes that should happen before any other initialization took place).But, generally, NumPy *should* always fill with None and it would be nice to make ""enforce"" this (i.e. remove support for `NULL` in a few places, because only bad user-provided arrays would use it.**TL;DR:** We should ensure that `np.empty_like` fills object arrays the same way that `np.empty` does.  This can be tested using `arr.tobytes()`.
"
21722,0,0,275,0,1,charris,0,"title:BUG: .f2py_f2cmap doesn't map long_long and other options description:Backport of #21712.Closes #15095.Essentially the previous behavior correctly overwrote the internal type, but didn't generate the required `typedef` helpers needed for the `C` wrapper. The fix is to track when the file includes a mapping value for which the `typedef` is needed and then to generate it.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21720,0,0,275,0,0,charris,0,"title:BUG: Enable fortran preprocessing for ifort on Windows description:Backport of #21701.Needed especially when compiling the latest scipy on Windows. This flag is alreadyset on Linux and Mac.
"
21719,0,0,275,0,1,charris,0,"title:BUG: Small fixupes found using valgrind description:Backport of #21691.This is part of my pre 1.23.x valgrind run. Besides these two fixes, there is one in f2py (gh-21682).There is another leak in numpy/core/tests/test_deprecations.py::TestNoseDecoratorsDeprecated::test_skip_generators_hardcoded, but I assume the test is either weird or it is upstream (since this is nose!).Besides these, all further issues seem to be related to either proper longdouble support missing, or the fact that ufunc strides appear not always filled for empty inputs. I may look into the last point, but it does not seem relevant in practice (for empty input, the stride really should not matter).<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21718,0,0,275,0,1,charris,0,"title:BUG: use explicit einsum_path whenever it is given description:Backport of #21639.* BUG: use explicit einsum_path whenever it is givenFor example, allow user to specify unary contractions in binary einsumas described in #20962.The commit also adds a sanity check on user-specified einsum_path.* fix lint* MAINT: refactor logic with explicit_einsum_path<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21712,0,0,291,0,1,HaoZeke,0,"title:BUG: `.f2py_f2cmap` doesn't map `long_long` and other options description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->Closes #15095.Essentially the previous behavior correctly overwrote the internal type, but didn't generate the required `typedef` helpers needed for the `C` wrapper. The fix is to track when the file includes a mapping value for which the `typedef` is needed and then to generate it.
"
21710,0,0,275,0,1,charris,0,"title:TST: Fixup loadtxt int-via-float tests when in release mode description:Backport of #21709.In release mode, the DeprecationWarning is not automatically raised,so we need to ensure this using a warning filter.(Also add missing metadata/info to the deprecation tests)Closes gh-21706<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21709,0,0,292,0,1,seberg,0,"title:TST: Fixup loadtxt int-via-float tests when in release mode description:In release mode, the DeprecationWarning is not automatically raised,so we need to ensure this using a warning filter.(Also add missing metadata/info to the deprecation tests)Closes gh-21706---Tested locally, by removing everything interesting from `pytest.ini` (simulating a release for testing purposes).  Should be good, unless there are slow tests (which would be surprising).
"
21701,0,0,0,0,0,i-shenl,0,"title:BUG: Enable fortran preprocessing for ifort on Windows description:Needed especially when compiling the latest scipy on Windows. This flag is alreadyset on Linux and Mac.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21698,0,0,275,0,0,charris,0,"title:BUG: Prevent attempted broadcasting of 0-D output operands in ufuncs description:Backport of #21690.Attempting to broadcast causes crashes when we later check for selfoverlap of the output operand (assuming it is 1-D).But it would also crash if the operation was done, the issue isnot rejecting the broadcasting right-away.Closes gh-21673<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21697,0,0,275,0,1,charris,0,"title:BUG: Fix a refactor leftover bug description:Backport of #21659.Fixed a minor bug probably left from refactoring the old code<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21693,1,1195,41,0,1,DavideColdebella,0,"title:BUG: finfo not working, issue related to numeric.dtype description:### Describe the issue:When calling np.finfo, I always get the << 'NoneType' object is not callable >> error, independently of the argument passed.The error trace indicates that there's an error in the linedtype = numeric.dtype(type(dtype))and, if I dofrom numpy.core import numericprint(numeric.dtype)I get a ""None"" value.I guess it could be fixed by replacing the line above with something like:dtype = dtype(type(dtype))### Reproduce the code example:```pythonimport numpynp.finfo(np.float32)```### Error message:```shell---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)File ~\anaconda3\envs\Melanion\lib\site-packages\numpy\core\getlimits.py:384, in finfo.__new__(cls, dtype)    383 try:--> 384     dtype = numeric.dtype(dtype)    385 except TypeError:    386     # In case a float instance was givenTypeError: 'NoneType' object is not callableDuring handling of the above exception, another exception occurred:TypeError                                 Traceback (most recent call last)Input In [62], in <cell line: 1>()----> 1 np.finfo(      2     # np.float16,       3     np.float32,       4     # np.float64      5 ).dtypeFile ~\anaconda3\envs\Melanion\lib\site-packages\numpy\core\getlimits.py:387, in finfo.__new__(cls, dtype)    384     dtype = numeric.dtype(dtype)    385 except TypeError:    386     # In case a float instance was given--> 387     dtype = numeric.dtype(type(dtype))    389 obj = cls._finfo_cache.get(dtype, None)    390 if obj is not None:TypeError: 'NoneType' object is not callable```### NumPy/Python version information:Python Version: 3.10.4Numpy Version: 1.21.5
"
21691,0,0,292,0,1,seberg,0,"title:BUG: Small fixupes found using valgrind description:This is part of my pre 1.23.x valgrind run.  Besides these two fixes, there is one in f2py (gh-21682).There is another leak in `numpy/core/tests/test_deprecations.py::TestNoseDecoratorsDeprecated::test_skip_generators_hardcoded`, but I assume the test is either weird or it is upstream (since this is nose!).Besides these, all further issues seem to be related to either proper `longdouble` support missing, or the fact that ufunc strides appear not always filled for _empty_ inputs.  I may look into the last point, but it does not seem relevant in practice (for empty input, the stride really should not matter).
"
21690,0,0,292,0,0,seberg,0,"title:BUG: Prevent attempted broadcasting of 0-D output operands in ufuncs description:Attempting to broadcast causes crashes when we later check for selfoverlap of the output operand (assuming it is 1-D).But it would also crash if the operation was done, the issue isnot rejecting the broadcasting right-away.Closes gh-21673
"
21687,0,0,0,0,1,rafaelcfsousa,0,"title:BUG: switch _CMP_NEQ_OQ to _CMP_NEQ_UQ for npyv_cmpneq_f[32,64] description:This PR fixes #21685.The comparison function `np.equal_not` returns `True` when one of the operands is `NaN`. The other comparison functions, on the other hand, return `False`.cc: @seberg 
"
21686,1,381,31,0,0,mearlboro,0,"title:Internal compiler error when installing on Raspberry Pi 4 with RPi OS (Buster) description:### Describe the issue:```numpy/core/src/umath/loops_trigonometric.dispatch.c.src:202:20: internal compiler error: in convert_move, at expr.c:218       NPY_NO_EXPORT void NPY_CPU_DISPATCH_CURFX(FLOAT_@func@)                          ^      0xb6b59717 __libc_start_main          /build/glibc-FUvrFr/glibc-2.28/csu/libc-start.c:308```### Reproduce the code example:```pythonpip3 install numpy```### Error message:```shellhttps://pastebin.com/EGraqF50```### NumPy/Python version information:Raspberry Pi 4 + Raspberry Pi OS Buster.Python 3.7.3Numpy version being attempted is 1.21 (didn't choose it in particular, it's just the one pip would install).Apt packages installed so far are:         - python3        - python3-pip        - build-essential                                                                                       - cmake                                                                                                 - libhdf5-dev                                                                                           - libatlas-base-dev                                                                                     - gfortran                                                                                              - libavcodec-dev                                                                                        - libavformat-dev                                                                                       - libswscale-dev                                                                                        - libv4l-dev                                                                                            - libopenblas-dev            I've setup an identical system a year ago, running the exact same code (using Ansible for setup) and there was no issue.
"
21685,0,799,271,0,0,WarrenWeckesser,0,"title:BUG: Incorrect handling of not-equal comparison to nan description:### Describe the issue:For a sufficiently large array `x`, the comparison `x != 0` returns False for elements of `x` that are `nan`. The result should be True.  For example,```In [1]: import numpy as npIn [2]: x = np.zeros((4, 8))In [3]: x[0,0] = np.nanIn [4]: x != 0  # The first element of the result should be TrueOut[4]: array([[False, False, False, False, False, False, False, False],       [False, False, False, False, False, False, False, False],       [False, False, False, False, False, False, False, False],       [False, False, False, False, False, False, False, False]])In [5]: x[:2] != 0  # The result with a smaller array works as expected.Out[5]: array([[ True, False, False, False, False, False, False, False],       [False, False, False, False, False, False, False, False]])```The bug appears to have been introduced in gh-21483.### NumPy/Python version information:```In [6]: import sys, numpy; print(numpy.__version__, sys.version)1.24.0.dev0+136.g15b92f7ab 3.10.1 (main, Jan 14 2022, 02:27:20) [GCC 11.2.0]```
"
21683,1,789,0,0,1,mpcasey2718,0,"title:BUG: Calling sort on a column vector returns the column as is, not sorted.  description:### Describe the issue:On both linux with python 3.8 and mac with python 3.10, I have found that calling sort on arrays of shape (N,1) leaves the array as is, possibly as if the sorting was done on each row, or just not at all. Transposing the array and then calling sort, or explicitly flattening the array and then calling sort both produce the expected results. Sample code is below. The result of np.sort(column) is not sorted. Given that the documentation says that omitting the axis parameter will flatten the array, something appears to be off. I do not know if there is some ""strange"" behavior in flatten() that does not act on (N, 1) arrays. I suppose adding a transpose for that case would be a sufficient fix?### Reproduce the code example:```pythonimport numpy as npfrom numpy.random import Generator, PCG64rg = Generator(PCG64())N = 10 column = rg.standard_normal((N, 1))print('The entries are', column, sep='\n')print('')row = column.TsortedCol = np.sort(column)print('The expected to be sorted column entries are', sortedCol, sep='\n')print('')sortedRow = np.sort(row)print('The sorted row entries are', sortedRow, sep='\n')print('')# flatCol = np.asanyarray(column).flatten()flatCol = column.flatten()print('The flattened column entries are', flatCol, sep='\n')sortedFlatCol = np.sort(flatCol)print('')print('The sorted flattened column entries are', sortedFlatCol, sep='\n')print('')print('The difference with the sorted row entries is', sortedFlatCol - sortedRow, sep='\n')```### Error message:_No response_### NumPy/Python version information:For the linux system:1.21.4 3.8.2 (default, Jul  2 2020, 00:57:00)                                   [GCC 9.2.0]I shall need a few days to get the info for the Mac if needed, but python and numpy were installed just last week on that machine. 
"
21680,1,1139,297,0,0,aamster,0,"title:BUG: memory leak with ndarray.tolist() description:### Describe the issue:When I call `ndarray.tolist()` on an array in a loop I would expect the process's memory to stay static. However, the memory appears to grow each iteration.![numpy_mem_leak](https://user-images.githubusercontent.com/5454341/172201261-18559cc6-9176-4f07-97dd-8f5f7d9ea41c.png)### Reproduce the code example:```pythonimport gcimport osimport numpy as npimport pandas as pdimport psutilfrom sklearn.linear_model import LinearRegressionfrom matplotlib import pyplot as pltimport seaborn as snsfrom tqdm import tqdmdef main():    x = np.random.random((int(1e6), 10))    mem = np.zeros(50)    process = psutil.Process(os.getpid())    for i in tqdm(range(50)):        y = x.tolist()        mem[i] = process.memory_info().rss    res = pd.DataFrame(        {'Memory usage': np.array(mem),         'iteration': range(len(mem))         })    reg = LinearRegression()    reg.fit(X=res['iteration'].values.reshape(-1, 1),            y=res['Memory usage'])    slope = reg.coef_[0]    intercept = reg.intercept_    sns.lineplot(data=res, x='iteration', y='Memory usage',                 marker='o')    plt.plot([0, res.shape[0]], [intercept, slope * res.shape[0] + intercept],             color='red')    plt.show()if __name__ == '__main__':    main()    gc.collect()    main()```### Error message:_No response_### NumPy/Python version information:```1.21.5 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]```
"
21673,0,95,252,0,0,mhvk,0,"title:BUG: Segmentation fault for ufunc with output with wrong shape description:### Describe the issue:A strange bug in astropy - https://github.com/astropy/astropy/issues/13283 - boils down to the example below giving a segmentation fault. To trigger the bug, one of the two arguments need to be scalar; if one replaces with `[1.]` in the example, one gets the correct broadcasting error.### Reproduce the code example:```pythonimport numpy as npnp.add(1., [1., 2.], out=np.empty(()))```### Error message:```shellSegmentation fault```### NumPy/Python version information:1.21.5 3.10.4 (main, Apr  2 2022, 09:04:19) [GCC 11.2.0]1.22.4 3.10.4 (main, Apr  2 2022, 09:04:19) [GCC 11.2.0]According to https://github.com/astropy/astropy/issues/13283, the bug was introduced in numpy 1.21
"
21668,1,208,90,0,0,jkunimune,0,"title:BUG: `initial` parameter in reduction operations is incorrectly type-converted description:### Describe the issue:When the `initial` parameter of a reduction operation has a type that is different from the contents of the array, it is converted to match in C, and thereby circumvents many of the checks that would normally go with such a conversion in Python.  This sometimes leads to behavior that would make sense in C, but seems incorrect in Python.  It seems to me that `initial` should be converted to the same type as the array in the Python function before it is passed to the C layer.### Reproduce the code example:```pythonimport numpy as npa = np.array([1, 2, 3])print(np.amin(a, initial=np.inf))# expected result: either 1 or OverflowError('cannot convert float infinity to integer')# actual result: -2147483648```### NumPy/Python version information:Numpy 1.20.2Python 3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)]
"
21665,0,364,29,0,0,jhaiduce,0,"title:BUG: f2py ignores value attribute description:### Describe the issue:f2py generates incorrect wrapper code when run on a Fortran procedure that uses the `value` attribute on any input variables. A compiler that complies with the Fortran 2003 standard treats such variables as pass-by-value. f2py wrappers for such functions produce incorrect behavior, presumably because f2py ignores the `value` attribute and the generated wrapper passes the variable's address instead of its value.Here's some example Fortran code that illustrates this:```module fortfuncs  implicit nonecontains  subroutine square(x,y)    integer, intent(in), value :: x    integer, intent(out) :: y    y = x*x  end subroutine squareend module fortfuncs```The above code compiles to a wrapper module as expected with the command `f2py -m fortfuncs -c fortfuncs.f90`, but the resulting wrapper code produces garbage output. For example the following```from fortfuncs import fortfuncsy=fortfuncs.square(2)assert y==4```raises an AssertionError. As a workaround, one can avoid using the `value` attribute, but it would be simpler for users if f2py supported the `value` attribute (or at least threw an error indicating that the `value` attribute is not supported).### Reproduce the code example:```pythonSee above; the code to reproduce is in Fortran rather than Python.```### Error message:_No response_### NumPy/Python version information:1.22.4 3.9.13 (main, May 24 2022, 21:28:12) [Clang 12.0.0 (clang-1200.0.32.29)]Fortran compiler version:GNU Fortran (Homebrew GCC 11.3.0_1) 11.3.0
"
21659,0,0,6,0,1,NamamiShanker,0,"title:BUG: Fix a bug left after f2py2e refactor description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->Fixed a minor bug probably left from refactoring the old code
"
21640,1,859,98,0,0,jhidding,0,"title:BUG: regression 1.22.4: error on exiting mmap context with buffered array description:### Describe the issue:The enclosed minimal code example runs correctly with Numpy version 1.22.3.The bug is triggered when a `mmap` context is left with a Numpy buffered array pointing to that `mmap` buffer.### Reproduce the code example:```pythonimport numpy as npimport mmapfrom contextlib import contextmanagerdata = np.arange(10, dtype=np.int32)with open(""test.bin"", ""wb"") as f_out:    data.tofile(f_out)@contextmanagerdef my_data():    with open(""test.bin"", ""r+b"") as f_in:        with mmap.mmap(f_in.fileno(), 0) as mm:            content = np.frombuffer(mm, dtype=np.int32, count=10, offset=0)            yield contentwith my_data() as d:    print(d)```### Error message:```shellTraceback (most recent call last):  File ""/mnt/data/Code/windfarms/cylinder/numpy_bug.py"", line 16, in <module>    with my_data() as d:  File ""/usr/lib64/python3.10/contextlib.py"", line 142, in __exit__    next(self.gen)  File ""/mnt/data/Code/windfarms/cylinder/numpy_bug.py"", line 12, in my_data    with mmap.mmap(f_in.fileno(), 0) as mm:BufferError: cannot close exported pointers exist```### NumPy/Python version information:1.22.4 3.10.4 (main, Mar 25 2022, 00:00:00) [GCC 12.0.1 20220308 (Red Hat 12.0.1-0)]
"
21639,0,0,38,0,0,toslunar,0,"title:BUG: use explicit einsum_path whenever it is given description:For example, allow user to specify unary contractions in binary einsum as described in #20962.The commit also adds a sanity check on user-specified einsum_path.
"
21612,0,744,294,0,0,carterbox,0,"title:BUG: 1.22.4 breaks frombuffer API compared with 1.22.3 description:### Describe the issue:Arrays returned by np.frombuffer() do not have the same base attribute when compared before and after version 1.22.4. I believe this behavior may only be reproduceable on Windows/OSX.Related:- https://github.com/numpy/numpy/pull/21324- https://github.com/tomopy/tomopy/pull/585### Reproduce the code example:```pythonimport numpy as npimport multiprocessing as mpimport ctypesshared_obj = mp.RawArray(ctypes.c_double, (6, 6))shared_arr = np.frombuffer(shared_obj)assert type(shared_arr) == np.ndarrayassert type(shared_obj) == type(shared_arr.base)```### Error message:```shell>       assert type(shared_obj) == type(shared_arr.base)E       AssertionError: assert <class 'multiprocessing.sharedctypes.c_double_Array_2'> == <class 'memoryview'>E        +  where <class 'multiprocessing.sharedctypes.c_double_Array_2'> = type(<multiprocessing.sharedctypes.c_double_Array_2 object at 0x0000010E0B283940>)E        +  and   <class 'memoryview'> = type(<memory at 0x0000010E0921ED00>)E        +    where <memory at 0x0000010E0921ED00> = array([6., 6.]).base```### NumPy/Python version information:The code example works on 1.22.3, but not 1.22.4
"
21604,0,0,275,0,1,charris,0,"title:BUILD: fix tag name for travis: it is v1.23.0rc1 description:Backport of #21602.Closes #21599The TRAVIS_TAG name is v1.23.0rc1, the old one was copied from github actions which is different.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21602,0,0,284,0,1,mattip,0,"title:BUILD: fix tag name for travis: it is v1.23.0rc1 description:Closes #21599 The TRAVIS_TAG name is v1.23.0rc1, the old one was copied from github actions which is different.
"
21594,1,174,1,0,0,cubanpit,0,"title:numpy.cdouble does not accept two arguments description:### Describe the issue:According to the [documentation](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.cdouble) I should be able to create a complex number with `numpy.cdouble(real=1.0, imag=2.0)` but this returns```TypeError: function takes at most 1 argument (2 given)```Same applies to `complex_` and `complex128`, since they are all the same as far as I understand.Not sure if this is a bug in the code or an outdated section in the documentation.I tested this with Numpy 1.22.3 compiled from source and with Numpy 1.22.4 installed from PyPi, both on Windows 10.### Reproduce the code example:```pythonimport numpynumpy.cdouble(real=1.0, imag=2.0)```### Error message:```shellTypeError: function takes at most 1 argument (2 given)```### NumPy/Python version information:`1.22.3 3.8.12 (default, May 19 2022, 11:54:29) [MSC v.1929 64 bit (AMD64)]`
"
21592,0,1003,190,0,0,HexDecimal,0,"title:BUG: Type hints disallow augmented assignment for unsigned arrays and a scalar. description:### Describe the issue:The 1.22.4 release causes type errors with code I assumed was correct.  The following example works as expected but will fail when type checked.Only unsigned arrays are affected.  I assume all augmented assignment operators are affected.### Reproduce the code example:```pythonimport numpy as nparray = np.zeros(4, dtype=np.uint32)array += 2array *= 2array //= 2```### Error message:```shell$ mypy myproblem.py myproblem.py:5: error: Argument 1 to ""__iadd__"" of ""ndarray"" has incompatible type ""int""; expected ""Union[_SupportsArray[dtype[Union[bool_, unsignedinteger[Any]]]], _NestedSequence[_SupportsArray[dtype[Union[bool_, unsignedinteger[Any]]]]], bool, _NestedSequence[bool]]""myproblem.py:6: error: Argument 1 to ""__imul__"" of ""ndarray"" has incompatible type ""int""; expected ""Union[_SupportsArray[dtype[Union[bool_, unsignedinteger[Any]]]], _NestedSequence[_SupportsArray[dtype[Union[bool_, unsignedinteger[Any]]]]], bool, _NestedSequence[bool]]""myproblem.py:7: error: Argument 1 to ""__ifloordiv__"" of ""ndarray"" has incompatible type ""int""; expected ""Union[_SupportsArray[dtype[Union[bool_, unsignedinteger[Any]]]], _NestedSequence[_SupportsArray[dtype[Union[bool_, unsignedinteger[Any]]]]], bool, _NestedSequence[bool]]""Found 3 errors in 1 file (checked 1 source file)```### NumPy/Python version information:1.22.4 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]$ mypy --versionmypy 0.950 (compiled: yes)
"
21591,0,0,275,0,1,charris,0,"title:BUG, STY: Fix doctest failure in EXAMPLE_DOCSTRING. description:The failures did not show up before the file type was changed from.rst.txt to .rst because the file wasn't tested.Also make some style fixes.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21590,1,287,296,0,0,eendebakpt,0,"title:BUG: Polynomial object fails in render in Spyder  description:### Describe the issue:The latex representation of a `Polynomial` fails to display under the [Spyder](https://github.com/spyder-ide/spyder) IDE. The reason is that the expression generated by `_repr_latex_` contains command `\text` and `\color{LightGray}` that are not handled by LaTeX without extra packages (for `\text` one needs amsmath, for the `LightGray` I am not sure).A snapshot from a Spyder session showing the problem:![image](https://user-images.githubusercontent.com/883786/170137383-e76cca4b-ee40-4e32-9ab4-d1460a8cef0a.png)Something similar happens when displaying the polynomial in matplotlib. A minimal example:``` from numpy.polynomial import Polynomialp=Polynomial([0.2,-1,1, 0, 3])print(p._repr_latex_())plt.figure(1); plt.clf()plt.plot(1,2)plt.title(p._repr_latex_()) # fails```To solve the problem with sympy we could make a method `Polynomial.latex_expression` that does not include the special commands. Spyder uses `_repr_latex_` by default. Instead of `\text` we could also use `\mathrm`.  But for the `\color` I have no good alternative in mind.### Reproduce the code example:```pythonfrom numpy.polynomial import Polynomialp=Polynomial([1,0, 1])p# (executed in Spyder console)```### Error message:_No response_### NumPy/Python version information:1.23.0.dev0+1252.gae8b9ce90 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
"
21585,1,452,297,0,1,honno,0,"title:BUG: Large distances between `start` and `stop` in `np.linspace()` result in non-finite values description:### Describe the issue:I'm guessing some internal logic causes this issue, like in #20226. Given it's such an edge case this is probably not worth fixing, just thought I'd write an issue for prosperity's sake.### Reproduce the code example:```python>>> np.linspace(-9.9792015476736e+291, 1.7976931348623157e+308, 1)RuntimeWarning: overflow encountered in double_scalars  delta = stop - startRuntimeWarning: invalid value encountered in multiply  y = y * deltaarray([nan])  # expected -9.9792015476736e+291>>> np.linspace(-9.9792015476736e+291, 1.7976931348623157e+308, 5)... same warnings ...array([ nan, inf, inf, inf, 1.79769313e+308] )  # expected finite values in-between```### NumPy/Python version information:1.23.0.dev0+1084.g5ab08cfa8 3.8.12 (default, Mar 13 2022, 19:12:08) [GCC 9.4.0]
"
21576,1,17,0,0,0,13Quavo,0,"title:Support for Python version 3.10.4?? description:### Describe the issue:When I do `pip install numpy ` it says Failed  building wheel for numpyAny solutions? Thank you### Reproduce the code example:```pythona```### Error message:```shella```### NumPy/Python version information:a
"
21574,0,975,300,0,1,ev-br,0,"title:BUG: refguide-check: respect the verbosity description:Consider```$ python runtests.py -s numpy.lib.recfunctions --refguide-check -v```Previously, the `-v` switch was silently ignored.With this PR, the output is ```$ python runtests.py -s numpy.lib.recfunctions --refguide-check -v<snip>numpy.lib.recfunctions.unstructured_to_structured-------------------------------------------------Trying:    from numpy.lib import recfunctions as rfnExpecting nothingokTrying:    dt = np.dtype([('a', 'i4'), ('b', 'f4,u2'), ('c', 'f4', 2)])Expecting nothingokTrying:    a = np.arange(20).reshape((4,5))Expecting nothingokTrying:    aExpecting:    array([[ 0,  1,  2,  3,  4],           [ 5,  6,  7,  8,  9],           [10, 11, 12, 13, 14],           [15, 16, 17, 18, 19]])okTrying:    rfn.unstructured_to_structured(a, dt)Expecting:    array([( 0, ( 1.,  2), [ 3.,  4.]), ( 5, ( 6.,  7), [ 8.,  9.]),           (10, (11., 12), [13., 14.]), (15, (16., 17), [18., 19.])],          dtype=[('a', '<i4'), ('b', [('f0', '<f4'), ('f1', '<u2')]), ('c', '<f4', (2,))])ok```which might be a tad too noisy for some tastes. I'd suggest to treat this as a bugfix and consider various levels of verbosity between above and the default  dots `.....` as a separate enhancement.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21567,0,151,256,1,1,bsipocz,0,"title:BUG: Adding the default pytest doctest instead of the ValueError description:This PR does the bare minimum of bringing the code in sync with the docs, and addresses the issue https://github.com/numpy/numpy/issues/21070 partially.Naturally, a lot of the doctests are failing, but those can be tracked in an issue and fix them gradually (excellent source for spring and first timer events), there is no reason to keep the infrastructure artificially broken with a ValueError, especially when it's documented all over in the docs that doctests can be run with:```>>> np.test(doctests=True)# OR>>> np.lib.test(doctests=True)```In addition it's also possible to individually run files with `rundocs`, but I find that approach more clumsy and would rather suggest to retire that test function in favour of the more standard pytest approach.```>>> from numpy.testing import rundocs>>> rundocs('numpy/lib/recfunctions.py')```
"
21563,0,140,256,0,0,bsipocz,0,"title:BUG: Make building docs with missing python3 easier description:### Describe the issue:I've spent quite a few minutes trying to decrypt why I cannot build the docs locally, when local testing, etc all work fine, dependencies are installed, etc. Naturally, I should have started with grepping for the error message to discover that I should do `make PYTHON=python html` instead.Ideally, it would be nice if the machinery wouldn't assume python3 as the name of the executable (are there any other python in these days?), or at minimum would give a useful error message (similar to the one given with mismatching version number).### Reproduce the code example:```shellmake  html```When no `python3` executable is available, or it's outside of the current virtualenv/pyenv### Error message:```shellnumpy not found, cannot build documentation without successful ""import numpy""make: *** [version-check] Error 1```
"
21561,1,72,288,1,1,kloczek,0,"title:BUG 1.22.4: sphinx warnings `reference target not found` description:### Describe the issue:I'm still not able to generate man page as I've reported that in https://github.com/numpy/numpy/issues/20229 however recently I've changed methodology of generate man pages from using sphinx<>setuptools integration (`python setup.py build_sphinx`) to straight use `sphinx-buid` command. All because already sphinx<>setuptools is marked as deprecated.As part of that change I've started using `sphinx-build -n` switch.Sphinx still is not able to generate man page however before it crashes it shows many warnings which are mot related to generate man page.Here is the outputYou can peak on fixes that kind of issues in other projectshttps://github.com/latchset/jwcrypto/pull/289https://github.com/click-contrib/sphinx-click/commit/abc31069### Reproduce the code example:```python`/usr/bin/sphinx-build -n -T -b man doc/source build/sphinx/man````### Error message:_No response_### NumPy/Python version information:1.22.4
"
21556,1,10225,288,0,0,kloczek,0,"title:1.22.4 BUG: pep517 build fails description:### Describe the issue:Looks like with just release 1.22.4 pep517 build fails.### Reproduce the code example:```python- Unpacka source tarball https://github.com/numpy/numpy//releases/download/v1.22.4/numpy-1.22.4.tar.gz- run in source root `/usr/bin/python3 -sBm build -w --no-isolation````### Error message:```shell+ /usr/bin/python3 -sBm build -w --no-isolation* Getting dependencies for wheel...Running from numpy source directory.running egg_inforunning build_srcINFO: build_srccreating numpy.egg-infowriting numpy.egg-info/PKG-INFOwriting dependency_links to numpy.egg-info/dependency_links.txtwriting entry points to numpy.egg-info/entry_points.txtwriting top-level names to numpy.egg-info/top_level.txtwriting manifest file 'numpy.egg-info/SOURCES.txt'package init file 'numpy/core/include/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/__init__.py' not found (or not a regular file)package init file 'numpy/core/include/numpy/__init__.py' not found (or not a regular file)package init file 'numpy/core/include/numpy/libdivide/__init__.py' not found (or not a regular file)package init file 'numpy/core/include/numpy/random/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/_simd/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/common/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/multiarray/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/npymath/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/npysort/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/umath/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/common/dlpack/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/common/simd/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/common/simd/avx2/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/common/simd/avx512/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/common/simd/neon/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/common/simd/sse/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/common/simd/vsx/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/umath/svml/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/umath/svml/linux/__init__.py' not found (or not a regular file)package init file 'numpy/core/src/umath/svml/linux/avx512/__init__.py' not found (or not a regular file)package init file 'numpy/core/tests/data/__init__.py' not found (or not a regular file)package init file 'numpy/core/tests/examples/__init__.py' not found (or not a regular file)package init file 'numpy/core/tests/examples/cython/__init__.py' not found (or not a regular file)package init file 'numpy/core/tests/examples/limited_api/__init__.py' not found (or not a regular file)package init file 'numpy/distutils/checks/__init__.py' not found (or not a regular file)package init file 'numpy/distutils/mingw/__init__.py' not found (or not a regular file)package init file 'numpy/f2py/src/__init__.py' not found (or not a regular file)package init file 'numpy/f2py/tests/src/__init__.py' not found (or not a regular file)package init file 'numpy/f2py/tests/src/array_from_pyobj/__init__.py' not found (or not a regular file)package init file 'numpy/f2py/tests/src/assumed_shape/__init__.py' not found (or not a regular file)package init file 'numpy/f2py/tests/src/common/__init__.py' not found (or not a regular file)package init file 'numpy/f2py/tests/src/kind/__init__.py' not found (or not a regular file)package init file 'numpy/f2py/tests/src/mixed/__init__.py' not found (or not a regular file)package init file 'numpy/f2py/tests/src/module_data/__init__.py' not found (or not a regular file)package init file 'numpy/f2py/tests/src/parameter/__init__.py' not found (or not a regular file)package init file 'numpy/f2py/tests/src/regression/__init__.py' not found (or not a regular file)package init file 'numpy/f2py/tests/src/size/__init__.py' not found (or not a regular file)package init file 'numpy/f2py/tests/src/string/__init__.py' not found (or not a regular file)package init file 'numpy/lib/tests/data/__init__.py' not found (or not a regular file)package init file 'numpy/linalg/lapack_lite/__init__.py' not found (or not a regular file)package init file 'numpy/random/_examples/__init__.py' not found (or not a regular file)package init file 'numpy/random/include/__init__.py' not found (or not a regular file)package init file 'numpy/random/src/__init__.py' not found (or not a regular file)package init file 'numpy/random/_examples/cffi/__init__.py' not found (or not a regular file)package init file 'numpy/random/_examples/cython/__init__.py' not found (or not a regular file)package init file 'numpy/random/_examples/numba/__init__.py' not found (or not a regular file)package init file 'numpy/random/src/distributions/__init__.py' not found (or not a regular file)package init file 'numpy/random/src/legacy/__init__.py' not found (or not a regular file)package init file 'numpy/random/src/mt19937/__init__.py' not found (or not a regular file)package init file 'numpy/random/src/pcg64/__init__.py' not found (or not a regular file)package init file 'numpy/random/src/philox/__init__.py' not found (or not a regular file)package init file 'numpy/random/src/sfc64/__init__.py' not found (or not a regular file)package init file 'numpy/random/src/splitmix64/__init__.py' not found (or not a regular file)package init file 'numpy/typing/tests/data/__init__.py' not found (or not a regular file)package init file 'numpy/typing/tests/data/fail/__init__.py' not found (or not a regular file)package init file 'numpy/typing/tests/data/misc/__init__.py' not found (or not a regular file)package init file 'numpy/typing/tests/data/pass/__init__.py' not found (or not a regular file)package init file 'numpy/typing/tests/data/reveal/__init__.py' not found (or not a regular file)/usr/lib/python3.8/site-packages/setuptools/command/egg_info.py:633: SetuptoolsDeprecationWarning: Custom 'build_py' does not implement 'get_data_files_without_manifest'.Please extend command classes from setuptools instead of distutils.  warnings.warn(reading manifest file 'numpy.egg-info/SOURCES.txt'reading manifest template 'MANIFEST.in'warning: no previously-included files found matching 'LICENSES_bundled.txt'warning: no previously-included files found matching 'azure-*.yml'no previously-included directories found matching 'doc/build'no previously-included directories found matching 'doc/source/generated'no previously-included directories found matching 'benchmarks/env'no previously-included directories found matching 'benchmarks/results'no previously-included directories found matching 'benchmarks/html'no previously-included directories found matching 'benchmarks/numpy'warning: no previously-included files matching '*.pyo' found anywhere in distributionwarning: no previously-included files matching '*.pyd' found anywhere in distributionwarning: no previously-included files matching '*.swp' found anywhere in distributionwarning: no previously-included files matching '*.bak' found anywhere in distributionwarning: no previously-included files matching '*~' found anywhere in distributionadding license file 'LICENSE.txt'writing manifest file 'numpy.egg-info/SOURCES.txt'* Building wheel...Running from numpy source directory.Cythonizing sourcesProcessing numpy/random/_bounded_integers.pxd.inProcessing numpy/random/_bounded_integers.pyx.inTraceback (most recent call last):  File ""/home/tkloczko/rpmbuild/BUILD/numpy-1.22.4/tools/cythonize.py"", line 234, in <module>    main()  File ""/home/tkloczko/rpmbuild/BUILD/numpy-1.22.4/tools/cythonize.py"", line 230, in main    find_process_files(root_dir)  File ""/home/tkloczko/rpmbuild/BUILD/numpy-1.22.4/tools/cythonize.py"", line 221, in find_process_files    process(root_dir, fromfile, tofile, function, hash_db)  File ""/home/tkloczko/rpmbuild/BUILD/numpy-1.22.4/tools/cythonize.py"", line 187, in process    processor_function(fromfile, tofile)  File ""/home/tkloczko/rpmbuild/BUILD/numpy-1.22.4/tools/cythonize.py"", line 90, in process_tempita_pyx    process_pyx(pyxfile, tofile)  File ""/home/tkloczko/rpmbuild/BUILD/numpy-1.22.4/tools/cythonize.py"", line 74, in process_pyx    raise RuntimeError(f'Building {VENDOR} requires Cython >= {required_version}'RuntimeError: Building NumPy requires Cython >= 0.29.30, found 0.29.25 at /home/tkloczko/.local/lib/python3.8/site-packages/Cython/__init__.pyTraceback (most recent call last):  File ""/usr/lib/python3.8/site-packages/pep517/in_process/_in_process.py"", line 363, in <module>    main()  File ""/usr/lib/python3.8/site-packages/pep517/in_process/_in_process.py"", line 345, in main    json_out['return_val'] = hook(**hook_input['kwargs'])  File ""/usr/lib/python3.8/site-packages/pep517/in_process/_in_process.py"", line 261, in build_wheel    return _build_backend().build_wheel(wheel_directory, config_settings,  File ""/usr/lib/python3.8/site-packages/setuptools/build_meta.py"", line 244, in build_wheel    return self._build_with_temp_dir(['bdist_wheel'], '.whl',  File ""/usr/lib/python3.8/site-packages/setuptools/build_meta.py"", line 229, in _build_with_temp_dir    self.run_setup()  File ""/usr/lib/python3.8/site-packages/setuptools/build_meta.py"", line 281, in run_setup    super(_BuildMetaLegacyBackend,  File ""/usr/lib/python3.8/site-packages/setuptools/build_meta.py"", line 174, in run_setup    exec(compile(code, __file__, 'exec'), locals())  File ""setup.py"", line 458, in <module>    setup_package()  File ""setup.py"", line 440, in setup_package    generate_cython()  File ""setup.py"", line 248, in generate_cython    raise RuntimeError(""Running cythonize failed!"")RuntimeError: Running cythonize failed!ERROR Backend subproccess exited when trying to invoke build_wheel```</details>### NumPy/Python version information:1.22.4
"
21550,1,2430,90,0,0,ghost,0,"title:RuntimeError: Cannot parse version 0+untagged description:### Describe the issue:Build fails on macOS Monterey 12.3.1 / python 3.10.4 / pip 22.1, not sure whether it's a numpy or pip issue though.### Reproduce the code example:```pythongit clone https://github.com/numpy/numpypip install numpy/```### Error message:```shell% pip install numpy/Processing ./numpy  Installing build dependencies ... done  Getting requirements to build wheel ... error  error: subprocess-exited-with-error    闂?Getting requirements to build wheel did not run successfully.  闂?exit code: 1  闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗霉閿濆懏鎯堟い銉︾閵囧嫰骞橀崡鐐典患缂佺偓鍎冲锟犲蓟閺囥垹閱囨繝闈涙祩濡倝姊虹紒妯肩畵闁绘牕銈搁獮鍐ㄎ旈崨顔芥珳闁硅偐琛ラ崜婵嬫倶閸垻纾? [20 lines of output]      Error in sitecustomize; set PYTHONVERBOSE for traceback:      AssertionError:      Traceback (most recent call last):        File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py"", line 363, in <module>          main()        File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py"", line 345, in main          json_out['return_val'] = hook(**hook_input['kwargs'])        File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pep517/in_process/_in_process.py"", line 130, in get_requires_for_build_wheel          return hook(config_settings)        File ""/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/build_meta.py"", line 177, in get_requires_for_build_wheel          return self._get_build_requires(        File ""/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/build_meta.py"", line 159, in _get_build_requires          self.run_setup()        File ""/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/build_meta.py"", line 281, in run_setup          super(_BuildMetaLegacyBackend,        File ""/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/build_meta.py"", line 174, in run_setup          exec(compile(code, __file__, 'exec'), locals())        File ""setup.py"", line 64, in <module>          raise RuntimeError(f'Cannot parse version {FULLVERSION}')      RuntimeError: Cannot parse version 0+untagged.1.gae8b9ce      [end of output]    note: This error originates from a subprocess, and is likely not a problem with pip.error: subprocess-exited-with-error闂?Getting requirements to build wheel did not run successfully.闂?exit code: 1闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗霉閿濆懏鎯堟い銉︾閵囧嫰骞橀崡鐐典患缂佺偓鍎冲锟犲蓟閺囥垹閱囨繝闈涙祩濡倝姊虹紒妯肩畵闁绘牕銈搁獮鍐ㄎ旈崨顔芥珳闁硅偐琛ラ崜婵嬫倶閸垻纾? See above for output.note: This error originates from a subprocess, and is likely not a problem with pip.```### NumPy/Python version information:python 3.10.4
"
21536,0,0,275,0,1,charris,0,"title:BUG: Fix GCC error during build configuration description:Backport of #21534.GCC 11 fails the configuration test for detecting `strtold_l` when the`-Wall` flag is present because `-Werror=nonnull` is activated. The fixis to add a pragma to `numpy/core/feature_detection_locale.h` to ignorethat error.Closes #21529.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21534,0,0,275,0,1,charris,0,"title:BUG: Fix GCC error during build configuration description:GCC 11 fails the configuration test for detecting `strtold_l` when the`-Wall` flag is present because `-Werror=nonnull` is activated. The fixis to add a pragma to `numpy/core/feature_detection_locale.h` to ignorethat error.Closes #21529.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21529,0,1088,275,0,0,charris,0,"title:Local build testing broken on Fedora 35 by #21154. description:Testing fails locally when checking `long double` with```ERROR numpy/core/tests/test_longdouble.py - UserWarning: Signature b'\x00\xd0\xcc\xcc\xcc\xcc\xcc\xcc\xfb\xbf\xff\x7f\x00\x00\x00\x00...ERROR numpy/core/tests/test_multiarray.py - KeyboardInterruptERROR numpy/core/tests/test_scalar_methods.py - UserWarning: Signature b'\x00\xd0\xcc\xcc\xcc\xcc\xcc\xcc\xfb\xbf\xff\x7f\x00\x00\x00...ERROR numpy/core/tests/test_scalarmath.py - UserWarning: Signature b'\x00\xd0\xcc\xcc\xcc\xcc\xcc\xcc\xfb\xbf\xff\x7f\x00\x00\x00\x00...ERROR numpy/core/tests/test_umath.py - UserWarning: Signature b'\x00\xd0\xcc\xcc\xcc\xcc\xcc\xcc\xfb\xbf\xff\x7f\x00\x00\x00\x00' for...```There are three problems I can see:1. The warning was not issued previous to #21154.2. The warning should be ignored, maybe should not be issued (`numpy/core/getlimits.py` line 346).3. Why is CI not failing? EDIT: Ignoring the warning leads to actual errrors:```ERROR numpy/core/tests/test_longdouble.py - AttributeError: 'MachAr' object has no attribute '_str_smallest_normal'ERROR numpy/core/tests/test_scalar_methods.py - AttributeError: 'MachAr' object has no attribute '_str_smallest_normal'ERROR numpy/core/tests/test_scalarmath.py - AttributeError: 'MachAr' object has no attribute '_str_smallest_normal'ERROR numpy/core/tests/test_umath.py - AttributeError: 'MachAr' object has no attribute '_str_smallest_normal'```EDIT2: gcc (GCC) 11.3.1 20220421 (Red Hat 11.3.1-2)
"
21526,0,4793,76,0,0,hrnciar,0,"title:BUG: Python 3.11.0b1, test_generic_alias, TypeError: 'property' object is not iterable description:### Describe the issue:Numpy's tests are failing with Python 3.11.0b1. test_generic_alias fails with `TypeError: 'property' object is not iterable` during collection. The problem seems to be connected to this change in CPython https://github.com/python/cpython/pull/31143. I am not sure if it's a regression in CPython or Numpy needs to be adapted.### Reproduce the code example:```pythonBuild numpy with Python 3.11.0b1```### Error message:```shell==================================== ERRORS ====================================_____________ ERROR collecting typing/tests/test_generic_alias.py ______________../../../../BUILDROOT/numpy-1.22.3-1.fc37.x86_64/usr/lib64/python3.11/site-packages/numpy/typing/tests/test_generic_alias.py:23: in <module>    FuncType = Callable[[Union[_GenericAlias, types.GenericAlias]], Any]        Any        = typing.Any        Callable   = typing.Callable        DType      = numpy.dtype[+ScalarType]        DType_ref  = numpy.dtype[+ScalarType]        NDArray    = numpy.ndarray[typing.Any, numpy.dtype[+ScalarType]]        NDArray_ref = numpy.ndarray[typing.Any, numpy.dtype[+ScalarType]]        ScalarType = +ScalarType        T1         = ~T1        T2         = ~T2        Tuple      = typing.Tuple        Type       = typing.Type        TypeVar    = <class 'typing.TypeVar'>        Union      = typing.Union        _GenericAlias = <class 'numpy.typing._generic_alias._GenericAlias'>        __builtins__ = <builtins>        __cached__ = '/builddir/build/BUILDROOT/numpy-1.22.3-1.fc37.x86_64/usr/lib64/python3.11/site-packages/numpy/typing/tests/__pycache__/test_generic_alias.cpython-311.pyc'        __doc__    = None        __file__   = '/builddir/build/BUILDROOT/numpy-1.22.3-1.fc37.x86_64/usr/lib64/python3.11/site-packages/numpy/typing/tests/test_generic_alias.py'        __loader__ = <_pytest.assertion.rewrite.AssertionRewritingHook object at 0x7f6280b124d0>        __name__   = 'numpy.typing.tests.test_generic_alias'        __package__ = 'numpy.typing.tests'        __spec__   = ModuleSpec(name='numpy.typing.tests.test_generic_alias', loader=<_pytest.assertion.rewrite.AssertionRewritingHook obje...uild/BUILDROOT/numpy-1.22.3-1.fc37.x86_64/usr/lib64/python3.11/site-packages/numpy/typing/tests/test_generic_alias.py')        annotations = _Feature((3, 7, 0, 'beta', 1), (3, 11, 0, 'alpha', 0), 16777216)        copy       = <module 'copy' from '/usr/lib64/python3.11/copy.py'>        np         = <module 'numpy' from '/builddir/build/BUILDROOT/numpy-1.22.3-1.fc37.x86_64/usr/lib64/python3.11/site-packages/numpy/__init__.py'>        pickle     = <module 'pickle' from '/usr/lib64/python3.11/pickle.py'>        pytest     = <module 'pytest' from '/usr/lib/python3.11/site-packages/pytest/__init__.py'>        sys        = <module 'sys' (built-in)>        types      = <module 'types' from '/usr/lib64/python3.11/types.py'>        weakref    = <module 'weakref' from '/usr/lib64/python3.11/weakref.py'>/usr/lib64/python3.11/typing.py:350: in inner    return func(*args, **kwds)        args       = (typing.Union, (<class 'numpy.typing._generic_alias._GenericAlias'>, <class 'types.GenericAlias'>))        cached     = <functools._lru_cache_wrapper object at 0x7f62815f5380>        func       = <function _SpecialForm.__getitem__ at 0x7f62815fc7c0>        kwds       = {}/usr/lib64/python3.11/typing.py:450: in __getitem__    return self._getitem(self, parameters)        parameters = (<class 'numpy.typing._generic_alias._GenericAlias'>, <class 'types.GenericAlias'>)        self       = typing.Union/usr/lib64/python3.11/typing.py:661: in Union    return _UnionGenericAlias(self, parameters)        msg        = 'Union[arg, ...]: each arg must be a type.'        parameters = (<class 'numpy.typing._generic_alias._GenericAlias'>, <class 'types.GenericAlias'>)        self       = typing.Union/usr/lib64/python3.11/typing.py:1317: in __init__    self.__parameters__ = _collect_parameters(args)        __class__  = <class 'typing._GenericAlias'>        _paramspec_tvars = False        args       = (<class 'numpy.typing._generic_alias._GenericAlias'>, <class 'types.GenericAlias'>)        inst       = True        name       = None        origin     = typing.Union        self       = typing.Union[numpy.typing._generic_alias._GenericAlias, types.GenericAlias]/usr/lib64/python3.11/typing.py:257: in _collect_parameters    for x in getattr(t, '__parameters__', ()):E   TypeError: 'property' object is not iterable        args       = (<class 'numpy.typing._generic_alias._GenericAlias'>, <class 'types.GenericAlias'>)        parameters = []        t          = <class 'numpy.typing._generic_alias._GenericAlias'>=========================== short test summary info ============================ERROR ../../typing/tests/test_generic_alias.py - TypeError: 'property' object...!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!1296 deselected, 1 error in 8.48shttps://download.copr.fedorainfracloud.org/results/@python/python3.11/fedora-rawhide-x86_64/04417682-numpy/builder-live.log.gz```### NumPy/Python version information:numpy 1.22.3python 3.11.0b1
"
21519,1,1836,90,0,1,ghost,0,"title:BUG: TypeError: 'NoneType' object is not callable description:### Describe the issue:Use [sample.zip](https://github.com/numpy/numpy/files/8701836/sample.zip) to run the exampleI need to know whether this is a numpy issue or a cython issue or pycharm's. The error only happens in pycharm debugger under ambiguous circumstances, and it is a known [issue](https://youtrack.jetbrains.com/issue/PY-52137). There are [mentions](https://youtrack.jetbrains.com/issue/PY-52137/Debugger-fails-with-numpy-getlimits-TypeError-NoneType-object-is#focus=Comments-27-6068544.0-0) that it's a cython [issue](https://github.com/cython/cython/pull/4735) despite the failure occurring in `numpy/core/getlimits.py Line 649`. I need to know where the problem originates and if it's a numpy issue, is there some merged fix?**Update:** The error is gone after building cython with the fix, numpy, pandas, and scikit-learn### Reproduce the code example:```pythonimport pandas as pdfrom sklearn.feature_extraction.text import CountVectorizerdf = pd.read_parquet('sample.parquet')corpus = df[df['cell_type'] == 'markdown']['source']vec = CountVectorizer(ngram_range=(1, 1))vec.fit(corpus)```### Error message:```shellTraceback (most recent call last):  File ""/usr/local/lib/python3.10/site-packages/numpy/core/getlimits.py"", line 649, in __init__    self.dtype = numeric.dtype(int_type)TypeError: 'NoneType' object is not callableDuring handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py"", line 1491, in _exec    pydev_imports.execfile(file, globals, locals)  # execute the script  File ""/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile    exec(compile(contents+""\n"", file, 'exec'), glob, loc)  File ""/Users/user/Library/Application Support/JetBrains/PyCharm2022.1/scratches/scratch_3.py"", line 7, in <module>    vec.fit(corpus)  File ""/usr/local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py"", line 1283, in fit    self.fit_transform(raw_documents)  File ""/usr/local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py"", line 1330, in fit_transform    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)  File ""/usr/local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py"", line 1224, in _count_vocab    if indptr[-1] > np.iinfo(np.int32).max:  # = 2**31 - 1  File ""/usr/local/lib/python3.10/site-packages/numpy/core/getlimits.py"", line 651, in __init__    self.dtype = numeric.dtype(type(int_type))TypeError: 'NoneType' object is not callablepython-BaseException```### NumPy/Python version information:```python: 3.10.4numpy: 1.22.3```
"
21518,0,0,292,0,1,seberg,0,"title:BUG: Fix complex+longdouble and broken subclass handling description:When we see a complex number, we should go into the ""promotion"" patheven for longdouble.  That is because the complex number will behavethe same as a NumPy complex scalar and thus promotion works fine(no issue with potential infinite recursion that would happen if wego into the object loop).Further, with a slight slowdown (but not slower than before), we nowcheck for subclasses of int, float, complex always and while we docheck whether we should defer, coercion is considered valid.That is: We do not explicitly defer to a subclass of float unless e.g.`__array_ufunc__ = None` or `__array_priority__` is set.Some (arguably broken) subclasses may for exampleonly add an `__rop__`,but not an `__op__`.  For these, the previous `is_forward` logic did notwork out correctly and could go into the wrong branch.This is now fixed, by first checking for exact maches, and then alsochecking for subclass, it should be safe to assume that one operandis a subclass, but that is the only thing we can assume.I now think that the only way to possibly get subclassing right, wouldbe by defining `__op__` and `__rop__` on a class to ensure that thesubclass cannot possibly inherit the base version.(To be clear, I do not think that is worthwhile, and Python does notdo it either.)Closes gh-21481.---Sorry that this is a rather large change again :(.  But making the ""check for defering"" more explicit seemed like a good idea.  The old code actually just checked always, if that seems nicer...In principle we could also keep the exact checks as fast-paths and do the subclass checks at the end (which should micro-optimize things a bit), but I guess ths should be good at least for now.
"
21513,0,98,300,0,0,RashulChutani,0,"title:BUG: np.linspace(-0.0, 0.0, 1) outpus [0.] which does not include the start value which is -0.0. description:### Describe the issue:Running np.linspace (-0.0, 0.0, 1) outputs array([0.]) which does not include the start value (-0.0).The documentation says Returns samples: ndarrayThere are num equally spaced samples in the closed interval [start, stop] or the half-open interval [start, stop) (depending on whether endpoint is True or False).Thus the start value should be always included.### Reproduce the code example:```pythonimport numpy as npnp.linspace(-0.0, 0.0, 1)```### Error message:```shellThe output is [0.0] instead of [-0.0].```### NumPy/Python version information:Numpy: 1.22.3 3.9.12 sys: [GCC 7.5.0]
"
21510,1,87,0,0,0,bjlBYUI,0,"title:numpy.poly1d variable option not working description:### Describe the issue:When using the variable option in numpy.poly1d, the variable is not changing from 'x' if the poly1d object is manipulated after creation.In the example below, the polynomial printed should show 'T' as the variable, but 'x' is showing.If the f = f/a is left out in the example, the print shows the correct 'T' variable.### Reproduce the code example:```pythonimport numpy as npa = 5f = np.poly1d([1,1],variable='T')f = f/aprint(f)```### Error message:_No response_### NumPy/Python version information:numpy version 1.22.3Python 3.10.4 (v3.10.4:9d38120e33, Mar 23 2022, 17:29:05) [Clang 13.0.0 (clang-1300.0.29.30)] on darwin
"
21509,1,509,0,0,0,CHARLESYY-CAFELATTE,0,"title:BUG: argsort description:### Describe the issue:np.argsort cannot really sort an array### Reproduce the code example:```pythonimport numpy as npscores = np.random.randn(10,2)print(scores)scores = np.argsort(scores,axis=0)print(scores)```### Error message:```shellerror output as:[[-0.93424302 -0.25495421] [-0.0445277  -0.7277739 ] [-0.49270801  0.18517224] [ 0.34054662  0.88074911] [ 0.37625286 -0.86732847] [-0.50659025  0.2918364 ] [-1.034566   -0.75474416] [ 1.74318646  1.93941125] [ 0.76326831  0.5199335 ] [ 0.54829216 -0.67852352]][[6 4] [0 6] [5 1] [2 9] [1 0] [3 2] [4 5] [9 8] [8 3] [7 7]]```### NumPy/Python version information:numpy==1.22.3python=3.8
"
21507,0,0,86,1,0,ganesh-k13,0,"title:BUG: Better report integer division overflow description:### Changes- Handle overflow cases- Testcases for sameRelated: https://github.com/numpy/numpy/issues/21506Finishes: https://github.com/numpy/numpy/pull/19260
"
21506,0,5335,86,1,1,ganesh-k13,0,"title:BUG: Division overflow tracking issue description:### Describe the issue:Currently, there are various cases where division leads to overflow/arithmetic exceptions. This happens when the dividend is the smallest possible value of the dtype and the divisor is `-1`.Example: ```pynp.iinfo(np.int32).min % np.int32(-1)```### Reproduce the code example:https://gist.github.com/ganesh-k13/6faaf65d418db13012bd403250cca70a```python~ 缂?python3 overflow.py                                                                                                                                                                                         ganesh@ganesh-MS-7B86 1.22.3                                                                                                                                                                                                                                Scalars: 100%|闂傚倸鍊风粈渚€鎮块崶顒夋晪鐟滄棃骞冭瀹曟﹢顢欓悡搴℃闂備礁鎲＄粙鎺戭焽濞嗘挻鍋傛繝闈涱儐閻撴洘銇勯幇鍓佹偧妞わ絾鐓￠弻锝嗘償濠靛棗绁梺鍝勮嫰缁夊爼骞忛悩缁樺殤妞ゆ巻鍋撴い锝囨暬濮婃椽宕崟闈涘壈闂佺娅曢敃銏犵暦濞差亜顫呴柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎺戝€归?48/48 [00:04<00:00, 10.65it/s]Arrays: 100%|闂傚倸鍊风粈渚€鎮块崶顒夋晪鐟滄棃骞冭瀹曟﹢顢欓悡搴℃闂備礁鎲＄粙鎺戭焽濞嗘挻鍋傛繝闈涱儐閻撴洘銇勯幇鍓佹偧妞わ絾鐓￠弻锝嗘償濠靛棗绁梺鍝勮嫰缁夊爼骞忛悩缁樺殤妞ゆ巻鍋撴い锝囨暬濮婃椽宕崟闈涘壈闂佺娅曢敃銏犵暦濞差亜顫呴柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█閹崇娀顢楅埀顒勩€傞悽鍛娾拺闁告繂瀚烽崕蹇涙煙閾忣偓鑰跨€规洘妞芥慨鈧柕鍫濇嚇閸炶泛鈹戦鏂や緵闁告﹢绠栭崺鈧い鎴濈仢瀹撳棝鏌＄仦鐣屝ら柟椋庡█瀹曪絾寰勫畝鈧粻?48/48 [00:04<00:00, 10.26it/s]Scalar Failures Observed:                                                                                                                                                                                                             +--------------+------------------+-----------------+| operation    | dividend_dtype   | divisor_dtype   |+==============+==================+=================+| np.remainder | np.int32         | np.int8         |+--------------+------------------+-----------------+| np.fmod      | np.int32         | np.int8         |+--------------+------------------+-----------------+| np.remainder | np.int32         | np.int16        |+--------------+------------------+-----------------+| np.fmod      | np.int32         | np.int16        |+--------------+------------------+-----------------+| np.remainder | np.int32         | np.int32        |+--------------+------------------+-----------------+| np.fmod      | np.int32         | np.int32        |                                                                                                                                                                                 +--------------+------------------+-----------------+                                                                                                                                                                                 | np.remainder | np.int64         | np.int8         |+--------------+------------------+-----------------+| np.fmod      | np.int64         | np.int8         |+--------------+------------------+-----------------+| np.remainder | np.int64         | np.int16        |+--------------+------------------+-----------------+| np.fmod      | np.int64         | np.int16        |+--------------+------------------+-----------------+| np.remainder | np.int64         | np.int32        |+--------------+------------------+-----------------+| np.fmod      | np.int64         | np.int32        |+--------------+------------------+-----------------+| np.remainder | np.int64         | np.int64        |+--------------+------------------+-----------------+| np.fmod      | np.int64         | np.int64        |+--------------+------------------+-----------------+Array Failures Observed:+--------------+------------------+-----------------+| operation    | dividend_dtype   | divisor_dtype   |+==============+==================+=================+| np.remainder | np.int32         | np.int8         |+--------------+------------------+-----------------+| np.fmod      | np.int32         | np.int8         |+--------------+------------------+-----------------+| np.remainder | np.int32         | np.int16        |+--------------+------------------+-----------------+| np.fmod      | np.int32         | np.int16        |+--------------+------------------+-----------------+| np.remainder | np.int32         | np.int32        |+--------------+------------------+-----------------+| np.fmod      | np.int32         | np.int32        |+--------------+------------------+-----------------+| np.remainder | np.int32         | np.int64        |+--------------+------------------+-----------------+| np.fmod      | np.int32         | np.int64        |+--------------+------------------+-----------------+| np.remainder | np.int64         | np.int8         |+--------------+------------------+-----------------+| np.fmod      | np.int64         | np.int8         |+--------------+------------------+-----------------+| np.remainder | np.int64         | np.int16        |+--------------+------------------+-----------------+| np.fmod      | np.int64         | np.int16        |+--------------+------------------+-----------------+| np.remainder | np.int64         | np.int32        |+--------------+------------------+-----------------+| np.fmod      | np.int64         | np.int32        |+--------------+------------------+-----------------+| np.remainder | np.int64         | np.int64        |+--------------+------------------+-----------------+| np.fmod      | np.int64         | np.int64        |+--------------+------------------+-----------------+```### Error message:```shell>>> np.iinfo(np.int64).min % np.int64(-1)[1]    61277 floating point exception (core dumped)  python3```### NumPy/Python version information:1.22.3 3.10.4 (main, Apr  2 2022, 09:04:19) [GCC 11.2.0]### Relate Issues and PRs:- https://github.com/numpy/numpy/issues/19246- https://github.com/numpy/numpy/pull/19260### ToDo- [x] Fix scalar overflow,- [x] Raise the right warning, xref: https://github.com/numpy/numpy/commit/f253ac2ab58884d6da18c429c0823c34b72092f9, related: https://github.com/numpy/numpy/pull/21188- [x] Handle SIMD oveflow
"
21497,1,0,0,0,1,RamyaNP,0,"title:BUG: array_split with list ary and nonzero axis returns wrong result description:Fixes #21476. array_split now works with array-like objects of the axis parameter is given as 1. The issue also mentions something about the function split. I wasn't sure what the problem was with it. <!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21496,1,174,19,0,0,onnoeberhard,0,"title:BUG: `np.full_like` casts float to int for non-finite values description:### Describe the issue:Please see the code snippet below. I create an integer array `a`, then create a new one (`b`) which is supposed to have the same shape as `a`, but filled with the float value `np.nan`. Here, I don't explicitly set the dtype for `b`. NumPy converts these float values to integer.This is unexpected behaviour, and I assume is not intended as such. I would have expected either1. `b` is automatically made a float-array (the dtype information from `a` is not used), or2. A TypeError is thrown, notifying me that I am trying to fill an int-array with float values.### Reproduce the code example:```python>>> import numpy as np>>> a = np.array([1, 2, 3])>>> b = np.full_like(a, np.nan)>>> barray([-9223372036854775808, -9223372036854775808, -9223372036854775808])```### Error message:_No response_### NumPy/Python version information:1.22.3 3.8.12 (default, Oct 22 2021, 18:39:35) [Clang 13.0.0 (clang-1300.0.29.3)]
"
21495,0,0,2,0,0,Snape3058,0,"title:BUG: Potential memory leak in function `gentype_reduce` (a static analyzer report) description:### Reproducing code example:**Static analysis results, no POC.**This static analysis report has been manually verified as a real bug and still exists in the latest version.### Error message:The path provided by the static analyzer is as follows.1. A new reference is returned from `PyTuple_New` and pointed to by `ret`.https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/scalartypes.c.src#L17332. Assume `ret` is not NULL.https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/scalartypes.c.src#L17342. Call function `PyImport_ImportModule`, assign return value to `mod`.https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/scalartypes.c.src#L17544. Assume `mod` is NULL,https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/scalartypes.c.src#L17555. Function returns without decreasing the refcnt of `ret`.https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/scalartypes.c.src#L1756Similarly, other non-decreased returns.https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/scalartypes.c.src#L1761https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/scalartypes.c.src#L1769https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/scalartypes.c.src#L1777https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/scalartypes.c.src#L1782### NumPy/Python version information:Static analysis carried out on commit 04ab04d.Internal bug report ID: NumPy-3f42e1 (1756), NumPy-be991e (1777)
"
21494,0,0,2,0,0,Snape3058,0,"title:BUG: Potential memory leak in function `get_struct_alignments` (a static analyzer report) description:### Reproducing code example:**Static analysis results, no POC.**This static analysis report has been manually verified as a real bug.### Error message:The path provided by the static analyzer is as follows.1. A new reference is returned from `PyTuple_New` and pointed to by `ret`.https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/_multiarray_tests.c.src#L20102. Call function `PyTuple_Pack`, assign return value to `val`.https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/_multiarray_tests.c.src#L20184. Assume `val` is NULL,https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/_multiarray_tests.c.src#L20215. Function returns without decreasing the refcnt of `ret`.https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/_multiarray_tests.c.src#L2022### NumPy/Python version information:Static analysis carried out on commit 04ab04d.Internal bug report ID: NumPy-dc1841
"
21493,0,0,2,0,0,Snape3058,0,"title:BUG: Potential memory leak in function `get_all_cast_information` (a static analyzer report) description:### Reproducing code example:**Static analysis results, no POC.**This static analysis report has been manually verified as a real bug.### Error message:The path provided by the static analyzer is as follows.1. A new reference is returned from `PyList_New` and pointed to by `result`.https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/_multiarray_tests.c.src#L10312. Assume `result` is not NULL.https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/_multiarray_tests.c.src#L10323. Call function `PyObject_CallMethod`, assign return value to `classes`.https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/_multiarray_tests.c.src#L10354. Assume `classes` is NULL,https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/_multiarray_tests.c.src#L10375. Function returns without decreasing the refcnt of `result`.https://github.com/numpy/numpy/blob/e49478c74282bc8f9cb86816897302724d95d5ab/numpy/core/src/multiarray/_multiarray_tests.c.src#L1038### NumPy/Python version information:Static analysis carried out on commit 04ab04d.Internal bug report ID: NumPy-86c782
"
21492,0,0,271,0,1,WarrenWeckesser,0,"title:BUG: lib: Allow type uint64 for eye() arguments. description:Closes gh-9982.(Plus a few small PEP 8 fixes.)
"
21481,0,3708,292,0,1,seberg,0,"title:BUG: Scalar changes did not capture `longdouble + complex` semantics fully description:SciPy is noticing these changes with NumPy main:```=================================== FAILURES ===================================_________________ TestCorrelateComplex.test_rank0[complex256] __________________../testenv/lib/python3.10/site-packages/scipy/signal/tests/test_signaltools.py:2155: in test_rank0    y_r += 1j * (-correlate(a.real, b.imag) + correlate(a.imag, b.real))E   TypeError: unsupported operand type(s) for *: 'complex' and 'numpy.float128'        a          = array(-0.7940189+1.39564349j, dtype=complex256)        b          = array(-0.25786004-0.99202761j, dtype=complex256)        dt         = <class 'numpy.complex256'>        self       = <scipy.signal.tests.test_signaltools.TestCorrelateComplex object at 0x7f8925201450>        y_r        = (-1.1797711271213198454+0j)________ TestPareto.test_fit_MLE_comp_optimzer[True-True-False-1-0-0.1] ________../testenv/lib/python3.10/site-packages/scipy/stats/tests/test_distributions.py:1556: in test_fit_MLE_comp_optimzer    args = [data, (stats.pareto._fitstart(data), )]        data       = array([2.12029996e+16, 1.19523801e+02, 1.40929869e+11, 2.07791008e+01,       4.66818325e+01, 3.51368966e+00, 1.592095...1.41045904e+00, 4.88716443e+02, 9.77757362e+08,       7.49791702e+01, 3.41238972e+07, 5.93724048e+12, 2.00158051e+00])        fix_loc    = True        fix_scale  = False        fix_shape  = True        rng        = Generator(PCG64) at 0x7F890CDA7CA0        rvs_loc    = 0        rvs_scale  = 1        rvs_shape  = 0.1        self       = <scipy.stats.tests.test_distributions.TestPareto object at 0x7f8921b78dc0>../testenv/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:2417: in _fitstart    loc, scale = self._fit_loc_scale_support(data, *args)        args       = (1.0,)        data       = array([2.12029996e+16, 1.19523801e+02, 1.40929869e+11, 2.07791008e+01,       4.66818325e+01, 3.51368966e+00, 1.592095...1.41045904e+00, 4.88716443e+02, 9.77757362e+08,       7.49791702e+01, 3.41238972e+07, 5.93724048e+12, 2.00158051e+00])        self       = <scipy.stats._continuous_distns.pareto_gen object at 0x7f892ad18e20>../testenv/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:2716: in _fit_loc_scale_support    loc_hat, scale_hat = self.fit_loc_scale(data, *args)        args       = (1.0,)        data       = array([2.12029996e+16, 1.19523801e+02, 1.40929869e+11, 2.07791008e+01,       4.66818325e+01, 3.51368966e+00, 1.592095...1.41045904e+00, 4.88716443e+02, 9.77757362e+08,       7.49791702e+01, 3.41238972e+07, 5.93724048e+12, 2.00158051e+00])        self       = <scipy.stats._continuous_distns.pareto_gen object at 0x7f892ad18e20>../testenv/lib/python3.10/site-packages/scipy/stats/_distn_infrastructure.py:2784: in fit_loc_scale    Lhat = muhat - Shat*muE   RuntimeWarning: invalid value encountered in multiply        Shat       = 0.0        args       = (1.0,)        data       = array([2.12029996e+16, 1.19523801e+02, 1.40929869e+11, 2.07791008e+01,       4.66818325e+01, 3.51368966e+00, 1.592095...1.41045904e+00, 4.88716443e+02, 9.77757362e+08,       7.49791702e+01, 3.41238972e+07, 5.93724048e+12, 2.00158051e+00])        mu         = array(inf)        mu2        = array(inf)        mu2hat     = 1.659444495471661e+40        muhat      = 1.3225472615245095e+19        self       = <scipy.stats._continuous_distns.pareto_gen object at 0x7f892ad18e20>        tmp        = array([2.12029996e+16, 1.19523801e+02, 1.40929869e+11, 2.07791008e+01,       4.66818325e+01, 3.51368966e+00, 1.592095...1.41045904e+00, 4.88716443e+02, 9.77757362e+08,       7.49791702e+01, 3.41238972e+07, 5.93724048e+12, 2.00158051e+00])```The first one is that for `1j * np.longdouble(3)` the longdouble gives up, but at least for this specific case it should not.  (I have to check the exact logic that we had, in theory, we do not need to give up for any object such that `np.array(obj)` is not a 0-D object array).The second (which causes many more identical ones), actually seems correct to me.  The code does call `0.0 * inf` of sort, which *should* give a warning.  Unless there is a warning filter active here and being missed.Although, there, I am still surprised that the behavior changed.  ThisIn this particular case, i tmay be that the the new code goes through the full `ufunc` path and the old code did not.  But even then, the old code should have given the warning also.Thanks @jarrodmillman for pointing this out.
"
21478,1,0,133,0,0,MicK7,0,"title:BUG: try to keep array ordering in expand_dims description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21473,0,0,275,1,1,charris,0,"title:BUG: Fix segmentation fault (#21436) description:Backport of #21436.BUG: Fixed segmentation fault with numpy.ufunc.at when ufunc hasnontrivial signature, issue #21301.Test cases were added in numpy/core/tests/test_ufunc.py to show thatwhen numpy.ufunc.at uses ufunc with nontrivial signature, thenTypeError should be raised, instead of a potential segmentation fault.Test cases were also added to show that ufunc with trivial signature isstill valid and works as intended. See [issue #21301](https://github.com/numpy/numpy/issues/21301). * Fixed #21301* Fixed #21436, better error message, organized test cases as requested* Update numpy/core/src/umath/ufunc_object.cCo-authored-by: Sebastian Berg <sebastian@sipsolutions.net><!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21472,0,0,275,0,0,charris,0,"title:BUG: Ensure compile errors are raised correclty description:Backport of #21442.This has been bugging me for a bit.  The concurrent.futures Executorrequires checking the result for the error to be raised.  That makessense, but just means we need to consume the result explicitly hereto ensure we know about compile errors.Otherwise, compile errors just pass silently (which is very confusingif the old object files are still around and the tests run based onthe old version).<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21469,1,1208,296,0,0,eendebakpt,0,"title:BUG: runtests.py fails with no-build option description:### Describe the issue:I am trying to run the tests without rebuilding numpy. I use the following command:```python runtests.py -n -v -t numpy/core/tests/test_nditer.py```it fails with error message:```..../usr/lib/python3/dist-packages/celery/utils/collections.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working  from collections import Callable, Mapping, MutableMapping, MutableSet================================================================== test session starts ==================================================================platform linux -- Python 3.8.10, pytest-6.2.5, py-1.11.0, pluggy-0.13.1rootdir: /mnt/data/numpy, configfile: pytest.iniplugins: importnb-0.7.0, hypothesis-6.24.1, cov-3.0.0, xonsh-0.9.13, celery-4.2.1collected 0 items                                                                                                                                       ================================================================= no tests ran in 0.03s =================================================================ERROR: module or package not found: numpy/core/tests/test_nditer.py (missing __init__.py?)```The goal is to use numpy from the source directory, but it seems it is trying to run with the system installed numpy.### Reproduce the code example:```pythonpython runtests.py -n -v -t numpy/core/tests/test_nditer.py```### Error message:_No response_### NumPy/Python version information:1.23.0.dev0+1129.gcd22d7df7 3.8.10 (default, Mar 15 2022, 12:22:08) [GCC 9.4.0]
"
21460,0,718,0,0,0,bribritos,0,"title:BUG: ESPILON with np.finfo(float).eps outputs a TypeError description:### Describe the issue:Hi,I have recently created a new python environment using the 3.10.4 python version. I have installed the latest public version (1.22.3) and when I am trying to catch the epsilon, I have an error that cannot allow me to use the command: numpy.finfo(float).eps or numpy.finfo(numpy.float32).epsThis can be very inconvenient because I hwill use some solutions of Scikit-Learn that calls this.Sorry for the inconvenience. Best.### Reproduce the code example:```pythonimport numpy as npeps = np.finfo(float).eps```### Error message:```shellTraceback (most recent call last):**  File ""C:\Users\ME\2022_deepl\lib\site-packages\numpy\core\getlimits.py"", line 459, in __new__    dtype = numeric.dtype(dtype)TypeError: 'numpy.dtype[bool_]' object is not callableDuring handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""C:\Users\ME\AppData\Local\Temp\ipykernel_10948\2225752278.py"", line 1, in <cell line: 1>    np.finfo(float).eps  File ""C:\Users\ME\2022_deepl\lib\site-packages\numpy\core\getlimits.py"", line 462, in __new__    dtype = numeric.dtype(type(dtype))TypeError: 'numpy.dtype[bool_]' object is not callable```### NumPy/Python version information:1.22.3 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]
"
21455,0,488,296,0,0,eendebakpt,0,"title:BUG: np.mean is slower than np.sum + a division description:### Describe the issue:Using `np.mean` takes longer than `np.sum` and then manually dividing by the number of elements.Benchmark result of `np.mean(x)` vs. `np.sum(x)/x.size`:```np.mean  0.8456945639991318np.sum + division 0.5549134930006403```(benchmark itself in the reproduce code block below)**Analysis**Using valgrind I did some profiling on `np.mean`.![np_mean_axis_1](https://user-images.githubusercontent.com/883786/167017630-c74eacd7-7afb-4568-8b5e-56dcf979b180.png)Below the `ufunc_generic_fastcall` there are large 4 blocks that I analyse below.- There is an expensive call to `solve_may_share_memory` (via `ufunc_generic_fastcall -> PyUFunc_GenericFunctionInternal -> try_trivial_single_output_loop -> PyArray_EQUIVALENTLY_ITERABLE_OVERLAP_OK -> solve_may_share_memory`). This is for a ufunc called `divide` (the second step in the `mean` calculation).But the call to the `ufunc_generic_fastcall` was without keyword arguments and `out_is_passed_by_position=0`. So a new output array is allocated for the result and this cannot overlap with the input arrays. If this is really the case, can we pass this knowledge to `try_trivial_single_output_loop` somehow to prevent the `PyArray_EQUIVALENTLY_ITERABLE_OVERLAP_OK` check?- The `PyUFunc_CheckOverride` is expensive due to the `__array_ufunc__` attribute missing. There are multiple ways of improving this, but there is already an issue at cpython: https://github.com/python/cpython/issues/92216 than might help here- Resolving `PyUFunc_TrueDivisionTypeResolver` takes some time. The method is from `ufunc_type_resolution.c`, which is marked as legacy code. Can we avoid getting at this point? It is called from `promote_and_get_info_and_ufuncimpl` (`dispatching.c`). In the code it is noted that""Using promotion failed, this should normally be an error."". What is happening there? All types involves are `float64` I guess, so it should not be hard to find the right `ufunc implementation`.- Why the PyArray_CastToType? It is called from `check_for_trivial_loop `where `must_copy` is `True`. The array is small so a copy is made@seberg ### Reproduce the code example:```pythonimport numpy as npimport timex=np.random.rand(5,8)   niter=10_0000t0=time.perf_counter()for kk in range(niter):        v1=np.mean(x, axis=1)dt1=time.perf_counter()-t0print(f'np.mean  {dt1}')t0=time.perf_counter()for kk in range(niter):    v=np.sum(x, axis=1)    v2=v/x.shape[1]dt2=time.perf_counter()-t0print(f'np.sum + division {dt2}')np.testing.assert_array_equal(v1, v2)```### Error message:_No response_### NumPy/Python version information:>>> import sys, numpy; print(numpy.__version__, sys.version)1.23.0.dev0+1127.g7f77205be 3.8.10 (default, Mar 15 2022, 12:22:08) [GCC 9.4.0]
"
21447,0,0,275,0,1,charris,0,"title:BUG: Stop using PyBytesObject.ob_shash deprecated in Python 3.11. description:Backport of #21321.This is unnecessary because a cached hash value should not be computed yet for `obj`. Moreover `PyBytesObject.ob_shash` was deprecated in Python 3.11, see https://github.com/python/cpython/issues/91020.Fixes #21317.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21446,0,0,275,0,0,charris,0,"title:BUG: Make mmap handling safer in frombuffer description:Backport of #21324.`frombuffer` always used the old buffer protocol, but this is notsafe in some cases when combined with the ""new"" one.The main/only use-case that was ever found for this is that enablingthe new buffer protocol (by going through a memoryview) protectsusers from accidentally closing memorymaps while they are still used.Closes gh-9537<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21445,0,0,275,1,0,charris,0,"title:BUG: Allow legacy dtypes to cast to datetime again description:Backport of #21372.This constraint was added out of a caution with the thought that nobodyuses it. Turns out ora does use it.In practice, this only affects cast to and from datetimes (or possiblystrings but that seems even less likely).Tested via ora (see https://github.com/numpy/numpy/issues/21365) the paths are not particularly special,but the parametric dtype resolution is in principle missing.This is not particularly problematic, since NumPy barely exposes thatthough, and it never worked.Closes https://github.com/numpy/numpy/issues/21365---Test is missing, it could be added a rational to string cast probably, but overall it seems `ora` is working fine with it (see issue) and I always only added the check because I thought that without a proper dtype resolution, this is probably useless in any case.  (proper dtype resolution was not possible previously)If there is a small chance of another 1.21.x release, this should also be backported to there.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21444,0,0,275,1,0,charris,0,"title:BUG: add linux guard per #21386 description:Backport of #21392.Closes https://github.com/numpy/numpy/issues/21386.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21442,0,0,292,0,0,seberg,0,"title:BUG: Ensure compile errors are raised correctly description:This has been bugging me for a bit.  The concurrent.futures Executorrequires checking the result for the error to be raised.  That makessense, but just means we need to consume the result explicitly hereto ensure we know about compile errors.Otherwise, compile errors just pass silently (which is very confusingif the old object files are still around and the tests run based onthe old version).
"
21439,1,209,0,0,0,casesyh,0,"title:BUG: <numpy array passing the address instead of content> description:### Describe the issue:As in the example below, `a` is a np array. `b = a` passed the content of `a` to `b`. Afterwards `b` is added with a constant array a few times by a loop with `b+= constant array`. When the loop is done, `a` and `b` are both printed out and they showed the same array which is supposed to be the content of `b`. However, `a` is not supposed to be updated in this case. A reason I suspected is that the memory of `a` is passed to `b` instead of only the content so `a` is updated when `b` is updated. I tested that when `a` is a number instead of a np array, `a` is not updated so there's not the problem. It's straightforward to see the problem in the example below.Thanks,Yuhao.### Reproduce the code example:```python>>> import numpy as np>>> a = np.array([1, 2, 3])>>> b = a>>> print(b)[1 2 3]>>> for i in range(3):...     b+= np.array([1, 2, 3])...>>> print(b)[ 4  8 12]>>> print(a)[ 4  8 12]```### Error message:_No response_### NumPy/Python version information:Python 3.10.0rc2 (tags/v3.10.0rc2:839d789, Sep  7 2021, 18:51:45) [MSC v.1929 64 bit (AMD64)] on win32Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> print(numpy.__version__, sys.version)1.22.3 3.10.0rc2 (tags/v3.10.0rc2:839d789, Sep  7 2021, 18:51:45) [MSC v.1929 64 bit (AMD64)]The problem was first seen inPython 3.6.3 (default, Apr 26 2018, 13:16:02) [GCC 4.4.7 20120313 (Red Hat 4.4.7-18)] on linux>>> print(numpy.__version__, sys.version)1.19.5 3.6.3 (default, Apr 26 2018, 13:16:02) [GCC 4.4.7 20120313 (Red Hat 4.4.7-18)]
"
21436,0,0,0,1,1,JohnnyOu,0,"title:BUG: Fix segmentation fault description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      https://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      https://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      https://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->BUG: Fixed segmentation fault with numpy.ufunc.at when ufunc hasnontrivial signature, issue #21301.Test cases were added in numpy/core/tests/test_ufunc.py to show thatwhen numpy.ufunc.at uses ufunc with nontrivial signature, thenTypeError should be raised, instead of a potential segmentation fault.Test cases were also added to show that ufunc with trivial signature isstill valid and works as intended. See [issue #21301](https://github.com/numpy/numpy/issues/21301). 
"
21432,1,437,288,0,0,germa89,0,"title:BUG: ``np.allclose`` evaluate different zero and non-zero dimensions description:### Describe the issue:It seems that ``numpy.allclose`` evaluates```pyimport numpy>>> assert np.allclose(    np.reshape([1,2,3], (3,)),    np.reshape([1,2,3], (3,1))   )False```but```py>>> assert np.allclose(    np.reshape([3,3,3], (3,)),    np.reshape([3,3,3], (3,1))   )True```I cannot find the logic behind this. Using Numpy ``1.22.0``.### Reproduce the code example:```pythonimport numpyassert np.allclose(    np.reshape([1,2,3], (3,)),    np.reshape([1,2,3], (3,1))   )assert np.allclose(    np.reshape([3,3,3], (3,)),    np.reshape([3,3,3], (3,1))   )```### Error message:```shellN/A```### NumPy/Python version information:1.22.0 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]
"
21428,0,1501,292,0,0,seberg,0,"title:DEV: `runtests.py --bench-compare` is not working currently description:The benchmarks are currently not running.  I expect this is due to how `asv` installs into the environment and using a new `setuptools` rather than the pinned, old version.  This leads to the following:```     Preparing metadata (setup.py): started     Running command python setup.py egg_info     Running from numpy source directory.     /home/sebastian/forks/numpy/benchmarks/env/50b802d75598d79f19544d50ebb57d10/project/setup.py:86: DeprecationWarning:       `numpy.distutils` is deprecated since NumPy 1.23.0, as a result       of the deprecation of `distutils` itself. It will be removed for       Python >= 3.12. For older Python versions it will remain present.       It is recommended to use `setuptools < 60.0` for those Python versions.       For more details, see:         https://numpy.org/devdocs/reference/distutils_status_migration.html       import numpy.distutils.command.sdist     error: Multiple top-level packages discovered in a flat-layout: ['numpy', 'branding'].     To avoid accidental inclusion of unwanted files or directories,     setuptools will not proceed with this build.     If you are trying to create a single distribution with multiple packages     on purpose, you should not rely on automatic discovery.     Instead, consider the following options:     1. set up custom discovery (`find` directive with `include` or `exclude`)     2. use a `src-layout`     3. explicitly set `py_modules` or `packages` with a list of names     To find more information, look for ""package discovery"" on setuptools docs.     error: subprocess-exited-with-error        闂?python setup.py egg_info did not run successfully.   闂?exit code: 1```
"
21427,0,332,4,0,0,clo-vis,0,"title:BUG: type of <float> * NDArray[int64] is NDArray[int64] description:### Describe the issue:The type of <float> * NDArray[int64] is not correctly inferred.### Reproduce the code example:```pythonfrom numpy.typing import NDArrayfrom numpy import int64, float64def my_fun(array: NDArray[int64]) -> NDArray[float64]:    return 0.01 * array```### Error message:```shellmypy complains: Incompatible return value type (got ""ndarray[Any, dtype[signedinteger[Any]]]"", expected ""ndarray[Any, dtype[floating[_64Bit]]]"")  [return-value]```### NumPy/Python version information:numpy: 1.22.3python: 3.10.4mypy: 0.950
"
21422,1,356,48,0,0,SmartManoj,0,"title:BUG: dereferencing pointer to incomplete type 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨搴ㄦ煕閵夈儺鍤熺紒杈ㄦ尰閹峰懘宕滈崣澹劑姊洪幖鐐测偓鏇㈡偘閻х斂eObject闂? description:### Describe the issue:Build Failed for Python3.11### Reproduce the code example:```pythonpython3.11 -m pip install git+https://github.com/numpy/numpy```### Error message:```shellnumpy/random/_mt19937.c: In function 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨宀勬⒑闁偛鑻晶顕€鏌熼搹顐㈠闁告帗甯為埀顒婄秵閸撴盯鎯岄崱娑欑厽闁圭儤姊归崯姝楢ddTraceback闂?      numpy/random/_mt19937.c:438:62: error: dereferencing pointer to incomplete type 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨搴ㄦ煕閵夈儺鍤熺紒杈ㄦ尰閹峰懘宕滈崣澹劑姊洪幖鐐测偓鏇㈡偘閻х斂eObject闂?{aka 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚妶澶嬪亗閹肩补妲呴弳銏＄箾鐎涙鐭岀痪鍓у隘uct _frame闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨鍫曟⒑?       438 |   #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)```### NumPy/Python version information:`Python 3.11.0a7+ (main, Apr 19 2022, 09:05:09) [GCC 9.4.0] on linux`
"
21416,1,549,0,0,0,Steven-R-Hall,0,"title:BUG: ufuncs that call into Python do not ignore FPEs e.g. for `inf - inf` description:### Describe the issue:I'm writing a program that uses the casadi module to automatically differentiate Python expressions. The program constructs a numpy ndarray (with dtype='O') of objects with the casadi SX data type. Say the array is called 'x'. When performing arithmetic operations on the array, sometimes a Numpy warning is generated. For example,    >>> 2**31  /  xgenerates the warning    RuntimeWarning: invalid value encountered in true_divideand    >>> 2**31 + xgenerates the warning    RuntimeWarning: invalid value encountered in addDespite the warning, the correct value is produced. However, the following code runs without warning:    >>> (2**31-1)  /  x    >>> (2**31-1)  +  xMy expectation is that    >>> numpy.true_divide(y, x)should run without a warning whenever y is a float or int, x is a numpy.ndarray with dtype='O', and y/x[i] can be calculated without warning for all values of i in range. But that is not what happens here. Curiously, it fails only when the integer or float is at least 2 **31, even though no such behavior exists in casadi (or at least not obviously). The sample code below is the simplest code that demonstrates the issue. It seems that the line calculating y2 should never generate a warning if the line calculating y1 does not.### Reproduce the code example:```pythonimport numpy as npimport casadi as cdx = np.zeros([1], dtype='O')x[0] = cd.SX.sym('r')  # only element of array x is a casadi symboly1 = 2 ** 31 / x[0]  # no warning or error generatedy2 = 2 ** 31 / x  # generates warning, but result should be np.array([y1], dtype='O')y3 = (2 ** 31 - 1) / x  # ... but this works fine with no warning or error```### Error message:```shelltrue_divide_problem.py:8: RuntimeWarning: invalid value encountered in true_divide  y2 = 2 ** 31 / x  # generates warning, but result should be np.array([y1], dtype='O')```### NumPy/Python version information:1.21.4 3.9.9 (main, Nov 30 2021, 10:15:14) 
"
21415,0,0,291,0,1,HaoZeke,0,"title:BUG: Fix handling of skip-empty-wrappers description:Earlier, `-c` flags were not handled.
"
21413,0,0,10,0,1,KushalBeniwal,0,"title:DOC: Secure PR template URLs [ci skip] description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      http://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      http://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      http://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->Fixes #21391 
"
21408,1,0,291,1,0,HaoZeke,0,"title:MAINT,BUG: Rework double_from_pyobj description:Closes https://github.com/numpy/numpy/issues/19769.Actually if this looks like a better approach, then some of the other `x_from_pyobj` can be updated similarly.
"
21404,1,208,94,0,0,Amith225,0,"title:BUG: where/argwhere returns incorrectly shaped array description:### Describe the issue:this is really weird, i have an array -> x shaped (112800, 47, 1).when i do:np.argwhere(np.argwhere(x == x.max(axis=1, keepdims=True)))i get an array shaped (112801, 3) instead, but its expected to give (112800, 3)direct code reproduction was not possible, i will attach the .npy file![image](https://user-images.githubusercontent.com/75326634/165687356-0d3de398-241d-47eb-b3ff-4e9c2c35d4f1.png)[x.zip](https://github.com/numpy/numpy/files/8579964/x.zip)### Reproduce the code example:```python# direct code reproduction was not possible, i will attach the .npy fileimport numpy as npx = np.load('x.npy')print(x.shape)y = np.argwhere(x == x.max(axis=1, keepdims=True))print(y.shape)```### Error message:_No response_### NumPy/Python version information:1.22.3 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
"
21395,1,300,6,0,0,hearues-zueke-github,0,"title:BUG: Problem with `1 * np.uint64(1)`, wrong result type `np.float64` description:### Describe the issue:The multiplication of the python int and the numpy uint64 should return a numpy int64 type, but it is numpy float64 type.### Reproduce the code example:```pythonimport numpy as npassert type(1*np.uint8(1)) == np.int64assert type(1*np.uint16(1)) == np.int64assert type(1*np.uint32(1)) == np.int64assert type(1*np.uint64(1)) == np.float64 # this makes for me no sense... is there a reason for this?```### Error message:```shellNo errors, but wrong return type only.```### NumPy/Python version information:`sys.version == '3.10.4 (main, Mar 23 2022, 23:05:40) [GCC 11.2.0]'``np.__version__ == '1.21.3'`
"
21393,1,150,286,0,0,NeilGirdhar,0,"title:BUG: Array real and imag don't seem to be visible to Pyright description:### Describe the issue:Array `real` and `imag` don't seem to be visible in Pyright### Reproduce the code example:```pythonimport numpy as npx = np.zeros(10, dtype=np.float64)print(x.real)```### Error message:In Pyright, this gives:```shellerror: Cannot access member ""real"" for type ""NDArray[float64]""```### NumPy/Python version information:1.22.3 3.10.4 (main, Apr  7 2022, 10:39:08) [GCC 11.2.0]
"
21392,0,0,22,0,0,jmgurney,0,"title:BUG: add linux guard per #21386 description:Closes #21386.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      http://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      http://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      http://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21391,0,25,22,0,1,jmgurney,0,"title:BUG: PR template references insecure URLs description:### Describe the issue:I am in the process of created a PR to fix an issue, and noticed that the URLs in the PR template are http, which is insecure.  As many people are not running browser plugins that force http urls to https, it means that they can have crypto miners or misinformation injected when viewing the information.### Reproduce the code example:```python# N/A```### Error message:```shell# N/A```### NumPy/Python version information:Applies to the github remplates, and not directly related the a numpy version
"
21389,1,279,247,0,0,stephenworsley,0,"title:BUG: MaskedArray comparison gives incorrect fill_value for <, >, >=, <= description:### Describe the issue:When an inequality is applied to a masked array, if the fill value in that masked array has _already been realized_, the resulting array will have an incorrect fill value (the fill value ought to be boolean).```python>>> m = np.ma.array([1, 1], mask=[0, 1])>>> (m > 1).fill_valueTrue>>> m.fill_value999999>>> (m > 1).fill_value999999```I believe this is linked with issue #10092 and that both of these issues are due to the fact that while `__eq__` has a special treatment in MaskedArray, the same is not applied to the likes of `__gt__`. This can be seen here: https://github.com/numpy/numpy/blob/732ed25e4a1e3802d82a976f9541f74548b13e6f/numpy/ma/core.py#L4151-L4162I believe that if equivalent functions were made for `__lt__`, `__le__`, `__gt__` and `__ge__` this ought to solve this issue and also #10092.### Reproduce the code example:```pythonimport numpy as npm = np.ma.array([1, 1], mask=[0, 1])print((m > 1).fill_value)print(m.fill_value)print((m > 1).fill_value)```### Error message:_No response_### NumPy/Python version information:1.21.5
"
21387,1,1791,245,0,0,machow,0,"title:BUG: reductions like np.sum can error on objects that handle ufuncs fine description:### Describe the issue:Hey--I'm adding support for ufuncs to [siuba](https://github.com/machow/siuba), which allows users to specify what they want to do, before executing on a backend (e.g. pandas, sql).Currently, I'm able to support ufuncs (in https://github.com/machow/siuba/pull/415), but noticed that some functions that ultimately call ufuncs--like np.sum--don't make it that far.It looks like this is because calls like `np.sum(some_obj)` follow this logic:* does `hasattr(some_obj, ""sum"")`? if so, use that method.* otherwise, call `np.add.reduce(some_obj, ...)`This leads to a tricky situation where `np.add.reduce` works fine, but `np.sum` raises an error (because it goes through the first path, not `__array_ufunc__`).### Reproduce the code example:Below are two examples: one in siuba, and one in polars### Siuba example```python# from the PR...from siuba import _import numpy as np# dispatches to _.__array_ufunc__(...)np.add.reduce(_)```Outputs siuba's abstract syntax tree (AST) for the ufunc call:```闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗銆掑锝呬壕闂佽鍠栧鈥崇暦閸洦鏁嗗璺侯儐濞呮棃鏌ｉ悢鍝ョ煁婵☆偄鍟撮悰顕€宕橀褎鈻岄柣搴ゎ潐濞叉﹢鏁冮姀銈冣偓浣糕枎閹炬潙娈愰梺瀹犳〃閻掞箓骞?__call__'闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗銆掑锝呬壕闂佽鍠栧鈥崇暦閸洦鏁嗗┑鐘插閳笺倕鈹戦悩顔肩伇婵炲鐩、鏍炊椤掍礁浠ч梺鍓插亝濞叉﹢鎮″☉銏＄厱闁靛绲介崝姘舵煟韫囧﹥娅囩紒杈ㄦ尰閹峰懘宕ｆ径瀣綃闂備礁鎼張顒€煤濠靛牏涓嶆繛鎴炲焹閸嬫捇鏁愭惔婵堟寜闂佺顑嗛幑鍥ь嚕閹绢喖顫呴柍銉ュ帠缁ㄥ灚绻濋悽闈涒枅婵炰匠鍥舵晞闁糕剝绋掗崑鍌炴煛閸モ晛鏋傚ù婊勭矒閺岀喖寮堕崹顕呮殺闂佽鍠栭崥瀣Φ閸曨垱鏅查柛鈩冪懃瀵劑姊?__custom_func__'闂?闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗銆掑锝呬壕闂佽鍠栧鈥崇暦閸洦鏁嗗┑鐘插閳笺倕鈹戦悩顔肩伇闁糕晜鐗犲畷婵嬪即閵忊€崇彅闂佺粯鏌ㄩ崥瀣偂閵夆晜鐓熼柡鍌涘閹牏鈧稒绻勭槐?function array_ufunc at 0x1078731f0>闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗銆掑锝呬壕闂佽鍠栧鈥崇暦閸洦鏁嗗┑鐘插閳笺倕鈹戦悩顔肩伇婵炲鐩、鏍炊椤掍礁浠ч梺鍓插亝濞叉﹢鎮″☉銏＄厱闁靛绲介崝姘舵煟韫囧﹥娅囩紒杈ㄦ尰閹峰懘宕ｆ径瀣絾闂備線娼уú銈団偓姘嵆瀵偊骞囬弶鍨獩濡炪倖鏌ㄩ崥瀣偩婵犳碍鈷掑ù锝呮啞閹牓鏌ゅú璇茬仯缂侇喗妫冨畷濂稿即閻愮數鏋€闂備礁婀遍搹搴ㄥ窗閺嶎偆鐭嗛悗锝庡亖娴滄粓鏌熸导瀛樻锭濞存粍绻冮妵鍕Ψ椤栨粎鐦堝┑顔硷功缁垶骞忛崨顔藉弿闁硅埇鍔屾禍楣冩煃瑜滈崜鐔煎蓟?ufunc 'add'>闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗銆掑锝呬壕闂佽鍠栧鈥崇暦閸洦鏁嗗┑鐘插閳笺倕鈹戦悩顔肩伇婵炲鐩、鏍炊椤掍礁浠ч梺鍓插亝濞叉﹢鎮″☉銏＄厱闁靛绲介崝姘舵煟韫囧﹥娅囩紒?reduce'闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗銆掑锝呬壕闂佽鍠栧鈥崇暦閸洦鏁嗗┑鐘插閳笺倕鈹戦悩顔肩伇闁糕晜鐗犲畷婵嬪即閵忊€崇彅闂佺粯鏌ㄩ崥瀣偂閵夆晜鐓熼柡鍌涘閹牏鈧稒绻勭槐鎾诲磼濞嗘帩鍞归梺鍝勬噺缁挻淇婇悽绋跨妞ゆ牗绋掑▍婊堟⒑閸涘﹣绶遍柛姗€绠栭弫宥咁嚈閻ユ€榦wever, this code produces the wrong AST, because it does not dispatch to `__array_ufunc__`:```python# incorrectly calls _.sum(...), since it existsnp.sum(_)```### Polars exampleIt looks like this also causes issues with https://github.com/pola-rs/polars (cc @ritchie46):```pythonimport polars as pldf = pl.read_csv(""https://j.mp/iriscsv"")# okaynp.sqrt(df.sepal_length)# error:TypeError: sum() got an unexpected keyword argument 'axis'np.sum(df.sepal_length)```### Error message:Here's the full stacktrace for polars (siuba does not error, but erroneously has the `.sum()` method called, rather than `__array_ufunc__`.```shellTypeError                                 Traceback (most recent call last)<ipython-input-16-3baf701c091e> in <module>      6 np.sqrt(df.sepal_length)      7 # error----> 8 np.sum(df.sepal_length)~/.virtualenvs/siuba/lib/python3.8/site-packages/numpy/core/overrides.py in sum(*args, **kwargs)~/.virtualenvs/siuba/lib/python3.8/site-packages/numpy/core/fromnumeric.py in sum(a, axis, dtype, out, keepdims, initial, where)   2294         return res   2295-> 2296     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,   2297                           initial=initial, where=where)   2298~/.virtualenvs/siuba/lib/python3.8/site-packages/numpy/core/fromnumeric.py in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs)     82                 return reduction(axis=axis, dtype=dtype, out=out, **passkwargs)     83             else:---> 84                 return reduction(axis=axis, out=out, **passkwargs)     85     86     return ufunc.reduce(obj, axis, dtype, out, **passkwargs)TypeError: sum() got an unexpected keyword argument 'axis'```### NumPy/Python version information:``` import sys, numpy; print(numpy.__version__, sys.version)1.22.3 3.8.12 (default, Feb  1 2022, 11:29:20)[Clang 13.0.0 (clang-1300.0.29.30)]```
"
21386,0,3151,22,0,0,jmgurney,0,"title:BUG: getauxval declaration invalid, causes compile issues description:### Describe the issue:Trying to install numpy, (main branch) on FreeBSD/aarch64 (aka arm64), using clang, and I get the following compile error:```      INFO: cc: numpy/core/src/common/npy_argparse.c                                                                                                                                [133/1808]      INFO: cc: numpy/core/src/common/npy_hashtable.c                                                                                                                                               INFO: cc: numpy/core/src/common/npy_longdouble.c                                                                                                                                              INFO: cc: numpy/core/src/common/ucsnarrow.c                                                                                                                                                   INFO: cc: numpy/core/src/common/ufunc_override.c                                                                                                                                              INFO: cc: numpy/core/src/common/numpyos.c                                                                                                                                                     INFO: cc: build/src.freebsd-14.0-CURRENT-arm64-3.9/numpy/core/src/common/npy_cpu_features.c                                                                                                   numpy/core/src/common/npy_cpu_features.c.src:586:22: error: static declaration of 'getauxval' follows non-static declaration                                                                  static unsigned long getauxval(unsigned long k)                                                                                                                                                                    ^                                                                                                                                                                        numpy/core/src/common/npy_cpu_features.c.src:582:37: note: previous declaration is here                                                                                                       __attribute__((weak)) unsigned long getauxval(unsigned long); // linker should handle it                                                                                                                                          ^                                                                                                                                                         1 error generated.                                                                                                                                                                      ```It is very clear that this is the case by code inspection:https://github.com/numpy/numpy/blob/main/numpy/core/src/common/npy_cpu_features.c.src#L582### Reproduce the code example:```python# I can't install numpy so there is no code to reproduce.```### Error message:```shell# see above.```### NumPy/Python version information:Main branch as of a few minutes before I filed this issue, the install was attempted via:```pip install git+https://github.com/numpy/numpy.git```Python version:```Python 3.9.12 (main, Mar 27 2022, 01:58:04) [Clang 13.0.0 (git@github.com:llvm/llvm-project.git llvmorg-13.0.0-0-gd7b669b3a on freebsd14```FreeBSD version info:```FreeBSD generic 14.0-CURRENT FreeBSD 14.0-CURRENT #0 main-n254105-d53927b0bae: Thu Mar 31 09:26:31 UTC 2022     root@releng1.nyi.freebsd.org:/usr/obj/usr/src/arm64.aarch64/sys/GENERIC arm64```
"
21384,0,0,0,0,1,code-review-doctor,0,"title:BUG: Missing ``f`` prefix on f-strings fix description:Fixes #21383
"
21380,1,573,296,0,0,leofang,0,"title:BUG: `einsum_path` returns in a non-compliant format when setting `optimize=False` description:### Describe the issue:Line 903 is incorrect:https://github.com/numpy/numpy/blob/79a5000a72f6e4432c0a76efa6cf8e3f12ecef9e/numpy/core/einsumfunc.py#L901-L903Instead of returning a list of pairs of indices as in all other `optimize` options, this could lead to `einsum_path` returning a list of a single tuple containing ascending numbers `[(0, 1, 2, 3, ...)]`.I think for `optimize=False` with N input arrays the returned path should either be```python[(-1, -2)]*(N-1)  # contracting from the end of the (remaining) array sequence```or```python[(0, 1)] + [(-1, 0)]*(N-2)  # contracting from the head of the (remaining) array sequence```### Reproduce the code example:```python>>> import numpy as np>>> shapes = [(3, 4, 5), (4, 5, 6), (3, 6, 2)]>>> arrays = [np.random.random(shape) for shape in shapes]>>> path, _ = np.einsum_path('abc,bcd,ade', *arrays, optimize=False)>>> path['einsum_path', (0, 1, 2)]```### Error message:_No response_### NumPy/Python version information:```python>>> print(np.__version__, sys.version)1.21.2 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]```
"
21378,1,753,0,0,0,thomas-e314,0,"title:BUG: unexpected ValueError description:### Describe the issue:import numpy as npx = np.zeros((5,5))x[1:1,2:2] = 5print(x[1:1,2:2].max())produces a ValueError.I just checked that on numpy.org using the interactive shell### Reproduce the code example:```pythonimport numpy as npx = np.zeros((5,5))x[1:1,2:2] = 5print(x[1:1,2:2].max())```### Error message:```shell---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)Input In [4], in <cell line: 3>()      1 x = np.zeros((5,5))      2 x[1:1,2:2] = 5----> 3 print(x[1:1,2:2].max())File /lib/python3.10/site-packages/numpy/core/_methods.py:40, in _amax(a, axis, out, keepdims, initial, where)     38 def _amax(a, axis=None, out=None, keepdims=False,     39           initial=_NoValue, where=True):---> 40     return umr_maximum(a, axis, None, out, keepdims, initial, where)ValueError: zero-size array to reduction operation maximum which has no identity```### NumPy/Python version information:actual interactive shell on numpy.org
"
21373,0,157,297,0,1,honno,0,"title:BUG: `array_api` arrays should support newaxis description:### Describe the issue:The Array API spec recently updated to allow expanding dimensions via `None` (https://github.com/data-apis/array-api/pull/408). @asmeurer had explicitly raised against such operations initially, as they were out-of-scope and strictness is prioritised in the `array_api` namespace. With this spec update, these checks should now be removed so that expanding dims via `None` just works as-is.Additionally, a `newaxis` alias for `None` should be introduced into the namespace (https://github.com/data-apis/array-api/pull/414).I'll look into fixing this soon unless folks had a thought.### Reproduce the code example:```python>>> from numpy import array_api as xp>>> x = xp.arange(5)>>> x[None, :]IndexError: newaxis indices are not allowed in the array API namespace```### NumPy/Python version information:1.22.3 3.8.12 (default, Mar 13 2022, 19:12:08) [GCC 9.4.0]
"
21372,0,0,292,0,0,seberg,0,"title:BUG: Allow legacy dtypes to cast to datetime again description:This constraint was added out of a caution with the thought that nobodyuses it.  Turns out ora does use it.In practice, this only affects cast to and from datetimes (or possiblystrings but that seems even less likely).Tested via ora (see gh-21365) the paths are not particularly special,but the parametric dtype resolution is in principle missing.This is not particularly problematic, since NumPy barely exposes thatthough, and it never worked.Closes gh-21365---Test is missing, it could be added a rational to string cast probably, but overall it seems `ora` is working fine with it (see issue) and I always only added the check because I thought that without a proper dtype resolution, this is probably useless in any case.  (proper dtype resolution was not possible previously)If there is a small chance of another 1.21.x release, this should also be backported to there.
"
21371,1,781,3,0,0,harshal306,0,"title:np.arange() return array consists of ""stop"" val in case of np.arange(start=0.69,stop=0.99,step=0.01) description:### Describe the issue:Usually, when np.arange() is called it returns the numpy array consisting of the start value and its progressive step size up to the stop value.It can be noted that in the **return numpy.ndarray, stop value is not included.**### For example:```pyimport numpy as npa = np.arange(start=0.1,stop=0.2,step=0.02)```### It returns```pyarray([0.1 , 0.12, 0.14, 0.16, 0.18])```**Please note that 0.2 is not included.**### However, let's take another example:```pya = np.arange(start=0.69,stop=0.99,step=0.01)```Ideally, it should not return the array consisting of value 0.99, it should stop at 0.98but in real it gives the output mentioned below.```pyarray([0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79,       0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9 ,       0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99])```I wonder **why 0.99** is included in the return array.### Reproduce the code example:```pythonimport numpy as npa = np.arange(start=0.69,stop=0.99,step=0.01)```### Error message:```shellarray([0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79,       0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9 ,       0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99])Ideally, 0.99 should be part of this return numpy array.```### NumPy/Python version information:```pyimport numpy as npnp.__version__```Version```py'1.20.3'```Python-version: 3.8.12
"
21369,1,111,0,0,0,baranzadeoglu,0,"title:BUG: random.shuffle does not work with arrays containing multiples of the same item description:### Describe the issue:If you ask for an array such as [1,1,2] to be shuffled, it will replace the array with None.I am not sure if it is intended or not. Couldn't find any indication in the documentation.### Reproduce the code example:```pythonimport numpy as nparr=np.array([1,1,2])arr= np.random.shuffle(arr)print(arr)```### Error message:```shellprints: None```### NumPy/Python version information:1.22.3
"
21366,0,0,284,0,1,mattip,0,"title:BUG: fix compilation error for VS 141 and earlier description:Compilers before vs 1922 are missing the `_knot_mask16` intrinsic, use a simple `NOT` instead.Also clean up a few stray `npy_intp`/`npy_int` warnings.Fixes #21346I verified the compiler version using https://godbolt.org/z/KMYhzaM1e.
"
21365,0,1321,158,0,0,alexhsamuel,0,"title:BUG: can't register cast functions between datetime64 and user dtype description:### Describe the issue:I'd like to register (unsafe) cast functions between `datetime64` and a custom dtype.  Per [the docs](https://numpy.org/devdocs/user/c-info.beyond-basics.html#registering-a-casting-function), I use `PyArray_RegisterCastFunc` to register these.  Essentially this logic:```c// ...PyArray_RegisterDataType(descr);// ...npy_datetime = PyArray_DescrFromType(NPY_DATETIME);PyArray_RegisterCastFunc(npy_datetime, descr->type_num, cast_from_datetime);PyArray_RegisterCastFunc(descr, NPY_DATETIME, cast_to_datetime);```These return no error state, and in fact `PyArray_GetCastFunc` returns the functions I set.My actual code is [here](https://github.com/alexhsamuel/ora/blob/master/python/ora/ext/np_time.hh#L241-L249) and happy to provide additional details about what I'm trying to do.Until 1.20, this worked as expected (`Time` is my custom dtype):```py>>> np.can_cast(np.dtype(""datetime64[ns]""), Time, casting=""unsafe"")True>>> np.can_cast(Time, np.dtype(""datetime64[ns]""), casting=""unsafe"")True>>> aarray([ora.Time(2022, 4, 20, 4, 3, 8.82545807, UTC)], dtype=Time)>>> a.astype(""datetime64[ns]"")array(['2022-04-20T04:03:08.825458080'], dtype='datetime64[ns]')```Starting in 1.21, ```py>>> np.can_cast(np.dtype(""datetime64[ns]""), Time, casting=""unsafe"")False>>> np.can_cast(Time, np.dtype(""datetime64[ns]""), casting=""unsafe"")False>>> a.astype(""datetime64[ns]"")Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>TypeError: Cannot cast array data from dtype(Time) to dtype('<M8[ns]') according to the rule 'unsafe'```I assume this has something to do with NEP 42, though I don't understand it well enough to understand whether there is now a different mechanism available for adding conversions to/from datetime64.### Reproduce the code example:```pythonimport numpyimport oranumpy.array([ora.now()]).astype(""datetime64[ns]"")```### Error message:```shellTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>TypeError: Cannot cast array data from dtype(Time) to dtype('<M8[ns]') according to the rule 'unsafe'```### NumPy/Python version information:```>>> print(numpy.__version__, sys.version)1.21.0 3.8.13 (default, Apr 19 2022, 21:32:23)[GCC 11.2.0]```Also tested in current main 55aacc70c.
"
21364,1,2645,13,0,0,pietrodantuono,0,"title:BUG: data type conversion of numpy array containing NaN description:I have already posted this as a [stackoverflow question][0], but this seems the best place to post it.I am incurring in a behaviour that I cannot comprehend, and it appears to me like a bug.## Problem descriptionI was hoping that trying to convert the data type of an array to integer would raise the ""classic"" `ValueError: cannot convert float NaN to integer` when the array contains NaN.This unfortunately does not happen.At a first glance this seems not happening because the NaN contained in a numpy array are converted to `numpy.float64` instead of ""remaining"" `float` as per [`numpy.ndarray`][1] documentation.In fact, consider this example:```pythonimport numpy as nparr = np.array([np.nan, 1])print(type(arr[0]))      # Output: <class 'numpy.float64'># Converting numpy.float64 NaN to other data types## numpy integersprint( np.int8(arr[0]))  # Output: 0 print(np.int32(arr[0]))  # Output: 0print(np.int32(arr[0]))  # Output:          -2147483648 (i.e. -2 ** 31)print(np.int64(arr[0]))  # Output: -9223372036854775808 (i.e. -2 ** 63)## numpy unsigned integersprint( np.uint8(arr[0]))  # Output: 0print(np.uint16(arr[0]))  # Output: 0print(np.uint32(arr[0]))  # Output: 0print(np.uint64(arr[0]))  # Output: 9223372036854775808## numpy floatsprint(np.float16(arr[0]))  # Output: NaNprint(np.float32(arr[0]))  # Output: NaNprint(np.float64(arr[0]))  # Output: NaN# Converting numpy.float NaN to other data types## np.float and np.int are aliases to float and int respectively (both np.float and np.int are deprecated)type(np.nan) == type(np.float(np.nan))  # Output: Trueprint(np.int(np.nan))                   # Output: ValueError: cannot convert float NaN to integer## numpy integersprint( np.int8(np.nan))  # Output: ValueError: cannot convert float NaN to integerprint(np.int16(np.nan))  # Output: ValueError: cannot convert float NaN to integerprint(np.int32(np.nan))  # Output: ValueError: cannot convert float NaN to integerprint(np.int64(np.nan))  # Output: ValueError: cannot convert float NaN to integer## numpy unsigned integersprint( np.uint8(np.nan))  # Output: ValueError: cannot convert float NaN to integerprint(np.uint16(np.nan))  # Output: ValueError: cannot convert float NaN to integerprint(np.uint32(np.nan))  # Output: ValueError: cannot convert float NaN to integerprint(np.uint64(np.nan))  # Output: ValueError: cannot convert float NaN to integer## numpy floatsprint(np.float16(np.nan))  # Output: NaNprint(np.float32(np.nan))  # Output: NaNprint(np.float64(np.nan))  # Output: NaN```## Questions- Why the elements of `arr` are converted to `numpy.float64` instead of `float` in the first place?- In what exactly do python built-in `float` and `numpy.float64` differ?- Why `np.int32(arr)` and `np.int64(arr)` contain the ""smallest possible int"" while `np.int8(arr)` and `np.int16(arr)` contain zeros? (Similar question for unsigned integer types)  [0]:https://stackoverflow.com/questions/71926095/python-data-type-conversion-of-numpy-array-containing-nan    [1]: https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html### NumPy/Python version information:I am experiencing this behaviour on multiple platform/python/numpy versions, see the three examples below.```pythonimport platformimport sysimport numpyprint('Platform:', platform.platform())print('Python version:', sys.version)print('numpy.__version__:', numpy.__version__)```### WSL```pythonPlatform: Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.31Python version: 3.9.7 (default, Mar  3 2022, 13:49:04) [GCC 9.3.0]numpy.__version__: 1.21.5```### Windows```pythonPlatform: Windows-10-10.0.22593-SP0Python version: 3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]numpy.__version__: 1.21.0```### Online [W3Schools][2]```pythonPlatform: Linux-4.19.0-18-amd64-x86_64-with-glibc2.29Python version: 3.8.2 (default, Mar 13 2020, 10:14:16) [GCC 9.3.0]numpy.__version__: 1.18.2```  [2]:https://www.w3schools.com/python/trypython.asp?filename=demo_default
"
21362,0,58,141,1,1,ketch,0,"title:BUG: numpy 1.22 incorrectly infers dimensions description:### Describe the issue:Using f2py to wrap certain routines in Clawpack, on some systems we get a different calling signature using numpy 1.22 versus earlier versions of numpy.  Some specifics are described here: https://github.com/clawpack/pyclaw/issues/681Some of the input arrays' dimensions involve two variables, so normally f2py requires that those values be passed in.  Using 1.22, sometimes f2py sets up the wrapper so that both of those values are inferred, but their inferred values depend on each other.  So even if one passes the values in, the routine does not work correctly.I've found that rolling back to numpy version 1.18.5 fixes this issue.  I haven't tested other versions in between. I wonder if this is related to https://github.com/numpy/numpy/issues/20103 or https://github.com/numpy/numpy/issues/20696.### Reproduce the code example:```pythonAfter installing Clawpack, run any PyClaw example.```### Error message:_No response_### NumPy/Python version information:1.22.3
"
21359,0,24,205,0,0,Apteryks,0,"title:Parallel build / test options have very little effect description:### Describe the issue:Even when exporting the environment variable `NPY_NUM_BUILD_JOBS` to N (e.g., 24), the build of the C sources (Cythonization) occur on a single core.Even when invoking the test suite via `./runtests.py -j24`, the test suite still runs on a single core.This is with the latest 1.22.3 release.  Am I doing something wrong?### Reproduce the code example:```pythonSee description.```### Error message:_No response_### NumPy/Python version information:Python 3.9.9Numpy 1.22.3
"
21353,1,146,92,0,0,CarlDegio,0,"title:BUG: conda install numpy can't found description:### Describe the issue:I use conda to install numpy, just like [https://numpy.org/install/](https://numpy.org/install/).But when I import it in this env, it raise `ModuleNotFoundError: No module named 'numpy'`.I even reinstall my conda, things doesn't get better. Use pip to install numpy could solve this problem, but why conda can't?### Reproduce the code example:```pythonimport numpy```### Error message:```shellTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>ModuleNotFoundError: No module named 'numpy'```### NumPy/Python version information:python 3.8.13numpy 1.22.3(same for conda or pip)
"
21346,0,395,276,0,0,matthew-brett,0,"title:BUG: error compiling on MSVC 141 toolchain description:### Describe the issue:When compiling current Numpy main (ae1330773) on MSVC v141, with `pip install -v -v .`, I get the following compilation error:```C:\repos\numpy\numpy\core\src\npysort\x86-qsort.dispatch.cpp(651): error C3861: '_knot_mask16': identifier not found```This is with:```Microsoft (R) C/C++ Optimizing Compiler Version 19.16.27045 for x64```If I'm using the 142 toolchain, Numpy compiles to completion:```Microsoft (R) C/C++ Optimizing Compiler Version 19.29.30139 for x64```In both cases:```Python 3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)] on win32```### Reproduce the code example:```pythonSee above.```### Error message:```shellSee above.```### NumPy/Python version information:See above.
"
21337,1,4283,282,0,0,ogrisel,0,"title:BUG: PyUFunc_ReduceWrapper is not threadsafe when called from CPython nogil branch description:### Describe the issue:I am currently experimenting with the `nogil` [CPython branch](https://github.com/colesbury/nogil).It looks like some functions of numpy might not be thread-safe when run concurrently without the GIL and as a result I get the following segfault.I am not sure whether this is intentional or not but I think it would be great to get the scipy stack working on the `nogil` CPython branch to avoid having to deal with multiprocessing to parallelize CPU intensive numerical code on multi-CPU machines.Also that from time to time I also observe the following exception instead:```pythonTraceback (most recent call last):  File ""/home/ogrisel/code/nogil/Lib/threading.py"", line 935, in _bootstrap_inner    self.run()  File ""/home/ogrisel/code/nogil/Lib/threading.py"", line 886, in run    self._target(*self._args, **self._kwargs)  File ""/home/ogrisel/threaded_numpy.py"", line 15, in worker    f(item)  File ""/home/ogrisel/threaded_numpy.py"", line 7, in f    return a.max()  File ""/home/ogrisel/nogil-venv/lib/python3.9/site-packages/numpy/core/_methods.py"", line 40, in _amax    return umr_maximum(a, axis, None, out, keepdims, initial, where)RuntimeError: Identity cache already includes the item.```I cross-reported the issue on the nogil repo under: https://github.com/colesbury/nogil/issues/48### Reproduce the code example:```pythonimport numpy as npimport threading, queuedef f(*args, **kwargs):    a = np.zeros(1000)    return a.max()q = queue.Queue()def worker():    while True:        item = q.get()        f(item)        q.task_done()for i in range(2):    threading.Thread(target=worker, daemon=True, name=f""worker-{i}"").start()for item in range(100000):    q.put(item)q.join()print(""done"")```### Error message:```gdb#0  0x0000000000000000 in ?? ()#1  0x00007ffff744c717 in PyUFunc_ReduceWrapper (context=context@entry=0x7ffff37a9880, operand=operand@entry=0x763584903f0, out=out@entry=0x0, wheremask=wheremask@entry=0x0, axis_flags=axis_flags@entry=0x7ffff37a9920 ""\001\024"",     reorderable=reorderable@entry=1, keepdims=<optimized out>, identity=<optimized out>, loop=<optimized out>, data=<optimized out>, buffersize=<optimized out>, funcname=<optimized out>, errormask=<optimized out>)    at numpy/core/src/umath/reduction.c:390#2  0x00007ffff758605d in PyUFunc_Reduce (wheremask=0x0, initial=<optimized out>, keepdims=<optimized out>, signature=0x7ffff37a97a0, axes=0x7ffff37a98a0, naxes=<optimized out>, out=<optimized out>, arr=0x763584903f0, ufunc=<optimized out>)    at numpy/core/src/umath/ufunc_object.c:2994#3  PyUFunc_GenericReduction (ufunc=<optimized out>, args=<optimized out>, len_args=<optimized out>, kwnames=<optimized out>, operation=<optimized out>) at numpy/core/src/umath/ufunc_object.c:4155#4  0x00005555557cb811 in cfunction_vectorcall_FASTCALL_KEYWORDS (func=0x763574fb4d0, args=0x7ffff37a9b88, nargsf=<optimized out>, kwnames=<optimized out>) at Objects/methodobject.c:464#5  0x000055555580cdc6 in _PyEval_Fast (ts=0x5555559f9460, initial_acc=..., initial_pc=0x5555558d0bcc <func_vector_call> ""\t"") at Python/ceval.c:731#6  0x00005555556a86bf in _PyEval_Eval (pc=<optimized out>, acc=..., tstate=0x5555559f9460) at Python/ceval_meta.c:2788#7  _PyFunction_Vectorcall (func=0x763575e7130, stack=0x76358420e30, nargsf=<optimized out>, kwnames=<optimized out>) at Python/ceval_meta.c:3185#8  0x00007ffff739ce87 in forward_ndarray_method (self=<optimized out>, args=0x55555594b2d0 <_Py_EmptyTupleStruct+16>, kwds=0x0, forwarding_callable=0x763575e7130) at numpy/core/src/multiarray/methods.c:89#9  0x00005555557bdbfb in method_vectorcall_VARARGS_KEYWORDS (func=0x7635743c6d0, args=0x7ffff37a9d08, nargsf=<optimized out>, kwnames=<optimized out>) at Objects/descrobject.c:349#10 0x000055555580cdc6 in _PyEval_Fast (ts=0x5555559f9460, initial_acc=..., initial_pc=0x5555558cec6f <func_vector_call> ""\t"") at Python/ceval.c:731#11 0x00005555556a86bf in _PyEval_Eval (pc=<optimized out>, acc=..., tstate=0x5555559f9460) at Python/ceval_meta.c:2788#12 _PyFunction_Vectorcall (func=0x76356df0470, stack=0x7ffff37a9da8, nargsf=<optimized out>, kwnames=<optimized out>) at Python/ceval_meta.c:3185#13 0x00005555557b3ab4 in _PyObject_VectorcallTstate (kwnames=0x0, nargsf=1, args=0x7ffff37a9da8, callable=0x76356df0470, tstate=0x5555559f9460) at ./Include/cpython/abstract.h:118#14 method_vectorcall (method=<optimized out>, args=0x55555594b2f0 <_Py_EmptyTupleStruct+48>, nargsf=<optimized out>, kwnames=0x0) at Objects/classobject.c:62#15 0x0000555555771a41 in t_bootstrap (boot_raw=0x7635795ba30) at ./Modules/_threadmodule.c:1289#16 0x00005555557064bb in pythread_wrapper (arg=<optimized out>) at Python/thread_pthread.h:245#17 0x00007ffff7d38947 in start_thread (arg=<optimized out>) at pthread_create.c:435#18 0x00007ffff7dc8a44 in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:100```### NumPy/Python version information:```1.22.3 3.9.9+ (heads/nogil:9ba739f815, Mar 26 2022, 08:29:24) [GCC 11.2.0]```CPython was built from https://github.com/colesbury/nogil
"
21335,1,1106,0,0,0,TeusEE,0,"title:BUG: can't reconstruct 2darray from double pointer ctypes array description:### Describe the issue:i try to use dll using python ctypes and numpy array.before apply, i try to verify type(pointer(pointer(ctypes.c_double)) is availabletest sequence is below1. make numpy array with 2d2. convert numpy 2d array to ctypes double pointer3. reconstruct numpy 2d array from ctypes double pointer(using numpy.ctypeslib.as_array())https://numpy.org/doc/stable/reference/routines.ctypeslib.html#module-numpy.ctypeslibplease check this issue.even though i designate shape, it raise ValueError### Reproduce the code example:```pythonimport numpy as npimport ctypestemp = [[i+i*k for i in range(50)] for k in range(10)]temp = np.array(temp)arr_c = temp.ctypes.data_as(ctypes.POINTER(ctypes.POINTER(ctypes.c_double)))np.ctypeslib.as_array(arr_c, temp.shape)```### Error message:```shellTraceback (most recent call last):  File ""C:\Users\2066137\AppData\Local\Programs\Python\Python38\lib\site-packages\numpy\core\_internal.py"", line 597, in _dtype_from_pep3118    dtype, align = __dtype_from_pep3118(stream, is_subdtype=False)  File ""C:\Users\2066137\AppData\Local\Programs\Python\Python38\lib\site-packages\numpy\core\_internal.py"", line 670, in __dtype_from_pep3118    raise NotImplementedError(NotImplementedError: Unrepresentable PEP 3118 data type '&' (pointers)The above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""C:\Users\2066137\AppData\Local\Programs\Python\Python38\lib\site-packages\numpy\ctypeslib.py"", line 518, in as_array    return asarray(obj)ValueError: '&<d' is not a valid PEP 3118 buffer format string```### NumPy/Python version information:numpy version = 1.21.5python version = 3.8.7
"
21333,1,340,283,0,0,Leengit,0,"title:PERF: Improvement for linalg._multi_dot_three description:### Describe the issue:If we divide both costs by `a1b0 * b1c0 * c1` inhttps://github.com/numpy/numpy/blob/5ffb84c3057a187b01acdeaa628137193df12098/numpy/linalg/linalg.py#L2747-L2750then the relative costs become```python    # relative_cost1 = cost((AB)C)  / (a1b0 * b1c0 * c1) = (a0*a1b0*b1c0 + a0*b1c0*c1) / (a1b0 * b1c0 * c1)    relative_cost1 = a0 / c1 + a0 / a1b0    # relative_cost2 = cost(A(BC))  / (a1b0 * b1c0 * c1) = (a1b0*b1c0*c1 + a0*a1b0*c1)  / (a1b0 * b1c0 * c1)    relative_cost2 = a0 / b1c0 + 1```... which is only 5 arithmetic operations instead of 6 arithmetic operations.  Is it faster?### Reproduce the code example:```pythonSee above.```### Error message:```shellSee above.```### NumPy/Python version information:This is in commit 5ffb84c3057a187b01acdeaa628137193df12098.
"
21325,1,570,296,0,0,oleksandr-pavlyk,0,"title:BUG: Adding element 1D array with empty array gives empty array instead of raising an error description:### Describe the issue:In the context of array API spec I observed that `np.add(np.array([0]), np.array([]))` outputs an empty array, while `np.add(np.array([1,2]), np.array([]))` raises a `ValueError` which seems questionable.I would have expected both inputs to raise an exception.### Reproduce the code example:```pythonimport numpy as npprint(np.add(np.array([1]), np.array([])))  # outputs empty arrayprint(np.add(np.array([1, 2]), np.array([])))  # raises ValueError```### Error message:```shell$ python -c ""import numpy as np; print(np.add(np.array([1]), np.array([]))); print(np.add(np.array([1, 2]), np.array([])))""[]Traceback (most recent call last):  File ""<string>"", line 1, in <module>ValueError: operands could not be broadcast together with shapes (2,) (0,)```### NumPy/Python version information:```In [7]: (np.__version__, sys.version)Out[7]: ('1.21.2', '3.9.7 (default, Oct 27 2021, 01:23:21) \n[GCC 9.3.0]')```
"
21324,0,0,292,0,0,seberg,0,"title:BUG: Make mmap handling safer in frombuffer description:`frombuffer` always used the old buffer protocol, but this is notsafe in some cases when combined with the ""new"" one.The main/only use-case that was ever found for this is that enablingthe new buffer protocol (by going through a memoryview) protectsusers from accidentally closing memorymaps while they are still used.Closes gh-9537
"
21322,1,6019,299,0,0,spyroot,0,"title:BUG: pytest 6 test failing on M1 description:### Describe the issue:Hi Folks,Is it normal that 6 tests fail on M1?   ( It looks like all 6 test for dtype=complex64)```FAILED miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/core/tests/test_ufunc.py::TestUfuncGenericLoops::test_unary_PyUFunc_O_O_method_full[reciprocal] - Assertion...FAILED miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/linalg/tests/test_linalg.py::TestSVDHermitian::test_herm_cases - AssertionError: In test case: <LinalgCase:...FAILED miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/linalg/tests/test_linalg.py::TestPinvHermitian::test_herm_cases - AssertionError: In test case: <LinalgCase...FAILED miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/linalg/tests/test_linalg.py::TestEighCases::test_herm_cases - AssertionError: In test case: <LinalgCase: hc...FAILED miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/typing/tests/test_generic_alias.py::TestGenericAlias::test_getattr[__copy__] - AttributeError: 'types.Gener...FAILED miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/typing/tests/test_generic_alias.py::TestGenericAlias::test_getattr[__deepcopy__] - AttributeError: 'types.G...6 failed, 14311 passed, 98 skipped, 1253 deselected, 19 xfailed, 3 xpassed, 23 warnings in 109.99s (0:01:49)```### Reproduce the code example:```pythonI listed tests.  This one is more verbose.  (it looks like most of test related to complex dtype) miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/linalg/tests/test_linalg.py:382:_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _self = <numpy.linalg.tests.test_linalg.TestPinvHermitian object at 0x12db0b580>, require = {'hermitian'}, exclude = {'generalized', 'size-0'}    def check_cases(self, require=set(), exclude=set()):        """"""        Run func on each of the cases with all of the tags in require, and none        of the tags in exclude        """"""        for case in self.TEST_CASES:            # filter by require and exclude            if case.tags & require != require:                continue            if case.tags & exclude:                continue            try:                case.check(self.do)            except Exception as e:                msg = f'In test case: {case!r}\n\n'                msg += traceback.format_exc()>               raise AssertionError(msg) from eE               AssertionError: In test case: <LinalgCase: hcsingle>EE               Traceback (most recent call last):E                 File ""/Users/spyroot/miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/testing/_private/utils.py"", line 576, in assert_almost_equalE                   assert_almost_equal(actualr, desiredr, decimal=decimal)E                 File ""/Users/spyroot/miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/testing/_private/utils.py"", line 583, in assert_almost_equalE                   return assert_array_almost_equal(actual, desired, decimal, err_msg)E                 File ""/Users/spyroot/miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/testing/_private/utils.py"", line 1046, in assert_array_almost_equalE                   assert_array_compare(compare, x, y, err_msg=err_msg, verbose=verbose,E                 File ""/Users/spyroot/miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/testing/_private/utils.py"", line 844, in assert_array_compareE                   raise AssertionError(msg)E               AssertionError:E               Arrays are not almost equal to 5 decimalsEE               Mismatched elements: 4 / 4 (100%)E               Max absolute difference: 1.4734483E               Max relative difference: 0.9652817E                x: array([[0.57435, 3.47345],E                      [3.47345, 0.03472]], dtype=float32)E                y: array([[1., 2.],E                      [2., 1.]], dtype=float32)EE               During handling of the above exception, another exception occurred:EE               Traceback (most recent call last):E                 File ""/Users/spyroot/miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/linalg/tests/test_linalg.py"", line 350, in check_casesE                   case.check(self.do)E                 File ""/Users/spyroot/miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/linalg/tests/test_linalg.py"", line 85, in checkE                   do(self.a, self.b, tags=self.tags)E                 File ""/Users/spyroot/miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/linalg/tests/test_linalg.py"", line 835, in doE                   assert_almost_equal(dot(dot(a, a_ginv), a), a, single_decimal=5, double_decimal=11)E                 File ""/Users/spyroot/miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/linalg/tests/test_linalg.py"", line 41, in assert_almost_equalE                   old_assert_almost_equal(a, b, decimal=decimal, **kw)E                 File ""/Users/spyroot/miniconda3/envs/torchenv/lib/python3.10/site-packages/numpy/testing/_private/utils.py"", line 579, in assert_almost_equalE                   raise AssertionError(_build_err_msg())E               AssertionError:E               Arrays are not almost equal to 5 decimalsE                ACTUAL: array([[0.5743456 +0.0000000e+00j, 3.4734483 +4.2373457e+00j],E                      [3.4734483 -4.2373452e+00j, 0.03471828+5.9604645e-08j]],E                     dtype=complex64)E                DESIRED: array([[1.+0.j, 2.+3.j],E                      [2.-3.j, 1.+0.j]], dtype=complex64)case       = <LinalgCase: hcsingle>exclude    = {'generalized', 'size-0'}msg        = 'In test case: <LinalgCase: hcsingle>\n\nTraceback (most recent call last):\n  File ""/Users/spyroot/miniconda3/envs/to...4645e-08j]],\n      dtype=complex64)\n DESIRED: array([[1.+0.j, 2.+3.j],\n       [2.-3.j, 1.+0.j]], dtype=complex64)\n'require    = {'hermitian'}self       = <numpy.linalg.tests.test_linalg.TestPinvHermitian object at 0x12db0b580>```### Error message:_No response_### NumPy/Python version information:>>> import sys, numpy; print(numpy.__version__, sys.version)1.21.2 3.10.4 (main, Mar 31 2022, 03:37:37) [Clang 12.0.0 ]
"
21321,0,0,299,0,1,felixxm,0,"title:BUG: Stop using PyBytesObject.ob_shash deprecated in Python 3.11. description:This is unnecessary because a cached hash value should not be computed yet for `obj`. Moreover `PyBytesObject.ob_shash` was deprecated in Python 3.11, see https://github.com/python/cpython/issues/91020.Fixes #21317.
"
21320,0,2245,6,0,0,kohlerjl,0,"title:BUG: numpy.lib.recfunctions.structured_to_unstructured is not thread-safe description:### Describe the issue:numpy.lib.recfunctions.structured_to_unstructured uses numpy.testing.suppress_warnings, which is inherently thread unsafe. However, structured_to_unstructured is not documented as thread unsafe, and would otherwise not be expected to alter global state.If this function is used in a multi-threaded program, multiple suppress_warnings context managers may be entered and exited out of order, leaving the global warnings.show_warnings handler in an invalid state. Any subsequent code that issues any warning will trigger an AttributeError instead. This issue resulted in a crash of one of our production services. This error is related to #8413, and an example of this failure is constructed below.From a quick search, this usage in structured_to_unstructured appears to be the only usage of suppress_warnings in the numpy library outside of testing routines. It would seem this suppress_warnings context manager is only suitable for testing purposes, and should not be used in library or production code.### Reproduce the code example:```pythonimport loggingimport warningsimport threadingfrom numpy.testing import suppress_warningsdef thread_a():    logging.info(""Entering a"")    with suppress_warnings() as sup:        logging.info(""Entered a"")        entered_a.set()        entered_b.wait()        logging.info(""Exiting a"")    logging.info(""Exited a"")    exited_a.set()def thread_b():    logging.info(""Entering b"")    entered_a.wait()    with suppress_warnings() as sup:        logging.info(""Entered b"")        entered_b.set()        exited_a.wait()        logging.info(""Exiting b"")    logging.info(""Exited b"")    exited_b.set()entered_a = threading.Event()exited_a = threading.Event()entered_b = threading.Event()exited_b = threading.Event()    thread1 = threading.Thread(target=thread_a)thread2 = threading.Thread(target=thread_b)entered_a.clear()exited_a.clear()entered_b.clear()exited_b.clear()thread1.start()thread2.start()exited_b.wait()warnings.warn('test')```### Error message:```shell---------------------------------------------------------------------------AttributeError                            Traceback (most recent call last)Input In [11], in <cell line: 14>()     10 thread2.start()     12 exited_b.wait()---> 14 warnings.warn('test')File /usr/lib/python3.10/warnings.py:109, in _showwarnmsg(msg)    105         if not callable(sw):    106             raise TypeError(""warnings.showwarning() must be set to a ""    107                             ""function or method"")--> 109         sw(msg.message, msg.category, msg.filename, msg.lineno,    110            msg.file, msg.line)    111         return    112 _showwarnmsg_impl(msg)File /usr/lib/python3.10/site-packages/numpy/testing/_private/utils.py:2273, in suppress_warnings._showwarning(self, message, category, filename, lineno, use_warnmsg, *args, **kwargs)   2271 if self._forwarding_rule == ""always"":   2272     if use_warnmsg is None:-> 2273         self._orig_show(message, category, filename, lineno,   2274                         *args, **kwargs)   2275     else:   2276         self._orig_showmsg(use_warnmsg)AttributeError: 'suppress_warnings' object has no attribute '_orig_show'```### NumPy/Python version information:1.22.3 3.10.4 (main, Mar 23 2022, 23:05:40) [GCC 11.2.0]
"
21317,0,258,299,0,1,felixxm,0,"title:BUG: Fix ob_shash deprecation warning on Python 3.11 description:### Describe the issue:`ob_shash` is deprecated on Python 3.11:```numpy/core/src/multiarray/scalarapi.c:709:13: warning: 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚妶澶嬪亗閹肩补妲呴弳銏＄箾鐎涙鐭岄柍褜鍓欓妶鐥礹ash闂?is deprecated [-Wdeprecated-declarations]```This looks unnecessary :thinking:, cached hash value for `obj` should not be computed yet:> https://github.com/numpy/numpy/blob/28e624d1e78ee46d7040e6a099bda39d7fa60e3d/numpy/core/src/multiarray/scalarapi.c#L709### Reproduce the code example:```pythonRun tests on Python 3.11.```### Error message:```shellnumpy/core/src/multiarray/scalarapi.c:709:13: warning: 闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚妶澶嬪亗閹肩补妲呴弳銏＄箾鐎涙鐭岄柍褜鍓欓妶鐥礹ash闂?is deprecated [-Wdeprecated-declarations]```### NumPy/Python version information:1.23.0.dev0+1020.g08569fcf0 3.8.10 (default, Mar 15 2022, 12:22:08) [GCC 9.4.0]
"
21312,1,2182,3,0,0,mateusfbsoares,0,"title:BUG: Error when importing numpy on an AWS Lambda function description:### Describe the issue:I have numpy along with other libraries on an AWS EFS directory that i append to the path on a lambda function (so it can use the dependencies) that imports numpy (please see screenshot and code below)![image](https://user-images.githubusercontent.com/43099047/162269835-7dc2e969-879a-4c32-aa10-a25a1311cb34.png)When I import numpy, i get an error.Following the troubleshooting hints did not solve the error.### Reproduce the code example:```pythonimport sys, os, jsonsys.path.append(""/mnt/access"")import numpydef lambda_handler(event, context):    return {        'statusCode': 200,        'body': json.dumps('Hello from Lambda!')    }```### Error message:```shellTest Event NametResponse{  ""errorMessage"": ""Unable to import module 'lambda_function': \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.7 from \""/var/lang/bin/python3.7\""\n  * The NumPy version is: \""1.22.3\""\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n"",  ""errorType"": ""Runtime.ImportModuleError"",  ""stackTrace"": []}Function LogsSTART RequestId: 0d5ec298-258c-430e-a8ec-e7552ede9eee Version: $LATEST[ERROR] Runtime.ImportModuleError: Unable to import module 'lambda_function': IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!Importing the numpy C-extensions failed. This error can happen formany reasons, often due to issues with your setup or how NumPy wasinstalled.We have compiled some common reasons and troubleshooting tips at:https://numpy.org/devdocs/user/troubleshooting-importerror.htmlPlease note and check the following:* The Python version is: Python3.7 from ""/var/lang/bin/python3.7""* The NumPy version is: ""1.22.3""and make sure that they are the versions you expect.Please carefully study the documentation linked above for further help.Original error was: No module named 'numpy.core._multiarray_umath'Traceback (most recent call last):END RequestId:xxxxxxxREPORT RequestId: xxxxxxxxxx	Duration: 1.70 ms	Billed Duration: 2 ms	Memory Size: 1024 MB	Max Memory Used: 47 MB	Init Duration: 1770.46 msRequest IDxxxxxxxxxx```### NumPy/Python version information:Python 3.7NumPy 1.22.3
"
21309,1,31,0,0,0,rajatscibi,0,"title:BUG: Getting numpy error while installing pycaret description:### Describe the issue:Im installing pycaret on a windows vm (aws). But getting this error again and again.![python_error](https://user-images.githubusercontent.com/74652470/162144582-b17a39a6-e75f-4be5-98cd-200a2cac844c.png)![python_error1](https://user-images.githubusercontent.com/74652470/162144588-c404cfa2-13f2-49f4-9e3e-af189b1a2a0c.png)### Reproduce the code example:```pythonits during installation```### Error message:_No response_### NumPy/Python version information:3.10
"
21302,0,172,6,0,0,jzombi,0,"title:BUG: numpy build fails with gcc version 4.9.2 description:### Describe the issue:Numpy fails to build with gcc version 4.9.2 with the following error:    RuntimeError: Broken toolchain: cannot link a simple C++ program. note: A compiler with support for C++11 language features is required.This should not be a problem, because C++11 standard is supported since gcc `4.8.1`.The problem is that when compiling the test code in `numpy/core/setup.py`, the `-std=c++11` flag is not passed to the compiler.The default c++ standard was changed in version 6.1 from C++98 to C++14, so this issue might affect all prior gcc versions.By monkey-patching `setup.py` to include the `-std=c++11` flag, the build run successfully.### Reproduce the code example:```pythonpython setup.py build```### Error message:```shellRuntimeError: Broken toolchain: cannot link a simple C++ program. note: A compiler with support for C++11 language features is required.```### NumPy/Python version information:1.22.3 3.8.12 (default, Jan 12 2022, 09:59:17) [GCC 4.9.2]
"
21301,0,4995,30,0,0,dbeutel,0,"title:BUG: `matmul.at` segfaults description:### Describe the issue:Calling `matmul.at` on arrays that pass all checks on shape, indices, etc, leads to a segmentation fault.**Expected result**Calling other methods of ufuncs with a non-trivial signature raises either a `RuntimeError: Reduction not defined on ufunc with signature` or, in the case of `outer`,  a `TypeError: method outer is not allowed in ufunc with non-trivial signature`. Because `at` is not a reduction, my expectation is getting a `TypeError: method at is not allowed in ufunc with non-trivial signature`. I took the liberty to make the tiny adaption that implements the expected behavior here: https://github.com/dbeutel/numpy/commit/6db8d9649f07836b25edf6f038f9ded7a5e2314a ### Reproduce the code example:```pythonimport numpy as nparr = np.ones((2, 2, 2))np.matmul.at(arr, [0], np.ones((1, 2, 2)))```### Error message:```shell$ gdb --args python-dbg segfault_matmul_at.pyGNU gdb (GDB) 11.2Copyright (C) 2022 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Type ""show copying"" and ""show warranty"" for details.This GDB was configured as ""x86_64-pc-linux-gnu"".Type ""show configuration"" for configuration details.For bug reporting instructions, please see:<https://www.gnu.org/software/gdb/bugs/>.Find the GDB manual and other documentation resources online at:    <http://www.gnu.org/software/gdb/documentation/>.For help, type ""help"".Type ""apropos word"" to search for commands related to ""word""...Reading symbols from python-dbg...(gdb) runStarting program: /usr/bin/python-dbg segfault_matmul_at.py[Thread debugging using libthread_db enabled]Using host libthread_db library ""/usr/lib/libthread_db.so.1"".[New Thread 0x7ffff45ff640 (LWP 5504)][New Thread 0x7ffff3dfe640 (LWP 5505)][New Thread 0x7ffff15fd640 (LWP 5506)][New Thread 0x7fffecdfc640 (LWP 5507)][New Thread 0x7fffea5fb640 (LWP 5508)][New Thread 0x7fffe7dfa640 (LWP 5509)][New Thread 0x7fffe55f9640 (LWP 5510)]Thread 1 ""python-dbg"" received signal SIGSEGV, Segmentation fault.0x00007ffff707fb00 in DOUBLE_matmul () from /home/dbeutel/.local/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-x86_64-linux-gnu.so(gdb) bt#0  0x00007ffff707fb00 in DOUBLE_matmul () from /home/dbeutel/.local/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-x86_64-linux-gnu.so#1  0x00007ffff70842e5 in generic_wrapped_legacy_loop () from /home/dbeutel/.local/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-x86_64-linux-gnu.so#2  0x00007ffff7087548 in ufunc_at () from /home/dbeutel/.local/lib/python3.10/site-packages/numpy/core/_multiarray_umath.cpython-310-x86_64-linux-gnu.so#3  0x00007ffff7cfa81e in method_vectorcall_VARARGS (func=func@entry=0x7ffff7330dd0,  args=args@entry=0x5555555f86d8, nargsf=<optimized out>, kwnames=0x0) at Objects/descrobject.c:311#4  0x00007ffff7d08f4b in _PyObject_VectorcallTstate (kwnames=<optimized out>, nargsf=<optimized out>, args=<optimized out>, callable=<optimized out>, tstate=<optimized out>) at ./Include/cpython/abstract.h:114#5  PyObject_Vectorcall (kwnames=<optimized out>, nargsf=<optimized out>, args=<optimized out>, callable=<optimized out>) at ./Include/cpython/abstract.h:123#6  call_function (tstate=0x55555555e7a0, trace_info=<optimized out>, pp_stack=0x7fffffffe1f0, oparg=<optimized out>, kwnames=<optimized out>) at Python/ceval.c:5867#7  0x00007ffff7cfec4e in _PyEval_EvalFrameDefault (tstate=<optimized out>, f=0x5555555f8570, throwflag=<optimized out>) at Python/ceval.c:4198#8  0x00007ffff7cfd2eb in _PyEval_EvalFrame (throwflag=0, f=0x5555555f8570, tstate=0x55555555e7a0) at ./Include/internal/pycore_ceval.h:46#9  _PyEval_Vector (tstate=<optimized out>, con=<optimized out>, locals=<optimized out>, args=<optimized out>, argcount=0, kwnames=<optimized out>) at Python/ceval.c:5065#10 0x00007ffff7d7a1b4 in PyEval_EvalCode (co=0x7ffff739f780, globals=0x7ffff73c15b0, locals=<optimized out>) at Python/ceval.c:1134#11 0x00007ffff7d948b4 in run_eval_code_obj (tstate=0x55555555e7a0, co=0x7ffff739f780, globals=0x7ffff73c15b0, locals=0x7ffff73c15b0) at Python/pythonrun.c:1291#12 0x00007ffff7d8c316 in run_mod (mod=<optimized out>, filename=<optimized out>, globals=0x7ffff73c15b0, locals=0x7ffff73c15b0, flags=<optimized out>, arena=<optimized out>) at Python/pythonrun.c:1312#13 0x00007ffff7c4024f in pyrun_file (fp=fp@entry=0x55555555a4f0, filename=filename@entry=0x7ffff73dc0b0, start=start@entry=257, globals=globals@entry=0x7ffff73c15b0, locals=locals@entry=0x7ffff73c15b0, closeit=closeit@entry=1, flags=0x7fffffffe5c8) at Python/pythonrun.c:1208#14 0x00007ffff7c3f9fc in _PyRun_SimpleFileObject (fp=0x55555555a4f0, filename=0x7ffff73dc0b0, closeit=1, flags=0x7fffffffe5c8) at Python/pythonrun.c:456#15 0x00007ffff7c40b2b in _PyRun_AnyFileObject (fp=0x55555555a4f0, filename=0x7ffff73dc0b0, closeit=1, flags=0x7fffffffe5c8) at Python/pythonrun.c:90#16 0x00007ffff7da4e9c in pymain_run_file_obj (skip_source_first_line=0, filename=0x7ffff73dc0b0, program_name=0x7ffff73c1960) at Modules/main.c:353#17 pymain_run_file (config=0x555555585550) at Modules/main.c:372#18 pymain_run_python (exitcode=0x7fffffffe5c4) at Modules/main.c:587#19 Py_RunMain () at Modules/main.c:666#20 0x00007ffff7d67efd in Py_BytesMain (argc=<optimized out>, argv=<optimized out>) at Modules/main.c:720#21 0x00007ffff7999310 in __libc_start_call_main () from /usr/lib/libc.so.6#22 0x00007ffff79993c1 in __libc_start_main_impl () from /usr/lib/libc.so.6#23 0x0000555555555045 in _start ()```### NumPy/Python version information:* numpy: 1.22.3* python: 3.10.2 (main, Apr  5 2022, 14:03:41) [GCC 11.2.0]
"
21293,1,113,5,0,0,SmolakK,0,"title:BUG: Unexpected np.unique behaviour on an array of lists description:### Describe the issue:When applying np.unique on an array of lists, instead of unique lists, the unique symbols are returned. The same behaviour is observed for tuples, but it works fine using sets. This occurs only when lists in an array are of identical length. For example, trying to find unique lists from below array:`ydata = np.array([[1,2,3],[1,2],[1,2],[2,3]],dtype=object)`works as expected returning `array([list([1, 2]), list([1, 2, 3]), list([2, 3])], dtype=object)`. However, when applying np.unique on:`xdata = np.array([[1,2],[1,2],[1,2],[2,3]],dtype = object)`returns `array([1, 2, 3], dtype=object)`, instead of  `array([list([1, 2]), list([2, 3])], dtype=object)`.This is caused by the way `ar = np.asanyarray(ar)` in the function converts such an array into an array of symbols instead of an array of lists.### Reproduce the code example:```pythonimport numpy as npxdata = np.array([[1,2],[1,2],[1,2],[2,3]],dtype=object)np.unique(xdata)```### Error message:```shellNone```### NumPy/Python version information:numpy.__version__: 1.20.3sys.verson: 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]
"
21289,0,129,5,0,0,hujie369,0,"title:BUG: abs(np.int8(-128)) should arguably give an OverflowWarning description:### Describe the issue:The range of np.int8 is -128 to 127. The ideal range of np.abs(np.int8) is -127 to 128. But apparently 128 overflow. So np.abs(-128, dtype=int8) = -128, while the rest of the cases are all correct. This error is hard to detect and is also found in np.int16.### Reproduce the code example:```pythonimport numpy as npa = np.array([-128, -127], dtype=np.int8)print(a)# [-128 -127]print(np.abs(a))# [-128, 127]```### Error message:_No response_### NumPy/Python version information:numpy: 1.18.5 sys: 3.7.10 (default, Jun  4 2021, 14:48:32) [GCC 7.5.0]
"
21288,1,13540,291,0,0,xkszltl,0,"title:BUG: Failed to build with setuptools 61.3.1 description:### Describe the issue:This could be related:https://github.com/pypa/setuptools/issues/3197#issuecomment-1086858941Latest numpy release (1.22.3) cannot build from source when using latest setuptools.### Reproduce the code example:```pythonpython3 -m pip install -Uv setuptools==61.3.1python3 -m pip install -Uv git+https://github.com/numpy/numpy.git@v1.22.3```### Error message:```shell#9 529.2 Using pip 22.0.4 from /usr/local/lib/python3.9/dist-packages/pip (python 3.9)                                                                                                                                                                        #9 529.3 Looking in indexes: https://mirrors.aliyun.com/pypi/simple                                                                                                                                                                                           #9 529.3 Processing ./mirrored-pip-GRCQUK/numpy                                                                                                                                                                                                               #9 529.5   Installing build dependencies: started                                                                                                                                                                                                             #9 529.5   Running command pip subprocess to install build dependencies                                                                                                                                                                                       #9 531.1   Looking in indexes: https://mirrors.aliyun.com/pypi/simple                                                                                                                                                                                         #9 531.1   Ignoring packaging: markers 'platform_machine == ""arm64""' don't match your environment                                                                                                                                                             #9 531.7   Collecting setuptools==59.2.0                                                                                                                                                                                                                      #9 531.8     Downloading https://mirrors.aliyun.com/pypi/packages/18/ad/ec41343a49a0371ea40daf37b1ba2c11333cdd121cb378161635d14b9750/setuptools-59.2.0-py3-none-any.whl (952 kB)                                                                              #9 533.1        闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸婂潡鏌ㄩ弮鍌涙珪缂佺姵鍎抽埞鎴︽偐閸欏鎮欓梺缁樺笒閻忔岸濡甸崟顖氱鐎广儱鐗嗛崢鈥愁渻閵堝骸澧柛姘儔婵＄敻宕熼姘棟濠电偛妫涢崑鎾诲煝閸儲鈷戦柛婵嗗閻掕法绱掔紒妯肩疄鐎规洘妞介崺鈧い鎺嶉檷娴滄粓鏌熼悜妯虹仴妞ゅ浚浜弻锟犲川椤旇偐绁峰銈庡弨濞夋洟骞戦崟顖涘仏闁哄鍨甸～鐘绘⒒娴ｅ憡鍟為柨姘舵煟鎺抽崝搴ㄥ箲閵忕姭妲堟繛鍡樺姉缁夊爼姊洪崨濠冨瘷闁告劑鍔庨崢鎺楁⒑鐠囨彃顒㈡い鏃€鐗犲畷浼村冀椤撶喎浜梺缁樻尭鐎垫帡宕甸弴鐔翠簻闁规壋鏅涢悞鐑樼箾鐏忔牗娅婇柡灞诲€濆畷顐﹀Ψ閿旇姤鐦庨梻浣告啞钃遍柟鐟版搐椤繒绱掑Ο鑲╂嚌闂佹悶鍎滈崒婊冨毈缂傚倸鍊风粈渚€顢栭崱娑欏亱闁绘ɑ鐪归埀顑跨閳诲酣骞囬鍌滅嵁闂備礁缍婇崑濠囧储妤ｅ啫鍌ㄩ柟闂寸劍閳锋垿姊洪銈呬粶闁兼椿鍨遍弲鍫曞箻椤旂晫鍘告繛杈剧悼閹虫挻鎱ㄩ崼鈶╁亾閸偅绶查悗姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€?952.0/952.0 KB 734.9 kB/s eta 0:00:00                                                                                                                                                                   #9 533.2   Collecting wheel==0.37.0                                                                                                                                                                                                                           #9 533.2     Downloading https://mirrors.aliyun.com/pypi/packages/04/80/cad93b40262f5d09f6de82adbee452fd43cdff60830b56a74c5930f7e277/wheel-0.37.0-py2.py3-none-any.whl (35 kB)                                                                                #9 534.0   Collecting Cython<3.0,>=0.29.24                                                                                                                                                                                                                    #9 534.0     Downloading https://mirrors.aliyun.com/pypi/packages/9a/26/d2b6bc4cb7d716c82ebc89690cbd5ba0f547db364809cd42dad34d593182/Cython-0.29.28-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)                   #9 536.6        闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸婂潡鏌ㄩ弮鍌涙珪缂佺姵鍎抽埞鎴︽偐閸欏鎮欓梺缁樺笒閻忔岸濡甸崟顖氱鐎广儱鐗嗛崢鈥愁渻閵堝骸澧柛姘儔婵＄敻宕熼姘棟濠电偛妫涢崑鎾诲煝閸儲鈷戦柛婵嗗閻掕法绱掔紒妯肩疄鐎规洘妞介崺鈧い鎺嶉檷娴滄粓鏌熼悜妯虹仴妞ゅ浚浜弻锟犲川椤旇偐绁峰銈庡弨濞夋洟骞戦崟顖涘仏闁哄鍨甸～鐘绘⒒娴ｅ憡鍟為柨姘舵煟鎺抽崝搴ㄥ箲閵忕姭妲堟繛鍡樺姉缁夊爼姊洪崨濠冨瘷闁告劑鍔庨崢鎺楁⒑鐠囨彃顒㈡い鏃€鐗犲畷浼村冀椤撶喎浜梺缁樻尭鐎垫帡宕甸弴鐔翠簻闁规壋鏅涢悞鐑樼箾鐏忔牗娅婇柡灞诲€濆畷顐﹀Ψ閿旇姤鐦庨梻浣告啞钃遍柟鐟版搐椤繒绱掑Ο鑲╂嚌闂佹悶鍎滈崒婊冨毈缂傚倸鍊风粈渚€顢栭崱娑欏亱闁绘ɑ鐪归埀顑跨閳诲酣骞囬鍌滅嵁闂備礁缍婇崑濠囧储妤ｅ啫鍌ㄩ柟闂寸劍閳锋垿姊洪銈呬粶闁兼椿鍨遍弲鍫曞箻椤旂晫鍘告繛杈剧悼閹虫挻鎱ㄩ崼鈶╁亾閸偅绶查悗姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑閸濆嫷鍎庨柣鎺炵畵楠炲牓濡搁妷搴ｅ枛瀹曞綊顢欓幆褍缂氶梻鍌欒兌缁垶骞愰幖浣哥柈闁哄鍩堝鏍ㄧ箾瀹割喕鎲鹃柡浣稿暣閺屻劌鈹戦崱妯笺偐闂佽绻愬畷顒勨€旈崘顔嘉ч柛鈩冾焽閸欏棗顪冮妶蹇擃洭闁轰浇顕ч锝嗙節濮橆厽娅㈤梺缁橆焾鐏忔瑩宕濋敃鈧—鍐Χ閸℃鐟ㄩ柣搴㈠嚬閸欏啫顕ｉ弻銉ョ闁圭儤绻勯崬鐢告煟閻樼儤顏犻悘蹇嬪姂瀹曟繈鎮㈤崗鑲╁幈濠碘槅鍨靛▍锝夊箺閻樼數纾肩紓浣诡焽閳洘绻涢悡搴ｇ鐎规洘绮忛ˇ鏌ユ煕閳轰胶鐒搁柟顔筋殔閳绘捇宕归鐣屼邯闂備胶绮悧婊堝储瑜旈、姘舵晲婢舵ɑ鏅濋梺闈涚箚閺呮粓宕撻悽鍛娾拺闁绘挸瀛╅幉鎼佹煛娴ｈ鍊愮€规洏鍨介獮妯肩磼濡攱瀚藉┑鐐存尰閼规儳煤閵堝棛顩叉繝闈涚墢绾惧ジ鎮楅敐搴′簽濠⒀冪仛閵囧嫰濮€閿涘嫭鍣悗鍨緲鐎氫即鐛崶顒夋晣闁绘ɑ褰冪粻浼存⒒閸屾瑧绐旈柍褜鍓涢崑娑㈡嚐椤栨稒娅犻柟缁㈠枟閻撴稑霉閿濆洦鍤€濠殿喖鐗忛埀顒€鐏氬妯尖偓姘煎幘閹广垹鈹戠€ｎ亞顦板銈嗗姂閸ㄥ顢橀崫鍕ㄦ斀闁绘ê鐏氶弳鈺呮煕鐎ｎ剙鈻堟鐐存崌椤㈡棃宕卞Δ鍐摌闂備浇濮ら敋妞わ缚绮欏畷鐢稿即閵忥紕鍘卞銈嗗姧缁插墽绮堥埀顒勬⒑?1.9/1.9 MB 761.3 kB/s eta 0:00:00                                                                                                                                                                    #9 536.9   Installing collected packages: wheel, setuptools, Cython                                                                                                                                                                                           #9 537.8   Successfully installed Cython-0.29.28 setuptools-59.2.0 wheel-0.37.0                                                                                                                                                                               #9 537.8   WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv                      #9 537.9   Installing build dependencies: finished with status 'done'                                                                                                                                                                                         #9 537.9   Getting requirements to build wheel: started                                                                                                                                                                                                       #9 537.9   Running command Getting requirements to build wheel                                                                                                                                                                                                #9 538.3   Running from numpy source directory.                                                                                                                                                                                                               #9 539.2   error: Multiple top-level packages discovered in a flat-layout: ['numpy', 'branding'].                                                                                                                                                             #9 539.2                                                                                                                                                                                                                                                      #9 539.2   To avoid accidental inclusion of unwanted files or directories,                                                                                                                                                                                    #9 539.2   setuptools will not proceed with this build.                                                                                                                                                                                                       #9 539.2                                                                                                                                                                                                                                                      #9 539.2   If you are trying to create a single distribution with multiple packages                                                                                                                                                                           #9 539.2   on purpose, you should not rely on automatic discovery.                                                                                                                                                                                            #9 539.2   Instead, consider the following options:                                                                                                                                                                                                           #9 539.2                                                                                                                                                                                                                                                      #9 539.2   1. set up custom discovery (`find` directive with `include` or `exclude`)                                                                                                                                                                          #9 539.2   2. use a `src-layout`                                                                                                                                                                                                                              #9 539.2   3. explicitly set `py_modules` or `packages` with a list of names                                                                                                                                                                                  #9 539.2                                                                                                                                                                                                                                                      #9 539.2   To find more information, look for ""package discovery"" on setuptools docs.                                                                                                                                                                         #9 539.3   error: subprocess-exited-with-error                                                                                                                                                                                                                #9 539.3                                                                                                                                                                                                                                                      #9 539.3   闂?Getting requirements to build wheel did not run successfully.                                                                                                                                                                                    #9 539.3   闂?exit code: 1                                                                                                                                                                                                                                     #9 539.3   闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗霉閿濆懏鎯堟い銉︾閵囧嫰骞橀崡鐐典患缂佺偓鍎冲锟犲蓟閺囥垹閱囨繝闈涙祩濡倝姊虹紒妯肩畵闁绘牕銈搁獮鍐ㄎ旈崨顔芥珳闁硅偐琛ラ崜婵嬫倶閸垻纾? See above for output.                                                                                                                                                                                                                          #9 539.3                                                                                                                                                                                                                                                      #9 539.3   note: This error originates from a subprocess, and is likely not a problem with pip.                                                                                                                                                               #9 539.3   full command: /usr/bin/python3 /usr/local/lib/python3.9/dist-packages/pip/_vendor/pep517/in_process/_in_process.py get_requires_for_build_wheel /tmp/tmpis1s8vl8                                                                                   #9 539.3   cwd: /tmp/scratch/mirrored-pip-GRCQUK/numpy                                                                                                                                                                                                        #9 539.3   Getting requirements to build wheel: finished with status 'error'                                                                                                                                                                                  #9 539.3 error: subprocess-exited-with-error                                                                                                                                                                                                                  #9 539.3                                                                                                                                                                                                                                                      #9 539.3 闂?Getting requirements to build wheel did not run successfully.                                                                                                                                                                                      #9 539.3 闂?exit code: 1                                                                                                                                                                                                                                       #9 539.3 闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗霉閿濆懏鎯堟い銉︾閵囧嫰骞橀崡鐐典患缂佺偓鍎冲锟犲蓟閺囥垹閱囨繝闈涙祩濡倝姊虹紒妯肩畵闁绘牕銈搁獮鍐ㄎ旈崨顔芥珳闁硅偐琛ラ崜婵嬫倶閸垻纾? See above for output.                                                                                                                                                                                                                            #9 539.3                                                                                                                                                                                                                                                      #9 539.3 note: This error originates from a subprocess, and is likely not a problem with pip.```### NumPy/Python version information:Numpy 1.22.3Python 3.9Debian 11Setuptools 61.3.1
"
21284,1,4336,8,0,0,codingCoffee,0,"title:BUG: numpy.linalg.inv fails with Segmentation Fault in LXC but works on the host description:### Describe the issue:This might not necessarily be a `numpy` issue. But I was not sure where to go about posting it. It could be a bug in OpenBlas or in LXC.### Reproduce the code example:```python#!/usr/bin/env python3import numpynumpy.linalg.inv(5 * numpy.eye(40))```### Error message:```shell$ gdb --args python3 sample.pyGNU gdb (Ubuntu 8.1.1-0ubuntu1) 8.1.1Copyright (C) 2018 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.  Type ""show copying""and ""show warranty"" for details.This GDB was configured as ""x86_64-linux-gnu"".Type ""show configuration"" for configuration details.For bug reporting instructions, please see:<http://www.gnu.org/software/gdb/bugs/>.Find the GDB manual and other documentation resources online at:<http://www.gnu.org/software/gdb/documentation/>.For help, type ""help"".Type ""apropos word"" to search for commands related to ""word""...Reading symbols from python3...(no debugging symbols found)...done.(gdb) runStarting program: /usr/bin/python3 sample.py[Thread debugging using libthread_db enabled]Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".Program received signal SIGSEGV, Segmentation fault.0x00007ffff2f8b8ea in dgetrf_parallel () from /usr/lib/x86_64-linux-gnu/libopenblas.so.0(gdb) backtrace#0  0x00007ffff2f8b8ea in dgetrf_parallel () from /usr/lib/x86_64-linux-gnu/libopenblas.so.0#1  0x00007ffff2f8b543 in dgetrf_parallel () from /usr/lib/x86_64-linux-gnu/libopenblas.so.0#2  0x00007ffff2d790d4 in dgesv_ () from /usr/lib/x86_64-linux-gnu/libopenblas.so.0#3  0x00007ffff2237dde in call_dgesv (params=0x7fffffffb490) at numpy/linalg/umath_linalg.c.src:1566#4  DOUBLE_inv (args=<optimized out>, dimensions=<optimized out>, steps=<optimized out>, __NPY_UNUSED_TAGGEDfunc=<optimized out>) at numpy/linalg/umath_linalg.c.src:1711#5  0x00007ffff647364e in PyUFunc_GeneralizedFunction (op=0x7fffffffcd70, kwds=<optimized out>, args=<optimized out>, ufunc=0xeabf60) at numpy/core/src/umath/ufunc_object.c:2968#6  PyUFunc_GenericFunction_int (ufunc=<optimized out>, ufunc@entry=0x7ffff5161138, args=args@entry=0x7ffff68d6438, kwds=kwds@entry=0x7ffff6968870, op=op@entry=0x7fffffffcd70) at numpy/core/src/umath/ufunc_object.c:3101#7  0x00007ffff64738e6 in ufunc_generic_call (ufunc=0x7ffff5161138, args=0x7ffff68d6438, kwds=0x7ffff6968870) at numpy/core/src/umath/ufunc_object.c:4701#8  0x00000000005aa9ac in _PyObject_FastCallKeywords ()#9  0x000000000050af03 in ?? ()#10 0x000000000050d784 in _PyEval_EvalFrameDefault ()#11 0x0000000000508675 in ?? ()#12 0x00000000005899c1 in ?? ()#13 0x00000000005a07ce in PyObject_Call ()#14 0x00007ffff62adab7 in array_implement_array_function (__NPY_UNUSED_TAGGEDdummy=<optimized out>, positional_args=<optimized out>) at numpy/core/src/multiarray/arrayfunction_override.c:265#15 0x000000000050abff in ?? ()#16 0x000000000050c924 in _PyEval_EvalFrameDefault ()#17 0x0000000000508675 in ?? ()#18 0x000000000050a3e0 in ?? ()#19 0x000000000050adcd in ?? ()#20 0x000000000050c924 in _PyEval_EvalFrameDefault ()#21 0x0000000000508675 in ?? ()#22 0x000000000050b7d3 in PyEval_EvalCode ()#23 0x00000000006352e2 in ?? ()#24 0x0000000000635397 in PyRun_FileExFlags ()#25 0x0000000000638b4f in PyRun_SimpleFileExFlags ()#26 0x00000000006396f1 in Py_Main ()#27 0x00000000004b0e50 in main ()```### NumPy/Python version information:```>>> import sys, numpy; print(numpy.__version__, sys.version)1.19.5 3.6.9 (default, Mar 15 2022, 13:55:28)[GCC 8.4.0]```Also posting numpy config```>>> import numpy; print(numpy.__version__); numpy.show_config()1.19.5blas_mkl_info:  NOT AVAILABLEblis_info:  NOT AVAILABLEopenblas_info:    libraries = ['openblas', 'openblas']    library_dirs = ['/usr/lib/x86_64-linux-gnu']    language = c    define_macros = [('HAVE_CBLAS', None)]blas_opt_info:    libraries = ['openblas', 'openblas']    library_dirs = ['/usr/lib/x86_64-linux-gnu']    language = c    define_macros = [('HAVE_CBLAS', None)]lapack_mkl_info:  NOT AVAILABLEopenblas_lapack_info:    libraries = ['openblas', 'openblas']    library_dirs = ['/usr/lib/x86_64-linux-gnu']    language = c    define_macros = [('HAVE_CBLAS', None)]lapack_opt_info:    libraries = ['openblas', 'openblas']    library_dirs = ['/usr/lib/x86_64-linux-gnu']    language = c    define_macros = [('HAVE_CBLAS', None)]```
"
21279,1,348,280,0,0,felixdivo,0,"title:BUG: Indexing with single-value pytorch tensors can remove dimension description:### Describe the issue:In the interplay with *pytorch*, some indexing behaves very unexpected. I'd expect both pieces of indexing code to produce the exact same output. If this should be moved to https://github.com/pytorch/pytorch, please just tell me.### Reproduce the code example:```pythonimport numpyimport torchassert numpy.array ([0]).shape == torch.tensor([0]).shape, ""this is expected""assert numpy.array([[1,2],[3,4]])[numpy.array ([0]), :].shape == (1, 2), ""this is expected""assert numpy.array([[1,2],[3,4]])[torch.tensor([0]), :].shape == (2,), ""this is surprising""```### Error message:```shellNo traceback or real error message```### NumPy/Python version information:`1.21.2 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]`(And `torch.__version__` is `1.10.1`.)
"
21276,1,466,275,0,1,charris,0,"title:BUG,ENH: Fix negative bounds for F2PY description:Backport of #21256.Closes #20853.Some alternatives were suggested in the issue, namely disabling all checks, which is still an option but seems sub-optimal.However, there are some implementation notes which are important.This PR changes the behaviour of the **python caller**, which is now responsible for being the right size. That is:```fortransubroutine foo(is_, ie_, arr, tout) implicit none integer :: is_,ie_ real, intent(in) :: arr(is_:ie_) real, intent(out) :: tout(is_:ie_) tout = arrend```After compiling `f2py -m blah blah.f90`, this can be called with:```pythonimport numpy as npimport blahxlow = -6xhigh = 4xvec = np.arange(12)def ubound(xl, xh):  return abs(xl) + abs(xh) + 1rval = blah.foo(is_ = xlow, ie_ xhigh,         arr = xvec[:ubound(xlow, xhigh))expval = np.arange(11, dtype = np.float32)np.allclose(rval, expval) ```Essentially, the caller is now responsible in this scenario for ensuring that the **size** of the array passed in is correct, and this means for the most part that the slice should be calculated as above.Co-authored-by: Pearu Peterson <pearu.peterson@gmail.com><!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      http://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      http://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      http://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21272,0,0,7,0,1,shadchin,0,"title:BUG: Fix typos description:Replace `c99z` by `c99_z`.
"
21271,1,1475,4,0,1,robochat,0,"title:BUG: memory leak when casting SQLAlchemy results to numpy array description:### Describe the issue:I have a long running process that periodically requests data from a postgresql database using sqlalchemy and converts to the results to a numpy array for analysis. I see the process leaking memory on each coercion of the results to a numpy array. The sqlalchemy results are a list of sqlalchemy.engine.row.LegacyRow objects. The issue is the following line in the code below:    data = np.array(rows) In my real process after a couple of days it can be using 9 GB of RAM and after a week it crashes the server. The previous version (python2.7) used less than 200MB even after running for weeks.While creating the test case, I found that the same issue occurs with a sqlite in memory database. I also saw the same issue on my laptop and my server (both using sqlalchemy v.1.4.32 and v1.4.23). I posted this [issue](https://github.com/sqlalchemy/sqlalchemy/issues/7875) to the sqlalchemy github issues and it was confirmed to only occur when using the C-extensions version of sqlalchemy and occurred as far back as v1.3.### Reproduce the code example:```pythonimport sqlalchemy as sqlimport numpy as npimport timedburl = 'sqlite://'engine = sql.create_engine(dburl, echo=False)meta = sql.MetaData()tbl = sql.Table('test_table',meta,            sql.Column('a',sql.Integer,primary_key=True),            sql.Column('b',sql.Integer),            )meta.create_all(engine)#fill tablewith engine.connect() as conn:    conn.execute(tbl.insert(),                 [{'b': i} for i in range(200)]                 )#testwhile True:    with engine.connect() as conn:        query = sql.text(""SELECT a, b FROM test_table ORDER BY a LIMIT 200"")        results = conn.execute(query)        rows = results.fetchall()        data = np.array(rows)                #fixes that didn't work        del rows        results.close()        del data        time.sleep(0.1)```### Error message:```shellResident memory usage is up to 358MB in just a few minutes and there's no sign of stabilisation.after a couple of minutesPID    USER  PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                                                                                                                                                              1952762 aaa  20   0  762204 186264  16188 S   5.7   0.9   0:09.77 python3a bit laterPID    USER  PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND 1952762 aaa  20   0  934200 358092  16188 S   5.6   1.8   0:21.20 python3```### NumPy/Python version information:Numpy: 1.22.3 3.10.2 (main, Jan 15 2022, 19:56:27) [GCC 11.1.0]OS: Linux (CentOS)Python: 3.6.8SQLAlchemy: 1.4.32, 1.4.23Database: Postgresql (v12.9 64bit)DBAPI: psycopg2
"
21267,1,328,291,0,0,trivialfis,0,"title:BUG: `astype` corrupts data on ppc64le description:### Describe the issue:Using `astype(np.float32)` on integer array corrupts the data on ppc64el platform using numpy from conda-forge.### Reproduce the code example:```pythonnp.array([1, 0, 1, 0, 1, 0], dtype=int).astype(np.float32)```### Error message:```shellarray([0.0000000e+00, 0.0000000e+00,           nan, 2.3509886e-38,       1.0000000e+00, 0.0000000e+00], dtype=float32)``````### NumPy/Python version information:1.22.3 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:42:07) [GCC 10.3.0]
"
21259,1,270,31,0,0,salehmontazeran,0,"title:BUG: numpy.array(sample_python_list) and numpy.array(sample_python_list, dtype=numpy.float64) have different running time. description:### Describe the issue:`numpy.array(sample_python_list)` and `numpy.array(sample_python_list, dtype=numpy.float64)` have different running time.### Reproduce the code example:```pythonimport timeimport numpy as npa = list(range(100000000))start = time.time()np.array(a)end = time.time()print(""Without dtype:"", end - start)start = time.time()np.array(a, dtype=np.float64)end = time.time()print(""With dtype:"", end - start)```### Error message:_No response_### NumPy/Python version information:1.22.33.8.10 (default, Mar 15 2022, 12:22:08)[GCC 9.4.0]
"
21257,0,1090,86,0,0,ganesh-k13,0,"title:ENH: `np.kron` Enhancements Tracking description:## Kronecker Product Enhancements Tracker`np.kron` lacks a few features and required testing. This GH issue aims to capture all of them in a single place.### 1. Masked array supportCurrently, masked arrays are not supported for `np.kron`Example:```python>>> x = ma.array([[1, 2], [3, 4]], mask=[[0, 1], [1, 0]])>>> xmasked_array(  data=[[1, --],        [--, 4]],  mask=[[False,  True],        [ True, False]],  fill_value=999999)>>> np.kron(x,x)masked_array(  data=[[ 1,  2,  2,  4],        [ 3,  4,  6,  8],        [ 3,  6,  4,  8],        [ 9, 12, 12, 16]],  mask=False,  fill_value=999999)```### 2. `ValueError` on zero dimsOriginal issue: #21051`numpy.kron` function raises an exception `ValueError: need at least one array to concatenate` when first argument has zero dimensionality (either `[0, N]` or `[N, 0]` shape).Reproduce the code example:```pythonimport numpy as npnp.kron(np.zeros([0, 3]), np.zeros([2, 2]))  # raises an exceptionnp.kron(np.zeros([3, 0]), np.zeros([2, 2]))  # raises an exceptionnp.kron(np.zeros([3, 3]), np.zeros([0, 2]))  # works perfectly finenp.kron(np.zeros([3, 3]), np.zeros([2, 0]))  # works perfectly fine```### 3. Improve performance of kronPerformance of kron can be improved further. Source: https://stackoverflow.com/questions/56067643/speeding-up-kronecker-products-numpy/56067827#56067827Brief:Benchmarks```>>> a = np.random.random((60,60))>>> b = np.random.random((60,60))```After #21232 :```>>> np.__version__'1.22.0.dev0+2808.g7916d567f'>>> timeit.timeit(lambda: np.kron(a, b), number=10)0.6451533360000212```Before:```>>> np.__version__'1.21.2'>>> timeit.timeit(lambda: np.kron(a, b), number=10)1.0160858610001924```~57% perf improvement.But there is a better way as per https://stackoverflow.com/a/56067827/5671364```>>> timeit.timeit(lambda: np.einsum('ik,jl', a, b).reshape(3600,3600), number=10)0.3949863890002234```</details>### 4. Improve functional testingCurrently, there are only few test cases covering type checks, dim checks, and basic smoke tests.Requirement is to have more tests on the functionality of kronTracking:* [x] 1. Masked array support: https://github.com/numpy/numpy/pull/21262* [x] 2. `ValueError` on zero dims: #21232 * [x] 3. Improve performance of kron: https://github.com/numpy/numpy/pull/21354* [x] 4. Improve functional testing
"
21256,0,466,291,0,1,HaoZeke,0,"title:BUG,ENH: Fix negative bounds for F2PY description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      http://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      http://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      http://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->Closes #20853.Some alternatives were suggested in the issue, namely disabling all checks, which is still an option but seems sub-optimal.However, there are some implementation notes which are important.This PR changes the behaviour of the **python caller**, which is now responsible for being the right size. That is:```fortransubroutine foo(is_, ie_, arr, tout) implicit none integer :: is_,ie_ real, intent(in) :: arr(is_:ie_) real, intent(out) :: tout(is_:ie_) tout = arrend```After compiling `f2py -m blah blah.f90`, this can be called with:```pythonimport numpy as npimport blahxlow = -6xhigh = 4xvec = np.arange(12)def ubound(xl, xh):  return abs(xl) + abs(xh) + 1rval = blah.foo(is_ = xlow, ie_ xhigh,         arr = xvec[:ubound(xlow, xhigh))expval = np.arange(11, dtype = np.float32)np.allclose(rval, expval) ```Essentially, the caller is now responsible in this scenario for ensuring that the **size** of the array passed in is correct, and this means for the most part that the slice should be calculated as above.
"
21249,1,347,300,0,0,twoertwein,0,"title:TYP: Operators for npt.NDArray[np.number] are missing description:### Describe the issue:Functions often accepts any ndarray as long as the elements are numbers. Using `npt.NDArray[np.number]` creates many mypy/pyright errors as none of the operators seems to be annotated for it.### Reproduce the code example:```pythonimport numpy as npimport numpy.typing as nptdef foo(x: npt.NDArray[np.number]):    x * 1    x * x```### Error message:```shellerror: Unsupported operand types for * (""ndarray[Any, dtype[number[Any]]]"" and ""int"")  [operator]error: Unsupported operand types for * (""ndarray[Any, dtype[number[Any]]]"" and ""ndarray[Any, dtype[number[Any]]]"")  [operator]```### NumPy/Python version information:1.22.3 3.10.2 (v3.10.2:a58ebcc, Mar 10 2022, 19:36:59) [GCC 9.4.0]
"
21246,0,52,2,0,0,bhavukkalra,0,"title:BUG: restructuredtext VSCode Extension Un-responsive in Gitpod description:### Describe the issue:restructuredtext - An extension which is used to render live preview of the Documentation is not working. In short `unable to display live preview`Live Preview Not loading up - ![OBSELETE_PROBLEMS](https://user-images.githubusercontent.com/41142068/160176965-46651ba4-d3bc-4d66-a987-0343a11d36a0.PNG)**Issue cause** - Deprecated vscode settings, After the [178.0.0](https://github.com/vscode-restructuredtext/vscode-restructuredtext/releases/tag/178.0.0) release (Which was released 12 days ago, from the day of reporting this issue). Which made certain settings the project is using not work any more**Solution** - Replace the settings with the newer ones### Reproduce the code example:```pythonOpen up the Repo via Gitpod Chrome Extension```### Error message:_No response_### NumPy/Python version information:RAN ON GITPODprint(numpy.__version__)**1.23.0.dev0+950.g266aad747**print(sys.version)3.9.10 | packaged by conda-forge | (main, Feb  1 2022, 21:24:11) [GCC 9.4.0]
"
21242,1,10359,282,0,0,ilayn,0,"title:BUG: Cython can't find complex function symbols in ""npy_math.h"" description:### Describe the issue:It may be that this is not related to NumPy per se however I am running out of ideas hence I'd like to ask for your guidance on this. But if it is Cython related please feel free to close it. This is a bit of an XY problem. What I actually want is to get a `sqrt` function to be used in Cython code for SciPy involving negative reals and complex numbers. But `np.sqrt` or `libc.math.sqrt`  doesn't cut it as they are only defined for positive reals. Hence I wanted to use the `npy_csqrt(,f,l)` which are able to extend to complex domain. Now 1.5 issues - Is there any other alternative that I am missing for problem X? - If not, then I am trying to use the following cython code to no avail since (I think I have an MSVC and C99 issue, emphasis on I think).It is currently ready for to be pasted on a Jupyter notebook but can also be run separately in a Cythonized environment.It seems like somehow the externals are not available due to some problem I cannot point to. I've also tried with many complex functions and they all suffer from the same. I also tried importing `isnan` and alike again from `npy_math.h`, and suprisingly they work fine (don't know if it is related).### Reproduce the code example:```pythonimport cython%load_ext cython# ============ paste below to a separate cell =====%%cythoncimport cythoncimport numpy as cnpimport numpy as npcnp.import_array()ctypedef union _z_data:    cnp.npy_cdouble np_z    double complex lpck_zcdef extern from ""numpy/npy_math.h"":    cnp.npy_cdouble npy_csqrt(cnp.npy_cdouble z) nogil    cnp.npy_cfloat csqrtf(cnp.npy_cfloat x) nogil# Until Cython 3.0 arrives, we need to cook up a fast# C level complex sqrt wrapper. These are two util functions# that convert between ""double complex"" and ""npy_cdouble""cdef inline (double complex) np_to_lpck_z(cnp.npy_cdouble npz) nogil:    cdef _z_data z    z.np_z = npz    return z.lpck_zcdef inline cnp.npy_cdouble lpck_to_np_z(double complex lpckz) nogil:    cdef _z_data z     z.lpck_z = lpckz    return z.np_zprint(lpck_to_np_z(1.))  #  <- Runsprint(np_to_lpck_z(npy_csqrt(lpck_to_np_z(1.))))```### Error message:```shellCreating library C:\Users\ilhan\.ipython\cython\Users\ilhan\.ipython\cython\_cython_magic_030ed27135cc271819b55331db7acecf.cp39-win_amd64.lib and object C:\Users\ilhan\.ipython\cython\Users\ilhan\.ipython\cython\_cython_magic_030ed27135cc271819b55331db7acecf.cp39-win_amd64.exp_cython_magic_030ed27135cc271819b55331db7acecf.obj : error LNK2001: unresolved external symbol npy_csqrtC:\Users\ilhan\.ipython\cython\_cython_magic_030ed27135cc271819b55331db7acecf.cp39-win_amd64.pyd : fatal error LNK1120: 1 unresolved externals---------------------------------------------------------------------------DistutilsExecError                        Traceback (most recent call last)File c:\users\ilhan\appdata\local\programs\python\python39\lib\distutils\_msvccompiler.py:497, in MSVCCompiler.link(self, target_desc, objects, output_filename, output_dir, libraries, library_dirs, runtime_library_dirs, export_symbols, debug, extra_preargs, extra_postargs, build_temp, target_lang)    496     log.debug('Executing ""%s"" %s', self.linker, ' '.join(ld_args))--> 497     self.spawn([self.linker] + ld_args)    498 except DistutilsExecError as msg:File c:\users\ilhan\appdata\local\programs\python\python39\lib\distutils\_msvccompiler.py:507, in MSVCCompiler.spawn(self, cmd)    506     os.environ['path'] = self._paths--> 507     return super().spawn(cmd)    508 finally:File c:\users\ilhan\appdata\local\programs\python\python39\lib\site-packages\numpy-1.23.0.dev0+942.g2c89e154c-py3.9-win-amd64.egg\numpy\distutils\ccompiler.py:89, in replace_method.<locals>.<lambda>(self, *args, **kw)     87 def replace_method(klass, method_name, func):     88     # Py3k does not have unbound method anymore, MethodType does not work---> 89     m = lambda self, *args, **kw: func(self, *args, **kw)     90     setattr(klass, method_name, m)File c:\users\ilhan\appdata\local\programs\python\python39\lib\site-packages\numpy-1.23.0.dev0+942.g2c89e154c-py3.9-win-amd64.egg\numpy\distutils\ccompiler.py:180, in CCompiler_spawn(self, cmd, display, env)    179     msg = ''--> 180 raise DistutilsExecError('Command ""%s"" failed with exit status %d%s' %    181                         (cmd, s, msg))DistutilsExecError: Command ""C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.31.31103\bin\HostX86\x64\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:c:\users\ilhan\appdata\local\programs\python\python39\libs /LIBPATH:c:\users\ilhan\appdata\local\programs\python\python39\PCbuild\amd64 /LIBPATH:C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.31.31103\lib\x64 /LIBPATH:C:\Program Files (x86)\Windows Kits\10\lib\10.0.20348.0\ucrt\x64 /LIBPATH:C:\Program Files (x86)\Windows Kits\10\\lib\10.0.20348.0\\um\x64 /EXPORT:PyInit__cython_magic_030ed27135cc271819b55331db7acecf C:\Users\ilhan\.ipython\cython\Users\ilhan\.ipython\cython\_cython_magic_030ed27135cc271819b55331db7acecf.obj /OUT:C:\Users\ilhan\.ipython\cython\_cython_magic_030ed27135cc271819b55331db7acecf.cp39-win_amd64.pyd /IMPLIB:C:\Users\ilhan\.ipython\cython\Users\ilhan\.ipython\cython\_cython_magic_030ed27135cc271819b55331db7acecf.cp39-win_amd64.lib"" failed with exit status 1120During handling of the above exception, another exception occurred:LinkError                                 Traceback (most recent call last)Input In [6], in <cell line: 1>()----> 1 get_ipython().run_cell_magic('cython', '-a', 'cimport cython\ncimport numpy as cnp\nimport numpy as np\ncnp.import_array()\n\nctypedef union _z_data:\n    cnp.npy_cdouble np_z\n    double complex lpck_z\n\ncdef extern from ""numpy/npy_math.h"":\n    cnp.npy_cdouble npy_csqrt(cnp.npy_cdouble z) nogil\n    cnp.npy_cfloat csqrtf(cnp.npy_cfloat x) nogil\n\n# Until Cython 3.0 arrives, we need to cook up a fast\n# C level complex sqrt wrapper.\ncdef inline (double complex) np_to_lpck_z(cnp.npy_cdouble npz) nogil:\n    cdef _z_data z\n    z.np_z = npz\n    return z.lpck_z\n\ncdef inline cnp.npy_cdouble lpck_to_np_z(double complex lpckz) nogil:\n    cdef _z_data z\n    z.lpck_z = lpckz\n    return z.np_z\n\nprint(lpck_to_np_z(1.))\nprint(np_to_lpck_z(npy_csqrt(lpck_to_np_z(1.))))\n')File c:\users\ilhan\appdata\local\programs\python\python39\lib\site-packages\IPython\core\interactiveshell.py:2338, in InteractiveShell.run_cell_magic(self, magic_name, line, cell)   2336 with self.builtin_trap:   2337     args = (magic_arg_s, cell)-> 2338     result = fn(*args, **kwargs)   2339 return resultFile c:\users\ilhan\appdata\local\programs\python\python39\lib\site-packages\Cython\Build\IpythonMagic.py:345, in CythonMagics.cython(self, line, cell)    342         self._profile_pgo_wrapper(extension, lib_dir)    344 try:--> 345     self._build_extension(extension, lib_dir, pgo_step_name='use' if args.pgo else None,    346                           quiet=args.quiet)    347 except distutils.errors.CompileError:    348     # Build failed and printed error message    349     return NoneFile c:\users\ilhan\appdata\local\programs\python\python39\lib\site-packages\Cython\Build\IpythonMagic.py:459, in CythonMagics._build_extension(self, extension, lib_dir, temp_dir, pgo_step_name, quiet)    457     if not quiet:    458         old_threshold = distutils.log.set_threshold(distutils.log.DEBUG)--> 459     build_extension.run()    460 finally:    461     if not quiet and old_threshold is not None:File c:\users\ilhan\appdata\local\programs\python\python39\lib\distutils\command\build_ext.py:340, in build_ext.run(self)    337     self.compiler.set_link_objects(self.link_objects)    339 # Now actually compile and link everything.--> 340 self.build_extensions()File c:\users\ilhan\appdata\local\programs\python\python39\lib\distutils\command\build_ext.py:449, in build_ext.build_extensions(self)    447     self._build_extensions_parallel()    448 else:--> 449     self._build_extensions_serial()File c:\users\ilhan\appdata\local\programs\python\python39\lib\distutils\command\build_ext.py:474, in build_ext._build_extensions_serial(self)    472 for ext in self.extensions:    473     with self._filter_build_errors(ext):--> 474         self.build_extension(ext)File c:\users\ilhan\appdata\local\programs\python\python39\lib\distutils\command\build_ext.py:551, in build_ext.build_extension(self, ext)    548 # Detect target language, if not provided    549 language = ext.language or self.compiler.detect_language(sources)--> 551 self.compiler.link_shared_object(    552     objects, ext_path,    553     libraries=self.get_libraries(ext),    554     library_dirs=ext.library_dirs,    555     runtime_library_dirs=ext.runtime_library_dirs,    556     extra_postargs=extra_args,    557     export_symbols=self.get_export_symbols(ext),    558     debug=self.debug,    559     build_temp=self.build_temp,    560     target_lang=language)File c:\users\ilhan\appdata\local\programs\python\python39\lib\distutils\ccompiler.py:713, in CCompiler.link_shared_object(self, objects, output_filename, output_dir, libraries, library_dirs, runtime_library_dirs, export_symbols, debug, extra_preargs, extra_postargs, build_temp, target_lang)    700 def link_shared_object(self,    701                        objects,    702                        output_filename,   (...)    711                        build_temp=None,    712                        target_lang=None):--> 713     self.link(CCompiler.SHARED_OBJECT, objects,    714               output_filename, output_dir,    715               libraries, library_dirs, runtime_library_dirs,    716               export_symbols, debug,    717               extra_preargs, extra_postargs, build_temp, target_lang)File c:\users\ilhan\appdata\local\programs\python\python39\lib\distutils\_msvccompiler.py:499, in MSVCCompiler.link(self, target_desc, objects, output_filename, output_dir, libraries, library_dirs, runtime_library_dirs, export_symbols, debug, extra_preargs, extra_postargs, build_temp, target_lang)    497         self.spawn([self.linker] + ld_args)    498     except DistutilsExecError as msg:--> 499         raise LinkError(msg)    500 else:    501     log.debug(""skipping %s (up-to-date)"", output_filename)LinkError: Command ""C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.31.31103\bin\HostX86\x64\link.exe /nologo /INCREMENTAL:NO /LTCG /DLL /MANIFEST:EMBED,ID=2 /MANIFESTUAC:NO /LIBPATH:c:\users\ilhan\appdata\local\programs\python\python39\libs /LIBPATH:c:\users\ilhan\appdata\local\programs\python\python39\PCbuild\amd64 /LIBPATH:C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.31.31103\lib\x64 /LIBPATH:C:\Program Files (x86)\Windows Kits\10\lib\10.0.20348.0\ucrt\x64 /LIBPATH:C:\Program Files (x86)\Windows Kits\10\\lib\10.0.20348.0\\um\x64 /EXPORT:PyInit__cython_magic_030ed27135cc271819b55331db7acecf C:\Users\ilhan\.ipython\cython\Users\ilhan\.ipython\cython\_cython_magic_030ed27135cc271819b55331db7acecf.obj /OUT:C:\Users\ilhan\.ipython\cython\_cython_magic_030ed27135cc271819b55331db7acecf.cp39-win_amd64.pyd /IMPLIB:C:\Users\ilhan\.ipython\cython\Users\ilhan\.ipython\cython\_cython_magic_030ed27135cc271819b55331db7acecf.cp39-win_amd64.lib"" failed with exit status 1120```</details>### NumPy/Python version information:Windows 10 21H2 19044.1586Python 3.9.6NumPy 1.23.0.dev0+942.g2c89e154c (but also tried with the latest release with same problem)Cython 0.29.28MS Visual Studio 2022 Community Edition (installed components)  - Windows Universal C Runtime  - MSVC v143 - VS 2022 C++ x64/x86 Build Tools (latest)  - Windows 10 SDK (10.0.20348.0)
"
21240,0,2000,4,0,0,pdeblanc,0,"title:`TypeError` raised by `help(numpy.typing)` description:### Describe the issue:Calling `help(numpy.typing)` raises an exception rather than displaying help text.### Reproduce the code example:```pythonimport numpy.typinghelp(numpy.typing)```### Error message:```shellTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/_sitebuiltins.py"", line 103, in __call__    return pydoc.help(*args, **kwds)  File ""/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pydoc.py"", line 2002, in __call__    self.help(request)  File ""/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pydoc.py"", line 2061, in help    else: doc(request, 'Help on %s:', output=self._output)  File ""/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pydoc.py"", line 1780, in doc    pager(render_doc(thing, title, forceload))  File ""/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pydoc.py"", line 1773, in render_doc    return title % desc + '\n\n' + renderer.document(object, name)  File ""/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pydoc.py"", line 472, in document    if inspect.ismodule(object): return self.docmodule(*args)  File ""/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pydoc.py"", line 1267, in docmodule    contents.append(self.document(value, key, name))  File ""/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pydoc.py"", line 473, in document    if inspect.isclass(object): return self.docclass(*args)  File ""/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pydoc.py"", line 1343, in docclass    (str(cls.__name__) for cls in type.__subclasses__(object)TypeError: descriptor '__subclasses__' for 'type' objects doesn't apply to a 'types.GenericAlias' object```### NumPy/Python version information:```1.22.3 3.9.10 (main, Jan 15 2022, 11:48:00)[Clang 13.0.0 (clang-1300.0.29.3)]```
"
21237,1,109,0,0,0,cwestc,0,"title:BUG: Subtraction of uints that should result in negative number overflows without warning description:### Describe the issue:When subtracting uints that would result in a negative number, the result is an overflowed unsigned int without warning.Subtracting two uint16 arrays:[1,1,1] - [2,2,2] = [65535,65535,65535]OS: Windows 10### Reproduce the code example:```pythonimport numpy as npprint(np.array([1,1,1], dtype='uint16') - (np.array([2,2,2], dtype='uint16'))```### Error message:_No response_### NumPy/Python version information:NumPy: 1.20.3Python:  3.9
"
21233,1,397,99,0,0,w3sip,0,"title:BUG: Can't install universal2 version of numpy description:### Describe the issue:Release notes document MD5 checksums for universal2 wheels. However, I can't seem to find one.Any attempt to `python3 -m pip install numpy  --target foo --platform=universal2` results in building from source (asks to add `--no-deps`), which subsequently fails.What would be the best way to install universal2 (e.g. arm64+x86_64) distribution of numpy?### Reproduce the code example:```pythonn/a```### Error message:```shell: error: no such file or directory: 'build/temp.macosx-10.9-universal2-3.9/numpy/core/src/multiarray/dragon4.o'```Full error: https://gist.github.com/w3sip/a99d0febfd44e7e991b6d32117ba3291### NumPy/Python version information:```$ python3.9 --versionPython 3.9.11$ which python3.9/usr/local/bin/python3.9$ ls -la /usr/local/bin/python3.9lrwxr-xr-x  1 root  wheel  71 Mar 16  2021 /usr/local/bin/python3.9 -> ../../../Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9```
"
21232,0,0,86,0,1,ganesh-k13,0,"title:BUG: Fixes `ValueError` in `np.kron` description:## Changes### BUG: Refactor np.kron to handle 0 in shape* `np.kron` uses `np.concatenate` which fails when shape is 0 along an  axis* Refactor shape normalising portion.### TST: Added testcases for np.kron* Smoke tests to ensure `np.kron` works.* Shape tests to check if `np.kron` computes the right shape for  different edge cases of input arraysFixes: #21051
"
21231,0,0,292,0,0,seberg,0,"title:BUG: Catch error if array-priority is not float compatible description:This is a bit cleaner than before.  This shouldn't lead to seriousissues, normally just a SystemError, because the error is not cleared.But maybe it is a bit cleaner.EDIT: Moved from gh-21217  something went very wrong there after a force-push (that had failed on the github side the first time)~EDIT2: Well, I guess this will take a bit longer ;).  Now CI is acting up, seems github just has some issues right now...~
"
21230,1,977,0,0,0,sweenb1,0,"title:BUG:  importing numpy 1.22.3 throws error No module named 'numpy.random._common' description:### Describe the issue:After installing Numpy 1.22.3 (first time install) the ""import numpy"" command gives error:No module named 'numpy.random._common'Tried uninstalling/reinstalling several times. Then uninstalled version 1.22.3 and installed version 1.22.2 and the import worked without error.### Reproduce the code example:```pythonNo code see error message```### Error message:```shellPython 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)] on win32Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.>>> import numpyTraceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""C:\Users\[user]\AppData\Local\Programs\Python\Python310\Lib\site-packages\numpy\__init__.py"", line 155, in <module>    from . import random  File ""C:\Users\[user]\AppData\Local\Programs\Python\Python310\Lib\site-packages\numpy\random\__init__.py"", line 180, in <module>    from . import _pickle  File ""C:\Users\[user]\AppData\Local\Programs\Python\Python310\Lib\site-packages\numpy\random\_pickle.py"", line 1, in <module>    from .mtrand import RandomState  File ""mtrand.pyx"", line 1, in init numpy.random.mtrand  File ""bit_generator.pyx"", line 1, in init numpy.random.bit_generatorModuleNotFoundError: No module named 'numpy.random._common'>>>```### NumPy/Python version information:print(sys.version)3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]
"
21222,1,978,39,0,0,mahdibaghbanzadeh,0,"title:BUG: stop catching at least criticial errors in array comparisons description:### Describe the issue:I'm trying to compare each row of a NumPy array with the whole NumPy array without using iteration.```>>> sample = np.array([[1,2,3],[4,5,6]])>>> samplearray([[1, 2, 3],       [4, 5, 6]])```First I reshape the 2D-array to a 3D-array:```>>> sample2=sample.reshape(sample.shape[0],1,sample.shape[1])```And then with the following line of code, I can compare the rows:```>>> sample2 == samplearray([[[ True,  True,  True],        [False, False, False]],        [[False, False, False],        [ True,  True,  True]]])```...which is the result that I'm looking for.But this does not work with large numpy arrays:```>>> sample3 = np.random.randint(low= 0, high = 2, size = 30000000).reshape(30000,1000)>>> sample4 = sample3.reshape(sample3.shape[0],1,sample3.shape[1])>>> sample4 == sample3  <ipython-input-229-e1d55c6bb1ca>:1: DeprecationWarning: elementwisecomparison failed; this will raise an error in the future.False```### Reproduce the code example:```pythonimport numpy as npsample3 = np.random.randint(low= 0, high = 2, size = 30000000).reshape(30000,1000)sample4 = sample3.reshape(sample3.shape[0],1,sample3.shape[1])sample4 == sample3```### Error message:```shell<ipython-input-229-e1d55c6bb1ca>:1: DeprecationWarning: elementwisecomparison failed; this will raise an error in the future.False```### NumPy/Python version information:1.19.5
"
21218,0,0,292,0,1,seberg,0,"title:BUG: Use -0. as initial value for summation (internal only) description:Technically, we should ensure that we do all summations starting with-0 unless there is nothing to sum (in which case the result is clearly0).This is a start, since the initial value is still filled in as 0 bythe reduce machinery.  However, it fixes the odd case where aninplace addition:   x1 = np.array(-0.0)   x2 = np.array(-0.0)   x1 += x2May go into the reduce code path (becaus strides are 0).  We couldavoid the reduce path there, but -0 here is strictly correct anywayand also a necessary step towards fixing `sum([-0., -0., -0.])`which still requires `initial=-0.0` to be passed manually right now.There are new `xfail` marked tests also checking the path withoutinitial.  Presumably, we should be using -0.0 as initial value,but 0.0 as default (if an array is empty) here.This may be more reasonably possible after gh-20970.Closes gh-21213, gh-21212
"
21217,1,0,292,0,0,seberg,0,"title:BUG: Catch error if array-priority is not float compatible description:This is a bit cleaner than before.  This shouldn't lead to seriousissues, normally just a SystemError, because the error is not cleared.But maybe it is a bit cleaner.---Just because I stumbled on it writing scalar-math tests... Happy to just not follow up as well ;).
"
21214,0,222,39,0,0,ThunderKey,0,"title:BUG: Usage of implicit reexports breaks using mypy with `--no-implicit-reexport` description:### Describe the issue:The code example described below, when checked with mypy, reveals the type of the array and generates an error. If mypy is used with the option `--no-implicit-reexport` the code example described below does not reveal the type and does not generate any error. Adding the option `--warn-unreachable` shows that everything after `numpy.cross` is detected as unreachable.As detected in python/mypy#12350 the issue is that an overload of `numpy.cross` uses `_ArrayLikeBool_co` but it is an implicit reexport. Due to that it resolves to `Any` and the following overload matches all calls to `numpy.cross` and the calls resolve to `NoReturn`.https://github.com/numpy/numpy/blob/71e7620711d6ff8cb838bdffb5e91cdd25497dba/numpy/core/numeric.pyi#L461-L469I see two options to resolve this issue:1. Replacing imports from `numpy.typing` to the package where they are actually defined, like `from numpy.typing._array_like import _ArrayLikeBool_co`2. Explicitly reexport private types from `numpy.typing` as well.### Reproduce the code example:```pythonimport numpyfrom numpy.typing import ArrayLikedef test_method() -> None:    value: ArrayLike = numpy.cross(numpy.array([1, 2, 3]), numpy.array([4, 5, 6]))    reveal_type(value)    broken: int = 'test'```### Error message:_No response_### NumPy/Python version information:1.22.3 3.10.2 (main, Jan 15 2022, 19:56:27) [GCC 11.1.0]
"
21212,1,0,297,0,1,honno,0,"title:BUG: Fix `array_api` arrays not inplace adding neg zeros correctly description:Fixes #21211 and includes a regression test. Testing for neg zeros is a bit annoying闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨搴ｇ磽閸屾瑨顔夐柡鍛█瀵鏁愭径妯绘櫓闂佺粯鍔﹂崜姘舵偟?me know if I missed an existing utility for this.Note I opted to just fallback on `ndarray.__add__()`. This is not ideal as we lose the checks against an inplace array having their dtype/shape modified, so I hard-coded those checks in (an introduced an additional test).
"
21211,1,207,297,0,1,honno,0,"title:BUG: `__iadd__()` for `numpy.array_api` arrays does not follow negative zeros special case description:### Describe the issue:The Array API spec requires [`__add__()`](https://data-apis.org/array-api/latest/API_specification/generated/signatures.array_object.array.__add__.html#signatures.array_object.array.__add__), and by extension `__iadd__()`, to output a negative 0 when both operands are negative 0. NumPy currently follows this special case for `__add__()`, but not for `__iadd__()`. cc @asmeurer (I'll have a look at fixing this later.)### Reproduce the code example:```pythonIn [4]: x1 = xp.asarray(-0.)In [5]: x2 = xp.asarray(-0.)In [6]: x1 + x2Out[6]: Array(-0., dtype=float64)In [7]: x1 += x2In [8]: x1Out[8]: Array(0., dtype=float64)  # should be -0.```### Error message:_No response_### NumPy/Python version information:1.22.3 3.8.12 (default, Mar 13 2022, 19:12:08) [GCC 9.4.0]
"
21210,1,142,292,0,0,PrimozGodec,0,"title:BUG: float64 nan changes hash description:### Describe the issue:Float64 nan value changes its hashes, which is annoying when transforming array to another structure (e.g. tuple) and wants to compute has. I would expect that nan's hash would not change. It is happening just for float64 nans and only with Python 3.10. ### Reproduce the code example:```pythonfor i in range(10):    print(hash(np.float64(""nan"")))```Result:```87838128294478783812829423878381282944787838128294238783812829447```Observe different hashes. Also reproducible with running `hash(np.float64(""nan""))` multiple times in python console.### Error message:_No response_### NumPy/Python version information:1.22.3Python version: 3.10
"
21205,0,0,287,0,1,sunt05,0,"title:BUG: f2py cannot read in customised f2cmap file; fix #21204 description:Fixes numpy/numpy#21204<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      http://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      http://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      http://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21204,0,640,287,0,0,sunt05,0,"title:BUG: f2py cannot read in customised f2cmap file  description:### Describe the issue:F2PY cannot read in user defined f2cmap file:```Reading f2cmap from '.f2py_f2cmap' ...Failed to apply user defined f2cmap changes: dictionary changed size during iteration. Skipping.```### Reproduce the code example:1. `test.f90`:```! test.f90FUNCTION square(x) RESULT(xx)      IMPLICIT NONE      REAL(KIND(1D0)), INTENT(in) :: x      REAL(KIND(1D0)) :: xx      xx = x**2END FUNCTION square```2. custom f2cmap `.f2py_f2cmap`:```{'real':{'KIND(1D0)':'double'}}```place the above files in the same directory, then run the following command:```python -m numpy.f2py -m test -c test.f90```### Error message:```shellReading f2cmap from '.f2py_f2cmap' ...Failed to apply user defined f2cmap changes: dictionary changed size during iteration. Skipping.```### NumPy/Python version information:```1.22.2 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 20:33:18) [Clang 11.1.0 ]```
"
21196,0,1164,275,0,0,jonashaag,0,"title:BUG: Building 1.22.3 32 bit on non-AVX512 machine requires NPY_DISABLE_SVML=1 description:### Describe the issue:On GitHub Actions, which uses CPUs without AVX512 support, building 32 bit 1.22.3 fails:```...numpy/core/src/umath/svml/linux/avx512/svml_z0_atan_d_la.s:255: Error: bad register name `%xmm9'...```It works if you set `NPY_DISABLE_SVML=1`.### Reproduce the code example:GitHub Actions workflow:```yaml...jobs:  test-32bit:    runs-on: ubuntu-20.04    container: quay.io/pypa/manylinux2014_i686    steps:    - name: Build      run: /opt/python/cp38-cp38/bin/pip install numpy``````$ grep -i avx /proc/cpuinfoflags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt md_clearflags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt md_clear```### Error message:_No response_### NumPy/Python version information:1.22.3
"
21191,0,0,275,0,1,charris,0,"title:TYP, BUG: Fix ``np.lib.stride_tricks`` re-exported under the wrong name description:Backport of #21185.Closes #21183.In practice this is a typo fix: `stride_stricks` -> `stride_tricks`.<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      http://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      http://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      http://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21185,0,0,139,0,1,BvB93,0,"title:TYP, BUG: Fix ``np.lib.stride_tricks`` re-exported under wrong name description:Closes #21183.In practice this is a typo fix: `stride_stricks` -> `stride_tricks`.
"
21184,1,464,0,0,0,pEtienn,0,"title:BUG: _percentile_dispatcher() got an unexpected keyword argument 'method' description:### Describe the issue:The np.percentile function does not recognize the ""method"" argument. This can be reproduce with the code below or the example code in the doc page.### Reproduce the code example:```pythonnp.percentile(np.arange(100),np.arange(100),method='linear')```### Error message:```shellTypeError                                 Traceback (most recent call last)c:\Users\Etienne\Documents\GitHub\tensorflow_testing\npyTest.ipynb Cell 2' in <module>----> 1 np.percentile(np.arange(100),np.arange(100),method='linear')File <__array_function__ internals>:4, in percentile(*args, **kwargs)TypeError: _percentile_dispatcher() got an unexpected keyword argument 'method'```### NumPy/Python version information:My computer:1.21.5 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]and Google colab default env:1.21.5 3.7.12 (default, Jan 15 2022, 18:48:18) [GCC 7.5.0]
"
21183,0,159,300,0,0,twoertwein,0,"title:TYP: np.lib.stride_tricks is not marked as being public description:### Describe the issue:`sliding_window_view` is a public function, but it is inaccessible to type checkers.### Reproduce the code example:```pythonimport numpy as npnp.lib.stride_tricks.sliding_window_view```### Error message:```shellpyright: ""stride_tricks"" is not a known member of module (reportGeneralTypeIssues)```### NumPy/Python version information:1.22.3 3.10.2 (v3.10.2:a58ebcc, Mar 10 2022, 19:36:59) [GCC 9.4.0]
"
21182,1,1659,126,0,0,adrianschlatter,0,"title:BUG: ndarray prevents __radd__ overloading in custom classes description:### Describe the issue:I write a custom class MyClass that supports addition with ndarrays. That means* `MyClass + ndarray`* `ndarray + MyClass`are meaningful operations (that return a MyClass object). The former works flawlessly, the latter does not. Here's what happens (see demo in example code):For `ndarray + MyClass`, Python first tries `ndarray.__add__(...)`. This method does not know (and can not know) how to do additions involving MyClass objects. Therefore, I expect it to `raise NotImplementedError`. Instead, it tries to do elementwise addition, i.e., it calls `MyClass.__radd__(...)` multiple times with a float as argument (instead of once with an ndarray). The attached code example demonstrates this and also shows that `*, //, %, -` behave the same way. The only exception seems to be `np.matrix` multiplication which (correctly) calls `MyClass.__rmul__(...)` with the entire matrix as argument (but it also tries to go elementwise with `//, %, +, -`).I hoped to stop numpy from doing this by making clear that MyClass does not support addition with floats by raising NoteImplementedError in `MyClass.__radd__(...)`. However, numpy does not revert to calling `MyClass.__radd__(...)` with the entire ndarray and just fails (not shown in the attached code).Also, I cannot resort to only use `MyClass + ndarray` because this sort of addition is not commutative.### Reproduce the code example:```pythonimport numpy as npclass MyClass():    def __rmul__(self, left):        print(type(left))    def __rfloordiv__(self, left):        print(type(left))    def __rmod__(self, left):        print(type(left))    def __radd__(self, left):        print(type(left))    def __rsub__(self, left):        print(type(left))print('ndarray:\n\n')M = np.eye(2)thing = MyClass()print('Multiply:')result = M * thingprint('\nAdd:')result = M + thingprint('\nSub:')result = M - thingprint('\nTruediv:')result = M // thingprint('\nModulo:')result = M % thingprint('\n\nmatrix:\n\n')M = np.matrix(np.eye(2))thing = MyClass()print('Multiply:')result = M * thingprint('\nAdd:')result = M + thingprint('\nSub:')result = M - thingprint('\nTruediv:')result = M // thingprint('\nModulo:')result = M % thing```### Error message:```shellndarray:Multiply:<class 'float'><class 'float'><class 'float'><class 'float'>Add:<class 'float'><class 'float'><class 'float'><class 'float'>Sub:<class 'float'><class 'float'><class 'float'><class 'float'>Truediv:<class 'float'><class 'float'><class 'float'><class 'float'>Modulo:<class 'float'><class 'float'><class 'float'><class 'float'>matrix:Multiply:<class 'numpy.matrix'>Add:<class 'float'><class 'float'><class 'float'><class 'float'>Sub:<class 'float'><class 'float'><class 'float'><class 'float'>Truediv:<class 'float'><class 'float'><class 'float'><class 'float'>Modulo:<class 'float'><class 'float'><class 'float'><class 'float'>```### NumPy/Python version information:1.20.1 3.9.4 (default, Apr  9 2021, 09:32:38) [Clang 10.0.0 ]
"
21179,1,910,2,0,0,HoangTienDuc,0,"title:BUG: Segmentation fault (core dumped) description:### Describe the issue:闂?Hardware Platform GPU RTX 2080ti闂?DeepStream Version 6.0 [triton](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/deepstream)闂?Python Version: 3.6.15Successful to install NumPy (1.19.5, 1.19.4, 1.19.3, 1.19.2) on Deepstream triton 6.0. However, these NumPy versions are still the cause of the code dumps.Alternatively, I also tried python3-numpy, but it still doesn闂傚倸鍊搁崐鎼佸磹閹间礁纾归柣鎴ｅГ閸ゅ嫰鏌涢锝嗙缁炬儳顭烽弻鏇熺箾閻愵剚鐝旂紒鐐劤濞硷繝寮婚敍鍕勃閻犲洦褰冩慨鏇㈡⒑?work.Hope to get help! Thanks### Reproduce the code example:```pythonn_frame = pyds.get_nvds_buf_surface(hash(gst_buffer), frame_meta.batch_id)frame_copy = np.array(n_frame, copy=True, order='C')rgb_frame = cv2.cvtColor(frame_copy, cv2.COLOR_RGBA2RGB)```### Error message:```shellI0311 07:45:17.484594 10848 plan_backend.cc:859] Created instance detector_0_0_gpu0 on GPU 0 with stream priority 0 and optimization profile default[0];I0311 07:45:17.484653 10848 model_repository_manager.cc:1212] successfully loaded 'detector' version 1INFO: infer_trtis_backend.cpp:206 TrtISBackend id:1 initialized model: detectorDecodebin child added: source Now playing...Starting pipeline Decodebin child added: decodebin0 Decodebin child added: rtph264depay0 Decodebin child added: h264parse0 Decodebin child added: capsfilter0 Decodebin child added: nvv4l2decoder0 In cb_newpadgstname= video/x-rawDecodebin linked to pipelineSegmentation fault (core dumped)```### NumPy/Python version information:1.19.5, 1.19.4, 1.19.3, 1.19.2, python3-numpy
"
21173,1,549,26,0,1,LogWell,0,"title:incomplete path with np.loadtxt description:### Describe the issue:[Link](https://rec.ustc.edu.cn/share/672bbc20-9f48-11ec-8fa4-af76c0d5e041) to test file.When I use `np.loadtxt` to read the path file, some paths lack suffix, that is, the original `*.png` may be read as `*.p` or `*.pn`.When I take out the problematic line to generate a new file, it can be read normally again.### Reproduce the code example:```pythonimport osimport numpy as npfrom glob import globpath_data_patch_train = ""path_data_patch_train.txt""data_patch_train = np.loadtxt(path_data_patch_train, dtype=str)for idx, item in enumerate(data_patch_train):    if idx < 50000 or idx > 70000:        continue    for it in item:        # it = glob(it + ""*"")[0]        if not os.path.exists(it):            print(idx, it)            exit()``````### Error message:```shell59580 /media/lab0/SSD2TS1/NaGenHao/Datasets/dataset@h3d/POSED/GobotreePeople/hdqjd__M1/gtp_cwman_spg_13_andrea_cpl_wk_pntg_adl_ccs_mgr/bRendered_IGLOM/Z000/data_v4/for_network/img_nC_00000.pn```### NumPy/Python version information:1.19.2 3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]
"
21169,0,0,275,0,0,charris,0,"title:BUG: ``test_partial_iteration_cleanup`` is failing for wheel builds description:See [here](https://dev.azure.com/numpy/numpy/_build/results?buildId=23137&view=results).Not sure what changed to cause this, seems about two weeks old.
"
21166,0,63,0,0,0,Slagt,0,"title:BUG: Conversion of numpy.nan to int gives inconsistent results description:### Describe the issue:When converting a numpy array containing `numpy.nan` to type `int`, the `numpy.nan` are replaced by either `-9223372036854775808` or `0` depending on the computer.`numpy.nan` is replaced by `-9223372036854775808` on a Mac Pro (2019).`numpy.nan` is replaced by `0` on a MacBook Air (M1, 2020).Computers have the same version of macOS (12.2.1), Python (3.9.10) and numpy (1.22.2).### Expected outputBoth computers should behave the same. Either throw an error, or return the same value.### Reproduce the code example:```pythonimport numpyprint(numpy.array(numpy.nan).astype(int))```### Error message:_No response_### NumPy/Python version information:1.22.2 3.9.10 (main, Jan 15 2022, 11:40:53)[Clang 13.0.0 (clang-1300.0.29.3)]
"
21158,1,1599,132,0,0,Vinc0110,0,"title:BUG: linalg.qr became slower description:### Describe the issue:After upgrading to numpy v1.22.2, I noticed a significant increase (about +25%) in the runtime of `linalg.qr` compared to my old installation with v1.19.5.With the attached script, I ran linalg.qr() for 100 times on some random data and measured the average runtime with different package versions of NumPy in a Conda environment. Before v1.22.0 it consistently took less than 200 ms, with v1.22.0 and v1.22.2 it took about 250 ms.### Reproduce the code example:```pythonimport sysimport numpy as npfrom timeit import default_timer as timera = np.random.randn(10000, 600)n = 100t = np.empty(n)for i in range(n):    t_start = timer()    r = np.linalg.qr(a, mode='r')    t_stop = timer()    t[i] = t_stop - t_start#print('Python: {}'.format(sys.version))print('NumPy: {}'.format(np.__version__))print('QR took {:.3f} +- {:.3f} ms'.format(np.average(t) * 1e3, np.std(t) * 1e3))```### Error message:```shellpip install numpy==1.19.5Collecting numpy==1.19.5  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)NumPy: 1.19.5QR took 196.591 +- 3.452 mspip install numpy==1.20.0Collecting numpy==1.20.0  Downloading numpy-1.20.0-cp38-cp38-manylinux2010_x86_64.whl (15.4 MB)NumPy: 1.20.0QR took 196.010 +- 2.053 mspip install numpy==1.21.0Collecting numpy==1.21.0  Downloading numpy-1.21.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)NumPy: 1.21.0QR took 195.991 +- 7.306 mspip install numpy==1.21.5Collecting numpy==1.21.5  Using cached numpy-1.21.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)NumPy: 1.21.5QR took 197.896 +- 5.365 mspip install numpy==1.22.0Collecting numpy==1.22.0  Using cached numpy-1.22.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)NumPy: 1.22.0QR took 251.281 +- 7.309 mspip install numpy==1.22.2Collecting numpy==1.22.2  Using cached numpy-1.22.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)NumPy: 1.22.2QR took 252.205 +- 5.289 ms```### NumPy/Python version information:Ubuntu 20.04.4 LTSIntel(R) Core(TM) i7-4770 CPU @ 3.40GHzsys.version: `'3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]'`conda: 4.11.0
"
21148,0,0,275,0,1,charris,0,"title:BUG,ENH: np._from_dlpack: export arrays with any strided size-1 dimensions description:Backport of #21132.fixes gh-20336Export arrays with any strides in the dimension of size 1.cc @seberg<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      http://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      http://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      http://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21146,0,0,284,0,1,mattip,0,"title:BUG: assign all tuple items before using it for PyPy description:Fixes a bug introduced in #19346. When creating a tuple, all items must be assigned before calling any C-API functions that use the tuple. This PR rearranges the code to conform to that. It should allow #21131 and #21125 to pass CI.The failing test is in the full test suite, which requires over 60 minutes to run on PyPy.
"
21141,0,0,275,0,1,charris,0,"title:BUG: use ThreadPoolExecutor instead of ThreadPool description:Backport of #21027.Use concurrent.futures.ThreadPoolExecutor in distutils instead of multiprocessing.pool.ThreadPool.Fix #21026
"
21140,0,0,275,0,1,charris,0,"title:BUG: Fix unpickling an empty ndarray with a non-zero dimension (#21067) description:Backport of #21067.Changing num to the number of bytes in the input array, PyArray_NBYTES(self). Solves #21009.* Fixing nbyte size in methods.c:memcpy* Adding a test* Re-adding removed newline* Shrinking the test array to save memory<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      http://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      http://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      http://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21139,0,0,275,0,1,charris,0,"title:BUG: Fix numba DUFuncs added loops getting picked up description:Backport of #21113.It was always my intention to do this: If no loop is found and wego into the legacy ufunc path and legacy resolving works, we needto double check that the ufunc was not mutated.Normal operation never mutates ufuncs (its really not meant to be)but numbas DUFuncs need to do it (they compile loops dynamically).The future is much brighter for them in this regard, but right nowthey have to keep working.Closes gh-20735<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      http://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      http://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      http://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21138,0,326,275,1,1,charris,0,"title:BUG, ENH: np._from_dlpack: export correct device information description:Backport of #21119.fixes gh-20340It is possible to export incorrect device information if a new view has been created from an imported array:```pythonimport numpy as npfrom torchx = torch.arange(10).pin_memory()y = np._from_dlpack(x)y.base  # PyCapsule named 'numpy_dltensor' (contains device information)z = y[::2]z.base  # y (doesn't contain original device information)z.__dlpack_device__()  # (1, 0) --> wrong (should be (3, 0) for pinned memory)```This PR fixes this behavior by walking the bases (if they are ndarray) as suggested in https://github.com/numpy/numpy/issues/20340#issuecomment-1000861064. The test just coves the new changes but doesn't really test against an array from a different device.cc @seberg @mattip<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      http://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      http://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      http://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21134,1,134,8,0,0,code-yuan-shi,0,"title:BUG: numpy.arange() function return unexpected results description:### Describe the issue:Examples are as follows:``np.arange(0,1.12,0.04)will return``array([0.  , 0.04, 0.08, 0.12, 0.16, 0.2 , 0.24, 0.28, 0.32, 0.36, 0.4 ,       0.44, 0.48, 0.52, 0.56, 0.6 , 0.64, 0.68, 0.72, 0.76, 0.8 , 0.84,       0.88, 0.92, 0.96, 1.  , 1.04, 1.08, 1.12])but``np.arange(0,1.18,0.04)return ``array([0.  , 0.04, 0.08, 0.12, 0.16, 0.2 , 0.24, 0.28, 0.32, 0.36, 0.4 ,       0.44, 0.48, 0.52, 0.56, 0.6 , 0.64, 0.68, 0.72, 0.76, 0.8 , 0.84,       0.88, 0.92, 0.96, 1.  , 1.04])### Reproduce the code example:```pythonimport numpy as np# One open interval, one closed intervalprint(np.arange(0,1.12,0.04))print(np.arange(0,1.08,0.04))```### Error message:_No response_### NumPy/Python version information:1.22.2 3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]
"
21132,0,0,88,0,1,tirthasheshpatel,0,"title:BUG,ENH: np._from_dlpack: export arrays with any-strided size-1 dimen闂?,fixes gh-20336Export arrays with any strides in the dimension of size 1.cc @seberg description:"
21117,1,0,199,0,1,saran-t,0,"title:BUG: Fix unaligned memory access in `npy_memchr`. description:Fixes #21116<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      http://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      http://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      http://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->
"
21116,0,773,199,0,0,saran-t,0,"title:BUG: `npy_memchr` has misaligned memory access description:### Describe the issue:The function `npy_memchr` (in `multiarray/common.h`) has an optimisation for the case `!NPY_ALIGNMENT_REQUIRED && needle == 0 && stride == 1` where it start by find the first nonzero 4-byte block before iterating within the block. However, the coarse-grained loop begins at `haystack` itself, and since the stride is 1 there's no expectation that this pointer would have any particular alignment.While this is benign on x86_64, the misaligned access is nevertheless picked up by UBsan as it is undefined behaviour according to the C standard. `npy_memchr` should first scan each byte until it reaches the first 4-byte aligned block before entering the coarse-grained loop.### How to reproduce:Build NumPy with UBsan and run a test suite containing a sufficiently large number of `np.testing.assert_` calls. Since `func_assert_same_pos` constructs a boolean mask that is used to index into the arrays under test, with enough calls there's a decent chance that it will end up creating an unaligned boolean array at least once.### Error message:```shellthird_party/py/numpy/core/src/multiarray/common.h:277:35: runtime error: load of misaligned address 0x... for type 'unsigned int', which requires 4 byte alignment0x615000673205: note: pointer points here 01 01 01 01 01 01 01  01 01 01 01 01 01 01 01               ^     #0 0x... in npy_memchr third_party/py/numpy/core/src/multiarray/common.h:277:35    #1 0x... in array_boolean_subscript third_party/py/numpy/core/src/multiarray/mapping.c:1113:30    #2 0x... in array_subscript third_party/py/numpy/core/src/multiarray/mapping.c:1572:30    #3 0x... in PyObject_GetItem third_party/python_runtime/v3_7/Objects/abstract.c:182:26...SUMMARY: UndefinedBehaviorSanitizer: misaligned-pointer-use third_party/py/numpy/core/src/multiarray/common.h:277:35```### NumPy/Python version information:Bug exists at HEAD.
"
21113,0,0,292,0,1,seberg,0,"title:BUG: Fix numba DUFuncs added loops getting picked up description:It was always my intention to do this: If no loop is found and wego into the legacy ufunc path and legacy resolving works, we needto double check that the ufunc was not mutated.Normal operation never mutates ufuncs (its really not meant to be)but numbas DUFuncs need to do it (they compile loops dynamically).The future is much brighter for them in this regard, but right nowthey have to keep working.Closes gh-20735
"
21112,1,75,0,0,0,Ruws99,0,"title:BUG: long integer modulus bug description:### Describe the issue:When using np.floor_divide() on long integers the results are sometimes wrong.### Reproduce the code example:```pythonimport numpy as npprint(np.mod(10888869450418352160,10))>>8.0```### Error message:_No response_### NumPy/Python version information:numpy version 1.22.2
"
21105,1,311,12,0,0,vmagno,0,"title:BUG: log1p output has less precision for the real part of small complex inputs description:### Describe the issue:The real part of the output of numpy.log1p is rounded down to zero when the real part of a complex input is less than about 1e-15. This does not occur for the imaginary part of a complex input/output, or when the input is real.For example:```>>> import numpy as np>>> np.log1p(1e-14 + 1e-14j)(9.992007221626358e-15+9.9999999999999e-15j)>>> np.log1p(1e-16 + 1e-16j)1e-16j>>> np.log1p(1e-16)1e-16>>> np.log1p(1e-16j)1e-16j```This occurs on Linux with numpy version 1.22.2, and python version 3.10.2### Reproduce the code example:```pythonimport numpy as npnp.log1p(1e-14 + 1e-14j)np.log1p(1e-16 + 1e-16j)np.log1p(1e-16)np.log1p(1e-16j)```### Error message:_No response_### NumPy/Python version information:1.22.2 3.10.2 (main, Jan 15 2022, 19:56:27) [GCC 11.1.0]
"
21083,0,490,298,0,0,asmeurer,0,"title:BUG: ""Non-standard"" vector-norms of 1-D arrays in norm() always return float64 dtype description:### Describe the issue:The ""non-standard"" norms in `norm()`, i.e., `ord < 0` or `ord > 2` on a 1-d array (so it's a vector norm and not a matrix norm), incorrectly promote the result to float64 regardless of the input dtype. This is because the code just manually implements it with```pyabsx = abs(x)absx **= ordret = add.reduce(absx, axis=axis, keepdims=keepdims)ret **= (1 / ord)return ret```at https://github.com/numpy/numpy/blob/1168868df63678e5704acd866fafcf40dc849481/numpy/linalg/linalg.py#L2559.Specifically, the last line `ret **= (1 / ord)` promotes the result to float64 because `ret` is a scalar and `1/ord` is a Python float. ### Reproduce the code example:```python>>> np.linalg.norm(np.asarray([1., 2.], dtype=np.float32), ord=-1).dtypedtype('float64')>>> np.linalg.norm(np.asarray([1., 2.], dtype=np.float16), ord=-1).dtypedtype('float64')>>> np.linalg.norm(np.asarray([1., 2.], dtype=np.float32), ord=1).dtypedtype('float32')>>> np.linalg.norm(np.asarray([1., 2.], dtype=np.float16), ord=1).dtypedtype('float16')```### Error message:_No response_### NumPy/Python version information:>>> np.__version__'1.23.0.dev0+782.g1168868df6'
"
21080,1,11425,87,0,0,meow464,0,"title:BUG: Can't build on MacOS Monoterey description:### Describe the issue:I can't build numpy on macos 12.Information that might be relevant:1. I'm using a venv;2. `export SDKROOT=""/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk""`;3. `CFLAGS="" -v""`4. `export MACOSX_DEPLOYMENT_TARGET=12_0`;5. I'm using a custom openblas built for x86_64 only;6. This is my site.cfg:```[openblas]libraries = openblaslibrary_dirs = /Users/tuco/Projects/OpenBLAS/macOS/install/libinclude_dirs = /Users/tuco/Projects/OpenBLAS/macOS/install/include```### Reproduce the code example:```pythongit clone https://github.com/numpy/numpy.gitcd numpy && pip install .```### Error message:Long error```shellProcessing /Users/tuco/Projects/numpy/macOS/numpy  Installing build dependencies: started  Installing build dependencies: finished with status 'done'  Getting requirements to build wheel: started  Getting requirements to build wheel: finished with status 'done'  Preparing metadata (pyproject.toml): started  Preparing metadata (pyproject.toml): finished with status 'done'Building wheels for collected packages: numpy  Building wheel for numpy (pyproject.toml): started  Building wheel for numpy (pyproject.toml): finished with status 'error'  error: subprocess-exited-with-error    闂?Building wheel for numpy (pyproject.toml) did not run successfully.  闂?exit code: 1  闂傚倸鍊搁崐鎼佸磹閹间礁纾瑰瀣捣閻棗霉閿濆懏鎯堟い銉︾閵囧嫰骞橀崡鐐典患缂佺偓鍎冲锟犲蓟閺囥垹閱囨繝闈涙祩濡倝姊虹紒妯肩畵闁绘牕銈搁獮鍐ㄎ旈崨顔芥珳闁硅偐琛ラ崜婵嬫倶閸垻纾? [125 lines of output]      Processing numpy/random/_bounded_integers.pxd.in      Processing numpy/random/_philox.pyx      Processing numpy/random/_bounded_integers.pyx.in      Processing numpy/random/_sfc64.pyx      Processing numpy/random/_mt19937.pyx      Processing numpy/random/bit_generator.pyx      Processing numpy/random/mtrand.pyx      Processing numpy/random/_generator.pyx      Processing numpy/random/_pcg64.pyx      Processing numpy/random/_common.pyx      Cythonizing sources      INFO: blas_opt_info:      INFO: blas_armpl_info:      INFO: customize UnixCCompiler      INFO:   libraries armpl_lp64_mp not found in ['/Users/tuco/Projects/numpy/macOS/venv/lib', '/usr/local/lib', '/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: blas_mkl_info:      INFO:   libraries mkl_rt not found in ['/Users/tuco/Projects/numpy/macOS/venv/lib', '/usr/local/lib', '/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: blis_info:      INFO:   libraries blis not found in ['/Users/tuco/Projects/numpy/macOS/venv/lib', '/usr/local/lib', '/usr/lib']      INFO:   NOT AVAILABLE      INFO:      INFO: openblas_info:      INFO: C compiler: clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -iwithsysroot/System/Library/Frameworks/System.framework/PrivateHeaders -iwithsysroot/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/Headers -arch arm64 -arch x86_64 -Werror=implicit-function-declaration -v            creating /var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf/var      creating /var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf/var/folders      creating /var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf/var/folders/6p      creating /var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf/var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn      creating /var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf/var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T      creating /var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf/var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf      INFO: compile options: '-c'      INFO: clang: /var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf/source.c      Apple clang version 13.0.0 (clang-1300.0.29.30)      Target: x86_64-apple-darwin21.3.0      Thread model: posix      InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin      clang: error: invalid version number in 'MACOSX_DEPLOYMENT_TARGET=12_0'      clang: error: invalid version number in 'MACOSX_DEPLOYMENT_TARGET=12_0'      Running from numpy source directory.      setup.py:86: DeprecationWarning:              `numpy.distutils` is deprecated since NumPy 1.23.0, as a result        of the deprecation of `distutils` itself. It will be removed for        Python >= 3.12. For older Python versions it will remain present.        It is recommended to use `setuptools < 60.0` for those Python versions.        For more details, see: TODO!                    import numpy.distutils.command.sdist      numpy/core/setup.py:440: MismatchCAPIWarning: API mismatch detected, the C API version numbers have to be updated. Current C api version is 15, with checksum 04a7bf1e65350926a0e528798da263c0, but recorded checksum for C API version 15 in core/codegen_dir/cversions.txt is b8783365b873681cd204be50cdfb448d. If functions were added in the C API, you have to update C_API_VERSION in numpy/core/setup_common.py.        check_api_version(C_API_VERSION, codegen_dir)      Traceback (most recent call last):        File ""/Users/tuco/Projects/numpy/macOS/venv/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py"", line 363, in <module>          main()        File ""/Users/tuco/Projects/numpy/macOS/venv/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py"", line 345, in main          json_out['return_val'] = hook(**hook_input['kwargs'])        File ""/Users/tuco/Projects/numpy/macOS/venv/lib/python3.8/site-packages/pip/_vendor/pep517/in_process/_in_process.py"", line 261, in build_wheel          return _build_backend().build_wheel(wheel_directory, config_settings,        File ""/private/var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/pip-build-env-pzxib59z/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 230, in build_wheel          return self._build_with_temp_dir(['bdist_wheel'], '.whl',        File ""/private/var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/pip-build-env-pzxib59z/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 215, in _build_with_temp_dir          self.run_setup()        File ""/private/var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/pip-build-env-pzxib59z/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 267, in run_setup          super(_BuildMetaLegacyBackend,        File ""/private/var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/pip-build-env-pzxib59z/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 158, in run_setup          exec(compile(code, __file__, 'exec'), locals())        File ""setup.py"", line 492, in <module>          setup_package()        File ""setup.py"", line 484, in setup_package          setup(**metadata)        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/core.py"", line 135, in setup          config = configuration()        File ""setup.py"", line 136, in configuration          config.add_subpackage('numpy')        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/misc_util.py"", line 1054, in add_subpackage          config_list = self.get_subpackage(subpackage_name, subpackage_path,        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/misc_util.py"", line 1020, in get_subpackage          config = self._get_configuration_from_setup_py(        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/misc_util.py"", line 962, in _get_configuration_from_setup_py          config = setup_module.configuration(*args)        File ""numpy/setup.py"", line 9, in configuration          config.add_subpackage('core')        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/misc_util.py"", line 1054, in add_subpackage          config_list = self.get_subpackage(subpackage_name, subpackage_path,        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/misc_util.py"", line 1020, in get_subpackage          config = self._get_configuration_from_setup_py(        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/misc_util.py"", line 962, in _get_configuration_from_setup_py          config = setup_module.configuration(*args)        File ""numpy/core/setup.py"", line 812, in configuration          blas_info = get_info('blas_opt', 0)        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/system_info.py"", line 585, in get_info          return cl().get_info(notfound_action)        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/system_info.py"", line 845, in get_info          self.calc_info()        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/system_info.py"", line 2077, in calc_info          if self._calc_info(blas):        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/system_info.py"", line 2063, in _calc_info          return getattr(self, '_calc_info_{}'.format(name))()        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/system_info.py"", line 2000, in _calc_info_openblas          info = get_info('openblas')        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/system_info.py"", line 585, in get_info          return cl().get_info(notfound_action)        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/system_info.py"", line 845, in get_info          self.calc_info()        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/system_info.py"", line 2283, in calc_info          info = self._calc_info()        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/system_info.py"", line 2271, in _calc_info          if not (skip_symbol_check or self.check_symbols(info)):        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/system_info.py"", line 2350, in check_symbols          obj = c.compile([src], output_dir=tmpdir)        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/ccompiler.py"", line 89, in <lambda>          m = lambda self, *args, **kw: func(self, *args, **kw)        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/ccompiler.py"", line 364, in CCompiler_compile          single_compile(o)        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/ccompiler.py"", line 325, in single_compile          self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/ccompiler.py"", line 89, in <lambda>          m = lambda self, *args, **kw: func(self, *args, **kw)        File ""/Users/tuco/Projects/numpy/macOS/numpy/numpy/distutils/unixccompiler.py"", line 58, in UnixCCompiler__compile          raise CompileError(msg) from None      distutils.errors.CompileError: Command ""clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -iwithsysroot/System/Library/Frameworks/System.framework/PrivateHeaders -iwithsysroot/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/Headers -arch arm64 -arch x86_64 -Werror=implicit-function-declaration -v -c /var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf/source.c -o /var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf/var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf/source.o -MMD -MF /var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf/var/folders/6p/3b9nf01x021bf5qxf_0pq1qr0000gn/T/tmpt17u5yrf/source.o.d"" failed with exit status 1      [end of output]    note: This error originates from a subprocess, and is likely not a problem with pip.  ERROR: Failed building wheel for numpyFailed to build numpyERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects```</details>### NumPy/Python version information:Python 3.8.9Numpy master and at least v1.20.2 (this is the version I'm interested in)
"
21079,1,2221,154,0,0,arogozhnikov,0,"title:BUG: numpy.distutils.__config__.blas_opt_info is not set in the latest versions of numpy description:### Describe the issue:In CI my package that relies on theano fails specifically for python3.9 but not3.7(I am aware theano is not supported, but it seems to me that issue in numpy)Specifically, blas_opt_info is not set in its config, but source code still recommends using it.### Reproduce the code example:```pythondocker run -it --rm python:3.9-buster bashpip install numpy# Collecting numpy#   Downloading numpy-1.22.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)from numpy.distutils import __config__>>> __config__.__config__.blas_ilp64_opt_info      __config__.lapack_ilp64_opt_info    __config__.os__config__.extra_dll_dir            __config__.openblas64__info         __config__.show(__config__.get_info(                __config__.openblas64__lapack_info  __config__.sys```So config has blas_ilp64_opt_info, but not blas_opt_info, which I assume should contain the same info.### Error message:```shellFile ""/home/runner/work/hep_ml/hep_ml/tests/test_nnet.py"", line 14, in <module>    from hep_ml import nnet  File ""/home/runner/work/hep_ml/hep_ml/hep_ml/nnet.py"", line 129, in <module>    import theano  File ""/opt/hostedtoolcache/Python/3.9.10/x64/lib/python3.9/site-packages/theano/__init__.py"", line 124, in <module>    from theano.scan_module import (scan, map, reduce, foldl, foldr, clone,  File ""/opt/hostedtoolcache/Python/3.9.10/x64/lib/python3.9/site-packages/theano/scan_module/__init__.py"", line 41, in <module>    from theano.scan_module import scan_opt  File ""/opt/hostedtoolcache/Python/3.9.10/x64/lib/python3.9/site-packages/theano/scan_module/scan_opt.py"", line 60, in <module>    from theano import tensor, scalar  File ""/opt/hostedtoolcache/Python/3.9.10/x64/lib/python3.9/site-packages/theano/tensor/__init__.py"", line 17, in <module>    from theano.tensor import blas  File ""/opt/hostedtoolcache/Python/3.9.10/x64/lib/python3.9/site-packages/theano/tensor/blas.py"", line 155, in <module>    from theano.tensor.blas_headers import blas_header_text  File ""/opt/hostedtoolcache/Python/3.9.10/x64/lib/python3.9/site-packages/theano/tensor/blas_headers.py"", line 987, in <module>    if not config.blas.ldflags:  File ""/opt/hostedtoolcache/Python/3.9.10/x64/lib/python3.9/site-packages/theano/configparser.py"", line 332, in __get__    val_str = self.default()  File ""/opt/hostedtoolcache/Python/3.9.10/x64/lib/python3.9/site-packages/theano/configdefaults.py"", line 1284, in default_blas_ldflags    blas_info = np.distutils.__config__.blas_opt_infoAttributeError: module 'numpy.distutils.__config__' has no attribute 'blas_opt_info'```refer to CI job if more details are needed https://github.com/arogozhnikov/hep_ml/runs/5234020677?check_suite_focus=true### NumPy/Python version information:```numpy==1.22```Seems to be more dependent on python version, as in python 3.7 no failure observed, but 3.9 fails.
"
21075,1,1108,0,0,0,battulgag,0,"title:BUG: Numply build error on CentOS 7 description:### Describe the issue:Building error on CentOS 7```scl enable devtoolset-11 bashenv OPENBLAS=%{_libdir} BLAS=%{_libdir} LAPACK=%{_libdir} CFLAGS=""-std=c++11"" /opt/python/bin/python3.8 setup.py build --fcompiler=gnu95 -j 8numpy/core/src/npysort/binsearch.cpp:293:52: **error**: array must be initialized with a brace-enclosed initializer             (function_type)&npy_argbinsearch<right>};                                                    ^numpy/core/src/npysort/binsearch.cpp:293:52: **erro**r: too many initializers for 'const std::array<int (*)(const char*, const char*, const char*, char*, long int, long int, long int, long int, long int, long int, tagPyArrayObject*), 2ul>'numpy/core/src/npysort/binsearch.cpp:316:49: error: array must be initialized with a brace-enclosed initializer             (function_type)&npy_binsearch<right>};                                                 ^numpy/core/src/npysort/binsearch.cpp:316:49: **error**: too many initializers for 'const std::array<void (*)(const char*, const char*, char*, long int, long int, long int, long int, long int, tagPyArrayObject*), 2ul>'```### Reproduce the code example:```pythonbuilding error```### Error message:_No response_### NumPy/Python version information:numply 1.22.2
"
21074,0,0,139,1,0,BvB93,0,"title:BUG: Replace ``ssize_t`` with ``size_t`` in tokenize.cpp description:Closes https://github.com/numpy/numpy/issues/21073`ssize_t` is not defined for all platforms in C++ (_e.g._ windows), so replace it with `ptrdiff_t`.
"
21073,0,939,139,0,0,BvB93,0,"title:BUG: Failure to build on windows: `'ssize_t': undeclared identifier` description:Ever since the merging of https://github.com/numpy/numpy/pull/21025 I've been unable to locally build from the `main` branch when using windows.The full build log is attached below, but it seems `ssize_t` is currently not defined in tokenize.cpp:``` numpy\core\src\multiarray\textreading\tokenize.cpp(392): error C2065: 'ssize_t': undeclared identifiernumpy\core\src\multiarray\textreading\tokenize.cpp(392): error C2146: syntax error: missing ';' before identifier 'offset_last'numpy\core\src\multiarray\textreading\tokenize.cpp(392): error C2065: 'offset_last': undeclared identifiernumpy\core\src\multiarray\textreading\tokenize.cpp(393): error C2065: 'ssize_t': undeclared identifiernumpy\core\src\multiarray\textreading\tokenize.cpp(393): error C2146: syntax error: missing ';' before identifier 'end_last'numpy\core\src\multiarray\textreading\tokenize.cpp(393): error C2065: 'end_last': undeclared identifiernumpy\core\src\multiarray\textreading\tokenize.cpp(394): error C2065: 'end_last': undeclared identifiernumpy\core\src\multiarray\textreading\tokenize.cpp(394): error C2065: 'offset_last': undeclared identifier```Reproduce the code example:------------------------------``` shellgit clean -xfdpython setup.py build```Error message:---------------* Full build log: [build_log.txt](https://github.com/numpy/numpy/files/8081332/build_log.txt)NumPy/Python version information:-------------------------------------* Numpy version: `main` branch (post-https://github.com/numpy/numpy/commit/67bb936e8d8bc29c1dc4e54449a173280d43b9dd).* Python version: `3.10.2 | packaged by conda-forge | (main, Feb  1 2022, 19:27:13) [MSC v.1929 64 bit (AMD64)]`
"
21072,1,565,0,0,0,OulanB,0,"title:BUG: Erronous RuntimeWarning description:I compiled a local version of python 3.10 on a manjaro distrib on a lenovo ideapad 5 14alc05 (ryzen 5500U)Python 3.10.2 (main, Feb 15 2022, 13:42:14) [GCC 11.1.0] on linuxI build an openblas 0.3.19 in /usr/local, which give : lrwxrwxrwx  1 root root       27 16 f闂傚倸鍊搁崐鎼佸磹瀹勬噴褰掑炊椤掆偓绾惧鏌熼悧鍫熺凡闁稿被鍔庨幉绋款吋婢跺浠奸梺姹囧灮椤牓鎮? 15:35 libopenblas.so.0 -> libopenblas_zenp-r0.3.19.so-rw-r--r--  1 root root 29584842 16 f闂傚倸鍊搁崐鎼佸磹瀹勬噴褰掑炊椤掆偓绾惧鏌熼悧鍫熺凡闁稿被鍔庨幉绋款吋婢跺浠奸梺姹囧灮椤牓鎮? 14:57 libopenblas_zenp-r0.3.19.a-rwxr-xr-x  1 root root 14386232 16 f闂傚倸鍊搁崐鎼佸磹瀹勬噴褰掑炊椤掆偓绾惧鏌熼悧鍫熺凡闁稿被鍔庨幉绋款吋婢跺浠奸梺姹囧灮椤牓鎮? 14:57 libopenblas_zenp-r0.3.19.so---- in /usr/local/liball tests passed okNow I build numpy 1.22.2 with the following site.cfg[openblas]libraries = openblaslibrary_dirs = /usr/local/libinclude_dirs = /usr/local/includeruntime_library_dirs = /usr/local/libmany tests failed due to warning such as RuntimeWarning: divide by zero encountered in true_dividewith valid arguments.A small program exhibit the behavior, see the example : at 'step=delta/div' 2 warning are emitted.The same program with the local python3.8 and assorted numpy from manjaro does not exhibit the problem.This is certainly due to a problem with the fpu status flags from AVX extension for a zen 2 processor.Is the bug in numpy or openblas ... ???As seen in file included, my version of python/numpy use the same blas/lapack as the manjaro one so the bug shouldnot be in openblas.Anyway this is very annoying.[bug.txt](https://github.com/numpy/numpy/files/8081297/bug.txt)### Reproduce the code example:```pythonimport numpy as npnp.show_config()delta = np.array([ 4.        +0.j        , -1.20411998+0.j        ,        1.20411998+0.j        ,  1.90848502+0.j        ,        4.        +0.j        ,  0.        -1.36437635j])div=4step=delta/divprint(delta)print(div)print(step)```### Error message:```shell/home/olivier/test.py:11: RuntimeWarning: divide by zero encountered in true_divide  step=delta/div/home/olivier/test.py:11: RuntimeWarning: invalid value encountered in true_divide  step=delta/diverronous warning emittedmore infos in included file```### NumPy/Python version information:1.22.2 3.10.2 (main, Feb 15 2022, 13:42:14) [GCC 11.1.0]Upto date Manjaro linux on an ideapad 5 14alc05 (ryzen 5 5500U)
"
21071,0,0,285,0,1,pentschev,0,"title:BUG: Ensure equality/identity comparison with `__array_function__` description:Special-casing is needed to ensure the correct public API is passed to `__array_function__` when `like=` kwarg is present.Fixes #21033 .
"
21067,0,0,109,0,1,alexdesiqueira,0,"title:BUG: Fix unpickling an empty ndarray with a non-zero dimension description:<!--         ----------------------------------------------------------------                MAKE SURE YOUR PR GETS THE ATTENTION IT DESERVES!                ----------------------------------------------------------------*  FORMAT IT RIGHT:      http://www.numpy.org/devdocs/dev/development_workflow.html#writing-the-commit-message*  IF IT'S A NEW FEATURE OR API CHANGE, TEST THE WATERS:      http://www.numpy.org/devdocs/dev/development_workflow.html#get-the-mailing-list-s-opinion*  HIT ALL THE GUIDELINES:      https://numpy.org/devdocs/dev/index.html#guidelines*  WHAT TO DO IF WE HAVEN'T GOTTEN BACK TO YOU:      http://www.numpy.org/devdocs/dev/development_workflow.html#getting-your-pr-reviewed-->Changing `num` to the number of bytes in the input array, `PyArray_NBYTES(self)`. Solves #21009.
"
21066,0,51,296,0,0,justvanrossum,0,"title:macos wheels don't work on macos < 10.14 description:### Describe the issue:As of numpy 1.22.2, the macos wheels require macos 10.14 or later. 1.22.1 provides wheels that work back to 10.9. Is this a conscious decision? It seems a bit odd for a micro version bump to change os requirements so drastically.### Reproduce the code example:```python`pip install numpy` fails on macos 10.13.```### Error message:_No response_### NumPy/Python version information:1.22.2
"
