num,label,code_len,con_num,keyword_num,keyword_fix,username,permission,ds
44647,1,2982,20,0,0,sprootik,0,"title:Strange problem with docker. description:### DescriptionAt the request of @thaJeztah  I create a topic in continuation of topic https://github.com/docker/desktop-linux/issues/107Watching weird docker work.### Reproduce```闂?docker run -it --rm --name test alpine:latestsh-5.1# printenvHOSTNAME=129487e4b428PWD=/HOME=/rootTERM=xtermSHLVL=1PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin_=/usr/sbin/printenvsh-5.1# sh-5.1# apk -Vsh: apk: command not foundsh-5.1# ls -l /sbin | grep apksh-5.1# ``````闂?docker run -it --rm --name test nginx:stable-alpinedocker: Error response from daemon: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: exec: ""/docker-entrypoint.sh"": stat /docker-entrypoint.sh: no such file or directory: unknown.```### Expected behavior```[dan@dan-laptop ~]$ docker run -it --rm --name test alpine:latest/ # printenvHOSTNAME=85c390c50e03SHLVL=1HOME=/rootTERM=xtermPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binPWD=// # apk -Vapk-tools 2.12.10, compiled for x86_64./ #```### docker version```bash闂?docker versionClient: Version:           20.10.21 API version:       1.41 Go version:        go1.19.2 Git commit:        baeda1f82a Built:             Thu Oct 27 21:30:31 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          20.10.21  API version:      1.41 (minimum version 1.12)  Go version:       go1.19.2  Git commit:       3056208812  Built:            Thu Oct 27 21:29:34 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.6.10  GitCommit:        770bd0108c32f3fb5c73ae1264f7e503fe7b2661.m runc:  Version:          1.1.4  GitCommit:         docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bash闂?docker infoClient: Context:    default Debug Mode: false Plugins:  compose: Docker Compose (Docker Inc., 2.13.0)Server: Containers: 1  Running: 0  Paused: 0  Stopped: 1 Images: 49 Server Version: 20.10.21 Storage Driver: btrfs  Build Version: Btrfs v6.0  Library Version: 102 Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 770bd0108c32f3fb5c73ae1264f7e503fe7b2661.m runc version:  init version: de40ad0 Security Options:  seccomp   Profile: default  cgroupns Kernel Version: 5.19.17-2-MANJARO Operating System: Manjaro Linux OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.35GiB Name: workLP ID: AYT5:RAT2:HOV2:RQDV:4EKG:5JXU:LOIV:BXUF:WUWS:SU3F:N3NF:ZIS7 Docker Root Dir: /var/lib/docker Debug Mode: false Username: nixit89 Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```### Additional Infodec 15 09:35:43 workLP dockerd[508]: time=""2022-12-15T09:35:43.426269401+10:00"" level=info msg=""loading plugin \""io.containerd.event.v1.publisher\""..."" runtime=io.containerd.runc.v2 type=io.containerd.event.v1dec 15 09:35:43 workLP dockerd[508]: time=""2022-12-15T09:35:43.426312851+10:00"" level=info msg=""loading plugin \""io.containerd.internal.v1.shutdown\""..."" runtime=io.containerd.runc.v2 type=io.containerd.internal.v1dec 15 09:35:43 workLP dockerd[508]: time=""2022-12-15T09:35:43.426324317+10:00"" level=info msg=""loading plugin \""io.containerd.ttrpc.v1.task\""..."" runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1dec 15 09:35:43 workLP dockerd[508]: time=""2022-12-15T09:35:43.426411240+10:00"" level=info msg=""starting signal loop"" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/dc346679ec1e219c2151d342d9c174bf2e>dec 15 09:35:43 workLP dockerd[508]: time=""2022-12-15T09:35:43.596244372+10:00"" level=info msg=""shim disconnected"" id=dc346679ec1e219c2151d342d9c174bf2e8f12b903a5f1e2fa57dd232f75c35bdec 15 09:35:43 workLP dockerd[508]: time=""2022-12-15T09:35:43.596295318+10:00"" level=warning msg=""cleaning up after shim disconnected"" id=dc346679ec1e219c2151d342d9c174bf2e8f12b903a5f1e2fa57dd232f75c35b namespace=mobydec 15 09:35:43 workLP dockerd[508]: time=""2022-12-15T09:35:43.596304942+10:00"" level=info msg=""cleaning up dead shim""dec 15 09:35:43 workLP dockerd[508]: time=""2022-12-15T09:35:43.603659048+10:00"" level=warning msg=""cleanup warnings time=\""2022-12-15T09:35:43+10:00\"" level=info msg=\""starting signal loop\"" namespace=moby pid=20316 runtime=io.containerd>dec 15 09:35:43 workLP dockerd[508]: time=""2022-12-15T09:35:43.603892028+10:00"" level=error msg=""copy shim log"" error=""read /proc/self/fd/13: file already closed""dec 15 09:35:43 workLP dockerd[476]: time=""2022-12-15T09:35:43.604278487+10:00"" level=error msg=""stream copy error: reading from a closed fifo""dec 15 09:35:43 workLP dockerd[476]: time=""2022-12-15T09:35:43.803115468+10:00"" level=error msg=""dc346679ec1e219c2151d342d9c174bf2e8f12b903a5f1e2fa57dd232f75c35b cleanup: failed to delete container from containerd: no such container""dec 15 09:36:05 workLP dockerd[508]: time=""2022-12-15T09:36:05.756559481+10:00"" level=info msg=""loading plugin \""io.containerd.event.v1.publisher\""..."" runtime=io.containerd.runc.v2 type=io.containerd.event.v1dec 15 09:36:05 workLP dockerd[508]: time=""2022-12-15T09:36:05.756609461+10:00"" level=info msg=""loading plugin \""io.containerd.internal.v1.shutdown\""..."" runtime=io.containerd.runc.v2 type=io.containerd.internal.v1dec 15 09:36:05 workLP dockerd[508]: time=""2022-12-15T09:36:05.756620666+10:00"" level=info msg=""loading plugin \""io.containerd.ttrpc.v1.task\""..."" runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1dec 15 09:36:05 workLP dockerd[508]: time=""2022-12-15T09:36:05.756715166+10:00"" level=info msg=""starting signal loop"" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/a73ea935707fee6fa813e97b364f6eadc6>dec 15 09:36:11 workLP dockerd[508]: time=""2022-12-15T09:36:11.103701145+10:00"" level=info msg=""shim disconnected"" id=a73ea935707fee6fa813e97b364f6eadc6174c9615bd04c8e2c27e0d03740e52dec 15 09:36:11 workLP dockerd[508]: time=""2022-12-15T09:36:11.103811226+10:00"" level=warning msg=""cleaning up after shim disconnected"" id=a73ea935707fee6fa813e97b364f6eadc6174c9615bd04c8e2c27e0d03740e52 namespace=mobydec 15 09:36:11 workLP dockerd[508]: time=""2022-12-15T09:36:11.103830617+10:00"" level=info msg=""cleaning up dead shim""dec 15 09:36:11 workLP dockerd[476]: time=""2022-12-15T09:36:11.103953573+10:00"" level=info msg=""ignoring event"" container=a73ea935707fee6fa813e97b364f6eadc6174c9615bd04c8e2c27e0d03740e52 module=libcontainerd namespace=moby topic=/tasks/d>dec 15 09:36:11 workLP dockerd[508]: time=""2022-12-15T09:36:11.110781801+10:00"" level=warning msg=""cleanup warnings time=\""2022-12-15T09:36:11+10:00\"" level=info msg=\""starting signal loop\"" namespace=moby pid=20842 runtime=io.containerd>
"
44614,1,18,291,0,0,paralin,0,"title:[23.0.0-beta] go.sum and vendor/ tree currently mismatch go.mod. description:### DescriptionRunning ""go mod vendor"" also fails due to a missing line in go.sum.Errors when running ""go build -mod=vendor"" without running ""go mod tidy"":go: inconsistent vendoring in docker-engine-:  cloud.google.com/go@v0.102.1: is marked as explicit in vendor/modules.txt, but not explicitly required in go.mod  cloud.google.com/go/compute@v1.7.0: is marked as explicit in vendor/modules.txt, but not explicitly required in go.mod  cloud.google.com/go/logging@v1.4.2: is marked as explicit in vendor/modules.txt, but not explicitly required in go.mod  code.cloudfoundry.org/clock@v1.0.0: is marked as explicit in vendor/modules.txt, but not explicitly required in go.mod  [snip]  To ignore the vendor directory, use -mod=readonly or -mod=mod.  To sync the vendor directory, run:  go mod vendor### Reproduce1. Run `go build -mod=vendor ./cmd/dockerd`### Expected behaviorPrevious releases build correctly without any changes using `go build -mod=vendor`.### docker version```bashN/A```### docker info```bashN/A```### Additional Info_No response_
"
44604,1,2407,49,0,0,twiddler,0,"title:Dockerized node app cannot access its own node_modules if node_modules is missing on host. description:### DescriptionI am trying to dockerize the dev environment of a react app. I would like to- have hot module reloading, so I am mounting my project files into my docker container, and- keep this mount read-only so the container cannot mess with the host.My solution is:```consoledocker run -v $(pwd):/app:ro my-image ```However, this would prevent the image from populating its `node_modules` with `RUN npm i`. So I create an anonymous volume under /app/node_modules:```consoledocker run -v $(pwd):/app:ro -v /app/node_modules my-image```Now I don't know why, but that last command seemingly fails if `node_modules` does not exist on the host. I don't know if this is somehow intended behaviour; to me it seems like a bug. 婵犵妲呴崑鎾跺緤娴犲鐤柕濠忓椤?## Reproduce1. Download [this gist](https://gist.github.com/twiddler/7deb70deec62b298738858cee5aa00bb).2. Run `./this-works.sh` from your terminal. You should not see an error.3. Run `./this-fails.sh` from your terminal. You should see an error like this:> docker: Error response from daemon: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: error during container init: error mounting ""/var/lib/docker/volumes/2ab6fcb106bc90e22084e87b22bafc743731d59d2880e596b54cc3ff173edadf/_data"" to rootfs at ""/app/node_modules"": mkdir /var/lib/docker/btrfs/subvolumes/032e3d315649b4a6e71663145593ae1bebd6695091464a838bd4b4a342af9e8f/app/node_modules: read-only file system: unknown.> ERRO[0000] error waiting for container: context canceledThere's been times I could not reproduce this error. I don't know why.### Expected behavior`this-fails.sh` should not throw an error.### docker version```bashClient: Docker Engine - Community Version:           20.10.21 API version:       1.41 Go version:        go1.18.7 Git commit:        baeda1f Built:             Tue Oct 25 18:02:36 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.21  API version:      1.41 (minimum version 1.12)  Go version:       go1.18.7  Git commit:       3056208  Built:            Tue Oct 25 18:00:17 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.10  GitCommit:        770bd0108c32f3fb5c73ae1264f7e503fe7b2661 runc:  Version:          1.1.4  GitCommit:        v1.1.4-0-g5fd4c4d docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.9.1-docker)  compose: Docker Compose (Docker Inc., v2.12.2)  scan: Docker Scan (Docker Inc., v0.21.0)Server: Containers: 1  Running: 0  Paused: 0  Stopped: 1 Images: 182 Server Version: 20.10.21 Storage Driver: btrfs  Build Version: Btrfs v6.0  Library Version: 102 Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runtime.v1.linux runc io.containerd.runc.v2 Default Runtime: runc Init Binary: docker-init containerd version: 770bd0108c32f3fb5c73ae1264f7e503fe7b2661 runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options:  seccomp   Profile: default  cgroupns Kernel Version: 6.0.11-300.fc37.x86_64 Operating System: Fedora Linux 37 (Workstation Edition) OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.01GiB Name: fedora ID: GGNP:DDT5:P3RY:GESB:LT44:3LSS:7ALD:G6CU:32GH:B7HR:4KRV:U3OO Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```### Additional Info_No response_
"
44601,1,11286,126,0,0,linuxlonelyeagle,0,"title:failed to start daemon: Error initializing network controller: error obtaining controller instance: failed to create NAT chain. description:### DescriptionWhen i run `sudo service docker star`, it show that ```* Starting Docker: docker        ``` ,but the he docker daemon is not actually running. So i run dockerd.It show that```INFO[2022-12-07T11:55:13.689667840+08:00] Starting up                                  INFO[2022-12-07T11:55:13.690830312+08:00] libcontainerd: started new containerd process  pid=32636INFO[2022-12-07T11:55:13.690863933+08:00] parsed scheme: ""unix""                         module=grpcINFO[2022-12-07T11:55:13.690872053+08:00] scheme ""unix"" not registered, fallback to default scheme  module=grpcINFO[2022-12-07T11:55:13.690888392+08:00] ccResolverWrapper: sending update to cc: {[{unix:///var/run/docker/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}  module=grpcINFO[2022-12-07T11:55:13.690895837+08:00] ClientConn switching balancer to ""pick_first""  module=grpcWARN[0000] containerd config version `1` has been deprecated and will be removed in containerd v2.0, please switch to version `2`, see https://github.com/containerd/containerd/blob/main/docs/PLUGINS.md#version-header INFO[2022-12-07T11:55:13.709693601+08:00] starting containerd                           revision=d986545181c905378b0f90faa9c5eae3cbfa3755 version=1.6.11INFO[2022-12-07T11:55:13.721060527+08:00] loading plugin ""io.containerd.content.v1.content""...  type=io.containerd.content.v1INFO[2022-12-07T11:55:13.721162947+08:00] loading plugin ""io.containerd.snapshotter.v1.aufs""...  type=io.containerd.snapshotter.v1INFO[2022-12-07T11:55:13.721270857+08:00] loading plugin ""io.containerd.snapshotter.v1.btrfs""...  type=io.containerd.snapshotter.v1INFO[2022-12-07T11:55:13.721432440+08:00] skip loading plugin ""io.containerd.snapshotter.v1.btrfs""...  error=""path /var/lib/docker/containerd/daemon/io.containerd.snapshotter.v1.btrfs (overlay) must be a btrfs filesystem to be used with the btrfs snapshotter: skip plugin"" type=io.containerd.snapshotter.v1INFO[2022-12-07T11:55:13.721450064+08:00] loading plugin ""io.containerd.snapshotter.v1.devmapper""...  type=io.containerd.snapshotter.v1WARN[2022-12-07T11:55:13.721460759+08:00] failed to load plugin io.containerd.snapshotter.v1.devmapper  error=""devmapper not configured""INFO[2022-12-07T11:55:13.721469533+08:00] loading plugin ""io.containerd.snapshotter.v1.native""...  type=io.containerd.snapshotter.v1INFO[2022-12-07T11:55:13.721493960+08:00] loading plugin ""io.containerd.snapshotter.v1.overlayfs""...  type=io.containerd.snapshotter.v1INFO[2022-12-07T11:55:13.721607163+08:00] loading plugin ""io.containerd.snapshotter.v1.zfs""...  type=io.containerd.snapshotter.v1INFO[2022-12-07T11:55:13.721744493+08:00] skip loading plugin ""io.containerd.snapshotter.v1.zfs""...  error=""path /var/lib/docker/containerd/daemon/io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter: skip plugin"" type=io.containerd.snapshotter.v1INFO[2022-12-07T11:55:13.721766638+08:00] loading plugin ""io.containerd.metadata.v1.bolt""...  type=io.containerd.metadata.v1WARN[2022-12-07T11:55:13.721793906+08:00] could not use snapshotter devmapper in metadata plugin  error=""devmapper not configured""INFO[2022-12-07T11:55:13.721805042+08:00] metadata content store policy set             policy=sharedINFO[2022-12-07T11:55:13.721878548+08:00] loading plugin ""io.containerd.differ.v1.walking""...  type=io.containerd.differ.v1INFO[2022-12-07T11:55:13.721902457+08:00] loading plugin ""io.containerd.event.v1.exchange""...  type=io.containerd.event.v1INFO[2022-12-07T11:55:13.721912970+08:00] loading plugin ""io.containerd.gc.v1.scheduler""...  type=io.containerd.gc.v1INFO[2022-12-07T11:55:13.721935983+08:00] loading plugin ""io.containerd.service.v1.introspection-service""...  type=io.containerd.service.v1INFO[2022-12-07T11:55:13.721947382+08:00] loading plugin ""io.containerd.service.v1.containers-service""...  type=io.containerd.service.v1INFO[2022-12-07T11:55:13.721958460+08:00] loading plugin ""io.containerd.service.v1.content-service""...  type=io.containerd.service.v1INFO[2022-12-07T11:55:13.721970162+08:00] loading plugin ""io.containerd.service.v1.diff-service""...  type=io.containerd.service.v1INFO[2022-12-07T11:55:13.721981181+08:00] loading plugin ""io.containerd.service.v1.images-service""...  type=io.containerd.service.v1INFO[2022-12-07T11:55:13.721991853+08:00] loading plugin ""io.containerd.service.v1.leases-service""...  type=io.containerd.service.v1INFO[2022-12-07T11:55:13.722015595+08:00] loading plugin ""io.containerd.service.v1.namespaces-service""...  type=io.containerd.service.v1INFO[2022-12-07T11:55:13.722033448+08:00] loading plugin ""io.containerd.service.v1.snapshots-service""...  type=io.containerd.service.v1INFO[2022-12-07T11:55:13.722044916+08:00] loading plugin ""io.containerd.runtime.v1.linux""...  type=io.containerd.runtime.v1INFO[2022-12-07T11:55:13.722113613+08:00] loading plugin ""io.containerd.runtime.v2.task""...  type=io.containerd.runtime.v2INFO[2022-12-07T11:55:13.722162722+08:00] loading plugin ""io.containerd.monitor.v1.cgroups""...  type=io.containerd.monitor.v1INFO[2022-12-07T11:55:13.722489645+08:00] loading plugin ""io.containerd.service.v1.tasks-service""...  type=io.containerd.service.v1INFO[2022-12-07T11:55:13.722533280+08:00] loading plugin ""io.containerd.grpc.v1.introspection""...  type=io.containerd.grpc.v1INFO[2022-12-07T11:55:13.722546954+08:00] loading plugin ""io.containerd.internal.v1.restart""...  type=io.containerd.internal.v1INFO[2022-12-07T11:55:13.722593806+08:00] loading plugin ""io.containerd.grpc.v1.containers""...  type=io.containerd.grpc.v1INFO[2022-12-07T11:55:13.722605874+08:00] loading plugin ""io.containerd.grpc.v1.content""...  type=io.containerd.grpc.v1INFO[2022-12-07T11:55:13.722616935+08:00] loading plugin ""io.containerd.grpc.v1.diff""...  type=io.containerd.grpc.v1INFO[2022-12-07T11:55:13.722627139+08:00] loading plugin ""io.containerd.grpc.v1.events""...  type=io.containerd.grpc.v1INFO[2022-12-07T11:55:13.722640664+08:00] loading plugin ""io.containerd.grpc.v1.healthcheck""...  type=io.containerd.grpc.v1INFO[2022-12-07T11:55:13.722651709+08:00] loading plugin ""io.containerd.grpc.v1.images""...  type=io.containerd.grpc.v1INFO[2022-12-07T11:55:13.722662915+08:00] loading plugin ""io.containerd.grpc.v1.leases""...  type=io.containerd.grpc.v1INFO[2022-12-07T11:55:13.722673818+08:00] loading plugin ""io.containerd.grpc.v1.namespaces""...  type=io.containerd.grpc.v1INFO[2022-12-07T11:55:13.722689195+08:00] loading plugin ""io.containerd.internal.v1.opt""...  type=io.containerd.internal.v1INFO[2022-12-07T11:55:13.722728731+08:00] loading plugin ""io.containerd.grpc.v1.snapshots""...  type=io.containerd.grpc.v1INFO[2022-12-07T11:55:13.722739594+08:00] loading plugin ""io.containerd.grpc.v1.tasks""...  type=io.containerd.grpc.v1INFO[2022-12-07T11:55:13.722751170+08:00] loading plugin ""io.containerd.grpc.v1.version""...  type=io.containerd.grpc.v1INFO[2022-12-07T11:55:13.722765414+08:00] loading plugin ""io.containerd.tracing.processor.v1.otlp""...  type=io.containerd.tracing.processor.v1INFO[2022-12-07T11:55:13.722777879+08:00] skip loading plugin ""io.containerd.tracing.processor.v1.otlp""...  error=""no OpenTelemetry endpoint: skip plugin"" type=io.containerd.tracing.processor.v1INFO[2022-12-07T11:55:13.722790223+08:00] loading plugin ""io.containerd.internal.v1.tracing""...  type=io.containerd.internal.v1ERRO[2022-12-07T11:55:13.722804665+08:00] failed to initialize a tracing processor ""otlp""  error=""no OpenTelemetry endpoint: skip plugin""INFO[2022-12-07T11:55:13.723058139+08:00] serving...                                    address=/var/run/docker/containerd/containerd-debug.sockINFO[2022-12-07T11:55:13.723131504+08:00] serving...                                    address=/var/run/docker/containerd/containerd.sock.ttrpcINFO[2022-12-07T11:55:13.723188577+08:00] serving...                                    address=/var/run/docker/containerd/containerd.sockINFO[2022-12-07T11:55:13.723205294+08:00] containerd successfully booted in 0.014043s  INFO[2022-12-07T11:55:13.733521025+08:00] parsed scheme: ""unix""                         module=grpcINFO[2022-12-07T11:55:13.733544358+08:00] scheme ""unix"" not registered, fallback to default scheme  module=grpcINFO[2022-12-07T11:55:13.733558967+08:00] ccResolverWrapper: sending update to cc: {[{unix:///var/run/docker/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}  module=grpcINFO[2022-12-07T11:55:13.733570123+08:00] ClientConn switching balancer to ""pick_first""  module=grpcINFO[2022-12-07T11:55:13.734303148+08:00] parsed scheme: ""unix""                         module=grpcINFO[2022-12-07T11:55:13.734320174+08:00] scheme ""unix"" not registered, fallback to default scheme  module=grpcINFO[2022-12-07T11:55:13.734363656+08:00] ccResolverWrapper: sending update to cc: {[{unix:///var/run/docker/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}  module=grpcINFO[2022-12-07T11:55:13.734371622+08:00] ClientConn switching balancer to ""pick_first""  module=grpcINFO[2022-12-07T11:55:13.735080383+08:00] [graphdriver] using prior storage driver: aufs WARN[2022-12-07T11:55:13.735111136+08:00] [graphdriver] WARNING: the aufs storage-driver is deprecated, and will be removed in a future release WARN[2022-12-07T11:55:13.737444466+08:00] Your kernel does not support swap memory limit WARN[2022-12-07T11:55:13.737457309+08:00] Your kernel does not support CPU realtime scheduler INFO[2022-12-07T11:55:13.737565985+08:00] Loading containers: start.                   WARN[2022-12-07T11:55:13.738682711+08:00] Running iptables --wait -t nat -L -n failed with message: `iptables v1.8.4 (legacy): can't initialize iptables table `nat': Permission denied (you must be root)Perhaps iptables or your kernel needs to be upgraded.`, error: exit status 3 INFO[2022-12-07T11:55:13.755898363+08:00] stopping event stream following graceful shutdown  error=""<nil>"" module=libcontainerd namespace=mobyINFO[2022-12-07T11:55:13.756127037+08:00] stopping healthcheck following graceful shutdown  module=libcontainerdINFO[2022-12-07T11:55:13.756144427+08:00] stopping event stream following graceful shutdown  error=""context canceled"" module=libcontainerd namespace=plugins.mobyWARN[2022-12-07T11:55:14.756720700+08:00] grpc: addrConn.createTransport failed to connect to {unix:///var/run/docker/containerd/containerd.sock  <nil> 0 <nil>}. Err :connection error: desc = ""transport: Error while dialing dial unix:///var/run/docker/containerd/containerd.sock: timeout"". Reconnecting...  module=grpcfailed to start daemon: Error initializing network controller: error obtaining controller instance: failed to create NAT chain DOCKER: iptables failed: iptables -t nat -N DOCKER: iptables v1.8.4 (legacy): can't initialize iptables table `nat': Permission denied (you must be root)Perhaps iptables or your kernel needs to be upgraded. (exit status 3)```I find the problem that DOCKER: iptables failed: iptables -t nat -N DOCKER: iptables v1.8.4 (legacy): can't initialize iptables table `nat': Permission denied (you must be root).I looked up some information, but it didn't solve the problem.### Reproduce1.dockerd### Expected behavior'dockerd' runs successfully.### docker version```bashdocker --versionDocker version 20.10.21, build baeda1f```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.9.1-docker)  compose: Docker Compose (Docker Inc., v2.12.2)  scan: Docker Scan (Docker Inc., v0.21.0)Server:ERROR: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?errors pretty printing info.```### Additional Info_No response_
"
44570,0,6153,200,0,1,thaJeztah,1,"title:ci: buildkit CI is broken; ""cgo: malformed DWARF TagVariable entry"". description:### DescriptionSince late yesterday evening, BuildKit CI is broken; as far as I can see, it's breaking in a step that does not use the code in this repository (but please double-check if I'm right), so either- The base image used- The Dockerfile frontend (it looks to be using `dockerfile-upstream:master`)- Perhaps some obscure issue, similar to https://github.com/containerd/containerd/issues/6387, where the Git ""short commit"" is used in the source code?- Corrupted remote build-cache? (does it use that?)- something changes on GitHub action hosts ?- GitHub actions builds of docker / containerd / buildx ?Failure looks like this: (https://github.com/moby/moby/actions/runs/3600129177/jobs/6064524682)```> [containerd-alt-15 1/1] RUN --mount=from=containerd-src,src=/usr/src/containerd,readwrite --mount=target=/root/.cache,type=cache   git fetch origin   && git checkout -q ""v1.5.11""   && make bin/containerd   && make bin/containerd-shim-runc-v2   && mv bin /out:#0 4.935 + bin/containerd#47 268.1 # github.com/containerd/containerd/vendor/github.com/miekg/pkcs11#47 268.1 cgo: malformed DWARF TagVariable entry#47 279.5 make: *** [Makefile:213: bin/containerd] Error 2```Which is similar to reports in go1.17 some time ago;- looks reported in https://github.com/golang/go/issues/53000- and a fix in https://go-review.googlesource.com/c/go/+/406816 ?### ReproduceSee https://github.com/moby/moby/pull/44567 and other PRs### Expected behavior_No response_### docker version```bashsudo rm /etc/docker/daemon.json  sudo service docker restart  docker version  docker info  shell: /usr/bin/bash -e {0}  env:    BUNDLES_OUTPUT: ./bundles    BUILDKIT_REF: 4febae4f874bd8ef52dec30e988c8fe0bc96b3b9Client: Version:           20.10.21+azure-1 API version:       1.41 Go version:        go1.18.7 Git commit:        baeda1f82a10204ec5708d5fbba130ad76cfee49 Built:             Tue Oct 25 17:53:02 UTC 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      true```### docker info```bashServer: Engine:  Version:          20.10.21+azure-1  API version:      1.41 (minimum version 1.12)  Go version:       go1.18.7  Git commit:       3056208812eb5e792fa99736c9167d1e10f4ab49  Built:            Tue Oct 25 11:44:15 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.5.14+azure-1  GitCommit:        b84d0b151c2395a5917996d602b192ce1e0fa461 runc:  Version:          1.1.4  GitCommit:        5fd4c4d144137e991c4acebb2146ab1483a97925 docker-init:  Version:          0.19.0  GitCommit:        Client: Context:    default Debug Mode: false Plugins:  buildx: Docker Buildx (Docker Inc., 0.9.1+azure-2)  compose: Docker Compose (Docker Inc., 2.12.2+azure-1)Server: Containers: 1  Running: 0  Paused: 0  Stopped: 1 Images: 21 Server Version: 20.10.21+azure-1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: b84d0b151c2395a5917996d602b192ce1e0fa461 runc version: 5fd4c4d144137e991c4acebb2146ab1483a97925 init version:  Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.15.0-1023-azure Operating System: Ubuntu 20.04.5 LTS OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 6.781GiB Name: fv-az77-14 ID: 4IWW:VLI2:7YTM:AFEZ:4NJ5:VCDD:VCJU:3HXK:DSAL:C6S2:OKSN:N3A5 Docker Root Dir: /var/lib/docker Debug Mode: false Username: githubactions Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```### Additional InfoThe step where things break:```shell: /usr/bin/bash -e {0}  env:    BUNDLES_OUTPUT: ./bundles    BUILDKIT_REF: 4febae4f874bd8ef52dec30e988c8fe0bc96b3b9    CONTEXT: .    TEST_DOCKERD: 1    TEST_DOCKERD_BINARY: ./build/moby/binary-daemon/dockerd    TESTPKGS: ./client    TESTFLAGS: -v --parallel=1 --timeout=30m --run=//worker=dockerd$+ docker buildx build --target integration-tests --output type=docker,name=buildkit-tests . --progress=plain```Failure with more detail:``` > [containerd-alt-15 1/1] RUN --mount=from=containerd-src,src=/usr/src/containerd,readwrite --mount=target=/root/.cache,type=cache   git fetch origin   && git checkout -q ""v1.5.11""   && make bin/containerd   && make bin/containerd-shim-runc-v2   && mv bin /out:#0 5.824 + bin/containerd#49 311.7 # github.com/containerd/containerd/vendor/github.com/miekg/pkcs11#49 311.7 cgo: malformed DWARF TagVariable entry#49 324.2 make: *** [Makefile:213: bin/containerd] Error 2------Dockerfile:143-------------------- 142 |     ARG GO111MODULE=off 143 | >>> RUN --mount=from=containerd-src,src=/usr/src/containerd,readwrite --mount=target=/root/.cache,type=cache \ 144 | >>>   git fetch origin \ 145 | >>>   && git checkout -q ""$CONTAINERD_ALT_VERSION_15"" \ 146 | >>>   && make bin/containerd \ 147 | >>>   && make bin/containerd-shim-runc-v2 \ 148 | >>>   && mv bin /out 149 |     --------------------ERROR: failed to solve: process ""/bin/sh -c git fetch origin   && git checkout -q \""$CONTAINERD_ALT_VERSION_15\""   && make bin/containerd   && make bin/containerd-shim-runc-v2   && mv bin /out"" did not complete successfully: exit code: 2Error: Process completed with exit code 1.```:warning: As mentioned, it looks like it's using- a container builder- the `docker.io/docker/dockerfile-upstream:master` frontend (`sha256:0e39c80bd858c49913c85dd3636aae0f6c8266ff1dcc24e5aeabf98e93579843`)```#1 [internal] booting buildkit#1 starting container buildx_buildkit_builder-9473aa25-e043-4654-934c-be4271ea8e3d0#1 starting container buildx_buildkit_builder-9473aa25-e043-4654-934c-be4271ea8e3d0 0.6s done#1 DONE 0.6s#2 [internal] load .dockerignore#2 transferring context: 56B done#2 DONE 0.0s#3 [internal] load build definition from Dockerfile#3 transferring dockerfile: 11.57kB done#3 DONE 0.0s#4 resolve image config for docker.io/docker/dockerfile-upstream:master#4 ...#5 [auth] docker/dockerfile-upstream:pull token for registry-1.docker.io#5 DONE 0.0s#4 resolve image config for docker.io/docker/dockerfile-upstream:master#4 DONE 0.8s#6 docker-image://docker.io/docker/dockerfile-upstream:master@sha256:0e39c80bd858c49913c85dd3636aae0f6c8266ff1dcc24e5aeabf98e93579843#6 resolve docker.io/docker/dockerfile-upstream:master@sha256:0e39c80bd858c49913c85dd3636aae0f6c8266ff1dcc24e5aeabf98e93579843 done#6 sha256:0268775466e82aa89ffd3bd52916812c04ce4f8fb96af0e504edd8f997ffbcfc 1.05MB / 11.47MB 0.2s#6 sha256:0268775466e82aa89ffd3bd52916812c04ce4f8fb96af0e504edd8f997ffbcfc 3.15MB / 11.47MB 0.3s#6 sha256:0268775466e82aa89ffd3bd52916812c04ce4f8fb96af0e504edd8f997ffbcfc 11.47MB / 11.47MB 0.5s done#6 extracting sha256:0268775466e82aa89ffd3bd52916812c04ce4f8fb96af0e504edd8f997ffbcfc#6 extracting sha256:0268775466e82aa89ffd3bd52916812c04ce4f8fb96af0e504edd8f997ffbcfc 0.2s done#6 DONE 0.8s```
"
44525,1,2774,284,0,0,ferrarimarco,0,"title:docker buildx fails to validate ""--add-host=host.docker.internal:host-gateway"". description:### DescriptionWhen building an image with `docker buildx` on Linux and adding the `--add-host=host.docker.internal:host-gateway` option, it fails because the validation of the `host-gateway` is not an IP address, as required by https://github.com/moby/moby/blob/a263241ea16f1b018fc1c8f5c6564d84f1153543/builder/builder-next/builder.go#L562-L564`docker buildx` output:```$ docker build --add-host=host.docker.internal:host-gateway .[+] Building 0.0s (0/0)ERROR: invalid host host.docker.internal:host-gateway````docker build` is able to build the image correctly. In fact, it checks for the `host-gateway` special case: https://github.com/moby/moby/blob/f1dd6bf84e28930e1ccd903361f9284fb22d3b8a/opts/hosts.go#L180-L184`docker build` output:```$ docker build --add-host=host.docker.internal:host-gateway --tag whatever . Sending build context to Docker daemon  1.38MBStep 1/1 : FROM ubuntu:22.0422.04: Pulling from library/ubuntue96e057aae67: Pull completeDigest: sha256:4b1d0c4a2d2aaf63b37111f34eb9fa89fa1bf53dd6e4ca954d47caebca4005c2Status: Downloaded newer image for ubuntu:22.04 ---> a8780b506fa4Successfully built a8780b506fa4```### Reproduce1. Create a `Dockerfile` with the following contents:```dockerfileFROM ubuntu:22.04```2. Run `docker buildx --add-host=host.docker.internal:host-gateway .`### Expected behavior- `docker buildx` should be able to build the image- The `host.docker.internal` name should point to the address of the machine running the container### docker version```bashClient: Docker Engine - Community Version:           20.10.21 API version:       1.41 Go version:        go1.18.7 Git commit:        baeda1f Built:             Tue Oct 25 18:02:28 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.21  API version:      1.41 (minimum version 1.12)  Go version:       go1.18.7  Git commit:       3056208  Built:            Tue Oct 25 18:00:19 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.9  GitCommit:        1c90a442489720eec95342e1789ee8a5e1b9536f runc:  Version:          1.1.4  GitCommit:        v1.1.4-0-g5fd4c4d docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.9.1-docker)Server: Containers: 14  Running: 1  Paused: 0  Stopped: 13 Images: 549 Server Version: 20.10.21 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runtime.v1.linux runc io.containerd.runc.v2 Default Runtime: runc Init Binary: docker-init containerd version: 1c90a442489720eec95342e1789ee8a5e1b9536f runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default  cgroupns Kernel Version: 5.18.16-amd64 Operating System: Debian GNU/Linux OSType: linux Architecture: x86_64 CPUs: 48 Total Memory: 177.1GiB Name: [redacted] ID: [redacted] Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```### Additional Info_No response_
"
44512,0,7976,13,0,0,belugabehr,0,"title:List API includes partially-created containers which cannot be inspected. description:### DescriptionI am working on an application that was implemented before the various `docker system prune` commands were available and therefore had manually implemented pruning from the client side.  The logic is pretty straightforward:1. Request a _list_ of all docker containers2. For each container, _inspect_ it for more details3. Make a decision about deleting the container or not (e.g., status, error code, creation date)This process fails with some frequency as there are times when attempting to _inspect_ a container that was returned by _list_ returns a 404 code.  I've noticed that it consistently fails to _inspect_ containers that are in a ""created"" state.In the application, there is one thread that is regularly performing this prune process, and another thread that is launching containers by first _creating_ the container and then _starting_ it.```# Example container: aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b# Thread 1 - Creating the containerNov 22 13:29:42 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:42.814004115Z"" level=debug msg=""copying image data from aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b:/var, to f2044d2badae69af56bcc84b739b7eNov 22 13:29:43 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:43.064228098Z"" level=debug msg=""copying image data from aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b:/root, to 16bb75cc1a51a5cd69a371b9b6cdaNov 22 13:29:43 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:43.064312480Z"" level=debug msg=""copying image data from aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b:/opt, to 844b97098daaf1040aa2cafcf1d3a4Nov 22 13:29:44 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:44.381082225Z"" level=debug msg=""copying image data from aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b:/run, to 87c3f7a34557a0b08e3be1d9404943Nov 22 13:29:44 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:44.381892484Z"" level=debug msg=""copying image data from aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b:/private, to 424c0af91b3c2cde0f7f44ab82Nov 22 13:29:44 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:44.381916606Z"" level=debug msg=""copying image data from aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b:/tmp, to 5a77fcd42f70e14a8652a0a96df739# Thread 2 - Prune process - List all of the containers and then inspect each container in a loopNov 22 13:29:47 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:47.211366766Z"" level=debug msg=""Calling GET /v1.23/containers/json?all=true""# Thread 2 - Now returns a 404 error to the client - note these are subsequent calls in the logsNov 22 13:29:47 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:47.218430962Z"" level=debug msg=""Calling GET /v1.23/containers/aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b/json""# Thread 2 - The container is in a very unexpected state - so try to delete it (also fails with a 404)Nov 22 13:29:47 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:47.224637054Z"" level=debug msg=""Calling DELETE /v1.23/containers/aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b?v=true&force=true""# Thread 2 - More pruning activityNov 22 13:29:47 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:47.230754029Z"" level=debug msg=""Calling GET /v1.23/volumes?filters=%7B%22dangling%22%3A%5B%22true%22%5D%7D""Nov 22 13:29:47 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:47.230796460Z"" level=debug msg=VolumeStore.Find ByType=service.andCombinator ByValue=""[0x5581d5dc3500 false]""# Thread 1 - Now the container gets startedNov 22 13:29:50 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:50.190019073Z"" level=debug msg=""Calling POST /v1.23/containers/aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b/start""Nov 22 13:29:50 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:50.190411705Z"" level=warning msg=""Specifying a kernel memory limit is deprecated and will be removed in a future release.""Nov 22 13:29:50 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:50.190692420Z"" level=debug msg=""container mounted via layerStore: &{/local/docker/200000.200000/overlay2/dac334114dcbd314826c1b4a2531b9036b8a7a6a399067c4333d85eNov 22 13:29:50 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:50.190905625Z"" level=debug msg=""Assigning addresses for endpoint confident_kilby's interface on network bridge""Nov 22 13:29:50 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:50.190928606Z"" level=debug msg=""RequestAddress(LocalDefault/X.X.0.0/16/X.X.X.X/16, <nil>, map[])""Nov 22 13:29:50 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:50.190957426Z"" level=debug msg=""Request address PoolID:X.X.X.X/16 App: ipam/default/data, ID: LocalDefault/X.X.X.X/16, DBIndex: 0x0, Bits: 65536, UnselectNov 22 13:29:50 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:50.206877322Z"" level=debug msg=""Assigning addresses for endpoint confident_kilby's interface on network bridge""Nov 22 13:29:50 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:50.210671885Z"" level=debug msg=""Programming external connectivity on endpoint confident_kilby (acde711aa29fb7c1a507e54744e19051cfb3af21d0d43d2a234efbd58284ddb5)Nov 22 13:29:50 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:50.211956905Z"" level=debug msg=""EnableService aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b START""Nov 22 13:29:50 host.domain.com dockerd[1766]: time=""2022-11-22T13:29:50.211970514Z"" level=debug msg=""EnableService aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b DONE""```Subsequent attempts to prune the container are successful.  It seems perhaps that there is a small window of time where the container is in a state that makes it a candidate for _list_ but not for _inspect_.### ReproduceHappens randomly. I was unable to mimic this with CLI.### Expected behaviorAssuming no external modification between calls, all containers returned by `list` are available to `inspect`.### docker version```bashClient: Version:           20.10.7 API version:       1.41 Go version:        go1.15.14 Git commit:        f0df350 Built:             Wed Nov 17 03:05:36 2021 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          20.10.7  API version:      1.41 (minimum version 1.12)  Go version:       go1.15.14  Git commit:       b0f5bc3  Built:            Wed Nov 17 03:06:14 2021  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.6  GitCommit:        d71fcd7d8303cbf684402823e425e9dd2e99285d runc:  Version:          1.0.0  GitCommit:        84113eef6fc27af1b01b3181f31bbaf708715301 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 15 Server Version: 20.10.7 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan (Redacted) null overlay  Log: (Redacted) Swarm: inactive Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: d71fcd7d8303cbf684402823e425e9dd2e99285d runc version: 84113eef6fc27af1b01b3181f31bbaf708715301 init version: de40ad0 Security Options: (Redacted) Kernel Version: 5.10.144-111.639.amzn2int.x86_64 Operating System: Amazon Linux 2 OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 30.84GiB Name: host.domain.com ID: (Redacted) Docker Root Dir: /local/docker/200000.200000 Debug Mode: true  File Descriptors: 38  Goroutines: 48  System Time: 2022-11-22T21:01:45.968617867Z  EventsListeners: 0 Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: (Redacted) Live Restore Enabled: false```### Additional InfoThis is from the client perspective (docker-java):```# First inspect failure2022-11-22T13:29:47.218Z [INFO]   (Timer-0)  Was going to remove container aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b but it no longer exists2022-11-22T13:29:47.218Z [DEBUG]  (Timer-0)  Container aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b detailed errorcom.github.dockerjava.api.exception.NotFoundException: Status 404: No such container: aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b# Since inspect failed unexpectedly, things are weird, just try to delete the container2022-11-22T13:29:47.224Z [WARN]  (Timer-0)  Container aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b cannot be force removed. Manual removal is required.2022-11-22T13:29:47.224Z [DEBUG] (Timer-0)  Container aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b detailed errorcom.github.dockerjava.api.exception.NotFoundException: Status 404: No such container: aee19890438494eeecbf587b11221198ff199fe29437ecaa466c76156177b63b```
"
44481,1,3271,0,0,0,Hyllegaard,0,"title:Slow overlay network between nodes on different hosts. description:### DescriptionWe currently have two types of environments in which we run docker swarm.One is with VM hosts, on physical networks, running docker nodes.The other is VM hosts, on VLANs, running docker nodes.We are seeing strange behavior from the nodes on VM hosts running on VLANs. This includes very slow network speed, and lots of missing ACK's in network traces.The setup is as follows.We have physical servers with 4 ethernet ports. Two of them are bonded to network A, and the other two are bonded with 3 VLAN's (eg. vlan10, vlan20, vlan30).We have 4 network bridges, 1 that uses network A, the others connect to one VLAN each.Then we have created a number of VM's running ubuntu 20.04, and connected these to the bridges as needed.We currently have 4 different swarm environments, one per network.Each server may have more than one swarm node connected to the same network. Lets say that server1 has two nodes on vlan10, and server2 has one node on vlan10. These form a swarm.The problem is that overlay network communication is very slow between servers, and seems to be having missing packets.This causes problems if we have a single instance of a container, but try to acces it through one of the nodes that are not hosting it. But only if it on a different server.We have tried running some tests with iperf3 that illustrates the problem.Here is the result of running on the overlay network between two nodes on different servers. Very slow connection:iperf3 -c 10.0.5.220 -p 5201Connecting to host 10.0.5.220, port 5201[  5] local 10.0.5.219 port 60532 connected to 10.0.5.220 port 5201[ ID] Interval           Transfer     Bitrate         Retr  Cwnd[  5]   0.00-1.00   sec   108 KBytes   883 Kbits/sec   15   2.73 KBytes       [  5]   1.00-2.00   sec   116 KBytes   952 Kbits/sec   49   2.73 KBytes       [  5]   2.00-3.00   sec   442 KBytes  3.62 Mbits/sec  124   2.73 KBytes       [  5]   3.00-4.00   sec   442 KBytes  3.62 Mbits/sec  122   2.73 KBytes       [  5]   4.00-5.00   sec   442 KBytes  3.62 Mbits/sec  124   2.73 KBytes       [  5]   5.00-6.00   sec   479 KBytes  3.93 Mbits/sec  122   2.73 KBytes       [  5]   6.00-7.00   sec   442 KBytes  3.62 Mbits/sec  124   2.73 KBytes       [  5]   7.00-8.00   sec   479 KBytes  3.93 Mbits/sec  126   2.73 KBytes       [  5]   8.00-9.00   sec   442 KBytes  3.62 Mbits/sec  124   2.73 KBytes       [  5]   9.00-10.00  sec   442 KBytes  3.62 Mbits/sec  122   2.73 KBytes       - - - - - - - - - - - - - - - - - - - - - - - - -[ ID] Interval           Transfer     Bitrate         Retr[  5]   0.00-10.00  sec  3.75 MBytes  3.14 Mbits/sec  1052             sender[  5]   0.00-10.00  sec  3.69 MBytes  3.09 Mbits/sec                  receiverAnd here is the result of running on the overlay network between two nodes on the same server. No problems: iperf3 -c 10.0.5.218 -p 5201Connecting to host 10.0.5.218, port 5201[  5] local 10.0.5.219 port 60124 connected to 10.0.5.218 port 5201[ ID] Interval           Transfer     Bitrate         Retr  Cwnd[  5]   0.00-1.00   sec   775 MBytes  6.50 Gbits/sec  154   1.17 MBytes       [  5]   1.00-2.00   sec   784 MBytes  6.57 Gbits/sec    0   1.54 MBytes       [  5]   2.00-3.00   sec   769 MBytes  6.45 Gbits/sec  104   1.84 MBytes       [  5]   3.00-4.00   sec   771 MBytes  6.47 Gbits/sec  625   1.49 MBytes       [  5]   4.00-5.00   sec   768 MBytes  6.44 Gbits/sec   33   1.81 MBytes       [  5]   5.00-6.00   sec   819 MBytes  6.87 Gbits/sec   64   1.61 MBytes       [  5]   6.00-7.00   sec   808 MBytes  6.77 Gbits/sec   37   1.41 MBytes       [  5]   7.00-8.00   sec   776 MBytes  6.51 Gbits/sec   17   1.25 MBytes       [  5]   8.00-9.00   sec   806 MBytes  6.76 Gbits/sec    0   1.62 MBytes       [  5]   9.00-10.00  sec   826 MBytes  6.93 Gbits/sec   22   1.37 MBytes       - - - - - - - - - - - - - - - - - - - - - - - - -[ ID] Interval           Transfer     Bitrate         Retr[  5]   0.00-10.00  sec  7.72 GBytes  6.63 Gbits/sec  1056             sender[  5]   0.00-10.00  sec  7.71 GBytes  6.63 Gbits/sec                  receiverRunning it between servers on the ""normal"" network also shows normal speed.iperf3 -c 192.168.179.31Connecting to host 192.168.179.31, port 5201[  5] local 192.168.179.30 port 47300 connected to 192.168.179.31 port 5201[ ID] Interval           Transfer     Bitrate         Retr  Cwnd[  5]   0.00-1.00   sec   115 MBytes   962 Mbits/sec   90    790 KBytes[  5]   1.00-2.00   sec   111 MBytes   933 Mbits/sec   45    648 KBytes[  5]   2.00-3.00   sec   112 MBytes   944 Mbits/sec    0    769 KBytes[  5]   3.00-4.00   sec   111 MBytes   933 Mbits/sec   45    629 KBytes[  5]   4.00-5.00   sec   111 MBytes   933 Mbits/sec    0    755 KBytes[  5]   5.00-6.00   sec   112 MBytes   944 Mbits/sec   45    602 KBytes[  5]   6.00-7.00   sec   111 MBytes   933 Mbits/sec    0    731 KBytes[  5]   7.00-8.00   sec   111 MBytes   933 Mbits/sec    0    841 KBytes[  5]   8.00-9.00   sec   112 MBytes   944 Mbits/sec   45    717 KBytes[  5]   9.00-10.00  sec   111 MBytes   933 Mbits/sec    0    827 KBytes- - - - - - - - - - - - - - - - - - - - - - - - -[ ID] Interval           Transfer     Bitrate         Retr[  5]   0.00-10.00  sec  1.09 GBytes   939 Mbits/sec  270             sender[  5]   0.00-10.00  sec  1.09 GBytes   936 Mbits/sec                  receiverAny ideas why this is performing so poorly? If you need any further information, let me know :)### ReproduceCreate swarm on vlan on different physical servers.connection on overlay network is very bad.### Expected behaviorPerformance should approximate the optimal speed on the physical connection### docker version```bashVersion:           20.10.18 API version:       1.41 Go version:        go1.18.6 Git commit:        b40c2f6 Built:             Thu Sep  8 23:11:45 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.18  API version:      1.41 (minimum version 1.12)  Go version:       go1.18.6  Git commit:       e42327a  Built:            Thu Sep  8 23:09:37 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.8  GitCommit:        9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc:  Version:          1.1.4  GitCommit:        v1.1.4-0-g5fd4c4d docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.9.1-docker)  scan: Docker Scan (Docker Inc., v0.17.0)Server: Containers: 22  Running: 8  Paused: 0  Stopped: 14 Images: 11 Server Version: 20.10.18 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: active  NodeID: uds2xoto932ertyb90ux3zgte  Is Manager: true  ClusterID: il89p79hnmzoyjtvk6ivqg4gx  Managers: 3  Nodes: 3  Default Address Pool: 10.0.0.0/8  SubnetSize: 24  Data Path Port: 4789  Orchestration:   Task History Retention Limit: 5  Raft:   Snapshot Interval: 10000   Number of Old Snapshots to Retain: 0   Heartbeat Tick: 1   Election Tick: 10  Dispatcher:   Heartbeat Period: 5 seconds  CA Configuration:   Expiry Duration: 3 months   Force Rotate: 0  Autolock Managers: false  Root Rotation In Progress: false  Node Address: 192.168.179.30  Manager Addresses:   192.168.179.30:2377   192.168.179.31:2377   192.168.179.32:2377 Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.4.0-131-generic Operating System: Ubuntu 20.04.5 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.771GiB Name: swarm-devop1 ID: XXCJ:TGWR:744R:AGXQ:BLMD:XXHK:5HH3:CMRZ:A2FL:P2ZU:N4SI:U4YB Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: API is accessible on http://192.168.209.50:2375 without encryption.         Access to the remote API is equivalent to root access on the host. Refer         to the 'Docker daemon attack surface' section in the documentation for         more information: https://docs.docker.com/go/attack-surface/WARNING: No swap limit support```### Additional Info_No response_
"
44478,1,2131,0,0,0,dainora,0,"title:Docker is not compatible with Almalinux 8 and 9, if Firewall is running. description:### Description![image](https://user-images.githubusercontent.com/3883196/202234600-02a9d857-3d94-4c06-ba39-160382cecd97.png)ried with ALmalinux 8 and 9 same issue.Docker works if firewall is disabled.Docker is not compatible with Firewall, it should be compatible during installation, after OS or firewall reboot.### ReproduceJust enable firewall. :)### Expected behavior_No response_### docker version```bashClient: Docker Engine - CommunityVersion: 20.10.21API version: 1.41Go version: go1.18.7Git commit: baeda1fBuilt: Tue Oct 25 18:02:19 2022OS/Arch: linux/amd64Context: defaultExperimental: trueServer: Docker Engine - CommunityEngine:Version: 20.10.21API version: 1.41 (minimum version 1.12)Go version: go1.18.7Git commit: 3056208Built: Tue Oct 25 18:00:24 2022OS/Arch: linux/amd64Experimental: falsecontainerd:Version: 1.6.9GitCommit: 1c90a442489720eec95342e1789ee8a5e1b9536frunc:Version: 1.1.4GitCommit: v1.1.4-0-g5fd4c4ddocker-init:Version: 0.19.0GitCommit: de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.9.1-docker)  compose: Docker Compose (Docker Inc., v2.12.2)  scan: Docker Scan (Docker Inc., v0.21.0)Server: Containers: 14  Running: 9  Paused: 0  Stopped: 5 Images: 19 Server Version: 20.10.21 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 1c90a442489720eec95342e1789ee8a5e1b9536f runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options:  seccomp   Profile: default  cgroupns Kernel Version: 5.14.0-70.26.1.el9_0.x86_64 Operating System: AlmaLinux 9.0 (Emerald Puma) OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.505GiB Name: dev ID: OGFC:K6SI:J45L:7ACA:3X3H:2P5W:U6NG:EMV7:LQIM:GOLQ:2CH6:CEQ7 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```### Additional Info_No response_
"
44457,1,5637,288,0,0,s4ke,0,"title:overlay networking seems to be broken on Ubuntu 22.04. description:### Descriptionoverlay networking seems to be broken on Ubuntu 22.04### ReproduceCurrently this bug was verified with these (non minimal) steps:1. Change Ubuntu 22.04 VM to use iptables-legacy instead of nftables2. Create a docker swarm on Ubuntu 22.04 with more than one node3. Remove default ingress network, create with encryption turned on4. Set up docker socket proxy using tecnativa/docker-socket-proxy (really just any docker container, but this is easier to reproduce for my case as this is from a real world example)```version: ""3.8""services:  docker_socket_proxy:    image: tecnativa/docker-socket-proxy    volumes:        - /var/run/docker.sock:/var/run/docker.sock    networks:      docker_socket_proxy:        aliases:          - docker.socket.proxy.local    environment:      CONTAINERS: 1      SERVICES: 1      SWARM: 1      NODES: 1      NETWORKS: 1      TASKS: 1      VERSION: 1    deploy:      mode: global      update_config:        order: stop-first        parallelism: 1      rollback_config:        order: stop-first        parallelism: 1      restart_policy:        condition: on-failure      placement:        preferences:          - spread: node.labels.host        constraints:          - node.role==manager            resources:        limits:          cpus: ""0.5""          memory: 256M        reservations:          cpus: ""0.25""          memory: 128Mnetworks:  docker_socket_proxy:    driver: overlay    attachable: true    name: docker_socket_proxy    driver_opts:      encrypted: """"```5. Launch docker container on traefik-public network `docker run --rm -it --network docker_socket_proxy docker sh`6. Run `ping docker.socket.proxy.local` - Works7. Run `DOCKER_HOST=tcp://docker.socket.proxy.local:2375 docker ps` - HangsConsole Output:```/ # ping docker.socket.proxy.localPING docker.socket.proxy.local (10.1.0.2): 56 data bytes64 bytes from 10.1.0.2: seq=0 ttl=64 time=0.586 ms64 bytes from 10.1.0.2: seq=1 ttl=64 time=0.103 ms^C--- docker.socket.proxy.local ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.103/0.344/0.586 ms/ # DOCKER_HOST=tcp://docker.socket.proxy.local:2375 docker pserror during connect: Get ""http://docker.socket.proxy.local:2375/v1.24/containers/json"": dial tcp: lookup docker.socket.proxy.local: Try again/ # DOCKER_HOST=tcp://10.1.0.2:2375 docker psCONTAINER ID   IMAGE                                  COMMAND                  CREATED              STATUS                    PORTS      NAMES61a77209e0ee   docker                                 ""docker-entrypoint.s闂?   About a minute ago   Up About a minute                    jovial_perlman044845395d27   docker:latest                          """"docker-entrypoint.s闂?""   2 minutes ago        Up 2 minutes                         charming_lederberg.1.xsjz289m6c25o3cxkzdenlca81baa4d896d67   traefik:v2.9                           """"/entrypoint.sh trae闂?""   17 minutes ago       Up 17 minutes (healthy)   80/tcp     traefik_public_traefik_ingress.1.16jn4sq73p34r5g9cpfg8f77t7e621a6a8ba6   tecnativa/docker-socket-proxy:latest   """"/docker-entrypoint.闂?""   17 minutes ago       Up 17 minutes             2375/tcp   docker_socket_proxy_docker_socket_proxy.n107s8riublsi1ddqoqgl0ycn.ucly2dtswtx37nt4eihulwnnt/ # ```### Expected behavioroverlay networking should work like 20.04 on 22.04### docker version```bashClient: Docker Engine - Community Version:           20.10.21 API version:       1.41 Go version:        go1.18.7 Git commit:        baeda1f Built:             Tue Oct 25 18:01:58 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.21  API version:      1.41 (minimum version 1.12)  Go version:       go1.18.7  Git commit:       3056208  Built:            Tue Oct 25 17:59:49 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.9  GitCommit:        1c90a442489720eec95342e1789ee8a5e1b9536f runc:  Version:          1.1.4  GitCommit:        v1.1.4-0-g5fd4c4d docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc."
44366,1,4479,300,0,0,joschi,0,"title:20.10.20: Unable to pull postgres:11.2. description:### DescriptionAfter upgrading to Docker Desktop 4.13.0 (89412) with Docker Engine 20.10.20, downloading the `postgres:11.2` image using the [CreateImage](https://docs.docker.com/engine/api/v1.41/#tag/Image/operation/ImageCreate) operation in the Docker API and combining the image name and tag in the `fromImage` parameter is failing with the following error message:```unknown image in /images/create?fromImage=postgres%3A11.2```### Reproduce```# echo -e ""POST /images/create?fromImage=postgres%3A11.2 HTTP/1.0\r\n"" | nc -U /var/run/docker.sockHTTP/1.0 500 Internal Server ErrorContent-Type: text/plain; charset=utf-8X-Content-Type-Options: nosniffDate: Thu, 27 Oct 2022 15:16:25 GMTContent-Length: 65unknown image in /images/create?fromImage=postgres%3A11.2```Similar to how [`docker-java`](https://github.com/docker-java/docker-java) is executing the `pull` action.### Expected behaviorDocker Daemon should download the provided image.This is working with other tags of the same image:```闂?echo -e ""POST /images/create?fromImage=postgres%3A11 HTTP/1.0\r\n"" | nc -U /var/run/docker.sockHTTP/1.0 200 OKApi-Version: 1.41Content-Type: application/jsonDate: Thu, 27 Oct 2022 15:19:46 GMTDocker-Experimental: falseOstype: linuxServer: Docker/20.10.20 (linux){""status"":""Pulling from library/postgres"",""id"":""11""}{""status"":""Pulling fs layer"",""progressDetail"":{},""id"":""45f14b91a40f""}[...]{""status"":""Waiting"",""progressDetail"":{},""id"":""72d72d727faf""}[...]{""status"":""Downloading"",""progressDetail"":{""current"":758,""total"":1663},""progress"":""[======================\u003e                            ]     758B/1.663kB"",""id"":""d076a31c93ca""}[...]^C```It's also working when splitting `fromImage` and `tag` parameters:```闂?echo -e ""POST /images/create?fromImage=postgres&tag=11.2 HTTP/1.0\r\n"" | nc -U /var/run/docker.sockHTTP/1.0 200 OKApi-Version: 1.41Content-Type: application/jsonDate: Thu, 27 Oct 2022 15:22:02 GMTDocker-Experimental: falseOstype: linuxServer: Docker/20.10.20 (linux){""status"":""Pulling from library/postgres"",""id"":""11.2""}[...]^C```Older versions can download the image without any issue (`11.2-alpine` here, but also fails with `11.2`):```HTTP/1.0 200 OKApi-Version: 1.41Content-Type: application/jsonDate: Thu, 27 Oct 2022 15:23:14 GMTDocker-Experimental: falseOstype: linuxServer: Docker/20.10.13 (linux){""status"":""Pulling from library/postgres"",""id"":""11.2-alpine""}{""status"":""Digest: sha256:ac1494b4cd5c0c6a85209e645fbb84ea186b55fa8c3678ef66dd9e4edf2b0195""}{""status"":""Status: Image is up to date for postgres:11.2-alpine""}```### docker version```bashClient: Cloud integration: v1.0.29 Version:           20.10.20 API version:       1.41 Go version:        go1.18.7 Git commit:        9fdeb9c Built:             Tue Oct 18 18:20:35 2022 OS/Arch:           darwin/arm64 Context:           default Experimental:      trueServer: Docker Desktop 4.13.0 (89412) Engine:  Version:          20.10.20  API version:      1.41 (minimum version 1.12)  Go version:       go1.18.7  Git commit:       03df974  Built:            Tue Oct 18 18:18:16 2022  OS/Arch:          linux/arm64  Experimental:     false containerd:  Version:          1.6.8  GitCommit:        9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc:  Version:          1.1.4  GitCommit:        v1.1.4-0-g5fd4c4d docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  buildx: Docker Buildx (Docker Inc., v0.9.1)  compose: Docker Compose (Docker Inc., v2.12.0)  dev: Docker Dev Environments (Docker Inc., v0.0.3)  extension: Manages Docker extensions (Docker Inc., v0.2.13)  sbom: View the packaged-based Software Bill Of Materials (SBOM) for an image (Anchore Inc., 0.6.0)  scan: Docker Scan (Docker Inc., v0.21.0)Server: Containers: 6  Running: 3  Paused: 0  Stopped: 3 Images: 111 Server Version: 20.10.20 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options:  seccomp   Profile: default  cgroupns Kernel Version: 5.15.49-linuxkit Operating System: Docker Desktop OSType: linux Architecture: aarch64 CPUs: 6 Total Memory: 7.765GiB Name: docker-desktop ID: L4O4:PMKL:7KFT:ZO7W:HIYG:I3AU:QUGC:L6IR:WX42:6LN6:WLYJ:6G4J Docker Root Dir: /var/lib/docker Debug Mode: false HTTP Proxy: http.docker.internal:3128 HTTPS Proxy: http.docker.internal:3128 No Proxy: hubproxy.docker.internal Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  hubproxy.docker.internal:5000  127.0.0.0/8 Live Restore Enabled: false```### Additional InfoWe ran into the issue while using https://github.com/revolut-engineering/jooq-plugin which is using [docker-java 3.2.8](https://github.com/docker-java/docker-java/tree/3.2.8).
"
44361,0,3645,2,0,0,secsys-go,0,"title:Crash in config.(*BuilderGCFilter).UnmarshalJSON. description:### DescriptionWe used the Fuzz engine to modify some Test(TestBuilderGC) data, and then the following crash appeared. We hope to get the help of the developer to confirm whether it is a real bug.### ReproducePart of the modified Test Code```go	tempFile := fs.NewFile(t, ""config"", fs.WithContent(`{  ""builder"": {    ""gc"": {      ""enabled"": true,      ""poliCy"": [        {""keepStorage"": ""10GB"", ""filter"": [""unused-for(2200h""]},        {""keepStorage"": ""50GB"", ""filter"": {""unused-for"": {""3300h"": true}}},        {""keepStorage"": ""100GB"", ""all"": true}      ]    }  }}`))	defer tempFile.Remove()	configFile := tempFile.Path()	cfg, err := MergeDaemonConfigurations(&Config{}, nil, configFile) //crash in MergeDaemonConfigurations```Crash Log```panic: runtime error: index out of range [1] with length 1 [recovered]	panic: runtime error: index out of range [1] with length 1goroutine 101 [running]:testing.tRunner.func1.2({0x11f1120, 0xc000294cc0})	/home/gogen/.local/go/src/testing/testing.go:1209 +0x24etesting.tRunner.func1()	/home/gogen/.local/go/src/testing/testing.go:1212 +0x218panic({0x11f1120, 0xc000294cc0})	/home/gogen/.local/go/src/runtime/panic.go:1038 +0x215github.com/docker/docker/daemon/config.(*BuilderGCFilter).UnmarshalJSON(0xc000298108, {0xc0002a3870, 0x14, 0x190})	/home/gogen/workspace/gowork/src/topproj/moby/daemon/config/builder.go:50 +0x338encoding/json.(*decodeState).array(0xc0002fe090, {0x1175160, 0xc000298108, 0x1a2})	/home/gogen/.local/go/src/encoding/json/decode.go:506 +0x3f6encoding/json.(*decodeState).value(0xc0002fe090, {0x1175160, 0xc000298108, 0xc0002a3867})	/home/gogen/.local/go/src/encoding/json/decode.go:363 +0x7eencoding/json.(*decodeState).object(0xc0002fe090, {0x11b3a40, 0xc000298100, 0xb})	/home/gogen/.local/go/src/encoding/json/decode.go:774 +0xca5encoding/json.(*decodeState).value(0xc0002fe090, {0x11b3a40, 0xc000298100, 0x1})	/home/gogen/.local/go/src/encoding/json/decode.go:373 +0x45encoding/json.(*decodeState).array(0xc0002fe090, {0x10f5700, 0xc000b58960, 0x1d2})	/home/gogen/.local/go/src/encoding/json/decode.go:561 +0x626encoding/json.(*decodeState).value(0xc0002fe090, {0x10f5700, 0xc000b58960, 0xc0002a383b})	/home/gogen/.local/go/src/encoding/json/decode.go:363 +0x7eencoding/json.(*decodeState).object(0xc0002fe090, {0x11b3980, 0xc000b58958, 0x1192f01})	/home/gogen/.local/go/src/encoding/json/decode.go:774 +0xca5encoding/json.(*decodeState).value(0xc0002fe090, {0x11b3980, 0xc000b58958, 0xc0002a3816})	/home/gogen/.local/go/src/encoding/json/decode.go:373 +0x45encoding/json.(*decodeState).object(0xc0002fe090, {0x1192f60, 0xc000b58958, 0x1a6af01})	/home/gogen/.local/go/src/encoding/json/decode.go:774 +0xca5encoding/json.(*decodeState).value(0xc0002fe090, {0x1192f60, 0xc000b58958, 0x7})	/home/gogen/.local/go/src/encoding/json/decode.go:373 +0x45encoding/json.(*decodeState).object(0xc0002fe090, {0x120bfc0, 0xc000b58580, 0x886305})	/home/gogen/.local/go/src/encoding/json/decode.go:774 +0xca5encoding/json.(*decodeState).value(0xc0002fe090, {0x120bfc0, 0xc000b58580, 0x90})	/home/gogen/.local/go/src/encoding/json/decode.go:373 +0x45encoding/json.(*decodeState).unmarshal(0xc0002fe090, {0x120bfc0, 0xc000b58580})	/home/gogen/.local/go/src/encoding/json/decode.go:180 +0x1deencoding/json.Unmarshal({0xc0002a3800, 0x7f609b0b0c00, 0x857d50}, {0x120bfc0, 0xc000b58580})	/home/gogen/.local/go/src/encoding/json/decode.go:107 +0x125github.com/docker/docker/daemon/config.getConflictFreeConfiguration({0xc0002942d0, 0xc000b58000}, 0x0)	/home/gogen/workspace/gowork/src/topproj/moby/daemon/config/config.go:473 +0x405github.com/docker/docker/daemon/config.MergeDaemonConfigurations(0x1390f08, 0xc000882820, {0xc0002942d0, 0x6})	/home/gogen/workspace/gowork/src/topproj/moby/daemon/config/config.go:393 +0x33```### Expected behavior-### docker version```bash-```### docker info```bash-```### Additional InfoImplemented only with go test
"
44346,0,2761,18,0,0,luismulinari,0,"title:dockerd max-concurrent-uploads/download is not working according to the documentation. description:### DescriptionAccording to the [documentation](https://docs.docker.com/engine/reference/commandline/dockerd/#daemon), max-concurrent-uploads/download is set for ***each*** push/pull command:>      --max-concurrent-uploads int            Set the max concurrent uploads for each push (default 5)>      --max-download-attempts int             Set the max download attempts for each pull (default 5)However, it seems the max-concurrent-uploads/download is a 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墰缁犳棃鏌嶈閹€榖al闂?limit across all the transfers running on the dockerd daemon:* https://github.com/moby/moby/blob/v20.10.20/distribution/xfer/transfer.go#L282-L301* https://github.com/moby/moby/blob/v20.10.20/distribution/xfer/transfer.go#L321-L393So, if I'm running multiple docker pushes/pulls in parallel, the max concurrent uploads/downloads will be respected across all the pushes/pulls, instead of being for each push/pull.It seems like the documentation is wrong, or there is a bug?### Reproducehttps://user-images.githubusercontent.com/33168/197350928-2649b864-7a6c-4eeb-a2dc-fb23e26df9c6.mov### Expected behavior_No response_### docker version```bashClient: Cloud integration: v1.0.29 Version:           20.10.20 API version:       1.41 Go version:        go1.18.7 Git commit:        9fdeb9c Built:             Tue Oct 18 18:20:35 2022 OS/Arch:           darwin/amd64 Context:           default Experimental:      trueServer: Docker Desktop 4.13.0 (89412) Engine:  Version:          20.10.20  API version:      1.41 (minimum version 1.12)  Go version:       go1.18.7  Git commit:       03df974  Built:            Tue Oct 18 18:18:35 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.8  GitCommit:        9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc:  Version:          1.1.4  GitCommit:        v1.1.4-0-g5fd4c4d docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  buildx: Docker Buildx (Docker Inc., v0.9.1)  compose: Docker Compose (Docker Inc., v2.12.0)  dev: Docker Dev Environments (Docker Inc., v0.0.3)  extension: Manages Docker extensions (Docker Inc., v0.2.13)  sbom: View the packaged-based Software Bill Of Materials (SBOM) for an image (Anchore Inc., 0.6.0)  scan: Docker Scan (Docker Inc., v0.21.0)Server: Containers: 60  Running: 5  Paused: 0  Stopped: 55 Images: 257 Server Version: 20.10.20 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options:  seccomp   Profile: default  cgroupns Kernel Version: 5.15.49-linuxkit Operating System: Docker Desktop OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 7.772GiB Name: docker-desktop ID: JUMX:UP7B:ZRFZ:4IGD:DKZE:EVL3:VMCC:KZ4L:RY42:4WWM:735H:2SYH Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 45  Goroutines: 48  System Time: 2022-10-22T16:34:36.239358203Z  EventsListeners: 4 HTTP Proxy: http.docker.internal:3128 HTTPS Proxy: http.docker.internal:3128 No Proxy: hubproxy.docker.internal Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  hubproxy.docker.internal:5000  127.0.0.0/8 Live Restore Enabled: false```### Additional Info_No response_
"
44343,1,2760,19,0,0,marcpawl-arista,0,"title:Wrong platform used from previous run. description:### DescriptionIf you run an image with --platform, then run the same image again but without --platform, the platform for the first run is used.### Reproduce```bash(docker run --platform=linux/amd64 ubuntu:focal uname -a) && (docker run --platform=linux/arm64 ubuntu:focal uname -a) && (test $(docker run  ubuntu:focal uname -p) == $(uname -p))(docker run --platform=linux/arm64 ubuntu:focal uname -a) && (docker run --platform=linux/amd64 ubuntu:focal uname -a) && (test $(docker run  ubuntu:focal uname -p) == $(uname -p))```One of the two commands will fail on Ubuntu.Setting DOCKER_DEFAULT_PLATFORM makes both commands pass.### Expected behaviorBoth commands should pass,  the default platform should be the system and the last image run should not change the behavior for the next run command.### docker version```bashbsn@jenkins-w4:~$ docker versionClient: Docker Engine - Community Version:           20.10.20 API version:       1.41 Go version:        go1.18.7 Git commit:        9fdeb9c Built:             Tue Oct 18 18:20:19 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.20  API version:      1.41 (minimum version 1.12)  Go version:       go1.18.7  Git commit:       03df974  Built:            Tue Oct 18 18:18:11 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.8  GitCommit:        9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc:  Version:          1.1.4  GitCommit:        v1.1.4-0-g5fd4c4d docker-init:  Version:          0.19.0```### docker info```bashbsn@jenkins-w4:~$ docker infoClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.9.1-docker)Server: Containers: 14  Running: 0  Paused: 0  Stopped: 14 Images: 8 Server Version: 20.10.20 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.15.0-191-generic Operating System: Ubuntu 18.04.6 LTS OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 31.37GiB Name: jenkins-w4 ID: FPZI:LUCF:H2LH:46BL:NH3P:2OPY:KQV2:IGIT:63DM:LSZU:VJGL:P562 Docker Root Dir: /var/lib/docker Debug Mode: false Username: bsnjenkins Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Registry Mirrors:  https://docker-cache.eng.bigswitch.com/ Live Restore Enabled: trueWARNING: No swap limit support```### Additional Info_No response_
"
44301,1,80,267,0,1,WolfgangFahl,0,"title:Setting up docker-ce (5:20.10.19~3-0~ubuntu-focal) ... fails on Ubuntu 20.04 LTS. description:### DescriptionPreparing a Ubuntu 22.04 LTS upgrade fails.I can't update/upgrade or uninstall anything - even a reboot fails.### Reproduceapt-get updateand thenapt-get upgradeorapt-get purge docker-*all fail### Expected behavior- not hanging/proper error message- available FAQ/Documentation on how to fix the issue### docker version```bashdocke version does not work anymore```### docker info```bashdocker info does not work anymore```### Additional Info_No response_
"
44249,1,2413,0,0,0,enool,0,"title:Interrupt signal is not proxied and ""docker run"" terminates. description:### DescriptionInterrupt signal (SIGINT) is not proxied to the container when issued withkill() to ""docker run"".  Run command is terminated by the signal and containeris left running in the background.This issue is seen on Linux when running a container attached with --tty (-t)option and INT signal is sent from an external process with kill(). It's notabout CTRL+c INT that does indeed work as expected.Embedding ""docker run"" in to software like editors is a bit tricky because ofthis. For example, emacs compilation uses a tty by default, and it alsosends INT kill() instead of CTRL+c to the process group on ""kill-compilation"".Pull request for moby/term: https://github.com/moby/term/pull/31### Reproducedocker run -it --rm --sig-proxy --init alpine sleep 3600pkill --signal INT -f docker.*run.*sleepDocker run dies and container is left behind### Expected behaviorSignal is proxied from docker run and container dies### docker version```bashClient: Version:           20.10.17 API version:       1.41 Go version:        go1.19.1 Git commit:        100c70180f Built:             Mon Sep 26 21:49:37 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          20.10.17  API version:      1.41 (minimum version 1.12)  Go version:       go1.19.1  Git commit:       a89b84221c  Built:            Sat Oct  1 23:04:37 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.6.8  GitCommit:        9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc:  Version:          1.1.3  GitCommit:        6724737f999df9ee0d8ca5c6d7b81f97adc34374 docker-init:  Version:          0.19.0  GitCommit:        de40ad007797e0dcd8b7126f27bb87401d224240```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  buildx: Docker Buildx (Docker Inc., v0.9.1)Server: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 1 Server Version: 20.10.17 Storage Driver: fuse-overlayfs Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runtime.v1.linux runc io.containerd.runc.v2 Default Runtime: runc Init Binary: docker-init containerd version: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc version: 6724737f999df9ee0d8ca5c6d7b81f97adc34374 init version: de40ad007797e0dcd8b7126f27bb87401d224240 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.19.5-gentoo Operating System: Gentoo Linux OSType: linux Architecture: x86_64 CPUs: 24 Total Memory: 31.29GiB Name: deski ID: AMHJ:VETK:BOAC:BVC3:RTZ2:LQJA:4H4H:IHA3:U3ZQ:23GQ:XNKE:YFCA Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No cpu cfs quota supportWARNING: No cpu cfs period supportWARNING: No blkio throttle.read_bps_device supportWARNING: No blkio throttle.write_bps_device supportWARNING: No blkio throttle.read_iops_device supportWARNING: No blkio throttle.write_iops_device support```### Additional Info_No response_
"
44209,1,3108,0,0,0,psaini79,0,"title:Unable to read symlink inside the container. description:### DescriptionUnable to read symlink inside the containers. We are using pwdx command to read the cwd directory of the process and it is mapped through a symlink inside the /proc/ But when we execute pwdx, we are getting permission denied error. We tried giving sys_admin capability and it seems to be working. However, we can't give such a broad capability. Do we know what capability is required to read the softlinks inside the containers: ### Reproduce1.  Docker Run command```docker create -t -i \  --hostname test1 \  --dns-search=""example.info"" \  --privileged=false  \  --cap-add=SYS_NICE \  --cap-add=SYS_RESOURCE \  --cap-add=NET_ADMIN \  --restart=always \  --tmpfs=/run \  --ulimit rtprio=99  \  --name test1 \   oraclelinux:7``` 2. Exec to the container and execute the steps mentioned below:```docker exec -i -t test1 /bin/bashuseradd test1su - test1vi /home/test1/test.sh#!/bin/bashwhile true; doecho ""Hi""sleep 30done```3. Start the script```nohup ./test.sh &```4. Grab the process as test user```[test1@test1 ~]$ ps -ef | grep test.sh test1       56    35  0 03:43 pts/1    00:00:00 /bin/bash ./test.sh[test1@test1 ~]$ pwdx 5656: /home/test1[test1@test1 ~]$ ls -ltr /proc/56/cwdlrwxrwxrwx 1 test1 test1 0 Sep 28 03:44 /proc/56/cwd -> /home/test1[test1@test1 ~]$ ```5. Exit from the root user and test it as a root user```[root@test1 ~]# pwdx 5656: Permission denied[root@test1 ~]# ls -ltr /proc/56/cwdls: cannot read symbolic link /proc/56/cwd: Permission denied.   <<< Permission denied errorlrwxrwxrwx 1 test1 test1 0 Sep 28 03:44 /proc/56/cwd[root@test1 ~]# ```### Expected behavior`docker stop test1; docker rm test1`### docker version```bash[root@docker01 bldc]# docker versionClient: Docker Engine - Community Version:           19.03.11-ol API version:       1.40 Go version:        go1.16.2 Git commit:        9bb540d Built:             Fri Jul 23 01:33:55 2021 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.11-ol  API version:      1.40 (minimum version 1.12)  Go version:       go1.16.2  Git commit:       9bb540d  Built:            Fri Jul 23 01:32:08 2021  OS/Arch:          linux/amd64  Experimental:     false  Default Registry: docker.io containerd:  Version:          v1.4.8  GitCommit:        7eba5930496d9bbe375fdf71603e610ad737d2b2 runc:  Version:          1.0.2  GitCommit:        2856f01 docker-init:  Version:          0.18.0  GitCommit:        fec3683[root@docker01 bldc]#```### docker info```bash[root@docker01 bldc]# docker infoClient: Debug Mode: falseServer: Containers: 3  Running: 2  Paused: 0  Stopped: 1 Images: 38 Server Version: 19.03.11-ol Storage Driver: overlay2  Backing Filesystem: xfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7eba5930496d9bbe375fdf71603e610ad737d2b2 runc version: 2856f01 init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 5.4.17-2102.201.3.el7uek.x86_64 Operating System: Oracle Linux Server 7.9 OSType: linux Architecture: x86_64 CPUs: 6 Total Memory: 31.08GiB Name: docker01 ID: 5EUB:42QG:25UN:ASIE:Q7ML:JJSB:736R:5HQS:33LT:IY46:XZK2:RRAP Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseRegistries:```### Additional Info_No response_
"
44199,1,2054,1,0,0,mdecandia81,0,"title:dockerd hangup while running docker commands: eg. docker ps, docker version. description:### Descriptiondocker commands hang up with infinite wait or several minutes wait. To investigate the issue, I tryed to run  curl --silent -XGET --unix-socket /run/docker.sock http://localhost/versionand reply was not coming for minutes.I triggered the stack dump with  kill -s SIGUSR1 DAEMON_PID and got the traces in attachement [goroutine-stacks-2022-09-27T103519Z.log](https://github.com/moby/moby/files/9654021/goroutine-stacks-2022-09-27T103519Z.log)After SIGUSR1 was sent, the daemon comes out from hanging condition and continues working correctly### Reproducedocker ps hanged updocker version hanged up### Expected behaviordocker version should exit soon with docker version### docker version```bashClient: Docker Engine - Community Version:           19.03.13 API version:       1.40 Go version:        go1.13.15 Git commit:        4484c46 Built:             Wed Sep 16 17:03:40 2020 OS/Arch:           linux/arm64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.13  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       4484c46  Built:            Wed Sep 16 17:02:11 2020  OS/Arch:          linux/arm64  Experimental:     false containerd:  Version:          1.3.7  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```### docker info```bashClient: Debug Mode: falseServer: Containers: 16  Running: 15  Paused: 0  Stopped: 1 Images: 20 Server Version: 19.03.13 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 8fba4e9a7d01810a393d5d25a3621dc101981175 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 5.4.213+ Operating System: Ubuntu 20.04.4 LTS OSType: linux Architecture: aarch64 CPUs: 4 Total Memory: 3.625GiB Name: OTN ID: 65SE:G35T:TXVW:AZUR:Y6FC:4U7W:EBF6:HZER:MJ4A:3TKU:VH7B:A5OB Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  0.0.0.0/0  ::/0  127.0.0.0/8 Live Restore Enabled: trueWARNING: No swap limit support```### Additional Info_No response_
"
44185,1,2888,15,0,0,henres,0,"title:[AWSLOGS] Working when setup in docker-compose file but not in docker daemon.json. description:### DescriptionHello everyone, thanks in advance for your help !The server is installed on an Debian EC2. The role attached to the server have the right to write on cloudwatch (It works for a docker-compose.yaml on the same machine).But when I try to set up the deamon for global log on the machine, it didn't work.I don't know what to dodaemon.json:```{  ""log-driver"": ""awslogs"",  ""log-opts"": {    ""awslogs-region"": ""eu-west-3"",    ""awslogs-group"": ""docker"",    ""awslogs-stream"": ""my-service""   }}```docker-compose.yaml:```        logging:            driver: awslogs            options:                awslogs-region: ""eu-west-3""                awslogs-group: ""docker""                awslogs-stream: ""my-service""```### Reproducevim /etc/docker/daemon.json```{  ""log-driver"": ""awslogs"",  ""log-opts"": {    ""awslogs-region"": ""eu-west-3"",    ""awslogs-group"": ""docker"",    ""awslogs-stream"": ""my-service""   }}```service docker restart### Expected behaviorWhen i set up awslogs in docker daemon on an EC2 machine, I should be seeing logs in cloudwatch.### docker version```bashClient: Docker Engine - Community Version:           20.10.17 API version:       1.41 Go version:        go1.17.11 Git commit:        100c701 Built:             Mon Jun  6 23:03:17 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.17  API version:      1.41 (minimum version 1.12)  Go version:       go1.17.11  Git commit:       a89b842  Built:            Mon Jun  6 23:01:23 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.6  GitCommit:        10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc:  Version:          1.1.2  GitCommit:        v1.1.2-0-ga916309 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.8.2-docker)  compose: Docker Compose (Docker Inc., v2.6.0)  scan: Docker Scan (Docker Inc., v0.17.0)Server: Containers: 67  Running: 31  Paused: 0  Stopped: 36 Images: 48 Server Version: 20.10.17 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: awslogs Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: 10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc version: v1.1.2-0-ga916309 init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default  cgroupns Kernel Version: 5.10.0-18-cloud-amd64 Operating System: Debian GNU/Linux 11 (bullseye) OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 15.45GiB Name: ip-172-31-36-99 ID: J7AF:DYNH:QETT:KX5V:XPBZ:HKUO:SK4U:65HT:VBZU:PF3S:VTOS:7VGU Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```### Additional Info_No response_
"
44178,1,2999,0,0,0,paulmey,0,"title:20.10.18 no longer accepts HTTP/1.11 requests           6/2闂傚倸鍊风欢锟犲窗濞戞娑㈠礋椤旇桨姹? description:### DescriptionWe have a .NET core application that uses [Docker.DotNet](https://github.com/dotnet/Docker.DotNet), which for some reason generates HTTP/1.11 requests. This worked fine with all previous versions, but since 20.10.18 these requests are rejected with `400 Bad Request`, as soon as the first line of the request is sent.### ReproduceOn 20.10.17, this would work:```# nc -U /run/docker.sockGET /images/vmagent:0.2.2022092123/json HTTP/1.11User-Agent: Docker.DotNetHost: docker.sock:80Connection: closeHTTP/1.1 404 Not FoundApi-Version: 1.41Content-Type: application/jsonDocker-Experimental: falseOstype: linuxServer: Docker/20.10.17+azure-1 (linux)Date: Thu, 22 Sep 2022 10:35:42 GMTContent-Length: 91Connection: close{""message"":""no such image: vmagent:0.2.2022092123: No such image: vmagent:0.2.2022092123""}```But on 20.10.18:```# nc -U /run/docker.sockGET /images/vmagent:0.2.2022092123/json HTTP/1.11HTTP/1.1 400 Bad RequestContent-Type: text/plain; charset=utf-8Connection: close400 Bad Request```### Expected behavior_No response_### docker version```bash# docker versionClient: Version:           20.10.18+azure-1 API version:       1.41 Go version:        go1.18.6 Git commit:        b40c2f6b5deeb11ac6c485c940865ee40664f0f0 Built:             Thu Sep  8 08:19:02 UTC 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          dev  API version:      1.41 (minimum version 1.12)  Go version:       go1.18.6  Git commit:       e42327a6d3  Built:            Thu Sep 22 11:25:21 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.5.13+azure-1  GitCommit:        a17ec496a95e55601607ca50828147e8ccaeebf1 runc:  Version:          1.1.4  GitCommit:        5fd4c4d144137e991c4acebb2146ab1483a97925 docker-init:  Version:          0.19.0  GitCommit:```### docker info```bash# docker infoClient: Context:    default Debug Mode: false Plugins:  buildx: Docker Buildx (Docker Inc., 0.9.1+azure-1)Server: Containers: 7  Running: 6  Paused: 0  Stopped: 1 Images: 16 Server Version: dev Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: a17ec496a95e55601607ca50828147e8ccaeebf1 runc version: 5fd4c4d144137e991c4acebb2146ab1483a97925 init version: Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.4.0-1091-azure Operating System: Ubuntu 18.04.6 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 15.7GiB Name: aded90e730ef ID: SIV3:EQES:FQK6:ZJJI:KYL2:XFFP:QABH:6KML:APUX:Z5FX:7FCH:ZALG Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 71  Goroutines: 78  System Time: 2022-09-22T11:56:44.949555787Z  EventsListeners: 1 Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: true```### Additional InfoBecause the daemon does not even wait for the rest of the request headers before returning Bad Request, I suspect the change is somewhere down in the HTTP stack and not in moby itself. However, the result is a non-functional client that was functional before.
"
44172,1,3021,0,0,0,DatalovePython,0,"title:docker swarm sometimes can't open service port as expected. description:### Descriptiondocker swarm **sometimes** can't open port as **expected**For the most part, it's healthy, whether it's listening on the host or iptables rules.But both a virtual machine or a physical machine, if I restart the Docker engine enough times, this may happen.**the service mode**[#](shell:)  docker service inspect --format='{{.Endpoint.Ports}}' ntp[{ udp 123 123 ingress}]the service use overlay ingress network**in most situation:**[#](shell:) netstat -lnup|grep 123udp6       0      0 :::123                  :::*                                2064/dockerd  [#](shell:) iptables -t nat -S |grep 123-A DOCKER-INGRESS -p udp -m udp --dport 123 -j DNAT --to-destination xx.xx.xx.xx:123**howerver sometimes error happen:**[#](shell:) netstat -lnup|grep 123return nothing, it looks like not listen socket on the host[# ](shell:)iptables -t nat -S |grep 123return nothing,it looks like not write iptables rule **Note that this error situation does not heal itself**### Reproduce1. restart docker2. wait sometime until all service is healthy and stable3. check the service port and  iptables rule is health or not4. if health ,restart docker againmy test restart docker about 200 times cant reproduce the situation.### Expected behavior**the service mode**[# ](shell:)docker service inspect --format='{{.Endpoint.Ports}}' ntp[{ udp 123 123 ingress}][# ](shell:)netstat -lnup|grep 123udp6       0      0 :::123                  :::*                                2064/dockerd  [#](shell:)iptables -t nat -S |grep 123-A DOCKER-INGRESS -p udp -m udp --dport 123 -j DNAT --to-destination xx.xx.xx.xx:123### docker version```bashClient: Docker Engine - Community Version:           19.03.08 API version:       1.40 Go version:        go1.12.17 Git commit:        19.03.08 Built:             Tue Feb  2 03:29:24 2021 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.08  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.17  Git commit:       19.03.08  Built:            Tue Feb  2 03:26:02 2021  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.6  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb runc:  Version:          1.0.0-rc8  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f docker-init:  Version:          0.18.0  GitCommit:        fec3683```### docker info```bashClient: Debug Mode: falseServer: Containers: 36  Running: 7  Paused: 0  Stopped: 29 Images: 11 Server Version: 19.03.08 Storage Driver: overlay2  Backing Filesystem: xfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: active  NodeID: 3jxr9ixxxxxxxxxxxxxxx  Is Manager: true  ClusterID: sp1uxxxxxxxxxxxxxxx  Managers: 2  Nodes: 2  Default Address Pool: xx.xx.xx.xx/24    SubnetSize: 24  Data Path Port: 47xx  Orchestration:   Task History Retention Limit: 5  Raft:   Snapshot Interval: 10000   Number of Old Snapshots to Retain: 0   Heartbeat Tick: 1   Election Tick: 10  Dispatcher:   Heartbeat Period: 5 seconds  CA Configuration:   Expiry Duration: 100 years   Force Rotate: 0  Autolock Managers: false  Root Rotation In Progress: false  Node Address:  xxx.xxx.xxx.248  Manager Addresses:   xxx.xxx.xxx.113:2377    xxx.xxx.xxx.248:2377 Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.10.0-xxx.x86_64 Operating System: xxxxxx OSType: linux Architecture: x86_64 CPUs: 17 Total Memory: 62.29GiB Name: xxx ID:xxx Docker Root Dir: /var/lib/xxx Debug Mode: true  File Descriptors: 104  Goroutines: 305  System Time: 2022-09-20T14:42:53.222571266  EventsListeners: 7 Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: Running Swarm in a two-manager configuration. This configuration provides         no fault tolerance, and poses a high risk to lose control over the cluster.         Refer to https://docs.docker.com/engine/swarm/admin_guide/ to configure the         Swarm for fault-tolerance.```### Additional Info_No response_
"
44161,1,2905,12,0,0,m0ddixx,0,"title:api: filter map doesn't recognize 'reference' attribute. description:### DescriptionI stumbled across a weird bug while using the Docker.Dotnet API Client.While debugging i found that just passing the simple request `http://localhost:2375/images/json?all=1&filters={%22reference%22:{%22postgres:11.14%22:true}}` results into this error response:```json{""message"":""invalid filter 'reference'""}```Since the request looks valid from the specification, I think there must be something wrong with parsing the filter attributes.### Reproduce1. form a image list request with a reference filter like `http://localhost:2375/images/json?all=1&filters={%22reference%22:{%22postgres:11.14%22:true}}`### Expected behaviorThe request should output a valid JSON list of images with the specified filter.### docker version```bashClient: Cloud integration: v1.0.29 Version:           20.10.17 API version:       1.41 Go version:        go1.17.11 Git commit:        100c701 Built:             Mon Jun  6 23:09:02 2022 OS/Arch:           windows/amd64 Context:           default Experimental:      trueServer: Docker Desktop 4.12.0 (85629) Engine:  Version:          22.06.0-beta.0-372-gd3bb8227ce.m  API version:      1.43 (minimum version 1.12)  Go version:       go1.18.4  Git commit:       d3bb8227ce  Built:            Thu Aug 25 16:48:56 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.8  GitCommit:        9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc:  Version:          1.1.4  GitCommit:        v1.1.4-0-g5fd4c4d docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  buildx: Docker Buildx (Docker Inc., v0.9.1)  compose: Docker Compose (Docker Inc., v2.10.2)  extension: Manages Docker extensions (Docker Inc., v0.2.9)  sbom: View the packaged-based Software Bill Of Materials (SBOM) for an image (Anchore Inc., 0.6.0)  scan: Docker Scan (Docker Inc., v0.19.0)Server: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 0 Server Version: 22.06.0-beta.0-372-gd3bb8227ce.m Storage Driver: stargz  driver-type: io.containerd.snapshotter.v1 Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 runc Default Runtime: runc Init Binary: docker-init containerd version: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options:  seccomp   Profile: builtin Kernel Version: 5.10.102.1-microsoft-standard-WSL2 Operating System: Docker Desktop OSType: linux Architecture: x86_64 CPUs: 20 Total Memory: 24.82GiB Name: docker-desktop ID: 2731c276-4d01-4168-b7b2-6214cca7bfdb Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 43  Goroutines: 47  System Time: 2022-09-21T10:53:43.35399671Z  EventsListeners: 4 HTTP Proxy: http.docker.internal:3128 HTTPS Proxy: http.docker.internal:3128 No Proxy: hubproxy.docker.internal Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  hubproxy.docker.internal:5000  127.0.0.0/8 Live Restore Enabled: falseWARNING: No blkio throttle.read_bps_device supportWARNING: No blkio throttle.write_bps_device supportWARNING: No blkio throttle.read_iops_device supportWARNING: No blkio throttle.write_iops_device support```### Additional Info_No response_
"
44157,1,1865,0,0,0,nthwyatt,0,"title:20.10.18 upgrade fails to run hello-world. description:### DescriptionUpgrade docker 20.10.17 to 20.10.18 causes ""docker run hello-world"" to fail.Got:# docker run hello-worlddocker: Error response from daemon: operation not supported.See 'docker run --help'.### Reproduce1. docker run hello-world2. Response:`docker: Error response from daemon: operation not supported.See 'docker run --help'.`### Expected behavior`Hello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the ""hello-world"" image from the Docker Hub.    (amd64) 3. The Docker daemon created a new container from that image which runs the    executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it    to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/`### docker version```bashClient: Version:           20.10.18 API version:       1.41 Go version:        go1.19 Git commit: Built:             Mon Sep 19 15:44:50 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          20.10.18  API version:      1.41 (minimum version 1.12)  Go version:       go1.19  Git commit:       e42327a  Built:            Mon Sep 19 15:45:12 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.6.8  GitCommit:        9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc:  Version:          1.1.4  GitCommit:        5fd4c4d144137e991c4acebb2146ab1483a97925```### docker info```bashClient: Context:    default Debug Mode: falseServer: Containers: 3  Running: 0  Paused: 0  Stopped: 3 Images: 6 Server Version: 20.10.18 Storage Driver: vfs Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc version: 5fd4c4d144137e991c4acebb2146ab1483a97925 init version: N/A Security Options:  seccomp   Profile: default Kernel Version: 5.10.82 Operating System: CRUX OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.49GiB Name: green ID: GS4P:SAWI:PQZO:OAWQ:AXTY:M5JC:TCP3:KSVA:UVPO:YHWZ:2QV2:44FD Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```### Additional Info`# docker image lsREPOSITORY    TAG       IMAGE ID       CREATED         SIZEcruxcore      latest    48ce1285250b   21 hours ago    645MBhello-world   latest    feb5d9fea6a5   12 months ago   13.3kB`trying to create a new image gives a similar error:`Sending build context to Docker daemon  155.5MBStep 1/6 : FROM scratch --->Step 2/6 : ADD crux-docker-image.xz / ---> 3cb35d968538Step 3/6 : ADD cruxcore-root.tar.gz /rootfailed to create rwlayer: operation not supported`
"
44155,1,3007,3,0,0,mengyuqiao,0,"title:Cannot run hello-world after fresh installation. description:### DescriptionIt worked a few months ago. But After I downloaded rshim for my Bluefield-2, docker cannot work anymore. I tried reinstalling docker but still got the same error. I also tried to stop the rshim service but didn't help.```docker: Error response from daemon: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: can't get final child's PID from pipe: EOF: unknown.ERRO[0000] error waiting for container: context canceled```### Reproduce1. docker run hello-world### Expected behaviorrun container successfully### docker version```bashClient: Docker Engine - Community Version:           20.10.18 API version:       1.41 Go version:        go1.18.6 Git commit:        b40c2f6 Built:             Thu Sep  8 23:11:45 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.18  API version:      1.41 (minimum version 1.12)  Go version:       go1.18.6  Git commit:       e42327a  Built:            Thu Sep  8 23:09:37 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.8  GitCommit:        9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc:  Version:          1.1.4  GitCommit:        v1.1.4-0-g5fd4c4d docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.9.1-docker)  compose: Docker Compose (Docker Inc., v2.10.2)  scan: Docker Scan (Docker Inc., v0.17.0)Server: Containers: 36  Running: 0  Paused: 0  Stopped: 36 Images: 4 Server Version: 20.10.18 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.4.0-124-generic Operating System: Ubuntu 20.04.5 LTS OSType: linux Architecture: x86_64 CPUs: 64 Total Memory: 125.6GiB Name: kiwi ID: KT6L:4UVB:XX52:SJLN:J5PR:P7PQ:7ACW:CMUX:FNU3:Z42B:YFCO:6VB3 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```### Additional InfoUbuntu Version```NAME=""Ubuntu""VERSION=""20.04.5 LTS (Focal Fossa)""ID=ubuntuID_LIKE=debianPRETTY_NAME=""Ubuntu 20.04.5 LTS""VERSION_ID=""20.04""HOME_URL=""https://www.ubuntu.com/""SUPPORT_URL=""https://help.ubuntu.com/""BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""VERSION_CODENAME=focalUBUNTU_CODENAME=focal```
"
44149,1,3462,5,0,1,carlfriess,0,"title:`ContainerExecAttach` fails to connect when using TLS connection to docker daemon. description:### DescriptionWhen calling [`ContainerExecAttach`](https://pkg.go.dev/github.com/docker/docker/client#Client.ContainerExecAttach) with a client connected to an HTTPS socket, it fails with the following error:```cannot connect to the Docker daemon. Is 'docker daemon' running on this host?: dial https: unknown network https```This is because for a TLS configuration the [`Client.Dialer`](https://github.com/moby/moby/blob/e42327a6d3c55ceda3bd5475be7aae6036d02db3/client/client.go#L298) function will fall back to [`fallbackDial`](https://github.com/moby/moby/blob/e42327a6d3c55ceda3bd5475be7aae6036d02db3/client/hijack.go#L54) even if [`client. WithDialContext`](https://github.com/moby/moby/blob/e42327a6d3c55ceda3bd5475be7aae6036d02db3/client/options.go#L68) was used. [`fallbackDial`](https://github.com/moby/moby/blob/e42327a6d3c55ceda3bd5475be7aae6036d02db3/client/hijack.go#L54) calls `tls.Dial` passing `""https""` as the network due to this:https://github.com/moby/moby/blob/e42327a6d3c55ceda3bd5475be7aae6036d02db3/client/options.go#L86The network argument should be set to `""tcp""`.### ReproduceThe following code fails:```gocli, err := client.NewClientWithOpts(	client.WithHost(""https://example.com:2376""),	client.WithTLSClientConfig(""ca.pem"", ""cert.pem"", ""key.pem""),	client.WithAPIVersionNegotiation())if err != nil {	log.Fatalln(err)}// ...con, err := cli.ContainerExecAttach(context.Background(), ""..."", types.ExecStartCheck{})if err != nil {	log.Fatalln(err)}```The following hack sets the `Client.proto` field to `""tcp""` and fixes the issue:```gocli, err := client.NewClientWithOpts(	client.WithHost(""https://example.com:2376""),	client.WithTLSClientConfig(""ca.pem"", ""cert.pem"", ""key.pem""),	client.WithAPIVersionNegotiation())if err != nil {	log.Fatalln(err)}// cli.proto = ""tcp""ptrCli := unsafe.Pointer(cli)ptrCliProto := (*string)(unsafe.Pointer(uintptr(ptrCli) + 2*unsafe.Sizeof("""")))*ptrCliProto = ""tcp""// ...con, err := cli.ContainerExecAttach(context.Background(), ""..."", types.ExecStartCheck{})if err != nil {	log.Fatalln(err)}```### Expected behavior`ContainerExecAttach` should not return an error.### docker version```bashClient: Cloud integration: v1.0.29 Version:           20.10.17 API version:       1.41 Go version:        go1.17.11 Git commit:        100c701 Built:             Mon Jun  6 23:04:45 2022 OS/Arch:           darwin/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.17  API version:      1.41 (minimum version 1.12)  Go version:       go1.17.11  Git commit:       a89b842  Built:            Mon Jun  6 23:01:03 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.8  GitCommit:        9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc:  Version:          1.1.4  GitCommit:        v1.1.4-0-g5fd4c4d docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  buildx: Docker Buildx (Docker Inc., v0.9.1)  compose: Docker Compose (Docker Inc., v2.10.2)  extension: Manages Docker extensions (Docker Inc., v0.2.9)  sbom: View the packaged-based Software Bill Of Materials (SBOM) for an image (Anchore Inc., 0.6.0)  scan: Docker Scan (Docker Inc., v0.19.0)Server: Containers: 1  Running: 1  Paused: 0  Stopped: 0 Images: 1 Server Version: 20.10.17 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.4.0-125-generic Operating System: Ubuntu 20.04.4 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.741GiB Name: ****.inf.ethz.ch ID: V4OT:OKOF:FAPF:ZUQ7:4WB7:ZNUG:FH7I:OGUI:5GBJ:LX6Q:CYS7:6IOA Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```### Additional Info_No response_
"
44133,1,2612,33,0,0,sm171190,0,"title:Unable to update runc to v1.1.4. description:### DescriptionWith docker/docker v20.10.18, we are unable to build our project which also requires runc v1.1.3 or above![Screenshot from 2022-09-12 12-26-18](https://user-images.githubusercontent.com/45711974/189591669-2b2202e5-8b76-480b-9f54-cfad19442192.png)Apparently, the package is looking for type Device in package configs at Lines 15,27 here https://github.com/moby/moby/blob/v20.10.18/oci/devices_linux.go. However, the struct Device is actaully present in the devices package in runc https://github.com/opencontainers/runc/blob/v1.1.4/libcontainer/devices/device.goThe runc version being used curently is 1.0.0 - rc92. https://github.com/moby/moby/tree/v20.10.18/vendor/github.com/opencontainersFor our project , due to securiy vulnerabilities in runc we need to use runc 1.13 or above. That's conflicting with docker/docker.There was a PR ""updating' the runc version to 1.1.4 https://github.com/moby/moby/pull/44038/filesBut this is only a change on the packaging level. The runc codebase in vendor/ is still on the older version.Is there any plan of updating the runc src version inside docker/docker ? Thanks### Reproducego run main.go### Expected behaviorproject should compile sucessfully### docker version```bashClient: Docker Engine - Community Version:           20.10.17 API version:       1.41 Go version:        go1.17.11 Git commit:        100c701 Built:             Mon Jun  6 23:02:57 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.17  API version:      1.41 (minimum version 1.12)  Go version:       go1.17.11  Git commit:       a89b842  Built:            Mon Jun  6 23:01:03 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.8  GitCommit:        9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc:  Version:          1.1.4  GitCommit:        v1.1.4-0-g5fd4c4d docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  scan: Docker Scan (Docker Inc., v0.17.0)WARNING: Plugin ""/home/saurabh/.docker/cli-plugins/docker-buildx"" is not valid: failed to fetch metadata: fork/exec /home/saurabh/.docker/cli-plugins/docker-buildx: no such file or directoryWARNING: Plugin ""/home/saurabh/.docker/cli-plugins/docker-compose"" is not valid: failed to fetch metadata: fork/exec /home/saurabh/.docker/cli-plugins/docker-compose: no such file or directoryServer: Containers: 9  Running: 3  Paused: 0  Stopped: 6 Images: 2 Server Version: 20.10.17 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.13.0-41-generic Operating System: Ubuntu 20.04.4 LTS OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.33GiB Name: SAURABH-UBUNTU ID: QT35:XHFC:SKNS:4NVM:WYJO:HUYV:BLKC:RIGI:BCHG:TSA7:LLWJ:RWL4 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```### Additional Info_No response_
"
44130,0,3004,9,0,0,aya,0,"title:sysvinit debian script fails to restart docker daemon when it is stopped. description:### DescriptionWhen running`apt-get upgrade` on debian with sysvinit,if docker daemon is stopped and the `DOCKER_SSD_PIDFILE` file does not exist,it fails with following error:```Setting up docker-ce (5:20.10.18~3-0~debian-bullseye) ...invoke-rc.d: initscript docker, action ""restart"" failed.dpkg: error processing package docker-ce (--configure): installed docker-ce package post-installation script subprocess returned error exit status 1Errors were encountered while processing: docker-ceE: Sub-process /usr/bin/dpkg returned an error code (1)```### Reproduce1. /etc/init.d/docker stop2. rm -f /var/run/docker-ssd.pid3. /etc/init.d/docker restart### Expected behaviordocker daemon should be started### docker version```bashClient: Docker Engine - Community Version:           20.10.18 API version:       1.41 Go version:        go1.18.6 Git commit:        b40c2f6 Built:             Thu Sep  8 23:11:11 2022 OS/Arch:           linux/arm64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.18  API version:      1.41 (minimum version 1.12)  Go version:       go1.18.6  Git commit:       e42327a  Built:            Thu Sep  8 23:09:33 2022  OS/Arch:          linux/arm64  Experimental:     false containerd:  Version:          1.6.8  GitCommit:        9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc:  Version:          1.1.4  GitCommit:        v1.1.4-0-g5fd4c4d docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.9.1-docker)Server: Containers: 3  Running: 3  Paused: 0  Stopped: 0 Images: 57 Server Version: 20.10.18 Storage Driver: btrfs  Build Version: Btrfs v5.10.1  Library Version: 102 Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: 9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 runc version: v1.1.4-0-g5fd4c4d init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default  cgroupns Kernel Version: 5.4.88-sunxi64 Operating System: Devuan GNU/Linux 5 (daedalus/ceres) OSType: linux Architecture: aarch64 CPUs: 4 Total Memory: 1.914GiB Name: teres-a64 ID: NPJ4:4W5H:OB7G:SZBC:MTRU:YP7N:C7PG:XVU6:JX2S:GDRM:6ZRH:MDTX Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No memory limit supportWARNING: No swap limit supportWARNING: No cpu cfs quota supportWARNING: No cpu cfs period supportWARNING: No cpu shares supportWARNING: No cpuset supportWARNING: No io.weight supportWARNING: No io.weight (per device) supportWARNING: No io.max (rbps) supportWARNING: No io.max (wbps) supportWARNING: No io.max (riops) supportWARNING: No io.max (wiops) support```### Additional Info_No response_
"
44106,0,3824,284,0,0,vasiliy-ul,0,"title:Wrong directory permissions with btrfs or devicemapper storage drivers. description:### DescriptionHello. We currently see an issue with one of our images. When we run a container, some directories end up to have `0600` permissions. This happens only when docker is configured with either `btrfs` or `devicemapper` storage drivers. When `overlay2` is used, the directories are created with `0755` as expected.The image itself does not define explicitly the permissions for the affected directories. But I guess when unpacking the files, they should be created with defaults `0755` (or at least be consistent no matter what storage driver is in use). Might it be some bug in the unpack code?### ReproduceRun the commands below using docker configured with either `btrfs` or `devicemapper` storage drivers, and observe that `/usr/lib64/qemu-kvm/` has `0600` permissions:```docker run --rm -ti --entrypoint /bin/bash quay.io/kubevirt/virt-launcher:v0.55.0bash-4.4# ls -la /usr/lib64/qemu-kvm/total 272drw------- 1 root root   466 Sep  5 06:12 .dr-xr-xr-x 1 root root 14218 Jan  1  1970 ..-rwxr-xr-x 1 root root 11792 Jan  1  1970 accel-qtest-x86_64.so-rwxr-xr-x 1 root root 24832 Jan  1  1970 accel-tcg-x86_64.so-rwxr-xr-x 1 root root  7568 Jan  1  1970 hw-display-virtio-gpu-gl.so-rwxr-xr-x 1 root root  7576 Jan  1  1970 hw-display-virtio-gpu-pci-gl.so-rwxr-xr-x 1 root root 12688 Jan  1  1970 hw-display-virtio-gpu-pci.so-rwxr-xr-x 1 root root 53792 Jan  1  1970 hw-display-virtio-gpu.so-rwxr-xr-x 1 root root  7568 Jan  1  1970 hw-display-virtio-vga-gl.so-rwxr-xr-x 1 root root 17368 Jan  1  1970 hw-display-virtio-vga.so-rwxr-xr-x 1 root root 47688 Jan  1  1970 hw-usb-host.so-rwxr-xr-x 1 root root 67584 Jan  1  1970 hw-usb-redirect.so```### Expected behavior`/usr/lib64/qemu-kvm/` should have `0755` permissions like when docker is configured to use `overlay2` storage:```docker run --rm -ti --entrypoint /bin/bash quay.io/kubevirt/virt-launcher:v0.55.0bash-4.4# ls -la /usr/lib64/qemu-kvm/total 300drwxr-xr-x  2 root root  4096 Sep  5 06:12 .dr-xr-xr-x 29 root root 20480 Jan  1  1970 ..-rwxr-xr-x  1 root root 11792 Jan  1  1970 accel-qtest-x86_64.so-rwxr-xr-x  1 root root 24832 Jan  1  1970 accel-tcg-x86_64.so-rwxr-xr-x  1 root root  7568 Jan  1  1970 hw-display-virtio-gpu-gl.so-rwxr-xr-x  1 root root  7576 Jan  1  1970 hw-display-virtio-gpu-pci-gl.so-rwxr-xr-x  1 root root 12688 Jan  1  1970 hw-display-virtio-gpu-pci.so-rwxr-xr-x  1 root root 53792 Jan  1  1970 hw-display-virtio-gpu.so-rwxr-xr-x  1 root root  7568 Jan  1  1970 hw-display-virtio-vga-gl.so-rwxr-xr-x  1 root root 17368 Jan  1  1970 hw-display-virtio-vga.so-rwxr-xr-x  1 root root 47688 Jan  1  1970 hw-usb-host.so-rwxr-xr-x  1 root root 67584 Jan  1  1970 hw-usb-redirect.so```### docker version```bashClient: Version:           20.10.17-ce API version:       1.41 Go version:        go1.17.11 Git commit:        a89b84221c85 Built:             Wed Jun 29 00:00:00 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          20.10.17-ce  API version:      1.41 (minimum version 1.12)  Go version:       go1.17.11  Git commit:       a89b84221c85  Built:            Wed Jun 29 00:00:00 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.6.6  GitCommit:        10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc:  Version:          1.1.3  GitCommit:        v1.1.3-0-ga916309fff0f docker-init:  Version:          0.1.7_catatonit  GitCommit:```### docker info```bashClient: Context:    default Debug Mode: falseServer: Containers: 4  Running: 3  Paused: 0  Stopped: 1 Images: 38 Server Version: 20.10.17-ce Storage Driver: btrfs  Build Version: Btrfs v5.18.1  Library Version: 102 Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux oci runc Default Runtime: runc Init Binary: docker-init containerd version: 10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc version: v1.1.3-0-ga916309fff0f init version:  Security Options:  apparmor  seccomp   Profile: default  cgroupns Kernel Version: 5.19.2-1-default Operating System: openSUSE Tumbleweed OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 13.53GiB Name: <...> ID: <...> Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  192.168.122.1:5000  127.0.0.0/8 Live Restore Enabled: false```### Additional InfoThis was discovered while debugging https://github.com/kubevirt/kubevirt/issues/8195
"
44097,1,5780,0,0,1,dln22,0,"title:docker build build hangs at various build places. description:### DescriptionWe have a multistage docker build that hangs from time to time. The only fix we found to work is to restart the docker daemon, but that is not ideal. Here is a snapshot of our Dockerfile:```Dockerfile# syntax=docker.io/docker/dockerfile:1ARG IMAGE1ARG IMAGE2FROM $IMAGE1 as baseFROM $IMAGE2 as stage2ARG INDOMAIN_TEXT_DIRWORKDIR /COPY --from=base /model modelRUN apt-get update && apt-get install jq -y# we found that once the build passes through the above commands, it is ok...```The command to run the build is:```bash$ docker buildx build -f ./Dockerfile \  -t test_image:1 \  --no-cache \  --build-arg INDOMAIN_TEXT_DIR=test_files \  --build-arg IMAGE1=<image1> \  --build-arg IMAGE2=<image2> \  --progress=plain .```and the build log:```bash#2 [internal] load .dockerignore#2 sha256:e1125fcdcb65e1d02a1ab47b78e44cbe529e2d2e960dae626e0098cb765cea71#2 ...#1 [internal] load build definition from Dockerfile#1 sha256:38ac11d81305fbd114c796d89fdcce3f74dfea50124e708fb8bf40ba169780d0#1 transferring dockerfile: 1.91kB done#1 DONE 0.3s#2 [internal] load .dockerignore#2 sha256:e1125fcdcb65e1d02a1ab47b78e44cbe529e2d2e960dae626e0098cb765cea71#2 transferring context: 2B done#2 DONE 0.3s#3 resolve image config for docker.io/docker/dockerfile:1#3 sha256:ac072d521901222eeef550f52282877f196e16b0247844be9ceb1ccc1eac391d#3 DONE 0.6s#4 docker-image://docker.io/docker/dockerfile:1@sha256:9ba7531bd80fb0a858632727cf7a112fbfd19b17e94c4e84ced81e24ef1a0dbc#4 sha256:84d67e2b065a884889a458003692092baff84dfef79249c83c999fc53beb53ca#4 CACHED#6 [internal] load .dockerignore#6 sha256:9b8e7e2caa4f48fe03e54fae50c84478eee68762e03e4013e7046f8209ab7877#6 DONE 0.0s#5 [internal] load build definition from Dockerfile#5 sha256:f29167e4c24564eec7dd668391346c3c5a1b00da4ee752ba24808253e2216917#5 DONE 0.0s#8 [internal] load metadata for <image2>#8 sha256:31298c0f2ce9d20ea5f5e27e553b313b4a7a6d7e5a676aef197c3142a3eeea07#8 DONE 0.0s#7 [internal] load metadata for <image1>#7 sha256:51db483feac18390cb3febf4642eee4929997b1729d0adbcbb24d228d6da70cd#7 DONE 0.1s#9 [base 1/1] FROM <image1>@sha256:76999133a655ba37bf91ab14755f16a2a0033476eebae18dd1850f5dfdfa3491#9 sha256:053b7177fe817be1291ade108b2947db8ab5743d381bebf085b8f659ed05996f#9 CACHED#10 [stage2 1/8] FROM <image2>#10 sha256:3c99951ae9eb178f5789032c47b2b494d4bef45fa7a67cfa94b0a262f78de1ca#10 DONE 1.9s#15 [internal] load build context#15 sha256:f6dc8f9b83403fbb9190f50979fc831774ad1cdebde26b968da4df5d8ed348de#15 transferring context: 78B done#15 DONE 0.1s  # This is where it freezes```and docker daemon log at the time of freeze:```bash2022-09-06 09:39:37   (no unique labels) time=""2022-09-06T09:39:37.792916912+01:00"" level=info msg=""parsed scheme: \""\"""" module=grpc2022-09-06 09:39:37   (no unique labels) time=""2022-09-06T09:39:37.792947618+01:00"" level=info msg=""scheme \""\"" not registered, fallback to default scheme"" module=grpc2022-09-06 09:39:37   (no unique labels) time=""2022-09-06T09:39:37.793010037+01:00"" level=info msg=""ccResolverWrapper: sending update to cc: {闂傚倸鍊烽懗鍫曞磻閵娾晛纾块梺顒€绋侀弫鍕煕瀹€鈧崑娑㈡倿閸偁浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滈箖姊虹紒妯尖槈闁兼彃鐭傚缁樻媴閸濆嫪缂撻梺绋块叄娴滃爼銆侀弽顓炵＜闁绘劘灏欓崝锕€顪冮妶鍡楀潑闁稿鎸婚妵鍕箣濠靛棌鍋撻崸妤€鏄ラ柍褜鍓氶妵鍕箳閸℃ぞ澹曟俊鐐€栭崹鐢稿磹閸ф鏄ラ柍褜鍓氶妵鍕箳閸℃ぞ澹曟俊鐐€栭崹鐢稿磹閸ф鏄ラ柍褜鍓氶妵鍕箳閸℃ぞ澹曟俊鐐€栭崹鐢稿磹閸ф鏄ラ柍褜鍓氶妵鍕箳閸℃ぞ澹曟俊鐐€栭崹鐢稿磹閸ф鏄ラ柍褜鍓氶妵鍕箳閸℃ぞ澹曢梻浣虹帛娓氭鈻嶉悞宸僱host  <nil> 0 <nil>}闂傚倸鍊烽懗鍫曞磻閵娾晛纾块梺顒€绋侀弫鍕煕瀹€鈧崑娑㈡倿閸偁浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滈箖姊?<nil> <nil>}闂傚倸鍊烽懗鍫曞磻閵娾晛纾块梺顒€绋侀弫鍕煕瀹€鈧崑娑㈡倿閸偁浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵椤掍降浜滈柟鍝勬娴滄儳顪冮妶鍡楃仴闁稿﹤娼″畷娲焵? module=grpc2022-09-06 09:39:37   (no unique labels) time=""""2022-09-06T09:39:37.793023498+01:00"""" level=info msg=""""ClientConn switching balancer to \""""pick_first\"""""""" module=grpc2022-09-06 09:39:39   (no unique labels) time=""""2022-09-06T09:39:39.897347877+01:00"""" level=warning msg=""""grpc: Server.processUnaryRPC failed to write status: connection error: desc = \""""transport is closing\"""""""" module=grpc# This is where it freezes```Any help would be much appreciated.### Reproduce1. Run the docker buildx build command as listed above### Expected behavior_No response_### docker version```bashClient: Docker Engine - Community Version:           20.10.3 API version:       1.41 Go version:        go1.13.15 Git commit:        48d30b5 Built:             Fri Jan 29 14:33:13 2021 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.7  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       b0f5bc3  Built:            Wed Jun  2 11:54:48 2021  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc."
43999,1,3638,0,0,0,alanondra,0,"title:Dockerfile image version constraints ignored in favor of latest tag. description:### DescriptionVersion constraints for dependency images are ignored.### Reproduce1. Create a project with these settings in a Dockerfile:    ```dockerfile    FROM mlocati/php-extension-installer:1.5.35    FROM composer:2.2    FROM php:7.0-fpm-alpine    ```2. Build3. Observe wrong versions:    ```     => [api-project_php] FROM docker.io/library/composer:latest                 0.2s                                                          ^should be ~2.2     => => resolve docker.io/library/composer:latest                             0.2s                                              ^should be ~2.2     => [api-project_php internal] load build context                            0.0s     => => transferring context: 58B                                             0.0s     => [api-project_php] FROM docker.io/mlocati/php-extension-installer:latest  0.2s                                                                         ^should be 1.5.35     => => resolve docker.io/mlocati/php-extension-installer:latest              0.2s                                                             ^should be 1.5.35     => [api-project_php stage-2 1/9] FROM docker.io/library/php:7.0-fpm-alpine  0.0s                                                                 ^correct    ```### Expected behaviorI expected it to download the versions I indicated instead of ignoring my instructions.### docker version```bashClient: Docker Engine - Community Cloud integration: v1.0.28 Version:           20.10.17 API version:       1.41 Go version:        go1.17.11 Git commit:        100c701 Built:             Mon Jun  6 23:03:17 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.17  API version:      1.41 (minimum version 1.12)  Go version:       go1.17.11  Git commit:       a89b842  Built:            Mon Jun  6 23:01:23 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.7  GitCommit:        0197261a30bf81f1ee8e6a4dd2dea0ef95d67ccb runc:  Version:          1.1.3  GitCommit:        v1.1.3-0-g6724737 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.8.2-docker)  compose: Docker Compose (Docker Inc., v2.7.0)  extension: Manages Docker extensions (Docker Inc., v0.2.8)  sbom: View the packaged-based Software Bill Of Materials (SBOM) for an image (Anchore Inc., 0.6.0)  scan: Docker Scan (Docker Inc., v0.17.0)Server: Containers: 2  Running: 2  Paused: 0  Stopped: 0 Images: 7 Server Version: 20.10.17 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 0197261a30bf81f1ee8e6a4dd2dea0ef95d67ccb runc version: v1.1.3-0-g6724737 init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default  cgroupns Kernel Version: 5.10.0-17-amd64 Operating System: LMDE 5 (elsie) OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.26GiB Name: utvikler ID: I2QO:VT7D:LE7J:QPAG:NWK4:A36F:DG52:KNNU:C2WN:YBQK:ZNDJ:F4VT Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```### Additional Info_No response_
"
43969,1,2585,15,0,0,fansari,0,"title:OCI runtime exec failed: exec failed: unable to start container process: open /dev/pts/0: operation not permitted: unknown. description:### DescriptionI cannot enter any containers with ""docker exec -it ..."" on my CentOS 9 VMs with  this runc version:```runc version 1.1.3commit: v1.1.3-0-g6724737spec: 1.0.2-devgo: go1.17.13libseccomp: 2.5.2```I get this error message:```OCI runtime exec failed: exec failed: unable to start container process: open /dev/pts/0: operation not permitted: unknown```### ReproduceRun any container (e.g. alpine:latest) and try to enter it:docker run exec <mycontainer> /bin/sh -lOCI runtime exec failed: exec failed: unable to start container process: open /dev/pts/0: operation not permitted: unknown### Expected behaviorIt should be possible to get inside the container with ""run exec -it ..."".### docker version```bashClient: Docker Engine - Community Version:           20.10.17 API version:       1.41 Go version:        go1.17.11 Git commit:        100c701 Built:             Mon Jun  6 23:03:29 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.17  API version:      1.41 (minimum version 1.12)  Go version:       go1.17.11  Git commit:       a89b842  Built:            Mon Jun  6 23:01:12 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.7  GitCommit:        0197261a30bf81f1ee8e6a4dd2dea0ef95d67ccb runc:  Version:          1.1.3  GitCommit:        v1.1.3-0-g6724737 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.8.2-docker)  scan: Docker Scan (Docker Inc., v0.17.0)Server: Containers: 2  Running: 2  Paused: 0  Stopped: 0 Images: 16 Server Version: 20.10.17 Storage Driver: overlay2  Backing Filesystem: xfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 0197261a30bf81f1ee8e6a4dd2dea0ef95d67ccb runc version: v1.1.3-0-g6724737 init version: de40ad0 Security Options:  seccomp   Profile: default  cgroupns Kernel Version: 5.14.0-142.el9.x86_64 Operating System: CentOS Stream 9 OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 3.569GiB Name: xxx ID: YKYV:PDNS:DNMI:S6P2:ZMFQ:HB7Q:UEU3:CKQY:JDSM:LDN3:WJQN:T6GR Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```### Additional InfoSystems I setup with runc 1.1.2 and kernel 5.14.0-130.el9.x86_64 did not have this issue.
"
43956,1,7839,8,0,0,zhizunbao84,0,"title:fail to run amd64 image on linux mips64el host. description:### Descriptionmy computer is linux mips64el with 4.19.0 kernel.i enable Experimental in docker.i test mongodb version 4.4闂?.4.15闂?.2.21 and 4.0.11, but i cannot runt it normally.run mongodb 4.4闂?.4.15 image, i get the error `qemu:handle_cpu_signal received signal outside vCPU context`.run mongodb 4.2.21闂?4.0.11 image, i get the error `/usr/bin/mongod: error while loading shared libraries: libcurl.so.4: failed to map segment from shared object`.so what happened and what should i do ?!### Reproducedocker run -it --entrypoint /bin/bash mongo:4.4docker run -it mongo:4.2.21 /bin/bash### Expected behavior_No response_### docker version```bashClient: Version:           19.03.0-dev API version:       1.40 Go version:        go1.15.9 Git commit:         Built:             Thu Dec  9 02:17:17 2021 OS/Arch:           linux/mips64le Experimental:      trueServer: Engine:  Version:          dev  API version:      1.40 (minimum version 1.12)  Go version:       go1.15.9  Git commit:         Built:            Thu Dec  9 02:10:48 2021  OS/Arch:          linux/mips64le  Experimental:     true containerd:  Version:          c542a377  GitCommit:        c542a377e62f5cadf1244423227059548688476c runc:  Version:          1.0.0~rc6+dfsg1  GitCommit:        1.0.0~rc6+dfsg1-3 docker-init:  Version:          0.18.0  GitCommit:        fec3683```### docker info```bashClient: Debug Mode: false Plugins:  app: Docker Application (Docker Inc., v0.8.0)  buildx: Build with BuildKit (Docker Inc., 0.0.0+unknown)Server: Containers: 7  Running: 2  Paused: 0  Stopped: 5 Images: 12 Server Version: dev Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: c542a377e62f5cadf1244423227059548688476c runc version: 1.0.0~rc6+dfsg1-3 init version: fec3683  Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Registry Mirrors:  https://docker.mirrors.ustc.edu.cn/  https://registry.docker-cn.com/ Live Restore Enabled: falseWARNING: No memory limit supportWARNING: No swap limit supportWARNING: No kernel memory limit supportWARNING: No kernel memory TCP limit supportWARNING: No oom kill disable support```### Additional Info### install tonistiigi/binfmt.```user@user-PC:~$ docker run --privileged --rm tonistiigi/binfmt:qemu-v6.0.0-12 --install alluser@user-PC:~$ ls -al /proc/sys/fs/binfmt_misc/-rw-r--r-- 1 root root 0 8闂?  9 12:05 qemu-aarch64-rw-r--r-- 1 root root 0 8闂?  9 12:05 qemu-arm-rw-r--r-- 1 root root 0 8闂?  9 12:05 qemu-i386-rw-r--r-- 1 root root 0 8闂?  9 12:05 qemu-mips64-rw-r--r-- 1 root root 0 8闂?  9 12:05 qemu-ppc64le-rw-r--r-- 1 root root 0 8闂?  9 12:05 qemu-riscv64-rw-r--r-- 1 root root 0 8闂?  9 12:05 qemu-s390x-rw-r--r-- 1 root root 0 8闂?  9 12:05 qemu-x86_64```### run amd64 mongodbi test mongodb version 4.4闂?.4.15闂?.2.21 and 4.0.11, but i cannot runt it normally.```user@user-PC:~$ docker pull --platform amd64 mongo:4.4user@user-PC:~$ docker --debug run -it  mongo:4.4 /bin/bashDEBU[0001] [hijack] End of stdout                       user@user-PC:~/my_develop/my_py$ docker ps -aCONTAINER ID        IMAGE                      COMMAND                  CREATED             STATUS                        PORTS     NAMES7a84523d8124        mongo:4.4                  ""docker-entrypoint.s闂?   23 seconds ago      Exited (133) 22 seconds ago             friendly_proskuriakovauser@user-PC:~/my_develop/my_py$ docker logs 7a84523d8124user@user-PC:~/my_develop/my_py$ user@user-PC:~/my_develop/my_py$ docker run -it --entrypoint /bin/bash mongo:4.4root@997dfb6833ce:/# uname -mx86_64root@997dfb6833ce:/# lsqemu:handle_cpu_signal received signal outside vCPU context @ pc=0x12021a58eTrace/breakpoint trap (core dumped)root@997dfb6833ce:/# mongod --versiondb version v4.4.11Build Info: {    """"version"""": """"4.4.11"""""
43886,1,2327,82,0,0,silenceper,0,"title:windows docker exec ipconfig failed: hcsshim::System::CreateProcess: failure in a Windows system call: The remote procedure call failed.. description:### Descriptiondocker exec `ipconfig` command, Occasionally returns an error```exec's CreateProcess() failed [module=libcontainerd namespace=moby container=aaac0ba9e739663257cb7266651328bd578f592c034c9f39c9193d503d7a906c exec=2fd3b4ca8edde2204fd77a54ccbcd0a6f070efc6ebdc14358d63f77a7ac6e83a error=container aaac0ba9e739663257cb7266651328bd578f592c034c9f39c9193d503d7a906c encountered an error during hcsshim::System::CreateProcess: failure in a Windows system call: The remote procedure call failed. (0x6be)]```### ReproduceExecute `ipconfig` multiple times, sometimes it will return a null value, or time out### Expected behaviornormal### docker version```bashVersion:           20.10.17 API version:       1.41 Go version:        go1.17.11 Git commit:        100c701 Built:             Mon Jun  6 23:09:02 2022 OS/Arch:           windows/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.17  API version:      1.41 (minimum version 1.24)  Go version:       go1.17.11  Git commit:       a89b842  Built:            Mon Jun  6 23:03:58 2022  OS/Arch:          windows/amd64  Experimental:     false```### docker info```bashServer: Docker Engine - Community Engine:  Version:          20.10.17  API version:      1.41 (minimum version 1.24)  Go version:       go1.17.11  Git commit:       a89b842  Built:            Mon Jun  6 23:03:58 2022  OS/Arch:          windows/amd64  Experimental:     falseClient: Context:    default Debug Mode: falseServer: Containers: 57  Running: 42  Paused: 0  Stopped: 15 Images: 7 Server Version: 20.10.17 Storage Driver: windowsfilter  Windows: Logging Driver: json-file Plugins:  Volume: local  Network: ics internal l2bridge l2tunnel nat null overlay private transparent  Log: awslogs etwlogs fluentd gcplogs gelf json-file local logentries splunk syslog Swarm: inactive Default Isolation: process Kernel Version: 10.0 17763 (17763.1.amd64fre.rs5_release.180914-1434) Operating System: Windows Server 2019 Datacenter Version 1809 (OS Build 17763.2628) OSType: windows Architecture: x86_64 CPUs: 48 Total Memory: 126GiB Name: 9-150-114-181 ID: LNEQ:6FHT:QWQ2:RN67:PO6K:3WKZ:5BYW:P7S4:C4HE:RTWK:Q3N6:MISE Docker Root Dir: D:\ProgramData\docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Registry Mirrors:  https://dockerhub.xxxx.com/ Live Restore Enabled: false```### Additional Info_No response_
"
43860,1,3019,25,0,0,HunterXuan,0,"title:""docker logs -f xxx"" lost last log if no newline at the end. description:### DescriptionWhen I run a container on linux system which prints something without newline (\n) at the end, the last log would be lost if using `docker logs -f` command to follow its logs.And such behavior differs with different operate system:1. On CentOS, the last log is always lost2. On Windows, the last log is lost sometimes3. On Mac (M1 chip), the last log is printed as expected### Reproduce1. run a container that echo something without a newline at the end```bashdocker run --name test --rm  alpine /bin/sh -c ""sleep 5; echo hello; echo -n world""```2. use `docker logs -f` to follow the logs, and you will never get the ""world"" output```bashdocker logs -f test```### Expected behavior`docker logs -f` should print the last log even if no newline at the end.### docker version```bashClient: Docker Engine - Community Version:           20.10.8 API version:       1.41 Go version:        go1.16.6 Git commit:        3967b7d Built:             Fri Jul 30 19:55:49 2021 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.8  API version:      1.41 (minimum version 1.12)  Go version:       go1.16.6  Git commit:       75249d8  Built:            Fri Jul 30 19:54:13 2021  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.9  GitCommit:        e25210fe30a0a703442421b0f60afac609f950a3 runc:  Version:          1.0.1  GitCommit:        v1.0.1-0-g4144b63 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.6.1-docker)  scan: Docker Scan (Docker Inc., v0.8.0)Server: Containers: 4  Running: 4  Paused: 0  Stopped: 0 Images: 5 Server Version: 20.10.8 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: active  NodeID: v993fmlrkssle7n7x5hfjcg5p  Is Manager: true  ClusterID: ih8yo8lb4npcfa56ij8e4en1j  Managers: 1  Nodes: 3  Default Address Pool: 10.0.0.0/8    SubnetSize: 24  Data Path Port: 4789  Orchestration:   Task History Retention Limit: 5  Raft:   Snapshot Interval: 10000   Number of Old Snapshots to Retain: 0   Heartbeat Tick: 1   Election Tick: 10  Dispatcher:   Heartbeat Period: 5 seconds  CA Configuration:   Expiry Duration: 3 months   Force Rotate: 0  Autolock Managers: false  Root Rotation In Progress: false  Node Address: 10.0.0.17  Manager Addresses:   10.0.0.17:2377 Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: e25210fe30a0a703442421b0f60afac609f950a3 runc version: v1.0.1-0-g4144b63 init version: de40ad0 Security Options:  seccomp   Profile: default Kernel Version: 3.10.0-1160.36.2.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 1 Total Memory: 1.795GiB Name: web-qq-01 ID: ZLO2:2LRS:HRY7:3OT7:2K3L:GW63:QDCW:WHWJ:OOSK:5OW2:3R3F:Y5BK Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```### Additional Info_No response_
"
43826,1,193,102,0,0,zhgqiang,0,"title:centos7.9 binary install docker,systemctl start docker stuck,disable selinux start success. description:### DescriptionOS: centos7.9闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈鹃檮閸嬧晠鏌ｈ椤けry install docker, systemctl start docker stuck, kill failure, setenforce 0, systemctl start docker is ok, start selinux is not ok.### Reproduce systemctl start docker stuck### Expected behavior_No response_### docker version```bash19.03.15```### docker info```bashClient: Debug Mode: falseServer:ERROR: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?errors pretty printing info```### Additional Info_No response_
"
43799,0,2821,43,0,1,kc-dot-io,0,"title:TTY stopped working as expected in Docker version 20.10.17, build 100c701, API 1.42. description:### DescriptionFirst, thanks to all the contributors for their hard work on this project, greatly appreciated. 婵犵妲呴崑鎾跺緤娴犲鐤い鏍仜閻?We have a custom end user CLI that leverages [apocas/dockerode](https://github.com/apocas/dockerode) as a client to communicate with the Docker engine directly for the purpose of executing scripts inside of a container. These scripts typically have an interactive user experience in them and thus stdin/stdout and the container attach functionality is very important for TTY.We've received some reports that this TTY has stopped working suddenly upon upgrading to`Docker version 20.10.17, build 100c701`. It appears that downgrading back to `Docker version 20.10.16, build aa7e414` fixes this immediately.I found similar public reports from [JetBrains for their IDE](https://youtrack.jetbrains.com/issue/IDEA-297446) as well which seems to validate there is possibly a breaking change `20.10.17` for other docker clients which require TTY, as well.The [`20.10.17` release notes](https://github.com/moby/moby/releases/tag/v20.10.17) didn't suggest any big changes but then I reviewed [the changes introduced between `20.10.16` & `20.10.17`](https://github.com/moby/moby/compare/v20.10.16...v20.10.17) and I came across [this API documentation change](https://github.com/moby/moby/commit/829951ec19c6762d358c0a6dae10c648bc515e4b) & [this change to the server that appears to specifically limit some Stdin, Stdout, Stderr functionality to v1.42 of the API](https://github.com/moby/moby/commit/ea6760138c35c607a0b51ad041051374d8304e68)?I can see from the commit comments that @ndeloof is indicating that these APIs were documented but not supported prior to this version, however this (or similar) appears to be a breaking change for some custom clients such as ours unfortunately.I'm looking for a bit more context to help me understand the impact of this change as it seems to very directly relate to the broken TTY problem being reported upstream. I'm still trying to break this down into a simple enough set of replication steps, but thought I might get this issue open in the meantime to see if anyone else is seeing this. Thanks for patience here.### ReproduceApologies, I don't have simple replication steps yet (I'm working on it) without creating or using our custom client.1. create a custom client using dockerode 2. create the container, attach to the container3. pipe stdin/stdout to support interactive TTY4. stdin should be passed to container appropriately_Please note_ I have tested this with the docker client using a simple `read` test in bash and it *does* work.### Expected behaviorExpecting non breaking API for custom clients in `Docker Desktop 4.10.0` (`Docker version 20.10.17, build 100c701`), which require TTY when connecting directly to the Docker daemon (not using docker client).### docker version```bash闂?docker version                                                                                        [15:57:17]Client: Cloud integration: v1.0.24 Version:           20.10.17 API version:       1.41 Go version:        go1.17.11 Git commit:        100c701 Built:             Mon Jun  6 23:04:45 2022 OS/Arch:           darwin/amd64 Context:           default Experimental:      trueServer: Docker Desktop 4.10.0 (82025) Engine:  Version:          20.10.17  API version:      1.41 (minimum version 1.12)  Go version:       go1.17.11  Git commit:       a89b842  Built:            Mon Jun  6 23:01:23 2022  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          1.6.6  GitCommit:        10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc:  Version:          1.1.2  GitCommit:        v1.1.2-0-ga916309 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  buildx: Docker Buildx (Docker Inc., v0.8.2)  compose: Docker Compose (Docker Inc., v2.6.1)  extension: Manages Docker extensions (Docker Inc., v0.2.7)  sbom: View the packaged-based Software Bill Of Materials (SBOM) for an image (Anchore Inc., 0.6.0)  scan: Docker Scan (Docker Inc., v0.17.0)Server: Containers: 22  Running: 0  Paused: 0  Stopped: 22 Images: 30 Server Version: 20.10.17 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc version: v1.1.2-0-ga916309 init version: de40ad0 Security Options:  seccomp   Profile: default  cgroupns Kernel Version: 5.10.104-linuxkit Operating System: Docker Desktop OSType: linux Architecture: x86_64 CPUs: 6 Total Memory: 7.773GiB Name: docker-desktop ID: 4LKV:R7KC:SONZ:LMAU:Y37L:66SS:KWEN:6RXB:JJR7:2PTJ:FC77:26ZN Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 46  Goroutines: 49  System Time: 2022-07-12T22:57:32.145616762Z  EventsListeners: 4 HTTP Proxy: http.docker.internal:3128 HTTPS Proxy: http.docker.internal:3128 No Proxy: hubproxy.docker.internal Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  hubproxy.docker.internal:5000  127.0.0.0/8 Live Restore Enabled: false```### Additional Info_No response_
"
43791,1,6131,0,0,0,pigwow,0,"title:docker swarm hang. description:### DescriptionAll commands related to docker swarm do not respond.### ReproduceAfter node A is added to the cluster, all requests for invoking docker.swarmkit.v1.Control on node A do not respond.```goroutine 6334162 [select]:github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.(*Stream).waitOnHeader(0xc006a1a000)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/transport.go:312 +0x85github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.(*Stream).RecvCompress(...)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/transport.go:331github.com/docker/docker/vendor/google.golang.org/grpc.(*csAttempt).recvMsg(0xc005e55500, {0x564c59625360, 0xc005a3c390}, 0x0)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:871 +0xbagithub.com/docker/docker/vendor/google.golang.org/grpc.(*clientStream).RecvMsg.func1(0x2)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:736 +0x25github.com/docker/docker/vendor/google.golang.org/grpc.(*clientStream).withRetry(0xc004cee240, 0xc005ecca20, 0xc005ecc9f0)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:594 +0xd3github.com/docker/docker/vendor/google.golang.org/grpc.(*clientStream).RecvMsg(0xc004cee240, {0x564c59625360, 0xc005a3c390})        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:735 +0x11fgithub.com/docker/docker/vendor/google.golang.org/grpc.invoke({0x564c59792188, 0xc005693500}, {0x564c58f9c984, 0xc0006a0000}, {0x564c59625160, 0xc000011788}, {0x564c59625360, 0xc005a3c390}, 0x564c579c1b01, {0xc007430c40, ...})        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/vendor/google.golang.org/grpc/call.go:73 +0xd7github.com/docker/docker/vendor/github.com/grpc-ecosystem/go-grpc-prometheus.(*ClientMetrics).UnaryClientInterceptor.func1({0x564c59792188, 0xc005693500}, {0x564c58f9c984, 0x25}, {0x564c59625160, 0xc000011788}, {0x564c59625360, 0xc005a3c390}, 0x564c5a777fa0, 0x564c5970d948, ...)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/vendor/github.com/grpc-ecosystem/go-grpc-prometheus/client_metrics.go:112 +0x117github.com/docker/docker/vendor/google.golang.org/grpc.(*ClientConn).Invoke(0xc000957c00, {0x564c59792188, 0xc005693500}, {0x564c58f9c984, 0x25}, {0x564c59625160, 0xc000011788}, {0x564c59625360, 0xc005a3c390}, {0xc00148ec10, ...})        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/vendor/google.golang.org/grpc/call.go:35 +0x21fgithub.com/docker/docker/vendor/google.golang.org/grpc.Invoke(...)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/vendor/google.golang.org/grpc/call.go:60github.com/docker/docker/vendor/github.com/docker/swarmkit/api.(*controlClient).ListNodes(0xc00029a4d8, {0x564c59792188, 0xc005693500}, 0xc00029a4d8, {0xc00148ec10, 0x1, 0x1})        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/api/control.pb.go:3128 +0xc9github.com/docker/docker/daemon/cluster.(*Cluster).GetNodes(0xc000285440, {{0x0}})        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/daemon/cluster/nodes.go:32 +0x2b3github.com/docker/docker/api/server/router/swarm.(*swarmRouter).getNodes(0xc0020547e0, {0x24ab44312b06349f, 0xc00558f4d0}, {0x564c59763c60, 0xc0065940e0}, 0xc006ca7f00, 0xc0052c1600)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/api/server/router/swarm/cluster_routes.go:308 +0xc2github.com/docker/docker/api/server/middleware.ExperimentalMiddleware.WrapHandler.func1({0x564c597921c0, 0xc0066d12c0}, {0x564c59763c60, 0xc0065940e0}, 0x564c5939d020, 0xc00148ebd0)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/api/server/middleware/experimental.go:26 +0x15bgithub.com/docker/docker/api/server/middleware.VersionMiddleware.WrapHandler.func1({0x564c597921c0, 0xc0066d1290}, {0x564c59763c60, 0xc0065940e0}, 0x203001, 0x40)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/api/server/middleware/version.go:62 +0x4d8github.com/docker/docker/pkg/authorization.(*Middleware).WrapHandler.func1({0x564c597921c0, 0xc0066d1290}, {0x564c59763c60, 0xc0065940e0}, 0xc006ca7f00, 0xc00148eb80)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/pkg/authorization/middleware.go:59 +0x664github.com/docker/docker/api/server.(*Server).makeHTTPHandler.func1({0x564c59763c60, 0xc0065940e0}, 0xc006ca7e00)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/api/server/server.go:142 +0x2fanet/http.HandlerFunc.ServeHTTP(0xc006ca7c00, {0x564c59763c60, 0xc0065940e0}, 0x564c596da300)        /opt/buildtools/golang_go-1.17.5/src/net/http/server.go:2047 +0x2fgithub.com/docker/docker/vendor/github.com/gorilla/mux.(*Router).ServeHTTP(0xc0013be300, {0x564c59763c60, 0xc0065940e0}, 0xc006ca7b00)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/vendor/github.com/gorilla/mux/mux.go:212 +0x202github.com/docker/docker/api/server.(*routerSwapper).ServeHTTP(0x0, {0x564c59763c60, 0xc0065940e0}, 0x564c57a1bc90)        /usr1/workspace/docker_x86_build/build/BUILD_TMP/src/github.com/docker/docker/api/server/router_swapper.go:29 +0x9enet/http.serverHandler.ServeHTTP({0xc0066d1110}, {0x564c59763c60, 0xc0065940e0}, 0xc006ca7b00)        /opt/buildtools/golang_go-1.17.5/src/net/http/server.go:2879 +0x43bnet/http.(*conn).serve(0xc002101220, {0x564c597921c0, 0xc006881200})        /opt/buildtools/golang_go-1.17.5/src/net/http/server.go:1930 +0xb08created by net/http.(*Server).Serve        /opt/buildtools/golang_go-1.17.5/src/net/http/server.go:3034 +0x4e8```### Expected behavior_No response_### docker version```bashVersion:           19.03.15```### docker info```bashdocker info No response```### Additional Info_No response_
"
43782,1,5890,43,0,1,georgemarshall,0,"title:Apple M1 cross x86_64 support missing CPU instructions. description:### DescriptionWhen running docker commands that target a non-native platform such as `linux/amd64`. CPU instructions such as SSE and SSE2 are missing inside of the container, while being being available on the host machine.### Reproduce```~ 闂傚倸鍊烽悞锕€顭囧▎鎾崇；闁糕剝绋戦崹鍌涖亜韫囨挸顏撮柣鏂挎閺屾稑鐣濋埀顒勫磻濞戭潿鈧?docker run -it --platform linux/amd64 'ubuntu:20.04' lscpuArchitecture:                    x86_64CPU op-mode(s):                  32-bitByte Order:                      Little EndianCPU(s):                          6On-line CPU(s) list:             0-5Thread(s) per core:              1Core(s) per socket:              6Socket(s):                       1Vendor ID:                       0x00Model:                           0Stepping:                        0x0BogoMIPS:                        48.00Vulnerability Itlb multihit:     Not affectedVulnerability L1tf:              Not affectedVulnerability Mds:               Not affectedVulnerability Meltdown:          Not affectedVulnerability Spec store bypass: VulnerableVulnerability Spectre v1:        Mitigation; __user pointer sanitizationVulnerability Spectre v2:        Not affectedVulnerability Srbds:             Not affectedVulnerability Tsx async abort:   Not affectedFlags:                           fp asimd evtstrm aes pmull sha1 sha2 crc32 atomics fphp asimdhp cpuid asimdrdm jscvt fcma lrcpc dcpop sha3 asimddp sha512 asimdfhm dit us                                 cat ilrcpc flagm ssbs sb paca pacg dcpodp flagm2 frint```### Expected behavior```~ 闂傚倸鍊烽悞锕€顭囧▎鎾崇；闁糕剝绋戦崹鍌涖亜韫囨挸顏撮柣鏂挎閺屾稑鐣濋埀顒勫磻濞戭潿鈧?docker run -it --platform linux/amd64 'ubuntu:20.04' lscpuArchitecture:                    x86_64CPU op-mode(s):                  32-bit, 64-bitByte Order:                      Little EndianAddress sizes:                   39 bits physical, 48 bits virtualCPU(s):                          8On-line CPU(s) list:             0-7Thread(s) per core:              1Core(s) per socket:              1Socket(s):                       8Vendor ID:                       GenuineIntelCPU family:                      6Model:                           158Model name:                      Intel(R) Core(TM) i9-9880H CPU @ 2.30GHzStepping:                        13CPU MHz:                         2300.000BogoMIPS:                        4600.00L1d cache:                       256 KiBL1i cache:                       256 KiBL2 cache:                        2 MiBL3 cache:                        128 MiBVulnerability Itlb multihit:     KVM: Mitigation: VMX unsupportedVulnerability L1tf:              Mitigation; PTE InversionVulnerability Mds:               Vulnerable; SMT Host state unknownVulnerability Meltdown:          VulnerableVulnerability Spec store bypass: VulnerableVulnerability Spectre v1:        Vulnerable: __user pointer sanitization and usercopy barriers only; no swapgs barriersVulnerability Spectre v2:        Vulnerable, STIBP: disabledVulnerability Srbds:             Unknown: Dependent on hypervisor statusVulnerability Tsx async abort:   Mitigation; TSX disabledFlags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht pbe s                                 yscall nx pdpe1gb lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid pni pclmulqdq dtes64 ds_cpl ssse3                                  sdbg fma cx16 xtpr pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowpre                                 fetch fsgsbase bmi1 avx2 bmi2 erms xsaveopt arat```### docker version```bashClient: Cloud integration: v1.0.24 Version:           20.10.17 API version:       1.41 Go version:        go1.17.11 Git commit:        100c701 Built:             Mon Jun  6 23:04:45 2022 OS/Arch:           darwin/arm64 Context:           default Experimental:      trueServer: Docker Desktop 4.10.1 (82475) Engine:  Version:          20.10.17  API version:      1.41 (minimum version 1.12)  Go version:       go1.17.11  Git commit:       a89b842  Built:            Mon Jun  6 23:01:01 2022  OS/Arch:          linux/arm64  Experimental:     false containerd:  Version:          1.6.6  GitCommit:        10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc:  Version:          1.1.2  GitCommit:        v1.1.2-0-ga916309 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```### docker info```bashClient: Context:    default Debug Mode: false Plugins:  buildx: Docker Buildx (Docker Inc., v0.8.2)  compose: Docker Compose (Docker Inc., v2.6.1)  extension: Manages Docker extensions (Docker Inc., v0.2.7)  sbom: View the packaged-based Software Bill Of Materials (SBOM) for an image (Anchore Inc., 0.6.0)  scan: Docker Scan (Docker Inc., v0.17.0)Server: Containers: 8  Running: 0  Paused: 0  Stopped: 8 Images: 21 Server Version: 20.10.17 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc version: v1.1.2-0-ga916309 init version: de40ad0 Security Options:  seccomp   Profile: default  cgroupns Kernel Version: 5.10.104-linuxkit Operating System: Docker Desktop OSType: linux Architecture: aarch64 CPUs: 6 Total Memory: 15.6GiB Name: docker-desktop ID: YVTJ:2TRX:DTI4:DPP3:RDCN:54EP:PC33:Y7NA:KX5G:K6KK:23GU:YDVU Docker Root Dir: /var/lib/docker Debug Mode: false HTTP Proxy: http.docker.internal:3128 HTTPS Proxy: http.docker.internal:3128 No Proxy: hubproxy.docker.internal Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  hubproxy.docker.internal:5000  127.0.0.0/8 Live Restore Enabled: false```### Additional InfoAccording to MacCPUID the above mentioned instructions are present when an application running in ""Intel"" mode.<img width=""586"" alt=""Screen Shot 2022-07-07 at 3 15 42 PM"" src=""https://user-images.githubusercontent.com/132688/177880715-59970992-ff48-4d7e-9c34-018dac09195c.png"">Additionally I'm not sure if this would require using the new Rosetta changes to fix the issue.https://developer.apple.com/documentation/virtualization/running_intel_binaries_in_linux_vms_with_rosetta?language=objc
"
43781,0,2950,247,0,1,liskin,0,"title:No networking in rootless docker with firewalld. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**When running the docker daemon rootless, it still attempts to detect and use firewalld. If it succeeds (more on that later), iptables rules for NAT (necessary for traffic to be routed out of the docker0 bridge) are set up in the host network namespace instead of the network namespace dockerd runs in, so networking doesn't work. This is what the traffic looks like on the slirp4netns tap0 in the dockerd namespace:```15:30:41.600319 IP 172.17.0.2.52323 > 10.0.2.3.53: 1825+ A? deb.debian.org. (32)15:30:41.606028 ARP, Request who-has 172.17.0.2 tell 10.0.2.2, length 28```No reply, obviously, 172.17.0.2 is connected to the bridge, it's meant to be masqueraded when forwarded to tap0.Running `nsenter -U --preserve-credentials -n -m -t $(cat $XDG_RUNTIME_DIR/docker.pid) /usr/sbin/iptables-save` gives no output whatsoever, because there are no rules inside the net namespace.Now the important bit: this issue can only be reproduced with recent [godbus/dbus](https://github.com/godbus/dbus) (5.0.5+) because versions before that fail to connect to dbus from inside the _user_ namespace. This is because it's uid 0 in that namespace, it tells dbus it's uid 0 (`AUTH EXTERNAL 30\r\n`), and from dbus' point of view it's obviously not uid 0, so it rejects the connection, and dockerd thinks there's no firewalld and correctly uses iptables as it should inside a network namespace. This auth issue is [fixed in godbus/dbus 5.0.5](https://github.com/godbus/dbus/pull/265). The [20.10 branch of moby vendors godbus/dbus 5.0.3](https://github.com/moby/moby/blob/ff7feeac370921f4aa544d18a5348ad796055d7a/vendor.conf#L105) so it isn't affected, but moby 22.06 and master [vendor godbus/dbus 5.0.6](https://github.com/moby/moby/blob/5daceee6cab9fe5cf8580220d63a27db107d1cfa/vendor.mod#L37) so the bug is reproducible there. I've also reproduced the issue with Debian's packaging of moby 20.10 which doesn't use the vendored godbus/dbus and is built against godbus/dbus 5.0.6 instead (and I've [reported the issue to Debian as well](https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1014631)).tl;dr of the above: Not reproducible with 20.10.17, reproducible with 22.06 and master as of 2022-07-10, and also affects 20.10.14 in Debian which is built against godbus/dbus 5.0.6.What I think the fix might look like: in libnetwork/iptables, firewalld should only be used when not running rootless, as it makes no sense to set up iptables rules in the host network namespace while the bridge is in another network namespace.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. build recent dockerd with godbus/dbus 5.0.5 or later (22.06 or master as of 2022-07-10 has that); alternatively install docker.io from Debian testing2. install and start firewalld3. (make sure polkit allows your user to change firewalld settings闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劚缂佲晝绱掗崡鐐茬煑erwise dockerd detects firewalld but fails later and just terminates; polkit will normally ask interactively for authorisation but won't if experimenting in a minimal VM)4. set up dockerd rootless (using `dockerd-rootless-setuptool.sh`)5. start a container (e.g. `debian:testing`)6. try to access the internet (e.g. `apt update`)**Describe the results you received:**fails after it realises it can't resolve any hostnames**Describe the results you expected:**internet works**Additional information you deem important (e.g. issue happens only occasionally):**There's [a workaround](https://github.com/liskin/dotfiles/commit/ac0028a72d31211c09e7c3fd7a5704976c45660c) which involves bind-mounting /dev/null over /run/dbus/system_bus_socket and hoping nothing else breaks.**Output of `docker version`:**```Client: Version:           20.10.14+dfsg1 API version:       1.41 Go version:        go1.18.1 Git commit:        a224086 Built:             Sun May  1 19:59:40 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          dev  API version:      1.42 (minimum version 1.12)  Go version:       go1.18.3  Git commit:       0910306bf9  Built:            Sun Jul 10 16:24:51 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.6.6  GitCommit:        10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc:  Version:          1.1.2  GitCommit:        v1.1.2-0-ga916309f docker-init:  Version:          0.19.0  GitCommit:        de40ad0 rootlesskit:  Version:          1.0.0  ApiVersion:       1.1.1  NetworkDriver:    slirp4netns  PortDriver:       builtin  StateDir:         /tmp/rootlesskit4121490 slirp4netns:  Version:          1.0.1  GitCommit:        6a7b16babc95b6a3056b33fb45b74a6f62262dd4```**Output of `docker info`:**```Client: Context:    default Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 1 Server Version: dev Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Using metacopy: false  Native Overlay Diff: false  userxattr: true Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 runc Default Runtime: runc Init Binary: docker-init containerd version: 10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc version: v1.1.2-0-ga916309f init version: de40ad0 Security Options:  seccomp   Profile: builtin  rootless  cgroupns Kernel Version: 5.18.0-2-amd64 Operating System: Debian GNU/Linux bookworm/sid OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.768GiB Name: deb-docker3 ID: bdd42690-abb4-494e-91d1-fad7d00297df Docker Root Dir: /home/vagrant/.local/share/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No cpu cfs quota supportWARNING: No cpu cfs period supportWARNING: No cpu shares supportWARNING: No cpuset supportWARNING: No io.weight supportWARNING: No io.weight (per device) supportWARNING: No io.max (rbps) supportWARNING: No io.max (wbps) supportWARNING: No io.max (riops) supportWARNING: No io.max (wiops) supportWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**Reproduced on both my laptop and in a VM (debian testing image from vagrant), using both the version of docker.io shipped with Debian and binaries freshly built from this repo today. Not reproduced when using the packages from https://download.docker.com/linux/debian as those are built with the older vendored godbus/dbus.
"
43747,0,0,200,0,1,thaJeztah,0,"title:api: POST /containers/{id}/wait: fix validation for ""condition"" parameter. description:commit 737e8c6ab81842d61d86df3efec5f505b5484d4c (https://github.com/moby/moby/pull/43235) added validation for the wait condition parameter, however, the default (""not-running"") option was not part of the list of valid options, resulting in a regression if the default value was explicitly passed;    docker scan --accept-license --version    Error response from daemon: invalid condition: ""not-running""This patch adds the missing option, and adds a test to verify.With this patch;    make BIND_DIR=. DOCKER_GRAPHDRIVER=vfs TEST_FILTER=TestWaitConditions test-integration    ...    --- PASS: TestWaitConditions (0.04s)    --- PASS: TestWaitConditions/removed (1.79s)    --- PASS: TestWaitConditions/default (1.91s)    --- PASS: TestWaitConditions/next-exit (1.97s)    --- PASS: TestWaitConditions/not-running (1.99s)    PASS**- Description for the changelog**<!--Write a short (one line) summary that describes the changes in thispull request for inclusion in the changelog:-->**- A picture of a cute animal (not mandatory but encouraged)**
"
43742,0,1430,290,0,1,tonistiigi,1,"title:[22.06] COPY --link broken in some cases. description:Reported by @sudo-bmitch in slackWith the default builder `docker builder use default````$ cat df.copy-link # syntax=docker/dockerfile:1FROM alpine:latest as buildRUN addgroup -g 5000 appuser \ && adduser -u 5000 -G appuser -D appuser \ && mkdir -p /home/appuser/.config \ && chown -R appuser /home/appuser/.configFROM scratch as releaseCOPY --link --from=build /etc/passwd /etc/group /etc/COPY --link --from=build --chown=5000:5000 /home/appuser/ /home/appuser/$ docker build -t test-copy-link -f df.copy-link ..... => [build 2/2] RUN addgroup -g 5000 appuser  && adduser -u 5000 -G appuser -D appuser  && mkdir -p /home/appuser/.config  && chown -R appuser /home/appuser/.config                                          0.5s => [release 2/2] COPY --link --from=build --chown=5000:5000 /home/appuser/ /home/appuser/                                                                                                                    0.1s => ERROR exporting to image                                                                                                                                                                                  0.0s => => exporting layers                                                                                                                                                                                       0.0s------ > exporting to image:------error: failed to solve: can not convert active kjb10koor6qk2zaa57bn3q9t8 to layer```Fix by @sipsma is in https://github.com/sipsma/moby/commit/ab819190efd66dde0224c7fbcb54de9f8f19fbc2 that needs to be opened as a PR.We also need to look into why the integration tests did not catch this case @crazy-max 
"
43737,0,4472,9,0,0,seleznev,0,"title:dockerd doesn't kill healthcheck processes after timeout. description:**Description**dockerd already has logic to gracefully stop healthcheck processes after timeout ([/daemon/exec.go#L277-L291](https://github.com/moby/moby/blob/v20.10.17/daemon/exec.go#L277-L291)).But it seems completely broken because of using canceled context in `daemon.containerd.SignalProcess()` call ([/daemon/exec.go#L279](https://github.com/moby/moby/blob/v20.10.17/daemon/exec.go#L279)). `SignalProcess()` just returns `context canceled` error and does nothing.**Steps to reproduce the issue:**1. Create `Dockerfile`:    ```    FROM ubuntu:22.04    HEALTHCHECK --interval=5s --timeout=5s \       CMD [""sleep"", ""3600""]    CMD [""sleep"", ""infinity""]    ```2. Build image:    ```    docker build --tag=healthcheck-test .    ```3. Start container:    ```    docker run -d --rm --name=healthcheck-test healthcheck-test    ```4. Wait some health intervals:    ```    sleep 30    ```5. Check processes in the container:    ```    docker exec healthcheck-test ps axuf    ```* Cleanup:    ```    docker rm --force healthcheck-test # remove container    docker rmi healthcheck-test # remove image    ```**Describe the results you received:**More then one `sleep 3600` processes:```$ docker build --tag=healthcheck-test .Sending build context to Docker daemon  2.048kBStep 1/3 : FROM ubuntu:22.04 ---> 27941809078cStep 2/3 : HEALTHCHECK --interval=5s --timeout=5s    CMD [""sleep"", ""3600""] ---> Running in 248a9dcfaa6fRemoving intermediate container 248a9dcfaa6f ---> 16d09d0a1b09Step 3/3 : CMD [""sleep"", ""infinity""] ---> Running in 55ef832b3170Removing intermediate container 55ef832b3170 ---> 7e8b71425a0aSuccessfully built 7e8b71425a0aSuccessfully tagged healthcheck-test:latest$ docker run -d --rm --name=healthcheck-test healthcheck-test41e8e2eb21d0bdd485e647c6ec1273474b19ba616d284d48d53ea607edd96841$ sleep 30$ docker exec healthcheck-test ps axufUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDroot          25  0.0  0.0   7060  1664 ?        Rs   12:01   0:00 ps axufroot          19  0.2  0.0   2788  1036 ?        Ss   12:01   0:00 sleep 3600root          13  0.0  0.0   2788  1036 ?        Ss   12:00   0:00 sleep 3600root           7  0.0  0.0   2788  1056 ?        Ss   12:00   0:00 sleep 3600root           1  0.0  0.0   2788  1108 ?        Ss   12:00   0:00 sleep infinity```**Describe the results you expected:**Zero or one `sleep 3600` process:```$ docker exec healthcheck-test ps axufUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDroot          25  0.0  0.0   7060  1664 ?        Rs   12:01   0:00 ps axufroot          19  0.2  0.0   2788  1036 ?        Ss   12:01   0:00 sleep 3600root           1  0.0  0.0   2788  1108 ?        Ss   12:00   0:00 sleep infinity```**Additional information you deem important (e.g. issue happens only occasionally):**N/A**Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.17 API version:       1.41 Go version:        go1.17.11 Git commit:        100c701 Built:             Mon Jun  6 23:02:57 2022 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.17  API version:      1.41 (minimum version 1.12)  Go version:       go1.17.11  Git commit:       a89b842  Built:            Mon Jun  6 23:01:03 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.6  GitCommit:        10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc:  Version:          1.1.2  GitCommit:        v1.1.2-0-ga916309 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.8.2-docker)  scan: Docker Scan (Docker Inc., v0.17.0)Server: Containers: 10  Running: 1  Paused: 0  Stopped: 9 Images: 119 Server Version: 20.10.17 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc version: v1.1.2-0-ga916309 init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.13.0-51-generic Operating System: Ubuntu 20.04.4 LTS OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.34GiB Name: uk-ubnt-61 ID: BXVR:65LG:FDYH:IX7Q:U2LT:LQI6:P5B5:ZFEG:EIMS:WPWM:D3ND:RN4H Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 90  Goroutines: 74  System Time: 2022-06-22T15:03:06.064800737+03:00  EventsListeners: 0 Username: 2gis Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  docker-hub.2gis.ru:5444  127.0.0.0/8 Registry Mirrors:  https://docker-registry-proxy.2gis.io/ Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**N/A
"
43734,1,3945,0,0,0,alexander-hirth,0,"title:`docker builder prune` no longer respects `--filters`. description:Docker 22.06.0-beta.0 broke `docker builder prune --filter ""until=XYZ"". I get the following on my fedora 36 system:```[alex@ad ~]$ docker builder prune -f --filter ""until=24h"" --verboseTotal:  0B[alex@ad ~]$ docker builder pruneWARNING! This will remove all dangling build cache. Are you sure you want to continue? [y/N] yID                                              RECLAIMABLE     SIZE            LAST ACCESSEDu5752nigmrh4tlyboso5waiei                       true            98.09MB         46 hours agorinmtsj7ckgfc1kht2z1zyluw                       true    60.83MB         45 hours agoindan1ushjvqe4kfkrugpy68d                       true    653.8MB         44 hours ago94qdrqmlhi77068lih5cvcpl4                       true    0B              32 hours agosu9a6wrhefbn0xpfawhb4k6p4                       true    653.8MB         44 hours agoodkwfoatyk73jqztnc6jocrod                       true    98.1MB          33 hours agoyypopqkfk8qsulg2ufu100d9d                       true    0B              44 hours agondtg45xjxxrhu5nog55bz1uw4                       true    101.4MB         45 hours agop67kbju3eefseaqexvmy1tsm9                       true    98.1MB          44 hours agonble8o6rougry4myx41cyzey5                       true    0B              45 hours agou05q4vx2889aevmuruzn5ty3v                       true    101.4MB         44 hours agoq56k51l8vvwkvchrn5g2lk5lo                       true    101.4MB         33 hours ago9gouwora0chhzyqkws6f4y9q8                       true    78.36MB         46 hours ago...```The command `docker builder prune -f --filter ""until=24h""` used to work in a version of Docker that was shipped with Fedora 35.**Output of `docker version`:**```Client: Docker Engine - Community Version:           22.06.0-beta.0 API version:       1.42 Go version:        go1.18.3 Git commit:        3e9117b Built:             Fri Jun  3 17:59:03 2022 OS/Arch:           linux/amd64 Context:           defaultServer: Docker Engine - Community Engine:  Version:          22.06.0-beta.0  API version:      1.42 (minimum version 1.12)  Go version:       go1.18.3  Git commit:       38633e7  Built:            Fri Jun  3 17:56:21 2022  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.6.6  GitCommit:        10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc:  Version:          1.1.2  GitCommit:        v1.1.2-0-ga916309 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  buildx: Docker Buildx (Docker Inc.)    Version:  v0.8.2    Path:     /usr/libexec/docker/cli-plugins/docker-buildx  compose: Docker Compose (Docker Inc.)    Version:  v2.6.0    Path:     /usr/libexec/docker/cli-plugins/docker-compose  scan: Docker Scan (Docker Inc.)    Version:  v0.17.0    Path:     /usr/libexec/docker/cli-plugins/docker-scanServer: Containers: 1  Running: 1  Paused: 0  Stopped: 0 Images: 29 Server Version: 22.06.0-beta.0 Storage Driver: overlay2  Backing Filesystem: xfs  Supports d_type: true  Using metacopy: false  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 10c12954828e7c7c9b6e0ea9b0c02b01407d3ae1 runc version: v1.1.2-0-ga916309 init version: de40ad0 Security Options:  seccomp   Profile: builtin Kernel Version: 5.18.5-200.fc36.x86_64 Operating System: Fedora Linux 36 (Thirty Six) OSType: linux Architecture: x86_64 CPUs: 16 Total Memory: 23.47GiB Name: ad.vault13 ID: BK57:HJG6:X5WD:PFIC:PPAZ:GWGB:FPRB:KHVW:6W6G:AXG6:FZ3L:ZLVX Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**I installed docker from Fedora's repositories at baseurl=https://download.docker.com/linux/fedora/$releasever/$basearch/stable.
"
43724,0,654,43,0,0,setharnold,0,"title:incorrect accessible() implementation. description:https://github.com/moby/moby/blob/74286cba8c2c14d5360caec44d2da74858e9c707/pkg/idtools/idtools_unix.go#L95```func accessible(isOwner, isGroup bool, perms os.FileMode) bool {	if isOwner && (perms&0100 == 0100) {		return true	}	if isGroup && (perms&0010 == 0010) {		return true	}	if perms&0001 == 0001 {		return true	}	return false}```Hello, the `accessible()` function can give incorrect results if `isOwner` or `isGroup` is true. (Well, 'incorrect' in the sense that it gives different results than Unix and Linux systems.)The traditional implementation of discretionary access controls does NOT fall back to the wider permissions:Consider:```$ mkdir owner$ mkdir group$ mkdir world$ chmod 100 owner$ chmod 010 group$ chmod 001 world$ cd owner/$ cd ..$ cd group/bash: cd: group/: Permission denied$ cd world/bash: cd: world/: Permission denied$ ls -ld owner group worldd-----x--- 2 sarnold sarnold 2 Jun 17 02:17 groupd--x------ 2 sarnold sarnold 2 Jun 17 02:17 ownerd--------x 2 sarnold sarnold 2 Jun 17 02:17 world```(For the ultra-curious, I strongly recommend checking out the ancient Unix source code at http://warsus.github.io/lions-/all.html ; there's a bit of complication around root getting all permissions except execution, but a very pleasing ""shift the permissions right three bits"" if the uid or gid don't match followed by a single test. Look for `access(aip, mode)`.)I'm a little worried about the presence of this function at all, however; `access(2)` has been a source of security bugs in the Unix world for decades, and this implementation completely ignores the permissions on path resolution, so it's even less useful than the `access(2)` syscall provided by the Linux kernel.How is this function used? Why?Thanks
"
43679,0,0,0,1,1,thaJeztah,0,"title:Flaky test: TestRunContainerWithRmFlagCannotStartContainer (on windows). description:This test has failed frequently recently; https://github.com/moby/moby/search?q=TestRunContainerWithRmFlagCannotStartContainer&type=issues- was once marked as racy/flaky a long time ago: https://github.com/moby/moby/issues/11966- originally fixed in: https://github.com/moby/moby/pull/12206```=== FAIL: github.com/docker/docker/integration-cli TestDockerSuite/TestRunContainerWithRmFlagCannotStartContainer (2.17s)    docker_cli_run_test.go:2770: Expected not to have containers 357547ca53b5            --- FAIL: TestDockerSuite/TestRunContainerWithRmFlagCannotStartContainer (2.17s)=== FAIL: github.com/docker/docker/integration-cli TestDockerSuite (3440.51s)```
"
43653,0,9963,200,0,0,thaJeztah,0,"title:[regression in master] docker build without --tag tries to tag as empty image name (BuildKit)  . description:While running internal tests against builds from master, I noticed some tests failing; when trying to build an image without explicitly tagging it (`-t` / `--tag`), BuildKit attempts to tag the image with an empty name, causing  an `invalid reference format` error.All cases below use the same version of the CLI and buildx (I'm running the `docker:20.10-dind` image with the socket mounted)```bashdocker --versionDocker version 20.10.16, build aa7e414```Note that the example uses a remote source, but I've seen other tests in our internal tests fail with the same (building from a Dockerfile)On a docker 20.10 daemon with `DOCKER_BUILDKIT=1` (not using buildx);```bashDOCKER_BUILDKIT=1 docker build https://github.com/docker/docker-bench-security.git#v1.3.5[+] Building 14.5s (9/9) FINISHED => [internal] load git source https://github.com/docker/docker-bench-security.git#v1.3.5                                                                                                              1.5s => [internal] load metadata for docker.io/library/alpine:3.10                                                                                                                                         3.7s => [auth] library/alpine:pull token for registry-1.docker.io                                                                                                                                          0.0s => [1/5] FROM docker.io/library/alpine:3.10@sha256:451eee8bedcb2f029756dc3e9d73bab0e7943c1ac55cff3a4861c52a0fdd3e98                                                                                   0.8s => => resolve docker.io/library/alpine:3.10@sha256:451eee8bedcb2f029756dc3e9d73bab0e7943c1ac55cff3a4861c52a0fdd3e98                                                                                   0.0s => => sha256:451eee8bedcb2f029756dc3e9d73bab0e7943c1ac55cff3a4861c52a0fdd3e98 1.64kB / 1.64kB                                                                                                         0.0s => => sha256:e515aad2ed234a5072c4d2ef86a1cb77d5bfe4b11aa865d9214875734c4eeb3c 528B / 528B                                                                                                             0.0s => => sha256:e7b300aee9f9bf3433d32bc9305bfdd22183beb59d933b48d77ab56ba53a197a 1.47kB / 1.47kB                                                                                                         0.0s => => sha256:396c31837116ac290458afcb928f68b6cc1c7bdd6963fc72f52f365a2a89c1b5 2.80MB / 2.80MB                                                                                                         0.5s => => extracting sha256:396c31837116ac290458afcb928f68b6cc1c7bdd6963fc72f52f365a2a89c1b5                                                                                                              0.2s => [2/5] RUN set -eux;   sed -i 's!http://dl-cdn.alpinelinux.org/!https://alpine.global.ssl.fastly.net/!g' /etc/apk/repositories &&   apk add --no-cache     iproute2     docker-cli     dumb-init    7.5s => [3/5] COPY ./*.sh /usr/local/bin/                                                                                                                                                                  0.2s => [4/5] COPY ./tests/*.sh /usr/local/bin/tests/                                                                                                                                                      0.1s => [5/5] WORKDIR /usr/local/bin                                                                                                                                                                       0.1s => exporting to image                                                                                                                                                                                 0.5s => => exporting layers                                                                                                                                                                                0.5s => => writing image sha256:7349ab5126886ba84770b3cead8c19de5fb897eb6b0a5cd6d7e161db1541dffb                                                                                                           0.0s```On master;Docker CLI hangs;```bashDOCKER_BUILDKIT=1 docker build https://github.com/docker/docker-bench-security.git#v1.3.5[+] Building 8.1s (8/8) => CACHED [internal] load git source https://github.com/docker/docker-bench-security.git#v1.3.5                                                                                                       0.0s => [internal] load metadata for docker.io/library/alpine:3.10                                                                                                                                         0.0s => [1/5] FROM docker.io/library/alpine:3.10                                                                                                                                                           0.0s => CACHED [2/5] RUN set -eux;   sed -i 's!http://dl-cdn.alpinelinux.org/!https://alpine.global.ssl.fastly.net/!g' /etc/apk/repositories &&   apk add --no-cache     iproute2     docker-cli     dumb  0.0s => CACHED [3/5] COPY ./*.sh /usr/local/bin/                                                                                                                                                           0.0s => CACHED [4/5] COPY ./tests/*.sh /usr/local/bin/tests/                                                                                                                                               0.0s => CACHED [5/5] WORKDIR /usr/local/bin                                                                                                                                                                0.0s => ERROR exporting to image                                                                                                                                                                           0.0s => => exporting layers                                                                                                                                                                                0.0s => => writing image sha256:accf73094158d5531fa6c29bdf5554f6b7eecbb9864fd6ad5d35eb7e5bae0749                                                                                                           0.0s => => naming to                                                                                                                                                                                       8.0s^CERRO[0008] got 3 SIGTERM/SIGINTs, forcing shutdown````With buildx the error also occurs, but it doesn't hang:```bashdocker buildx versiongithub.com/docker/buildx v0.8.2 6224def4dd2c3d347eee19db595348c50d7cb491docker buildx build https://github.com/docker/docker-bench-security.git#v1.3.5[+] Building 11.8s (8/8) FINISHED => [internal] load git source https://github.com/docker/docker-bench-security.git#v1.3.5                                                                                                              2.6s => [internal] load metadata for docker.io/library/alpine:3.10                                                                                                                                         0.0s => [1/5] FROM docker.io/library/alpine:3.10                                                                                                                                                           0.0s => [2/5] RUN set -eux;   sed -i 's!http://dl-cdn.alpinelinux.org/!https://alpine.global.ssl.fastly.net/!g' /etc/apk/repositories &&   apk add --no-cache     iproute2     docker-cli     dumb-init    5.6s => [3/5] COPY ./*.sh /usr/local/bin/                                                                                                                                                                  0.1s => [4/5] COPY ./tests/*.sh /usr/local/bin/tests/                                                                                                                                                      0.0s => [5/5] WORKDIR /usr/local/bin                                                                                                                                                                       0.0s => ERROR exporting to image                                                                                                                                                                           0.5s => => exporting layers                                                                                                                                                                                0.5s => => writing image sha256:619742465254ba9662a5ee8433919f35498bc958af2ae39b76505da63de76dd3                                                                                                           0.0s => => naming to                                                                                                                                                                                       3.0s------ > exporting to image:------error: failed to solve: invalid reference format```With BuildKit disabled, it works as expected;```bashDOCKER_BUILDKIT=0 docker build https://github.com/docker/docker-bench-security.git#v1.3.5DOCKER_BUILDKIT=0 docker build https://github.com/docker/docker-bench-security.git#v1.3.5Sending build context to Docker daemon  136.2kBStep 1/9 : FROM alpine:3.10 ---> e7b300aee9f9Step 2/9 : LABEL   org.label-schema.name=""docker-bench-security""   org.label-schema.url=""https://dockerbench.com""   org.label-schema.vcs-url=""https://github.com/docker/docker-bench-security.git"" ---> Using cache ---> 6a12ab30ca54Step 3/9 : RUN set -eux;   sed -i 's!http://dl-cdn.alpinelinux.org/!https://alpine.global.ssl.fastly.net/!g' /etc/apk/repositories &&   apk add --no-cache     iproute2     docker-cli     dumb-init ---> Using cache ---> 11813d801d06Step 4/9 : COPY ./*.sh /usr/local/bin/ ---> Using cache ---> 1b30d93bf486Step 5/9 : COPY ./tests/*.sh /usr/local/bin/tests/ ---> Using cache ---> 3adc8d904556Step 6/9 : HEALTHCHECK CMD exit 0 ---> Using cache ---> 092c4e4e7695Step 7/9 : WORKDIR /usr/local/bin ---> Using cache ---> ed88260a96a4Step 8/9 : ENTRYPOINT [ ""/usr/bin/dumb-init"", ""docker-bench-security.sh"" ] ---> Using cache ---> aa6f3e91bcccStep 9/9 : CMD [""""] ---> Using cache ---> 709ff8947191Successfully built 709ff8947191```
"
43647,0,440,245,0,1,vvoland,1,"title:[regression in master] Corrupted logs. description:**Description**Found it when writing tests for getting the container logs: - https://github.com/moby/moby/pull/43642The logs are corrupted when capturing both stdout and stderr at the same time.This isn't an issue with reading the logs, because the corruption is already visible in the json log file.Example of corrupted json log file```# cat /var/lib/docker/containers/babb35c51972046a575a42c414cf2ad7d58d270b9594a251fb6d59234ccc021a/babb35c51972046a575a42c414cf2ad7d58d270b9594a251fb6d59234ccc021a-json.log{""log"":""accidents happ""st,""stre""std""std,rr"",""time"":""2022-05-26T07:43:19.448576002Z""}{""log"":""accidents happ""st,""stre""std""std,rr"",""time"":""2022-05-26T07:43:19.44857621Z""}```</details>First commit with the regression is ae5f664f4e62b8235a9b37ad0f33c2f1748aaa32 (https://github.com/moby/moby/pull/43294)The issue is that marshalFunc used in LogFile use a shared buffer. See:- https://github.com/moby/moby/blob/master/daemon/logger/jsonfilelog/jsonfilelog.go#L98- https://github.com/moby/moby/blob/master/daemon/logger/local/local.go#L96With the mutex lock around WriteLogEntry got removed in the linked commit, the marshaller can be called for both stdout and stderr at the same time, which makes them write to the same buffer.Allocating a buffer inside the marshaller call fixes the problem. But this is probably not a good idea because it would cause too many memory allocation? Maybe we should restore the critical section for the WriteLogEntry?**Steps to reproduce the issue:**```docker logs -f $(docker run -d busybox sh -c 'echo stdout; echo stderr >&2')```**Describe the results you received:**Randomly one of:1. Correct output2. both stdout printed3. both stderr printed4. Error getting logs, for example: `error from daemon in stream: Error grabbing logs: json: cannot unmarshal string into Go value of type jsonlog.JSONLog`**Describe the results you expected:**Command should print```stdoutstderr```
"
43646,0,0,247,0,1,AkihiroSuda,1,"title:[regression in master] `docker info` always shows `WARNING: No swap limit support` on cgroup v2 hosts. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->`docker info` always shows `WARNING: No swap limit support` on cgroup v2 hosts.Regression in https://github.com/moby/moby/pull/43347.The commit in the master branch is not backported to the 20.10 branch, so v20.10.16 is not affected.**Steps to reproduce the issue:**`docker info`**Describe the results you received:**Always shows `WARNING: No swap limit support`**Describe the results you expected:**No warning- - -Being fixed in:- https://github.com/containerd/cgroups/pull/232
"
43595,1,1467,20,1,1,sandy-lcq,0,"title:Build will fail when docker has glibc2.34+ and glib2.72+ (close_range EPERM). description:**Description**docker has glibc2.35,  and build with  glib2.72+,  the build will fail with error:(glib-compile-resources:19315): GLib-GObject-CRITICAL **: 08:08:56.312: g_object_unref: assertion 'G_IS_OBJECT (object)' failed../gdk-pixbuf-2.42.8/tests/resources.gresource.xml: Failed to close file descriptor for child process (Operation not permitted).The reason is that, close_range treturn EPERM for docker container, .since commit [1],  glib will report error,  and upstream reject to accpect EPERM as return value.This issue is a little similar like the issue we met before for clone3, and the fix is [3].I notice that we have an RFE [4] to make Seccomp Profiles to ENOSYS Default, seems this is the solution,since glib only will take ENOSYS as correct return.[1] https://gitlab.gnome.org/GNOME/glib/-/commit/ce04a124040be091407e070280d86ca810bacb8c[2] https://gitlab.gnome.org/GNOME/glib/-/issues/2580[3]  https://github.com/moby/moby/pull/42681[4]  https://github.com/moby/moby/issues/42871**Steps to reproduce the issue:**In order to simple the reproduce steps,  I just pick the usefull part1. docker run --rm -i -t -v /docker/:/mnt ubuntu:22.04 /bin/bash2. setup yocto project and bitbake gdk-pixbuf-native     the actually failed command is:glib-compile-resources --sourcedir=/mnt/ubuntu2204/build/tmp-glibc/work/x86_64-linux/gdk-pixbuf-native/2.42.8-r0/gdk-pixbuf-2.42.8/tests --source ../gdk-pixbuf-2.42.8/tests/resources.gresource.xml tests/resources.cWhile glib-compile-resources is build from glib 2.72.1**Describe the results you received:**(glib-compile-resources:19315): GLib-GObject-CRITICAL **: 08:08:56.312: g_object_unref: assertion 'G_IS_OBJECT (object)' failed../gdk-pixbuf-2.42.8/tests/resources.gresource.xml: Failed to close file descriptor for child process (Operation not permitted).**Describe the results you expected:**build success**Additional information you deem important (e.g. issue happens only occasionally):**Issue not happens on docker ubuntu2104 which have glibc 2.33, close_range is added in glibc since 2.34**Output of `docker version`:**```Docker version 20.10.12, build e91ed57```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Docker Buildx (Docker Inc., v0.7.1-docker)  scan: Docker Scan (Docker Inc., v0.12.0)Server: Containers: 10  Running: 2  Paused: 0  Stopped: 8 Images: 37 Server Version: 20.10.12 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 7b11cfaabd73bb80907dd23182b9347b4245eb5d runc version: v1.0.2-0-g52b36a2 init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.13.0-35-generic Operating System: Ubuntu 20.04.3 LTS OSType: linux Architecture: x86_64 CPUs: 48 Total Memory: 247.3GiB Name: core2 ID: H5SQ:4MGO:KUUX:QJUT:QDJS:CVO2:WXHZ:KKUM:6WVI:VSIP:7PP3:6T67 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: Live Restore Enabled: false```
"
43284,0,2357,288,0,0,crazy-max,1,"title:Wrong operating system reported by docker info on Windows. description:**Description**For WCOW case, _Operating System_ reported by `docker info` is not right.**Steps to reproduce the issue:**1. _Switch to Windows containers_ on Docker Desktop2. Open `cmd`3. Type `docker info`**Describe the results you received:**```> docker infoClient: Context:    default Debug Mode: false Plugins:  buildx: Docker Buildx (Docker Inc., v0.7.1)  compose: Docker Compose (Docker Inc., v2.2.3)  hub: Docker Hub (Docker Inc., 346ece73cb-dirty)  scan: Docker Scan (Docker Inc., v0.17.0)Server: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 4 Server Version: 20.10.12 Storage Driver: windowsfilter  Windows: Logging Driver: json-file Plugins:  Volume: local  Network: ics internal l2bridge l2tunnel nat null overlay private transparent  Log: awslogs etwlogs fluentd gcplogs gelf json-file local logentries splunk syslog Swarm: inactive Default Isolation: hyperv Kernel Version: 10.0 22000 (22000.1.amd64fre.co_release.210604-1628) Operating System: Windows 10 Pro Version 2009 (OS Build 22000.527) OSType: windows Architecture: x86_64 CPUs: 32 Total Memory: 63.93GiB Name: pc-sff ID: BJ23:IQXR:IXL3:FAEE:TGKX:5XWD:7ZKB:6GXF:P5BL:LU3E:T45O:MULU Docker Root Dir: C:\ProgramData\Docker Debug Mode: false Username: ... Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false Product License: Community Engine```Here we have:```Operating System: Windows 10 Pro Version 2009 (OS Build 22000.527)```**Describe the results you expected:**Expected:```Operating System: Windows 11 Pro Version 21H2 (OS Build 22000.527)```**Additional information you deem important (e.g. issue happens only occasionally):**Looking at the source code, we rely on the HKLM hive in the registry: https://github.com/moby/moby/blob/dc8fb8f03ba30a80b036706ef89d4dd156729216/pkg/parsers/operatingsystem/operatingsystem_windows.go#L45Here are the registry values for me:```Windows Registry Editor Version 5.00[HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows NT\CurrentVersion]""BaseBuildRevisionNumber""=dword:00000001""BuildBranch""=""co_release""""BuildGUID""=""ffffffff-ffff-ffff-ffff-ffffffffffff""""BuildLab""=""22000.co_release.210604-1628""""BuildLabEx""=""22000.1.amd64fre.co_release.210604-1628""""CompositionEditionID""=""Enterprise""""CurrentBuild""=""22000""""CurrentBuildNumber""=""22000""""CurrentMajorVersionNumber""=dword:0000000a""CurrentMinorVersionNumber""=dword:00000000""CurrentType""=""Multiprocessor Free""""CurrentVersion""=""6.3""""DisplayVersion""=""21H2""""EditionID""=""Enterprise""""EditionSubManufacturer""=""""""EditionSubstring""=""""""EditionSubVersion""=""""""InstallationType""=""Client""""InstallDate""=dword:00000000""ProductName""=""Windows 10 Enterprise""""ReleaseId""=""2009""""SoftwareType""=""System""""SystemRoot""=""C:\\Windows""""UBR""=dword:0000020f""RegisteredOwner""=""[redacted]""""RegisteredOrganization""=""""""PathName""=""C:\\Windows""```* `Windows 10 Pro`: As I can see `ProductName` is being used in the source code so should be `Windows 10 Enterprise` at least. Not sure where he found `Windows 10 Pro`.* `2009`: Using `DisplayVersion` (`21H2`) should be more accurate with what is reported by sysinfo.`winver` output:![image](https://user-images.githubusercontent.com/1951866/155297027-b8454a86-5e81-413f-801b-d95b59f5ade0.png)cc @thaJeztah 
"
43229,0,2450,11,1,1,MoritzKn,0,"title:Terminal Size Zero in Docker Run. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**`ioctl(STDIN_FILENO, TIOCGWINSZ, &ws)` returns a terminal size of 0 columns and 0 lines and no error code when run in docker.When using `tput` you see 24 lines and 80 columns. I think the underlying issue is the same but `tput` seems to fall back to a default value.This is only the case when the command is run right away after starting the container with `docker run`. A short delay fixes the issue.**Steps to reproduce the issue:**See this repo for a detailed minimal reproduction:- [MoritzKn/docker-terminal-size-issues](https://github.com/MoritzKn/docker-terminal-size-issues)Or this code snipped for a quick demo of the issue:```shdocker run -t ubuntu:16.04 tput lines# vsdocker run -t ubuntu:16.04 bash -c 'sleep 0.1 && tput lines'```**Describe the results you received:**The first command always returns 24. The second command returns the actual terminal size.**Describe the results you expected:**Both commands should return the same value, i.e. the actual terminal size.**Additional information you deem important (e.g. issue happens only occasionally):**This was already reported previously as #25450 and supposed to be fixed through opencontainers/runc#1275 and #37172 however the behavior seems to have persisted or reappeared.This is also evidenced by [this comment](https://github.com/moby/moby/issues/25450#issuecomment-357355857) with 14 likes:> I just updated to the latest CE docker for mac install and I ran into this issue. I'm only able to get it to ""work"" by passing in the COLUMNS/LINES/TERM vars into docker exec. >Is this something that hasn't landed yet on docker for mac?**Output of `docker version`:**```Client: Cloud integration: 1.0.17 Version:           20.10.8 API version:       1.41 Go version:        go1.16.6 Git commit:        3967b7d Built:             Fri Jul 30 19:55:20 2021 OS/Arch:           darwin/arm64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.8  API version:      1.41 (minimum version 1.12)  Go version:       go1.16.6  Git commit:       75249d8  Built:            Fri Jul 30 19:53:48 2021  OS/Arch:          linux/arm64  Experimental:     true containerd:  Version:          1.4.9  GitCommit:        e25210fe30a0a703442421b0f60afac609f950a3 runc:  Version:          1.0.1  GitCommit:        v1.0.1-0-g4144b63 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  buildx: Build with BuildKit (Docker Inc., v0.6.3)  compose: Docker Compose (Docker Inc., v2.0.0)  scan: Docker Scan (Docker Inc., v0.8.0)Server: Containers: 313  Running: 0  Paused: 0  Stopped: 313 Images: 126 Server Version: 20.10.8 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: e25210fe30a0a703442421b0f60afac609f950a3 runc version: v1.0.1-0-g4144b63 init version: de40ad0 Security Options:  seccomp   Profile: default Kernel Version: 5.10.47-linuxkit Operating System: Docker Desktop OSType: linux Architecture: aarch64 CPUs: 4 Total Memory: 3.841GiB Name: docker-desktop ID: C73Z:I6SH:3JDZ:UE3T:MK7K:27OA:V4RI:ZIF7:PEAA:F33M:BDMB:IION Docker Root Dir: /var/lib/docker Debug Mode: false HTTP Proxy: http.docker.internal:3128 HTTPS Proxy: http.docker.internal:3128 Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Reproduced both on Docker for Mac and Docker for Linux.
"
43102,1,4434,0,0,0,dyoueco,0,"title:Docker runs well but the docker command will get ""Unexpected fault address"" (`github.com/docker/cli/cli/command.ShowHelp.func1`). description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->My docker run with docker-compose and all the containers run well. But when I send any docker related command even docker command without any parameters I got the ""Unexpected fault address""<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. send ""docker ps"" or ""docker"" 2. It fails with msg listed below3.**Describe the results you received:**```unexpected fault address 0x55c4454038c0fatal error: fault[signal SIGSEGV: segmentation violation code=0x1 addr=0x55c4454038c0 pc=0x55c4454038c0]goroutine 1 [running]:runtime.throw(0x55c44ca2fbe9, 0x5)	/usr/local/go/src/runtime/panic.go:1117 +0x74 fp=0xc0005b78c8 sp=0xc0005b7898 pc=0x55c44b42cb34runtime.sigpanic()	/usr/local/go/src/runtime/signal_unix.go:741 +0x285 fp=0xc0005b7900 sp=0xc0005b78c8 pc=0x55c44b443a45text/template/parse.New(...)	/usr/local/go/src/text/template/parse/parse.go:131text/template/parse.Parse(0x55c44ca2e6a6, 0x3, 0x55c44caa88d9, 0x3b, 0x0, 0x0, 0x0, 0x0, 0xc000460130, 0x2, ...)	/usr/local/go/src/text/template/parse/parse.go:63 +0x45 fp=0xc0005b7988 sp=0xc0005b7900 pc=0x55c44ba0ae85text/template.(*Template).Parse(0xc00014c680, 0x55c44caa88d9, 0x3b, 0xc000182100, 0xc0005b7ae0, 0x55c44ba396f2)	/usr/local/go/src/text/template/template.go:210 +0x825 fp=0xc0005b7a98 sp=0xc0005b7988 pc=0x55c44ba2be65github.com/docker/cli/vendor/github.com/spf13/cobra.tmpl(0x55c44d0b7398, 0xc000010020, 0x55c44caa88d9, 0x3b, 0x55c44d08cba0, 0xc0000e4b00, 0xc0000e4b00, 0xc0005b7b00)	/go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/cobra.go:160 +0x92 fp=0xc0005b7af0 sp=0xc0005b7a98 pc=0x55c44ba312d2github.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).HelpFunc.func1(0xc0000e4b00, 0x55c44deaaa30, 0x0, 0x0)	/go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:396 +0xbb fp=0xc0005b7b60 sp=0xc0005b7af0 pc=0x55c44ba3f1fbmain.setHelpFunc.func1(0xc0000e4b00, 0x55c44deaaa30, 0x0, 0x0)	/go/src/github.com/docker/cli/cmd/docker/docker.go:166 +0x28c fp=0xc0005b7be8 sp=0xc0005b7b60 pc=0x55c44ca288acgithub.com/docker/cli/cli/command.ShowHelp.func1(0xc0000e4b00, 0x55c44deaaa30, 0x0, 0x0, 0x55c44ba3f4a0, 0xc0005b7c48)	/go/src/github.com/docker/cli/cli/command/cli.go:121 +0x83 fp=0xc0005b7c18 sp=0xc0005b7be8 pc=0x55c44ba4c603main.newDockerCommand.func1(0xc0000e4b00, 0x55c44deaaa30, 0x0, 0x0, 0x0, 0x0)	/go/src/github.com/docker/cli/cmd/docker/docker.go:44 +0x78 fp=0xc0005b7c70 sp=0xc0005b7c18 pc=0x55c44ca280f8github.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).execute(0xc0000e4b00, 0x55c44deaaa30, 0x0, 0x0, 0xc0000e4b00, 0x55c44deaaa30)	/go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:850 +0x472 fp=0xc0005b7d30 sp=0xc0005b7c70 pc=0x55c44ba34ef2github.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc0000e4b00, 0xc00043d860, 0xc0000e4b00, 0x55c44deaaa30)	/go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:958 +0x375 fp=0xc0005b7e10 sp=0xc0005b7d30 pc=0x55c44ba35a75github.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).Execute(...)	/go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:895main.runDocker(0xc00043d860, 0x55c44d0b7398, 0xc000010020)	/go/src/github.com/docker/cli/cmd/docker/docker.go:287 +0x1eb fp=0xc0005b7ef8 sp=0xc0005b7e10 pc=0x55c44ca26b2bmain.main()	/go/src/github.com/docker/cli/cmd/docker/docker.go:298 +0xfc fp=0xc0005b7f88 sp=0xc0005b7ef8 pc=0x55c44ca26e3cruntime.main()	/usr/local/go/src/runtime/proc.go:225 +0x263 fp=0xc0005b7fe0 sp=0xc0005b7f88 pc=0x55c44b42f3a3runtime.goexit()	/usr/local/go/src/runtime/asm_amd64.s:1371 +0x1 fp=0xc0005b7fe8 sp=0xc0005b7fe0 pc=0x55c44b463ac1goroutine 19 [chan receive]:github.com/docker/cli/vendor/k8s.io/klog.(*loggingT).flushDaemon(0x55c44de7b1e0)	/go/src/github.com/docker/cli/vendor/k8s.io/klog/klog.go:1010 +0x8dcreated by github.com/docker/cli/vendor/k8s.io/klog.init.0	/go/src/github.com/docker/cli/vendor/k8s.io/klog/klog.go:411 +0xd8```**Describe the results you expected:**```CONTAINER ID   IMAGE               COMMAND                  CREATED        STATUS      PORTS                                                                                  NAMESb9242a59071c   eclipse-mosquitto   ""/docker-entrypoint.闂?   6 months ago   Up 6 days   0.0.0.0:1883->1883/tcp"
42786,1,2782,49,0,0,leesei,0,"title:Replica not working as before in multiple Compose files. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**I've been using multiple Compose files to suppress some services and run it locally in dev environment .**Steps to reproduce the issue:**1. docker stack deploy -c stack.yaml -c stack.dev.yaml testhttps://gist.github.com/leesei/aaa22b2ea191c2ef313096622359c7e9**Describe the results you received:**2 instances of caddy service, 2 instances of mongo service**Describe the results you expected:**0 instances of caddy service, 2 instances of mongo service**Additional information you deem important (e.g. issue happens only occasionally):**It used to work before.In recent release (maybe a month or so) this was not working anymore.It works if I remove the replica setting in the base `stack.yaml` but I intended it to be my production config.I would like to see if this is the expected behavior, that the base yaml should not contain replica setting.**Output of `docker version`:**```Client: Version:           20.10.8 API version:       1.41 Go version:        go1.16.6 Git commit:        3967b7d28e Built:             Wed Aug  4 10:59:01 2021 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          20.10.7  API version:      1.41 (minimum version 1.12)  Go version:       go1.16.4  Git commit:       b0f5bc36fe  Built:            Fri Jun  4 08:14:24 2021  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.5.2  GitCommit:        36cc874494a56a253cd181a1a685b44b58a2e34a.m runc:  Version:          1.0.1  GitCommit:        v1.0.1-0-g4144b638 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  buildx: Build with BuildKit (Docker Inc., v0.6.1-docker)Server: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 32 Server Version: 20.10.7 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false  userxattr: false Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: active  NodeID: hgu2bdliejhoaftel9e2x9u96  Is Manager: true  ClusterID: gaphvwyuvw21fqiv8jndm2u3u  Managers: 1  Nodes: 1  Default Address Pool: 10.0.0.0/8    SubnetSize: 24  Data Path Port: 4789  Orchestration:   Task History Retention Limit: 5  Raft:   Snapshot Interval: 10000   Number of Old Snapshots to Retain: 0   Heartbeat Tick: 1   Election Tick: 3  Dispatcher:   Heartbeat Period: 5 seconds  CA Configuration:   Expiry Duration: 3 months   Force Rotate: 0  Autolock Managers: false  Root Rotation In Progress: false  Node Address: 10.6.64.48  Manager Addresses:   10.6.64.48:2377 Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 36cc874494a56a253cd181a1a685b44b58a2e34a.m runc version: v1.0.1-0-g4144b638 init version: de40ad0 Security Options:  seccomp   Profile: default  cgroupns Kernel Version: 5.12.9-arch1-1 Operating System: Antergos Linux OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 31.23GiB Name: kylee-arch ID: FEMU:DA7A:ZSTT:TKA5:ZQNQ:672W:ZL6Q:DIRC:OXH4:LQVY:KAXR:DT72 Docker Root Dir: /var/lib/docker Debug Mode: false Username: leesei Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Arch on physical machine, everything up to date.
"
42713,1,0,0,0,0,wangchonghu,0,"title:panic闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟鐑橆殔閺勩儵鏌涢幇闈涙灈闁绘帒鐏氶妵鍕箳瀹ュ洩绐楀┑鐐存尵閸楁檱alid memory address or nil pointer dereference闂?in rejoinClusterBootStrap. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->The swarm node crash with panic when cpu-load keeps high(>90%)闂?panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x10 pc=0xaaaac8a00f98] goroutine 3450 [running]: panic(0xaaaac96b64a0, 0xaaaaca638ff0) 	/go/src/runtime/panic.go:1065 +0x4d8 fp=0x4009229d10 sp=0x4009229c40 pc=0xaaaac7f66948 runtime.panicmem() 	/go/src/runtime/panic.go:212 +0x58 fp=0x4009229d30 sp=0x4009229d10 pc=0xaaaac7f64d08 runtime.sigpanic() 	/go/src/runtime/signal_unix.go:734 +0x154 fp=0x4009229d70 sp=0x4009229d30 pc=0xaaaac7f7e374 github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).rejoinClusterBootStrap(0x400974b680) 	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:305 +0x488 fp=0x4009229ee0 sp=0x4009229d80 pc=0xaaaac8a00f98 github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).rejoinClusterBootStrap-fm() 	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:284 +0x30 fp=0x4009229f00 sp=0x4009229ee0 pc=0xaaaac8a26520 github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).triggerFunc(0x400974b680, 0xdf8475800, 0x4007aa19e0, 0x4007f8d8e0) 	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:256 +0xdc fp=0x4009229fb0 sp=0x4009229f00 pc=0xaaaac8a0085c runtime.goexit() 	/go/src/runtime/asm_arm64.s:1130 +0x4 fp=0x4009229fb0 sp=0x4009229fb0 pc=0xaaaac7f9e024 created by github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).clusterInit 	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:178 +0x770
"
42698,0,296,200,0,0,thaJeztah,0,"title:Flaky test: TestNetworkDBNodeJoinLeaveIteration. description:Looks like https://github.com/moby/moby/pull/42625#issuecomment-878447879 didn't fully resolve the flakiness in this test;``` === FAIL: libnetwork/networkdb TestNetworkDBNodeJoinLeaveIteration (5.81s)[2021-07-29T18:12:43.071Z]     networkdb_test.go:511: Network existence verification failed[2021-07-29T18:12:43.071Z]     networkdb_test.go:513: The networkNodes list has to have be 2 instead of 1 - [8518394491d6]```
"
42493,1,1892,200,0,1,thaJeztah,0,"title:Flaky test: libnetwork TestPortMappingV6Config (and broken on ppc64le). description:See https://ci-next.docker.com/public/blue/organizations/jenkins/moby/detail/PR-42325/6/testsLooks like `modprobe` is not installed on the ppc64le machines (may have to install https://packages.debian.org/buster/kmod), causing thistest to fail. I think this was added in the libnetwork migration, so we shouldfix this (either in the Jenkinsfile, or ideally update the machine configurations)```=== RUN   TestPortMappingV6Configtime=""2021-06-07T21:23:04Z"" level=warning msg=""Running modprobe bridge br_netfilter failed with message: , error: exec: \""modprobe\"": executable file not found in $PATH""time=""2021-06-07T21:23:04Z"" level=warning msg=""running inside docker container, ignoring missing kernel params: open /proc/sys/net/bridge/bridge-nf-call-iptables: no such file or directory""time=""2021-06-07T21:23:04Z"" level=warning msg=""bridge store not initialized. kv object docker/network/v1.0/bridge/dummy/ is not added to the store""time=""2021-06-07T21:23:04Z"" level=warning msg=""bridge store not initialized. kv object docker/network/v1.0/bridge-endpoint/ep1/ is not added to the store""time=""2021-06-07T21:23:05Z"" level=warning msg=""bridge store not initialized. kv object docker/network/v1.0/bridge-endpoint/ep1/ is not added to the store""--- FAIL: TestPortMappingV6Config (0.81s)    port_mapping_test.go:157: Failed to store the port bindings into the sandbox info. Found: [{udp 172.19.0.11 400 0.0.0.0 54000 54000} {tcp 172.19.0.11 500 0.0.0.0 65000 65000} {sctp 172.19.0.11 500 0.0.0.0 65000 65000}]```On s390x, the test is also failing, but not showing the `modprobe` error:```=== RUN   TestPortMappingV6Configtime=""2021-06-07T21:18:20Z"" level=warning msg=""bridge store not initialized. kv object docker/network/v1.0/bridge/dummy/ is not added to the store""time=""2021-06-07T21:18:20Z"" level=warning msg=""bridge store not initialized. kv object docker/network/v1.0/bridge-endpoint/ep1/ is not added to the store""time=""2021-06-07T21:18:20Z"" level=warning msg=""bridge store not initialized. kv object docker/network/v1.0/bridge-endpoint/ep1/ is not added to the store""--- FAIL: TestPortMappingV6Config (1.54s)    port_mapping_test.go:157: Failed to store the port bindings into the sandbox info. Found: [{udp 172.19.0.11 400 0.0.0.0 54000 54000} {tcp 172.19.0.11 500 0.0.0.0 65000 65000} {sctp 172.19.0.11 500 0.0.0.0 65000 65000}]```
"
42458,0,323,274,0,0,samuelkarp,0,"title:Flaky test: libnetwork/iptables TestConcurrencyNoWait. description:Looks like this failed a couple times on https://github.com/moby/moby/pull/42409``` === FAIL: libnetwork/iptables TestConcurrencyNoWait (0.14s)     iptables_test.go:217:  (iptables failed: iptables -t nat -A POSTROUTING -p tcp -s 172.17.0.1 -d 172.17.0.1 --dport 4321 -j MASQUERADE: Another app is currently holding the xtables lock. Perhaps you want to use the -w option?          (exit status 4))```
"
42314,0,1570,8,0,0,xinfengliu,0,"title:Analysis of docker swarm ""dispatcher is stopped"". description:I have seen a few times that the swarm dispatcher is gone and the swarm cluster stopped working. The only way to recover is restarting the manager nodes.I happen to have a stacktrace of the leader node captured at the problem time, the docker version is `19.03.12`.[daemon-stack-trace.zip](https://github.com/moby/moby/files/6358233/daemon-stack-trace.zip)In the stacktrace, there's no `dispatcher` stack, but there's a stack `becomeFollower`, this is abnormal. It is blocked in `(*LogBroker).Stop````goroutine 613 [semacquire, 747 minutes]:sync.runtime_SemacquireMutex(0xc000b1a184, 0x0, 0x1)        /.GOROOT/src/runtime/sema.go:71 +0x49sync.(*Mutex).lockSlow(0xc000b1a180)        /.GOROOT/src/sync/mutex.go:138 +0xfesync.(*Mutex).Lock(...)        /.GOROOT/src/sync/mutex.go:81sync.(*RWMutex).Lock(0xc000b1a180)        /.GOROOT/src/sync/rwmutex.go:98 +0x99github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/logbroker.(*LogBroker).Stop(0xc000b1a180, 0x0, 0x0)        /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/logbroker/broker.go:78 +0x3bgithub.com/docker/docker/vendor/github.com/docker/swarmkit/manager.(*Manager).becomeFollower(0xc000845860)        /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/manager.go:1111 +0x4d```Below code means if `becomeFollower()` is blocked, then `becomeLeader()` has no chance to run when the node is re-elected as the leader. Thus `dispatcher` will not be run.```// handleLeadershipEvents handles the is leader event or is follower event.func (m *Manager) handleLeadershipEvents(ctx context.Context, leadershipCh chan events.Event) {	// get the current leader and save it for logging leadership changes in	// this loop	oldLeader := m.getLeaderNodeID()	for {		select {		case leadershipEvent := <-leadershipCh:			m.mu.Lock()			if m.stopped {				m.mu.Unlock()				return			}			newState := leadershipEvent.(raft.LeadershipState)			if newState == raft.IsLeader {				m.becomeLeader(ctx)				leaderMetric.Set(1)			} else if newState == raft.IsFollower {				m.becomeFollower()				leaderMetric.Set(0)...```
"
42288,0,9106,10,0,0,Gui13,0,"title:Docker 20.10.6: all containers stopped and cannot start if ipv6 is disabled on host. description:Related to the release notes here: https://docs.docker.com/engine/release-notes/#20106Possibly related bug: https://github.com/moby/libnetwork/issues/2629**Description**Since upgrading (automatically) to docker-ce 20.10.06, all our containers fail to start.The error says:  **failed to start container"" container=[number removed] error=""driver failed programming external connectivity on endpoint tvheadend ([number removed]): Error starting userland proxy: listen tcp6 [::]:9982: socket: address family not supported by protocol""**Our docker machines have ipv6 disabled in the kernel with the commandline `ipv6.disable=1`**Steps to reproduce the issue:**1. Have ipv6 disabled2. Update docker to 20.10.063. All your containers fail to start**Describe the results you received:**All your containers fail to start**Describe the results you expected:**Containers restart normally?**Additional information you deem important (e.g. issue happens only occasionally):**This is the log we get at docker start:```avril 13 07:26:20 apigateway1 systemd[1]: Starting Docker Application Container Engine...avril 13 07:26:25 apigateway1 dockerd[775]: time=""2021-04-13T07:26:25.939440237Z"" level=info msg=""Starting up""avril 13 07:26:26 apigateway1 dockerd[775]: time=""2021-04-13T07:26:26.248057733Z"" level=info msg=""parsed scheme: \""unix\"""" module=grpcavril 13 07:26:26 apigateway1 dockerd[775]: time=""2021-04-13T07:26:26.248153074Z"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpcavril 13 07:26:26 apigateway1 dockerd[775]: time=""2021-04-13T07:26:26.248233851Z"" level=info msg=""ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}"" module=grpcavril 13 07:26:26 apigateway1 dockerd[775]: time=""2021-04-13T07:26:26.248307947Z"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpcavril 13 07:26:26 apigateway1 dockerd[775]: time=""2021-04-13T07:26:26.265810303Z"" level=info msg=""parsed scheme: \""unix\"""" module=grpcavril 13 07:26:26 apigateway1 dockerd[775]: time=""2021-04-13T07:26:26.265857230Z"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpcavril 13 07:26:26 apigateway1 dockerd[775]: time=""2021-04-13T07:26:26.265891159Z"" level=info msg=""ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}"" module=grpcavril 13 07:26:26 apigateway1 dockerd[775]: time=""2021-04-13T07:26:26.265910772Z"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpcavril 13 07:26:26 apigateway1 dockerd[775]: time=""2021-04-13T07:26:26.636639243Z"" level=info msg=""[graphdriver] using prior storage driver: overlay2""avril 13 07:26:26 apigateway1 dockerd[775]: time=""2021-04-13T07:26:26.915413961Z"" level=warning msg=""Your kernel does not support swap memory limit""avril 13 07:26:26 apigateway1 dockerd[775]: time=""2021-04-13T07:26:26.915450962Z"" level=warning msg=""Your kernel does not support CPU realtime scheduler""avril 13 07:26:26 apigateway1 dockerd[775]: time=""2021-04-13T07:26:26.915919011Z"" level=info msg=""Loading containers: start.""avril 13 07:26:27 apigateway1 dockerd[775]: time=""2021-04-13T07:26:27.817745243Z"" level=info msg=""failed to read ipv6 net.ipv6.conf.<bridge>.accept_ra"" bridge=br-3458afb7e0fb syspath=/proc/sys/net/ipv6/conf/br-3458afb7e0fb/accept_raavril 13 07:26:27 apigateway1 dockerd[775]: time=""2021-04-13T07:26:27.884334406Z"" level=info msg=""failed to read ipv6 net.ipv6.conf.<bridge>.accept_ra"" bridge=docker0 syspath=/proc/sys/net/ipv6/conf/docker0/accept_raavril 13 07:26:27 apigateway1 dockerd[775]: time=""2021-04-13T07:26:27.884919514Z"" level=info msg=""failed to read ipv6 net.ipv6.conf.<bridge>.accept_ra"" bridge=docker0 syspath=/proc/sys/net/ipv6/conf/docker0/accept_raavril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.169815521Z"" level=info msg=""Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.170524023Z"" level=info msg=""failed to read ipv6 net.ipv6.conf.<bridge>.accept_ra"" bridge=docker0 syspath=/proc/sys/net/ipv6/conf/docker0/accept_raavril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.461643528Z"" level=warning msg=""Failed to allocate and map port 1337-1337: Error starting userland proxy: listen tcp6 [::]:1337: socket: address family not supported by protocol""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.489205748Z"" level=warning msg=""Failed to allocate and map port 8080-8080: Error starting userland proxy: listen tcp6 [::]:8080: socket: address family not supported by protocol""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.629822309Z"" level=warning msg=""Failed to allocate and map port 8000-8000: Error starting userland proxy: listen tcp6 [::]:8000: socket: address family not supported by protocol""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.670531244Z"" level=error msg=""791cd702dbdc24094aa27be1a6bf21e3b008b545d297b1e1181d5d278ae0ef62 cleanup: failed to delete container from containerd: no such container""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.670913826Z"" level=error msg=""failed to start container"" container=791cd702dbdc24094aa27be1a6bf21e3b008b545d297b1e1181d5d278ae0ef62 error=""driver failed programming external connectivity on endpoint kong_konga_1 (f1cafeb16e89b42fb4f418add1abee0b44dc7c776b1dd5d5a97fbc04dda863de): Error starting userland proxy: listen tcp6 [::]:1337: socket: address family not supported by protocol""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.722145131Z"" level=warning msg=""Failed to allocate and map port 9042-9042: Error starting userland proxy: listen tcp6 [::]:9042: socket: address family not supported by protocol""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.772404127Z"" level=error msg=""c997c4c1b097c34a2688d30a9c178f297866098ce86cfd437e20689b0631fa11 cleanup: failed to delete container from containerd: no such container""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.772911179Z"" level=error msg=""failed to start container"" container=c997c4c1b097c34a2688d30a9c178f297866098ce86cfd437e20689b0631fa11 error=""driver failed programming external connectivity on endpoint kong_kong-sidecar_1 (d54f401742450b01cb649b428f91ef76b820e4722a43b77406d24c5f8a888e0a): Error starting userland proxy: listen tcp6 [::]:8080: socket: address family not supported by protocol""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.884089786Z"" level=error msg=""1dd07dc91b27d7a57c7c3becbb1519fee76bbe79ff79569270a4731735a4861f cleanup: failed to delete container from containerd: no such container""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.884841529Z"" level=error msg=""failed to start container"" container=1dd07dc91b27d7a57c7c3becbb1519fee76bbe79ff79569270a4731735a4861f error=""driver failed programming external connectivity on endpoint kong_kong_1 (7d0441a5219f56147a10ce269edb8b7cd07391846a25db3cc445a30e79b03a45): Error starting userland proxy: listen tcp6 [::]:8000: socket: address family not supported by protocol""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.972249864Z"" level=error msg=""c77ee0c3833f73b747ed9ad7affa3a692123b909bf8fce8107402d0c7e3f4ba5 cleanup: failed to delete container from containerd: no such container""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.972310664Z"" level=error msg=""failed to start container"" container=c77ee0c3833f73b747ed9ad7affa3a692123b909bf8fce8107402d0c7e3f4ba5 error=""driver failed programming external connectivity on endpoint kong_db_1 (a33664b1825441bef099df18cbd46470f449907ae8a16ba76f528b68d4abb26c): Error starting userland proxy: listen tcp6 [::]:9042: socket: address family not supported by protocol""avril 13 07:26:28 apigateway1 dockerd[775]: time=""2021-04-13T07:26:28.972369960Z"" level=info msg=""Loading containers: done.""avril 13 07:26:29 apigateway1 dockerd[775]: time=""2021-04-13T07:26:29.208780479Z"" level=info msg=""Docker daemon"" commit=8728dd2 graphdriver(s)=overlay2 version=20.10.6avril 13 07:26:29 apigateway1 dockerd[775]: time=""2021-04-13T07:26:29.209351109Z"" level=info msg=""Daemon has completed initialization""avril 13 07:26:29 apigateway1 systemd[1]: Started Docker Application Container Engine.```**Output of `docker version`:**```Docker version 20.10.6, build 370c289```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)  scan: Docker Scan (Docker Inc., v0.7.0)Server: Containers: 6  Running: 4  Paused: 0  Stopped: 2 Images: 8 Server Version: 20.10.5 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 05f951a3781f4f2c1911b05e61c160e9c30eaa8e runc version: 12644e614e25b05da6fd08a38ffa0cfe1903fdec init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.19.0-16-amd64 Operating System: Debian GNU/Linux 10 (buster) OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 3.854GiB Name: apigateway1 ID: ZTQA:TV6R:PYGF:SJ6W:TEDY:74TF:LT4T:DUHS:UATR:LUJY:FSH7:HL53 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**The docker machines run on KVM, and are on Debian 9 or 10 depending on freshness of install.
"
42206,0,0,10,0,0,onurbbr,0,"title:Docker Rootless I/O Error. description:Hello there. I'm new to Docker. I am an Arch Linux user. After installing Docker's rootless, I follow the necessary steps. I get this error when I pull the archlinux and ubuntu image from Docker. I install busybox and hello-world images in Docker Rootless without any problem.[onur@archlinux ~]$ docker pull archlinuxUsing default tag: latestlatest: Pulling from library/archlinux19c50925705c: Pull complete 200e2a8b5fe3: Extracting [==================================================>]  6.645kB/6.645kBfailed to register layer: Error processing tar file(exit status 1): replaceDirWithOverlayOpaque(""/var/cache/ldconfig"") failed: createDirWithOverlayOpaque(""/var/cache/rdwoo127155212"") failed: failed to mkdir /var/cache/rdwoo127155212/m/d: mkdir /var/cache/rdwoo127155212/m/d: input/output error[onur@archlinux ~]$ docker pull ubuntuUsing default tag: latestlatest: Pulling from library/ubuntu04a5f4cda3ee: Pull complete ff496a88c8ed: Pull complete 0ce83f459fe7: Extracting [==================================================>]     189B/189Bfailed to register layer: Error processing tar file(exit status 1): replaceDirWithOverlayOpaque(""/run/systemd"") failed: createDirWithOverlayOpaque(""/run/rdwoo953609474"") failed: failed to mkdir /run/rdwoo953609474/m/d: mkdir /run/rdwoo953609474/m/d: input/output error[onur@archlinux ~]$ docker pull busyboxUsing default tag: latestlatest: Pulling from library/busybox8b3d7e226fab: Pull complete Digest: sha256:ce2360d5189a033012fbad1635e037be86f23b65cfd676b436d0931af390a2acStatus: Downloaded newer image for busybox:latestdocker.io/library/busybox:latest[onur@archlinux ~]$ docker pull hello-worldUsing default tag: latestlatest: Pulling from library/hello-worldb8dfde127a29: Pull complete Digest: sha256:308866a43596e83578c7dfa15e27a73011bdd402185a84c5cd7f32a88b501a24Status: Downloaded newer image for hello-world:latestdocker.io/library/hello-world:latestI had installed docker in Ubuntu before and did not encounter any problems like this. I have such a problem. I installed and tried Docker Rootless 20.10.3 from the AUR repos, but this issue also exists in this version. I upgraded Docker Rootless to 20.10.5 but my problem still persists. How can I solve this?I added to .zshrc:export PATH=/usr/bin:$PATHexport DOCKER_HOST=unix://$XDG_RUNTIME_DIR/docker.sockFilesystem Info:[onur@archlinux ~]$ df -khTFilesystem     Type      Size  Used Avail Use% Mounted ondev            devtmpfs  7.8G     0  7.8G   0% /devrun            tmpfs     7.8G  1.9M  7.8G   1% /run/dev/nvme0n1p2 ext4      230G   64G  155G  30% /tmpfs          tmpfs     7.8G  1.5M  7.8G   1% /dev/shmtmpfs          tmpfs     4.0M     0  4.0M   0% /sys/fs/cgrouptmpfs          tmpfs     7.8G   28M  7.8G   1% /tmp/dev/nvme1n1p1 ext4      234G   61M  222G   1% /mnt/Projects/dev/nvme0n1p1 vfat      511M  144K  511M   1% /boot/efi/dev/sda1      ext4      916G   77M  870G   1% /mnt/Storagetmpfs          tmpfs     1.6G  112K  1.6G   1% /run/user/1000Docker Rootless Info:[onur@archlinux ~]$ pacman -Qi docker-rootless-extras-binName            : docker-rootless-extras-binVersion         : 20.10.5-1Description     : Extras to run docker as non-root.Architecture    : x86_64URL             : https://docs.docker.com/engine/security/rootless/Licenses        : ApacheGroups          : NoneProvides        : docker-rootless  docker-rootless-extrasDepends On      : dockerOptional Deps   : fuse-overlayfs: overlayfs support [installed]                  slirp4netns: faster network stack [installed]Required By     : NoneOptional For    : NoneConflicts With  : docker-rootless  docker-rootless-extrasReplaces        : NoneInstalled Size  : 36.89 MiBPackager        : Unknown PackagerBuild Date      : Fri 26 Mar 2021 10:23:36 AM +03Install Date    : Fri 26 Mar 2021 10:23:48 AM +03Install Reason  : Explicitly installedInstall Script  : YesValidated By    : NoneDocker Version:[onur@archlinux ~]$ docker versionClient: Version:           20.10.5 API version:       1.41 Go version:        go1.16 Git commit:        55c4c88966 Built:             Wed Mar  3 16:51:54 2021 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          20.10.5  API version:      1.41 (minimum version 1.12)  Go version:       go1.16  Git commit:       363e9a88a1  Built:            Wed Mar  3 16:51:28 2021  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.4.4  GitCommit:        05f951a3781f4f2c1911b05e61c160e9c30eaa8e.m runc:  Version:          1.0.0-rc93  GitCommit:        12644e614e25b05da6fd08a38ffa0cfe1903fdec docker-init:  Version:          0.19.0  GitCommit:        de40ad0Docker info:[onur@archlinux ~]$ docker infoClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-tp-docker)Server: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 2 Server Version: 20.10.5 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: none Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 05f951a3781f4f2c1911b05e61c160e9c30eaa8e.m runc version: 12644e614e25b05da6fd08a38ffa0cfe1903fdec init version: de40ad0 Security Options:  seccomp   Profile: default  rootless Kernel Version: 5.11.9-arch1-1 Operating System: Arch Linux OSType: linux Architecture: x86_64 CPUs: 12 Total Memory: 15.47GiB Name: archlinux ID: C7P3:KBNS:5FMK:34AU:I2YH:YFJH:TN4X:OD7B:B77K:7IF7:5EEF:YWWH Docker Root Dir: /mnt/Storage/VMs/Docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: Running in rootless-mode without cgroups. To enable cgroups in rootless-mode, you need to boot the system in cgroup v2 mode.WARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled
"
42191,0,4774,27,0,0,marcelo-ochoa,0,"title:docker plugin create on 20.x version makes unusable plugins for 19.x/18.x/17.x. description:**A plugin created and pulled to hub.docker.com using 20.x version will fail to install on 19-17.x version with error: Layers from manifest don't match image configuration**When building on 20.10.5 version of Docker Engine/Cli a docker volume plugins from project [docker-volume-plugins](https://github.com/marcelo-ochoa/docker-volume-plugins) I found that I can't install on Docker Engine 19/18/17 version with an error Layers from manifest don't match image configuration.**Steps to reproduce the issue:**Build a plugin using 20.x version of Docker engine/cli1. docker plugin create mochoa/s3fs-volume-plugin-x86_64:latest  build2. docker plugin push mochoa/s3fs-volume-plugin-x86_64:latest Installing on previous release of Docker engine/cli (for example 19.x)1. docker plugin install --alias s3fs mochoa/s3fs-volume-plugin-x86_64:latest --grant-all-permissions --disableAbove command shows this output:```bash$ docker plugin install --alias s3fs mochoa/s3fs-volume-plugin-x86_64:test --grant-all-permissions --disableTrying to pull repository docker.io/mochoa/s3fs-volume-plugin-x86_64 ... test: Pulling from docker.io/mochoa/s3fs-volume-plugin-x86_647cb61fa08378: Download complete layers from manifest don't match image configuration```If same plugin is built using Docker engine/cli 19.x version it works OK:```bash$ docker plugin install --alias s3fs mochoa/s3fs-volume-plugin-x86_64:latest --grant-all-permissions --disableTrying to pull repository docker.io/mochoa/s3fs-volume-plugin-x86_64 ... latest: Pulling from docker.io/mochoa/s3fs-volume-plugin-x86_646adc36b99bc7: Download complete Digest: sha256:7131b6621c320a08ae61aa95ecc8d932997c1e48dbff4dae43708e62b37d906dStatus: Downloaded newer image for mochoa/s3fs-volume-plugin-x86_64:latestInstalled plugin mochoa/s3fs-volume-plugin-x86_64:latest```**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.5 API version:       1.41 Go version:        go1.13.15 Git commit:        55c4c88 Built:             Tue Mar  2 20:18:20 2021 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.5  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       363e9a8  Built:            Tue Mar  2 20:16:15 2021  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          1.4.4  GitCommit:        05f951a3781f4f2c1911b05e61c160e9c30eaa8e runc:  Version:          1.0.0-rc93  GitCommit:        12644e614e25b05da6fd08a38ffa0cfe1903fdec docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.4.2)Server: Containers: 10  Running: 0  Paused: 0  Stopped: 10 Images: 619 Server Version: 20.10.5 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: active  NodeID: mnzsbflpwe41140g27i79rd7b  Is Manager: true  ClusterID: wo4mmgys6wxs20w2aiw9kqaa1  Managers: 1  Nodes: 1  Default Address Pool: 10.0.0.0/8    SubnetSize: 24  Data Path Port: 4789  Orchestration:   Task History Retention Limit: 5  Raft:   Snapshot Interval: 10000   Number of Old Snapshots to Retain: 0   Heartbeat Tick: 1   Election Tick: 10  Dispatcher:   Heartbeat Period: 5 seconds  CA Configuration:   Expiry Duration: 3 months   Force Rotate: 0  Autolock Managers: false  Root Rotation In Progress: false  Node Address: 172.29.160.34  Manager Addresses:   172.29.160.34:2377 Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: 05f951a3781f4f2c1911b05e61c160e9c30eaa8e runc version: 12644e614e25b05da6fd08a38ffa0cfe1903fdec init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.4.0-67-generic Operating System: Ubuntu 20.04.2 LTS OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.51GiB Name: pocho ID: C3WY:YORD:TA4B:M6L5:JAJL:OKAU:5E4H:2QSP:Z3VM:FBYA:AJRO:RBZI Docker Root Dir: /var/lib/docker Debug Mode: false Username: mochoa Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```**Manifest of plugin created with [20.x](https://hub.docker.com/layers/142532700/mochoa/s3fs-volume-plugin-x86_64/test/images/sha256-9235dbfc8803bcf25ebc56a04710f30c8e804c6a155cef71e00e09604881a3a1?context=explore):**```{  ""schemaVersion"": 2,  ""config"": {    ""mediaType"": ""application/vnd.docker.plugin.v1+json"",    ""digest"": ""sha256:03a44636bcdb1b661261d654e732b44d0fb15396e0e037ed6099033baedd2347"",    ""size"": 1003  },  ""layers"": [    {      ""mediaType"": ""application/vnd.oci.image.layer.v1.tar+gzip"",      ""digest"": ""sha256:7cb61fa083786e446f1032b9798b8e3d08f086cfa0dac3b55873f0f1a2b46e18"",      ""size"": 55932817    }  ],  ""mediaType"": ""application/vnd.docker.distribution.manifest.v2+json""}```**Manifest of plugin created with [19.x](https://hub.docker.com/layers/141758479/mochoa/s3fs-volume-plugin-x86_64/latest/images/sha256-7131b6621c320a08ae61aa95ecc8d932997c1e48dbff4dae43708e62b37d906d?context=explore):**```{  ""schemaVersion"": 2,  ""mediaType"": ""application/vnd.docker.distribution.manifest.v2+json"",  ""config"": {    ""mediaType"": ""application/vnd.docker.plugin.v1+json"",    ""size"": 1004,    ""digest"": ""sha256:7032a5148630a0052372c8785ca23d0449a6da3d4910813af741278d2953c80b""  },  ""layers"": [    {      ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip"",      ""size"": 55932830,      ""digest"": ""sha256:6adc36b99bc70203bd542a473aa0f76fca363b14e4b08565558be60682162a3c""    }  ]}```Difference on mediaType:- ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip""- ""mediaType"": ""application/vnd.oci.image.layer.v1.tar+gzip""Plugins created with 20.x version works OK on 20.x engine.Complete discussion is at Slack channel # docker-storage thanks a lot @cpuguy83 for your time.
"
42177,0,0,247,0,0,AkihiroSuda,0,"title:overlayfs: s/trusted/user/ when userxattr is enabled (required for avoiding I/O error on kernel >= 5.11). description:https://github.com/moby/moby/blob/46cdcd206c56172b95ba5c77b827a722dab426c5/pkg/archive/archive_linux.go#L72-L91We should use `user.overlay.opaque`, not `trusted.overlay.opaque` when the filesystem is mounted with `userxattr` option: https://github.com/moby/moby/pull/42068
"
42151,0,2627,247,0,0,AkihiroSuda,0,"title:info: MemoryLimit, CPUShares, PIdsLimit, ..., should be shown as `false` when CgroupDriver == none (i.e. rootless cgroup v1). description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->`docker info --format {{ json . }}`  should not show `MemoryLimit`, `CPUShares`, `PidsLimit` to be true when `CgroupDriver` is `none` (i.e. rootless cgroup v1)**Steps to reproduce the issue:**1. Boot the host with cgroup v12. `dockerd-rootless-setuptool.sh install`3. `docker info --format {{ json. }}`**Describe the results you received:**```json{...  ""MemoryLimit"": true,  ""SwapLimit"": true,  ""KernelMemory"": true,  ""KernelMemoryTCP"": true,  ""CpuCfsPeriod"": true,  ""CpuCfsQuota"": true,  ""CPUShares"": true,  ""CPUSet"": true,  ""PidsLimit"": true,...  ""CgroupDriver"": ""none"",...}```**Describe the results you expected:**These should be false**Output of `docker version`:**```Client: Version:           20.10.0-dev API version:       1.41 Go version:        go1.13.15 Git commit:        d3c36a2a7 Built:             Mon Mar 15 04:15:07 2021 OS/Arch:           linux/amd64 Context:           rootless Experimental:      trueServer: Engine:  Version:          dev  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       4735a0c84f  Built:            Mon Mar 15 04:13:59 2021  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.5.0-beta.3-62-gecb881e5e  GitCommit:        ecb881e5e6e3ea77721865c5bb1d61725579fd54 runc:  Version:          1.0.0-rc93+dev  GitCommit:        249bca0a1316129dcd5bd38b5d75572274181cb5 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    rootless Debug Mode: false Plugins:  buildx: Build with BuildKit (Docker Inc., v0.5.1-45-gc9f02c3)Server: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 2 Server Version: dev Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: none Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: ecb881e5e6e3ea77721865c5bb1d61725579fd54 runc version: 249bca0a1316129dcd5bd38b5d75572274181cb5 init version: de40ad0 Security Options:  seccomp   Profile: default  rootless Kernel Version: 5.11.0-051100-generic Operating System: Ubuntu 20.10 OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 15.6GiB Name: suda-ws01 ID: CWVR:KJQU:3CNT:IJF7:FMME:22Y7:GKFW:AFKJ:IVLQ:JOVW:3KZY:S25M Docker Root Dir: /home/suda/.local/share/docker Debug Mode: false Username: akihirosuda Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: Running in rootless-mode without cgroups. To enable cgroups in rootless-mode, you need to boot the system in cgroup v2 mode.```
"
42133,1,2338,298,0,0,gvanbrakel,0,"title:Cannot COPY directories with wildcard in Dockerfile. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**In my Dockerfile, I want to copy files from a directory that has a variable part in the name. I would like to use a wildcard for this variable part, but that does not work:Does not work: ``COPY --chown=was:root target/project-*-dependencies/*.py /work/config/``Does work: ``COPY --chown=was:root target/project-7.6-SNAPSHOT-dependencies/*.py /work/config/``**Steps to reproduce the issue:**1. Create a Dockerfile with COPY command with a wildcard in the directory name2. Execute docker build .3. see error message **Describe the results you received:**I received an error message containing: ``error from sender: readdir: open target\project-*-dependencies: The filename, directory name, or volume label syntax is incorrect.``**Describe the results you expected:**I expected the files in the covered directory to be copied**Additional information you deem important (e.g. issue happens only occasionally):**Earlier I commented about this in issue #35604. **Output of `docker version`:**```Client: Docker Engine - Community Cloud integration: 1.0.9 Version:           20.10.5 API version:       1.41 Go version:        go1.13.15 Git commit:        55c4c88 Built:             Tue Mar  2 20:14:53 2021 OS/Arch:           windows/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.5  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       363e9a8  Built:            Tue Mar  2 20:15:47 2021  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)  scan: Docker Scan (Docker Inc., v0.5.0)Server: Containers: 13  Running: 6  Paused: 0  Stopped: 7 Images: 78 Server Version: 20.10.5 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  seccomp   Profile: default Kernel Version: 5.4.72-microsoft-standard-WSL2 Operating System: Docker Desktop OSType: linux Architecture: x86_64 CPUs: 12 Total Memory: 24.75GiB Name: docker-desktop ID: AGDW:ECHP:D3TZ:I4BA:SLND:SOJY:BRA5:A2GS:BSCV:I6H7:KNGO:6NKG Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
42125,0,2685,34,0,0,dnrce,0,"title:OOM when following ""local"" logs of high-log-output container. description:**Description**When logging to the `local` driver, Docker will quickly run out of memory when following the logs of a container with a lot of log output.This also occurs when following local logs while using a driver such as `syslog` that supports dual logging.This issue appears to be similar or identical to #39963.**Steps to reproduce the issue:**1. Run a container that logs heavily to the `local` driver:    ```    ID=$(docker run --rm -d --log-driver local alpine cat /dev/urandom)    ```2. Follow the container's logs:    ```    docker logs -f $ID > /dev/null    ```Alternatively:1. Run a container that logs heavily to a driver that supports dual logging:    ```    ID=$(docker run --rm -d --log-driver syslog --log-opt syslog-address=udp://127.0.0.1:0 alpine cat /dev/urandom)    ```2. Follow the container's logs:    ```    docker logs -f $ID > /dev/null    ```**Describe the results you received:**`dockerd` exits with `fatal error: runtime: out of memory`.Stack trace: https://gist.github.com/2f674f1ff24c679ba4778f458facb7b2**Describe the results you expected:**Docker remains stable and keeps a reasonable memory footprint.**Additional information you deem important (e.g. issue happens only occasionally):**I have been unable to reproduce the issue when logging to the `json-file` driver.**Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.5 API version:       1.41 Go version:        go1.13.15 Git commit:        55c4c88 Built:             Tue Mar  2 20:18:20 2021 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.5  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       363e9a8  Built:            Tue Mar  2 20:16:15 2021  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)Server: Containers: 1  Running: 1  Paused: 0  Stopped: 0 Images: 1 Server Version: 20.10.5 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: local Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.4.0-54-generic Operating System: Ubuntu 20.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 981.1MiB Name: ubuntu-focal ID: 5X6F:5OLY:MQHX:I5T3:AVJQ:AMIX:5OBO:XI4L:CI62:LRA7:INKW:26IT Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 30  Goroutines: 40  System Time: 2021-03-08T20:11:15.100104538Z  EventsListeners: 0 Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**This was initially observed in a [Nomad](https://www.nomadproject.io/) environment. Nomad follows logs by default for Docker tasks. The host was a lightly loaded AWS `m5.xlarge` instance.I have reproduced it on Ubuntu 16.04 and 20.04 using Virtualbox VMs, and on Docker for Mac 3.1.0 (20.10.2).
"
42101,0,3382,28,0,1,akomakom,0,"title:docker start hangs in 20.10.4 but not 20.10.3. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**swarm container hangs on start in 20.10.4 but not 20.10.3**<!--Briefly describe the problem you are having in a few paragraphs.-->After a recent upgrade (see below), starting a container (**swarm** in my case) hangs on `start`, and a `kill -9` is the only thing that stops it.```Feb 28 05:01:13 Updated: 1:docker-ce-cli-20.10.4-3.el7.x86_64Feb 28 05:01:17 Updated: 3:docker-ce-20.10.4-3.el7.x86_64Feb 28 05:01:18 Updated: docker-ce-rootless-extras-20.10.4-3.el7.x86_64```**Steps to reproduce the issue:**1. On a CentOS 7 system, install docker 20.10.4.  (I cleaned out data/run dirs, it makes no difference)2. Pull: `docker pull swarm`3. Create a container: `/usr/bin/docker create --net host -m 0b -l protected  --name SwarmManager swarm  manage --strategy spread -H tcp://0.0.0.0:2375 etcd://127.0.0.1:2379`4. Start Container: `docker start -a SwarmManager` (no output, hangs, does not respond to Ctrl-C)*With 20.10.3 the above produces output and responds to Ctrl-C***Describe the results you received:**`docker start` hangs, produces no output and does not respond to Ctrl-C or `kill`.  Only `kill -9` on the docker process terminates the command.**Describe the results you expected:**```[ root@host ] docker start -a SwarmManagertime=""2021-03-01T16:58:22Z"" level=info msg=""Initializing discovery without TLS"" time=""2021-03-01T16:58:22Z"" level=info msg=""Listening for HTTP"" addr=""0.0.0.0:2375"" proto=tcp time=""2021-03-01T16:58:22Z"" level=info msg=""Registered Engine xxxxxxxx at xxxxxxx:4243"" ...```*should respond to Ctrl-C***Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.4 API version:       1.41 Go version:        go1.13.15 Git commit:        d3cb89e Built:             Thu Feb 25 07:06:20 2021 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.4  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       363e9a8  Built:            Thu Feb 25 07:04:45 2021  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client:                        Context:    default Debug Mode: false                     Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)                                            Server:                   Containers: 1                            Running: 0   Paused: 0                   Stopped: 1 Images: 1 Server Version: 20.10.4 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: trueWARNING: API is accessible on http://0.0.0.0:4243 without encryption.         Access to the remote API is equivalent to root access on the host. Refer         to the 'Docker daemon attack surface' section in the documentation for         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runtime.v1.linux runc io.containerd.runc.v2 Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  seccomp   Profile: default Kernel Version: 3.10.0-1160.15.2.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 11.58GiB Name: xxxxx-swarm-01.xxxx.xxxx.xxxx ID: 7UO7:7HWW:XWIV:XJO6:NR2V:HELO:PBHW:WKJP:2YRV:INZY:EP4N:KA6Z Docker Root Dir: /data/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  xxxxxxxx03.xxxx.xxxx.xxxx:4443  dtr.xxxx.xxxx.xxxx:4443  xxxx-swarm-01.xxxx.xxxx.xxxx:5000  127.0.0.0/8 Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):*** CentOS Linux release 7.9.2009 (Core)* Using default file driver (this machine only runs the swarm manager)* Dockerd: `/usr/bin/dockerd --data-root /data/docker -H tcp://0.0.0.0:4243 -H unix:///var/run/docker.sock --ip-forward=true --iptables=true --ip-masq=true --ipv6 --fixed-cidr-v6 2001:db8:1::/64 --log-driver json-file --log-opt max-size=10m --log-opt max-file=3 -G docker  --mtu=1600`
"
42093,1,2043,288,0,0,rgl,0,"title:docker 20.10.4 on linux and windows breaks docker-compose run -T. description:**Description**Upgrading from 20.10.3 to 20.10.4 on Windows 2019 (and also in Ubuntu 20.04) breaks `docker-compose run -T`. It never returns any output nor ends.Please note that this works fine with 20.10.3.**Steps to reproduce the issue:**1. `docker-compose run -T hello`**Describe the results you received:**None.**Describe the results you expected:**```Hello World!```**Additional information you deem important (e.g. issue happens only occasionally):**I'm using the docker binaries from https://github.com/rgl/docker-ce-windows-binaries-vagrant/releasesI'm using docker-compose 1.26.2.I'm using this docker-compose file:```ymlversion: '3.8'services:  hello:    image: mcr.microsoft.com/windows:1809    command: cmd.exe /c ""echo Hello World!""```**Output of `docker version`:**```Client: Version:           20.10.4 API version:       1.41 Go version:        go1.13.15 Git commit:        d3cb89ee53 Built:             Fri Feb 26 20:00:01 2021 OS/Arch:           windows/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          20.10.4  API version:      1.41 (minimum version 1.24)  Go version:       go1.13.15  Git commit:       363e9a88a1  Built:            Fri Feb 26 19:57:55 2021  OS/Arch:          windows/amd64  Experimental:     false```**Output of `docker info`:**```Client: Context:    default Debug Mode: falseServer: Containers: 22  Running: 0  Paused: 0  Stopped: 22 Images: 100 Server Version: 20.10.4 Storage Driver: windowsfilter  Windows: Logging Driver: json-file Plugins:  Volume: local  Network: ics internal l2bridge l2tunnel nat null overlay private transparent  Log: awslogs etwlogs fluentd gcplogs gelf json-file local logentries splunk syslog Swarm: inactive Default Isolation: process Kernel Version: 10.0 17763 (17763.1.amd64fre.rs5_release.180914-1434) Operating System: Windows Server 2019 Standard Evaluation Version 1809 (OS Build 17763.1757) OSType: windows Architecture: x86_64 CPUs: 2 Total Memory: 3.999GiB Name: windows ID: JTOV:XZLF:QOVU:7I3C:PUWJ:DGCD:TRBB:QRBV:AIT3:XIJH:YB4I:HD3S Docker Root Dir: C:\ProgramData\docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels:  os=windows Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: API is accessible on http://0.0.0.0:2375 without encryption.         Access to the remote API is equivalent to root access on the host. Refer         to the 'Docker daemon attack surface' section in the documentation for         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface```**Additional environment details (AWS, VirtualBox, physical, etc.):**Docker is running in Windows 2019 in a qemu-kvm VM (as launched by https://github.com/rgl/gitlab-ci-vagrant).
"
42041,0,167,87,0,1,skaegi,0,"title:Failed to set OOM Score on shim error when running docker:dind in Kubernetes. description:**Description**We're running `docker:dind` in a Kubernetes pod for CI. With the Docker 20 version of dind (which now uses the v2 shim) this is now broken and errors with a message similar to...```docker: Error response from daemon: io.containerd.runc.v2: failed to adjust OOM score for shim: set shim OOM score: write /proc/211/oom_score_adj: invalid argument```Also see -- https://github.com/containerd/containerd/issues/4837Fixed in this PR -- https://github.com/containerd/containerd/pull/4845Current containerd version is... https://github.com/moby/moby/blob/master/vendor.conf#L133Could we bump to a more recent commit -- potentially https://github.com/containerd/containerd/releases/tag/v1.5.0-beta.1Also, could this be backported for a Docker 20 minor release as we've seen many teams encounter issues and the current workaround is to go back to using Docker 19.
"
42039,0,916,2,0,0,nathanlcarlson,0,"title:ExtraAttributes checking the wrong length for labels-regex. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->This line is checking the length of the wrong variable https://github.com/moby/moby/blob/master/daemon/logger/loginfo.go#L45 . This is likely a copy paste error, I assume `len(labels)` should be `len(labelsRegex)`. **Steps to reproduce the issue:**1. Try to specify `labelsRegex` but not `labels` for a log driver and the regex you specified will be ignored.**Describe the results you received:**My labelsRegex is being ignored.**Describe the results you expected:**I'd expect to see the matching labels.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```$ docker versionClient: Docker Engine - Community Cloud integration: 1.0.7 Version:           20.10.2 API version:       1.41 Go version:        go1.13.15 Git commit:        2291f61 Built:             Mon Dec 28 16:12:42 2020 OS/Arch:           darwin/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.2  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       8891c58  Built:            Mon Dec 28 16:15:28 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```not relevant```
"
42032,0,6376,8,0,0,nrafal,0,"title:Docker deamon get's stuck, can't serve DNS requests . description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**From some time (I believe after update from 19.03, but I'm not sure) we are experiencing strange Docker Swarm behavior. We are running a small Docker Swarm cluster, two workers, one manager. Nodes are in VMs, under Ubuntu 20.04, managed by Proxmox. We can see that sometimes (can't tell why and when exactly) Docker Daemon become unresponsive. We experience it as a problem with DNS requests. All containers on that node are working well, they just can't query Docker's internal DNS. When this happens, I can't drain that node from manager - it is marked as Drain, but containers are not stopping. I can't stop containers with `docker stop` also. The only solution is to restart `docker` with `systemctl`, after that all is well for some time.While restarting Docker I can see dump from go that's very long, but the most repeated part is:```Feb 16 11:41:06 docker-worker-2 dockerd[3187807]: goroutine 21208128 [semacquire, 7 minutes]:Feb 16 11:41:06 docker-worker-2 dockerd[3187807]: sync.runtime_SemacquireMutex(0xc000f320fc, 0xc0027b9c00, 0x1)Feb 16 11:41:06 docker-worker-2 dockerd[3187807]:         /usr/local/go/src/runtime/sema.go:71 +0x49Feb 16 11:41:06 docker-worker-2 dockerd[3187807]: sync.(*Mutex).lockSlow(0xc000f320f8)Feb 16 11:41:06 docker-worker-2 dockerd[3187807]:         /usr/local/go/src/sync/mutex.go:138 +0xfeFeb 16 11:41:06 docker-worker-2 dockerd[3187807]: sync.(*Mutex).Lock(...)Feb 16 11:41:06 docker-worker-2 dockerd[3187807]:         /usr/local/go/src/sync/mutex.go:81Feb 16 11:41:06 docker-worker-2 dockerd[3187807]: github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).isManager(0xc000f32000, 0xc0061e7b00)Feb 16 11:41:06 docker-worker-2 dockerd[3187807]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:666 +0xeaFeb 16 11:41:06 docker-worker-2 dockerd[3187807]: github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).isDistributedControl(0xc000f32000, 0xc0061e7bb0)Feb 16 11:41:06 docker-worker-2 dockerd[3187807]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:684 +0x2dFeb 16 11:41:06 docker-worker-2 dockerd[3187807]: github.com/docker/docker/vendor/github.com/docker/libnetwork.(*sandbox).ResolveName(0xc0027b9b00, 0xc0090b1740, 0x9, 0x2, 0x3330333135613134, 0x8, 0x656532633>Feb 16 11:41:06 docker-worker-2 dockerd[3187807]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/sandbox.go:557 +0x4c2Feb 16 11:41:06 docker-worker-2 dockerd[3187807]: github.com/docker/docker/vendor/github.com/docker/libnetwork.(*resolver).handleIPQuery(0xc00289b340, 0xc0090b1740, 0x9, 0xc00a4f4ea0, 0x2, 0x0, 0x0, 0x0)Feb 16 11:41:06 docker-worker-2 dockerd[3187807]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/resolver.go:246 +0x74Feb 16 11:41:06 docker-worker-2 dockerd[3187807]: github.com/docker/docker/vendor/github.com/docker/libnetwork.(*resolver).ServeDNS(0xc00289b340, 0x564bc8bf8c80, 0xc006029920, 0xc00a4f4ea0)Feb 16 11:41:06 docker-worker-2 dockerd[3187807]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/resolver.go:375 +0x2027Feb 16 11:41:06 docker-worker-2 dockerd[3187807]: github.com/docker/docker/vendor/github.com/miekg/dns.(*Server).serveDNS(0xc0061e3560, 0xc009239800, 0x1a, 0x200, 0xc006029920)Feb 16 11:41:06 docker-worker-2 dockerd[3187807]:         /go/src/github.com/docker/docker/vendor/github.com/miekg/dns/server.go:609 +0x2e2Feb 16 11:41:06 docker-worker-2 dockerd[3187807]: github.com/docker/docker/vendor/github.com/miekg/dns.(*Server).serveUDPPacket(0xc0061e3560, 0xc001e08ba0, 0xc009239800, 0x1a, 0x200, 0xc0010c2450, 0xc00a0c724>Feb 16 11:41:06 docker-worker-2 dockerd[3187807]:         /go/src/github.com/docker/docker/vendor/github.com/miekg/dns/server.go:549 +0xb4Feb 16 11:41:06 docker-worker-2 dockerd[3187807]: created by github.com/docker/docker/vendor/github.com/miekg/dns.(*Server).serveUDPFeb 16 11:41:06 docker-worker-2 dockerd[3187807]:         /go/src/github.com/docker/docker/vendor/github.com/miekg/dns/server.go:479 +0x2ae```Can't think of anything else. It seems to be related with a number of containers running. Our application is relying a lot on docker swarm internal restart policy. We have around 100 running containers per node. We use `docker-gc` to clean old containers periodically. Our containers are rather short lived - we use swarm's restart policy as an alternative for cron, so containers starts very often. We use quite a lot of NFS volumes in our services for data storage.**Steps to reproduce the issue:**1. I wish I knew - in our case we just need to wait for this error to happen, restart docker, wait again and surely within 24 hours the problem will arise again.**Describe the results you received:**Apart from already described log I can't see anything relevant in logs. One of our network have quite a lot of entries in NetworkDB stats (more than 1500), but I can't see a pattern there. We also see this logs when restarting docker:```Feb 16 11:40:50 docker-worker-2 dockerd[3187807]: time=""2021-02-16T11:40:50.294200938+01:00"" level=info msg=""Processing signal 'terminated'""Feb 16 11:41:05 docker-worker-2 dockerd[3187807]: time=""2021-02-16T11:41:05.296233481+01:00"" level=error msg=""agent failed to clean up assignments"" error=""context deadline exceeded""Feb 16 11:41:05 docker-worker-2 dockerd[3187807]: time=""2021-02-16T11:41:05.297377446+01:00"" level=error msg=""failed to shut down cluster node: context deadline exceeded""``` which seems relevant and looks like some problem with mutex and deadlock, but I don't now that much about Docker internals to pinpoint a problem.**Describe the results you expected:**The daemon is stable and DNS works as expected.**Additional information you deem important (e.g. issue happens only occasionally):**Issue happens quite regulary.**Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.3 API version:       1.41 Go version:        go1.13.15 Git commit:        48d30b5 Built:             Fri Jan 29 14:33:21 2021 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.3  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       46229ca  Built:            Fri Jan 29 14:31:32 2021  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)Server: Containers: 235  Running: 70  Paused: 0  Stopped: 165 Images: 14 Server Version: 20.10.3 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: active  NodeID: nnf06svm6en4chin0urdvo2hp  Is Manager: false  Node Address: 192.168.200.196  Manager Addresses:   192.168.200.217:2377 Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.4.0-65-generic Operating System: Ubuntu 20.04.2 LTS OSType: linux Architecture: x86_64 CPUs: 64 Total Memory: 62.8GiB Name: docker-worker-2 ID: DXBV:NFMD:BEIL:DL2N:5YFZ:4P34:CXJO:B63Y:6RFY:KBV5:ZSBS:WCPR Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  hub.dmsales.io:5000  192.168.200.217:5000  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit supportWARNING: No blkio weight supportWARNING: No blkio weight_device support```**Additional environment details (AWS, VirtualBox, physical, etc.):**VM, running Ubuntu 20.04, managed by Proxmox 6.2-12
"
41985,1,2174,58,0,0,bingbing8,0,"title:intermittent issue: ""Unsupported signal: <nil>. Discarding.."" pending to the return from ""docker run"" on latest windows docker CE master-dockerproject-2021-02-03. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**intermittent issue: ""Unsupported signal: <nil>. Discarding.."" pending to the return from ""docker run"" on latest windows docker from master.dockerproject.org<!--Briefly describe the problem you are having in a few paragraphs.-->intermittent issue: ""Unsupported signal: <nil>. Discarding.."" pending to the return from ""docker run"" on latest windows docker from master.dockerproject.org**Steps to reproduce the issue:**  1. C:\docker pull mcr.microsoft.com/windows/nanoserver:20H2-KB459824220H2-KB4598242: Pulling from windows/nanoserver2ddfbf39b1d8: Already existsDigest: sha256:b0a754e60c8fdf311b29db7d871452a431c4b86ae4730450b6fe320da533e31eStatus: Downloaded newer image for mcr.microsoft.com/windows/nanoserver:20H2-KB4598242mcr.microsoft.com/windows/nanoserver:20H2-KB4598242  2. C:\>docker run --isolation hyperv --rm mcr.microsoft.com/windows/nanoserver:20H2-KB4598242 cmd /k echo hellohelloC:\>Unsupported signal: <nil>. Discarding.C:\>docker run --rm mcr.microsoft.com/windows/nanoserver:20H2-KB4598242 cmd /k echo hellohelloC:\>Unsupported signal: <nil>. Discarding.**Describe the results you received:**""Unsupported signal: <nil>. Discarding."" is pending to the returned expected message**Describe the results you expected:**no pending error**Additional information you deem important (e.g. issue happens only occasionally):**Container host Windows Version: it repros on any version of windows host both server and client sku.  server2019, Windows Server 1909, Windows Server 1903, Windows Server 20H2, Windows Server 2004  OS Name:                   Microsoft Windows 10 EnterpriseOS Version:                10.0.19042 N/A Build 19042I can repro it inside a VM as container host, but did not repro on physical machine.**Output of `docker version`:**```docker versionClient: Docker Engine - Community Version:           master-dockerproject-2021-02-03 API version:       1.41 Go version:        go1.13.15 Git commit:        70a00157f1 Built:             Wed Feb  3 23:58:43 2021 OS/Arch:           windows/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          master-dockerproject-2021-02-03  API version:      1.41 (minimum version 1.24)  Go version:       go1.13.15  Git commit:       8d31795  Built:            Thu Feb  4 00:08:25 2021  OS/Arch:          windows/amd64  Experimental:     true```**Output of `docker info`:**```docker infoClient: Context:    default Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 5 Server Version: master-dockerproject-2021-02-03 Storage Driver: windowsfilter (windows) lcow (linux)  Windows:  LCOW: Logging Driver: json-file Plugins:  Volume: local  Network: ics internal l2bridge l2tunnel nat null overlay private transparent  Log: awslogs etwlogs fluentd gcplogs gelf json-file local logentries splunk syslog Swarm: inactive Default Isolation: hyperv Kernel Version: 10.0 19042 (19041.1.amd64fre.vb_release.191206-1406) Operating System: Windows 10 Enterprise Version 2009 (OS Build 19042.746) OSType: windows Architecture: x86_64 CPUs: 8 Total Memory: 16GiB Name: T20h22101BC ID: UC7Q:3NRT:BELW:XWDW:43UT:PIMS:JWTW:AA55:JVBY:KWCQ:OAWQ:QXUG Docker Root Dir: C:\docker Debug Mode: true  File Descriptors: -1  Goroutines: 25  System Time: 2021-02-04T18:51:25.9398485-08:00  EventsListeners: 0 Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false Product License: Community EngineWARNING: API is accessible on http://0.0.0.0:2375 without encryption.         Access to the remote API is equivalent to root access on the host. Refer         to the 'Docker daemon attack surface' section in the documentation for         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface```**Additional environment details (AWS, VirtualBox, physical, etc.):**Windows VM
"
41983,1,2486,107,0,0,exdx,0,"title:comitting an existing image locally caused docker to hang. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Running `docker commit <image-id> <name>` caused the command to hang, when the name of the image already existed locally (basically when overwriting the existing image locally and not using a tag). Need to verify if this is consistently reproducible. **Steps to reproduce the issue:**1. commit a container without a tag in the name2. make some changes inside the container filesystem to change the digest3. commit the container again **Describe the results you received:**docker hanged at the command line**Describe the results you expected:**docker would succeed or fail and return an exit code**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.2 API version:       1.41 Go version:        go1.13.15 Git commit:        2291f61 Built:             Mon Dec 28 16:12:42 2020 OS/Arch:           darwin/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.2  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       8891c58  Built:            Mon Dec 28 16:15:28 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)  scan: Docker Scan (Docker Inc., v0.5.0)Server: Containers: 8  Running: 3  Paused: 0  Stopped: 5 Images: 291 Server Version: 20.10.2 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runtime.v1.linux runc io.containerd.runc.v2 Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  seccomp   Profile: default Kernel Version: 4.19.121-linuxkit Operating System: Docker Desktop OSType: linux Architecture: x86_64 CPUs: 6 Total Memory: 1.943GiB Name: docker-desktop ID: LF7J:CXS5:2TI7:AYEV:24LW:5Q55:ICZB:JFLE:STS4:DSDV:EHTP:TBXZ Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 63  Goroutines: 69  System Time: 2021-02-04T23:03:56.429713Z  EventsListeners: 3 HTTP Proxy: gateway.docker.internal:3128 HTTPS Proxy: gateway.docker.internal:3129 Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
41978,0,318,292,0,0,rhatdan,0,"title:If I create a compressed tar ball with etc/password in it.. description:```console$ cat /tmp/DockerfileFROM scratchADD test.tar.gz /$ gtar --pax-option=globexthdr.comment=""test /etc/passwd"" -czf test.tar.gz /etc/passwdgtar: Removing leading `/' from member names```Now if I do a docker build of this, I end up with an image which has strange permissions on the directories it creates.```consolels -l /total 0drwxrwxrwx. 2 root root 20 Feb  3 12:58 etcdrwxrwxrwx. 2 root root  6 Feb  3 12:58 tmp```It creates a tmp directory, no idea why?  I would have figured that only /etc/passwd would be in the image.Secondly it creates the /etc directory as 777 permissions?In docker 19.3 version it created these directories as 755 permissions.  Was this an intentional change? 
"
41944,0,469,277,0,0,WhyNotHugo,0,"title:Docker rootless does not exit properly if containers are running. description:**Description**I'm running docker rootless (as a systemd service).When stopping the service:- ... if containers are NOT running, docker exits fine.- ... if containers are running, docker stops the containers immediately, but **does not** exit fine, but is killed by systemd after the 90s timeout (service had 90s to exit cleanly before being `SIGKILL`'d.This initial became evident since, when shutting down the system, systemd waits 90s for docker to stop, and _then_ kills it, so it's been slowing down people's shutdown.I'm the maintainer for the docker-rootless [ArchLinux AUR package](https://aur.archlinux.org/packages/docker-rootless-extras-bin/), and several other users report the same issue.**Steps to reproduce the issue:**1. Run docker rootless2. Run a container (e.g.: `docker run --rm -it node:12 bash`)3. Stop the service (e.g.: `systemctl --user stop docker.service`)**Describe the results you received:**The container is killed immediately, but the docker service does not stop until the 90s timeout (systemd sends a SIGKILL after that time). Changing the systemd's timeout makes docker take that long to exit.This _does not_ happen is no containers are running.**Describe the results you expected:**The docker service should exit immediately.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```$ docker versionClient: Version:           20.10.1 API version:       1.41 Go version:        go1.15.6 Git commit:        2291f610ae Built:             Tue Jan 19 17:19:21 2021 OS/Arch:           linux/amd64 Context:           default Experimental:      true```**Output of `docker info`:**```$ docker infoClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-tp-docker)```**Additional environment details (AWS, VirtualBox, physical, etc.):**I'm having this issue on a physical ArchLinux machine, and other Arch users report the same issue.
"
41941,0,2038,19,0,0,coderwangke,0,"title:Container in an incorrect 'UP' status. description:**Description**I observe that the Contianer is in the UP state and the task (from ctr task list) is in the STOPPED state.Container:**Describe the results you received:**the exec stdio file is still there.![image](https://user-images.githubusercontent.com/42019725/105992323-ef147180-60df-11eb-9278-8ccdeeededb9.png)the docker can not deal 'tasks/exit' event.![image](https://user-images.githubusercontent.com/42019725/105992437-1408e480-60e0-11eb-94d2-20e832b1ae19.png)and write stdout stuck in cond.Wait(), The initial reason is that the length exceeds the BlockThreshold.![image](https://user-images.githubusercontent.com/42019725/105992579-461a4680-60e0-11eb-9104-789aa655e8d0.png)**Describe the results you expected:**Delete the container correctly.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.8 API version:       1.40 Go version:        go1.12.17 Git commit:        afacb8b Built:             Wed Mar 11 01:27:04 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.8  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.17  Git commit:       afacb8b  Built:            Wed Mar 11 01:25:42 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 154  Running: 109  Paused: 0  Stopped: 45 Images: 62 Server Version: 19.03.8 Storage Driver: overlay2  Backing Filesystem: <unknown>  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 4.14.105-19-0008 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 62.41GiB Name: vm-2-42-centos ID: 7ZD5:3KAS:KRHV:JVXS:WADR:R2AZ:TQ47:BFPB:M6ZH:BWU2:MAIS:RPQY Docker Root Dir: /data/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Registry Mirrors: Live Restore Enabled: true```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
41933,0,1259,200,0,0,thaJeztah,0,"title:Jenkins: s390x agents have stale authentication info set. description:I suspect these nodes had authentication info set for some of our internal pipelines, but those credentials changed and are no longer valid; not sure which nodes have this info set (if it's just ""some"" or all nodes)```[2021-01-26T10:32:05.771Z]  Username: dockerbuildbot[2021-01-26T10:32:05.771Z]  Registry: https://index.docker.io/v1/```As a result, builds fail in CI: https://ci-next.docker.com/public/blue/rest/organizations/jenkins/pipelines/moby/branches/PR-41709/runs/3/nodes/166/log/?start=0```[2021-01-26T10:32:07.264Z] + docker build --force-rm --build-arg APT_MIRROR -t docker:14fb1650856f52928cb9f9fd3b495c3e14776069 .[2021-01-26T10:32:07.264Z] #2 [internal] load .dockerignore[2021-01-26T10:32:07.264Z] #2 transferring context: 87B 0.0s done[2021-01-26T10:32:07.264Z] #2 DONE 0.0s[2021-01-26T10:32:07.264Z][2021-01-26T10:32:07.264Z] #1 [internal] load build definition from Dockerfile[2021-01-26T10:32:07.264Z] #1 transferring dockerfile: 16.55kB done[2021-01-26T10:32:07.264Z] #1 DONE 0.0s[2021-01-26T10:32:07.264Z][2021-01-26T10:32:07.264Z] #3 resolve image config for docker.io/docker/dockerfile:1.1.7-experimental[2021-01-26T10:32:07.554Z] #3 ERROR: failed to fetch oauth token: unexpected status: 401 Unauthorized[2021-01-26T10:32:07.554Z] ------[2021-01-26T10:32:07.554Z]  > resolve image config for docker.io/docker/dockerfile:1.1.7-experimental:[2021-01-26T10:32:07.554Z] ------[2021-01-26T10:32:07.555Z] failed to solve with frontend dockerfile.v0: failed to solve with frontend gateway.v0: failed to fetch oauth token: unexpected status: 401 Unauthorizedscript returned exit code 1```@StefanScherer 婵犵妲呴崑鎾跺緤娴犲绐楁慨姗嗗劦?
"
41930,0,3863,247,0,0,AkihiroSuda,0,"title:Flaky test: TestHealthKillContainer fails intermittently. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->As of f266f13965d5bfb1825afa181fe6c32f3a597fa3, `TestHealthKillContainer`  fails intermittently  ~~on cgroup v2 hosts~~ (**EDIT**: irrelevant to cgroup version)https://github.com/moby/moby/blob/f266f13965d5bfb1825afa181fe6c32f3a597fa3/integration/container/health_test.go#L36-L78**Steps to reproduce the issue:**```console$ make TEST_SKIP_INTEGRATION_CLI=1 TESTFLAGS=""-test.run TestHealthKillContainer  -test.count 10"" test-integration ```**Describe the results you received:**4 PASS, 6 FAIL```=== RUN   TestHealthKillContainer--- FAIL: TestHealthKillContainer (13.03s)    health_test.go:62: timeout hit after 10s: waiting for container to become healthy=== RUN   TestHealthKillContainer--- PASS: TestHealthKillContainer (2.56s)=== RUN   TestHealthKillContainer--- PASS: TestHealthKillContainer (2.49s)=== RUN   TestHealthKillContainer--- FAIL: TestHealthKillContainer (12.42s)    health_test.go:62: timeout hit after 10s: waiting for container to become healthy=== RUN   TestHealthKillContainer--- PASS: TestHealthKillContainer (2.50s)=== RUN   TestHealthKillContainer--- FAIL: TestHealthKillContainer (12.42s)    health_test.go:62: timeout hit after 10s: waiting for container to become healthy=== RUN   TestHealthKillContainer--- FAIL: TestHealthKillContainer (12.46s)    health_test.go:62: timeout hit after 10s: waiting for container to become healthy=== RUN   TestHealthKillContainer--- FAIL: TestHealthKillContainer (12.39s)    health_test.go:62: timeout hit after 10s: waiting for container to become healthy=== RUN   TestHealthKillContainer--- PASS: TestHealthKillContainer (2.48s)=== RUN   TestHealthKillContainer--- FAIL: TestHealthKillContainer (12.43s)    health_test.go:62: timeout hit after 10s: waiting for container to become healthyFAIL```**Describe the results you expected:**10 PASS**Additional information you deem important (e.g. issue happens only occasionally):**- kernel cmdline: `systemd.unified_cgroup_hierarchy=1 cgroup_enable=memory swapaccount=1`**Output of `docker version`:**```Client: Version:           20.10.0-dev API version:       1.41 Go version:        go1.13.15 Git commit:        c6bb56136 Built:             Tue Jan 26 08:46:11 2021 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          dev  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       f266f13965  Built:            Tue Jan 26 08:45:56 2021  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          v1.4.0-2523-g1230bd630  GitCommit:        1230bd63031ba4b65709103b5cb8f5be78a43b75 runc:  Version:          1.0.0-rc92+dev  GitCommit:        c69ae759fbf5acf6e8ef805471b99feee8246c3c docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  buildx: Build with BuildKit (Docker Inc., v0.5.1-3-g8b8725d)Server: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 3 Server Version: dev Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runtime.v1.linux kata runsc-kvm sysbox-runc crun io.containerd.runc.v2 runsc runc runc-rc92 Default Runtime: runc Init Binary: docker-init containerd version: 1230bd63031ba4b65709103b5cb8f5be78a43b75 runc version: c69ae759fbf5acf6e8ef805471b99feee8246c3c init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default  cgroupns Kernel Version: 5.8.0-40-generic Operating System: Ubuntu 20.10 OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 15.61GiB Name: suda-ws01 ID: E2YB:EGZO:6BNW:EPHS:4WFQ:EIDV:ZZ6D:QBZK:6673:CIOR:DLZ6:SI3D Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 22  Goroutines: 34  System Time: 2021-01-26T17:58:54.968084742+09:00  EventsListeners: 0 Username: akihirosuda Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: trueWARNING: Support for cgroup v2 is experimental```**Additional environment details (AWS, VirtualBox, physical, etc.):**VMware Fusion
"
41926,0,0,247,0,0,AkihiroSuda,0,"title:[cgroup2] docker info: `SwapLimit = true` is set without checking. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**https://github.com/moby/moby/blob/v20.10.2/pkg/sysinfo/cgroup2_linux.go#L69-L84`info.SwapLimit = true` should be set only if `memory.swap.max` exists.When the swap support is present (with `swapaccount=1` in kernel cmdline), `memory.swap.max` appears in a non-top cgroup.i.e., `/sys/fs/cgroup/${dockerd_cgroup}/memory.swap.max` appears, but `/sys/fs/cgroup/memory.swap.max` does not appear (unless we are in dind)Related: https://github.com/containers/podman/pull/8197/files** `docker version` **20.10.2
"
41915,1,222,10,0,0,ridv,0,"title:Overflow in unix collector. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->While looking through the unix collector code to understand how the CPU percentage is calculated, I noticed that the total number of clock ticks is multiplied by a pretty big number before being divided by 100.The relevant line is here https://github.com/moby/moby/blob/master/daemon/stats/collector_unix.go#L61The information on the ticks is pulled from `/proc/stat`. Trying to better understand the code I went on a local system and got the output from that pseudofile. The numbers it spit out were particularly large which made me wonder if this was resulting in an overflow (even with uint64 which, just for quick reference, has a max of `18446744073709551615`).These were the numbers pulled from that particular VM running on GCP:```~$ cat /proc/statcpu  391560803 250677279 651257224 21492460706 617141613 0 40558038 0 0 0```These numbers add up to: `23443655663`This is then multiplied by 1e9 which (on a calculator) results in:  `2.3443655663e19`This leads to an overflow in the program which returns: `49969115892904483`https://play.golang.org/p/Dt7K2fRGg88The result should actually be: `2.3443655663e17`https://play.golang.org/p/1ZG7iUtyEwr**Steps to reproduce the issue:**1. Find a node with a large number of cpu clock ticks in /proc/stat2. Calculate the numbers by hand**Describe the results you received:**SystemCPUUsage: `49969115892904483`**Describe the results you expected:**SystemCPUUsage: `234436556630000000`**Additional information you deem important (e.g. issue happens only occasionally):**Only happens on Nodes which contain a high number of CPU clock ticks on /proc/stat**Output of `docker version`:**```Can be provided but isn't particularly useful for this bug.```**Output of `docker info`:**```Can be provided but isn't particularly useful for this bug.```**Additional environment details (AWS, VirtualBox, physical, etc.):** VM running GCP
"
41911,0,1040,200,0,0,thaJeztah,0,"title:[20.10] Classic builder silently ignores unsupported Dockerfile command flags. description:- related: https://github.com/moby/buildkit/issues/1945 `docker-compose up --build` does not use `--mount=type=cache`, only `docker build .`- related: https://github.com/moby/buildkit/issues/799 [RFC] Warn on unknown flags instead of failingWith the promotion of the experimental Dockerfile syntax to ""stable"", the Dockerfile syntax now includes some options that are supported by BuildKit, but not (yet) supported in the classic builder.As a result, parsing a Dockerfile may succeed, but any flag that's known to BuildKit, but not supported by the classic builder is silently ignored;```console$ mkdir buildkit_flags && cd buildkit_flags$ touch foo.txt```For example, `RUN --mount`:```console$ DOCKER_BUILDKIT=0 docker build --no-cache -f- . <<EOFFROM busyboxRUN --mount=type=cache,target=/foo echo helloEOF``````consoleSending build context to Docker daemon  2.095kBStep 1/2 : FROM busybox ---> 219ee5171f80Step 2/2 : RUN --mount=type=cache,target=/foo echo hello ---> Running in 022fdb856bc8helloRemoving intermediate container 022fdb856bc8 ---> e9f0988844d1Successfully built e9f0988844d1```Or `COPY --chmod` (same for `ADD --chmod`):```consoleDOCKER_BUILDKIT=0 docker build --no-cache -f- . <<EOFFROM busyboxCOPY --chmod=0777 /foo.txt /foo.txtEOF``````Sending build context to Docker daemon  2.095kBStep 1/2 : FROM busybox ---> 219ee5171f80Step 2/2 : COPY --chmod=0777 /foo.txt /foo.txt ---> 8b7117932a2aSuccessfully built 8b7117932a2a```Note that unknown flags still produce and error, for example, the below fails because `--hello` is an unknown flag;```consoleDOCKER_BUILDKIT=0 docker build -<<EOFFROM busyboxRUN --hello echo helloEOF``````Sending build context to Docker daemon  2.048kBError response from daemon: dockerfile parse error line 2: Unknown flag: hello```
"
41891,1,2572,0,0,0,DaveDunne,0,"title:Docker pull fails consistently in rootless mode. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->Ubuntu 20.04.1 LTS - 64 Bit <!--Briefly describe the problem you are having in a few paragraphs.-->Simply docker pull fails all the time91b65e469d9a: Extracting [==================================================>]  37.54MB/37.54MBebca2667abd2: Download complete 7dcbb0d6b4db: Download complete 2aa779b8c40d: Download complete d9523f88ad67: Download complete failed to register layer: Error processing tar file(exit status 1): lchown /dev/initctl: no such file or directory**Steps to reproduce the issue:****Describe the results you received:**91b65e469d9a: Extracting [==================================================>]  37.54MB/37.54MBebca2667abd2: Download complete 7dcbb0d6b4db: Download complete 2aa779b8c40d: Download complete d9523f88ad67: Download complete failed to register layer: Error processing tar file(exit status 1): lchown /dev/initctl: no such file or directorytried everything under the sun to make it work. Changed to overlay from overlay2 ... played with many configurations of /etc/subuid and etc/subgid**Describe the results you expected:**expect docker pull to work **Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:** ```docker versionClient: Docker Engine - Community Version:           20.10.2 API version:       1.41 Go version:        go1.13.15 Git commit:        2291f61 Built:             Mon Dec 28 16:11:26 2020 OS/Arch:           linux/amd64 Context:           rootless Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.2  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       8891c58  Built:            Mon Dec 28 16:15:23 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```docker infoClient: Context:    rootless Debug Mode: falseServer: Containers: 1  Running: 0  Paused: 0  Stopped: 1 Images: 2 Server Version: 20.10.2 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: none Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runtime.v1.linux runc io.containerd.runc.v2 Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  seccomp   Profile: default  rootless Kernel Version: 5.4.0-62-generic Operating System: Ubuntu 20.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.52GiB Name: IEDUB-3WT9SQ2-LNX ID: S6QM:QDPQ:4QC2:HLUM:NJJE:GCO3:YUPT:65DM:BENU:HLQY:EDZ4:BZGL Docker Root Dir: /home/dave.dunne/.local/share/docker Debug Mode: true  File Descriptors: 23  Goroutines: 39  System Time: 2021-01-18T20:49:37.979712108Z  EventsListeners: 0 Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false Product License: Community EngineWARNING: Running in rootless-mode without cgroups. To enable cgroups in rootless-mode, you need to boot the system in cgroup v2 mode.WARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
41890,1,2453,41,0,1,atline,0,"title:WARNING: Error loading config file: .dockercfg: $HOME is not defined. description:**Description**We have a software which will call `docker xxx` in its code.a) It's ok in the pastb) After upgrade docker to `20.10.1`, it reports next:> WARNING: Error loading config file: .dockercfg: $HOME is not defined**NOTE: we don't have HOME set in our env. I wonder if it's a bug? What's the root cause?****Should I add `export HOME=/root` in our software to act as a workaround, or you will fix it in future release?****Steps to reproduce the issue:**1. Install 20.10.12. unset HOME3. `docker ps` or any other docker command will show warning.**Describe the results you received:**```# docker psWARNING: Error loading config file: .dockercfg: $HOME is not definedCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES```**Describe the results you expected:**No warning.**Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.1 API version:       1.41 Go version:        go1.13.15 Git commit:        831ebea Built:             Tue Dec 15 04:34:48 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.1  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       f001486  Built:            Tue Dec 15 04:32:45 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.0-docker)Server: Containers: 1  Running: 0  Paused: 0  Stopped: 1 Images: 3 Server Version: 20.10.1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.19.0-13-amd64 Operating System: Debian GNU/Linux 10 (buster) OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.593GiB Name: shlava ID: TULV:U34A:NIJQ:Y3SP:FKLM:UX64:YXUE:KMOU:LND5:HBBN:F5YV:F3D4 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```
"
41876,0,3235,0,1,0,Rao-CZ,0,"title:rootless: `docker run -v docker.sock:docker.sock:ro` fails with `mounting ""docker.sock"" to rootfs at ""docker.sock"" caused: operation not permitted`. description:**Description**Similarly as in https://github.com/moby/moby/issues/41457, process fails to start with `docker: Error response from daemon: OCI runtime create failed: container_linux.go:370: starting container process caused: process_linux.go:459: container init caused: rootfs_linux.go:59: mounting ""/run/user/1002/docker.sock"" to rootfs at ""/home/app_docker/.local/share/docker/fuse-overlayfs/24a81be0bbbae07387f84498c51623a2faf39c5b5b1b5c4222c478fb9899337e/merged/var/run/docker.sock"" caused: operation not permitted: unknown.` on rootless docker. **Steps to reproduce the issue:**1. rootless docker2. `docker run --rm -v /run/user/1002/docker.sock:/var/run/docker.sock:ro hello-world`**Describe the results you received:**`docker: Error response from daemon: OCI runtime create failed: container_linux.go:370: starting container process caused: process_linux.go:459: container init caused: rootfs_linux.go:59: mounting ""/run/user/1002/docker.sock"" to rootfs at ""/home/app_docker/.local/share/docker/fuse-overlayfs/24a81be0bbbae07387f84498c51623a2faf39c5b5b1b5c4222c478fb9899337e/merged/var/run/docker.sock"" caused: operation not permitted: unknown.`**Describe the results you expected:**Should not fail**Additional information you deem important (e.g. issue happens only occasionally):**I found this issue when trying to run [Docker Bench for Security](https://github.com/docker/docker-bench-security) as```docker run \--rm \--net host \--pid host \--userns host \--cap-add audit_control \-e DOCKER_CONTENT_TRUST=$DOCKER_CONTENT_TRUST \-v /home/lowly_user/bin/containerd:/usr/bin/containerd:ro \-v /home/lowly_user/bin/runc:/usr/bin/runc:ro \-v /usr/lib/systemd:/usr/lib/systemd:ro \-v /var/lib:/var/lib:ro \-v /run/user/1002/docker.sock:/var/run/docker.sock:ro \--label docker_bench_security \docker/docker-bench-security```and after triming down some pieces I found this (new?) error. Maybe it is duplicate of linked https://github.com/moby/moby/issues/41457, but I cannot tell.**Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.1 API version:       1.41 Go version:        go1.13.15 Git commit:        831ebea Built:             Tue Dec 15 04:28:35 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.1  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       f001486  Built:            Tue Dec 15 04:32:28 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: falseServer: Containers: 1  Running: 0  Paused: 0  Stopped: 1 Images: 4 Server Version: 20.10.1 Storage Driver: fuse-overlayfs Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  seccomp   Profile: default  rootless  cgroupns Kernel Version: 4.18.0-193.19.1.el8_2.x86_64 Operating System: CentOS Linux 8 (Core) OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.626GiB Name: <redacted> ID: ZBAT:LVV3:5XV7:RRP3:B2EW:X2BN:BLJE:5AZL:LECA:WBZJ:GALX:B6CH Docker Root Dir: /home/lowly_user/.local/share/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false Product License: Community EngineWARNING: No kernel memory TCP limit supportWARNING: No oom kill disable supportWARNING: No cpu cfs quota supportWARNING: No cpu cfs period supportWARNING: No cpu shares supportWARNING: No cpuset supportWARNING: Support for cgroup v2 is experimentalWARNING: No blkio weight supportWARNING: No blkio weight_device supportWARNING: No blkio throttle.read_bps_device supportWARNING: No blkio throttle.write_bps_device supportWARNING: No blkio throttle.read_iops_device supportWARNING: No blkio throttle.write_iops_device supportWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**None I am aware of and of importance.
"
41871,0,5120,0,0,0,ealessandria-orange,0,"title:dockerd (in live-restore mode) stops containers' healthcheck execution when restarted. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. having this Dockerfile:```bashFROM httpd:2.4COPY hc /RUN apt-get update && apt-get install curlHEALTHCHECK --interval=10s --timeout=5s --start-period=10s CMD /hc || exit 1```2. build & run it```bashdocker build . -t bug_hcdocker run --name bug_hc_cont -dti bug_hc:latest```3. wait a bit for the container to be healthy (~1 min), then look at dockerd logs, you see healthcheck execution:```bashsudo journalctl -u docker -f | grep ""Health check for container""Jan 12 17:37:01 ealessandria.vm.vdi.s1.p.fti.net dockerd[14821]: time=""2021-01-12T17:37:01.671192623+01:00"" level=debug msg=""Health check for container 69b507e6c1eb7f7ff1b352915c623dca69b50d11f6b744a554831d64875198b2 done (exitCode=0)""Jan 12 17:37:12 ealessandria.vm.vdi.s1.p.fti.net dockerd[14821]: time=""2021-01-12T17:37:12.288922075+01:00"" level=debug msg=""Health check for container 69b507e6c1eb7f7ff1b352915c623dca69b50d11f6b744a554831d64875198b2 done (exitCode=0)""...```4. restart dockerd, you won't see anymore healthcheck executions in daemon logs```bashsudo systemctl restart docker```5. container healthcheck execution becomes again effective if:* you restart the container ( `docker restart bug_hc_cont` )or* you `docker pause bug_hc_cont && docker unpause bug_hc_cont`**Describe the results you received:**After dockerd restart, container healthcheck is no more executed by dockerd**Describe the results you expected:**After dockerd restart, container healthcheck is still executed by dockerd**Additional information you deem important (e.g. issue happens only occasionally):**It happens systematically**Dockerd configuration :**```:[ ealessandria@ealessandria /home/ealessandria : sudo cat /etc/systemd/system/docker.service[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target firewalld.service containerd.serviceWants=network-online.targetRequires=docker.socket containerd.service[Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --live-restore --debugExecReload=/bin/kill -s HUP $MAINPIDTimeoutSec=0RestartSec=2Restart=always# Note that StartLimit* options were moved from ""Service"" to ""Unit"" in systemd 229.# Both the old, and new location are accepted by systemd 229 and up, so using the old location# to make them work for either version of systemd.StartLimitBurst=3# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make# this option work for either version of systemd.StartLimitInterval=60s# Having non-zero Limit*s causes performance problems due to accounting overhead# in the kernel. We recommend using cgroups to do container-local accounting.LimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinity# Comment TasksMax if your systemd version does not support it.# Only systemd 226 and above support this option.TasksMax=infinity# set delegate yes so that systemd does not reset the cgroups of docker containersDelegate=yes# kill only the docker process, not all processes in the cgroupKillMode=processOOMScoreAdjust=-500[Install]WantedBy=multi-user.target```**Output of `docker version`:**```Client: Docker Engine - Community闂傚倷娴囨竟鍫熺椤掑倻鐭堢紒澶夋嫹sion: 闂?闂?闂?闂?闂?20.10.2闂傚倷娴囨竟鍫熺椤掑嫭鐓ユい銉ь渹 version: 闂?闂?闂?1.41闂傚倷娴囨竟鍫熺椤掆偓鑿愮痪?version: 闂?闂?闂?闂傚倷娴囨竟鍫熺椤掑倻鐭夐柟?.13.15闂傚倷娴囨竟鍫熺椤掆偓鑿愰柣顔绢攷 commit: 闂?闂?闂?闂?291f61闂傚倷娴囨竟鍫熺椤掑嫬鍨傞柛濠佸珐lt: 闂?闂?闂?闂?闂?闂?Mon Dec 28 16:17:32 2020闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣?Arch: 闂?闂?闂?闂?闂?linux/amd64闂傚倷娴囨竟鍫熺椤掑嫬鍙婃い褏顨妕ext: 闂?闂?闂?闂?闂?default闂傚倷娴囨竟鍫熺椤掑嫭鐓侀柛锝嗩劒erimental: 闂?闂?闂傚倷娴囨竟鍫熺椤掍焦濯撮柛鐐存eServer: Docker Engine - Community闂傚倷娴囨竟鍫熺椤掑嫭鐓侀柛锝呪€檌ne:闂?Version: 闂?闂?闂?闂?闂?0.10.2闂?API version: 闂?闂?闂?.41 (minimum version 1.12)闂?Go version: 闂?闂?闂?go1.13.15闂?Git commit: 闂?闂?闂?8891c58闂?Built: 闂?闂?闂?闂?闂?闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣婊呮箯 Dec 28 16:15:09 2020闂?OS/Arch: 闂?闂?闂?闂?闂傚倷娴囨竟鍫熺椤掑嫬绠柛妤佹崟ux/amd64闂?Experimental: 闂?闂?false闂傚倷娴囨竟鍫熺椤掑倻鐭夊┑顖涚瑴tainerd:闂?Version: 闂?闂?闂?闂?闂?.4.3闂?GitCommit: 闂?闂?闂?闂?69548fa27e0089a8b8278fc4fc781d7f65a939b闂傚倷娴囨竟鍫熺椤掑嫬绫嶆い鈺傛崟c:闂?Version: 闂?闂?闂?闂?闂?.0.0-rc92闂?GitCommit: 闂?闂?闂?闂傚倷娴囨竟鍫熺椤掑倻鐭夌€?19c7e9184c13b7c2607fe6c30ae19403a7aff闂傚倷娴囨竟鍫熺椤掑倻鐭夐悗鍦腹ker-init:闂?Version: 闂?闂?闂?闂?闂?.19.0闂?GitCommit: 闂?闂?闂?闂傚倷娴囨竟鍫熺椤掑倻鐭夐悗?0ad0```**Output of `docker info`:**```Client:闂傚倷娴囨竟鍫熺椤掑嫬鍙婃い褏顨妕ext: 闂?闂傚倷娴囨竟鍫熺椤掑倻鐭夐悗瑙勬敥ault闂傚倷娴囨竟鍫熺椤掆偓椤啰缂撻悤绲琯 Mode: false闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣褏纾玤ins:闂?app: Docker App (Docker Inc., v0.9.1-beta3)闂?buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)Server:闂傚倷娴囨竟鍫熺椤掑嫬鍙婃い褏顨妕ainers: 21闂?Running: 1闂?Paused: 0闂?Stopped: 20闂傚倷娴囨竟鍫熺椤掑倻鐭堟い锔藉礁ges: 149闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣顔炬櫌ver Version: 20.10.2闂傚倷娴囨竟鍫熺椤掑倻鐭堢痪顓炪€媟age Driver: overlay2闂?Backing Filesystem: extfs闂?Supports d_type: true闂?Native Overlay Diff: true闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣姘辩墾ging Driver: json-file闂傚倷娴囨竟鍫熺椤掑嫬鍙婃い褏鎹噊up Driver: cgroupfs闂傚倷娴囨竟鍫熺椤掑嫬鍙婃い褏鎹噊up Version: 1闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣褏纾玤ins:闂?Volume: local闂?Network: bridge host ipvlan macvlan null overlay闂?Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog闂傚倷娴囨竟鍫熺椤掑倻鐭堢痪顓炵〗rm: inactive闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣顒傛櫅times: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc闂傚倷娴囨竟鍫熺椤掆偓椤啰缂撻悥涔lt Runtime: runc闂傚倷娴囨竟鍫熺椤掑倻鐭堟い锔芥敯t Binary: docker-init闂傚倷娴囨竟鍫熺椤掑倻鐭夊┑顖涚瑴tainerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b闂傚倷娴囨竟鍫熺椤掑嫬绫嶆い鈺傛崟c version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff闂傚倷娴囨竟鍫熺椤掑倻鐭夐柟棰濇钩t version: de40ad0闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣顔炬暅urity Options:闂?apparmor闂?seccomp闂?闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣銊ャ€媐ile: default闂傚倷娴囨竟鍫熺椤掑倻鐭堥柕鍡楁晝nel Version: 4.15.0-88-generic闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣锝呭劚rating System: Ubuntu 18.04.4 LTS闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣銏犫敊ype: linux闂傚倷娴囨竟鍫熺椤掑嫭鐓ユい锔筋浖hitecture: x86_64闂傚倷娴囨竟鍫熺椤掑嫬鍙婃い褎婀: 4闂傚倷娴囨竟鍫熺椤掑倻鐭堢痪鐐敻al Memory: 5.82GiB闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣鐑嗘煃e: ealessandria.vm.vdi.s1.p.fti.net闂傚倷娴囨竟鍫熺椤掑倻鐭堟い? VOGF:5VLL:DTKI:7RZL:WVVU:QBQC:K3TM:VG7S:AEE4:FBQW:IGGF:56KP闂傚倷娴囨竟鍫熺椤掆偓椤啰缂撻悮姝琫r Root Dir: /var/lib/docker闂傚倷娴囨竟鍫熺椤掆偓椤啰缂撻悤绲琯 Mode: true闂?File Descriptors: 30闂?Goroutines: 39闂?System Time: 2021-01-12T17:41:20.706127024+01:00闂?EventsListeners: 0闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣顒佹綆istry: https://index.docker.io/v1/闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣姘浕els:闂傚倷娴囨竟鍫熺椤掑嫭鐓侀柛锝嗩劒erimental: false闂傚倷娴囨竟鍫熺椤掑倻鐭堟い锔芥晝ecure Registries:闂?127.0.0.0/8闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣姘兼簜e Restore Enabled: trueWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**: VM ubuntu 18.04, problem also detected on bare metal ubuntu 18.04 servers
"
41861,0,3674,13,0,1,fnkr,0,"title:Docker uses 'iptables' instead of 'ip6tables' for IPv6 NAT rule, crashes. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**I'm trying to enable IPv6 NAT for the default bridge network. If the `ip6tables` daemon option is enabled, Docker tries to add an IPv6 NAT rule using `iptables`, which fails because `ip6tables` should be used instead.Related to https://github.com/moby/moby/pull/41622.**Steps to reproduce the issue:**1. Update `/etc/docker/daemon.json`:```json{    ""experimental"": true,    ""ipv6"": true,    ""ip6tables"": true,    ""fixed-cidr-v6"": ""fd9e:63ac:6dcd::/48""}```2. Restart Docker: `sudo systemctl stop docker; sudo ip link del docker0; sudo systemctl start docker`3. Docker daemon crashed during start.```# sudo journalctl -u dockerdockerd[11587]: failed to start daemon: Error initializing network controller: Error creating default ""bridge"" network: Failed to Setup IP tables: Unable to enable NAT rule:  (COMMAND_FAILED: '/usr/sbin/iptables -w10 -t nat -I POSTROUTING -s fd9e:63ac:6dcd::/48 ! -o docker0 -j MASQUERADE' failed: iptables v1.8.5 (legacy): invalid mask `48' specified```**Describe the results you received:**Docker tries to run the following command, which fails and Docker crashes:```/usr/sbin/iptables -w10 -t nat -I POSTROUTING -s fd9e:63ac:6dcd::/48 ! -o docker0 -j MASQUERADE```**Describe the results you expected:**Docker should run the command using `ip6tables` instead:```/usr/sbin/ip6tables -w10 -t nat -I POSTROUTING -s fd9e:63ac:6dcd::/48 ! -o docker0 -j MASQUERADE```**Additional information you deem important (e.g. issue happens only occasionally):**If I remove the `ip6tables` option from `daemon.json`, restart Docker and run the fixed command from above (using `ip6tables`), IPv6 NAT works:```闂?docker run --rm -it alpine ping -c 4 2606:4700:4700::1111PING 2606:4700:4700::1111 (2606:4700:4700::1111): 56 data bytes64 bytes from 2606:4700:4700::1111: seq=0 ttl=63 time=5.24 ms64 bytes from 2606:4700:4700::1111: seq=1 ttl=63 time=5.40 ms64 bytes from 2606:4700:4700::1111: seq=2 ttl=63 time=5.44 ms64 bytes from 2606:4700:4700::1111: seq=3 ttl=63 time=5.46 ms--- fde0:8899:8672:1::1 ping statistics ---4 packets transmitted, 4 packets received, 0% packet lossround-trip min/avg/max = 5.236/5.381/5.456 ms```**Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.2 API version:       1.41 Go version:        go1.13.15 Git commit:        2291f61 Built:             Mon Dec 28 16:18:35 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.2  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       8891c58  Built:            Mon Dec 28 16:15:44 2020  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)Server: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 13 Server Version: 20.10.2 Storage Driver: btrfs  Build Version: Btrfs v5.9   Library Version: 102 Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  seccomp   Profile: default  cgroupns Kernel Version: 5.9.16-200.fc33.x86_64 Operating System: Fedora 33 (Workstation Edition) OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 39.07GiB Name: redacted ID: S5VU:MHDD:7D2V:YPGW:IOU2:AUQG:DMYS:IJ3Y:IRZD:5MWB:DBV4:PRR2 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false Default Address Pools:   Base: 100.96.0.0/16, Size: 24WARNING: No kernel memory TCP limit supportWARNING: No oom kill disable supportWARNING: Support for cgroup v2 is experimental```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical (Notebook)
"
41852,0,2053,9,0,0,Wonskcalb,0,"title:Invalid error message when providing 4MB memory reservations through docker-compose. description:<!--For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->Providing 4MB memory reservations in a docker-compose yaml file shows an invalid error message stating the minimal value should be 4MB, which should be 6MB following [this PR](https://github.com/moby/moby/pull/41168)**Steps to reproduce the issue:**1. Create the following docker-compose.yaml file```yaml version: ""3.7""services:  hello-world:    image: hello-world    deploy:      resources:        reservations:          memory: 4M```2. Run `docker-compose up`**Describe the results you received:**An error message stating the minimum memory reservation allowed is 4MB```ERROR: for tmp_hello-world_1  Cannot create container for service hello-world: Minimum memory reservation allowed is 4MB```**Describe the results you expected:**An error message stating the minimum memory reservation allowed is 6MB```ERROR: for tmp_hello-world_1  Cannot create container for service hello-world: Minimum memory reservation allowed is 6MB```**Additional information you deem important (e.g. issue happens only occasionally):**After checking around the exact line (and since docker-compose is mostly a wrapper around docker), I believe the issue is coming from [this line](https://github.com/moby/moby/blob/8891c58a433a823ce0a65b57efff45f32ee9cb45/daemon/daemon_unix.go#L464) in the daemon code.**Output of `docker version`:**```/tmp闂?docker --version Docker version 20.10.1, build 831ebeae96/tmp闂?docker-compose --versiondocker-compose version 1.27.4, build unknown```**Output of `docker info`:**```/tmp闂?docker infoClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-tp-docker)Server: Containers: 12  Running: 11  Paused: 0  Stopped: 1 Images: 22 Server Version: 20.10.1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b.m runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.10.2-2-MANJARO Operating System: Manjaro Linux OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.12GiB Name: Oghma ID: 6O5U:ZSYA:P64B:RZEZ:JAP3:JUUP:T5PT:QIMC:Q62A:3J7A:KRUT:IU4N Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No blkio weight supportWARNING: No blkio weight_device support```
"
41831,1,2741,194,0,0,zhangyoufu,0,"title:containerd-shim hangs on reboot/shutdown (live restore + runc v2 runtime). description:**Description**After upgrading docker-ce to 20.10.x, reboot/shutdown the machine hangs 90s due to containerd-shim.```[  OK  ] Reached target Shutdown.[  OK  ] Reached target Final Step.[  OK  ] Finished Reboot.[  OK  ] Reached target Reboot.[  214.337805] systemd-shutdown[1]: Waiting for process: containerd-shim```**Steps to reproduce the issue:**1. fresh install docker-ce from download.docker.com on Ubuntu 20.04 LTS2. enable live-restore3. `docker run -d k8s.gcr.io/pause`4. `sudo reboot`**Describe the results you received:**The shutdown/reboot process stuck for 90s, due to containerd-shim.**Describe the results you expected:**containerd-shim should not interfere with shutdown/reboot process.**Additional information you deem important (e.g. issue happens only occasionally):**Since #41210, the default runtime is runc v2. The old runc v1 runtime does not have this issue. Tested with the following commands.```docker run -d --name runc-v1 --runtime=io.containerd.runtime.v1.linux k8s.gcr.io/pausedocker run -d --name runc-v2 --runtime=io.containerd.runc.v2 k8s.gcr.io/pause```**Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.1 API version:       1.41 Go version:        go1.13.15 Git commit:        831ebea Built:             Tue Dec 15 04:34:58 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.1  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       f001486  Built:            Tue Dec 15 04:32:52 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.0-docker)Server: Containers: 2  Running: 1  Paused: 0  Stopped: 1 Images: 5 Server Version: 20.10.1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.4.0-58-generic Operating System: Ubuntu 20.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 1 Total Memory: 981.2MiB Name: hk.zju.co ID: EZ3R:GFZG:PCIO:CEYW:Z3P5:MIND:EDKS:2VDJ:HVPF:SAWD:BKQY:OP2H Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: trueWARNING: No swap limit supportWARNING: No blkio weight supportWARNING: No blkio weight_device support```**Additional environment details (AWS, VirtualBox, physical, etc.):**N/A
"
41822,0,4648,239,0,0,nightah,0,"title:Upgrade to 20.10 fails to release ports published to IPv6 literal addresses. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Upon upgrading to Docker `20.10.1` any container which has a port published to a hosts IPv6 literal address cannot clean up after itself. Initial launch of the container is successful but any subsequent restarts will result in an error.Restarting the Docker daemon will cause the `docker-proxy` instance holding the port open to be released however the issue will reoccur upon attempts to restart the container again. **Steps to reproduce the issue:**1. `docker run -d --name nginx-test -p [fc00:1337:1337:1337:1337:1337:1337:1337]:80:80 nginx`2. `docker restart nginx-test`**Describe the results you received:**Once issuing the restart the following error is received:`Error response from daemon: Cannot restart container nginx-test: driver failed programming external connectivity on endpoint nginx-test (9a6f7a503369a88aa1d200050e4a82ba09e755e48588f4000086c5abae6c3710): Bind for fc00:1337:1337:1337:1337:1337:1337:1337:80 failed: port is already allocated`Upon checking the status of the docker daemon via systemctl I can see there's an instance of `docker-proxy` holding on to the port:```systemctl status docker闂?docker.service - Docker Application Container Engine     Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)     Active: active (running) since Thu 2020-12-17 13:04:12 AEDT; 1 day 23h agoTriggeredBy: 闂?docker.socket       Docs: https://docs.docker.com   Main PID: 384483 (dockerd)      Tasks: 41 (limit: 38458)     Memory: 265.4M     CGroup: /system.slice/docker.service             闂傚倸鍊风粈渚€鎮块崶顒婄稏濠㈣泛顑囬悵鍫曟煛閸ャ儱鐏╃紓?84483 /usr/bin/dockerd -H fd://             闂傚倸鍊风粈渚€鎮块崶顒婄稏濠㈣泛顑囬悵鍫曟煛閸ャ儱鐏╃紓?84495 containerd --config /var/run/docker/containerd/containerd.toml --log-level info             闂傚倸鍊风粈渚€鎮块崶顒婄稏濠㈣埖鍔曢拑鐔兼煥閻斿搫孝缂?34622 /usr/bin/docker-proxy -proto tcp -host-ip fc00:1337:1337:1337:1337:1337:1337:1337 -host-port 80 -container-ip 172.17.0.2 -container-port 80```The logs for the Docker daemon also provide the following output:```Dec 19 12:04:11 mana dockerd[384483]: time=""2020-12-19T12:04:11.366530647+11:00"" level=info msg=""ignoring event"" container=ed24834d6f45bbaf301c8243f51a942bb82d81675c70481f68d64cf14f8f005e module=libcontainerd namespace=moby topic=/tasks/delete type=""*events.TaskDelete""Dec 19 12:04:11 mana dockerd[384495]: time=""2020-12-19T12:04:11.366851423+11:00"" level=info msg=""shim disconnected"" id=ed24834d6f45bbaf301c8243f51a942bb82d81675c70481f68d64cf14f8f005eDec 19 12:04:11 mana dockerd[384483]: time=""2020-12-19T12:04:11.368999767+11:00"" level=warning msg=""\ncould not release {tcp 172.17.0.2 80 fc00:1337:1337:1337:1337:1337:1337:1337 80 80} because of port is not mapped""Dec 19 12:04:11 mana dockerd[384483]: time=""2020-12-19T12:04:11.582843296+11:00"" level=warning msg=""Failed to allocate and map port 80-80: Bind for fc00:1337:1337:1337:1337:1337:1337:1337:80 failed: port is already allocated""Dec 19 12:04:11 mana dockerd[384483]: time=""2020-12-19T12:04:11.682239315+11:00"" level=error msg=""ed24834d6f45bbaf301c8243f51a942bb82d81675c70481f68d64cf14f8f005e cleanup: failed to delete container from containerd: no such container""Dec 19 12:04:11 mana dockerd[384483]: time=""2020-12-19T12:04:11.693431409+11:00"" level=error msg=""Handler for POST /v1.41/containers/nginx-test/restart returned error: Cannot restart container nginx-test: driver failed programming external connectivity on endpoint nginx-test (9a6f7a503369a88aa1d200050e4a82ba09e755e48588f4000086c5abae6c3710): Bind for fc00:1337:1337:1337:1337:1337:1337:1337:80 failed: port is already allocated""```**Describe the results you expected:**I expect that the container would have restarted successfully with the appropriate port being published on the specified IPv6 address.**Additional information you deem important (e.g. issue happens only occasionally):**I cannot reproduce the issue if publishing a port to a hosts IPv4 address, for example:1. `docker run -d --name nginx-test -p 10.10.10.4:80:80 nginx`2. `docker restart nginx-test`The above commands will run successfully.Downgrading to `19.03.14` provides a temporary workaround as this issue does not exist in the older version.While my default runtime is set to `crun` I also went back to the Docker defaults with `runc` and I was able to reproduce the issue.**Output of `docker version`:**```Client: Version:           20.10.1 API version:       1.41 Go version:        go1.15.6 Git commit:        831ebeae96 Built:             Tue Dec 15 22:25:01 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          20.10.1  API version:      1.41 (minimum version 1.12)  Go version:       go1.15.6  Git commit:       f0014860c1  Built:            Tue Dec 15 22:24:28 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b.m crun:  Version:          0.16  GitCommit:        eb0145e5ad4d8207e84a327248af76663d4e50dd docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-tp-docker)Server: Containers: 1  Running: 1  Paused: 0  Stopped: 0 Images: 32 Server Version: 20.10.1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: crun io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: crun Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b.m runc version: eb0145e5ad4d8207e84a327248af76663d4e50dd init version: de40ad0 Security Options:  seccomp   Profile: default Kernel Version: 5.9.14-arch1-1 Operating System: Archcraft OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 31.32GiB Name: mana ID: WSAG:GWTA:H6MH:IIOR:M5TO:DMEQ:6HMW:BJ25:VB3W:ERGY:ORNA:3RGQ Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Registry Mirrors:  http://nerv:5000/ Live Restore Enabled: falseWARNING: No blkio weight supportWARNING: No blkio weight_device support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Not applicable.
"
41820,0,4334,9,0,0,PandarinDev,0,"title:Upgrade to 20.10 breaks log tailing: unexpected EOF errors. description:**Description**Our E2E test suite uses [testcontainers-java](https://github.com/testcontainers/testcontainers-java) to run our microservices and their dependencies in containers for the duration of our tests. All of the tests were passing with 19.03.14 until we updated our build nodes to Docker 20.10.1, at which point we started repeatedly getting `STDOUT: $Error grabbing logs: unexpected EOF errors`, and our Wait.forLogMessage calls started timing out.Note however, that this issue seems sporadic as about 1 out of 10 builds still passes. After we reverted to Docker 19.03.14 the issue went away. We're using the latest version of Testcontainers (1.15.1 at the time of reporting the issue).After contacting the developers [I was told this is most likely a Docker issue](https://github.com/testcontainers/testcontainers-java/issues/3613).**Steps to reproduce the issue:**Unfortunately our projects are not OSS, so I cannot give you the exact containers used. I'll try to describe a matching scenario.1. Set up a project that uses the latest version of testcontainers-java (`1.15.1`).2. Set up a docker image that produces a lot of standard output.3. Start the image using testcontainers-java and wait for a log message using `Wait.forLogMessage()`.4. A huge percentage of the times this will result in the error message `STDOUT: $Error grabbing logs: unexpected EOF errors` and the wait policy will not trigger even though the messages are present in the log.**Describe the results you received:**Error message: `STDOUT: $Error grabbing logs: unexpected EOF errors`, wait policy for log message not triggering even though the message was present in the log.**Describe the results you expected:**No EOF error, wait policy for log message working.**Additional information you deem important (e.g. issue happens only occasionally):**As mentioned in the description the issue seems sporadic, but it happens in about 80+% of our CI runs.**Output of `docker version`:**Previous version where the tests were passing: ```Client: Docker Engine - Community Version:           19.03.14 API version:       1.40 Go version:        go1.13.15 Git commit:        5eb3275d40 Built:             Tue Dec  1 19:20:26 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.14  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       5eb3275d40  Built:            Tue Dec  1 19:18:53 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.3.9  GitCommit:        ea765aba0d05254012b0b9e595e995c09186427f runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```Current version where the issue is present:```Client: Version:           20.10.1 API version:       1.41 Go version:        go1.15.6 Git commit:        831ebeae96 Built:             Tue Dec 15 22:25:01 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          20.10.1  API version:      1.41 (minimum version 1.12)  Go version:       go1.15.6  Git commit:       f0014860c1  Built:            Tue Dec 15 22:24:28 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b.m runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**Previous version where the tests were passing:```Client: Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 92 Server Version: 19.03.14 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: ea765aba0d05254012b0b9e595e995c09186427f runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.4.0-58-generic Operating System: Ubuntu 20.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 3 Total Memory: 15.64GiB Name: build1 ID: QWYR:EE5C:DWTE:MY65:MQ7Y:FERG:F7J2:IDTT:7LVR:VHSE:REFY:6AQH Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```Current version where the issue is present:```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-tp-docker)Server: Containers: 134  Running: 8  Paused: 0  Stopped: 126 Images: 1390 Server Version: 20.10.1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b.m runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  seccomp   Profile: default Kernel Version: 5.9.14-arch1-1 Operating System: Arch Linux OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 31.24GiB Name: RE02WL03 ID: YC3H:JCWA:APFN:VOQ7:CWPG:B4VO:5FYW:UPVL:2H5B:PO4H:SXO7:LSGH Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No blkio weight supportWARNING: No blkio weight_device support```The current version and info parts were copied from an Arch box, while the previous version and info parts were copied from an Ubuntu box, but we could also reproduce the issue on Ubuntu after upgrading to 20.10.**Additional environment details (AWS, VirtualBox, physical, etc.):**- Could reproduce using both Ubuntu 20.10 and Arch Linux.
"
41813,1,2314,24,0,0,mlan,0,"title:Upgrade to 20.10 breaks networking dependent on identifying real source IP (UDP). description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**UDP (RTP) package streams are sent to wrong destination address when using an [Asterisk VoIP](https://github.com/mlan/docker-asterisk) container. Since the UDP voice package streams might traverse several NAT boundaries including the docker-proxy the VoIP server (asterisk) need to be able to figure out the real IP of the remote endpoint. This has worked flawlessly but stopped working with version 20.10. **Steps to reproduce the issue:**1. start a [mlan/asterisk](https://github.com/mlan/docker-asterisk#docker-compose-example) VoIP server2. connect an endpoint (phone) with the VoIP server3. place a call**Describe the results you received:*** 19.03.14: Two way audio* 20.10.0: No audio, since the UDP (RTP) package streams are sent to wrong destination address.* 20.10.1: No audio, since the UDP (RTP) package streams are sent to wrong destination address.**Describe the results you expected:**Two way audio**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**Working system with docker-ce downgraded to 19.03.14```Client: Docker Engine - Community Version:           20.10.1 API version:       1.40 Go version:        go1.13.15 Git commit:        831ebea Built:             Tue Dec 15 04:34:58 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          19.03.14  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       5eb3275d40  Built:            Tue Dec  1 19:18:53 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**Working system with docker-ce downgraded to 19.03.14```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.0-docker)Server: Containers: 5  Running: 5  Paused: 0  Stopped: 0 Images: 5 Server Version: 19.03.14 Storage Driver: zfs  Zpool: rpool  Zpool Health: ONLINE  Parent Dataset: rpool/docker  Space Used By Parent: 444006400  Space Available: 1661051703296  Parent Quota: no  Compression: lz4 Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local zfs  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.4.0-58-generic Operating System: Ubuntu 20.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 31.33GiB Name: srv2 ID: WVEK:PAQ6:NHJ3:BGLG:ZNMG:EVZO:YJKF:ZYCP:VW3E:BT5Q:AXKJ:XLA2 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
41803,0,3429,228,0,0,georglauterbach,0,"title:[rootless] lchown [...]: no such file or directory. description:# Rootless Docker cannot pull certain images?!No matter what I do, I can't quite get it to work, and the internet is full of reports where this is the case. I'm on Ubuntu 20.04 with a `5.4.0-58` kernel. `systemctl --user status docker` reports:``` BASHdockerd-rootless.sh[1932]: [...] level=warning msg=""Not using native diff for overlay2, this may cause degraded performance for building images: failed to set opaque flag on middle layer: operation not permitted"" storage-driver=overlay2```I tried:1. Setting `options overlay metacopy=off redirect_dir=off` for the overlay kernel module2. Installing packages like `fuse-overlayfs` and its libraries3. https://mikeshade.com/posts/docker-native-overlay-diff/Reports:1. https://github.com/docker/for-linux/issues/10552. https://stackoverflow.com/questions/65273160/how-to-enable-native-overlay-diff-on-debian-docker-rootless3. https://github.com/containers/buildah/issues/23264. https://github.com/containers/buildah/blob/master/troubleshooting.md#6-rootless-buildah-bud-fails-when-using-overlayfsWhy is this important? Some images cannot be pulled, and fail due to a strange error where `lchown` does not find a file or directory:``` BASH ~ $ docker pull docker.io/gitlab/gitlab-ee:13.6.3-ee.013.6.3-ee.0: Pulling from gitlab/gitlab-eebe8ec4e48d7f: Pull complete33b8b485aff0: Pull completed887158cc58c: Pull complete05895bb28c18: Pull complete5a5da1768523: Pull completefabe58ce18d2: Pull complete7eb97e608ff0: Pull complete1ab51a6460c9: Pull completeb07e61468e0b: Pull completec5dd26abc4c2: Extracting [==================================================>]  901.9MB/901.9MBfailed to register layer: Error processing tar file(exit status 1): lchown /opt/gitlab/sv/sshd/log/supervise/ok: no such file or directory```**Steps to reproduce the issue:**1. Install rootless Docker on Ubuntu 20.04.1**Describe the results you received:**I'm seeing``` BASHStorage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false```and I cannot pull (large?) images.**Describe the results you expected:**If would like to see``` BASHStorage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  <--------```and I'd like to pull large images.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.0 API version:       1.41 Go version:        go1.13.15 Git commit:        7287ab3 Built:             Tue Dec  8 18:54:00 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.0  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       eeddea2  Built:            Tue Dec  8 18:58:04 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 0 Server Version: 20.10.0 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runtime.v1.linux runc io.containerd.runc.v2 Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  seccomp   Profile: default  rootless  cgroupns Kernel Version: 5.4.0-58-generic Operating System: Ubuntu 20.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.775GiB Name: itbsd ID: WCKE:YRNK:PITP:G345:T3KJ:IMZH:2N7L:Y5YP:FFLO:MLZW:CFD7:ZMGU Docker Root Dir: /home/notroot/.local/share/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false Product License: Community EngineWARNING: No kernel memory TCP limit supportWARNING: No oom kill disable supportWARNING: Support for cgroup v2 is experimental```**Additional environment details (AWS, VirtualBox, physical, etc.):**Happens here: https://github.com/docker/docker-ce/blob/master/components/engine/daemon/graphdriver/overlay2/check.go#L55 ?
"
41794,0,2821,0,0,1,parikshitataws,0,"title:""awslogs"" driver with ""non-blocking"" mode cause log events to split larger then 16k size. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**When using awslogs driver with non-blocking logging mode to prevent containers hanging to mitigate issues with CloudWatch service, ECS tasks log events greater than 16 KB are split into multiple events in CloudWatch logs.The same ECS service deployment without ""mode"": ""non-blocking"" log options treats log events longer than 16 KB as a single CloudWatch log event.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**One can reproduce this issue on Docker, ECS EC2 launch type, Fargate 1.3.0 and Fargate 1.4.0 launch types by running a container image that outputs 17 KB:Here is my Dockerfile to build image ```$ cat DockerfileFROM ubuntu:18.04CMD tr -dc A-Za-z0-9 </dev/urandom | head -c 17000; echo ''``````...    ""logConfiguration"": {    ""logDriver"": ""awslogs"",    ""options"": {    ""awslogs-group"": ""/ecs/nonblocking"",    ""awslogs-region"": ""us-east-1"",    ""mode"": ""non-blocking"",    ""awslogs-stream-prefix"": ""ecs""    }}```Also Running directly using docker command below has same result for non-blocking mode.```docker run -d --log-driver=awslogs --log-opt mode=non-blocking --log-opt max-buffer-size=4m --log-opt awslogs-group=""/ecs/log-event-split-test"" --log-opt mode=non-blocking --log-opt awslogs-region=ap-southeast-2 hello2parikshit/log-event-split-test:latest```**Describe the results you received:**When the logging mode is set to default (blocking), the entire line is sent as a single event to CloudWatch.When set to non-blocking, the event is split and sent to CloudWatch Logs with the exact same timestamp.**Describe the results you expected:**When set to non-blocking, the cloud watch event should be recorded entire log event without splitting to CloudWatch Logs with the exact same timestamp.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```docker versionClient: Version:           19.03.13-ce API version:       1.40 Go version:        go1.13.15 Git commit:        4484c46 Built:             Mon Oct 12 18:51:20 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          19.03.13-ce  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       4484c46  Built:            Mon Oct 12 18:51:50 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.1  GitCommit:        c623d1b36f09f8ef6536a057bd658b3aa8632828 runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```docker infoClient: Debug Mode: falseServer: Containers: 66  Running: 17  Paused: 0  Stopped: 49 Images: 8 Server Version: 19.03.13-ce Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: amazon-ecs-volume-plugin local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: c623d1b36f09f8ef6536a057bd658b3aa8632828 runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 (expected: fec3683) Security Options:  seccomp   Profile: default Kernel Version: 4.14.203-156.332.amzn2.x86_64 Operating System: Amazon Linux 2 OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 3.618GiB Name: ip-172-31-43-108.ap-southeast-2.compute.internal ID: 7ENC:ICR2:4LS6:BQ2N:EQYC:FNOI:IRSW:VGCI:5LVB:5KYQ:CHXW:7XSR Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 147  Goroutines: 172  System Time: 2020-12-15T02:52:14.501116615Z  EventsListeners: 1 Username: hello2parikshit Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):** AWS EC2, Fargate PV 1.3.0, Fargate PV 1.4.0
"
41774,1,7853,8,0,1,bboehmke,0,"title:ip6tables causes daemon to crash (experimental). description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**With enabled ip6tables (including the experimental option) the daemon crashes on startup.**Steps to reproduce the issue:**Start the daemon with:```dockerd --ipv6 --fixed-cidr-v6 fd00:dead:beef::/48 --ip6tables --experimental```**Describe the results you received:**```INFO[2020-12-10T15:23:18.538460939+01:00] Starting up                                  WARN[2020-12-10T15:23:18.538675516+01:00] Running experimental build                   INFO[2020-12-10T15:23:18.539879145+01:00] parsed scheme: ""unix""                         module=grpcINFO[2020-12-10T15:23:18.540005907+01:00] scheme ""unix"" not registered, fallback to default scheme  module=grpcINFO[2020-12-10T15:23:18.540109662+01:00] ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}  module=grpcINFO[2020-12-10T15:23:18.540210588+01:00] ClientConn switching balancer to ""pick_first""  module=grpcINFO[2020-12-10T15:23:18.542245104+01:00] parsed scheme: ""unix""                         module=grpcINFO[2020-12-10T15:23:18.542271637+01:00] scheme ""unix"" not registered, fallback to default scheme  module=grpcINFO[2020-12-10T15:23:18.542293888+01:00] ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}  module=grpcINFO[2020-12-10T15:23:18.542363497+01:00] ClientConn switching balancer to ""pick_first""  module=grpcINFO[2020-12-10T15:23:18.556494462+01:00] [graphdriver] using prior storage driver: overlay2 WARN[2020-12-10T15:23:18.561225739+01:00] Your kernel does not support swap memory limit WARN[2020-12-10T15:23:18.564152713+01:00] Your kernel does not support CPU realtime scheduler INFO[2020-12-10T15:23:18.564628857+01:00] Loading containers: start.                   panic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x10 pc=0x5590ba437939]goroutine 1 [running]:github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*bridgeNetwork).setupIP6Tables(0xc0003a9260, 0xc000ad7790, 0xc0003a9140, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/setup_ip_tables.go:128 +0x79github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*bridgeSetup).apply(0xc0009b4750, 0xc00008e180, 0x8)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/setup.go:17 +0x7cgithub.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*driver).createNetwork(0xc000a82200, 0xc000ad7790, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge.go:809 +0x7e7github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*driver).populateNetworks(0xc000a82200, 0x5, 0x5590bb13bf7a)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge_store.go:62 +0x28dgithub.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*driver).initStore(0xc000a82200, 0xc000a85b90, 0x0, 0xc00083a8c0)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge_store.go:35 +0x211github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*driver).configure(0xc000a82200, 0xc000a85b90, 0x5590bbe3dae0, 0xc000a858c0)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge.go:439 +0x20dgithub.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.Init(0x5590bc312760, 0xc0006a6d80, 0xc000a85b90, 0xc000a85b90, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge.go:169 +0x9cgithub.com/docker/docker/vendor/github.com/docker/libnetwork/drvregistry.(*DrvRegistry).AddDriver(...)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drvregistry/drvregistry.go:72github.com/docker/docker/vendor/github.com/docker/libnetwork.New(0xc000a82180, 0x9, 0x10, 0xc0005015f0, 0xc000a85860, 0xc000a82180, 0x9)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:221 +0x4f0github.com/docker/docker/daemon.(*Daemon).initNetworkController(0xc00000c1e0, 0xc0000c5600, 0xc000a85860, 0x0, 0x0, 0x0, 0x0)	/go/src/github.com/docker/docker/daemon/daemon_unix.go:854 +0xa9github.com/docker/docker/daemon.(*Daemon).restore(0xc00000c1e0, 0xc000713900, 0xc00015c380)	/go/src/github.com/docker/docker/daemon/daemon.go:467 +0x50bgithub.com/docker/docker/daemon.NewDaemon(0x5590bc341a20, 0xc000713900, 0xc0000c5600, 0xc0005015f0, 0x0, 0x0, 0x0)	/go/src/github.com/docker/docker/daemon/daemon.go:1117 +0x2be7main.(*DaemonCli).start(0xc000501350, 0xc00084b920, 0x0, 0x0)	/go/src/github.com/docker/docker/cmd/dockerd/daemon.go:195 +0x743main.runDaemon(...)	/go/src/github.com/docker/docker/cmd/dockerd/docker_unix.go:13main.newDaemonCommand.func1(0xc0006fadc0, 0xc000504500, 0x0, 0x5, 0x0, 0x0)	/go/src/github.com/docker/docker/cmd/dockerd/docker.go:34 +0x7cgithub.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).execute(0xc0006fadc0, 0xc00004e1f0, 0x5, 0x5, 0xc0006fadc0, 0xc00004e1f0)	/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:850 +0x462github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc0006fadc0, 0x0, 0x0, 0x10)	/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:958 +0x34bgithub.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).Execute(...)	/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:895main.main()	/go/src/github.com/docker/docker/cmd/dockerd/docker.go:97 +0x191```**Describe the results you expected:**Startup without exception**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.0 API version:       1.41 Go version:        go1.13.15 Git commit:        7287ab3 Built:             Tue Dec  8 18:59:49 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.0  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       eeddea2  Built:            Tue Dec  8 18:57:58 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.4.2-docker)Server: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 0 Server Version: 20.10.0 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.19.0-13-amd64 Operating System: Debian GNU/Linux 10 (buster) OSType: linux Architecture: x86_64 CPUs: 1 Total Memory: 1.902GiB Name: docker-test ID: J7KW:ISZL:54TP:KIGF:IFYC:YTTF:635N:LD2C:XMRZ:NTRG:4RJD:IXA5 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Hetzner cloud CX11 VM 
"
41771,1,3942,31,0,0,Aragur,0,"title:Command 'docker login' does not work. description:--------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------**Description**Docker crashes after command ```docker login```**Steps to reproduce the issue:**1. Run ```docker login```**Describe the results you received:**```panic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x8 pc=0x55a136904406]goroutine 1 [running]:github.com/docker/cli/cli/command.ConfigureAuth(0x55a138346e00, 0xc00034a1a0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x55a1382b6201, 0xc00005af80, 0xc00041b968)        /go/src/github.com/docker/cli/cli/command/registry.go:128 +0x46github.com/docker/cli/cli/command/registry.runLogin(0x55a138346e00, 0xc00034a1a0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...)        /go/src/github.com/docker/cli/cli/command/registry/login.go:123 +0x223github.com/docker/cli/cli/command/registry.NewLoginCommand.func1(0xc000244840, 0x55a1393515c8, 0x0, 0x0, 0x0, 0x0)        /go/src/github.com/docker/cli/cli/command/registry/login.go:45 +0xccgithub.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).execute(0xc000244840, 0xc000252f30, 0x0, 0x0, 0xc000244840, 0xc000252f30)        /go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:850 +0x462github.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc000573080, 0xc000252f30, 0x1, 0x1)        /go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:958 +0x34bgithub.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).Execute(...)        /go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:895main.runDocker(0xc00034a1a0, 0x55a1382b8f40, 0xc0000ce010)        /go/src/github.com/docker/cli/cmd/docker/docker.go:287 +0x1d3main.main()        /go/src/github.com/docker/cli/cmd/docker/docker.go:298 +0xf3```**Describe the results you expected:**I should be able to login :)**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.0 API version:       1.41 Go version:        go1.13.15 Git commit:        7287ab3 Built:             Tue Dec  8 18:59:49 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.0  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       eeddea2  Built:            Tue Dec  8 18:57:58 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.4.2-docker)Server: Containers: 3  Running: 3  Paused: 0  Stopped: 0 Images: 3 Server Version: 20.10.0 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.19.0-13-amd64 Operating System: Debian GNU/Linux 10 (buster) OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 11.73GiB Name: v2202011133880133864 ID: M3MB:RTMT:TGLN:CJSU:6PKI:XSGP:AADE:SNDO:I5LB:KQRQ:2FIL:6EOG Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical root Server. (Fresh install)
"
41762,0,2918,247,1,0,AkihiroSuda,0,"title:[rootless] driver ""btrfs"" failed to remove root filesystem: Failed to destroy btrfs snapshot /home/<USER>/.local/share/docker/btrfs/subvolumes for <ID>: operation not permitted . description:### WorkaroundCreate the `~/.config/docker/daemon.json` with the following content and run `systemctl --user restart docker````json{""storage-driver"": ""fuse-overlayfs""}```- - -<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->btrfs driver is not really expected to be supported for rootless, but it is automatically chosen by default when the host filesystem is btrfs (e.g. on Fedora 33 Workstation), and it does not work actually.**Steps to reproduce the issue:**1. Install Fedora 33 Workstation (aka ""Desktop Edition"")2. Install Docker 20.103. Disable SELInux, at least for iptables (https://github.com/moby/moby/issues/41230): `sudo dnf install -y policycoreutils-python-utils && sudo semanage permissive -a iptables_t`4. `docker-rootless-setuptool.sh install`5. `export DOCKER_HOST=$XDG_RUNTIME_DIR/docker.sock`6. Make sure `docker info` shows btrfs as the storage driver7. `docker run --rm busybox true`**Describe the results you received:**```console$ docker run --rm busybox trueERRO[0000] Error waiting for container: container 17f95f5c7b026d9af2367b3676382ec1cc9c7c36e61e93ade87c30f86ce6ace1: driver ""btrfs"" failed to remove root filesystem: Failed to destroy btrfs snapshot /home/suda/.local/share/docker/btrfs/subvolumes for a9644718eaa311671fddd7440b275f97ad3642e21397cc7bd02244d5c9b0e81d: operation not permitted ```**Describe the results you expected:**It should work with btrfs, or it should chose fuse-overlayfs, not btrfs.The latter one is my expected behavior, but the former one might be more ideal.**Additional information you deem important (e.g. issue happens only occasionally):**Fedora 33 Server users are unlikely to be affected because it does not use btrfs by default**Output of `docker version`:**```console$ docker versionClient: Docker Engine - Community Version:           20.10.0 API version:       1.41 Go version:        go1.13.15 Git commit:        7287ab3 Built:             Tue Dec  8 19:00:39 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.0  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       eeddea2  Built:            Tue Dec  8 18:58:12 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.4.3  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```console$ $ docker infoClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.4.2-docker)Server: Containers: 3  Running: 0  Paused: 0  Stopped: 3 Images: 2 Server Version: 20.10.0 Storage Driver: btrfs  Build Version: Btrfs v5.9   Library Version: 102 Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 269548fa27e0089a8b8278fc4fc781d7f65a939b runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  seccomp   Profile: default  rootless  cgroupns Kernel Version: 5.9.11-200.fc33.x86_64 Operating System: Fedora 33 (Workstation Edition) OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 3.809GiB Name: localhost.localdomain ID: WMPE:OZUM:S6ZX:YRMZ:J2LY:J5DJ:7QNJ:IPJ2:QAMV:TE4J:W5U2:AWSY Docker Root Dir: /home/suda/.local/share/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No kernel memory TCP limit supportWARNING: No oom kill disable supportWARNING: No cpuset supportWARNING: Support for cgroup v2 is experimental```
"
41710,1,2737,247,0,0,AkihiroSuda,0,"title:[containerd@master] `docker run busybox true` fails with `io.containerd.runc.v2`. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**`docker run busybox true` fails with `io.containerd.runc.v2`, though it works with `io.containerd.runtime.v1.linux`.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**```$ docker run --name tmp --runtime=io.containerd.runtime.v1.linux busybox true; echo $?WARNING: Configured runtime ""io.containerd.runtime.v1.linux"" is deprecated and will be removed in the next release.0$ docker run --name tmp --runtime=io.containerd.runc.v2 busybox true; echo $137```**Describe the results you received:**Fails with `io.containerd.runc.v2`, though it works with `io.containerd.runtime.v1.linux`.Can't find suspicious output in the daemon logs.Also, the issue is not reproducible with `ctr run docker.io/library/busybox:latest tmp true`.~~So the issue is likely to be on Moby side rather than on containerd side.~~ Regression in https://github.com/containerd/containerd/pull/4538**Describe the results you expected:**Should work with `io.containerd.runc.v2`**Output of `docker version`:**```Client: Version:           20.10.0-dev API version:       1.41 Go version:        go1.13.15 Git commit:        5836f20c2 Built:             Tue Nov 24 09:30:34 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          dev  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       6c0a036dce  Built:            Tue Nov 24 09:29:30 2020  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          v1.4.0-2353-gebc0ddb28  GitCommit:        ebc0ddb28cd4ccc81ebf9cc14a6758e4d4aea2ae runc:  Version:          1.0.0-rc92+dev  GitCommit:        06b737bb156b49382a46736558d225c4210894a7 docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  buildx: Build with BuildKit (Docker Inc., v0.4.2-42-g1ccf0bd)Server: Containers: 3  Running: 0  Paused: 0  Stopped: 3 Images: 151 Server Version: dev Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runsc-kvm crun io.containerd.runc.v2 io.containerd.runtime.v1.linux kata runc runc-rc92 runsc sysbox-runc Default Runtime: runc Init Binary: docker-init containerd version: ebc0ddb28cd4ccc81ebf9cc14a6758e4d4aea2ae runc version: 06b737bb156b49382a46736558d225c4210894a7 init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.8.0-29-generic Operating System: Ubuntu 20.10 OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 15.61GiB Name: suda-ws01 ID: E2YB:EGZO:6BNW:EPHS:4WFQ:EIDV:ZZ6D:QBZK:6673:CIOR:DLZ6:SI3D Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 25  Goroutines: 43  System Time: 2020-11-24T19:46:12.422124142+09:00  EventsListeners: 0 Username: akihirosuda Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No blkio weight supportWARNING: No blkio weight_device support```
"
41699,1,3950,4,0,1,chris-crone,0,"title:Docker 20.10 RC1 breaks IPv6 routing. description:**Description**Prior to 20.10 RC1 (including beta1 and 19.03.x) the following Compose snippet would work:```yamlservices:  test:    image: nginx    networks:      test_net:    ports:      - ""${IP6_ADDR}:80:80/tcp""networks:  test_net:    enable_ipv6: true    ipam:      config:        - subnet: ""fd00:2::/64""```It now fails with:```consoleERROR: for d67edf86c583_ip6_test_1  Cannot start service test: driver failed programming external connectivity on endpoint ip6_test_1 (207d3ce431f361136e1bd137c9ea429beb6b2e5690ea7b0b05793738125bc8f2):  (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d REDACTED_IPV6_ADDRESS --dport 80 -j DNAT --to-destination 172.31.0.2:80 ! -i br-3c90dbe5ce74: iptables v1.8.4 (legacy): host/network `REDACTED_IPV6_ADDRESS' not foundTry `iptables -h' or 'iptables --help' for more information. (exit status 2))ERROR: for test  Cannot start service test: driver failed programming external connectivity on endpoint ip6_test_1 (207d3ce431f361136e1bd137c9ea429beb6b2e5690ea7b0b05793738125bc8f2):  (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d REDACTED_IPV6_ADDRESS --dport 80 -j DNAT --to-destination 172.31.0.2:80 ! -i br-3c90dbe5ce74: iptables v1.8.4 (legacy): host/network `REDACTED_IPV6_ADDRESS' not foundTry `iptables -h' or 'iptables --help' for more information. (exit status 2))```**Steps to reproduce the issue:**1. `docker-compose up` with Compose snippet above and a valid IPv6 address.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```$ docker versionClient: Docker Engine - Community Version:           20.10.0-rc1 API version:       1.41 Go version:        go1.13.15 Git commit:        5cc2396 Built:             Tue Nov 17 22:51:53 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.0-rc1  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       131bf7e  Built:            Tue Nov 17 22:50:10 2020  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          1.4.1  GitCommit:        c623d1b36f09f8ef6536a057bd658b3aa8632828 runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker-compose version`:**```docker-compose version 1.27.4, build 40524192docker-py version: 4.3.1CPython version: 3.7.7OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.4.2-docker)Server: Containers: 7  Running: 4  Paused: 0  Stopped: 3 Images: 28 Server Version: 20.10.0-rc1 Storage Driver: overlay2  Backing Filesystem: btrfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: c623d1b36f09f8ef6536a057bd658b3aa8632828 runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.4.0-54-generic Operating System: Ubuntu 20.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.59GiB Name: jupiter ID: RROU:WC3V:7XMK:H2BY:2ICR:6A4R:VMTP:RKAU:XHZU:LEY4:M2BM:JXR4 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit supportWARNING: No blkio weight supportWARNING: No blkio weight_device support```**Docker daemon config**```{  ""storage-driver"": ""overlay2"",  ""experimental"": true,  ""ipv6"": true,  ""fixed-cidr-v6"": ""fd00::/80"",  ""features"": {          ""buildkit"": true  }}```
"
41692,1,1293,0,0,0,qoobic,0,"title:The docker stack deploy command does not mount secrets correctly when a service spec is overridden. description:**Description**When using docker stack deploy with multiple compose files overriding the same service spec, the secrets defined in the base spec are munged, at least in the case where the same secret (eg - `foobar`) is mounted to multiple target locations (ie - `foobar` --> `/run/secrets/foobar1` and `foobar` --> `/run/secrets/foobar2`).For information, I encountered this issue when creating a base configuration for a server and providing an override file with extra environment variables set depending on use-case, even without the override file modifying the secrets.**File: foobar.yml**```version: '3.7'services:  foobar:    image: nginx    secrets:      - source: foobar        target: foobar1      - source: foobar        target: foobar2secrets:  foobar:    file: foobar.secret```**File: foobar-extend.yml**```version: '3.7'services:  foobar:    environment:      HELLO: WORLD```**File: foobar.secret**```foobar```**Steps to reproduce the issue:**1. Create files as specified above.2. Run `docker stack deploy -c foobar.yml -c foobar-extend.yml foobar`.3. Run `docker service inspect foobar_foobar | jq -r "".[0].Spec.TaskTemplate.ContainerSpec.Secrets""` to evaluate the secrets mounted onto the service.**Describe the results you received:**The secret `foobar` is only mounted into one of the two locations.```[  {    ""File"": {      ""Name"": ""foobar2"",      ""UID"": ""0"",      ""GID"": ""0"",      ""Mode"": 292    },    ""SecretID"": ""7szqcfqgk62xwy4j4r7ldi92k"",    ""SecretName"": ""foobar_foobar""  }]```**Describe the results you expected:**The secret `foobar` should be mounted into both `/run/secrets/foobar1` and `/run/secrets/foobar2`**Additional information you deem important (e.g. issue happens only occasionally):**I have Swarm mode active, I have not tried the same test with Swarm mode inactive.**Output of `docker version`:**```Client: Version:           19.03.6-ce API version:       1.40 Go version:        go1.13.4 Git commit:        369ce74 Built:             Fri May 29 04:01:26 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          19.03.6-ce  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.4  Git commit:       369ce74  Built:            Fri May 29 04:01:57 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.3.2  GitCommit:        ff48f57fc83a8c44cf4ad5d672424a98ba37ded6 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Additional environment details (AWS, VirtualBox, physical, etc.):**AWS Workspace
"
41686,0,3712,14,0,0,Chostakovitch,0,"title:docker volume prune removes ALL volumes when live restore is enabled and unless-stopped restart policy is used. description:**Note : issue edited to include an additional restart of Docker daemon to really reproduce the issue from scratch.****Description**When [live restore](https://docs.docker.com/config/containers/live-restore/) is enabled, stopping and restarting the daemon then running `docker volume prune` removes **all volumes** mounted in containers with `unless-stopped` policy.It is very dangerous, as volumes used by running containers will just disappear with no warning.**Steps to reproduce the issue:**Here is a MWE from a fresh Debian 10.1. Install Docker from the [Docker repository](https://docs.docker.com/engine/install/debian/#install-using-the-repository)2. Add yourself into the `docker` group3. Start the Docker daemon a first time :```bashsudo systemctl start docker```3. Edit `/etc/docker/daemon.json` with the following content to enable live restore :```json{	""live-restore"": true}```5. Restart the Docker daemon to enable live restore :```bash$ sudo systemctl restart docker```6. Create a local volume (`pica`) :```bash$ docker volume create pica```7. Create a dummy container with `unless-stopped` policy and mount the volume :```bash$ docker run -d --volume pica:/pica --name pica --restart unless-stopped busybox sleep 10000```8. Check that the container is running :```bash$ docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES32749a84d3a6        busybox             ""sleep 10000""       17 seconds ago      Up 16 seconds                           pica```9. Restart the daemon. With live restore enabled, the container won't stop.```bash$ sudo systemctl restart docker```10. Check that the container is indeed still running :```bash$ docker psCONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMES32749a84d3a6        busybox             ""sleep 10000""       About a minute ago   Up 38 seconds                           pica```11. Prune volumes :```bash$ docker volume pruneWARNING! This will remove all local volumes not used by at least one container.Are you sure you want to continue? [y/N] yDeleted Volumes:picaTotal reclaimed space: 0B```**Describe the results you received:**The `pica` volume is **removed** whereas the `pica` container is **still running**.Even after the removal, we can still execute a command in the container, showing that it is **really** still running :```bash docker exec -it pica sh/ # ```Excerpt of `docker inspect pica` :```json""Mounts"": [            {                ""Type"": ""volume"",                ""Name"": ""pica"",                ""Source"": ""/var/lib/docker/volumes/pica/_data"",                ""Destination"": ""/pica"",                ""Driver"": ""local"",                ""Mode"": ""z"",                ""RW"": true,                ""Propagation"": """"            }        ]```Obviously the volume has been removed, so :```bash$ docker volume inspect pica[]Error: No such volume: pica$ sudo ls /var/lib/docker/volumes/pica/_datals: cannot access '/var/lib/docker/volumes/pica/_data': No such file or directory```**Describe the results you expected:**Volumes mounted in running containers should not be removed when running `docker volume prune`.**Additional information you deem important (e.g. issue happens only occasionally):**With live restore alone or `unless-stopped` alone, `docker volume prune` will not remove volumes mounted in running containers.If a container has been manually restarted after restarting the Docker daemon, the volume won't be removed.**Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.13 API version:       1.40 Go version:        go1.13.15 Git commit:        4484c46d9d Built:             Wed Sep 16 17:02:55 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.13  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       4484c46d9d  Built:            Wed Sep 16 17:01:25 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.3.7  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 1  Running: 1  Paused: 0  Stopped: 0 Images: 1 Server Version: 19.03.13 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 8fba4e9a7d01810a393d5d25a3621dc101981175 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.19.0-5-cloud-amd64 Operating System: Debian GNU/Linux 10 (buster) OSType: linux Architecture: x86_64 CPUs: 1 Total Memory: 1.904GiB Name: vps-5c256a04 ID: D3BW:DYRD:D2UJ:5FAM:NOIR:CEPB:CDKT:DVBP:OFLO:WNFW:SPLK:LTCA Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: trueWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Tested with Debian 10 on virtual machines.
"
41683,0,7548,300,0,0,AdamKorcz,0,"title:/image/store.go Empty configuration causes runtime panic. description:This is a bug report.I have recently submitted a fuzzer. It can be found [here](https://github.com/moby/moby/pull/41682).The fuzzer exposes a crash with the input `{}` and variations of this input such as new line inbetween, before and after the curly brackets.Docker was pulled with the command `go get github.com/docker/docker/image` prior to running the fuzzer against the target.**Input that causes crash**The fuzzer with the input that causes the crash is to be found below. The only thing that is modified from the fuzzer in the PR is the input passed to `store.Create()`.```package fuzzimport (        ""github.com/docker/docker/image""        ""os""        ""io/ioutil""        ""runtime""        ""github.com/docker/docker/layer"")type mockLayerGetReleaser struct{}func (ls *mockLayerGetReleaser) Get(layer.ChainID) (layer.Layer, error) {        return nil, nil}func (ls *mockLayerGetReleaser) Release(layer.Layer) ([]layer.Metadata, error) {        return nil, nil}func FuzzImage(data []byte) int {        tmpdir, err := ioutil.TempDir("""", ""images-fs-store"")        defer os.RemoveAll(tmpdir)        if err != nil {                return -1        }        fsBackend, err := image.NewFSStoreBackend(tmpdir)        if err != nil {                return -1        }        mlgrMap := make(map[string]image.LayerGetReleaser)        mlgrMap[runtime.GOOS] = &mockLayerGetReleaser{}        store, err := image.NewImageStore(fsBackend, mlgrMap)        if err != nil {                return 0        }        _, err = store.Create([]byte(`{}`))        if err != nil {                return 0        }        return 1}```**Stacktrace**```signal 11 received but handler not on signal stackfatal error: non-Go code set up signal handler without SA_ONSTACK flagruntime stack:runtime: unexpected return pc for runtime.sigtramp called from 0x7f03988d8390stack: frame={sp:0x10c00014f528, fp:0x10c00014f580} stack=[0x10c000147458,0x10c00014f858)000010c00014f428:  000010c00014f448  000000000059f5a5 <runtime.sigNotOnStack+133>000010c00014f438:  0000000000a2ac1a  0000000000000039000010c00014f448:  000010c00014f4a0  000000000059e2fb <runtime.adjustSignalStack+411>000010c00014f458:  000000000000000b  000010c00014f470000010c00014f468:  000010c00014f4b0  00007f0398ffb000000010c00014f478:  0000000000000000  0000000000008000000010c00014f488:  00000000005242b0  000010c00014f6b0000010c00014f498:  000010c00014f580  000010c00014f518000010c00014f4a8:  000000000059e05f <runtime.sigtrampgo+319>  000010c00000000b000010c00014f4b8:  000010c000038000  000010c00014f4d8000010c00014f4c8:  000010c00014f500  0000000000555eb1 <runtime.nilinterhash+113>000010c00014f4d8:  0000000000000000  0000000000000000000010c00014f4e8:  0000000000000000  0000000000000000000010c00014f4f8:  0000000000000000  000010c000000600000010c00014f508:  000010c00014f6b0  000010c00014f580000010c00014f518:  000010c00014f570  00000000005bfa23 <runtime.sigtramp+67>000010c00014f528: <000000000000000b  000010c00014f6b0000010c00014f538:  000010c00014f580  000010c00031c680000010c00014f548:  000010c000000600  000010c000038000000010c00014f558:  000010c00014f970  000010c00014f570000010c00014f568:  00000000addc2fb7  000010c00014fdc0000010c00014f578: !00007f03988d8390 >0000000000000007000010c00014f588:  0000000000000000  00007f0398ffb000000010c00014f598:  0000000000000000  0000000000008000000010c00014f5a8:  0000000000000000  0000000000f84400000010c00014f5b8:  000010c000000480  0000000000000001000010c00014f5c8:  000010c00014f970  000010c000038000000010c00014f5d8:  000010c000000600  000010c00031c680000010c00014f5e8:  000010c00014fdb0  0000000000000001000010c00014f5f8:  000010c00014fdc0  00000000addc2fb7000010c00014f608:  00000000b9fd536a  000010c0002c3900000010c00014f618:  0000000000000000  000010c00014fb28000010c00014f628:  00000000009f85e9 <github.com/docker/docker/image.(*store).Create+329>  0000000000010286000010c00014f638:  002b000000000033  0000000000000004000010c00014f648:  000000000000000e  0000000000000000000010c00014f658:  0000000000000018  000010c00014f740000010c00014f668:  0000000000000009  000010c00014f6c0000010c00014f678:  000000000070aed1 <encoding/json.(*decodeState).scanWhile+241>runtime.throw(0xa2ac1a, 0x39)        runtime/panic.go:1116 +0x74runtime.sigNotOnStack(0xb)        runtime/signal_unix.go:926 +0x85runtime.adjustSignalStack(0x10c00000000b, 0x10c000038000, 0x10c00014f4d8, 0x10c00014f500)        runtime/signal_unix.go:516 +0x19bruntime.sigtrampgo(0xb, 0x10c00014f6b0, 0x10c00014f580)        runtime/signal_unix.go:461 +0x13fruntime: unexpected return pc for runtime.sigtramp called from 0x7f03988d8390stack: frame={sp:0x10c00014f528, fp:0x10c00014f580} stack=[0x10c000147458,0x10c00014f858)000010c00014f428:  000010c00014f448  000000000059f5a5 <runtime.sigNotOnStack+133>000010c00014f438:  0000000000a2ac1a  0000000000000039000010c00014f448:  000010c00014f4a0  000000000059e2fb <runtime.adjustSignalStack+411>000010c00014f458:  000000000000000b  000010c00014f470000010c00014f468:  000010c00014f4b0  00007f0398ffb000000010c00014f478:  0000000000000000  0000000000008000000010c00014f488:  00000000005242b0  000010c00014f6b0000010c00014f498:  000010c00014f580  000010c00014f518000010c00014f4a8:  000000000059e05f <runtime.sigtrampgo+319>  000010c00000000b000010c00014f4b8:  000010c000038000  000010c00014f4d8000010c00014f4c8:  000010c00014f500  0000000000555eb1 <runtime.nilinterhash+113>000010c00014f4d8:  0000000000000000  0000000000000000000010c00014f4e8:  0000000000000000  0000000000000000000010c00014f4f8:  0000000000000000  000010c000000600000010c00014f508:  000010c00014f6b0  000010c00014f580000010c00014f518:  000010c00014f570  00000000005bfa23 <runtime.sigtramp+67>000010c00014f528: <000000000000000b  000010c00014f6b0000010c00014f538:  000010c00014f580  000010c00031c680000010c00014f548:  000010c000000600  000010c000038000000010c00014f558:  000010c00014f970  000010c00014f570000010c00014f568:  00000000addc2fb7  000010c00014fdc0000010c00014f578: !00007f03988d8390 >0000000000000007000010c00014f588:  0000000000000000  00007f0398ffb000000010c00014f598:  0000000000000000  0000000000008000000010c00014f5a8:  0000000000000000  0000000000f84400000010c00014f5b8:  000010c000000480  0000000000000001000010c00014f5c8:  000010c00014f970  000010c000038000000010c00014f5d8:  000010c000000600  000010c00031c680000010c00014f5e8:  000010c00014fdb0  0000000000000001000010c00014f5f8:  000010c00014fdc0  00000000addc2fb7000010c00014f608:  00000000b9fd536a  000010c0002c3900000010c00014f618:  0000000000000000  000010c00014fb28000010c00014f628:  00000000009f85e9 <github.com/docker/docker/image.(*store).Create+329>  0000000000010286000010c00014f638:  002b000000000033  0000000000000004000010c00014f648:  000000000000000e  0000000000000000000010c00014f658:  0000000000000018  000010c00014f740000010c00014f668:  0000000000000009  000010c00014f6c0000010c00014f678:  000000000070aed1 <encoding/json.(*decodeState).scanWhile+241>runtime.sigtramp(0x7, 0x0, 0x7f0398ffb000, 0x0, 0x8000, 0x0, 0xf84400, 0x10c000000480, 0x1, 0x10c00014f970, ...)        runtime/sys_linux_amd64.s:409 +0x43goroutine 34 [syscall, locked to thread]:runtime.goexit()        runtime/asm_amd64.s:1374 +0x1 fp=0x10c000047fe8 sp=0x10c000047fe0 pc=0x5bde01goroutine 17 [running, locked to thread]:        goroutine running on other thread; stack unavailableAddressSanitizer:DEADLYSIGNAL===================================================================11==ERROR: AddressSanitizer: ABRT on unknown address 0x00000000000b (pc 0x0000005bf681 bp 0x10c00014f360 sp 0x10c00014f348 T0)SCARINESS: 10 (signal)    #0 0x5bf681 in runtime.raise runtime/sys_linux_amd64.s:165DEDUP_TOKEN: runtime.raiseAddressSanitizer can not provide additional info.SUMMARY: AddressSanitizer: ABRT runtime/sys_linux_amd64.s:165 in runtime.raise==11==ABORTINGMS: 0 ; base unit: 0000000000000000000000000000000000000000```
"
41647,0,3659,200,0,1,thaJeztah,0,"title:[20.10] Regression: detection of experimental --stream is incorrect. description:relates to https://github.com/moby/moby/pull/39983relates to https://github.com/docker/docker-ce/pull/660#discussion_r510536957relates to https://github.com/docker/cli/pull/2809Looks like the report we received about the daemon producing an error about the experimental `--stream` option no longer being supported is not fixed yet (the fix in the CLI https://github.com/docker/cli/pull/2809 is not sufficient, as older CLI's will fail)I accidentally discovered how to reproduce:### Daemon (built from v20.10.0-beta1 tag) started without `--experimental`:```consoledocker run -it --rm -v /var/run/docker.sock:/var/run/docker.sock docker:18.09 shecho ""FROM scratch"" | docker build -Sending build context to Docker daemon  2.048kBStep 1/1 : FROM scratch --->No image was generated. Is your Dockerfile empty?```Daemon:```DEBU[2020-11-06T17:10:57.689685060Z] Calling POST /v1.39/build?buildargs={}&cachefrom=[]&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=Dockerfile&labels={}&memory=0&memswap=0&networkmode=default&pull=1&q=1&rm=1&shmsize=0&target=&ulimits=null&version=1```### Daemon, started with `--experimental````consoledocker run -it --rm -v /var/run/docker.sock:/var/run/docker.sock docker:18.09 shecho ""FROM scratch"" | docker build -Sending build context to Docker daemon  2.048kBError response from daemon: experimental session with v1 builder is no longer supported, use builder version v2 (BuildKit) instead```Daemon:```DEBU[2020-11-06T17:06:11.433017409Z] Calling POST /v1.39/build?buildargs={}&cachefrom=[]&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=Dockerfile&labels={}&memory=0&memswap=0&networkmode=default&pull=1&q=1&rm=1&session=btn05f8k6kkk2110fs3djyork&shmsize=0&target=&ulimits=null&version=1DEBU[2020-11-06T17:06:11.434237792Z] Calling POST /sessionINFO[2020-11-06T17:06:11.434395940Z] parsed scheme: """"                             module=grpcINFO[2020-11-06T17:06:11.434453021Z] scheme """" not registered, fallback to default scheme  module=grpcINFO[2020-11-06T17:06:11.434470626Z] ccResolverWrapper: sending update to cc: {[{  <nil> 0 <nil>}] <nil> <nil>}  module=grpcINFO[2020-11-06T17:06:11.434477816Z] ClientConn switching balancer to ""pick_first""  module=grpcDEBU[2020-11-06T17:06:11.486615969Z] FIXME: Got an API for which error does not match any expected type!!!: experimental session with v1 builder is no longer supported, use builder version v2 (BuildKit) instead(removed stack dump)ERRO[2020-11-06T17:06:11.486694465Z] Handler for POST /v1.39/build returned error: experimental session with v1 builder is no longer supported, use builder version v2 (BuildKit) insteadDEBU[2020-11-06T17:06:11.486818111Z] FIXME: Got an API for which error does not match any expected type!!!: experimental session with v1 builder is no longer supported, use builder version v2 (BuildKit) instead(removed stack dump)WARN[2020-11-06T17:06:11.489208009Z] grpc: addrConn.createTransport failed to connect to {  <nil> 0 <nil>}. Err :connection error: desc = ""transport: Error while dialing only one connection allowed"". Reconnecting...  module=grpc```:warning: Notice that the CLI sends `session=btn05f8k6kkk2110fs3djyork`, _even without it having the `--stream` option set_, so for some reason, it looks for the daemon to be experimental, and in that case, sends a session-idTrying with explicit `--stream`:```bashecho ""FROM scratch"" | docker build --stream -failed to open Dockerfile: open Dockerfile: no such file or directoryecho ""FROM scratch"" | docker build --stream=true -failed to open Dockerfile: open Dockerfile: no such file or directory```That looks like another bug, but working around that by using a Dockerfile instead of `stdin`;```consoleecho ""FROM scratch"" > Dockerfiledocker build --stream .Error response from daemon: experimental session with v1 builder is no longer supported, use builder version v2 (BuildKit) instead``````console# without --streamCalling POST /v1.39/build?buildargs={}&cachefrom=[]&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=Dockerfile&labels={}&memory=0&memswap=0&networkmode=default&pull=1&q=1&rm=1&session=btn05f8k6kkk2110fs3djyork&shmsize=0&target=&ulimits=null&version=1# With --streamCalling POST /v1.39/build?buildargs={}&cachefrom=[]&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=Dockerfile&labels={}&memory=0&memswap=0&networkmode=default&remote=client-session&rm=1&session=361whphfmy9h8g4u5kd2zjayi&shmsize=0&target=&ulimits=null&version=1```:warning: So, with `--stream`, the `remote=client-session` is set: perhaps set should produce an error for that parameter instead?
"
41598,1,3365,0,0,0,tejksat,0,"title:Unexpected EOF when trying to start non-existing container. description:**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->When trying to start a non-existing Docker container daemon does not reply with `404` as it is declared in [Docker Engine API Reference](https://docs.docker.com/engine/api/v1.40/#operation/ContainerStart) but it rather unexpectedly interrupts the connection.**Steps to reproduce the issue:**1. Run `curl -v --unix-socket /var/run/docker.sock -X POST http:/v1.24/containers/non-existing/start`    _or_2. Run `docker start non-existing` in Terminal.**Describe the results you received:**1.```*   Trying /var/run/docker.sock:0...* Connected to v1.24 (docker.sock) port 80 (#0)> POST /containers/non-existing/start HTTP/1.1> Host: v1.24> User-Agent: curl/7.71.1> Accept: */*>* Empty reply from server* Connection #0 to host v1.24 left intactcurl: (52) Empty reply from server```2.```error during connect: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.40/containers/non-existing/start: EOFError: failed to start containers: non-existing```**Describe the results you expected:**1.```*   Trying /var/run/docker.sock:0...* Connected to v1.24 (docker.sock) port 80 (#0)> POST /containers/non-existing/start HTTP/1.1> Host: v1.24> User-Agent: curl/7.71.1> Accept: */*>* Mark bundle as not supporting multiuse< HTTP/1.1 404 Not Found< Api-Version: 1.40< Content-Type: application/json< Date: Wed, 28 Oct 2020 08:24:46 GMT< Docker-Experimental: false< Ostype: linux< Server: Docker/19.03.13 (linux)< Transfer-Encoding: chunked<{""message"":""No such container: non-existing""}* Connection #0 to host v1.24 left intact```2.```Error response from daemon: No such container: non-existing```**Output of `docker version`:**```Client: Docker Engine - Community Cloud integration  0.1.18 Version:           19.03.13 API version:       1.40 Go version:        go1.13.15 Git commit:        4484c46d9d Built:             Wed Sep 16 16:58:31 2020 OS/Arch:           darwin/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.13  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       4484c46d9d  Built:            Wed Sep 16 17:07:04 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.3.7  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 38  Running: 22  Paused: 0  Stopped: 16 Images: 195 Server Version: 19.03.13 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 8fba4e9a7d01810a393d5d25a3621dc101981175 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 4.19.76-linuxkit Operating System: Docker Desktop OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 1.944GiB Name: docker-desktop ID: WTP6:BLYV:IM42:YEVO:XJJ6:D5UK:V2UO:WZDI:LMJM:BNNI:7O2B:BXA2 Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 40  Goroutines: 47  System Time: 2020-10-28T08:13:36.787602854Z  EventsListeners: 3 HTTP Proxy: gateway.docker.internal:3128 HTTPS Proxy: gateway.docker.internal:3129 Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false Product License: Community Engine```
"
41581,1,3264,17,0,0,IMMORTALxJO,0,"title:docker service create ignores --update-order. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Hi!It looks like command `docker service create` ignores **--update-order** parameter.**Steps to reproduce the issue:**1. Run in docker swarm cluster `docker service create --update-order start-first --restart-condition none --no-healthcheck --name start-first-test alpine tail -f /dev/null`2. Check output of `docker inspect start-first-test --format '{{ json .Spec.UpdateConfig.Order }}'`**Describe the results you received:**```root@test-manager-01:~# docker service create --update-order start-first --restart-condition none --no-healthcheck --name start-first-test alpine tail -f /dev/nullcnx2j810zwcge4l2211u7meqyoverall progress: 1 out of 1 tasks1/1: running   [==================================================>]verify: Service convergedroot@test-manager-01:~# docker inspect start-first-test --format '{{ json .Spec.UpdateConfig.Order }}'""stop-first""```**Describe the results you expected:**`UpdateConfig.Order` of a new service should be ""start-first""**Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.13 API version:       1.40 Go version:        go1.13.15 Git commit:        4484c46d9d Built:             Wed Sep 16 17:03:03 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.13  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       4484c46d9d  Built:            Wed Sep 16 17:01:33 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.3.7  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 1  Running: 1  Paused: 0  Stopped: 0 Images: 1 Server Version: 19.03.13 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: active  NodeID: v2ob63wvh06t2xa30snjpekj5  Is Manager: true  ClusterID: jwow2iuh7j72bot1mgucrt6va  Managers: 1  Nodes: 1  Default Address Pool: 10.0.0.0/8  SubnetSize: 24  Data Path Port: 4789  Orchestration:   Task History Retention Limit: 5  Raft:   Snapshot Interval: 10000   Number of Old Snapshots to Retain: 0   Heartbeat Tick: 1   Election Tick: 10  Dispatcher:   Heartbeat Period: 5 seconds  CA Configuration:   Expiry Duration: 3 months   Force Rotate: 0  Autolock Managers: false  Root Rotation In Progress: false  Node Address: 10.128.0.15  Manager Addresses:   10.128.0.15:2377 Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 8fba4e9a7d01810a393d5d25a3621dc101981175 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.19.0-0.bpo.8-amd64 Operating System: Debian GNU/Linux 9 (stretch) OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 1.948GiB Name: test-manager-01 ID: EXYO:YTB2:VJ2I:BF3D:ON6N:AGPV:HBS7:QGFT:VBYF:GZMK:X3NH:GVX6 Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 41  Goroutines: 155  System Time: 2020-10-23T08:08:12.87835291Z  EventsListeners: 1 Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```
"
41562,0,2823,29,0,0,aiordache,0,"title:[20.10 beta] Unknown capability ""CAP_PERFMON"" on Linux 5.8.14. description:Running a DIND container fails on an Arch Linux with 5.8.14 kernel.**Steps to reproduce the issue:**```$ docker run --rm -d -p ""2375:2375"" --privileged -e ""DOCKER_TLS_CERTDIR="" --name dind docker:19.03.3-dind```**Describe the results you received:**```docker: Error response from daemon: OCI runtime create failed: container_linux.go:370: starting container process caused: unknown capability ""CAP_PERFMON"": unknown.```**Describe the results you expected:**A running DIND container.**Output of `docker version`:**```Client: Docker Engine - Community Version:           20.10.0-beta1 API version:       1.41 Go version:        go1.13.15 Git commit:        ac365d7 Built:             Tue Oct 13 18:13:41 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Docker Engine - Community Engine:  Version:          20.10.0-beta1  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       9c15e82  Built:            Tue Oct 13 18:17:18 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.4.1  GitCommit:        c623d1b36f09f8ef6536a057bd658b3aa8632828 runc:  Version:          1.0.0-rc92  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```$ docker infoClient: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.4.2-27-gac2e081-tp-docker)Server: Containers: 1  Running: 0  Paused: 0  Stopped: 1 Images: 15 Server Version: 20.10.0-beta1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: c623d1b36f09f8ef6536a057bd658b3aa8632828 runc version: ff819c7e9184c13b7c2607fe6c30ae19403a7aff init version: de40ad0 Security Options:  seccomp   Profile: default Kernel Version: 5.8.14-arch1-1 Operating System: Arch Linux OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.38GiB Name: coldwave ID: KLCY:J2HM:MPJB:PQMJ:7VVB:3B3H:DDM6:CKAV:EQS3:I5IY:HYCG:JZ3H Docker Root Dir: /home/anca/.local/docker Debug Mode: true  File Descriptors: 22  Goroutines: 35  System Time: 2020-10-16T16:27:34.896840907+02:00  EventsListeners: 0 Username: ancaiordache Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false Product License: Community EngineWARNING: No blkio weight supportWARNING: No blkio weight_device support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Arch Linux 5.8.14-arch1-1
"
41552,0,598,200,0,0,thaJeztah,0,"title:[20.10 beta] regression / change in behavior when running different architecture images. description:See https://github.com/moby/moby/pull/40725#issuecomment-709393496This came up in CI for Docker Desktop;looks like  https://github.com/moby/moby/pull/40725 introduced a regression / change in behavior; it will now  at all times print an error, even if the platform supports the other architecture (through quemu); ```docker run --rm arm32v7/alpine uname -mUnable to find image 'arm32v7/alpine:latest' locallylatest: Pulling from arm32v7/alpine52278dd8e579: Pulling fs layer52278dd8e579: Verifying Checksum52278dd8e579: Download complete52278dd8e579: Pull completeDigest: sha256:c929c5ca1d3f793bfdd2c6d6d9210e2530f1184c0f488f514f1bb8080bb1e82bStatus: Downloaded newer image for arm32v7/alpine:latestdocker: Error response from daemon: image with reference arm32v7/alpine was found but does not match the specified platform cpu architecture: wanted: amd64, actual: arm.See 'docker run --help```The above previously worked, but now requires the `--platform` flag to be set (even though the image is not multi-arch)/cc @cpuguy83 @tonistiigi 
"
41531,0,69,279,0,0,cpuguy83,1,"title:Checkpoint fails with shimv2. description:Calling `docker checkpoint` with the (now default) v2 shim yields an error from the shim:```invalid task checkpoint option for io.containerd.runc.v2: unknown```
"
41517,0,1543,242,0,0,mvsde,0,"title:Parsing AppArmor version fails on Ubuntu 20.10. description:**Description**Ubuntu 20.10 uses AppArmor parser that reports the version `3.0.0-beta1`. Output from `apparmor_parser --version`:```AppArmor parser version 3.0.0-beta1Copyright (C) 1999-2008 Novell Inc.Copyright 2009-2018 Canonical Ltd.```This leads to the following error:```ERROR: Service '***' failed to build : AppArmor enabled on system but the docker-default profile could not be loaded: strconv.Atoi: parsing ""0-beta1"": invalid syntax```This issue is probably related to this function: https://github.com/moby/moby/blob/8e610b2b55bfd1bfa9436ab110d311f5e8a74dcb/pkg/aaparser/aaparser.go#L49**Steps to reproduce the issue:**1. Use Ubuntu 20.10 or a beta version of AppArmor.2. Build a Docker image.**Output of `docker version`:**```Docker version 19.03.13, build 4484c46d9d```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 41  Running: 0  Paused: 0  Stopped: 41 Images: 1537 Server Version: 19.03.13 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 8fba4e9a7d01810a393d5d25a3621dc101981175 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.8.0-20-generic Operating System: Ubuntu Groovy Gorilla (development branch) OSType: linux Architecture: x86_64 CPUs: 12 Total Memory: 15.26GiB Name: falcon ID: YBN5:BSM7:JVWU:374Q:RUU7:WLRE:VGF7:Q4UK:YND4:KBXJ:RPB5:6LTM Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Ubuntu 20.10 installed on a physical device.
"
41512,0,534,3,0,0,phaas,0,"title:gcplogs driver is leaking gRPC connections (cloud logger instances). description:**Description**When containers using `--log-driver=gcplogs` are restarted, the cloud logging object is not closed. This results in a leak of ~200Kb memory and 1 tcp socket.**Steps to reproduce the issue:**1. Start a short-lived container using gcplogs driver:`sudo docker run --rm --log-driver=gcplogs debian ""echo"" ""Hello from docker""`or`sudo docker restart ${container_with_gcplogs}` 2. Check the dockerd connection count (and/or memory)`sudo ls -l /proc/$(pidof dockerd)/fd | wc -l`**Describe the results you received:**Memory and tcp sockets grow with every container (re)start**Describe the results you expected:**Resources are released when containers are stopped/restarted**Output of `docker version`:**```Server: Engine:  Version:          19.03.6  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.5  Git commit:       369ce74  Built:            Thu May 21 19:33:08 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.3.2  GitCommit:        ff48f57fc83a8c44cf4ad5d672424a98ba37ded6 runc:  Version:          1.0.0-rc10  GitCommit:         docker-init:  Version:          0.18.0  GitCommit:        fec3683b971d9c3ef73f284f176672c44b448662```**Additional environment details (AWS, VirtualBox, physical, etc.):**Tested directly on GCP VM
"
41464,0,3017,243,0,0,TinoDidriksen,0,"title:Buildkit causes GnuPG error. description:**Description**Buildkit causes an error in GnuPG, but only for 32 bit Debian.**Steps to reproduce the issue:***Dockerfile*````FROM i386/debian:sidRUN apt-get -qy update && apt-get -qfy --no-install-recommends install apt-utils````*Build*````mkdir /tmp/hubbacd /tmp/hubbacat > Dockerfile # ...and fill the aboveDOCKER_BUILDKIT=1 docker build --no-cache -t hubba .````This dies with an error````#5 [2/2] RUN apt-get -qy update && apt-get -qfy --no-install-recommends install apt-utils#5 sha256:7a182bb377f1495082bba8746e32d30ada61253ad14b7772b7708707c6029f1c#5 0.592 Get:1 http://deb.debian.org/debian sid InRelease [146 kB]#5 0.724 Err:1 http://deb.debian.org/debian sid InRelease#5 0.724   At least one invalid signature was encountered.#5 0.728 Reading package lists...#5 0.738 W: GPG error: http://deb.debian.org/debian sid InRelease: At least one invalid signature was encountered.#5 0.738 E: The repository 'http://deb.debian.org/debian sid InRelease' is not signed.#5 ERROR: executor failed running [/bin/sh -c apt-get -qy update && apt-get -qfy --no-install-recommends install apt-utils]: runc did not terminate sucessfully````*Observations*- If I disable buildkit, it works: `DOCKER_BUILDKIT=0 docker build --no-cache -t hubba .`- If I change to `FROM amd64/debian:sid`, it works.- If I change to `FROM i386/ubuntu:focal`, it works.- If I change to `FROM i386/debian:stretch`, it works.- However, `FROM i386/debian:bullseye` does not work.Actually this could be https://github.com/debuerreotype/docker-debian-artifacts/issues/97 but I have kernel `5.4.0-47-generic`, docker `19.03.13`, libseccomp2 `2.4.3-1ubuntu3.20.04.3`, and libc6 `2.31-0ubuntu9`, and rebooted to make sure everything was indeed loaded. And if it was that error, then it would also happen without buildkit.**Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.13 API version:       1.40 Go version:        go1.13.15 Git commit:        4484c46d9d Built:             Wed Sep 16 17:02:52 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.13  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       4484c46d9d  Built:            Wed Sep 16 17:01:20 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.3.7  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 10 Server Version: 19.03.13 Storage Driver: btrfs  Build Version: Btrfs v5.4.1  Library Version: 102 Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 8fba4e9a7d01810a393d5d25a3621dc101981175 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.4.0-47-generic Operating System: Ubuntu 20.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 62.6GiB Name: dev ID: 6ERM:H6NB:ZCHM:SBAU:OBOX:B54X:X4PP:R7JG:F2QQ:2COL:AMNA:TEFI Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```
"
41457,0,2610,247,0,0,AkihiroSuda,0,"title:rootless: `docker run --pid=host` fails with `mounting ""proc"" to rootfs at ""/proc"" caused: operation not permitted`. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->`docker run --pid=host` fails with `mounting ""proc"" to rootfs at ""/proc"" caused: operation not permitted` on rootless**Steps to reproduce the issue:**1. `dockerd-rootless.sh`2. `docker -H unix:///run/user/1001/docker.sock run --rm --pid=host hello-world`**Describe the results you received:**```docker: Error response from daemon: OCI runtime create failed: container_linux.go:370: starting container process caused: process_linux.go:459: container init caused: rootfs_linux.go:60: mounting ""proc"" to rootfs at ""/proc"" caused: operation not permitted: unknown.```**Describe the results you expected:**Shouldn't fail**Output of `docker version`:**```Client: Version:           20.03.0-dev API version:       1.41 Go version:        go1.13.15 Git commit:        e0eba83bd Built:             Wed Sep 16 10:08:53 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          dev  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.15  Git commit:       f99814d749  Built:            Wed Sep 16 10:07:13 2020  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          v1.4.0-81-g373cbc2a  GitCommit:        373cbc2a7f5469b2a833660ba2f474cf4f947d32 runc:  Version:          1.0.0-rc92+dev  GitCommit:        892477ca26638b214dc79150a09ba3565b93137d docker-init:  Version:          0.19.0  GitCommit:        de40ad0```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  buildx: Build with BuildKit (Docker Inc., v0.4.1)Server: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 5 Server Version: dev Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: none Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 373cbc2a7f5469b2a833660ba2f474cf4f947d32 runc version: 892477ca26638b214dc79150a09ba3565b93137d init version: de40ad0 Security Options:  seccomp   Profile: default  rootless Kernel Version: 5.4.0-47-generic Operating System: Ubuntu 20.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 7.748GiB Name: suda-ws01 ID: CWVR:KJQU:3CNT:IJF7:FMME:22Y7:GKFW:AFKJ:IVLQ:JOVW:3KZY:S25M Docker Root Dir: /home/suda/.local/share/docker Debug Mode: false Username: akihirosuda Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: Running in rootless-mode without cgroups. To enable cgroups in rootless-mode, you need to boot the system in cgroup v2 mode.```
"
41338,0,289,200,1,1,thaJeztah,0,"title:Flaky test: TestDockerDaemonSuite/TestDaemonRestartUnlessStopped (again). description:this test was flaky before https://github.com/moby/moby/issues/38720, which was fixed in https://github.com/moby/moby/pull/38737However, recently, it became flaky again. It was noticed as ""flaky"" on https://github.com/moby/moby/pull/41317#issuecomment-669834399 (not sure if it was noticed as flaky before that, so mentioning here, just in case it's a regression).https://ci-next.docker.com/public/blue/organizations/jenkins/moby/detail/PR-41335/1/tests```=== RUN   TestDockerDaemonSuite/TestDaemonRestartUnlessStopped    --- FAIL: TestDockerDaemonSuite/TestDaemonRestartUnlessStopped (6.33s)        docker_cli_daemon_test.go:140: assertion failed: true (bool) != false (shouldRun bool): After daemon restart: container ""exit"" is running```
"
41230,0,13603,247,0,0,AkihiroSuda,0,"title:Rootless mode doesn't start on Fedora 32 with SELinux enabled (but works on CentOS 8.2): ""can't open lock file /run/xtables.lock: Permission denied"". description:# EDIT : workaround : `sudo dnf install -y policycoreutils-python-utils && sudo semanage permissive -a iptables_t`---<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Rootless mode doesn't start on Fedora 32 with SELinux enabled.It works when SELinux is disabled.(**NOTE**: ""SELinux enabled"" in this context just means `getenforce` = `Enforcing`, with the `system_u:object_r:container_runtime_exec_t:s0` context for running `dockerd`. This issue is NOT about running `dockerd-rootless.sh` with `--selinux-enabled`)**Steps to reproduce the issue:**1. Set up Fedora 322. Download `moby-snapshot-fedora-32-x86_64-rpm.tbz` from  https://github.com/AkihiroSuda/moby-snapshot/releases/tag/snapshot-202007173. `tar xjvf moby-snapshot-fedora-32-x86_64-rpm.tbz`4. `sudo dnf install -y *.rpm`5 . `dockerd-rootless.sh`**Describe the results you received:**```[vagrant@localhost ~]$ dockerd-rootless.sh + '[' -w /run/user/1000 ']'+ '[' -w /home/vagrant ']'+ rootlesskit=+ for f in docker-rootlesskit rootlesskit+ which docker-rootlesskit+ for f in docker-rootlesskit rootlesskit+ which rootlesskit+ rootlesskit=rootlesskit+ break+ '[' -z rootlesskit ']'+ : ''+ : ''+ : builtin+ : auto+ : auto+ net=+ mtu=+ '[' -z ']'+ which slirp4netns+ slirp4netns --help+ grep -qw -- --netns-type+ net=slirp4netns+ '[' -z ']'+ mtu=65520+ '[' -z slirp4netns ']'+ '[' -z 65520 ']'+ '[' -z ']'+ _DOCKERD_ROOTLESS_CHILD=1+ export _DOCKERD_ROOTLESS_CHILD+ exec rootlesskit --net=slirp4netns --mtu=65520 --slirp4netns-sandbox=auto --slirp4netns-seccomp=auto --disable-host-loopback --port-driver=builtin --copy-up=/etc --copy-up=/run --propagation=rslave /usr/bin/dockerd-rootless.sh+ '[' -w /run/user/1000 ']'+ '[' -w /home/vagrant ']'+ rootlesskit=+ for f in docker-rootlesskit rootlesskit+ which docker-rootlesskit+ for f in docker-rootlesskit rootlesskit+ which rootlesskit+ rootlesskit=rootlesskit+ break+ '[' -z rootlesskit ']'+ : ''+ : ''+ : builtin+ : auto+ : auto+ net=+ mtu=+ '[' -z ']'+ which slirp4netns+ slirp4netns --help+ grep -qw -- --netns-type+ net=slirp4netns+ '[' -z ']'+ mtu=65520+ '[' -z slirp4netns ']'+ '[' -z 65520 ']'+ '[' -z 1 ']'+ '[' 1 = 1 ']'+ rm -f /run/docker /run/xtables.lock+ exec dockerdINFO[2020-07-18T02:51:29.598987874Z] Starting up                                  WARN[2020-07-18T02:51:29.599044054Z] Running in rootless mode. This mode has feature limitations. INFO[2020-07-18T02:51:29.599049153Z] Running with RootlessKit integration         INFO[2020-07-18T02:51:29.600299588Z] libcontainerd: started new containerd process  pid=9337INFO[2020-07-18T02:51:29.600571807Z] parsed scheme: ""unix""                         module=grpcINFO[2020-07-18T02:51:29.600703491Z] scheme ""unix"" not registered, fallback to default scheme  module=grpcINFO[2020-07-18T02:51:29.600829684Z] ccResolverWrapper: sending update to cc: {[{unix:///run/user/1000/docker/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}  module=grpcINFO[2020-07-18T02:51:29.600998464Z] ClientConn switching balancer to ""pick_first""  module=grpcINFO[2020-07-18T02:51:29.618626058Z] starting containerd                           revision=4feb8c462393ce6834dda9e3464c4fee8ee73232 version=""0.20200717.014906~4feb8c4""INFO[2020-07-18T02:51:29.638162035Z] loading plugin ""io.containerd.content.v1.content""...  type=io.containerd.content.v1INFO[2020-07-18T02:51:29.638216642Z] loading plugin ""io.containerd.snapshotter.v1.aufs""...  type=io.containerd.snapshotter.v1INFO[2020-07-18T02:51:29.639887838Z] skip loading plugin ""io.containerd.snapshotter.v1.aufs""...  error=""aufs is not supported (modprobe aufs failed: exit status 1 \""modprobe: FATAL: Module aufs not found in directory /lib/modules/5.6.6-300.fc32.x86_64\\n\""): skip plugin"" type=io.containerd.snapshotter.v1INFO[2020-07-18T02:51:29.639969108Z] loading plugin ""io.containerd.snapshotter.v1.devmapper""...  type=io.containerd.snapshotter.v1WARN[2020-07-18T02:51:29.640017186Z] failed to load plugin io.containerd.snapshotter.v1.devmapper  error=""devmapper not configured""INFO[2020-07-18T02:51:29.640032709Z] loading plugin ""io.containerd.snapshotter.v1.native""...  type=io.containerd.snapshotter.v1INFO[2020-07-18T02:51:29.640056787Z] loading plugin ""io.containerd.snapshotter.v1.overlayfs""...  type=io.containerd.snapshotter.v1INFO[2020-07-18T02:51:29.640128945Z] loading plugin ""io.containerd.snapshotter.v1.zfs""...  type=io.containerd.snapshotter.v1INFO[2020-07-18T02:51:29.640252839Z] skip loading plugin ""io.containerd.snapshotter.v1.zfs""...  error=""path /home/vagrant/.local/share/docker/containerd/daemon/io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter: skip plugin"" type=io.containerd.snapshotter.v1INFO[2020-07-18T02:51:29.640268957Z] loading plugin ""io.containerd.metadata.v1.bolt""...  type=io.containerd.metadata.v1WARN[2020-07-18T02:51:29.640284172Z] could not use snapshotter devmapper in metadata plugin  error=""devmapper not configured""INFO[2020-07-18T02:51:29.640291902Z] metadata content store policy set             policy=sharedINFO[2020-07-18T02:51:29.640441355Z] loading plugin ""io.containerd.differ.v1.walking""...  type=io.containerd.differ.v1INFO[2020-07-18T02:51:29.640672100Z] loading plugin ""io.containerd.gc.v1.scheduler""...  type=io.containerd.gc.v1INFO[2020-07-18T02:51:29.640856727Z] loading plugin ""io.containerd.service.v1.introspection-service""...  type=io.containerd.service.v1INFO[2020-07-18T02:51:29.640884286Z] loading plugin ""io.containerd.service.v1.containers-service""...  type=io.containerd.service.v1INFO[2020-07-18T02:51:29.640894221Z] loading plugin ""io.containerd.service.v1.content-service""...  type=io.containerd.service.v1INFO[2020-07-18T02:51:29.640906814Z] loading plugin ""io.containerd.service.v1.diff-service""...  type=io.containerd.service.v1INFO[2020-07-18T02:51:29.640916268Z] loading plugin ""io.containerd.service.v1.images-service""...  type=io.containerd.service.v1INFO[2020-07-18T02:51:29.640928865Z] loading plugin ""io.containerd.service.v1.leases-service""...  type=io.containerd.service.v1INFO[2020-07-18T02:51:29.640938611Z] loading plugin ""io.containerd.service.v1.namespaces-service""...  type=io.containerd.service.v1INFO[2020-07-18T02:51:29.640950067Z] loading plugin ""io.containerd.service.v1.snapshots-service""...  type=io.containerd.service.v1INFO[2020-07-18T02:51:29.640972084Z] loading plugin ""io.containerd.runtime.v1.linux""...  type=io.containerd.runtime.v1INFO[2020-07-18T02:51:29.641032736Z] loading plugin ""io.containerd.runtime.v2.task""...  type=io.containerd.runtime.v2INFO[2020-07-18T02:51:29.641104258Z] loading plugin ""io.containerd.monitor.v1.cgroups""...  type=io.containerd.monitor.v1INFO[2020-07-18T02:51:29.641486265Z] loading plugin ""io.containerd.service.v1.tasks-service""...  type=io.containerd.service.v1INFO[2020-07-18T02:51:29.641536295Z] loading plugin ""io.containerd.internal.v1.restart""...  type=io.containerd.internal.v1INFO[2020-07-18T02:51:29.641599367Z] loading plugin ""io.containerd.grpc.v1.containers""...  type=io.containerd.grpc.v1INFO[2020-07-18T02:51:29.641619825Z] loading plugin ""io.containerd.grpc.v1.content""...  type=io.containerd.grpc.v1INFO[2020-07-18T02:51:29.641634736Z] loading plugin ""io.containerd.grpc.v1.diff""...  type=io.containerd.grpc.v1INFO[2020-07-18T02:51:29.641643317Z] loading plugin ""io.containerd.grpc.v1.events""...  type=io.containerd.grpc.v1INFO[2020-07-18T02:51:29.641657485Z] loading plugin ""io.containerd.grpc.v1.healthcheck""...  type=io.containerd.grpc.v1INFO[2020-07-18T02:51:29.641686643Z] loading plugin ""io.containerd.grpc.v1.images""...  type=io.containerd.grpc.v1INFO[2020-07-18T02:51:29.641697750Z] loading plugin ""io.containerd.grpc.v1.leases""...  type=io.containerd.grpc.v1INFO[2020-07-18T02:51:29.641709417Z] loading plugin ""io.containerd.grpc.v1.namespaces""...  type=io.containerd.grpc.v1INFO[2020-07-18T02:51:29.641717946Z] loading plugin ""io.containerd.internal.v1.opt""...  type=io.containerd.internal.v1INFO[2020-07-18T02:51:29.641744782Z] loading plugin ""io.containerd.grpc.v1.snapshots""...  type=io.containerd.grpc.v1INFO[2020-07-18T02:51:29.641755111Z] loading plugin ""io.containerd.grpc.v1.tasks""...  type=io.containerd.grpc.v1INFO[2020-07-18T02:51:29.641764533Z] loading plugin ""io.containerd.grpc.v1.version""...  type=io.containerd.grpc.v1INFO[2020-07-18T02:51:29.641778388Z] loading plugin ""io.containerd.grpc.v1.introspection""...  type=io.containerd.grpc.v1INFO[2020-07-18T02:51:29.642519423Z] serving...                                    address=/run/user/1000/docker/containerd/containerd-debug.sockINFO[2020-07-18T02:51:29.642649591Z] serving...                                    address=/run/user/1000/docker/containerd/containerd.sock.ttrpcINFO[2020-07-18T02:51:29.642724411Z] serving...                                    address=/run/user/1000/docker/containerd/containerd.sockINFO[2020-07-18T02:51:29.642740391Z] containerd successfully booted in 0.024729s  INFO[2020-07-18T02:51:29.648118109Z] parsed scheme: ""unix""                         module=grpcINFO[2020-07-18T02:51:29.648142231Z] scheme ""unix"" not registered, fallback to default scheme  module=grpcINFO[2020-07-18T02:51:29.648157728Z] ccResolverWrapper: sending update to cc: {[{unix:///run/user/1000/docker/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}  module=grpcINFO[2020-07-18T02:51:29.648165737Z] ClientConn switching balancer to ""pick_first""  module=grpcINFO[2020-07-18T02:51:29.649079074Z] parsed scheme: ""unix""                         module=grpcINFO[2020-07-18T02:51:29.649142022Z] scheme ""unix"" not registered, fallback to default scheme  module=grpcINFO[2020-07-18T02:51:29.649156372Z] ccResolverWrapper: sending update to cc: {[{unix:///run/user/1000/docker/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}  module=grpcINFO[2020-07-18T02:51:29.649161973Z] ClientConn switching balancer to ""pick_first""  module=grpcINFO[2020-07-18T02:51:29.649994007Z] [graphdriver] using prior storage driver: fuse-overlayfs WARN[2020-07-18T02:51:29.652815432Z] Unable to find cpu controller                WARN[2020-07-18T02:51:29.653025241Z] Unable to find io controller                 WARN[2020-07-18T02:51:29.653155342Z] Unable to find cpuset controller             INFO[2020-07-18T02:51:29.653690214Z] Loading containers: start.                   WARN[2020-07-18T02:51:29.655152150Z] Running iptables --wait -t nat -L -n failed with message: `Fatal: can't open lock file /run/xtables.lock: Permission denied`, error: exit status 4 INFO[2020-07-18T02:51:29.672504396Z] stopping event stream following graceful shutdown  error=""context canceled"" module=libcontainerd namespace=plugins.mobyINFO[2020-07-18T02:51:29.672563671Z] stopping healthcheck following graceful shutdown  module=libcontainerdINFO[2020-07-18T02:51:29.672613758Z] stopping event stream following graceful shutdown  error=""context canceled"" module=libcontainerd namespace=mobyfailed to start daemon: Error initializing network controller: error obtaining controller instance: failed to create NAT chain DOCKER: iptables failed: iptables -t nat -N DOCKER: Fatal: can't open lock file /run/xtables.lock: Permission denied (exit status 4)[rootlesskit:child ] error: command [/usr/bin/dockerd-rootless.sh] exited: exit status 1[rootlesskit:parent] error: child exited: exit status 1```**Describe the results you expected:**It should work**Additional information you deem important (e.g. issue happens only occasionally):**It works by allowing `iptables_t` to do everything (`sudo semanage permissive -a iptables_t`) or by just disabling SELinux (`sudo setenforce 0`).`dockerd-rootless.sh  --iptables=false` also works. (But not really useful.)**Output of `docker version`:**```console$ DOCKER_HOST=unix:///run/user/1000/docker.sock docker versionClient: Moby Engine Version:           0.0.0-20200716165816-bece8cc41c API version:       1.41 Go version:        go1.13.10 Git commit:        bece8cc41c Built:             Fri Jul 17 07:07:23 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      falseServer: Moby Engine Engine:  Version:          0.0.0-20200716165816-bece8cc41c  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.10  Git commit:       260c26b7be  Built:            Fri Jul 17 08:29:21 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          0.20200717.014906~4feb8c4  GitCommit:        4feb8c462393ce6834dda9e3464c4fee8ee73232 runc:  Version:          1.0.0-rc91+dev  GitCommit:        f9850afa9153b48b654b5c901ae20cabaa4089f8 docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```console$ DOCKER_HOST=unix:///run/user/1000/docker.sock docker infoClient: Context:    default Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 1 Server Version: 0.0.0-20200716165816-bece8cc41c Storage Driver: fuse-overlayfs Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc io.containerd.runc.v2 io.containerd.runtime.v1.linux Default Runtime: runc Init Binary: docker-init containerd version: 4feb8c462393ce6834dda9e3464c4fee8ee73232 runc version: f9850afa9153b48b654b5c901ae20cabaa4089f8 init version: fec3683 Security Options:  seccomp   Profile: default  rootless  cgroupns Kernel Version: 5.6.6-300.fc32.x86_64 Operating System: Fedora 32 (Cloud Edition) OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 1.933GiB Name: localhost.localdomain ID: RKTZ:KLY6:LPTN:TXJ2:3LWP:6YBW:KXQX:XSMG:OO7V:JXR5:TDM7:ZHNN Docker Root Dir: /home/vagrant/.local/share/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No kernel memory limit supportWARNING: No kernel memory TCP limit supportWARNING: No oom kill disable supportWARNING: No cpu cfs quota supportWARNING: No cpu cfs period supportWARNING: No cpu shares supportWARNING: No cpuset supportWARNING: Support for cgroup v2 is experimentalWARNING: No blkio weight supportWARNING: No blkio weight_device supportWARNING: No blkio throttle.read_bps_device supportWARNING: No blkio throttle.write_bps_device supportWARNING: No blkio throttle.read_iops_device supportWARNING: No blkio throttle.write_iops_device support```**Additional environment details (AWS, VirtualBox, physical, etc.):**container-selinux-2.132.0-1.fc32.noarchkernel-core-5.6.6-300.fc32.x86_64
"
41077,0,6229,58,0,0,wangyumu,0,"title:buildkit build cache migration  (v19.03.8 -> master). description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**We upgrade nodes from Docker Version 19.03.08 to master branch for new features of buidkit, but few builds failed with :> failed to prepare ... : open ... : no such file or directoryand we finnally dug out that the reason maybe the buildkit cache of 19.03 is not compliance with the latest version, we can clear the path `/var/lib/docker/buildkit` to avoid the failure, but we'd have better choice when it released in the coming 20.03 version.**Steps to reproduce the issue:**1.  build with 19.03.082.  upgrade version to master branch3.  build with the same base image, it wil be failed**Describe the results you received:**```$ docker infoClient: Debug Mode: falseServer: Containers: 1  Running: 0  Paused: 0  Stopped: 1 Images: 42 Server Version: 19.03.8 Storage Driver: overlay2  Backing Filesystem: <unknown>  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 3.10.0-693.2.2.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 1 Total Memory: 1.796GiB Name: zcm-test ID: ZAGZ:H2UI:BEYE:R7GA:G2K2:ZIPS:VWDQ:MHS3:DVB6:KD4K:4BQB:NA2C Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false$ ls -trltotal 16-rw-r--r-- 1 root root  4 Jun  7 15:22 foo-rw-r--r-- 1 root root  6 Jun  7 15:22 bar-rw-r--r-- 1 root root 26 Jun  7 15:25 Dockerfile_foo-rw-r--r-- 1 root root 26 Jun  7 15:25 Dockerfile_bar$  cat foofoo$  cat barbar$  cat Dockerfile_foo FROM busybox COPY foo /$  cat Dockerfile_barFROM busybox COPY bar /$ export DOCKER_BUILDKIT=1$ docker build -t foo -f Dockerfile_foo .[+] Building 3.9s (7/7) FINISHED                                                                                       => [internal] load build definition from Dockerfile_foo                                                         0.0s => => transferring dockerfile: 67B                                                                              0.0s => [internal] load .dockerignore                                                                                0.1s => => transferring context: 2B                                                                                  0.0s => [internal] load metadata for docker.io/library/busybox:latest                                                3.0s => [internal] load build context                                                                                0.0s => => transferring context: 34B                                                                                 0.0s => [1/2] FROM docker.io/library/busybox@sha256:95cf004f559831017cdf4628aaf1bb30133677be8702a8c5f2994629f637a20  0.8s => => resolve docker.io/library/busybox@sha256:95cf004f559831017cdf4628aaf1bb30133677be8702a8c5f2994629f637a20  0.0s ... => => extracting sha256:76df9210b28cbd4bc127844914d0a23937ed213048dc6289b2a2d4f7d675c75e                        0.1s => [2/2] COPY foo /                                                                                             0.0s => exporting to image                                                                                           0.0s => => exporting layers                                                                                          0.0s => => writing image sha256:87722e065e0892f1a03c26a9a699a035a3cff59c3c92c83d43f082d1d51438a7                     0.0s => => naming to docker.io/library/foo  $ systemctl stop docker$ cp ~/dockerd-dev /usr/bin/dockerd$ systemctl start docker$  docker versionServer: Engine:  Version:          dev  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.8  Git commit:       5ffd677824  Built:            Tue Jun  2 19:57:05 2020  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683$  docker build -t bar -f Dockerfile_bar .[+] Building 3.0s (6/6) FINISHED                                                                                       => [internal] load build definition from Dockerfile_bar                                                         0.0s => => transferring dockerfile: 67B                                                                              0.0s => [internal] load .dockerignore                                                                                0.0s => => transferring context: 2B                                                                                  0.0s => [internal] load metadata for docker.io/library/busybox:latest                                                2.9s => [internal] load build context                                                                                0.0s => => transferring context: 36B                                                                                 0.0s => CACHED [1/2] FROM docker.io/library/busybox@sha256:95cf004f559831017cdf4628aaf1bb30133677be8702a8c5f2994629  0.0s => ERROR [2/2] COPY bar /                                                                                       0.0s------ > [2/2] COPY bar /:------failed to prepare ichmd73l4mnzof7inzjponubi: open /var/lib/docker/overlay2/sha256:1be74353c3d0fd55fb5638a52953e6f1bc441e5b1710921db9ec2aa202725569/committed: no such file or directory$ docker system dfError response from daemon: error getting build cache usage: failed to get usage for sok2lp7lqrmpmh7d09eep3kxi: lstat /var/lib/docker/overlay2/sha256:1be74353c3d0fd55fb5638a52953e6f1bc441e5b1710921db9ec2aa202725569/diff: no such file or directory$ docker system pruneWARNING! This will remove:  - all stopped containers  - all networks not used by at least one container  - all dangling images  - all dangling build cacheAre you sure you want to continue? [y/N] yError response from daemon: failed to prune build cache: failed to remove a48fl9rx4d4ksq0x47v9wedl0: lease ""a48fl9rx4d4ksq0x47v9wedl0"": not found```**Describe the results you expected:**build success
"
41071,0,2930,247,0,0,AkihiroSuda,0,"title:cgroup2: cgroupns is not unshared when DOCKER_API_VERSION < 1.41. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Docker is expected to unshare cgroup namespace by default on cgroup v2 hosts.However, the cgroup namespace is not unshared when a container was created by an older API client.**Steps to reproduce the issue:**Inspect the host cgroup namespace (4026531835):```console$ sudo ls -l /proc/1/ns/cgrouplrwxrwxrwx 1 root root 0 Jun  5 16:36 /proc/1/ns/cgroup -> 'cgroup:[4026531835]'```API 1.41 creates a container with a new namespace (4026533000) as expected:```console$ DOCKER_API_VERSION=1.41 docker run --rm alpine ls -l /proc/1/ns/cgrouplrwxrwxrwx    1 root     root             0 Jun  5 07:36 /proc/1/ns/cgroup -> cgroup:[4026533000]```OTOH API 1.40 creates a container with the host cgroup namespace (4026531835):```console$ DOCKER_API_VERSION=1.40 docker run --rm alpine ls -l /proc/1/ns/cgrouplrwxrwxrwx    1 root     root             0 Jun  5 07:36 /proc/1/ns/cgroup -> cgroup:[4026531835]```**Describe the results you received:**API 1.40 creates a container with the host cgroup namespace (4026531835).**Describe the results you expected:**A new cgroup namespace should be always created by default on cgroup v2 hosts..**Output of `docker version`:**```Client: Version:           20.03.0-dev API version:       1.41 Go version:        go1.13.11 Git commit:        8f14db8df Built:             Fri Jun  5 07:30:25 2020 OS/Arch:           linux/amd64 Context:           default Experimental:      trueServer: Engine:  Version:          dev  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.11  Git commit:       fa38a6cd21  Built:            Fri Jun  5 07:28:36 2020  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          v1.4.0-beta.1-18-g38cb1c1a  GitCommit:        38cb1c1a54e3180edd29933974d715b69334f0f1 runc:  Version:          1.0.0-rc10+dev  GitCommit:        2a0466958d9af23af2ad12bd79d06ed0af4091e2 docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Context:    default Debug Mode: false Plugins:  buildx: Build with BuildKit (Docker Inc., v0.4.1)Server: Containers: 1  Running: 1  Paused: 0  Stopped: 0 Images: 4 Server Version: dev Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: systemd Cgroup Version: 2 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 38cb1c1a54e3180edd29933974d715b69334f0f1 runc version: 2a0466958d9af23af2ad12bd79d06ed0af4091e2 init version: fec3683 Security Options:  apparmor  seccomp   Profile: default  cgroupns Kernel Version: 5.4.0-33-generic Operating System: Ubuntu 20.04 LTS OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 7.748GiB Name: suda-ws01 ID: E2YB:EGZO:6BNW:EPHS:4WFQ:EIDV:ZZ6D:QBZK:6673:CIOR:DLZ6:SI3D Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 32  Goroutines: 56  System Time: 2020-06-05T16:42:51.430978282+09:00  EventsListeners: 0 Username: akihirosuda Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No kernel memory limit supportWARNING: No kernel memory TCP limit supportWARNING: No oom kill disable supportWARNING: Support for cgroup v2 is experimental```
"
41066,0,0,189,0,1,kevpar,0,"title:Slow Windows container start time when using servercore image. description:We are seeing slower launch times of Windows containers using servercore images (or images derived from servercore). Upon investigation, this appears to be due to the C:\Windows\System32\CatRoot directory modification timestamp being different from the value in the container. This causes the Windows catdb to be rebuilt on container launch, which impacts container startup time.We have root caused this to an issue in the Windows layer unpack code in Microsoft/hcsshim. When unpacking a delta layer, the directory timestamps are not correctly reset to their proper values after removing files removed via whiteout. We are working on a fix, and will then need to revendor Microsoft/hcsshim. We are tracking the issue on the hcsshim side via https://github.com/microsoft/hcsshim/issues/830.Note that this bug could have other impact as well, as in general it can cause delta layer directory timestamps to be incorrect. The primary impact we have observed is the slow start time with servercore container images.
"
41044,0,2245,144,0,0,Antiarchitect,0,"title:19.03.9 goroutine stack exceeds 1000000000-byte limit. description:**Description**Complicated multi-stage build with multiple --cache-from and COPY --from <previous-stage>Logs: https://gist.github.com/Antiarchitect/583d7a75f7cbc5f19ebff9b9f38c8d0a**Steps to reproduce the issue:**1. Run the build2. Wait for docker daemon crash**Describe the results you received:**Docker daemon crashes, build log ends with unexpected EOF**Describe the results you expected:**Build passes normally**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.9 API version:       1.40 Go version:        go1.13.10 Git commit:        9d98839 Built:             Fri May 15 00:26:15 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.9  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.10  Git commit:       9d98839  Built:            Fri May 15 00:24:15 2020  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client:                                                                                                                                                                                           [0/1823] Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 1 Server Version: 19.03.9 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 5.6.13-300.fc32.x86_64 Operating System: Fedora 32 (Thirty Two) OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.57GiB Name: localhost.localdomain ID: P5EM:M6NC:P7AY:35ET:CJUH:AITQ:CENP:LJB7:4IOL:ZQMC:YVJG:F7OK Docker Root Dir: /var/lib/docker Debug Mode: false Username: antiarchitect Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Fedora 32, local build by hand
"
41041,0,2543,197,0,0,Haarolean,0,"title:Secondary DNS servers are ignored, 8.8.8.8 is not being added. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->The secondary DNS server passed via `--dns` option is being ignored, `8.8.8.8` is not being added as a backup server, contradictory to official [documentation](https://docs.docker.com/config/containers/container-networking/).**Steps to reproduce the issue:**Could reproduce on clean debian. Ubuntu is affected just partially, if you specify both invalid DNS servers, it won't use `8.8.8.8`.Bridge is important, it works fine without it.In this example `1.255` is not a valid DNS server, meanwhile `1.1` is.```$ docker network create -d bridge test$ docker run --rm --dns 192.168.1.255 --dns 192.168.1.1 --network test --name test -it debian sh# ping google.comping: google.com: Temporary failure in name resolution$ docker run --rm --dns 192.168.1.1 --dns 192.168.1.255 --network test --name test -it debian sh# ping google.comPING google.com (108.177.14.113) 56(84) bytes of data.64 bytes from lt-in-f113.1e100.net (108.177.14.113): icmp_seq=1 ttl=46 time=17.4 ms```**Describe the results you received:**Secondary server is ignored, 8.8.8.8 is not being added.**Describe the results you expected:**Secondary server is not ignored, additional 8.8.8.8 added.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.9 API version:       1.40 Go version:        go1.13.10 Git commit:        9d988398e7 Built:             Fri May 15 00:25:25 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.9  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.10  Git commit:       9d988398e7  Built:            Fri May 15 00:23:57 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 1 Server Version: 19.03.9 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.19.0-9-amd64 Operating System: Debian GNU/Linux 10 (buster) OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 11.64GiB Name: debian-test ID: VVRQ:CXMQ:N7CI:7LQI:M5AT:NYEC:HAUO:BTNK:3KWO:33TS:SS2U:MKMF Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Linux debian-test 4.19.0-9-amd64 #1 SMP Debian 4.19.118-2 (2020-04-29) x86_64 GNU/LinuxCouldn't get any significantly useful information from daemon debug logs, nothing related.
"
41034,0,0,0,0,0,behzadENG,0,"title:docker ps Error. description:hi guys,i have a problem with the version of docker , when i run this command i got error. please help me.thank you in advance.root@root:~/Desktop/Mydocker/visits/frontend# _docker ps_**Error response from daemon: client version 1.40 is too new. Maximum supported API version is 1.39**
"
41010,0,3522,142,0,0,evandam,0,"title:Empty logs are not Syslog RFC 5424 compliant. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->As outlined in https://github.com/treasure-data/omnibus-td-agent/issues/248, Docker logs using syslog RFC 5424 are not compliant and tools like Fluentd are unable to parse them.**Steps to reproduce the issue:**`docker-compose.yml`:```yamlversion: '3'services:  fluentd:    command: [""fluentd"", ""-c"", ""/etc/fluentd.conf""]    image: fluent/fluentd:v1.10.4-1.0    volumes:      - ./fluentd.conf:/etc/fluentd.conf    ports:      - 5140:5140/udp  test:    image: alpine    logging:      driver: syslog      options:        syslog-address: ""udp://127.0.0.1:5140""        tag: test        syslog-format: rfc5424    depends_on:      - fluentd````fluentd.conf`:```<source>  @type syslog  tag syslog.docker.containers  port 5140  protocol_type udp  <parse>    message_format rfc5424  </parse>  @log_level info</source><match syslog.docker.containers.**>  @type stdout</match>``````shdocker-compose up fluentddocker-compose run test echo """"docker-compose run test echo ""test""```**Describe the results you received:**```fluentd_1  | 2020-05-21 21:18:10 +0000 [warn]: #0 failed to parse message data=""<30>1 2020-05-21T21:18:10Z default test 2139 test - ""fluentd_1  | 2020-05-21 21:18:14.000000000 +0000 syslog.docker.containers.daemon.info: {""host"":""default"",""ident"":""test"",""pid"":""2139"",""msgid"":""test"",""extradata"":""-"",""message"":""test""}```**Describe the results you expected:**```fluentd_1  | 2020-05-21 21:18:14.000000000 +0000 syslog.docker.containers.daemon.info: {""host"":""default"",""ident"":""test"",""pid"":""2139"",""msgid"":""test"",""extradata"":""-"",""message"":""""}fluentd_1  | 2020-05-21 21:18:14.000000000 +0000 syslog.docker.containers.daemon.info: {""host"":""default"",""ident"":""test"",""pid"":""2139"",""msgid"":""test"",""extradata"":""-"",""message"":""test""}```**Additional information you deem important (e.g. issue happens only occasionally):**As per https://github.com/treasure-data/omnibus-td-agent/issues/248, it looks like Docker is including extra SP in the log when there is no MSG.**Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.8 API version:       1.40 Go version:        go1.12.17 Git commit:        afacb8b7f0 Built:             Wed Mar 11 01:25:46 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.8  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.17  Git commit:       afacb8b7f0  Built:            Wed Mar 11 01:24:19 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 22  Running: 22  Paused: 0  Stopped: 0 Images: 33 Server Version: 19.03.8 Storage Driver: overlay2  Backing Filesystem: <unknown>  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.15.0-1065-aws Operating System: Ubuntu 18.04.4 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 15.53GiB Name: nomad-compute-i-0fc56cf7700d38a6b.dev-usw2-dev1 ID: DKFC:27MZ:XONM:TQUD:LNZ3:IKR4:SVNI:NITE:GQHV:3EHC:NVCW:UNHE Docker Root Dir: /docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
41003,0,5577,0,0,0,DevInsanity,0,"title:DNS resolution failure in compose stack with docker engine 19.03.9. description:**Description**Updating to docker-ce 19.03.9 breaks DNS resolution inside compose managed stack.**Steps to reproduce the issue:**Test docker-compose.yml file:```version: ""3.7""services:  centos:    image: ""centos:7""    init: true    tty: true    networks:      test:networks:  test:```Start with `docker-compose up -d`Run `docker-compose exec centos ping -c 4 bbc.co.uk`**Describe the results you received:**`ping: bbc.co.uk: Name or service not known`**Describe the results you expected:**```PING bbc.co.uk (151.101.192.81) 56(84) bytes of data.64 bytes from 151.101.192.81 (151.101.192.81): icmp_seq=1 ttl=58 time=10.8 ms64 bytes from 151.101.192.81 (151.101.192.81): icmp_seq=2 ttl=58 time=29.7 ms64 bytes from 151.101.192.81 (151.101.192.81): icmp_seq=3 ttl=58 time=12.2 ms64 bytes from 151.101.192.81 (151.101.192.81): icmp_seq=4 ttl=58 time=11.0 ms--- bbc.co.uk ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 6045msrtt min/avg/max/mdev = 10.887/15.981/29.704/7.941 ms```(The above output was obtained after rolling back docker engine to 19.03.8. No other packages were modified).**Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.9 API version:       1.40 Go version:        go1.13.10 Git commit:        9d988398e7 Built:             Fri May 15 00:25:18 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.9  API version:      1.40 (minimum version 1.12)  Go version:       go1.13.10  Git commit:       9d988398e7  Built:            Fri May 15 00:23:50 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 13  Running: 9  Paused: 0  Stopped: 4 Images: 149 Server Version: 19.03.9 Storage Driver: aufs  Root Dir: /var/lib/docker/aufs  Backing Filesystem: extfs  Dirs: 173  Dirperm1 Supported: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.15.0-101-generic Operating System: Ubuntu 18.04.4 LTS OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 7.667GiB Name: diablos ID: VTPB:4JKM:NQFD:5PGF:J5LJ:CLSR:ZWBL:M4MN:BLJL:3APJ:XGAZ:FMYA Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit supportWARNING: the aufs storage-driver is deprecated, and will be removed in a future release.```**Output of `docker version` in working state (ie, rolled back):**```Client: Docker Engine - Community Version:           19.03.9 API version:       1.40 Go version:        go1.13.10 Git commit:        9d988398e7 Built:             Fri May 15 00:25:18 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.8  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.17  Git commit:       afacb8b7f0  Built:            Wed Mar 11 01:24:19 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info` in working state (ie, rolled back):**```Client: Debug Mode: falseServer: Containers: 13  Running: 9  Paused: 0  Stopped: 4 Images: 149 Server Version: 19.03.8 Storage Driver: aufs  Root Dir: /var/lib/docker/aufs  Backing Filesystem: extfs  Dirs: 173  Dirperm1 Supported: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.15.0-101-generic Operating System: Ubuntu 18.04.4 LTS OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 7.667GiB Name: diablos ID: VTPB:4JKM:NQFD:5PGF:J5LJ:CLSR:ZWBL:M4MN:BLJL:3APJ:XGAZ:FMYA Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit supportWARNING: the aufs storage-driver is deprecated, and will be removed in a future release.```**Additional info**My /etc/resolv.conf file on host contains two nameserver entries. 192.168.5.1 (which is the host machine's own ip address, and is where a dnsmasq server is running) and 127.0.0.1.daemon.json contains `""dns"": [""192.168.5.1"",""8.8.8.8""]`.Running without docker-compose works fine. Ie:```$ docker run centos:7 ping -c 4 bbc.co.ukPING bbc.co.uk (151.101.128.81) 56(84) bytes of data.64 bytes from 151.101.128.81 (151.101.128.81): icmp_seq=1 ttl=58 time=11.1 ms64 bytes from 151.101.128.81 (151.101.128.81): icmp_seq=2 ttl=58 time=13.0 ms64 bytes from 151.101.128.81 (151.101.128.81): icmp_seq=3 ttl=58 time=13.8 ms64 bytes from 151.101.128.81 (151.101.128.81): icmp_seq=4 ttl=58 time=11.8 ms--- bbc.co.uk ping statistics ---4 packets transmitted, 4 received, 0% packet loss, time 3005msrtt min/avg/max/mdev = 11.170/12.489/13.829/1.044 ms```works in both versions.Using docker-compose 1.25.5 in all cases.
"
40999,0,0,279,0,1,cpuguy83,0,"title:Windows log rotation errors with active readers. description:On Windows, when the daemon attempts to rotate logs, if there is an active reader, the rotation fails.This failure was totally unrecoverable until https://github.com/moby/moby/pull/40920However that PR only allows the daemon to recover after an error.The issue occurs when the daemon tries to rename a file that a log reader (e.g. `docker logs` client) has open.This should have, based on the best info I've found, been fixed by using FILE_SHARE_DELETE (https://github.com/moby/moby/pull/39974), however that does not seem to be the case.Furthermore, I've tried to apply this same change to all file opens in that package and still hit the same issue.What this means right now is that if there is a `docker logs` client open and log rotation is enabled, if a file is ready for rotation then log writes will error out until the log client is gone.
"
40993,0,2925,116,0,0,steinybot,0,"title:Multistage docker build fails with unexpected EOF. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**```DOCKER_BUILDKIT=1 docker build \  --build-arg BUILDKIT_INLINE_CACHE=1 \  --cache-from ""community-build-image:latest"" \  --file docker/Dockerfile \  --tag ""community-build-image:latest"" \  .```**Describe the results you received:**```... => CACHED [stage-1 10/11] COPY project project                                                                                                                   0.0s => CACHED [stage-1 11/11] RUN source ""/root/.bashrc"" &&   nvm use &&   sdk env &&   sbt update Test/update npmUpdate Test/npmUpdate                              0.0s------ > importing cache manifest from community-build-image:latest:------unexpected EOF[1]+  Exit 2```**Describe the results you expected:**The build should succeed.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.8 API version:       1.40 Go version:        go1.12.17 Git commit:        afacb8b7f0 Built:             Wed Mar 11 01:22:56 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.8  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.17  Git commit:       afacb8b7f0  Built:            Wed Mar 11 01:30:32 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 0 Server Version: 19.03.8 Storage Driver: overlay2  Backing Filesystem: <unknown>  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 4.19.76-linuxkit Operating System: Amazon Linux 2 (containerized) OSType: linux Architecture: x86_64 CPUs: 6 Total Memory: 1.944GiB Name: 64112fa3bd2a ID: Z2SE:SWKL:JJGS:IRNP:5SPC:UKDY:WQ7Q:Z7U2:Z3GP:PN2F:5YKU:DCPP Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 21  Goroutines: 41  System Time: 2020-05-18T21:45:23.4842333Z  EventsListeners: 0 Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false Product License: Community EngineWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**I first encountered this when trying to build a Docker image in AWS CodeBuild using the image `aws/codebuild/amazonlinux2-x86_64-standard:3.0`.I built the image myself from https://github.com/aws/aws-codebuild-docker-images/tree/master/al2/x86_64/standard/3.0 and I can reproduce it reliably.Here is the daemon log file:[dockerd-logfile.txt](https://github.com/moby/moby/files/4647058/dockerd-logfile.txt)It looks as though the root cause is a stack overflow.
"
40989,0,206,8,0,0,xinfengliu,0,"title:Node LB not deleted after container exits itself (cause IP overlapping). description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Since docker 18.09, there's a node LB per network on the node. When the last container of the network is finished, the node LB is removed. This is correct when the swarm task container is explicitly shutdown. However, when the task container exits itself (either due to task completion or failure), the node LB is NOT removed. This is dangerous and could cause IP overlapping.**Steps to reproduce the issue:**On a simple 1-node swarmkit cluster:1. Create a very small network to make IP overlapping quicky happen`$ docker network create -d overlay --subnet 10.6.6.0/29 net0`2. Create a simple service that will complete by itself. `$ docker service create --network net0 --name bb --restart-max-attempts=1 --restart-delay=10s busybox sleep 5`3. Wait 30s for the service tasks to complete, at this time there's no container running, but node LB is still there.```$ docker network inspect --format '{{range .Containers}}{{printf ""%s\t%s\n"" .Name .IPv4Address}}{{end}}' net0net0-endpoint	10.6.6.4/29```4. Now try creating an IP overlapping```$ docker service scale bb=3$ docker service ps bb --no-trunc```You will see `""starting container failed: Address already in use""`**Describe the results you received:**node LB is not deleted and could cause IP overlapping later.**Describe the results you expected:**node LB should be deleted when the last container on this network on this node exists.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**I can reproduce this issue on any docker 18.09 and 19.03 version.
"
40947,0,0,247,0,0,AkihiroSuda,0,"title:idtools: NewIdentityMapping should not take groupname as an argument. description:https://github.com/moby/moby/blob/298ba5b13150bfffe8414922a951a7a793276d31/pkg/idtools/idtools.go#L117-L120`/etc/subgid` should not be looked up by a groupname: http://man7.org/linux/man-pages/man5/subgid.5.html>     Each line in /etc/subgid contains a user name and a range of subordinate group ids that user is allowed to use. 
"
40944,0,5538,0,0,0,cquon,0,"title:Mounting Docker NFS Volume with selinux enabled not working. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**With Docker daemon running on Centos 7 with selinux enabled, creating an NFS volume and mounting it into a container erroring with ""operation not supported"".**Steps to reproduce the issue:**1. Install Centos 7 with Selinux enabled.```$ cat /etc/os-releaseNAME=""CentOS Linux""VERSION=""7 (Core)""ID=""centos""ID_LIKE=""rhel fedora""VERSION_ID=""7""PRETTY_NAME=""CentOS Linux 7 (Core)""ANSI_COLOR=""0;31""CPE_NAME=""cpe:/o:centos:centos:7""HOME_URL=""https://www.centos.org/""BUG_REPORT_URL=""https://bugs.centos.org/""CENTOS_MANTISBT_PROJECT=""CentOS-7""CENTOS_MANTISBT_PROJECT_VERSION=""7""REDHAT_SUPPORT_PRODUCT=""centos""REDHAT_SUPPORT_PRODUCT_VERSION=""7""``````$ sestatusSELinux status:                 enabledSELinuxfs mount:                /sys/fs/selinuxSELinux root directory:         /etc/selinuxLoaded policy name:             targetedCurrent mode:                   enforcingMode from config file:          enforcingPolicy MLS status:              enabledPolicy deny_unknown status:     allowedMax kernel policy version:      31``````$ cat /etc/docker/daemon.json{""debug"":true, ""selinux-enabled"":true}```2. Create NFS Volume```docker volume create --name nfs-volume --opt type=nfs --opt o=addr=34.221.163.71,rw --opt device=:/home/ubuntu/nfs``````$ docker volume inspect nfs-volume[    {        ""CreatedAt"": ""2020-05-10T04:28:55Z"",        ""Driver"": ""local"",        ""Labels"": {},        ""Mountpoint"": ""/var/lib/docker/volumes/nfs-volume/_data"",        ""Name"": ""nfs-volume"",        ""Options"": {            ""device"": "":/home/ubuntu/nfs"",            ""o"": ""addr=34.221.163.71,rw"",            ""type"": ""nfs""        },        ""Scope"": ""local""    }]```3. Run container with mounting the volume:**Describe the results you received:**```$ docker run -it -v nfs-volume:/tmp busybox  truedocker: Error response from daemon: failed to set file label on /var/lib/docker/volumes/nfs-volume/_data: operation not supported.See 'docker run --help'.``````$ docker run -it -v nfs-volume:/tmp:z busybox  truedocker: Error response from daemon: failed to set file label on /var/lib/docker/volumes/nfs-volume/_data: operation not supported.See 'docker run --help'.``````$ docker run -it -v nfs-volume:/tmp:Z busybox  truedocker: Error response from daemon: failed to set file label on /var/lib/docker/volumes/nfs-volume/_data: operation not supported.See 'docker run --help'.```**Describe the results you expected:**Expected volume to be able to be mounted properly.**Additional information you deem important (e.g. issue happens only occasionally):**NFS Mount working properly:```sudo mount 34.221.163.71:/home/ubuntu/nfs /tmp/nfs```produces no errors.After mounting see it is indeed mounted```$ mount...34.221.163.71:/home/ubuntu/nfs on /tmp/nfs type nfs4 (rw,relatime,vers=4.1,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=172.31.20.209,local_lock=none,addr=34.221.163.71)```**Output of `docker version`:**```$ docker versionClient: Docker Engine - Community Version:           19.03.8 API version:       1.40 Go version:        go1.12.17 Git commit:        afacb8b Built:             Wed Mar 11 01:27:04 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.8  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.17  Git commit:       afacb8b  Built:            Wed Mar 11 01:25:42 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```$ docker infoClient: Debug Mode: falseServer: Containers: 4  Running: 0  Paused: 0  Stopped: 4 Images: 1 Server Version: 19.03.8 Storage Driver: overlay2  Backing Filesystem: <unknown>  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: active  NodeID: w95pd62dr6reenh1euodwkcxw  Is Manager: true  ClusterID: ipscr41ds5l8z6344ehftaf38  Managers: 1  Nodes: 1  Default Address Pool: 10.0.0.0/8  SubnetSize: 24  Data Path Port: 4789  Orchestration:   Task History Retention Limit: 5  Raft:   Snapshot Interval: 10000   Number of Old Snapshots to Retain: 0   Heartbeat Tick: 1   Election Tick: 10  Dispatcher:   Heartbeat Period: 5 seconds  CA Configuration:   Expiry Duration: 3 months   Force Rotate: 0  Autolock Managers: false  Root Rotation In Progress: false  Node Address: 172.31.20.209  Manager Addresses:   172.31.20.209:2377 Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  seccomp   Profile: default  selinux Kernel Version: 3.10.0-957.1.3.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.145GiB Name: cquon-test-centos-0 ID: GIEE:C7R2:ACGO:UGQ4:27KW:6R44:UW6P:JP5P:PBTE:2VWA:E4Z2:VYEM Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 40  Goroutines: 157  System Time: 2020-05-10T04:58:28.212784955Z  EventsListeners: 0 Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: API is accessible on http://0.0.0.0:2376 without encryption.         Access to the remote API is equivalent to root access on the host. Refer         to the 'Docker daemon attack surface' section in the documentation for         more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface```**Additional environment details (AWS, VirtualBox, physical, etc.):**Running AWS EC2 instance with centos7 installed.
"
40939,0,777,133,0,0,flavienbwk,0,"title:Failed to registrer layer when docker pull with Docker Rootless. description:Hi,I am using Docker Rootless mode and encounter a problem while pulling an image.A `docker pull osixia/phpldapadmin:stable` or any of its version (`:latest`, `:0.9.0` etc...) leads to this error message :```latest: Pulling from osixia/phpldapadmin1ab2bdfe9778: Already exists0abcaf321aa9: Already exists6d688c3d4e02: Already exists454331b99b9a: Pull complete5cada7c8cb4e: Pull completeb0f406024ee7: Pull completeb04a43f9c3ac: Pull complete92a3a5c2b5a5: Extracting [==================================================>]  34.17kB/34.17kBe4955dcfbe65: Download completefailed to register layer: Error processing tar file(exit status 1): failed to mknodChar0UserNS(""/container/service/:apache2/install.sh""): failed to mount overlay (lowerdir=/container/service/:apache2/mc0o793276857/l,upperdir=/container/service/:apache2/mc0o793276857/u,workdir=/container/service/:apache2/mc0o793276857/w) on /container/service/:apache2/mc0o793276857/m: no such file or directory```Docker version : `19.03.8, build afacb8b7f0`  OS : Ubuntu 18.04 (bionic)It works perfectly fine on a classic non-rootless Docker install.   I did not experience the problem with any other image yet.- Would you have an idea why it fails ?Thank you,
"
40932,0,2225,247,0,1,AkihiroSuda,0,"title:TestDockerPluginSuite/TestPluginInstallArgs  nil panic on s390x and ppc64le. description:https://ci-next.docker.com/public/blue/organizations/jenkins/moby/detail/master/487/pipeline/213```=== FAIL: s390x.integration-cli TestDockerPluginSuite/TestPluginInstallArgs (15.01s)    --- FAIL: TestDockerPluginSuite/TestPluginInstallArgs (15.01s)        suite.go:65: test suite panicked: runtime error: invalid memory address or nil pointer dereference            goroutine 28144 [running]:            runtime/debug.Stack(0xc0011c9618, 0x2649160, 0x3b1fd20)            	/usr/local/go/src/runtime/debug/stack.go:24 +0x98            github.com/docker/docker/internal/test/suite.failOnPanic(0xc000b8de00)            	/go/src/github.com/docker/docker/internal/test/suite/suite.go:65 +0x5a            panic(0x2649160, 0x3b1fd20)            	/usr/local/go/src/runtime/panic.go:679 +0x1d4            github.com/docker/docker/integration-cli.(*DockerPluginSuite).TestPluginInstallArgs.func1(0xc000bfd800)            	/go/src/github.com/docker/docker/integration-cli/docker_cli_plugins_test.go:200 +0xba            github.com/docker/docker/testutil/fixtures/plugin.CreateInRegistry(0x2d136a0, 0xc000bfd7a0, 0xc00098ad50, 0x2f, 0x0, 0xc0011c9a90, 0x1, 0x1, 0x0, 0x0)            	/go/src/github.com/docker/docker/testutil/fixtures/plugin/plugin.go:95 +0x1a2            github.com/docker/docker/integration-cli.(*DockerPluginSuite).TestPluginInstallArgs(0xc0007210b0, 0xc000b8de00)            	/go/src/github.com/docker/docker/integration-cli/docker_cli_plugins_test.go:199 +0x122            reflect.Value.call(0xc000357680, 0xc0000cb228, 0x13, 0x28ccff2, 0x4, 0xc000cddf40, 0x2, 0x2, 0x1020652, 0x1633546, ...)            	/usr/local/go/src/reflect/value.go:460 +0x650            reflect.Value.Call(0xc000357680, 0xc0000cb228, 0x13, 0xc000061740, 0x2, 0x2, 0x2f4d968, 0xf, 0x0)            	/usr/local/go/src/reflect/value.go:321 +0x98            github.com/docker/docker/internal/test/suite.Run.func2(0xc000b8de00)            	/go/src/github.com/docker/docker/internal/test/suite/suite.go:57 +0x28c            testing.tRunner(0xc000b8de00, 0xc0001568c0)            	/usr/local/go/src/testing/testing.go:909 +0xd6            created by testing.(*T).Run            	/usr/local/go/src/testing/testing.go:960 +0x36c=== FAIL: s390x.integration-cli TestDockerPluginSuite (177.75s)```Observed only on s390x and ppc64le
"
40926,0,2191,1,0,0,NikolausDemmel,0,"title:rootless docker fails to start when using numeric uids in /etc/subuid. description:**Description**I just tried installing rootless docker, and it seems to fail if `/etc/subuid` doesn't use usernames but instead uids. With numeric uids (as in `20592:3900000:100000`) I get this error:```[rootlesskit:parent] error: failed to setup UID/GID map: failed to compute uid/gid map: No subuid ranges found for user ""demmeln""```After replacing it with `demmeln:3900000:100000` in `/etc/subuid` (and `subgid`) I can start the rootless daemon just fine. According to the man page of `/etc/subuid` numeric uids should be supported and also podman works fine with them.**Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.8 API version:       1.40 Go version:        go1.12.17 Git commit:        afacb8b7f0 Built:             Wed Mar 11 01:22:56 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.8  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.17  Git commit:       afacb8b7f0  Built:            Wed Mar 11 01:30:32 2020  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          v1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 2  Running: 0  Paused: 0  Stopped: 2 Images: 1 Server Version: 19.03.8 Storage Driver: vfs Logging Driver: json-file Cgroup Driver: none Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  seccomp   Profile: default  rootless Kernel Version: 5.3.0-51-generic Operating System: Ubuntu 18.04.4 LTS OSType: linux Architecture: x86_64 CPUs: 12 Total Memory: 62.44GiB Name: atcremers83 ID: XMTU:VR3S:4QUF:3ZMX:LAEK:N6AU:K47O:4G7T:MAUL:EWL3:SI5M:MUVH Docker Root Dir: /usr/wiss/demmeln/bionic/.local/share/docker Debug Mode: false Username: nikolausdemmel Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false Product License: Community EngineWARNING: No swap limit support```
"
40912,0,41,41,0,1,cristianrz,0,"title:curl: option --progress: is ambiguous. description:**Description**`download-frozen-image-v2.sh` does not download because of a wrong option passed to curl**Steps to reproduce the issue:**1. run `download-frozen-image-v2.sh dummy ubuntu:latest`**Describe the results you received:**```curl: option --progress: is ambiguous```**Describe the results you expected:**The image to be downloaded successfully**Additional information you deem important (e.g. issue happens only occasionally):**Is `--progress` the correct option? On all the implementations I have checked it is called `--progress-bar`. If both exist, the script should check for which one is installed, otherwise correct the option to `--progress-bar`. Never worked with pull requests but happy to try and fix it if someone answers the question above :)**Output of `docker version`:**N/A**Output of `docker info`:**N/A**Additional environment details (AWS, VirtualBox, physical, etc.):**Using gnu curl 7.68.0 
"
40858,0,16005,248,0,0,tao12345666333,0,"title:buildkit: can not convert active xx to layer. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->After I executed `docker system prune -a --volumes`, I encountered an error when using buildkit build image**Steps to reproduce the issue:**1. `docker system prune -a --volumes`2.  build docker image using buildkit.```(MoeLove) 闂? test-build docker build --no-cache -t local/test .[+] Building 14.1s (5/5) FINISHED                                                                                                        => [internal] load build definition from Dockerfile                                                                               0.0s => => transferring dockerfile: 113B                                                                                               0.0s => [internal] load .dockerignore                                                                                                  0.0s => => transferring context: 2B                                                                                                    0.0s => [internal] load metadata for docker.io/library/alpine:latest                                                                   7.1s => [1/1] FROM docker.io/library/alpine@sha256:9a839e63dad54c3a6d1834e29692c8492d93f90c59c978c1ed79109ea4fb9a54                    6.9s => => resolve docker.io/library/alpine@sha256:9a839e63dad54c3a6d1834e29692c8492d93f90c59c978c1ed79109ea4fb9a54                    0.0s => => extracting sha256:cbdbe7a5bc2a134ca8ec91be58565ec07d037386d1f1d8385412d224deafca08                                          0.1s => => sha256:9a839e63dad54c3a6d1834e29692c8492d93f90c59c978c1ed79109ea4fb9a54 1.64kB / 1.64kB                                     0.0s => => sha256:39eda93d15866957feaee28f8fc5adb545276a64147445c64992ef69804dbf01 528B / 528B                                         0.0s => => sha256:f70734b6a266dcb5f44c383274821207885b549b75c8e119404917a61335981a 1.51kB / 1.51kB                                     0.0s => => sha256:cbdbe7a5bc2a134ca8ec91be58565ec07d037386d1f1d8385412d224deafca08 2.81MB / 2.81MB                                     0.0s => ERROR exporting to image                                                                                                       0.0s => => exporting layers                                                                                                            0.0s------ > exporting to image:------can not convert active uyehw145omml8y9yajo11nm2r to layer(MoeLove) 闂? test-build cat Dockerfile FROM alpine```**Describe the results you received:**```can not convert active uyehw145omml8y9yajo11nm2r to layer```**Describe the results you expected:**build success.**Additional information you deem important (e.g. issue happens only occasionally):**before I executed `docker system prune -a --voluems` , the `docker system df` output:```(MoeLove) 闂? infra git:(master) 闂?docker system df                                                                              TYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLE                                             Images              126                 2                   29.68GB             29.66GB (99%)                                           Containers          2                   0                   638.6MB             638.6MB (100%)                                          Local Volumes       11                  10                  2.454GB             32.76MB (1%)                                            Build Cache         174                 0                   570.3MB             570.3MB ```The docker daemon's log here:```-- Logs begin at Wed 2020-01-08 07:20:55 CST, end at Sun 2020-04-26 01:02:36 CST. --4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.694947430+08:00"" level=debug msg=""Calling HEAD /_ping""4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.696260414+08:00"" level=debug msg=""Calling POST /v1.41/build?buildargs=%7B%7D&buildid=efd6c49f711f0d39d1db6e232c9d8714746618de97739fc4cc651d9ce41ae695&cachefrom=%5B%5D&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=&labels=%7B%7D&memory=0&memswap=0&networkmode=default&nocache=1&remote=client-session&rm=1&session=mvorl2qfiurej9npbplj9zvpk&shmsize=0&t=local%2Ftest&target=&ulimits=null&version=2""4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.696311169+08:00"" level=debug msg=""Calling POST /session""4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.696434584+08:00"" level=info msg=""parsed scheme: \""\"""" module=grpc4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.696485478+08:00"" level=info msg=""scheme \""\"" not registered, fallback to default scheme"" module=grpc4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.696509478+08:00"" level=info msg=""ccResolverWrapper: sending update to cc: {[{  <nil> 0 <nil>}] <nil> <nil>}"" module=grpc4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.696524005+08:00"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpc4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.715814904+08:00"" level=debug msg=""reusing ref for local: uipo0ngzebmltllre2fuca6hk""4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.717552971+08:00"" level=debug msg=""reusing ref for local: ke4oxtlz4afipbbdc8x2q89go""4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.718569398+08:00"" level=debug msg=""diffcopy took: 2.55404ms""4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.718838756+08:00"" level=debug msg=""diffcopy took: 1.158315ms""4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.722039301+08:00"" level=debug msg=""saved uipo0ngzebmltllre2fuca6hk as local.sharedKey:dockerfile:dockerfile:d9182bf2bf9d695526bcfa3cd58d50347c1df6db22513d1ae9179f082fb3d481""4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.725234432+08:00"" level=debug msg=""saved ke4oxtlz4afipbbdc8x2q89go as local.sharedKey:context:context-.dockerignore:d9182bf2bf9d695526bcfa3cd58d50347c1df6db22513d1ae9179f082fb3d481""4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.762946297+08:00"" level=debug msg=resolving host=registry-1.docker.io4闂?26 01:01:23 bogon dockerd[5438]: time=""2020-04-26T01:01:23.762990663+08:00"" level=debug msg=""do request"" host=registry-1.docker.io request.header.accept=""application/vnd.docker.distribution.manifest.v2+json, application/vnd.docker.distribution.manifest.list.v2+json, application/vnd.oci.image.manifest.v1+json, application/vnd.oci.image.index.v1+json, */*"" request.header.user-agent=containerd/1.3.0+unknown request.method=HEAD url=""https://registry-1.docker.io/v2/library/alpine/manifests/latest""4闂?26 01:01:25 bogon dockerd[5438]: time=""2020-04-26T01:01:25.029225199+08:00"" level=debug msg=""fetch response received"" host=registry-1.docker.io response.header.content-length=157 response.header.content-type=application/json response.header.date=""Sat, 25 Apr 2020 17:01:24 GMT"" response.header.docker-distribution-api-version=registry/2.0 response.header.strict-transport-security=""max-age=31536000"" response.header.www-authenticate=""Bearer realm=\""https://auth.docker.io/token\"",service=\""registry.docker.io\"",scope=\""repository:library/alpine:pull\"""" response.status=""401 Unauthorized"" url=""https://registry-1.docker.io/v2/library/alpine/manifests/latest""4闂?26 01:01:25 bogon dockerd[5438]: time=""2020-04-26T01:01:25.029504751+08:00"" level=debug msg=Unauthorized header=""Bearer realm=\""https://auth.docker.io/token\"",service=\""registry.docker.io\"",scope=\""repository:library/alpine:pull\"""" host=registry-1.docker.io4闂?26 01:01:25 bogon dockerd[5438]: time=""2020-04-26T01:01:25.240188818+08:00"" level=debug msg=""do request"" host=registry-1.docker.io request.header.accept=""application/vnd.docker.distribution.manifest.v2+json, application/vnd.docker.distribution.manifest.list.v2+json, application/vnd.oci.image.manifest.v1+json, application/vnd.oci.image.index.v1+json, */*"" request.header.user-agent=containerd/1.3.0+unknown request.method=HEAD url=""https://registry-1.docker.io/v2/library/alpine/manifests/latest""4闂?26 01:01:31 bogon dockerd[5438]: time=""2020-04-26T01:01:31.173306868+08:00"" level=debug msg=""fetch response received"" host=registry-1.docker.io response.header.content-length=1638 response.header.content-type=application/vnd.docker.distribution.manifest.list.v2+json response.header.date=""Sat, 25 Apr 2020 17:01:31 GMT"" response.header.docker-content-digest=""sha256:9a839e63dad54c3a6d1834e29692c8492d93f90c59c978c1ed79109ea4fb9a54"" response.header.docker-distribution-api-version=registry/2.0 response.header.etag=""\""sha256:9a839e63dad54c3a6d1834e29692c8492d93f90c59c978c1ed79109ea4fb9a54\"""" response.header.strict-transport-security=""max-age=31536000"" response.status=""200 OK"" url=""https://registry-1.docker.io/v2/library/alpine/manifests/latest""4闂?26 01:01:31 bogon dockerd[5438]: time=""2020-04-26T01:01:31.173718342+08:00"" level=debug msg=resolved desc.digest=""sha256:9a839e63dad54c3a6d1834e29692c8492d93f90c59c978c1ed79109ea4fb9a54"" host=registry-1.docker.io4闂?26 01:01:31 bogon dockerd[5438]: time=""2020-04-26T01:01:31.174123087+08:00"" level=debug msg=fetch digest=""sha256:9a839e63dad54c3a6d1834e29692c8492d93f90c59c978c1ed79109ea4fb9a54"" mediatype=application/vnd.docker.distribution.manifest.list.v2+json size=16384闂?26 01:01:31 bogon dockerd[5438]: time=""2020-04-26T01:01:31.181218688+08:00"" level=debug msg=fetch digest=""sha256:39eda93d15866957feaee28f8fc5adb545276a64147445c64992ef69804dbf01"" mediatype=application/vnd.docker.distribution.manifest.v2+json size=5284闂?26 01:01:31 bogon dockerd[5438]: time=""2020-04-26T01:01:31.184170880+08:00"" level=debug msg=fetch digest=""sha256:f70734b6a266dcb5f44c383274821207885b549b75c8e119404917a61335981a"" mediatype=application/vnd.docker.container.image.v1+json size=15074闂?26 01:01:31 bogon dockerd[5438]: time=""2020-04-26T01:01:31.190957583+08:00"" level=debug msg=""load cache for [1/1] FROM docker.io/library/alpine@sha256:9a839e63dad54c3a6d1834e29692c8492d93f90c59c978c1ed79109ea4fb9a54 with moby::uyehw145omml8y9yajo11nm2r""4闂?26 01:01:31 bogon dockerd[5438]: time=""2020-04-26T01:01:31.193516005+08:00"" level=warning msg=""grpc: addrConn.createTransport failed to connect to {  <nil> 0 <nil>}. Err :connection error: desc = \""transport: Error while dialing only one connection allowed\"". Reconnecting..."" module=grpc```**Output of `docker version`:**```(MoeLove) 闂? ~ docker versionClient: Docker Engine - Community Version:           0.0.0-20200421170140-7f2f916fba API version:       1.41 Go version:        go1.13.10 Git commit:        7f2f916fba Built:             Tue Apr 21 20:13:01 2020 OS/Arch:           linux/amd64 Experimental:      trueServer: Docker Engine - Community Engine:  Version:          0.0.0-20200421170140-7f2f916fba  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.10  Git commit:       7f2f916fba  Built:            Tue Apr 21 20:10:23 2020  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          v1.3.3  GitCommit:        d76c121f76a5fc8a462dc64594aea72fe18e1178 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```(MoeLove) 闂? ~ docker info                                          Client:                                                              Debug Mode: false                                                                                                                       Plugins:                                                                                                                                 app: Docker App (Docker Inc., v0.9.0-zeta1-96-g44932b629b)                                                                                             buildx: Build with BuildKit (Docker Inc., v0.3.1-42-g7b297eb-tp-docker)                                                                                                   year: A docker plugin, Happy New Year! (Jintao Zhang, v1.0.0)                                                                                                                                                                                                                        Server:                                                                     Containers: 0                                                                                                                                                                                                                       Running: 0                                                          Paused: 0                                                                                                                                                                                                                          Stopped: 0                                                                                                                             Images: 0                                                                                                                                                                                                                          Server Version: 0.0.0-20200421170140-7f2f916fba                            Storage Driver: overlay2                                                                          Backing Filesystem: extfs                                                                                                                                                                                                                                                       Supports d_type: true                                               Native Overlay Diff: true                                                                                       Logging Driver: json-file                                                                                        Cgroup Driver: systemd                                  Plugins:                                                 Volume: local                                                       Network: bridge host ipvlan macvlan null overlay                    Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive                                                     Runtimes: runc                                                      Default Runtime: runc                                               Init Binary: docker-init                                            containerd version: d76c121f76a5fc8a462dc64594aea72fe18e1178 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683                                               Security Options:                                                    seccomp                                                              Profile: default                                                  Kernel Version: 5.5.16-100.fc30.x86_64 Operating System: Fedora 30 (Workstation Edition) OSType: linux                                                       Architecture: x86_64                                                CPUs: 4                                                             Total Memory: 15.53GiB                                              Name: bogon                                                         ID: XXXXXXXX Docker Root Dir: /var/lib/docker                                    Debug Mode: true                                                     File Descriptors: 24                                                Goroutines: 38                                                      System Time: 2020-04-26T01:05:45.758762687+08:00  EventsListeners: 0                                                 HTTP Proxy: socks5://127.0.0.1:1080 HTTPS Proxy: socks5://127.0.0.1:1080 No Proxy: localhost,127.0.0.1 Registry: https://index.docker.io/v1/ Labels:                                                             Experimental: true                                                  Insecure Registries:                                                 127.0.0.1:5000                                                      127.0.0.0/8                                                        Live Restore Enabled: true```**Additional environment details (AWS, VirtualBox, physical, etc.):**physical
"
40829,0,2046,25,0,0,zhy1,0,"title:SIGSEGV in github.com/fluent/fluent-logger-golang/fluent.(*Fluent).write. description:**Description**docker crash**Steps to reproduce the issue:**1. i  use fluentd**Describe the results you received:**Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: panic: runtime error: invalid memory address or nil pointer dereferenceApr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x50 pc=0x563fc57ebad9]Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: goroutine 561046 [running]:Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: github.com/docker/docker/vendor/github.com/fluent/fluent-logger-golang/fluent.(*Fluent).write(0xc000824210, 0xc00153f350, 0xc00153f2f0, 0xc00153f320)Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/fluent/fluent-logger-golang/fluent/fluent.go:384 +0x119Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: github.com/docker/docker/vendor/github.com/fluent/fluent-logger-golang/fluent.(*Fluent).postRawData(0xc000824210, 0xc00153f350, 0x44, 0x18f43bbd)Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/fluent/fluent-logger-golang/fluent/fluent.go:223 +0x6eApr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: github.com/docker/docker/vendor/github.com/fluent/fluent-logger-golang/fluent.(*Fluent).EncodeAndPostData(0xc000824210, 0xc0005e4b90, 0x44, 0x18f43bbd, 0xed62a3596, 0x0, 0x563fc6792da0, 0xc00153f2f0, 0x98, 0x8)Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/fluent/fluent-logger-golang/fluent/fluent.go:210 +0x1beApr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: github.com/docker/docker/vendor/github.com/fluent/fluent-logger-golang/fluent.(*Fluent).PostWithTime(0xc000824210, 0xc0005e4b90, 0x44, 0x18f43bbd, 0xed62a3596, 0x0, 0x563fc67982c0, 0xc00153f2c0, 0x1a13, 0x563fc41b1833)Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/fluent/fluent-logger-golang/fluent/fluent.go:201 +0x7bbApr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: github.com/docker/docker/daemon/logger/fluentd.(*fluentd).Log(0xc001717ec0, 0xc0012ac230, 0x563fc7fa82a0, 0x400a)Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/logger/fluentd/fluentd.go:177 +0x3cbApr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: github.com/docker/docker/daemon/logger.(*Copier).copySrc(0xc001576040, 0x563fc5ac17b5, 0x6, 0x7fd920d88d70, 0xc001717f00)Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/logger/copier.go:123 +0x369Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: created by github.com/docker/docker/daemon/logger.(*Copier).RunApr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ dockerd[2120]: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/logger/copier.go:48 +0x111Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ systemd[1]: docker.service: main process exited, code=exited, status=2/INVALIDARGUMENTApr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ systemd[1]: Unit docker.service entered failed state.Apr 16 19:16:38 iZuf6jb9uv1lmingd0agruZ systemd[1]: docker.service failed.Apr 16 19:16:40 iZuf6jb9uv1lmingd0agruZ systemd[1]: docker.service holdoff time over, scheduling restart.Apr 16 19:16:40 iZuf6jb9uv1lmingd0agruZ systemd[1]: Stopped Docker Application Container Engine.Apr 16 19:16:40 iZuf6jb9uv1lmingd0agruZ systemd[1]: Closed Docker Socket for the API.Apr 16 19:16:40 iZuf6jb9uv1lmingd0agruZ systemd[1]: Stopping Docker Socket for the API.Apr 16 19:16:40 iZuf6jb9uv1lmingd0agruZ systemd[1]: Starting Docker Socket for the API.Apr 16 19:16:40 iZuf6jb9uv1lmingd0agruZ systemd[1]: Listening on Docker Socket for the API.Apr 16 19:16:40 iZuf6jb9uv1lmingd0agruZ systemd[1]: Starting Docker Application Container Engine...**Describe the results you expected:****Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.1 API version:       1.40 Go version:        go1.12.5 Git commit:        74b1e89 Built:             Thu Jul 25 21:21:07 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.1  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.5  Git commit:       74b1e89  Built:            Thu Jul 25 21:19:36 2019  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.6  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb runc:  Version:          1.0.0-rc8  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**``` docker infoClient: Debug Mode: falseServer: Containers: 17  Running: 15  Paused: 0  Stopped: 2 Images: 59 Server Version: 19.03.1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 3.10.0-957.21.3.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.638GiB Name: iZuf6jb9uv1lmingd0agruZ ID: TUDV:GL7K:XGNU:AN7J:Z3X7:KRGN:D2K3:JP5Y:FGVZ:ZOWA:GQR3:7L3G Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**ALIYUN
"
40789,0,0,279,0,0,cpuguy83,0,"title:containers not killed properly on startup. description:The normal expected workflow for daemon shutdown (w/o live-restore) is that on shutdown docker kills all running processes using the normal flow of `docker stop`... so attempt to send a graceful shutdown, wait for exit or `SIGKILL` after 10s.If dockerd crashes or is `SIGKILL`'d, docker checks containerd for what is still running and shuts the containers down.The problem is the 2nd case. Docker only sends the configured stop signal and does not follow up with a `SIGKILL`.Code called on startup is:https://github.com/moby/moby/blob/aa6a9891b09cce3d9004121294301a30d45d998d/daemon/daemon.go#L343which callshttps://github.com/moby/moby/blob/aa6a9891b09cce3d9004121294301a30d45d998d/daemon/kill.go#L177-L179So we only send the configured stop signal to the process, we don't do anything after that, not even wait for an exit.If the process does not behave appropriately it stays running.This affects 19.03 as well as master.
"
40752,0,2848,0,0,0,tsh56,0,"title:concurrent map writes panic when building multiple images in parallel. description:---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------I'm observing the docker daemon crash when I build multiple images in parallel. This started when we enabled Buildkit, so this is likely related. I first observed this on a system with 40 logical cores, but am able to reproduce this in under a minute on a 6 core vm.<!--Briefly describe the problem you are having in a few paragraphs.-->The following script is the most concise repro I've found. It'll exit when the daemon panics.```#!/bin/bashset -eDOCKER_BUILDKIT=1; export DOCKER_BUILDKITmkdir -p /tmp/test_imageecho ""FROM ubuntu:16.04"" > /tmp/test_image/Dockerfileecho ""RUN echo 1 > out"" >> /tmp/test_image/Dockerfiledocker build --build-arg BUILDKIT_INLINE_CACHE=1 -t foo:bar /tmp/test_imagewhile true; do    for i in $(seq 12)    do        docker build -t\        foo:derived_${i}\        --build-arg BUILDKIT_INLINE_CACHE=1\        --cache-from=foo:bar \        /tmp/test_image &    done    for job in `jobs -p`    do        wait $job    donedone```**Describe the results you received:**The daemon exits with an error message `fatal error: concurrent map writes`**Describe the results you expected:**I expect the daemon to not have to restart.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```docker version                                                                                   1 闂傚倸鍊烽悞锕傚礈濮樿泛纾婚柛鈩冭泲閸モ晝鐭堥柛宥囧腐nt: Docker Engine - Community Version:           19.03.8 API version:       1.40 Go version:        go1.12.17 Git commit:        afacb8b7f0 Built:             Wed Mar 11 01:25:55 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.8  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.17  Git commit:       afacb8b7f0  Built:            Wed Mar 11 01:24:26 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```docker infoClient: Debug Mode: falseServer: Containers: 21  Running: 0  Paused: 0  Stopped: 21 Images: 7 Server Version: 19.03.8 Storage Driver: zfs  Zpool: rpool  Zpool Health: ONLINE  Parent Dataset: rpool/ROOT/ubuntu_2bts8c/var/lib  Space Used By Parent: 4867842048  Space Available: 43242509440  Parent Quota: no  Compression: lz4 Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.3.0-40-generic Operating System: Ubuntu 19.10 OSType: linux Architecture: x86_64 CPUs: 6 Total Memory: 15.61GiB Name: tsh-buster ID: BEGE:NR2X:X2ZT:WZMW:XQSQ:3MPI:NS5M:HPPY:V6GE:ROLS:UF6T:TCDG Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Ubuntu 19.10 vm running on a 2018 Macbook pro with 6 cores.Originally this was seen on a CI system running with the 19-dind docker image on a 40 core server.The following are logs of the backtraces that are associated with the panic.[docker-logs.txt](https://github.com/moby/moby/files/4397484/docker-logs.txt)
"
40727,1,9425,28,0,0,RuRo,0,"title:Docker stats memory doesn't include tmpfs usage. description:**Description**The `MEMORY USAGE` and `MEM %` columns in `docker stats` don't include RAM used by `tmpfs` filesystems.**Steps to reproduce the issue:**1) Run    ```sh    docker run --shm-size=256MB --memory=256MB -it alpine sh -c ""            dd if=/dev/urandom of=/dev/shm/file bs=32M            ls -lh /dev/shm            read    ""    ```    and/or    ```sh    docker run --shm-size=256MB --memory=256MB -it alpine sh -c ""            dd if=/dev/urandom of=/tmp/file bs=32M            ls -lh /tmp            read    ""    ```2) Observe that the `dd` process is killed after exhausting the `memory`/`shm-size` limits and the RAM resident filesystem now contains a `200M`ish file:    ```    Killed    total 217M       -rw-r--r--    1 root     root      216.6M Mar 20 05:23 file    ```3) Run `docker stats`**Describe the results you received:**```CONTAINER ID        NAME                   CPU %               MEM USAGE / LIMIT   MEM %               NET I/O             BLOCK I/O           PIDS8c601a0d8404        keen_elbakyan          0.00%               7.316MiB / 256MiB   2.86%               8.49kB / 0B         0B / 0B             17066646c1a76        infallible_engelbart   0.00%               1.613MiB / 256MiB   0.63%               5.06kB / 0B         0B / 0B             1```**Describe the results you expected:**The `MEM USAGE` and `MEM %` columns in the above table to be around `200M`ish and `78%`ish.**Output of `docker version`:**```Docker version 19.03.7-ce, build 7141c199a2```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 21  Running: 2  Paused: 0  Stopped: 19 Images: 5 Server Version: 19.03.7-ce Storage Driver: overlay2  Backing Filesystem: <unknown>  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: nvidia runc Default Runtime: runc Init Binary: docker-init containerd version: d76c121f76a5fc8a462dc64594aea72fe18e1178.m runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 5.4.24-1-MANJARO Operating System: Manjaro Linux OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.56GiB Name: ruro-laptop ID: XHD5:R5HL:34CY:3UJ2:4QD6:IP3P:FIOD:NUZX:ZBEE:XND6:OJ5P:J6RM Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```</details>**Additional details:**Output of```shcurl --unix-socket /var/run/docker.sock ""http://localhost/containers/<container-id>/stats?stream=0"" | python -m json.tool```For the <code>/tmp</code> container```json{    ""read"": ""2020-03-20T05:24:03.754425567Z"",    ""preread"": ""2020-03-20T05:24:02.752857441Z"",    ""pids_stats"": {        ""current"": 1    },    ""blkio_stats"": {        ""io_service_bytes_recursive"": [],        ""io_serviced_recursive"": [],        ""io_queue_recursive"": [],        ""io_service_time_recursive"": [],        ""io_wait_time_recursive"": [],        ""io_merged_recursive"": [],        ""io_time_recursive"": [],        ""sectors_recursive"": []    },    ""num_procs"": 0,    ""storage_stats"": {},    ""cpu_stats"": {        ""cpu_usage"": {            ""total_usage"": 1841965540,            ""percpu_usage"": [                992402,                1665649,                1619827291,                2729087,                4554574,                5189767,                201081062,                5925708            ],            ""usage_in_kernelmode"": 1620000000,            ""usage_in_usermode"": 200000000        },        ""system_cpu_usage"": 2611727730000000,        ""online_cpus"": 8,        ""throttling_data"": {            ""periods"": 0,            ""throttled_periods"": 0,            ""throttled_time"": 0        }    },    ""precpu_stats"": {        ""cpu_usage"": {            ""total_usage"": 1841965540,            ""percpu_usage"": [                992402,                1665649,                1619827291,                2729087,                4554574,                5189767,                201081062,                5925708            ],            ""usage_in_kernelmode"": 1620000000,            ""usage_in_usermode"": 200000000        },        ""system_cpu_usage"": 2611719640000000,        ""online_cpus"": 8,        ""throttling_data"": {            ""periods"": 0,            ""throttled_periods"": 0,            ""throttled_time"": 0        }    },    ""memory_stats"": {        ""usage"": 234754048,        ""max_usage"": 268439552,        ""stats"": {            ""active_anon"": 0,            ""active_file"": 113635328,            ""cache"": 227082240,            ""dirty"": 197885952,            ""hierarchical_memory_limit"": 268435456,            ""hierarchical_memsw_limit"": 536870912,            ""inactive_anon"": 0,            ""inactive_file"": 113577984,            ""mapped_file"": 0,            ""pgfault"": 8976,            ""pgmajfault"": 0,            ""pgpgin"": 64152,            ""pgpgout"": 8749,            ""rss"": 0,            ""rss_huge"": 0,            ""total_active_anon"": 0,            ""total_active_file"": 113635328,            ""total_cache"": 227082240,            ""total_dirty"": 197885952,            ""total_inactive_anon"": 0,            ""total_inactive_file"": 113577984,            ""total_mapped_file"": 0,            ""total_pgfault"": 8976,            ""total_pgmajfault"": 0,            ""total_pgpgin"": 64152,            ""total_pgpgout"": 8749,            ""total_rss"": 0,            ""total_rss_huge"": 0,            ""total_unevictable"": 0,            ""total_writeback"": 0,            ""unevictable"": 0,            ""writeback"": 0        },        ""failcnt"": 19,        ""limit"": 268435456    },    ""name"": ""/keen_elbakyan"",    ""id"": ""8c601a0d84047b079b4e409c0fd3197efc1ce80bd964c472f49cbf769517ee5d"",    ""networks"": {        ""eth0"": {            ""rx_bytes"": 5610,            ""rx_packets"": 39,            ""rx_errors"": 0,            ""rx_dropped"": 0,            ""tx_bytes"": 0,            ""tx_packets"": 0,            ""tx_errors"": 0,            ""tx_dropped"": 0        }    }}```</details>For the <code>/dev/shm</code> container```json{    ""read"": ""2020-03-20T05:32:09.684746601Z"",    ""preread"": ""2020-03-20T05:32:08.683481358Z"",    ""pids_stats"": {        ""current"": 1    },    ""blkio_stats"": {        ""io_service_bytes_recursive"": [],        ""io_serviced_recursive"": [],        ""io_queue_recursive"": [],        ""io_service_time_recursive"": [],        ""io_wait_time_recursive"": [],        ""io_merged_recursive"": [],        ""io_time_recursive"": [],        ""sectors_recursive"": []    },    ""num_procs"": 0,    ""storage_stats"": {},    ""cpu_stats"": {        ""cpu_usage"": {            ""total_usage"": 1494756157,            ""percpu_usage"": [                822498,                856679,                558496,                8284470,                200931734,                1192872,                1278601167,                3508241            ],            ""usage_in_kernelmode"": 1270000000,            ""usage_in_usermode"": 200000000        },        ""system_cpu_usage"": 2615624390000000,        ""online_cpus"": 8,        ""throttling_data"": {            ""periods"": 0,            ""throttled_periods"": 0,            ""throttled_time"": 0        }    },    ""precpu_stats"": {        ""cpu_usage"": {            ""total_usage"": 1494756157,            ""percpu_usage"": [                822498,                856679,                558496,                8284470,                200931734,                1192872,                1278601167,                3508241            ],            ""usage_in_kernelmode"": 1270000000,            ""usage_in_usermode"": 200000000        },        ""system_cpu_usage"": 2615616430000000,        ""online_cpus"": 8,        ""throttling_data"": {            ""periods"": 0,            ""throttled_periods"": 0,            ""throttled_time"": 0        }    },    ""memory_stats"": {        ""usage"": 234721280,        ""max_usage"": 268439552,        ""stats"": {            ""active_anon"": 0,            ""active_file"": 0,            ""cache"": 233029632,            ""dirty"": 0,            ""hierarchical_memory_limit"": 268435456,            ""hierarchical_memsw_limit"": 536870912,            ""inactive_anon"": 232894464,            ""inactive_file"": 0,            ""mapped_file"": 0,            ""pgfault"": 8976,            ""pgmajfault"": 0,            ""pgpgin"": 65604,            ""pgpgout"": 8741,            ""rss"": 0,            ""rss_huge"": 0,            ""total_active_anon"": 0,            ""total_active_file"": 0,            ""total_cache"": 233029632,            ""total_dirty"": 0,            ""total_inactive_anon"": 232894464,            ""total_inactive_file"": 0,            ""total_mapped_file"": 0,            ""total_pgfault"": 8976,            ""total_pgmajfault"": 0,            ""total_pgpgin"": 65604,            ""total_pgpgout"": 8741,            ""total_rss"": 0,            ""total_rss_huge"": 0,            ""total_unevictable"": 0,            ""total_writeback"": 0,            ""unevictable"": 0,            ""writeback"": 0        },        ""failcnt"": 30,        ""limit"": 268435456    },    ""name"": ""/infallible_engelbart"",    ""id"": ""7066646c1a76b421db4ccee09d9bf6e2802203b42509b4138913bcf16a5132b1"",    ""networks"": {        ""eth0"": {            ""rx_bytes"": 5737,            ""rx_packets"": 40,            ""rx_errors"": 0,            ""rx_dropped"": 0,            ""tx_bytes"": 0,            ""tx_packets"": 0,            ""tx_errors"": 0,            ""tx_dropped"": 0        }    }}```</details>Addressing similar issues:- This issue might be an unintended side effect of issue #10824 / https://github.com/docker/cli/pull/80. Not including caches in memory usage is correct, since they will be automatically freed, if memory is needed. Not including `tmpfs` is not correct since the kernel can't just delete these files and so exhausting this resource will result in dead processes.- Possibly related to #39004, but not likely imo.
"
40715,0,10682,248,0,1,tao12345666333,0,"title:docker daemon exited when embedded DNS panic. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**```3闂?18 22:52:44 localhost dockerd[24752]: time=""2020-03-18T22:52:44.260463573+08:00"" level=debug msg=event module=libcontainerd namespace=moby topic=/tasks/create3闂?18 22:52:44 localhost dockerd[24752]: time=""2020-03-18T22:52:44.278716997+08:00"" level=debug msg=event module=libcontainerd namespace=moby topic=/tasks/start3闂?18 22:52:44 localhost dockerd[24752]: time=""2020-03-18T22:52:44.289235741+08:00"" level=debug msg=""Calling POST /v1.41/containers/3e79eacabe4e29c47545736cbaad76fddffdac1528c714a599c4b8acef1574c1/resize?h=13&w=123""3闂?18 22:52:45 localhost dockerd[24752]: time=""2020-03-18T22:52:45.551236099+08:00"" level=debug msg=""Calling POST /v1.41/exec/a27e75f03020df52e21f31da481d751e727a37d0b873aed7e2e9c9bb0eda6672/resize?h=27&w=123""3闂?18 22:52:58 localhost dockerd[24752]: time=""2020-03-18T22:52:58.402891147+08:00"" level=debug msg=""Calling POST /v1.41/exec/a27e75f03020df52e21f31da481d751e727a37d0b873aed7e2e9c9bb0eda6672/resize?h=6&w=123""3闂?18 22:53:13 localhost dockerd[24752]: time=""2020-03-18T22:53:13.278160707+08:00"" level=debug msg=""Calling HEAD /_ping""3闂?18 22:53:13 localhost dockerd[24752]: time=""2020-03-18T22:53:13.278488671+08:00"" level=debug msg=""Calling GET /v1.41/containers/json""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.723619823+08:00"" level=debug msg=""Calling HEAD /_ping""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.724235462+08:00"" level=debug msg=""Calling POST /v1.41/networks/uuu/connect""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.724317811+08:00"" level=debug msg=""form data: {\""Container\"":\""7193d08d480c\"",\""EndpointConfig\"":{\""Aliases\"":[],\""DriverOpts\"":{},\""EndpointID\"":\""\"",\""Gateway\"":\""\"",\""GlobalIPv6Address\"":\""\"",\""GlobalIPv6PrefixLen\"":0,\""IPAMConfig\"":{},\""IPAddress\"":\""\"",\""IPPrefixLen\"":0,\""IPv6Gateway\"":\""\"",\""Links\"":null,\""MacAddress\"":\""\"",\""NetworkID\"":\""\""}}""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.725158479+08:00"" level=debug msg=""Assigning addresses for endpoint priceless_poincare's interface on network uuu""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.725177685+08:00"" level=debug msg=""RequestAddress(LocalDefault/172.19.0.0/16, <nil>, map[])""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.725201718+08:00"" level=debug msg=""Request address PoolID:172.19.0.0/16 App: ipam/default/data, ID: LocalDefault/172.19.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65532, Sequence: (0xe0000000, 1)->(0x0, 2046)->(0x1, 1)->end Curr:3 Serial:false PrefAddress:<nil> ""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.732037880+08:00"" level=debug msg=""Assigning addresses for endpoint priceless_poincare's interface on network uuu""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.732629981+08:00"" level=debug msg=""d090be39adc71b334a98f0e1cf938ec9b4b94f49680f2ef91bc7c91caf8c2b12 (2d5de39).addSvcRecords(7193d08d480c, 172.19.0.3, <nil>, true) updateSvcRecord sid:d090be39adc71b334a98f0e1cf938ec9b4b94f49680f2ef91bc7c91caf8c2b12""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.732680112+08:00"" level=debug msg=""d090be39adc71b334a98f0e1cf938ec9b4b94f49680f2ef91bc7c91caf8c2b12 (2d5de39).addSvcRecords(7193d08d480c, 172.19.0.3, <nil>, false) updateSvcRecord sid:d090be39adc71b334a98f0e1cf938ec9b4b94f49680f2ef91bc7c91caf8c2b12""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.735252480+08:00"" level=debug msg=""d090be39adc71b334a98f0e1cf938ec9b4b94f49680f2ef91bc7c91caf8c2b12 (2d5de39).addSvcRecords(7193d08d480c, 172.19.0.3, <nil>, true) updateSvcRecord sid:d090be39adc71b334a98f0e1cf938ec9b4b94f49680f2ef91bc7c91caf8c2b12""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.735313819+08:00"" level=debug msg=""d090be39adc71b334a98f0e1cf938ec9b4b94f49680f2ef91bc7c91caf8c2b12 (2d5de39).addSvcRecords(7193d08d480c, 172.19.0.3, <nil>, false) updateSvcRecord sid:d090be39adc71b334a98f0e1cf938ec9b4b94f49680f2ef91bc7c91caf8c2b12""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.851635766+08:00"" level=debug msg=""EnableService 7193d08d480c554551037e18ec3b270f95c078dbc798e9495bef3eb88376e3d5 START""3闂?18 22:53:19 localhost dockerd[24752]: time=""2020-03-18T22:53:19.851664825+08:00"" level=debug msg=""EnableService 7193d08d480c554551037e18ec3b270f95c078dbc798e9495bef3eb88376e3d5 DONE""3闂?18 22:53:23 localhost dockerd[24752]: time=""2020-03-18T22:53:23.373728605+08:00"" level=debug msg=""Name To resolve: uuu.""3闂?18 22:53:23 localhost dockerd[24752]: time=""2020-03-18T22:53:23.375165920+08:00"" level=debug msg=""[resolver] query uuu. (A) from 172.17.0.2:41125, forwarding to udp:192.168.1.1""3闂?18 22:53:27 localhost dockerd[24752]: panic: runtime error: invalid memory address or nil pointer dereference3闂?18 22:53:27 localhost dockerd[24752]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x11 pc=0x55eebd258e5a]3闂?18 22:53:27 localhost dockerd[24752]: goroutine 1786 [running]:3闂?18 22:53:27 localhost dockerd[24752]: github.com/docker/docker/vendor/github.com/docker/libnetwork.(*resolver).ServeDNS(0xc000e4fdc0, 0x55eebefdb200, 0xc0009710e0, 0xc000c514d0)3闂?18 22:53:27 localhost dockerd[24752]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/resolver.go:487 +0x79a3闂?18 22:53:27 localhost dockerd[24752]: github.com/docker/docker/vendor/github.com/miekg/dns.(*Server).serveDNS(0xc00082d500, 0xc000c88400, 0x2c, 0x200, 0xc0009710e0)3闂?18 22:53:27 localhost dockerd[24752]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/miekg/dns/server.go:609 +0x2e23闂?18 22:53:27 localhost dockerd[24752]: github.com/docker/docker/vendor/github.com/miekg/dns.(*Server).serveUDPPacket(0xc00082d500, 0xc000bd24f0, 0xc000c88400, 0x2c, 0x200, 0xc000c38830, 0xc000a83760)3闂?18 22:53:27 localhost dockerd[24752]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/miekg/dns/server.go:549 +0xb43闂?18 22:53:27 localhost dockerd[24752]: created by github.com/docker/docker/vendor/github.com/miekg/dns.(*Server).serveUDP3闂?18 22:53:27 localhost dockerd[24752]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/miekg/dns/server.go:479 +0x27c3闂?18 22:53:27 localhost systemd[1]: docker.service: Main process exited, code=exited, status=2/INVALIDARGUMENT3闂?18 22:53:27 localhost systemd[1]: docker.service: Failed with result 'exit-code'.3闂?18 22:53:29 localhost systemd[1]: docker.service: Scheduled restart job, restart counter is at 2.3闂?18 22:53:29 localhost systemd[1]: Stopped Docker Application Container Engine.3闂?18 22:53:29 localhost systemd[1]: Starting Docker Application Container Engine...3闂?18 22:53:29 localhost dockerd[4452]: time=""2020-03-18T22:53:29.663975539+08:00"" level=info msg=""Starting up""3闂?18 22:53:29 localhost dockerd[4452]: time=""2020-03-18T22:53:29.664209297+08:00"" level=warning msg=""Running experimental build""3闂?18 22:53:29 localhost dockerd[4452]: time=""2020-03-18T22:53:29.669967834+08:00"" level=debug msg=""Listener created for HTTP on fd ()""3闂?18 22:53:29 localhost dockerd[4452]: time=""2020-03-18T22:53:29.670801784+08:00"" level=debug msg=""Golang's threads limit set to 114210""3闂?18 22:53:29 localhost dockerd[4452]: time=""2020-03-18T22:53:29.671365423+08:00"" level=info msg=""parsed scheme: \""unix\"""" module=grpc3闂?18 22:53:29 localhost dockerd[4452]: time=""2020-03-18T22:53:29.671392691+08:00"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpc3闂?18 22:53:29 localhost dockerd[4452]: time=""2020-03-18T22:53:29.671436019+08:00"" level=info msg=""ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}"" module=grpc```<!--Briefly describe the problem you are having in a few paragraphs.-->**Describe the results you received:**```/ # dig @127.0.0.11 uuu       error during connect: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.41/exec/a27e75f03020df52e21f31da481d751e727a37d0b873aed7e2e9c9bb0eda6672/json: read unix @->/var/run/docker.sock: read: connection reset by peer```When I started a container named `uuu` with new bridge network `uuu` and in other container try to run `dig @127.0.0.11 uuu` . The docker daemon exited.**Output of `docker version`:**```Client: Docker Engine - Community Version:           0.0.0-20200314012737-2e20eebe27 API version:       1.41 Go version:        go1.12.16 Git commit:        2e20eebe27 Built:             Mon Mar 16 20:14:30 2020 OS/Arch:           linux/amd64 Experimental:      trueServer: Docker Engine - Community Engine:  Version:          0.0.0-20200314012737-2e20eebe27  API version:      1.41 (minimum version 1.12)  Go version:       go1.12.16  Git commit:       2e20eebe27  Built:            Mon Mar 16 20:11:27 2020  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          v1.3.3  GitCommit:        d76c121f76a5fc8a462dc64594aea72fe18e1178 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.0-zeta1-96-g44932b629b)  buildx: Build with BuildKit (Docker Inc., v0.3.1-tp-docker)  year: A docker plugin, Happy New Year! (Jintao Zhang, v1.0.0)Server: Containers: 10  Running: 2  Paused: 0  Stopped: 8 Images: 39 Server Version: 0.0.0-20200314012737-2e20eebe27 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: systemd Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: d76c121f76a5fc8a462dc64594aea72fe18e1178 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 5.5.8-100.fc30.x86_64 Operating System: Fedora 30 (Workstation Edition) OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 15.53GiB Name: localhost ID: UWEO:YNU5:7YUR:3BSN:5DA7F:GFXV:AGRL:MEFG Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 46  Goroutines: 73  System Time: 2020-03-18T23:19:35.598453317+08:00  EventsListeners: 0 HTTP Proxy: socks5://127.0.0.1:1080 HTTPS Proxy: socks5://127.0.0.1:1080 No Proxy: localhost,127.0.0.1 Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.1:5000  127.0.0.0/8 Live Restore Enabled: true```**Additional environment details (AWS, VirtualBox, physical, etc.):**physical
"
40693,1,4153,0,0,0,jhowe-uw,0,"title:""docker system prune --volumes"" nukes volumes attached to running containers. description:**Description**""docker system prune --volumes"" nukes volumes attached to running containers**Steps to reproduce the issue:**1. Spin up a keycloak instance with docker-compose ( see below )2. Spin up a bitwarden instance3. Evaluate the bitwarden instance4. Stop the bitwarden instance5. Run 'docker system prune --volumes'6. Confirm volume deletion of bitwarden volume only**Describe the results you received:**ALL volumes were deleted from the machine! keycloak containers were running during the volume prune command.```$ sudo docker system prune --volumesWARNING! This will remove:  - all stopped containers  - all networks not used by at least one container  - all volumes not used by at least one container  - all dangling images  - all dangling build cacheAre you sure you want to continue? [y/N] yDeleted Volumes:keycloak_postgres-datadocker_mssql_dataTotal reclaimed space: 212.4MB```Also, this appeared to kill the running keycloak_db_1 instance ( postgres died when data dir was nuked ). No screen shot.**Describe the results you expected:**I expected the keycloak_postgres-data to be left alone.```Deleted Volumes:docker_mssql_data```**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```$ sudo docker versionClient: Docker Engine - Community Version:           19.03.8 API version:       1.40 Go version:        go1.12.17 Git commit:        afacb8b7f0 Built:             Wed Mar 11 01:25:56 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.8  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.17  Git commit:       afacb8b7f0  Built:            Wed Mar 11 01:24:28 2020  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          1.2.13  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```$ sudo docker infoClient: Debug Mode: falseServer: Containers: 3  Running: 3  Paused: 0  Stopped: 0 Images: 3 Server Version: 19.03.8 Storage Driver: overlay2  Backing Filesystem: <unknown>  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: systemd Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.19.0-8-amd64 Operating System: Debian GNU/Linux 10 (buster) OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.791GiB Name: strontium ID: 7IGT:Y35A:4BNQ:5ZP6:GMAW:LBMP:F7LO:TVFL:YFSJ:5VQR:6TG5:G5WO Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: true```**Additional environment details (AWS, VirtualBox, physical, etc.):**Debian Version 10.3 ( VM on KVM )$ docker-compose --versiondocker-compose version 1.25.4, build 8d51620a$ cat docker-compose.yml```---version: ""3.7""services:  # https://hub.docker.com/r/jboss/keycloak  keycloak:    image: jboss/keycloak:9.0.0    restart: unless-stopped    ports:      - ""127.0.0.1:${PROXY_KEYCLOAK_PORT:-8080}:8080""    environment:      KEYCLOAK_FRONTEND_URL:    ${KEYCLOAK_FRONTEND_URL:?err}      PROXY_ADDRESS_FORWARDING: 'true'      KEYCLOAK_STATISTICS:      'all'      KEYCLOAK_USER:            'cirg-admin'      KEYCLOAK_PASSWORD:        ${KEYCLOAK_PASSWORD:?err}      DB_VENDOR:                'postgres'      DB_ADDR:                  'db'      DB_PORT:                  5432      DB_DATABASE:              'keycloak'      DB_USER:                  'keycloak'      DB_PASSWORD:              ${POSTGRES_PASSWORD:?err}    depends_on:      - db    volumes:      # - /some/dir/my-script.cli:/opt/jboss/startup-scripts/my-script.cli      # - /path/to/keys(tls.crt|tls.key):/etc/x509/https      #      # Exporting dir for bin/standalone.sh calls      - ./exports:/exports      #      # krb5.keytab mapping      - ./krb5.keytab:/etc/krb5.keytab      # Themes      - ./themes/mapapp:/opt/jboss/keycloak/themes/mapapp  # https://hub.docker.com/_/postgres  db:    image: postgres:12.2    restart: unless-stopped    environment:      POSTGRES_DB:        'keycloak'      POSTGRES_USER:      'keycloak'      POSTGRES_PASSWORD:  ${POSTGRES_PASSWORD:?err}      POSTGRES_DB:        'keycloak'    volumes:      - postgres-data:/var/lib/postgresql/data      # Local import/export for DR      - ./import-export:/import-exportvolumes:  postgres-data: {}```
"
40667,0,1613,0,0,0,phidlipus,0,"title:Failed XFS detection in v19.03.7. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**It's not possible to start last Docker version (v19.03.7 at the moment) with XFS an disk quota enabled (overlay2.size).It ends with this error message:```Mar 11 11:24:10 docker dockerd[11974]: failed to start daemon: error initializing graphdriver: Storage Option overlay2.size only supported for backingFS XFS. Found <unknown>```After downgrade to previous version, Docker successfully starts.**Steps to reproduce the issue:**This bug occured on our bare-metal servers.I created Vagrantfile which you can easily re-use (or just copy&paste commands to some generic Debian Stretch installation):```$script = <<-SCRIPTapt-get -qq updateapt-get -y install xfsprogs curl apt-transport-httpsdd if=/dev/zero of=/docker.img bs=512MB count=4device=$(losetup --show -f /docker.img)mkfs.xfs ""$device""mkdir -p /data/dockerecho ""$device /data/docker xfs pquota 0 2"" >>/etc/fstabmount -amkdir /etc/dockercat <<EOF >/etc/docker/daemon.json{  ""exec-opts"": [""native.cgroupdriver=systemd""],  ""data-root"": ""/data/docker"",  ""storage-driver"": ""overlay2"",  ""storage-opts"": [    ""overlay2.size=500M""  ],  ""log-driver"": ""json-file"",  ""log-opts"": {    ""max-size"": ""10m"",    ""max-file"": ""3""  },  ""bridge"": ""none"",  ""iptables"": false,  ""ip-forward"": false,  ""ip-masq"": false}EOFcurl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add -echo ""deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable"" > /etc/apt/sources.list.d/docker.listapt-get -qq updateSCRIPTVagrant.configure(""2"") do |config|  config.vm.box = ""debian/stretch64""  config.vm.provider ""virtualbox"" do |v|    v.memory = 2048    v.cpus = 2  end  config.vm.hostname = ""docker""  config.vm.provision ""shell"", inline: $scriptend```Connect to installed machine (`vagrant ssh`) and try to install `v19.03.7` of `docker-ce` package. Simultaneously check the logs in the second terminal (`journalctl -f`).```apt-get install docker-ce=5:19.03.7~3-0~debian-stretch docker-ce-cli=5:19.03.7~3-0~debian-stretch containerd.io```You can try to start it manually and check the logs.```systemctl start docker```Downgrade to previous version, which successfully starts.```apt-get install docker-ce=5:19.03.6~3-0~debian-stretch docker-ce-cli=5:19.03.6~3-0~debian-stretch```
"
40660,1,7311,5,0,0,kbulygin,0,"title:BuildKit: `docker build -t /tmp/Dockerfile .` tries to access other files in `/tmp`. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->I preprocess Dockerfiles and put results to `/tmp`, then run `docker build`. When directory with Dockerfile contains a file which is not accessible to the current user (in my case it's `drwx------ 2 root root ... /tmp/pulse-.../`), `docker build` fails. The issue is experienced with BuildKit but not with the default builder.(As a workaround, I now put Dockerfiles to separate directories.) **Steps to reproduce the issue:**Run the following script:```bash#!/bin/bashset -eux -o pipefail[ $# = 0 ]cd /tmpmkdir testingcd testing{ echo 'FROM scratch'; echo 'COPY empty .'; } >Dockerfilemkdir -m700 secretsudo chown root:root secretmkdir buildcd buildtouch emptyexport DOCKER_BUILDKITfor DOCKER_BUILDKIT in '' 1; do  docker build -f /tmp/testing/Dockerfile -t temporary . || echo ""[exit $?]""done```**Describe the results you received:**```bash+ '[' 0 = 0 ']'+ cd /tmp+ mkdir testing+ cd testing+ echo 'FROM scratch'+ echo 'COPY empty .'+ mkdir -m700 secret+ sudo chown root:root secret+ mkdir build+ cd build+ touch empty+ export DOCKER_BUILDKIT+ for DOCKER_BUILDKIT in '' 1+ docker build -f /tmp/testing/Dockerfile -t temporary .Sending build context to Docker daemon  2.074kBStep 1/2 : FROM scratch ---> Step 2/2 : COPY empty . ---> Using cache ---> ecfc77bfe2e5Successfully built ecfc77bfe2e5Successfully tagged temporary:latest+ for DOCKER_BUILDKIT in '' 1+ docker build -f /tmp/testing/Dockerfile -t temporary .[+] Building 0.0s (2/2) FINISHED                                                                                                                                                               => ERROR [internal] load build definition from Dockerfile                                                                                                                               0.0s => => transferring dockerfile: 82B                                                                                                                                                      0.0s => [internal] load .dockerignore                                                                                                                                                        0.0s => => transferring context: 2B                                                                                                                                                          0.0s------ > [internal] load build definition from Dockerfile:------failed to solve with frontend dockerfile.v0: failed to resolve dockerfile: failed to build LLB: error from sender: open /tmp/testing/secret: permission denied+ echo '[exit 1]'[exit 1]```**Describe the results you expected:**I expected `docker build` to succeed, like without `secret`:```bash...+ docker build -f /tmp/testing/Dockerfile -t temporary .[+] Building 0.1s (5/5) FINISHED                                                                                                                                                               => [internal] load .dockerignore                                                                                                                                                        0.0s => => transferring context: 2B                                                                                                                                                          0.0s => [internal] load build definition from Dockerfile                                                                                                                                     0.0s => => transferring dockerfile: 69B                                                                                                                                                      0.0s => [internal] load build context                                                                                                                                                        0.0s => => transferring context: 26B                                                                                                                                                         0.0s => CACHED [1/1] COPY empty .                                                                                                                                                            0.0s => exporting to image                                                                                                                                                                   0.0s => => exporting layers                                                                                                                                                                  0.0s => => writing image sha256:e9d8504ab4460ae3168c53a65b1a9175780499f0477200d47da0f14d50f138e3                                                                                             0.0s => => naming to docker.io/library/temporary                                                                                                                                             0.0s```In general, I expected no user data to be used outside the referenced Dockerfile and the building directory. E.g., if I simply had lots of unrelated data in `/tmp`, I guess the building would be slow for no apparent reason.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.6 API version:       1.40 Go version:        go1.12.16 Git commit:        369ce74a3c Built:             Thu Feb 13 01:27:58 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.6  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.16  Git commit:       369ce74a3c  Built:            Thu Feb 13 01:26:32 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.10  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339 runc:  Version:          1.0.0-rc8+dev  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657 docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 42  Running: 28  Paused: 0  Stopped: 14 Images: 155 Server Version: 19.03.6 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: journald Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: active  NodeID: qai193ap23u7450vo6atj86dn  Is Manager: true  ClusterID: 6a98n2v9nh1m6m5aa0ju839xf  Managers: 3  Nodes: 3  Default Address Pool: 10.0.0.0/8    SubnetSize: 24  Data Path Port: 4789  Orchestration:   Task History Retention Limit: 5  Raft:   Snapshot Interval: 10000   Number of Old Snapshots to Retain: 0   Heartbeat Tick: 1   Election Tick: 10  Dispatcher:   Heartbeat Period: 5 seconds  CA Configuration:   Expiry Duration: 3 months   Force Rotate: 0  Autolock Managers: false  Root Rotation In Progress: false  Node Address: ...  Manager Addresses:   ... Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339 runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657 init version: fec3683 Security Options:  apparmor  seccomp   Profile: default  userns Kernel Version: 4.19.0-6-amd64 Operating System: Debian GNU/Linux 10 (buster) OSType: linux Architecture: x86_64 CPUs: 12 Total Memory: 31.35GiB Name: host ID: CO2V:GL7M:6JCU:O22Q:QZVK:4BDS:ZR3Q:4VGJ:DI3W:EH6Y:4KSY:3AGR Docker Root Dir: /var/lib/docker/1000.998 Debug Mode: false Username: kbulygin Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical.
"
40651,0,191,200,0,0,thaJeztah,0,"title:Flaky test: TestInspect. description:This one is failing frequently;```=== RUN   TestInspect--- FAIL: TestInspect (12.10s)    inspect_test.go:39: timeout hit after 10s: waiting for tasks to enter run state. task failed with error: task: non-zero exit (1)```
"
40634,1,9112,248,0,0,stgraber,0,"title:[libnetwork panic] Crash on startup with latest master builds. description:The LXD team runs a daily test of Docker inside LXD privileged and unprivileged containers.The source of the test is at: https://github.com/lxc/lxc-ci/blob/master/bin/test-lxd-dockerThe jenkins output at: https://jenkins.linuxcontainers.org/job/lxd-test-docker/Starting today (March 6th), we're seeing startup failures on Docker in both our tests.The associated stacktrace is:```Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: panic: interface conversion: interface {} is nil, not boolMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: goroutine 1 [running]:Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*networkConfiguration).UnmarshalJSON(0xc0004b92b0, 0xc0009bc1a0, 0x189, 0x189, 0x7fcf98Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge_store.go:201 +0xb9aMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: encoding/json.(*decodeState).object(0xc0003fb080, 0x2df71a0, 0xc0004b92b0, 0x16, 0xc0003fb0a8, 0xc0009ab07b)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /usr/local/go/src/encoding/json/decode.go:667 +0x220dMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: encoding/json.(*decodeState).value(0xc0003fb080, 0x2df71a0, 0xc0004b92b0, 0x16, 0xc000ada4f8, 0x5705bb)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /usr/local/go/src/encoding/json/decode.go:429 +0x6fMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: encoding/json.(*decodeState).unmarshal(0xc0003fb080, 0x2df71a0, 0xc0004b92b0, 0xc0003fb0a8, 0x0)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /usr/local/go/src/encoding/json/decode.go:179 +0x1fdMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: encoding/json.Unmarshal(0xc0009bc1a0, 0x189, 0x189, 0x2df71a0, 0xc0004b92b0, 0x2e753a0, 0xc0004b92b0)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /usr/local/go/src/encoding/json/decode.go:106 +0x114Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*networkConfiguration).SetValue(0xc0004b92b0, 0xc0009bc1a0, 0x189, 0x189, 0x1, 0x1)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge_store.go:231 +0x57Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/docker/libnetwork/datastore.(*cache).kmap(0xc00000fec0, 0x2f87440, 0xc0004b8dd0, 0x0, 0x1b, 0xc000983080)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/datastore/cache.go:61 +0x33cMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/docker/libnetwork/datastore.(*cache).list(0xc00000fec0, 0x2f87440, 0xc0004b8dd0, 0x0, 0x0, 0x0, 0x0, 0x0)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/datastore/cache.go:164 +0x7eMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/docker/libnetwork/datastore.(*datastore).List(0xc0009db680, 0xc000983080, 0x1b, 0x2f87440, 0xc0004b8dd0, 0x0, 0x0, 0x0, 0Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/datastore/datastore.go:517 +0x205Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*driver).populateNetworks(0xc000167aa0, 0x5, 0x1ebbd5e)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge_store.go:50 +0x1d7Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*driver).initStore(0xc000167aa0, 0xc000af4660, 0x0, 0xc0005f60c0)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge_store.go:35 +0x211Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*driver).configure(0xc000167aa0, 0xc000af4660, 0x2abde60, 0xc000af4390)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge.go:388 +0x17fMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.Init(0x2f30740, 0xc000913380, 0xc000af4660, 0xc000af4660, 0x0)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge.go:163 +0x9cMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/docker/libnetwork/drvregistry.(*DrvRegistry).AddDriver(...)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drvregistry/drvregistry.go:72Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/docker/libnetwork.New(0xc000050a00, 0x9, 0x10, 0xc000831950, 0xc000af4330, 0xc000050a00, 0x9)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:220 +0x4f0Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/daemon.(*Daemon).initNetworkController(0xc00000c5a0, 0xc0000d3080, 0xc000af4330, 0x0, 0x0, 0x0, 0x0)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/daemon/daemon_unix.go:890 +0xa9Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/daemon.(*Daemon).restore(0xc00000c5a0, 0xc0007e7180, 0xc0009ce000)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/daemon/daemon.go:468 +0x50bMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/daemon.NewDaemon(0x2f5b540, 0xc0007e7180, 0xc0000d3080, 0xc000831950, 0x0, 0x0, 0x0)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/daemon/daemon.go:1096 +0x2ab3Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: main.(*DaemonCli).start(0xc000831710, 0xc0007392c0, 0x0, 0x0)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/cmd/dockerd/daemon.go:199 +0x74cMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: main.runDaemon(...)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/cmd/dockerd/docker_unix.go:13Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: main.newDaemonCommand.func1(0xc00082e500, 0xc0008316b0, 0x0, 0x3, 0x0, 0x0)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/cmd/dockerd/docker.go:34 +0x7cMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).execute(0xc00082e500, 0xc00004e0d0, 0x3, 0x3, 0xc00082e500, 0xc00004e0d0)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:762 +0x462Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc00082e500, 0x0, 0x0, 0x10)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:852 +0x2ecMar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).Execute(...)Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:800Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]: main.main()Mar 06 14:19:47 docker-1c285a5e-4ca2-4f9d-a8f9-5b88ed62a65a dockerd[1434]:         /go/src/github.com/docker/docker/cmd/dockerd/docker.go:97 +0x191```Hopefully between the time at which we've noticed this change and the stacktrace above, the issue can easily be tracked down.We care about this use case as Travis-CI foreign architecture support runs on LXD and a lot of Travis jobs use Docker, so we're trying to catch things early by testing the master snapshots.
"
40626,0,461,0,0,0,mtrensch,0,"title:[Docker 19.03.7] - overlay/overlay2 shows Backing Filesystem as <unknown>. description:**Description**We are manually building docker / moby runtime in a project and after updating to 19.03.7 we remarked that the Backing Filesystem for overlay2 is now shown as `""<unknown>""` while it was `""extfs""` in 19.03.6.**Steps to reproduce the issue:**1. Install docker 19.03.72. Execute ""docker info""**Describe the results you received:**```Server: Server Version: 19.03.7 Storage Driver: overlay2  Backing Filesystem: <unknown>  Supports d_type: true  Native Overlay Diff: true```**Describe the results you expected:**```Server: Server Version: 19.03.7 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true```**Additional information:**This seems have been introduced with commit 5b6f2e1c59b442a118d1bfb6c76c01f0d14a26cb which removes the filesystem check and now ommits setting backingFs variable, making it default to `""<unknown>""`I am not a Go programmer, but probably something like the following can be readded in overlay.go in both overlay drivers:```fsMagic, err := graphdriver.GetFSMagic(testdir)if err == nil {    if fsName, ok := graphdriver.FsNames[fsMagic]; ok {        backingFs = fsName    }}```
"
40624,1,2551,144,0,0,Antiarchitect,0,"title:docker build hangs on COPY --from previous-stage. description:I have docker out of docker setup for my Gitlab Builds in K8s 1.16.7 on baremetal.I have a complicated multi-stage build that hangs on copy directory from the previous stage seems like for >20minutes. Have similar two COPY --from other-stage that do not hang. Size of the directory is about 8Mb - not much.strace:bash-5.0# strace -p 108strace: Process 108 attachedfutex(0x33fbac8, FUTEX_WAIT_PRIVATE, 0, NULLstucks soooo long...**Output of `docker version`:**``` docker version Client: Docker Engine - Community  Version:           19.03.7  API version:       1.40  Go version:        go1.12.17  Git commit:        7141c199a2  Built:             Wed Mar  4 01:19:42 2020  OS/Arch:           linux/amd64  Experimental:      false Server: Docker Engine - Community  Engine:   Version:          19.03.7   API version:      1.40 (minimum version 1.12)   Go version:       go1.12.17   Git commit:       7141c199a2   Built:            Wed Mar  4 01:19:50 2020   OS/Arch:          linux/amd64   Experimental:     false  containerd:   Version:          v1.2.13   GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429  runc:   Version:          1.0.0-rc10   GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd  docker-init:   Version:          0.18.0   GitCommit:        fec3683```**Output of `docker info`:**```docker info WARNING: API is accessible on http://0.0.0.0:2375 without encryption.          Access to the remote API is equivalent to root access on the host. Refer          to the 'Docker daemon attack surface' section in the documentation for          more information: https://docs.docker.com/engine/security/security/#docker-daemon-attack-surface Client:  Debug Mode: false Server:  Containers: 0   Running: 0   Paused: 0   Stopped: 0  Images: 32  Server Version: 19.03.7  Storage Driver: overlay2   Backing Filesystem: <unknown>   Supports d_type: true   Native Overlay Diff: true  Logging Driver: json-file  Cgroup Driver: cgroupfs  Plugins:   Volume: local   Network: bridge host ipvlan macvlan null overlay   Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog  Swarm: inactive  Runtimes: runc  Default Runtime: runc  Init Binary: docker-init  containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429  runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd  init version: fec3683  Security Options:   seccomp    Profile: default  Kernel Version: 5.3.13-1.el7.elrepo.x86_64  Operating System: Alpine Linux v3.11 (containerized)  OSType: linux  Architecture: x86_64  CPUs: 8  Total Memory: 15.64GiB  Name: production-app-gitlab-runners-docker-0  ID: ACPC:SJLM:E5P5:5XMH:4V3K:77NZ:NBSD:MQBC:SDC2:EANJ:4BMN:6P2L  Docker Root Dir: /var/lib/docker  Debug Mode: false  Registry: https://index.docker.io/v1/  Labels:  Experimental: false  Insecure Registries:   127.0.0.0/8  Live Restore Enabled: false  Product License: Community Engine```**Additional environment details (AWS, VirtualBox, physical, etc.):**Kubernetes 1.16.7Centos 7 with 5.3.13-1.el7.elrepo.x86_64 kernelBaremetalCilium 1.7.0 as network
"
40584,1,23630,0,0,1,qw1mb0,0,"title:The json-file driver log breaks the container logs during rotation. description:**Description**We use kubernetes version 1.15.0 with docker. Sometimes we have problems viewing the container logs. The `kubectl logs` command ends with an error:```failed to get parse function: unsupported log format: ""\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\```If you go straight to the node where the container lives, you can find the container:``` # docker ps -a --no-trunc | grep 7845874cf4-vgc7g2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006   docker-local-bcless-cat.art.domain.ss/bcless-cat/release/frontend@sha256:6ff6defe8f8ccb897d062580930da73229d1f307dc7ba4f39bcc6e9481b2d1c4         ""/bin/sh -c /entrypoint""    5 weeks ago         Up 5 weeks                                     k8s_frontend_frontend-7845874cf4-vgc7g_bcless-cat_52c02f25-26f0-4901-b637-cf33e6e93b25_03dad62e361069bd11362e05fe04c05d280517c37cc80f53e1a7b8c3275051393   k8s.gcr.io/pause:3.1  ""/pause""  5 weeks ago         Up 5 weeks                                     k8s_POD_frontend-7845874cf4-vgc7g_bcless-cat_52c02f25-26f0-4901-b637-cf33e6e93b25_0```Here's the inspectect of this container:```docker inspect 2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006[    {        ""Id"": ""2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006"",        ""Created"": ""2020-01-17T10:24:08.482474391Z"",        ""Path"": ""/bin/sh"",        ""Args"": [            ""-c"",            ""/entrypoint""        ],        ""State"": {            ""Status"": ""running"",            ""Running"": true,            ""Paused"": false,            ""Restarting"": false,            ""OOMKilled"": false,            ""Dead"": false,            ""Pid"": 1791820,            ""ExitCode"": 0,            ""Error"": """",            ""StartedAt"": ""2020-01-17T10:24:08.651566716Z"",            ""FinishedAt"": ""0001-01-01T00:00:00Z""        },        ""Image"": ""sha256:2aa6cf18486171fb549d0290f1735b2604db9d34bb65b3fbe4c9f53d116a894b"",        ""ResolvConfPath"": ""/var/lib/docker/containers/3dad62e361069bd11362e05fe04c05d280517c37cc80f53e1a7b8c3275051393/resolv.conf"",        ""HostnamePath"": ""/var/lib/docker/containers/3dad62e361069bd11362e05fe04c05d280517c37cc80f53e1a7b8c3275051393/hostname"",        ""HostsPath"": ""/var/lib/kubelet/pods/52c02f25-26f0-4901-b637-cf33e6e93b25/etc-hosts"",        ""LogPath"": ""/var/lib/docker/containers/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006-json.log"",        ""Name"": ""/k8s_frontend_frontend-7845874cf4-vgc7g_bcless-cat_52c02f25-26f0-4901-b637-cf33e6e93b25_0"",        ""RestartCount"": 0,        ""Driver"": ""overlay2"",        ""Platform"": ""linux"",        ""MountLabel"": """",        ""ProcessLabel"": """",        ""AppArmorProfile"": ""docker-default"",        ""ExecIDs"": null,        ""HostConfig"": {            ""Binds"": [                ""/var/lib/kubelet/pods/52c02f25-26f0-4901-b637-cf33e6e93b25/volumes/kubernetes.io~secret/default-token-8bhxj:/var/run/secrets/kubernetes.io/serviceaccount:ro"",                ""/var/lib/kubelet/pods/52c02f25-26f0-4901-b637-cf33e6e93b25/etc-hosts:/etc/hosts"",                ""/var/lib/kubelet/pods/52c02f25-26f0-4901-b637-cf33e6e93b25/containers/frontend/745a265d:/dev/termination-log""            ],            ""ContainerIDFile"": """",            ""LogConfig"": {                ""Type"": ""json-file"",                ""Config"": {                    ""max-file"": ""5"",                    ""max-size"": ""10m""                }            },            ""NetworkMode"": ""container:3dad62e361069bd11362e05fe04c05d280517c37cc80f53e1a7b8c3275051393"",            ""PortBindings"": null,            ""RestartPolicy"": {                ""Name"": ""no"",                ""MaximumRetryCount"": 0            },                        ""AutoRemove"": false,            ""VolumeDriver"": """",            ""VolumesFrom"": null,            ""CapAdd"": null,            ""CapDrop"": null,            ""Dns"": null,            ""DnsOptions"": null,            ""DnsSearch"": null,            ""ExtraHosts"": null,            ""GroupAdd"": null,            ""IpcMode"": ""container:3dad62e361069bd11362e05fe04c05d280517c37cc80f53e1a7b8c3275051393"",            ""Cgroup"": """",            ""Links"": null,            ""OomScoreAdj"": 999,            ""PidMode"": """",            ""Privileged"": false,            ""PublishAllPorts"": false,            ""ReadonlyRootfs"": false,            ""SecurityOpt"": [                ""seccomp=unconfined""            ],            ""UTSMode"": """",            ""UsernsMode"": """",            ""ShmSize"": 67108864,            ""Runtime"": ""runc"",            ""ConsoleSize"": [                0,                0            ],            ""Isolation"": """",            ""CpuShares"": 2,            ""Memory"": 67108864,            ""NanoCpus"": 0,            ""CgroupParent"": ""/kubepods/burstable/pod52c02f25-26f0-4901-b637-cf33e6e93b25"",                        ""BlkioWeight"": 0,            ""BlkioWeightDevice"": null,            ""BlkioDeviceReadBps"": null,            ""BlkioDeviceWriteBps"": null,            ""BlkioDeviceReadIOps"": null,            ""BlkioDeviceWriteIOps"": null,            ""CpuPeriod"": 100000,            ""CpuQuota"": 0,            ""CpuRealtimePeriod"": 0,            ""CpuRealtimeRuntime"": 0,            ""CpusetCpus"": """",            ""CpusetMems"": """",            ""Devices"": [],            ""DeviceCgroupRules"": null,            ""DiskQuota"": 0,            ""KernelMemory"": 0,            ""MemoryReservation"": 0,            ""MemorySwap"": -1,            ""MemorySwappiness"": null,            ""OomKillDisable"": false,            ""PidsLimit"": 0,            ""Ulimits"": null,            ""CpuCount"": 0,            ""CpuPercent"": 0,            ""IOMaximumIOps"": 0,            ""IOMaximumBandwidth"": 0,            ""MaskedPaths"": [                ""/proc/acpi"",                ""/proc/kcore"",                ""/proc/keys"",                ""/proc/latency_stats"",                ""/proc/timer_list"",                ""/proc/timer_stats"",                ""/proc/sched_debug"",                ""/proc/scsi"",                ""/sys/firmware""            ],            ""ReadonlyPaths"": [                ""/proc/asound"",                ""/proc/bus"",                ""/proc/fs"",                ""/proc/irq"",                ""/proc/sys"",                ""/proc/sysrq-trigger""            ]        },        ""GraphDriver"": {            ""Data"": {                ""LowerDir"": ""/var/lib/docker/overlay2/8bb806e4366e2f74828bafc5622eff888366244a4e64c9da0dfc54e9e3e360e9-init/diff:/var/lib/docker/overlay2/3d02b1884aa8867b638a77bfeb6e039045758962ddd604ad20600a2464da879e/diff:/var/lib/docker/overlay2/3a2fa9a5e698aaac5010fc1bb52e1263183145bef1d742ff6f3cb8f183b32f52/diff:/var/lib/docker/overlay2/cdabc7ec219ebcd14266f2217a77a1eb80221ff86b24655d0c7d67101154c918/diff:/var/lib/docker/overlay2/d6ae7735aa3fa182ea39035d52a3f28df1da29ea609dd1ae2a1b26ac92e39f6b/diff:/var/lib/docker/overlay2/e7e93a8ef802e685820b47197008e67ddd31246fa98da20cb15fe3d6bfb8c9e4/diff:/var/lib/docker/overlay2/39041725e5fd3216c12c0a4c0f1b280f0548c624812c0b481b6d0174dc96b603/diff:/var/lib/docker/overlay2/01a963a7b4dd78ac1f36653e85f149358c99b0e99a640dbec57a706568400b7b/diff:/var/lib/docker/overlay2/9e4bfa471b600ef1f2e279c378dd5b6e3f3f76cfa5f090ca02faf6ace7ba6066/diff:/var/lib/docker/overlay2/677419f548ea567d86d4e56c0a5e7f131b80abc24d78563cd04cb3bb8f960fde/diff:/var/lib/docker/overlay2/e7d8626996c41e77a7f28e5be50c3bdcf89c3c8318443c28c7611842022db81a/diff:/var/lib/docker/overlay2/b1d4e2bb20d55da77966fd18fe2ae9a0db2d3cb3d8f26f1f164c6760cf1cc9fb/diff:/var/lib/docker/overlay2/f31f7fec208112dfb1820324d39a2053729a0862a1a6e542153ab10d6faeef7a/diff"",                ""MergedDir"": ""/var/lib/docker/overlay2/8bb806e4366e2f74828bafc5622eff888366244a4e64c9da0dfc54e9e3e360e9/merged"",                ""UpperDir"": ""/var/lib/docker/overlay2/8bb806e4366e2f74828bafc5622eff888366244a4e64c9da0dfc54e9e3e360e9/diff"",                ""WorkDir"": ""/var/lib/docker/overlay2/8bb806e4366e2f74828bafc5622eff888366244a4e64c9da0dfc54e9e3e360e9/work""            },            ""Name"": ""overlay2""        },                ""Mounts"": [            {                ""Type"": ""bind"",                ""Source"": ""/var/lib/kubelet/pods/52c02f25-26f0-4901-b637-cf33e6e93b25/volumes/kubernetes.io~secret/default-token-8bhxj"",                ""Destination"": ""/var/run/secrets/kubernetes.io/serviceaccount"",                ""Mode"": ""ro"",                ""RW"": false,                ""Propagation"": ""rprivate""            },            {                ""Type"": ""bind"",                ""Source"": ""/var/lib/kubelet/pods/52c02f25-26f0-4901-b637-cf33e6e93b25/etc-hosts"",                ""Destination"": ""/etc/hosts"",                ""Mode"": """",                ""RW"": true,                ""Propagation"": ""rprivate""            },            {                ""Type"": ""bind"",                ""Source"": ""/var/lib/kubelet/pods/52c02f25-26f0-4901-b637-cf33e6e93b25/containers/frontend/745a265d"",                ""Destination"": ""/dev/termination-log"",                ""Mode"": """",                ""RW"": true,                ""Propagation"": ""rprivate""            }        ],        ""Config"": {            ""Hostname"": ""frontend-7845874cf4-vgc7g"",            ""Domainname"": """",            ""User"": ""0"",            ""AttachStdin"": false,            ""AttachStdout"": false,            ""AttachStderr"": false,            ""Tty"": false,            ""OpenStdin"": false,            ""StdinOnce"": false,            ""Env"": [                ""KUBERNETES_PORT=tcp://192.168.0.1:443"",                ""KUBERNETES_PORT_443_TCP=tcp://192.168.0.1:443"",                ""KUBERNETES_PORT_443_TCP_PROTO=tcp"",                ""KUBERNETES_PORT_443_TCP_PORT=443"",                ""KUBERNETES_PORT_443_TCP_ADDR=192.168.0.1"",                ""KUBERNETES_SERVICE_HOST=192.168.0.1"",                ""KUBERNETES_SERVICE_PORT=443"",                ""KUBERNETES_SERVICE_PORT_HTTPS=443"",                ""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"",                ""LANG=en_US.UTF-8"",                ""LANGUAGE=en_US.UTF-8"",                ""LC_CTYPE=en_US.UTF-8"",                ""LC_ALL=en_US.UTF-8"",                ""NGINX_CONFIG=/etc/nginx/nginx-static-site-react.conf""            ],            ""Cmd"": null,            ""Healthcheck"": {                ""Test"": [                    ""NONE""                ]            },                        ""Image"": ""docker-local-bcless-cat.art.domain.ss/bcless-cat/release/frontend@sha256:6ff6defe8f8ccb897d062580930da73229d1f307dc7ba4f39bcc6e9481b2d1c4"",            ""Volumes"": null,            ""WorkingDir"": ""/opt/app"",            ""Entrypoint"": [                ""/bin/sh"",                ""-c"",                ""/entrypoint""            ],            ""OnBuild"": null,            ""Labels"": {                ""annotation.io.kubernetes.container.hash"": ""5700b5a0"",                ""annotation.io.kubernetes.container.ports"": ""[{\""name\"":\""http\"",\""containerPort\"":80,\""protocol\"":\""TCP\""}]"",                ""annotation.io.kubernetes.container.restartCount"": ""0"",                ""annotation.io.kubernetes.container.terminationMessagePath"": ""/dev/termination-log"",                ""annotation.io.kubernetes.container.terminationMessagePolicy"": ""File"",                ""annotation.io.kubernetes.pod.terminationGracePeriod"": ""30"",                ""io.kubernetes.container.logpath"": ""/var/log/pods/bcless-cat_frontend-7845874cf4-vgc7g_52c02f25-26f0-4901-b637-cf33e6e93b25/frontend/0.log"",                ""io.kubernetes.container.name"": ""frontend"",                ""io.kubernetes.docker.type"": ""container"",                ""io.kubernetes.pod.name"": ""frontend-7845874cf4-vgc7g"",                ""io.kubernetes.pod.namespace"": ""bcless-cat"",                ""io.kubernetes.pod.uid"": ""52c02f25-26f0-4901-b637-cf33e6e93b25"",                ""io.kubernetes.sandbox.id"": ""3dad62e361069bd11362e05fe04c05d280517c37cc80f53e1a7b8c3275051393"",                ""lm.img-base-alpine.commit"": ""e58ff5c"",                ""lm.img-base-alpine.date"": ""2019-07-25 18:00:53 +0300"",            }        },        ""NetworkSettings"": {            ""Bridge"": """",            ""SandboxID"": """",            ""HairpinMode"": false,            ""LinkLocalIPv6Address"": """",            ""LinkLocalIPv6PrefixLen"": 0,            ""Ports"": {},            ""SandboxKey"": """",            ""SecondaryIPAddresses"": null,            ""SecondaryIPv6Addresses"": null,            ""EndpointID"": """",            ""Gateway"": """",            ""GlobalIPv6Address"": """",            ""GlobalIPv6PrefixLen"": 0,            ""IPAddress"": """",            ""IPPrefixLen"": 0,            ""IPv6Gateway"": """",            ""MacAddress"": """",            ""Networks"": {}        }    }]```That's where the logs of this container lie:```ls -lah /var/lib/docker/containers/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006/*-rw-r----- 1 root root 3.0M Feb 26 13:26 /var/lib/docker/containers/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006-json.log-rw-r----- 1 root root  92K Feb 13 06:24 /var/lib/docker/containers/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006-json.log-20200213-1581575101.gzcontainers/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006-json.log.1-rw-r----- 1 root root 9.6M Feb 22 05:08 /var/lib/docker/containers/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006-json.log.2-rw-r----- 1 root root 9.6M Feb 18 09:47 /var/lib/docker/containers/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006-json.log.3-rw-r----- 1 root root 9.6M Feb 14 16:35 /var/lib/docker/containers/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006-json.log.4-rw------- 1 root root 5.6K Jan 17 10:24 /var/lib/docker/containers/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006/config.v2.json-rw-r--r-- 1 root root 2.0K Jan 17 10:24 /var/lib/docker/containers/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006/hostconfig.json```If you look at the first record (with the help of hexdump) in the problematic log, you can see that there are some strange data at the very beginning of the log and then there are normal application logs:```head -n 1 /var/lib/docker/containers/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006/2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006-json.log | hexdump -C00000000  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|*001b6670  00 00 00 00 00 00 00 00  7b 22 6c 6f 67 22 3a 22  |........{""log"":""|001b6680  62 63 6c 65 73 73 2d 63  61 74 2d 73 68 61 72 65  |bcless-cat-share|001b6690  64 2e 61 70 70 73 2e 6c  6d 72 75 2e 74 65 63 68  |d.apps.domain.ss|001b66a0  20 31 30 2e 32 34 34 2e  33 2e 31 30 20 2d 20 2d  | 10.244.3.10 - -|001b66b0  20 5b 32 36 2f 46 65 62  2f 32 30 32 30 3a 30 39  | [26/Feb/2020:09|001b66c0  3a 32 35 3a 32 35 20 2b  30 33 30 30 5d 20 5c 22  |:25:25 +0300] \""|001b66d0  47 45 54 20 2f 3f 73 68  6f 70 5f 65 78 74 65 72  |GET /?shop_exter|001b66e0  6e 61 6c 5f 69 64 3d 32  34 5c 75 30 30 32 36 63  |nal_id=24\u0026c|001b66f0  61 73 68 62 6f 78 5f 69  64 3d 32 32 5c 75 30 30  |ashbox_id=22\u00|001b6700  32 36 63 61 73 68 69 65  72 5f 6c 64 61 70 3d 36  |26cashier_ldap=6|001b6710  30 30 31 39 32 36 35 20  48 54 54 50 2f 31 2e 31  |0019265 HTTP/1.1|001b6720  5c 22 20 32 30 30 20 32  36 39 39 20 5c 22 2d 5c  |\"" 200 2699 \""-\|001b6730  22 20 5c 22 4d 6f 7a 69  6c 6c 61 2f 34 2e 30 20  |"" \""Mozilla/4.0 |001b6740  28 63 6f 6d 70 61 74 69  62 6c 65 3b 20 4d 53 49  |(compatible; MSI|001b6750  45 20 37 2e 30 3b 20 57  69 6e 64 6f 77 73 20 4e  |E 7.0; Windows N|001b6760  54 20 36 2e 32 3b 20 57  4f 57 36 34 3b 20 54 72  |T 6.2; WOW64; Tr|001b6770  69 64 65 6e 74 2f 37 2e  30 3b 20 2e 4e 45 54 34  |ident/7.0; .NET4|001b6780  2e 30 43 3b 20 2e 4e 45  54 34 2e 30 45 3b 20 2e  |.0C; .NET4.0E; .|001b6790  4e 45 54 20 43 4c 52 20  32 2e 30 2e 35 30 37 32  |NET CLR 2.0.5072|001b67a0  37 3b 20 2e 4e 45 54 20  43 4c 52 20 33 2e 30 2e  |7; .NET CLR 3.0.|001b67b0  33 30 37 32 39 3b 20 2e  4e 45 54 20 43 4c 52 20  |30729; .NET CLR |001b67c0  33 2e 35 2e 33 30 37 32  39 29 5c 22 20 5c 22 31  |3.5.30729)\"" \""1|001b67d0  30 2e 38 31 2e 39 37 2e  32 32 5c 22 20 30 2e 30  |0.81.97.22\"" 0.0|001b67e0  30 30 20 2d 5c 6e 22 2c  22 73 74 72 65 61 6d 22  |00 -\n"",""stream""|001b67f0  3a 22 73 74 64 6f 75 74  22 2c 22 74 69 6d 65 22  |:""stdout"",""time""|001b6800  3a 22 32 30 32 30 2d 30  32 2d 32 36 54 30 36 3a  |:""2020-02-26T06:|001b6810  32 35 3a 32 35 2e 30 33  37 32 37 34 33 38 38 5a  |25:25.037274388Z|001b6820  22 7d 0a                                          |""}.|```If you look at the logs of another container where there is no such problem, you can see that there is no such data:``` head -n 1 /var/lib/docker/containers/ac96c58e1b8078b740796a0f698de6fdbe7499c76fcc23ecb0ab05dbd09ad7d6/ac96c58e1b8078b740796a0f698de6fdbe7499c76fcc23ecb0ab05dbd09ad7d6-json.log | hexdump -C00000000  7b 22 6c 6f 67 22 3a 22  62 63 6c 65 73 73 2d 63  |{""log"":""bcless-c|00000010  61 74 2d 73 68 61 72 65  64 2e 61 70 70 73 2e 6c  |at-shared.apps.l|00000020  6d 72 75 2e 74 65 63 68  20 31 30 2e 32 34 34 2e  |mru.tech 10.244.|00000030  33 2e 31 30 20 2d 20 2d  20 5b 32 36 2f 46 65 62  |3.10 - - [26/Feb|00000040  2f 32 30 32 30 3a 31 35  3a 33 34 3a 31 33 20 2b  |/2020:15:34:13 +|00000050  30 33 30 30 5d 20 5c 22  47 45 54 20 2f 6c 6f 67  |0300] \""GET /log|00000060  69 6e 2f 20 48 54 54 50  2f 31 2e 31 5c 22 20 32  |in/ HTTP/1.1\"" 2|00000070  30 30 20 34 32 39 36 20  5c 22 68 74 74 70 73 3a  |00 4296 \""https:|00000080  2f 2f 62 63 6c 65 73 73  2d 63 61 74 2d 73 68 61  |//bcless-cat-sha|00000090  72 65 64 2e 61 70 70 73  2e 6c 6d 72 75 2e 74 65  |red.apps.domain.|000000a0  63 68 2f 5c 22 20 5c 22  4d 6f 7a 69 6c 6c 61 2f  |ch/\"" \""Mozilla/|000000b0  35 2e 30 20 28 57 69 6e  64 6f 77 73 20 4e 54 20  |5.0 (Windows NT |000000c0  31 30 2e 30 3b 20 57 69  6e 36 34 3b 20 78 36 34  |10.0; Win64; x64|000000d0  29 20 41 70 70 6c 65 57  65 62 4b 69 74 2f 35 33  |) AppleWebKit/53|000000e0  37 2e 33 36 20 28 4b 48  54 4d 4c 2c 20 6c 69 6b  |7.36 (KHTML, lik|000000f0  65 20 47 65 63 6b 6f 29  20 43 68 72 6f 6d 65 2f  |e Gecko) Chrome/|00000100  37 38 2e 30 2e 33 39 30  34 2e 39 37 20 53 61 66  |78.0.3904.97 Saf|00000110  61 72 69 2f 35 33 37 2e  33 36 5c 22 20 5c 22 31  |ari/537.36\"" \""1|00000120  30 2e 38 30 2e 31 34 36  2e 31 36 36 5c 22 20 30  |0.80.146.166\"" 0|00000130  2e 30 30 30 20 2d 5c 6e  22 2c 22 73 74 72 65 61  |.000 -\n"",""strea|00000140  6d 22 3a 22 73 74 64 6f  75 74 22 2c 22 74 69 6d  |m"":""stdout"",""tim|00000150  65 22 3a 22 32 30 32 30  2d 30 32 2d 32 36 54 31  |e"":""2020-02-26T1|00000160  32 3a 33 34 3a 31 33 2e  33 35 30 36 30 37 36 33  |2:34:13.35060763|00000170  35 5a 22 7d 0a                                    |5Z""}.|``` In this case the command docker logs works correctly and does not output ""broken"" data: ``` docker logs 2d8e3bbf87a6431bfb08e90572a572a9c15d388f9916b2c233403f73de763006 | head -n 1bcless-cat-shared.apps.domain.ss 10.244.3.10 - - [14/Feb/2020:10:14:17 +0300] ""GET /static/js/2.c153bfa3.chunk.js HTTP/1.1"" 200 943454 ""https://bcless-cat-shared.apps.domain.ss/client?shop_external_id=19&cashbox_id=18&cashier_ldap=60026933"" ""Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.2; WOW64; Trident/7.0; .NET4.0C; .NET4.0E; .NET CLR 2.0.50727; .NET CLR 3.0.30729; .NET CLR 3.5.30729)"" ""10.81.77.18"" 0.000 -``` There is a feeling that some problem occurs during log rotation with docker logs and docker logs can just ignore these zeros, but kubectl does not.  How can zeros be called at the beginning of a log? **Steps to reproduce the issue:**1. Configure the rotation of json logs in docker2. Roll out the application that actively writes logs3. Wait**Describe the results you received:**There are bad data at the beginning of the log.**Describe the results you expected:**There should be no entries in the files with container logs except JSON**Additional information you deem important (e.g. issue happens only occasionally):**daemon.json configuration file:```{        ""log-driver"": ""json-file"",        ""log-opts"": {                ""max-file"": ""5"",                ""max-size"": ""10m""        }}```OS Kernel:```Linux p-shared-ks-node-76b52164-76744fc799-th5lw 5.0.0-36-generic #39~18.04.1-Ubuntu SMP Tue Nov 12 11:09:50 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux```OS:```No LSB modules are available.Distributor ID: UbuntuDescription:    Ubuntu 18.04.3 LTSRelease:        18.04Codename:       bionic```**Output of `docker version`:**```Client: Version:           18.09.7 API version:       1.39 Go version:        go1.10.1 Git commit:        2d0083d Built:             Fri Aug 16 14:20:06 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          18.09.7  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.1  Git commit:       2d0083d  Built:            Wed Aug 14 19:41:23 2019  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 93 Running: 87 Paused: 0 Stopped: 6Images: 45Server Version: 18.09.7Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version:runc version: N/Ainit version: v0.18.0 (expected: fec3683b971d9c3ef73f284f176672c44b448662)Security Options: apparmor seccomp  Profile: defaultKernel Version: 5.0.0-36-genericOperating System: Ubuntu 18.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 15.66GiBName: p-shared-ks-node-76b52164-76744fc799-th5lwID: D4E2:V366:3R3L:DK35:JUSW:LSKX:TBN4:S25Z:NIEZ:E7MN:JDQ6:MUFMDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**vmware vSphere host
"
40573,1,125781,2,0,0,SvenDowideit,0,"title:Docker 19.03.6 crash. description:single node swarm that is active, but down:```dow184@gitonaim:~$ docker node lsID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSIONpq3qo4m03mb7sjvzhpr761kjm *   gitonaim            Down                Active              Leader              19.03.6``````Feb 25 12:27:20 gitonaim systemd[1]: Stopping Docker Application Container Engine...Feb 25 12:27:20 gitonaim dockerd[1343]: time=""2020-02-25T12:27:20.589921083+11:00"" level=info msg=""Processing signal 'terminated'""Feb 25 12:27:35 gitonaim dockerd[1343]: time=""2020-02-25T12:27:35.590896988+11:00"" level=error msg=""agent failed to clean up assignments"" error=""context deadline exceeded""Feb 25 12:27:35 gitonaim dockerd[1343]: time=""2020-02-25T12:27:35.590982567+11:00"" level=error msg=""failed to shut down cluster node: context deadline exceeded""Feb 25 12:27:35 gitonaim dockerd[1343]: time=""2020-02-25T12:27:35.654518369+11:00"" level=info msg=""Stopping manager"" module=node node.id=pq3qo4m03mb7sjvzhpr761kjmFeb 25 12:27:35 gitonaim dockerd[1343]: time=""2020-02-25T12:27:35.654594916+11:00"" level=info msg=""shutting down certificate renewal routine"" module=node/tls node.id=pq3qo4m03mb7sjvzhpr761kjm node.role=swarm-managerFeb 25 12:27:35 gitonaim dockerd[1343]: time=""2020-02-25T12:27:35.654632739+11:00"" level=info msg=""dispatcher stopping"" method=""(*Dispatcher).Stop"" module=dispatcher node.id=pq3qo4m03mb7sjvzhpr761kjmFeb 25 12:27:35 gitonaim dockerd[1343]: goroutine 1 [running]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/pkg/signal.DumpStacks(0x0, 0x0, 0x0, 0x0, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/pkg/signal/trap.go:83 +0x97Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/daemon/cluster.(*Cluster).Cleanup(0xc001a166c0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/daemon/cluster/cluster.go:392 +0x272Feb 25 12:27:35 gitonaim dockerd[1343]: main.(*DaemonCli).start(0xc000679380, 0xc000773500, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/cmd/dockerd/daemon.go:260 +0xcf0Feb 25 12:27:35 gitonaim dockerd[1343]: main.runDaemon(...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/cmd/dockerd/docker_unix.go:13Feb 25 12:27:35 gitonaim dockerd[1343]: main.newDaemonCommand.func1(0xc00075ea00, 0xc000679320, 0x0, 0x3, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/cmd/dockerd/docker.go:34 +0x7dFeb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).execute(0xc00075ea00, 0xc00004e0d0, 0x3, 0x3, 0xc00075ea00, 0xc00004e0d0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:762 +0x467Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc00075ea00, 0x0, 0x0, 0x10)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:852 +0x2eeFeb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).Execute(...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:800Feb 25 12:27:35 gitonaim dockerd[1343]: main.main()Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/cmd/dockerd/docker.go:97 +0x191Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 5 [syscall]:Feb 25 12:27:35 gitonaim dockerd[1343]: os/signal.signal_recv(0x55edb6b13ae0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/runtime/sigqueue.go:139 +0x9eFeb 25 12:27:35 gitonaim dockerd[1343]: os/signal.loop()Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/os/signal/signal_unix.go:23 +0x24Feb 25 12:27:35 gitonaim dockerd[1343]: created by os/signal.init.0Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/os/signal/signal_unix.go:29 +0x43Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 57 [select]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/go.opencensus.io/stats/view.(*worker).start(0xc0001c6d80)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/go.opencensus.io/stats/view/worker.go:144 +0xdfFeb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/go.opencensus.io/stats/view.init.0Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/go.opencensus.io/stats/view/worker.go:29 +0x59Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 41 [select, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: io.(*pipe).Read(0xc0000e0be0, 0xc00078a000, 0x1000, 0x1000, 0x55edb664cae0, 0xc00006a601, 0xc00078a000)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/io/pipe.go:50 +0xe9Feb 25 12:27:35 gitonaim dockerd[1343]: io.(*PipeReader).Read(0xc000010588, 0xc00078a000, 0x1000, 0x1000, 0xc00006a648, 0x55edb40be757, 0x55edb40e8dce)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/io/pipe.go:127 +0x4eFeb 25 12:27:35 gitonaim dockerd[1343]: bufio.(*Scanner).Scan(0xc00084ef38, 0xc0000aec60)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/bufio/scan.go:213 +0xa6Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/github.com/sirupsen/logrus.(*Entry).writerScanner(0xc000148310, 0xc000010588, 0xc00076e3b0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/sirupsen/logrus/writer.go:53 +0xc6Feb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/github.com/sirupsen/logrus.(*Entry).WriterLevelFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/sirupsen/logrus/writer.go:45 +0x1a8Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 65 [chan receive]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/pkg/signal.Trap.func1(0xc000773c20, 0x55edb6ae1e60, 0xc0000962a0, 0xc0007b2fc0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/pkg/signal/trap.go:38 +0x5dFeb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/pkg/signal.TrapFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/pkg/signal/trap.go:36 +0x120Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 26 [IO wait, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.runtime_pollWait(0x7effb7fa3d68, 0x72, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/runtime/netpoll.go:182 +0x58Feb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.(*pollDesc).wait(0xc000356118, 0x72, 0x0, 0x0, 0x55edb5a13b04)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/internal/poll/fd_poll_runtime.go:87 +0x9dFeb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.(*pollDesc).waitRead(...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/internal/poll/fd_poll_runtime.go:92Feb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.(*FD).Accept(0xc000356100, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/internal/poll/fd_unix.go:384 +0x1bcFeb 25 12:27:35 gitonaim dockerd[1343]: net.(*netFD).accept(0xc000356100, 0xc000070700, 0x7effb7fff6d0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/net/fd_unix.go:238 +0x44Feb 25 12:27:35 gitonaim dockerd[1343]: net.(*UnixListener).accept(0xc0006808a0, 0xc00007de88, 0x55edb40c58da, 0x30)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/net/unixsock_posix.go:162 +0x34Feb 25 12:27:35 gitonaim dockerd[1343]: net.(*UnixListener).Accept(0xc0006808a0, 0x55edb690f700, 0xc000679d40, 0x55edb670ba60, 0x55edb7eaf080)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/net/unixsock.go:260 +0x4aFeb 25 12:27:35 gitonaim dockerd[1343]: net/http.(*Server).Serve(0xc000779a00, 0x55edb6b2a0e0, 0xc0006808a0, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/net/http/server.go:2859 +0x22fFeb 25 12:27:35 gitonaim dockerd[1343]: net/http.Serve(...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/net/http/server.go:2456Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/daemon.(*Daemon).listenMetricsSock.func1(0x55edb6b2a0e0, 0xc0006808a0, 0xc000302280)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/daemon/metrics_unix.go:31 +0x6fFeb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/daemon.(*Daemon).listenMetricsSockFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/daemon/metrics_unix.go:30 +0x1f6Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 67 [chan receive, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/daemon.(*Daemon).setupDumpStackTrap.func1(0xc000744300, 0x55edb5a222fe, 0xf)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/daemon/debugtrap_unix.go:18 +0x43Feb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/daemon.(*Daemon).setupDumpStackTrapFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/daemon/debugtrap_unix.go:17 +0xc1Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 28 [select, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc.(*ccBalancerWrapper).watcher(0xc000302540)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/balancer_conn_wrappers.go:115 +0x12fFeb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/google.golang.org/grpc.newCCBalancerWrapperFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/balancer_conn_wrappers.go:106 +0x16cFeb 25 12:27:35 gitonaim dockerd[1343]: goroutine 29 [chan receive, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc.(*addrConn).resetTransport(0xc000852000)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:1077 +0x5d3Feb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/google.golang.org/grpc.(*addrConn).connectFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:743 +0xb8Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 84 [IO wait, 7 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.runtime_pollWait(0x7effb7fa3c98, 0x72, 0xffffffffffffffff)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/runtime/netpoll.go:182 +0x58Feb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.(*pollDesc).wait(0xc00086e098, 0x72, 0x8000, 0x8000, 0xffffffffffffffff)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/internal/poll/fd_poll_runtime.go:87 +0x9dFeb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.(*pollDesc).waitRead(...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/internal/poll/fd_poll_runtime.go:92Feb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.(*FD).Read(0xc00086e080, 0xc000872000, 0x8000, 0x8000, 0x0, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/internal/poll/fd_unix.go:169 +0x19dFeb 25 12:27:35 gitonaim dockerd[1343]: net.(*netFD).Read(0xc00086e080, 0xc000872000, 0x8000, 0x8000, 0x0, 0x800010601, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/net/fd_unix.go:202 +0x51Feb 25 12:27:35 gitonaim dockerd[1343]: net.(*conn).Read(0xc000862008, 0xc000872000, 0x8000, 0x8000, 0x0, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/net/net.go:177 +0x6bFeb 25 12:27:35 gitonaim dockerd[1343]: bufio.(*Reader).Read(0xc0007d8240, 0xc0008aa038, 0x9, 0x9, 0xc000172380, 0x7effb7fffd98, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/bufio/bufio.go:223 +0x240Feb 25 12:27:35 gitonaim dockerd[1343]: io.ReadAtLeast(0x55edb6adf2e0, 0xc0007d8240, 0xc0008aa038, 0x9, 0x9, 0x9, 0x55edb46fb3a7, 0xc00636918c, 0xc000081e38)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/io/io.go:310 +0x8aFeb 25 12:27:35 gitonaim dockerd[1343]: io.ReadFull(...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/io/io.go:329Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/golang.org/x/net/http2.readFrameHeader(0xc0008aa038, 0x9, 0x9, 0x55edb6adf2e0, 0xc0007d8240, 0x0, 0xc000000000, 0x2e4e88d9456, 0x55edb7f2e660)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:237 +0x8aFeb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/golang.org/x/net/http2.(*Framer).ReadFrame(0xc0008aa000, 0xc006369180, 0xc006369180, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:492 +0xa3Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.(*http2Client).reader(0xc0008b0000)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/http2_client.go:1249 +0x182Feb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.newHTTP2ClientFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/http2_client.go:289 +0xd44Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 85 [select, 7 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.(*controlBuffer).get(0xc000860190, 0x1, 0x0, 0x0, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/controlbuf.go:395 +0x109Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.(*loopyWriter).run(0xc0007d8360, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/controlbuf.go:513 +0x1b8Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.newHTTP2Client.func3(0xc0008b0000)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/http2_client.go:333 +0x7dFeb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.newHTTP2ClientFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/http2_client.go:331 +0xee1Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 86 [select, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc.(*ccBalancerWrapper).watcher(0xc00004fb80)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/balancer_conn_wrappers.go:115 +0x12fFeb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/google.golang.org/grpc.newCCBalancerWrapperFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/balancer_conn_wrappers.go:106 +0x16cFeb 25 12:27:35 gitonaim dockerd[1343]: goroutine 87 [chan receive, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc.(*addrConn).resetTransport(0xc0000ec000)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:1077 +0x5d3Feb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/google.golang.org/grpc.(*addrConn).connectFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:743 +0xb8Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 89 [IO wait, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.runtime_pollWait(0x7effb7fa3bc8, 0x72, 0xffffffffffffffff)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/runtime/netpoll.go:182 +0x58Feb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.(*pollDesc).wait(0xc000356218, 0x72, 0x8000, 0x8000, 0xffffffffffffffff)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/internal/poll/fd_poll_runtime.go:87 +0x9dFeb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.(*pollDesc).waitRead(...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/internal/poll/fd_poll_runtime.go:92Feb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.(*FD).Read(0xc000356200, 0xc00087a000, 0x8000, 0x8000, 0x0, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/internal/poll/fd_unix.go:169 +0x19dFeb 25 12:27:35 gitonaim dockerd[1343]: net.(*netFD).Read(0xc000356200, 0xc00087a000, 0x8000, 0x8000, 0x0, 0x800010601, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/net/fd_unix.go:202 +0x51Feb 25 12:27:35 gitonaim dockerd[1343]: net.(*conn).Read(0xc000682120, 0xc00087a000, 0x8000, 0x8000, 0x0, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/net/net.go:177 +0x6bFeb 25 12:27:35 gitonaim dockerd[1343]: bufio.(*Reader).Read(0xc000096720, 0xc00039c2d8, 0x9, 0x9, 0xc000716700, 0x7effb7fff008, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/bufio/bufio.go:223 +0x240Feb 25 12:27:35 gitonaim dockerd[1343]: io.ReadAtLeast(0x55edb6adf2e0, 0xc000096720, 0xc00039c2d8, 0x9, 0x9, 0x9, 0x55edb46fb3a7, 0xc0002183ac, 0xc00007be38)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/io/io.go:310 +0x8aFeb 25 12:27:35 gitonaim dockerd[1343]: io.ReadFull(...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/io/io.go:329Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/golang.org/x/net/http2.readFrameHeader(0xc00039c2d8, 0x9, 0x9, 0x55edb6adf2e0, 0xc000096720, 0x0, 0xc000000000, 0xab5f2f06c, 0x55edb7f2e660)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:237 +0x8aFeb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/golang.org/x/net/http2.(*Framer).ReadFrame(0xc00039c2a0, 0xc0002183a0, 0xc0002183a0, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:492 +0xa3Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.(*http2Client).reader(0xc0001548c0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/http2_client.go:1249 +0x182Feb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.newHTTP2ClientFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/http2_client.go:289 +0xd44Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 90 [select, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.(*controlBuffer).get(0xc0002aaa50, 0x1, 0x0, 0x0, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/controlbuf.go:395 +0x109Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.(*loopyWriter).run(0xc000096840, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/controlbuf.go:513 +0x1b8Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.newHTTP2Client.func3(0xc0001548c0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/http2_client.go:333 +0x7dFeb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.newHTTP2ClientFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/http2_client.go:331 +0xee1Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 91 [select, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/libcontainerd/remote.(*client).processEventStream(0xc0000968a0, 0x55edb6b3afa0, 0xc00018eb80, 0x55edb5a1dc74, 0xc)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/libcontainerd/remote/client.go:700 +0x2acFeb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/libcontainerd/remote.NewClientFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/libcontainerd/remote/client.go:67 +0x26aFeb 25 12:27:35 gitonaim dockerd[1343]: goroutine 30 [select, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc.newClientStream.func5(0xc000398a80, 0xc0007f6120, 0x55edb6b3b060, 0xc00066e7b0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:319 +0xd9Feb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/google.golang.org/grpc.newClientStreamFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:318 +0x993Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 31 [select, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.(*recvBufferReader).readClient(0xc0001ba0f0, 0xc00028a210, 0x5, 0x5, 0xc000716700, 0xc00084c958, 0x55edb40e6593)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/transport.go:185 +0xd6Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.(*recvBufferReader).Read(0xc0001ba0f0, 0xc00028a210, 0x5, 0x5, 0x55edb6aa0608, 0xc000058200, 0xc00084c9d8)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/transport.go:165 +0x19aFeb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.(*transportReader).Read(0xc00066e870, 0xc00028a210, 0x5, 0x5, 0xc00084ca94, 0xc00084ca00, 0x55edb473ecfe)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/transport.go:488 +0x57Feb 25 12:27:35 gitonaim dockerd[1343]: io.ReadAtLeast(0x55edb6ae2ac0, 0xc00066e870, 0xc00028a210, 0x5, 0x5, 0x5, 0x55edb41eeece, 0xc00066e7b0, 0xc00074e360)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/io/io.go:310 +0x8aFeb 25 12:27:35 gitonaim dockerd[1343]: io.ReadFull(...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/io/io.go:329Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport.(*Stream).Read(0xc000676100, 0xc00028a210, 0x5, 0x5, 0x55edb69a3400, 0x7effb7fb62e8, 0xc00074e360)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/internal/transport/transport.go:472 +0xcaFeb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc.(*parser).recvMsg(0xc00028a200, 0x1000000, 0x90, 0x90, 0x0, 0x0, 0x7effb7fb62b8, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/rpc_util.go:508 +0x65Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc.recvAndDecompress(0xc00028a200, 0xc000676100, 0x0, 0x0, 0x1000000, 0x0, 0x0, 0x0, 0xc000404000, 0x90, ...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/rpc_util.go:639 +0x4fFeb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc.recv(0xc00028a200, 0x7effb7f67380, 0x55edb7f4e878, 0xc000676100, 0x0, 0x0, 0x55edb69a3400, 0xc0007441e0, 0x1000000, 0x0, ...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/rpc_util.go:684 +0x9dFeb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc.(*csAttempt).recvMsg(0xc000050080, 0x55edb69a3400, 0xc0007441e0, 0x0, 0xc00084cd70, 0xc0007441e0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:885 +0xefFeb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc.(*clientStream).RecvMsg.func1(0xc000050080, 0x55edb40be63e, 0x203000)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:736 +0x48Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc.(*clientStream).withRetry(0xc0007f6120, 0xc00084ce60, 0xc00084ce50, 0x1, 0x48)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:590 +0x2a1Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/google.golang.org/grpc.(*clientStream).RecvMsg(0xc0007f6120, 0x55edb69a3400, 0xc0007441e0, 0xc00084cf24, 0x2)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:735 +0x102Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/github.com/containerd/containerd/api/services/events/v1.(*eventsSubscribeClient).Recv(0xc0007700b0, 0xc00084cf20, 0x2, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/containerd/containerd/api/services/events/v1/events.pb.go:351 +0x64Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/github.com/containerd/containerd.(*eventRemote).Subscribe.func1(0xc00028c480, 0x55edb6b5cb80, 0xc0007700b0, 0xc00074e180, 0x55edb6b3afa0, 0xc00018eb80)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/containerd/containerd/events.go:99 +0x82Feb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/github.com/containerd/containerd.(*eventRemote).SubscribeFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/containerd/containerd/events.go:95 +0x1ccFeb 25 12:27:35 gitonaim dockerd[1343]: goroutine 797 [sync.Cond.Wait, 58 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: runtime.goparkunlock(...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/runtime/proc.go:307Feb 25 12:27:35 gitonaim dockerd[1343]: sync.runtime_notifyListWait(0xc0017337d0, 0x55ed00000001)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/runtime/sema.go:510 +0xfdFeb 25 12:27:35 gitonaim dockerd[1343]: sync.(*Cond).Wait(0xc0017337c0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/sync/cond.go:56 +0xa0Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/pkg/ioutils.(*BytesPipe).Read(0xc001733780, 0xc001736008, 0x800, 0x3ff8, 0xffffffffffffffff, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/pkg/ioutils/bytespipe.go:134 +0x26dFeb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/daemon/logger.(*Copier).copySrc(0xc001733880, 0x55edb5a12ba8, 0x6, 0x7effb7eded58, 0xc001733780)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/daemon/logger/copier.go:81 +0x915Feb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/daemon/logger.(*Copier).RunFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/daemon/logger/copier.go:48 +0x111Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 42 [select, 58 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: io.(*pipe).Read(0xc0000e0c30, 0xc00078e692, 0x96e, 0x96e, 0x0, 0x0, 0x0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/io/pipe.go:50 +0xe9Feb 25 12:27:35 gitonaim dockerd[1343]: io.(*PipeReader).Read(0xc000010598, 0xc00078e692, 0x96e, 0x96e, 0x0, 0xc000000002, 0xc0016f7570)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/io/pipe.go:127 +0x4eFeb 25 12:27:35 gitonaim dockerd[1343]: bufio.(*Scanner).Scan(0xc00153df38, 0x1)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/bufio/scan.go:213 +0xa6Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/github.com/sirupsen/logrus.(*Entry).writerScanner(0xc000148380, 0xc000010598, 0xc00076e3c0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/sirupsen/logrus/writer.go:53 +0xc6Feb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/github.com/sirupsen/logrus.(*Entry).WriterLevelFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/sirupsen/logrus/writer.go:45 +0x1a8Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 1096 [chan receive]:Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/github.com/docker/swarmkit/manager.(*Manager).Stop(0xc00083e340, 0x55edb6b3b060, 0xc0019e4900, 0xc001103c00)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/manager.go:704 +0x341Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/github.com/docker/swarmkit/node.(*Node).runManager.func2(0xc0007fec30, 0xc00083e340, 0x55edb6b3b060, 0xc0019e4900, 0xc001103c7f, 0xc001afd500)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/node/node.go:1048 +0x83Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/github.com/docker/swarmkit/node.(*Node).runManager(0xc0007fec30, 0x55edb6b3b060, 0xc0019e4900, 0xc00161e8c0, 0xc0012e2c40, 0x34, 0xc0012e2c80, 0x34, 0xc000692cc0, 0xc00192a540, ...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/node/node.go:1090 +0x5b2Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/github.com/docker/swarmkit/node.(*Node).superviseManager(0xc0007fec30, 0x55edb6b3b060, 0xc0019e4900, 0xc00161e8c0, 0xc0012e2c40, 0x34, 0xc0012e2c80, 0x34, 0xc000692cc0, 0xc00161e910, ...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/node/node.go:1122 +0x1a9Feb 25 12:27:35 gitonaim dockerd[1343]: github.com/docker/docker/vendor/github.com/docker/swarmkit/node.(*Node).run.func5(0xc0007fec30, 0x55edb6b3b060, 0xc0019e4900, 0xc00161e8c0, 0xc001702b00, 0xc000692cc0, 0xc00161e910, 0xc0012e7d70, 0xc001620670, 0xc001187ab0)Feb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/node/node.go:483 +0x9bFeb 25 12:27:35 gitonaim dockerd[1343]: created by github.com/docker/docker/vendor/github.com/docker/swarmkit/node.(*Node).runFeb 25 12:27:35 gitonaim dockerd[1343]:         /go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/node/node.go:481 +0xa28Feb 25 12:27:35 gitonaim dockerd[1343]: goroutine 100 [IO wait, 60 minutes]:Feb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.runtime_pollWait(0x7effb7fa3af8, 0x72, 0xffffffffffffffff)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/runtime/netpoll.go:182 +0x58Feb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.(*pollDesc).wait(0xc000744018, 0x72, 0x8001, 0x8000, 0xffffffffffffffff)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/internal/poll/fd_poll_runtime.go:87 +0x9dFeb 25 12:27:35 gitonaim dockerd[1343]: internal/poll.(*pollDesc).waitRead(...)Feb 25 12:27:35 gitonaim dockerd[1343]:         /usr/local/go/src/internal/poll/fd_p"
40550,1,3529,1,0,0,hacker-h,0,"title:single digit volume name leads to 'panic: runtime error: index out of range'. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Mounting a docker volume fails if its name is a single digit.**Steps to reproduce the issue:**1. Run `docker run -it --rm -v 1:/1 alpine`**Describe the results you received:**```panic: runtime error: index out of rangegoroutine 1 [running]:github.com/docker/cli/cli/compose/loader.isFilePath(0xc42027e058, 0x1, 0x557dcb978c20)	/build/docker.io-4PLKn6/docker.io-18.09.7/.gopath/src/github.com/docker/cli/cli/compose/loader/volume.go:121 +0x11cgithub.com/docker/cli/cli/compose/loader.populateType(0xc4202ef200)	/build/docker.io-4PLKn6/docker.io-18.09.7/.gopath/src/github.com/docker/cli/cli/compose/loader/volume.go:102 +0x77github.com/docker/cli/cli/compose/loader.ParseVolume(0x7fff5f223efd, 0x4, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...)	/build/docker.io-4PLKn6/docker.io-18.09.7/.gopath/src/github.com/docker/cli/cli/compose/loader/volume.go:44 +0x41dgithub.com/docker/cli/cli/command/container.parse(0xc420540600, 0xc420414000, 0xc4202efb98, 0x0, 0x0)	/build/docker.io-4PLKn6/docker.io-18.09.7/.gopath/src/github.com/docker/cli/cli/command/container/opts.go:336 +0x2begithub.com/docker/cli/cli/command/container.runRun(0x557dcae82cc0, 0xc4205098c0, 0xc420540600, 0xc420337f00, 0xc420414000, 0x557dcae543a0, 0x557dc92e7cc0)	/build/docker.io-4PLKn6/docker.io-18.09.7/.gopath/src/github.com/docker/cli/cli/command/container/run.go:111 +0x481github.com/docker/cli/cli/command/container.NewRunCommand.func1(0xc420421b80, 0xc4200d0500, 0x1, 0x5, 0x0, 0x0)	/build/docker.io-4PLKn6/docker.io-18.09.7/.gopath/src/github.com/docker/cli/cli/command/container/run.go:48 +0x11egithub.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).execute(0xc420421b80, 0xc4200d4020, 0x5, 0x5, 0xc420421b80, 0xc4200d4020)	/build/docker.io-4PLKn6/docker.io-18.09.7/.gopath/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:762 +0x46agithub.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc42033a280, 0xc4205b7e00, 0x557dcab3caa0, 0xc4205b7e10)	/build/docker.io-4PLKn6/docker.io-18.09.7/.gopath/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:852 +0x30cgithub.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).Execute(0xc42033a280, 0xc42033a280, 0x557dcae43c00)	/build/docker.io-4PLKn6/docker.io-18.09.7/.gopath/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:800 +0x2dmain.main()	/build/docker.io-4PLKn6/docker.io-18.09.7/.gopath/src/github.com/docker/cli/cmd/docker/docker.go:180 +0xde```**Describe the results you expected:**Docker/moby should not crash.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Docker version 18.09.7, build 2d0083d```**Output of `docker info`:**```Containers: 19 Running: 19 Paused: 0 Stopped: 0Images: 22Server Version: 18.09.7Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: runc version: N/Ainit version: v0.18.0 (expected: fec3683b971d9c3ef73f284f176672c44b448662)Security Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-135-genericOperating System: Ubuntu 16.04.6 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 15.67GiBName: infrastructure-mature-goatID: 2FNS:W4TS:3HOL:52UA:D4RR:F774:AGH7:ITXO:QOPY:KMOT:5A3S:JT6PDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Virtual Machine (OpenStack)Ubuntu 16.04.6 LTS
"
40514,1,3292,2,0,0,sereysethy,0,"title:docker run/build using echo commands hangs forever, centos 7. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Running `echo` during build or run an image, it hangs forever. And docker engine is stopped.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**```shell$ docker run hello-worldUnable to find image 'hello-world:latest' locallylatest: Pulling from library/hello-world1b930d010525: Pull complete Digest: sha256:9572f7cdcee8591948c2963463447a53466950b3fc15a247fcad1917ca215a2fStatus: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the ""hello-world"" image from the Docker Hub.    (amd64) 3. The Docker daemon created a new container from that image which runs the    executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it    to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/^C^C^C^C^C^Cc^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C```**Describe the results you received:**The container did not stop or build process did not finish. In the example I only use docker run, but docker build has the same problem.**Describe the results you expected:**The container should stop or build process should have succeeded**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```$ docker versionClient: Docker Engine - Community Version:           19.03.6 API version:       1.40 Go version:        go1.12.16 Git commit:        369ce74a3c Built:             Thu Feb 13 01:29:29 2020 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.6  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.16  Git commit:       369ce74a3c  Built:            Thu Feb 13 01:28:07 2020  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.12  GitCommit:        35bd7a5f69c13e1563af8a93431411cd9ecf5021 runc:  Version:          1.0.0-rc10  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 8  Running: 2  Paused: 0  Stopped: 6 Images: 182 Server Version: 19.03.6 Storage Driver: overlay  Backing Filesystem: extfs  Supports d_type: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 35bd7a5f69c13e1563af8a93431411cd9ecf5021 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 3.10.0-1062.12.1.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 1 Total Memory: 1.795GiB Name: XXXXXXXX ID: XXXXXXXX Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: bridge-nf-call-ip6tables is disabledWARNING: the overlay storage-driver is deprecated, and will be removed in a future release.```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
40459,0,0,247,1,0,AkihiroSuda,0,"title:`make binary` doesn't build `bundles/binary-daemon/vpnkit`. description:https://master.dockerproject.org was restarted a couple of days ago (https://github.com/moby/moby/issues/40378), but seems lacking vpnkit binary.Originally reported in https://github.com/docker/docker-install/issues/151#issuecomment-581270956
"
40405,0,3961,200,0,0,thaJeztah,0,"title:docker ps --filter publish=... filters on wrong values. description:The `publish` filter looks to be filtering on the wrong values (and the `TestPsListContainersFilterPorts ` is incorrect); see https://github.com/moby/moby/pull/27557#issuecomment-578016663Create some containers;```bashdocker run -d --name test_no_ports nginx:alpinedocker run -d --name test_port_1080 -p 1080:80 nginx:alpinedocker run -d --name test_port_1090 -p 1090:80 nginx:alpinedocker run -d --name test_port_80_random -p 80 nginx:alpinedocker run -d --name test_port_all_random -P nginx:alpinedocker ps --filter name=test_CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                   NAMES3ce8232cdd04        nginx:alpine        ""nginx -g 'daemon of闂?   6 seconds ago       Up 6 seconds        0.0.0.0:32775->80/tcp   test_port_all_random7f8fad7a0eb9        nginx:alpine        """"nginx -g 'daemon of闂?""   7 seconds ago       Up 6 seconds        0.0.0.0:32774->80/tcp   test_port_80_random3870ccc2f8f7        nginx:alpine        """"nginx -g 'daemon of闂?""   7 seconds ago       Up 6 seconds        0.0.0.0:1090->80/tcp    test_port_1090aa565211513e        nginx:alpine        """"nginx -g 'daemon of闂?""   8 seconds ago       Up 7 seconds        0.0.0.0:1080->80/tcp    test_port_1080c4a1c6e0e99b        nginx:alpine        """"nginx -g 'daemon of闂?""   8 seconds ago       Up 7 seconds        80/tcp                  test_no_ports```Filtering on the """"exposed"""" port works:```bashdocker ps --filter name=test_ --filter expose=80CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                   NAMES3ce8232cdd04        nginx:alpine        """"nginx -g 'daemon of闂?""   20 seconds ago      Up 19 seconds       0.0.0.0:32775->80/tcp   test_port_all_random7f8fad7a0eb9        nginx:alpine        """"nginx -g 'daemon of闂?""   21 seconds ago      Up 20 seconds       0.0.0.0:32774->80/tcp   test_port_80_random3870ccc2f8f7        nginx:alpine        """"nginx -g 'daemon of闂?""   21 seconds ago      Up 20 seconds       0.0.0.0:1090->80/tcp    test_port_1090aa565211513e        nginx:alpine        """"nginx -g 'daemon of闂?""   22 seconds ago      Up 20 seconds       0.0.0.0:1080->80/tcp    test_port_1080c4a1c6e0e99b        nginx:alpine        """"nginx -g 'daemon of闂?""   22 seconds ago      Up 21 seconds       80/tcp                  test_no_portsdocker ps --filter name=test_ --filter expose=90CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES```Filtering on the """"published"""" port doesn't (trying some variations below):```bashdocker ps --filter name=test_ --filter publish=1080CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                 NAMEdocker ps --filter name=test_ --filter publish=1080/tcpCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                 NAMESdocker ps --filter name=test_ --filter publish=1080/udpCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                 NAMES```However"
40258,0,2065,21,0,0,Caligatio,0,"title:Rootless Docker/containerd leaks file descriptors. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**It appears that rootless Docker, specifically the containerd process, leaks at least one file descriptor per container that is run.  We're attempting to use rootless Docker as our Gitlab CI back-end so this is problematic as the daemon is long lived.**Steps to reproduce the issue:**1. `dockerd-rootless.sh --experimental --storage-driver=vfs`2. Find your containerd PID: `ps aux | grep [c]ontainerd` (using 4464 as the example)3. `ls -l /proc/4464/fd/ | wc -l`  (usually something around 12)4. `docker -H unix:///run/user/$UID/docker.sock run -ti alpine true`5. `ls -l /proc/4464/fd/ | wc -l` is larger than the value from step 3.  The offending FD looks like `anon_inode:[eventfd]`**Describe the results you received:**The file descriptor count should not change after a container has run then exited**Describe the results you expected:**The file descriptor count increases**Additional information you deem important (e.g. issue happens only occasionally):**N/A**Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.5 API version:       1.40 Go version:        go1.12.12 Git commit:        633a0ea Built:             Wed Nov 13 07:25:41 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.5  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.12  Git commit:       633a0ea  Built:            Wed Nov 13 07:24:18 2019  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          1.2.10  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339 runc:  Version:          1.0.0-rc8+dev  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657 docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 2  Running: 0  Paused: 0  Stopped: 2 Images: 1 Server Version: 19.03.5 Storage Driver: vfs Logging Driver: json-file Cgroup Driver: none Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339 runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657 init version: fec3683 Security Options:  seccomp   Profile: default  rootless Kernel Version: 3.10.0-1062.4.1.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 3.699GiB Name: localhost.localdomain ID: M2EJ:FQZ5:5YSC:BCWJ:NMF3:J2YP:PRDY:YGEY:VDOL:YTTG:DQAR:Q4NU Docker Root Dir: /home/brian/.local/share/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**This problem arises on multiple hyper visors and across different backing file system types.
"
40236,0,2215,21,0,0,Caligatio,0,"title:Docker rootless dies when unable to read /etc/docker/certs.d. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--On machines that have a rootful daemon and a rootless daemon, the rootless daemon will exit if the relevant user does not have read access to /etc/docker/certs.d/<REGISTRY>.  It is useful for the rootful daemon to have separate and distinct certificates/keys from the rootless dameon.-->**Steps to reproduce the issue:**1. sudo mkdir -p /etc/docker/certs.d/quay.io && sudo touch /etc/docker/certs.d/quay.io/{client.cert,client.key,ca.crt} && sudo chmod 700 /etc/docker/certs.d/quay.io2.  ./dockerd-rootless.sh --experimental3.  docker -H unix:///run/user/<UID>/docker.sock pull quay.io/benyoo/gitlab**Describe the results you received:**```bashdocker -H unix:///run/user/1000/docker.sock pull quay.io/benyoo/gitlabUsing default tag: latestError response from daemon: open /etc/docker/certs.d/quay.io: permission denied```**Describe the results you expected:**If the rootless daemon cannot read /etc/docker/certs.d, it should ignore the directory.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.4 API version:       1.40 Go version:        go1.12.10 Git commit:        9013bf583a Built:             Fri Oct 18 15:52:22 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          dev  API version:      1.41 (minimum version 1.12)  Go version:       go1.13.3  Git commit:       649e4c8  Built:            Mon Nov 11 12:42:03 2019  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          v1.3.0  GitCommit:        36cf5b690dcc00ff0f34ff7799209050c3d0c59a runc:  Version:          1.0.0-rc8+dev  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657 docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 1 Server Version: dev Storage Driver: vfs Logging Driver: json-file Cgroup Driver: none Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 36cf5b690dcc00ff0f34ff7799209050c3d0c59a runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657 init version: fec3683 Security Options:  seccomp   Profile: default  rootless Kernel Version: 3.10.0-1062.4.1.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 3.699GiB Name: localhost.localdomain ID: ZGPZ:WCD7:AL65:BPHK:FEDC:XROH:BTT2:GS6N:V4ZJ:2W5Y:ZS7A:RPMY Docker Root Dir: /home/brian/.local/share/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**N/A
"
40232,0,6522,5,0,0,Jonas-Heinrich,0,"title:Logging driver for GELF sends message with empty mandatory field ""short_message"". description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Docker, or rather the logging driver for *GELF*, sends its output without checkingif messages have any content in the mandatory field `short_message`. According to the [*GELF* payload specification](http://docs.graylog.org/en/2.4/pages/gelf.html#gelf-payload-specification) this is explicitly forbidden and may result in exceptions.In the following bug report I am using Graylog as an example for the consequences thatresult downstream.**Steps to reproduce the issue:**- Run a local instance of Graylog 3 with docker compose version 3 in a default configuration as described [here](https://docs.graylog.org/en/3.1/pages/installation/docker.html).Note that this is not core to the issue at hand, but merely serves as a nice demonstration of the consequences:```version: '3'services:  # MongoDB: https://hub.docker.com/_/mongo/  mongo:    image: mongo:3    networks:      - graylog  # Elasticsearch: https://www.elastic.co/guide/en/elasticsearch/reference/6.x/docker.html  elasticsearch:    image: docker.elastic.co/elasticsearch/elasticsearch-oss:6.8.2    environment:      - http.host=0.0.0.0      - transport.host=localhost      - network.host=0.0.0.0      - ""ES_JAVA_OPTS=-Xms512m -Xmx512m""    ulimits:      memlock:        soft: -1        hard: -1    deploy:      resources:        limits:          memory: 1g    networks:      - graylog  # Graylog: https://hub.docker.com/r/graylog/graylog/  graylog:    image: graylog/graylog:3.1    environment:      # CHANGE ME (must be at least 16 characters)!      - GRAYLOG_PASSWORD_SECRET=somepasswordpepper      # Password: admin      - GRAYLOG_ROOT_PASSWORD_SHA2=8c6976e5b5410415bde908bd4dee15dfb167a9c873fc4bb8a81f6f2ab448a918      - GRAYLOG_HTTP_EXTERNAL_URI=http://127.0.0.1:9000/    networks:      - graylog    depends_on:      - mongo      - elasticsearch    ports:      # Graylog web interface and REST API      - 9000:9000      # Syslog TCP      - 1514:1514      # Syslog UDP      - 1514:1514/udp      # GELF TCP      - 12201:12201      # GELF UDP      - 12201:12201/udpnetworks:  graylog:    driver: bridge```- Run the hello-world docker container with gelf as a log driver:```bashdocker run \    --log-driver gelf \    --log-opt gelf-address=udp://localhost:12201 \    hello-world```**Describe the results you received:**Docker now takes the output below, formats it into *GELF* and sends it to graylog:```Hello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the ""hello-world"" image from the Docker Hub.    (amd64) 3. The Docker daemon created a new container from that image which runs the    executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it    to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/```This includes the empty lines that you see in the message above. With empty messages being forbidden in *GELF*, this may result in processing difficulties for a log handler downstream.In the case of Graylog, this results in several exceptions (here is just one):```graylog_1        | 2019-11-21 11:10:39,416 ERROR: org.graylog2.shared.buffers.processors.DecodingProcessor - Unable to decode raw message RawMessage{id=8cd524f1-0c4f-11ea-86f4-0242ac170004, journalOffset=12, codec=gelf, payloadSize=308, timestamp=2019-11-21T11:10:39.295Z, remoteAddress=/172.23.0.1:41406} on input <5dd670a67fa7b70012e2ef6a>.graylog_1        | 2019-11-21 11:10:39,417 ERROR: org.graylog2.shared.buffers.processors.DecodingProcessor - Error processing message RawMessage{id=8cd524f1-0c4f-11ea-86f4-0242ac170004, journalOffset=12, codec=gelf, payloadSize=308, timestamp=2019-11-21T11:10:39.295Z, remoteAddress=/172.23.0.1:41406}graylog_1        | java.lang.IllegalArgumentException: GELF message <8cd524f1-0c4f-11ea-86f4-0242ac170004> (received from <172.23.0.1:41406>) has empty mandatory ""short_message"" field.graylog_1        | 	at org.graylog2.inputs.codecs.GelfCodec.validateGELFMessage(GelfCodec.java:252) ~[graylog.jar:?]graylog_1        | 	at org.graylog2.inputs.codecs.GelfCodec.decode(GelfCodec.java:134) ~[graylog.jar:?]graylog_1        | 	at org.graylog2.shared.buffers.processors.DecodingProcessor.processMessage(DecodingProcessor.java:150) ~[graylog.jar:?]graylog_1        | 	at org.graylog2.shared.buffers.processors.DecodingProcessor.onEvent(DecodingProcessor.java:91) [graylog.jar:?]graylog_1        | 	at org.graylog2.shared.buffers.processors.ProcessBufferProcessor.onEvent(ProcessBufferProcessor.java:86) [graylog.jar:?]graylog_1        | 	at org.graylog2.shared.buffers.processors.ProcessBufferProcessor.onEvent(ProcessBufferProcessor.java:45) [graylog.jar:?]graylog_1        | 	at com.lmax.disruptor.WorkProcessor.run(WorkProcessor.java:143) [graylog.jar:?]graylog_1        | 	at com.codahale.metrics.InstrumentedThreadFactory$InstrumentedRunnable.run(InstrumentedThreadFactory.java:66) [graylog.jar:?]graylog_1        | 	at java.lang.Thread.run(Thread.java:748) [?:1.8.0_232]```**Describe the results you expected:**Normally, I would expect no error in Graylog since it would not have to deal with empty mandatory fields in the first place.**Additional information you deem important (e.g. issue happens only occasionally):**This bug affects all projects that use *GELF* as a logging format, including the elastic stack (though it may be handled differently there). It also extends to use in `docker-compose` files:```version: '3'services:  hello:    image: hello-world    logging:      driver: ""gelf""      options:        gelf-address: udp://localhost:12201        tag: ""hello""```**Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.5 API version:       1.40 Go version:        go1.12.12 Git commit:        633a0ea838 Built:             Wed Nov 13 07:29:52 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.5  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.12  Git commit:       633a0ea838  Built:            Wed Nov 13 07:28:22 2019  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.10  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339 runc:  Version:          1.0.0-rc8+dev  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657 docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 4  Running: 3  Paused: 0  Stopped: 1 Images: 4 Server Version: 19.03.5 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339 runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657 init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.0.0-36-generic Operating System: Ubuntu 18.04.3 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 7.764GiB Name: ubuntu ID: VRJA:MIFX:EADV:AZ4W:EPIK:J6YZ:22ZY:VPUJ:QPQH:7ALR:VCCQ:HKBS Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**- Run on a fresh install of Ubuntu 18.04 in VMWare Workstation Pro
"
40211,1,2594,0,0,0,jbmcfarlin31,0,"title:Docker cp command is not working on Ubuntu 16.04 in Azure Marketplace. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Running Docker `v19.03.4` on Ubuntu 16.04 images within the Azure marketplace and Azure stack marketplace result in the error:```failed to augment data: API error (500): error processing tar file: docker-tar: relocation error: /lib/x86_64-linux-gnu/libnss_files.so.2: symbol __libc_readline_unlocked, version GLIBC_PRIVATE not defined in file libc.so.6 with link time reference: exit status 127```<!--Briefly describe the problem you are having in a few paragraphs.-->When trying to use `docker cp`, the error above occurs only on Azure marketplace image versions of Ubuntu 16.04. **Steps to reproduce the issue:**1. `docker run --rm -d --name nginx nginx:1.16`2. `docker cp nginx:/etc/hostname .`**Describe the results you received:**The following error is returned:```Error response from daemon: error processing tar file: docker-tar: relocation error: /lib/x86_64-linux-gnu/libnss_files.so.2: symbol __libc_readline_unlocked, version GLIBC_PRIVATE not defined in file libc.so.6 with link time reference: exit status 127```**Describe the results you expected:**I expected a successful copy from container to host.**Additional information you deem important (e.g. issue happens only occasionally):**This appears to be a regression of #39449 **Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.4 API version:       1.40 Go version:        go1.12.10 Git commit:        9013bf583a Built:             Fri Oct 18 15:53:51 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.4  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.10  Git commit:       9013bf583a  Built:            Fri Oct 18 15:52:23 2019  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.10  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339 runc:  Version:          1.0.0-rc8+dev  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657 docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 49  Running: 41  Paused: 0  Stopped: 8 Images: 80 Server Version: 19.03.4 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339 runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657 init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.15.0-1013-azure Operating System: Ubuntu 16.04.4 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 13.69GiB Name: <redacted> ID: ZH4B:XEYB:HHVZ:LOXO:U2HA:VIZC:6KGP:LAAP:MZ4H:5GAI:46ZS:UCVS Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**The output above was executed on an Ubuntu 16.04 image from the Azure Stack marketplace, however, this also occurs on the same Ubuntu 16.04 image within Public Azure marketplace.
"
40088,0,1450,200,0,0,thaJeztah,0,"title:Makefile is broken when combining ""binary"" / ""dynbinary"" with other targets. description:introduced by https://github.com/moby/moby/pull/39340TL;DR; I know what's causing this, but will have to look how to best solve; thinking of having separate `build-image` and `build-binary` targets (one of the could be named just `build`); - `build-binary` would output a binary (run build with `--output..`)- `build-image` would build the dev imageThe problem introduced by https://github.com/moby/moby/pull/39340 is that after that change, the `binary`, `dynbinary`, and `cross` targets append a `--output` to `DOCKER_BUILD_ARGS`; https://github.com/moby/moby/blob/d56adcf0ece542a30fad0e54ea9c1ca3b7e6915c/Makefile#L151-L159While this works when running those targets _separately_ (e.g. just `make binary`), it doesn't work when combining them with other targets, as it would- when combined with (e.g.) the `shell` or `test-integration` target; only build the Dockerfile with `--output`, so no image will be built (only a binary)- any combination of `binary`, `dynbinary`, and/or `cross` would append _multiple_ `--output` and multiple `--target` options to `DOCKER_BUILD_ARGS`, which currently isn't supportedFor example, combining `binary` and `shell`;```bashdocker build  --output=bundles/ --target=binary --build-arg=CROSS=false  -t ""docker-dev:support-xattrs"" -f ""Dockerfile"" .[+] Building 19.2s (73/73) FINISHED ....=> exporting to client => => copying files 195.44MB...docker run --rm -i --privileged  .......  ""docker-dev:support-xattrs"" bashUnable to find image 'docker-dev:support-xattrs' locallydocker: Error response from daemon: manifest for docker-dev:support-xattrs not found: manifest unknown: manifest unknown.```And combining `binary` and `dynbinary`;```consolemake binary dynbinarydocker build  --output=bundles/ --target=binary --build-arg=CROSS=false  -t ""docker-dev:support-xattrs"" -f ""Dockerfile"" .[+] Building 9.6s (73/73) FINISHED... => exporting to client => => copying files 195.48MBmake: Nothing to be done for `dynbinary'.```Here, `dynbinary` became a no-op, because it effectively is an alias for `build` (but modifying `DOCKER_BUILD_ARGS` first), however `make` detects that the `build` target has already been executed, thus skips this.## Workaroundinstead of combining, run the make targets separately;```consolemake binarydocker build  --output=bundles/ --target=binary --build-arg=CROSS=false  -t ""docker-dev:support-xattrs"" -f ""Dockerfile"" .[+] Building 9.6s (73/73) FINISHED... => exporting to client => => copying files 195.48MBmake shelldocker build  --target=final --build-arg=CROSS=false  -t ""docker-dev:support-xattrs"" -f ""Dockerfile"" .[+] Building 2.2s (71/71) FINISHED... => => exporting layers => => writing image sha256:cb927fd7a4e4af4de5200bad984a66fc7e7d32901447889231af6413dee801bc => => naming to docker.io/library/docker-dev:support-xattrsdocker run --rm -i --privileged  .......  ""docker-dev:support-xattrs"" bash...```/cc @cpuguy83 
"
40069,0,1257,200,0,0,thaJeztah,0,"title:CI: Windows RS5 fails on compile errors, but doesn't print the error. description:I ran into this a couple of times, and recalled that RS1 acts different than RS5 on these; Windows RS5 hides compilation errors, which makes it difficult to find problems in pull requests.Here's from https://github.com/moby/moby/pull/40062:### Failure on Windows RS5https://ci.docker.com/public/blue/rest/organizations/jenkins/pipelines/moby/branches/PR-40062/runs/9/nodes/197/log/?start=0```?   	github.com/docker/docker/pkg/plugingetter	[no test files]ok  	github.com/docker/docker/pkg/plugins	35.063s	coverage: 73.4% of statements....ERROR: make.ps1 failed:Unit tests failedAt C:\gopath\src\github.com\docker\docker\hack\make.ps1:324 char:32+     if ($LASTEXITCODE -ne 0) { Throw ""Unit tests failed"" }```### Same failure on Windows RS1:https://ci.docker.com/public/blue/rest/organizations/jenkins/pipelines/moby/branches/PR-40062/runs/9/nodes/192/log/?start=0```?   	github.com/docker/docker/pkg/plugingetter	[no test files]powershell.exe : # github.com/docker/docker/testutil/daemonAt D:\gopath\src\github.com\docker\docker@tmp\durable-9a15b210\powershellWrapper.ps1:3 char:1+ & powershell -NoProfile -NonInteractive -ExecutionPolicy Bypass -Comm ...+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    + CategoryInfo          : NotSpecified: (# github.com/do...testutil/daemon    :String) [], RemoteException    + FullyQualifiedErrorId : NativeCommandError testutil\daemon\daemon.go:221:25: cannot use d (type *Daemon) as type string in argument to cleanupNetworkNamespaceok  	github.com/docker/docker/pkg/plugins	35.163s	coverage: 73.4% of statements.....ERROR: make.ps1 failed:Unit tests failedAt C:\gopath\src\github.com\docker\docker\hack\make.ps1:324 char:32+     if ($LASTEXITCODE -ne 0) { Throw ""Unit tests failed"" }```**Note that _both_ report all unit tests as `ok` (passing), but Windows RS5 hides the compile error**
"
40068,0,1537,64,0,0,lukasheinrich,0,"title:rootless docker in kubernetes: ""getting the final child's pid from pipe caused \""EOF\"""": unknown"". description:I am trying to run rootless docker-in-docker deployed on Kubernetes, where the docker daemon is deployed using this manifest:```apiVersion: apps/v1kind: Deploymentmetadata:  labels:    run: rootless  name: rootlessspec:  replicas: 1  selector:    matchLabels:      run: rootless  template:    metadata:      labels:        run: rootless    spec:      containers:      - image: docker:19.03.1-dind-rootless        name: rootless        command:        - sh        - -c        - dockerd-entrypoint.sh --experimental --storage-driver=vfs        securityContext:          runAsUser: 1000          allowPrivilegeEscalation: true          privileged: true        resources: {}status: {}```The daemon seems to start up fine but `kubectl exec`'ing into the pod, setting the DOCKER_HOST and attempting to run a container seems to break```kubctl create -f rootless.ymlkubectl exec -it rootless-7c94dcc5d7-gplvm sh/ $ export DOCKER_HOST=unix:///run/user/1000/docker.sock/ $ docker run --rm -it  busybox shdocker: Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused ""process_linux.go:303: getting the final child's pid from pipe caused \""EOF\"""": unknown./ $ command terminated with exit code 125```The dockerd daemon logs are collected in this gisthttps://gist.github.com/lukasheinrich/e23c00240afed83066978dab8c354f52#file-logs`kubectl version` gives```Client Version: version.Info{Major:""1"", Minor:""14"", GitVersion:""v1.14.3"", GitCommit:""5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0"", GitTreeState:""archive"", BuildDate:""2019-06-18T20:40:14Z"", GoVersion:""go1.12.5"", Compiler:""gc"", Platform:""linux/amd64""}Server Version: version.Info{Major:""1"", Minor:""12"", GitVersion:""v1.12.3"", GitCommit:""435f92c719f279a3a67808c80521ea17d5715c66"", GitTreeState:""clean"", BuildDate:""2018-11-26T12:46:57Z"", GoVersion:""go1.10.4"", Compiler:""gc"", Platform:""linux/amd64""}```cc @AkihiroSuda @rochaporto 
"
40063,0,2334,1,0,0,kaxap,0,"title:Container hangs when using fluentd logger. description:**Description**Docker container hangs when using fluentd logger with fluentd-async-connect=true and unreachable (turned off) fluentd server.**Steps to reproduce the issue:**1. Create docker-compose.yml with any container and logger set to```logging:      driver: fluentd      options:        fluentd-address: 10.147.49.79:24224        fluentd-async-connect: 'true'        fluentd-retry-wait: '1s'        fluentd-max-retries: '30'        tag: your_app```2. `docker-compose up --build -d`**Describe the results you received:**Docker container hangs, does not respond to `docker-compose down -f`, `docker stop`, `docker kill`. **Describe the results you expected:**Container exits with error message.**Additional information you deem important (e.g. issue happens only occasionally):**Issue happens every time the remote fluentd server is down or unreachable.**Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.2 API version:       1.40 Go version:        go1.12.8 Git commit:        6a30dfc Built:             Thu Aug 29 05:28:55 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.2  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.8  Git commit:       6a30dfc  Built:            Thu Aug 29 05:27:34 2019  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.6  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb runc:  Version:          1.0.0-rc8  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 30  Running: 29  Paused: 0  Stopped: 1 Images: 47 Server Version: 19.03.2 Storage Driver: overlay2  Backing Filesystem: xfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 3.10.0-957.27.2.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 64 Total Memory: 125.3GiB Name: server55 ID: SHMQ:YUKH:MZOS:EEYR:WZI6:JYVH:NPPJ:CEEQ:ILXV:6JNU:BVBG:2NTE Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**physical
"
40047,0,3893,95,0,0,dmandalidis,0,"title:Volume create event on container create. description:**Description**Volume create event is emitted on `docker create` independently if volume already exists. I would expect a single volume create event since I 've created the volume myself prior to creating the container.According to my tests, this started happening after 18.03.1 (excluding) and 18.06.3 (including) and it is reproducible up to and including 19.03.2.**Steps to reproduce the issue:**1. `docker events` (on another terminal)2. `docker create volume foo`3. `docker run -v foo:/bar busybox` **Describe the results you received:**```2019-10-06T17:33:50.529598724+03:00 volume create foo (driver=local)2019-10-06T17:34:06.642690750+03:00 volume create foo (driver=local)2019-10-06T17:34:06.673619523+03:00 container create 0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358 (image=busybox, name=great_poitras)2019-10-06T17:34:06.678983859+03:00 container attach 0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358 (image=busybox, name=great_poitras)2019-10-06T17:34:06.732641855+03:00 network connect 92b1bfd9f57ce29a27127d07ee8268a04b2ce5c35b3472960f73858fa0642c4b (container=0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358, name=bridge, type=bridge)2019-10-06T17:34:06.741265314+03:00 volume mount foo (container=0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358, destination=/bar, driver=local, propagation=, read/write=true)```**Describe the results you expected:**```2019-10-06T17:33:50.529598724+03:00 volume create foo (driver=local)2019-10-06T17:34:06.673619523+03:00 container create 0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358 (image=busybox, name=great_poitras)2019-10-06T17:34:06.678983859+03:00 container attach 0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358 (image=busybox, name=great_poitras)2019-10-06T17:34:06.732641855+03:00 network connect 92b1bfd9f57ce29a27127d07ee8268a04b2ce5c35b3472960f73858fa0642c4b (container=0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358, name=bridge, type=bridge)2019-10-06T17:34:06.741265314+03:00 volume mount foo (container=0a24e7e48aa1b71dfebf73696101e010bf6407b87fca1a0b949acf00cfd34358, destination=/bar, driver=local, propagation=, read/write=true)```**Output of `docker version`:**```Client: Version:           18.06.3-ce API version:       1.38 Go version:        go1.10.3 Git commit:        d7080c1 Built:             Wed Feb 20 02:27:18 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          18.06.3-ce  API version:      1.38 (minimum version 1.12)  Go version:       go1.10.3  Git commit:       d7080c1  Built:            Wed Feb 20 02:26:20 2019  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 18.06.3-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: f9bd8fw4occfpqwk6fccpgy1y Is Manager: true ClusterID: p5akkh9kxo9zlt7tmziyv6mu1 Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 10 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 127.0.0.1 Manager Addresses:  127.0.0.1:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 468a545b9edcd5932818eb9de8e72413e616e86erunc version: a592beb5bc4c4092b1b1bac971afed27687340c5init version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 4.15.0-1037-gcpOperating System: Ubuntu 16.04.6 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 7.298GiBName: travis-job-ca6d6f0b-880f-450b-9a4a-5d10e659112bID: BYBT:L62W:A24Q:UNFC:SG5Q:Z47D:C5QK:DXTM:44FB:QYIO:5IDE:7VLADocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Registry Mirrors: https://mirror.gcr.io/Live Restore Enabled: false```
"
40010,0,0,248,0,0,andrewhsu,0,"title:integration-cli failures in TestDockerNetworkSuite on s390x and ppc64le. description:The tests run against the code on `master` branch after PRs are merged are consistently red: https://ci.docker.com/public/blue/organizations/jenkins/moby/activity?branch=masterWith the same 12 tests failing on `s390x` or `ppc64le`:Test Name | Duration | Age-- | -- | --Build / ppc64le integration-cli / Integration-cli tests / ppc64le.integration-cli.TestDockerNetworkSuite/TestExternalVolumeDriverBindExternalVolume | 45 sec | 5Build / ppc64le integration-cli / Integration-cli tests / ppc64le.integration-cli.TestDockerNetworkSuite/TestExternalVolumeDriverGet | 30 sec | 5Build / ppc64le integration-cli / Integration-cli tests / ppc64le.integration-cli.TestDockerNetworkSuite/TestExternalVolumeDriverList | 45 sec | 5Build / ppc64le integration-cli / Integration-cli tests / ppc64le.integration-cli.TestDockerNetworkSuite/TestExternalVolumeDriverNamed | 16 sec | 5Build / ppc64le integration-cli / Integration-cli tests / ppc64le.integration-cli.TestDockerNetworkSuite/TestExternalVolumeDriverWithDaemonRestart | 1 min 0 sec | 5Build / ppc64le integration-cli / Integration-cli tests / ppc64le.integration-cli.TestDockerNetworkSuite | 9 min 5 sec | 5Build / s390x integration-cli / Integration-cli tests / s390x.integration-cli.TestDockerNetworkSuite/TestExternalVolumeDriverBindExternalVolume | 45 sec | 14Build / s390x integration-cli / Integration-cli tests / s390x.integration-cli.TestDockerNetworkSuite/TestExternalVolumeDriverGet | 30 sec | 14Build / s390x integration-cli / Integration-cli tests / s390x.integration-cli.TestDockerNetworkSuite/TestExternalVolumeDriverList | 45 sec | 14Build / s390x integration-cli / Integration-cli tests / s390x.integration-cli.TestDockerNetworkSuite/TestExternalVolumeDriverNamed | 16 sec | 14Build / s390x integration-cli / Integration-cli tests / s390x.integration-cli.TestDockerNetworkSuite/TestExternalVolumeDriverWithDaemonRestart | 1 min 0 sec | 14Build / s390x integration-cli / Integration-cli tests / s390x.integration-cli.TestDockerNetworkSuite | 9 min 6 sec | 14I see that most of the build failures are solely because of these tests.cc @arkodg @joeabbey
"
39963,0,7134,3,0,0,lwimmer,0,"title:Out of memory crash while following log with ""local"" logging driver.. description:**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->`dockerd` reproducibly crashes with `fatal error: runtime: out of memory` while running `docker logs -f`.It seems that the `local` log driver sometimes uses huge amounts of memory while running `docker logs -f`.**Steps to reproduce the issue:**1. Install Docker 19.03.2 on Ubuntu 18.04.2. Set the `log-driver` to `local`.3. Run a container that logs a lot, so we can trigger the issue fast. A suitable command is:```docker run -d --rm --name crazy_logger alpine cat /dev/urandom```4. Follow the log output:```docker logs -f crazy_logger > /dev/null```5. Wait for the crash or the massive memory usage (if you have enough RAM).**Describe the results you received:**`dockerd` crashed with the following log:```dockerd[4489]: fatal error: runtime: out of memorydockerd[4489]: runtime stack:dockerd[4489]: runtime.throw(0x5578d80974e2, 0x16)dockerd[4489]: #011/usr/local/go/src/runtime/panic.go:617 +0x74dockerd[4489]: runtime.sysMap(0xc004000000, 0xd4000000, 0x5578da578358)dockerd[4489]: #011/usr/local/go/src/runtime/mem_linux.go:170 +0xc9dockerd[4489]: runtime.(*mheap).sysAlloc(0x5578da55b940, 0xd267c000, 0x5578da55b950, 0x6933e)dockerd[4489]: #011/usr/local/go/src/runtime/malloc.go:633 +0x1cfdockerd[4489]: runtime.(*mheap).grow(0x5578da55b940, 0x6933e, 0x0)dockerd[4489]: #011/usr/local/go/src/runtime/mheap.go:1222 +0x44dockerd[4489]: runtime.(*mheap).allocSpanLocked(0x5578da55b940, 0x6933e, 0x5578da578368, 0x0)dockerd[4489]: #011/usr/local/go/src/runtime/mheap.go:1150 +0x381dockerd[4489]: runtime.(*mheap).alloc_m(0x5578da55b940, 0x6933e, 0x101, 0x0)dockerd[4489]: #011/usr/local/go/src/runtime/mheap.go:977 +0xc6dockerd[4489]: runtime.(*mheap).alloc.func1()dockerd[4489]: #011/usr/local/go/src/runtime/mheap.go:1048 +0x4edockerd[4489]: runtime.(*mheap).alloc(0x5578da55b940, 0x6933e, 0x10101, 0xc000654f00)dockerd[4489]: #011/usr/local/go/src/runtime/mheap.go:1047 +0x8cdockerd[4489]: runtime.largeAlloc(0xd267b395, 0xc0006b0101, 0x3)dockerd[4489]: #011/usr/local/go/src/runtime/malloc.go:1055 +0x9bdockerd[4489]: runtime.mallocgc.func1()dockerd[4489]: #011/usr/local/go/src/runtime/malloc.go:950 +0x48dockerd[4489]: runtime.systemstack(0x0)dockerd[4489]: #011/usr/local/go/src/runtime/asm_amd64.s:351 +0x63dockerd[4489]: runtime.mstart()dockerd[4489]: #011/usr/local/go/src/runtime/proc.go:1153dockerd[4489]: goroutine 400 [running]:dockerd[4489]: runtime.systemstack_switch()dockerd[4489]: #011/usr/local/go/src/runtime/asm_amd64.s:311 fp=0xc000befb08 sp=0xc000befb00 pc=0x5578d67a8450dockerd[4489]: runtime.mallocgc(0xd267b395, 0x5578d8ca01c0, 0x1, 0xc000befb28)dockerd[4489]: #011/usr/local/go/src/runtime/malloc.go:949 +0x884 fp=0xc000befba8 sp=0xc000befb08 pc=0x5578d6758b44dockerd[4489]: runtime.makeslice(0x5578d8ca01c0, 0xd267b395, 0xd267b395, 0x4)dockerd[4489]: #011/usr/local/go/src/runtime/slice.go:49 +0x6e fp=0xc000befbd8 sp=0xc000befba8 pc=0x5578d679118edockerd[4489]: github.com/docker/docker/daemon/logger/local.decodeFunc.func1(0x5578d912c760, 0xc00000f040, 0x0)dockerd[4489]: #011/go/src/github.com/docker/docker/daemon/logger/local/read.go:131 +0x38f fp=0xc000befcc0 sp=0xc000befbd8 pc=0x5578d7321e1fdockerd[4489]: github.com/docker/docker/daemon/logger/loggerutils.followLogs(0xc000ba2018, 0xc000c043c0, 0xc0009680c0, 0x5578d90e4f18, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)dockerd[4489]: #011/go/src/github.com/docker/docker/daemon/logger/loggerutils/logfile.go:637 +0x4c3 fp=0xc000befdf8 sp=0xc000befcc0 pc=0x5578d7319353dockerd[4489]: github.com/docker/docker/daemon/logger/loggerutils.(*LogFile).ReadLogs(0xc0007fe140, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0xffffffffffffffff, 0x1, 0xc000c043c0)dockerd[4489]: #011/go/src/github.com/docker/docker/daemon/logger/loggerutils/logfile.go:376 +0x269 fp=0xc000beff30 sp=0xc000befdf8 pc=0x5578d7316dc9dockerd[4489]: github.com/docker/docker/daemon/logger/local.(*driver).readLogs(0xc000976ac0, 0xc000c043c0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0xffffffffffffffff, 0x1)dockerd[4489]: #011/go/src/github.com/docker/docker/daemon/logger/local/read.go:31 +0xea fp=0xc000beff90 sp=0xc000beff30 pc=0x5578d73207eadockerd[4489]: runtime.goexit()dockerd[4489]: #011/usr/local/go/src/runtime/asm_amd64.s:1337 +0x1 fp=0xc000beff98 sp=0xc000beff90 pc=0x5578d67aa551dockerd[4489]: created by github.com/docker/docker/daemon/logger/local.(*driver).ReadLogsdockerd[4489]: #011/go/src/github.com/docker/docker/daemon/logger/local/read.go:20 +0x16cdockerd[4489]: goroutine 1 [chan receive]:dockerd[4489]: main.(*DaemonCli).start(0xc00002b7a0, 0xc00011a540, 0x0, 0x0)dockerd[4489]: #011/go/src/github.com/docker/docker/cmd/dockerd/daemon.go:259 +0xcbfdockerd[4489]: main.runDaemon(...)dockerd[4489]: #011/go/src/github.com/docker/docker/cmd/dockerd/docker_unix.go:13dockerd[4489]: main.newDaemonCommand.func1(0xc0006eac80, 0xc00002b740, 0x0, 0x3, 0x0, 0x0)dockerd[4489]: #011/go/src/github.com/docker/docker/cmd/dockerd/docker.go:34 +0x7ddockerd[4489]: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).execute(0xc0006eac80, 0xc00004e0d0, 0x3, 0x3, 0xc0006eac80, 0xc00004e0d0)dockerd[4489]: #011/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:762 +0x467dockerd[4489]: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc0006eac80, 0x0, 0x0, 0x10)dockerd[4489]: #011/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:852 +0x2eedockerd[4489]: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).Execute(...)dockerd[4489]: #011/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:800dockerd[4489]: main.main()```(Log truncated, full log can be provided)**Describe the results you expected:**Docker not crashing or using huge amount of memory.**Additional information:**- With the described setup we can reproduce the issue within seconds.  With a regular container logging normally, it can take some hours to trigger the issue.- It only seems to happen with `docker logs -f`.- It seems to be related to the `local` logging driver. We tested briefly with `json-file` and could not reproduce the issue.- On a VM with 32 GiB of RAM, dockerd does not crash, but uses around 13 GiB of memory after a few seconds.- Letting the crazy logging container run without following the log seems to be no problem and the memory usage of dockerd is inconspicuous.**Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.2 API version:       1.40 Go version:        go1.12.8 Git commit:        6a30dfc Built:             Thu Aug 29 05:29:11 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.2  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.8  Git commit:       6a30dfc  Built:            Thu Aug 29 05:27:45 2019  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.6  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb runc:  Version:          1.0.0-rc8  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 2 Server Version: 19.03.2 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: local Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.15.0-1050-aws Operating System: Ubuntu 18.04.3 LTS OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 3.794GiB Name: ip-10-1-16-91 ID: QCAE:K33Q:RKON:R3L2:KV5V:EZVD:3SOQ:EHHX:X36A:F5NU:7W5W:F2KO Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**We reproduced it on a AWS EC2 instance (t3.medium in eu-central-1) based on `ami-08a162fe1419adb2a` (Ubuntu 18.04 LTS 20190918).
"
39916,0,2980,192,1,0,goetas,0,"title:Dockerd eats too much RAM. description:**Description**Currently the `dockerd` process of a leader node is eating ~11GB of RAM.On that node there are no scheduled containers, it participates to the cluster only as manager (currently as leader). **Output of `docker version`:**```root@vim11:/home/goetas# docker versionClient: Version:           18.09.8 API version:       1.39 Go version:        go1.10.8 Git commit:        0dd43dd87f Built:             Wed Jul 17 17:41:13 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.1  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.5  Git commit:       74b1e89  Built:            Thu Jul 25 21:20:35 2019  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.6  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb runc:  Version:          1.0.0-rc8  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 46Server Version: 19.03.1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: active NodeID: 27ajn65e9o1zfla8j532wbt5b Is Manager: true ClusterID: tzm417keomjtxndqclyvsz6fd Managers: 3 Nodes: 13 Default Address Pool: 10.0.0.0/8   SubnetSize: 24 Orchestration:  Task History Retention Limit: 3 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 10 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 172.16.21.231 Manager Addresses:  172.16.21.231:2377  172.16.21.233:2377  172.16.21.238:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fbrunc version: 425e105d5a03fabd737a126ad93d62a9eeede87finit version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 4.9.0-9-amd64Operating System: Debian GNU/Linux 9 (stretch)OSType: linuxArchitecture: x86_64CPUs: 3Total Memory: 15.68GiBName: vim11ID: CU7J:E35G:YUKM:76S7:LYCX:2XJD:Y46P:VBXT:HD5A:UYXT:44AR:UH4QDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**```root@vim11:/home/goetas# uname -aLinux vim11 4.9.0-9-amd64 #1 SMP Debian 4.9.168-1+deb9u3 (2019-06-16) x86_64 GNU/Linux```I saw that there are https://github.com/moby/moby/issues/32728 https://github.com/moby/moby/issues/32711 , but they refer to older versions of docker. This one is pretty recent.```USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDroot     31186 76.5 72.1 24888568 11781872 ?   Ssl  Aug01 46401:24 /usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --ip-forward=true --iptables=true ```How can I provide you more info to debug this?
"
39875,1,2886,291,0,0,MichaelSimons,0,"title:/proc/<pid>/maps: Pathnames are '/' inside a container using kernel 5.0.0-27-generic. description:Using kernel 5.0.0-27-generic with an Ubuntu 18.04 container, every pathname in /proc/<pid>/maps is / instead of the mapped file path.**Steps to reproduce the issue:**1. In an environment using kernel 5.0.0-25-generic (or earlier) $ sudo docker run ubuntu cat /proc/1/maps56324a3f5000-56324a3fd000 r-xp 00000000 fc:01 665673 /bin/cat56324a5fc000-56324a5fd000 r--p 00007000 fc:01 665673 /bin/cat56324a5fd000-56324a5fe000 rw-p 00008000 fc:01 665673 /bin/cat56324a8eb000-56324a90c000 rw-p 00000000 00:00 0 [heap]7f8ab5f91000-7f8ab6178000 r-xp 00000000 fc:01 666073 /lib/x86_64-linux-gnu/libc-2.27.so7f8ab6178000-7f8ab6378000 ---p 001e7000 fc:01 666073 /lib/x86_64-linux-gnu/libc-2.27.so7f8ab6378000-7f8ab637c000 r--p 001e7000 fc:01 666073 /lib/x86_64-linux-gnu/libc-2.27.so7f8ab637c000-7f8ab637e000 rw-p 001eb000 fc:01 666073 /lib/x86_64-linux-gnu/libc-2.27.so7f8ab637e000-7f8ab6382000 rw-p 00000000 00:00 07f8ab6382000-7f8ab63a9000 r-xp 00000000 fc:01 666055 /lib/x86_64-linux-gnu/ld-2.27.so7f8ab6583000-7f8ab65a7000 rw-p 00000000 00:00 07f8ab65a9000-7f8ab65aa000 r--p 00027000 fc:01 666055 /lib/x86_64-linux-gnu/ld-2.27.so7f8ab65aa000-7f8ab65ab000 rw-p 00028000 fc:01 666055 /lib/x86_64-linux-gnu/ld-2.27.so7f8ab65ab000-7f8ab65ac000 rw-p 00000000 00:00 07ffc25954000-7ffc25975000 rw-p 00000000 00:00 0 [stack]7ffc259f1000-7ffc259f4000 r--p 00000000 00:00 0 [vvar]7ffc259f4000-7ffc259f5000 r-xp 00000000 00:00 0 [vdso]ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall]2. In an environment using kernel 5.0.0-27-generic (broken):$ sudo docker run ubuntu cat /proc/1/maps55de0e052000-55de0e05a000 r-xp 00000000 fc:01 665673 /55de0e259000-55de0e25a000 r--p 00007000 fc:01 665673 /55de0e25a000-55de0e25b000 rw-p 00008000 fc:01 665673 /55de0fcb3000-55de0fcd4000 rw-p 00000000 00:00 0 [heap]7f7a8d881000-7f7a8da68000 r-xp 00000000 fc:01 666073 /7f7a8da68000-7f7a8dc68000 ---p 001e7000 fc:01 666073 /7f7a8dc68000-7f7a8dc6c000 r--p 001e7000 fc:01 666073 /7f7a8dc6c000-7f7a8dc6e000 rw-p 001eb000 fc:01 666073 /7f7a8dc6e000-7f7a8dc72000 rw-p 00000000 00:00 07f7a8dc72000-7f7a8dc99000 r-xp 00000000 fc:01 666055 /7f7a8de73000-7f7a8de97000 rw-p 00000000 00:00 07f7a8de99000-7f7a8de9a000 r--p 00027000 fc:01 666055 /7f7a8de9a000-7f7a8de9b000 rw-p 00028000 fc:01 666055 /7f7a8de9b000-7f7a8de9c000 rw-p 00000000 00:00 07ffc744bd000-7ffc744de000 rw-p 00000000 00:00 0 [stack]7ffc7452d000-7ffc74530000 r--p 00000000 00:00 0 [vvar]7ffc74530000-7ffc74531000 r-xp 00000000 00:00 0 [vdso]**Describe the results you received:**Every pathname in /proc/<pid>/maps is / instead of the mapped file path**Describe the results you expected:**Every pathname in /proc/<pid>/maps is / the mapped file path**Additional information you deem important (e.g. issue happens only occasionally):**There is a kernel issue for this as well -https://bugs.launchpad.net/ubuntu/+source/linux/+bug/1843018.  I wanted to log a Docker issue for visibility in case others are affected by it and to verify Docker isn't at fault here.This is breaking .NET Core apps - https://github.com/dotnet/corefx/issues/40850The problem can be reproduced in various Ubuntu releases, e.g. 18.04 and 19.04.**Output of `docker version`:**```Client: Docker Engine - Community                            Version:           19.03.2                                  API version:       1.40                                     Go version:        go1.12.8                                 Git commit:        6a30dfc                                  Built:             Thu Aug 29 05:29:11 2019                 OS/Arch:           linux/amd64                              Experimental:      false                                                                                               Server: Docker Engine - Community                            Engine:                                                      Version:          19.03.2                                   API version:      1.40 (minimum version 1.12)               Go version:       go1.12.8                                  Git commit:       6a30dfc                                   Built:            Thu Aug 29 05:27:45 2019                  OS/Arch:          linux/amd64                               Experimental:     false                                    containerd:                                                  Version:          1.2.6                                     GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb runc:                                                        Version:          1.0.0-rc8                                 GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f docker-init:                                                 Version:          0.18.0                                    GitCommit:        fec3683     ```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 1  Running: 0  Paused: 0  Stopped: 1 Images: 10 Server Version: 19.03.2 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.0.0-1018-azure Operating System: Ubuntu 18.04.3 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 13.67GiB Name: mikeharder-docker-test ID: L2CI:XKAM:WL3O:UUFW:T3EQ:QLCH:CGOR:7U4A:ORCL:JXFY:7VRN:ERQ7 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```
"
39866,1,3091,70,0,0,mejedi,0,"title:User namespace remapping breaks BuildKit-powered builds (19.03.2). description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->With version 19.03.2, enabling user namespace remapping breaks BuildKit-powered builds.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. Enable user namespace remapping;2. Dockerfile: ```FROM alpine as testRUN id```3. `DOCKER_BUILDKIT=1 docker build . --progress=plain`**Describe the results you received:**Build fails.```#2 [internal] load .dockerignore#2 transferring context: 2B done#2 DONE 0.0s#1 [internal] load build definition from Dockerfile#1 transferring dockerfile: 64B done#1 DONE 0.0s#3 [internal] load metadata for docker.io/library/alpine:latest#3 DONE 0.0s#4 [1/2] FROM docker.io/library/alpine#4 CACHED#5 [2/2] RUN id#5 0.173 container_linux.go:345: starting container process caused ""process_linux.go:430: container init caused \""rootfs_linux.go:58: mounting \\\""/run/runc/1argvey9yo2x2mwmd7nplwwua/notify.sock\\\"" to rootfs \\\""/var/lib/docker/231072.231072/buildkit/executor/1argvey9yo2x2mwmd7nplwwua/rootfs\\\"" at \\\""/run/systemd/notify\\\"" caused \\\""stat /run/runc/1argvey9yo2x2mwmd7nplwwua/notify.sock: permission denied\\\""\""""#5 ERROR: executor failed running [/bin/sh -c id]: exit code: 1------ > [2/2] RUN id:------failed to solve with frontend dockerfile.v0: failed to build LLB: executor failed running [/bin/sh -c id]: exit code: 1```**Describe the results you expected:**Should've succeeded.**Additional information you deem important (e.g. issue happens only occasionally):**Works just fine without either BuildKit or user namespace remapping. This is a clean install, i.e. not upgrading from a prior version.**Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.2 API version:       1.40 Go version:        go1.12.8 Git commit:        6a30dfc Built:             Thu Aug 29 05:29:11 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.2  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.8  Git commit:       6a30dfc  Built:            Thu Aug 29 05:27:45 2019  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.6  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb runc:  Version:          1.0.0-rc8  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 1 Server Version: 19.03.2 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f init version: fec3683 Security Options:  apparmor  seccomp   Profile: default  userns Kernel Version: 4.15.0-60-generic Operating System: Ubuntu 18.04.3 LTS OSType: linux Architecture: x86_64 CPUs: 1 Total Memory: 985.6MiB Name: kvm-experiment ID: WWEW:H7D5:Q7Y3:7CCW:2WON:OR4N:RQMT:6DMC:QVBF:6RME:ENUV:36MN Docker Root Dir: /var/lib/docker/231072.231072 Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
39859,0,4006,300,0,0,stbenjam,0,"title:race condition in pkg/archive DecompressStream. description:**Description**There is a race condition in pkg/archive when using `cmd.Start` for pigz and xz. The `*bufio.Reader` could be returned to the pool while the command is still writing to it. The command is wrapped in a `CommandContext` where the process will be killed when the context is cancelled, however this is not instantaneous, so there's a brief window while the command could still be running but the `*bufio.Reader` was already returned to the pool. wrapReadCloser calls `cancel()`, and then `readBuf.Close()` which eventually returns the buffer to the pool:https://github.com/moby/moby/blob/1d19062b640b66daaf3e6f2246a947aaaf909dec/pkg/archive/archive.go#L179-L180However, because cmdStream runs `cmd.Wait` in a go routine that we never wait for to finish, it is not safe to return the reader to the pool yet. We need to ensure we wait for `cmd.Wait` to finish!**Steps to reproduce the issue:**I have written a reproducer at https://github.com/stbenjam/docker-race-reproducer, where you can see the behavior. Check out the repo and run `go run main.go`.**Describe the results you received:**In the worst case, a panic:```Waiting...DoneDonepanic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x18 pc=0x4b20b0]goroutine 34 [running]:bufio.(*Reader).fill(0xc0000fe300)	/usr/lib/golang/src/bufio/bufio.go:100 +0xe0bufio.(*Reader).WriteTo(0xc0000fe300, 0x554bc0, 0xc000118068, 0x7fb786381fb0, 0xc0000fe300, 0x4eb001)	/usr/lib/golang/src/bufio/bufio.go:486 +0x259io.copyBuffer(0x554bc0, 0xc000118068, 0x554a40, 0xc0000fe300, 0x0, 0x0, 0x0, 0x0, 0x0, 0xc00010c060)	/usr/lib/golang/src/io/io.go:384 +0x352io.Copy(0x554bc0, 0xc000118068, 0x554a40, 0xc0000fe300, 0x0, 0xc00003c7b8, 0x4ebb89)	/usr/lib/golang/src/io/io.go:364 +0x5aos/exec.(*Cmd).stdin.func1(0x0, 0x0)	/usr/lib/golang/src/os/exec/exec.go:234 +0x55os/exec.(*Cmd).Start.func1(0xc000110160, 0xc00011e120)	/usr/lib/golang/src/os/exec/exec.go:400 +0x27created by os/exec.(*Cmd).Start	/usr/lib/golang/src/os/exec/exec.go:399 +0x5afexit status 2```**Describe the results you expected:**No race condition.Here's the output of `go run -race`:```=================WARNING: DATA RACERead at 0x00c000076088 by goroutine 16:  bufio.(*Reader).writeBuf()      /usr/lib/golang/src/bufio/bufio.go:510 +0x50  bufio.(*Reader).WriteTo()      /usr/lib/golang/src/bufio/bufio.go:468 +0x6a  io.copyBuffer()      /usr/lib/golang/src/io/io.go:384 +0x46a  io.Copy()      /usr/lib/golang/src/io/io.go:364 +0x74  os/exec.(*Cmd).stdin.func1()      /usr/lib/golang/src/os/exec/exec.go:234 +0x8a  os/exec.(*Cmd).Start.func1()      /usr/lib/golang/src/os/exec/exec.go:400 +0x34Previous write at 0x00c000076088 by goroutine 6:  github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/pools.(*BufioReaderPool).Put()      /usr/lib/golang/src/bufio/bufio.go:75 +0xaf  github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/pools.(*BufioReaderPool).NewReadCloserWrapper.func1()      /home/stbenjam/go/src/github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/pools/pools.go:93 +0x98  github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/ioutils.(*ReadCloserWrapper).Close()      /home/stbenjam/go/src/github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/ioutils/readers.go:20 +0x4c  github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/archive.wrapReadCloser.func1()      /home/stbenjam/go/src/github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/archive/archive.go:180 +0x67  github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/ioutils.(*ReadCloserWrapper).Close()      /home/stbenjam/go/src/github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/ioutils/readers.go:20 +0x4c  main.decompress()      /home/stbenjam/go/src/github.com/stbenjam/docker-race-reproducer/main.go:33 +0xdbGoroutine 16 (running) created at:  os/exec.(*Cmd).Start()      /usr/lib/golang/src/os/exec/exec.go:399 +0x9bf  github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/archive.cmdStream()      /home/stbenjam/go/src/github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/archive/archive.go:1217 +0x33b  github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/archive.gzDecompress()      /home/stbenjam/go/src/github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/archive/archive.go:174 +0x17a  github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/archive.DecompressStream()      /home/stbenjam/go/src/github.com/stbenjam/docker-race-reproducer/vendor/github.com/docker/docker/pkg/archive/archive.go:207 +0x572  main.decompress()      /home/stbenjam/go/src/github.com/stbenjam/docker-race-reproducer/main.go:29 +0x46Goroutine 6 (finished) created at:  main.main()      /home/stbenjam/go/src/github.com/stbenjam/docker-race-reproducer/main.go:21 +0xb6==================```
"
39823,0,2074,0,0,0,kross-italk,0,"title:Docker run reports wrong image missing when using --link. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**If you use --link and the linked image isn't running, the top level image you're trying to run reports as not found. <!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. docker run --link thisdoesntexist python2. Unable to find image 'python:latest' locally**Describe the results you received:**The image to run has to already have been built. It is noticed if you run docker run --link thisdoesntexist pythonit first downloads python, then correctly says ""unable to find thisdoesntexist"" only if python hasn't downloaded before**Describe the results you expected:**Correctly report the linked image name that's missing**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```婵?docker versionClient: Docker Engine - Community Version:           19.03.1 API version:       1.40 Go version:        go1.12.5 Git commit:        74b1e89 Built:             Thu Jul 25 21:21:05 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.1  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.5  Git commit:       74b1e89  Built:            Thu Jul 25 21:19:41 2019  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.6  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb runc:  Version:          1.0.0-rc8  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```婵?docker infoClient: Debug Mode: falseServer: Containers: 11  Running: 4  Paused: 0  Stopped: 7 Images: 89 Server Version: 19.03.1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.15.0-55-generic Operating System: Ubuntu 18.04.2 LTS OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 3.852GiB Name: kross ID: EPUW:J7KX:4IAV:MMOT:MWDW:GPIT:O32V:U4AO:WQSC:FF53:ZT6K:PLQN Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
39727,0,0,0,0,0,msyihchen,0,"title:Docker 19.03 doesn't support OCI image. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Docker 17.09 and 18.06 are able to pull down OCI image, Docker 19.03 is not able to.When docker client sends /v2/\<repo\>/manifests/\<tag\> request, * In docker 17.09, it doesn't contain ""application/vnd.oci.image.manifest.v1+json"" in the request accept header, so it receives a docker v2 format manifest, which is supported natively by docker.* In docker 18.06, it contains ""application/vnd.oci.image.manifest.v1+json"" in the request accept header, it receives an OCI format manifest, it looks like docker is able to handle it correctly. Docker client converts it into docker v2 format.* In docker 19.03, it contains ""application/vnd.oci.image.manifest.v1+json"" in the request accept header, it receives an OCI format manifest, docker client is not able to handle it. So it gives this error message: Error response from daemon: mediaType in manifest should be 'application/vnd.docker.distribution.manifest.v2+json' not ''**Steps to reproduce the issue:**1. Create a container registry in Azure, use podman build an OCI image and use podman to push it. In Azure portal, 2. Docker client 17.09 and 18.06 are able to pull it down. Docker client 19.03 is not able to.**Describe the results you received:**Docker client 19.03 gives the following error:Error response from daemon: mediaType in manifest should be 'application/vnd.docker.distribution.manifest.v2+json' not ''**Describe the results you expected:**Docker pull should succeed.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**docker versionClient: Docker Engine - Community Version:           19.03.1 API version:       1.40 Go version:        go1.12.5 Git commit:        74b1e89 Built:             Thu Jul 25 21:21:05 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.1  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.5  Git commit:       74b1e89  Built:            Thu Jul 25 21:19:41 2019  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          1.2.6  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb runc:  Version:          1.0.0-rc8  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f docker-init:  Version:          0.18.0  GitCommit:        fec3683**Output of `docker info`:**Client: Debug Mode: falseServer: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 2 Server Version: 19.03.1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: false Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.18.0-1024-azure Operating System: Ubuntu 18.04.2 LTS OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 15.64GiB Name: testpodmanyihchen ID: X3OI:UE7F:NMDF:WHSI:PRN2:UNPZ:Z24D:5CHF:5YMJ:2U2L:OSEF:U726 Docker Root Dir: /var/lib/docker Debug Mode: false Username: yc993 Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support**Additional environment details (AWS, VirtualBox, physical, etc.):**Ubuntu 16.04 amd64
"
39654,1,2257,85,0,0,mpepping,0,"title:Docker 19.03.n client ignores proxy env settings. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**As per 19.03.1 (19.03.n), it's not possible anymore to use a local Docker Client to connect to a remote Docker Engine, via a http-proxy.For versions previous to 19.03.n it was sufficient to set `http_proxy` and `https_proxy` (and an optionally `no_proxy`) in the local shell-environment to let the local Docker client connect to a remote Engine (or Docker UCP controller).Since 19.03.n any Docker command towards a remote Engine throws a lookup error:`error during connect: Get https://foo.example.com:8443/v1.40/version: dial tcp: lookup foo.example.com no such host`Downgrading the **docker client binary** to 18.09 resolves the issue. So, it seems to be an issue in the client binary.Steps to downgrade the client binary on macOS:```export DOCKERVERSION=18.09.8curl -fsSLO https://download.docker.com/mac/static/stable/x86_64/docker-${DOCKERVERSION}.tgz && \tar xzvf docker-${DOCKERVERSION}.tgz --strip 1 -C /usr/local/bin docker/docker && \rm docker-${DOCKERVERSION}.tgz```Steps to undo the downgrade:```rm-v  /usr/local/bin/docker && \ln -s /Applications/Docker.app/Contents/Resources/bin/docker```**Steps to reproduce the issue:**1. Install 19.03.1 locally2. Setup a remote Docker Engine, accessible via a HTTP-proxy3. Configure proxy-settings in the local shell (`http_proxy` and `https_proxy`, and to make it complete set `HTTP_PROXY` and `HTTPS_PROXY` )4. Setup the local shell for the remote Engine (`DOCKER_TLS_VERIFY`, `DOCKER_HOST`, `DOCKER_CERT_PATH`)5. Run a docker command (eg. `docker ps`)6. See the error: `error during connect: Get https://foo.example.com:8443/v1.40/version: dial tcp: lookup foo.example.com: no such host`**Describe the results you received:**Connecting to remote Docker instances throws an error:```error during connect: Get https://foo.example.com:8443/v1.40/version: dial tcp: lookup foo.example.com: no such host```**Describe the results you expected:**Output for `docker ps`**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.1 API version:       1.40 Go version:        go1.12.5 Git commit:        74b1e89 Built:             Thu Jul 25 21:18:17 2019 OS/Arch:           darwin/amd64 Experimental:      falseerror during connect: Get https://foo.example.com:8443/v1.40/version: dial tcp: lookup foo.example.com no such host```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 2  Running: 2  Paused: 0  Stopped: 0 Images: 136 Server Version: 19.03.1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fb runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 4.9.184-linuxkit Operating System: Docker Desktop OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 5.818GiB Name: docker-desktop ID: JZS5:IGBZ:Y5UO:PLD7:LAGQ:6SRR:XNA3:MNS7:6KHR:V3DV:3Q4H:SVDD Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 47  Goroutines: 62  System Time: 2019-08-02T11:33:31.433932824Z  EventsListeners: 2 HTTP Proxy: gateway.docker.internal:3128 HTTPS Proxy: gateway.docker.internal:3129 Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false Product License: Community Engine```**Additional environment details (AWS, VirtualBox, physical, etc.):**macOS 10.14 /w Docker for Mac 2.1.0.0
"
39648,1,534,6,0,0,henrahmagix,0,"title:Suspicious privilege escalation dialog after update [Docker for Mac]. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->![Pasted_Image_01_08_2019__17_47](https://user-images.githubusercontent.com/1429026/62311772-7863cd00-b484-11e9-9a98-97dc3c754161.png)I quit docker and restarted. It asked me if I wanted to update, so I confirmed. The update downloaded and asked me to install and relaunch: I confirmed.The top dialog appeared, which I have seen before, so I clicked ""OK"" and the bottom dialog appeared. It immediately stood out to me as not looking quite right, so I chose not to input my user password in case of an attacker gaining access to my computer.I cannot start Docker.app because the only options are to input my password or click ""Exit"".**Steps to reproduce the issue:**1. Be on a Mac2. Update Docker for Mac3. See request for privilege escalation: submit button has no text and is not aligned with the cancel button, which raises alarm.**Describe the results you received:**Alarming privilege escalation dialog.**Describe the results you expected:**A privilege escalation dialog that does not look suspicious.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.1 API version:       1.40 Go version:        go1.12.5 Git commit:        74b1e89 Built:             Thu Jul 25 21:18:17 2019 OS/Arch:           darwin/amd64 Experimental:      falseCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?```**Output of `docker info`:**```Client: Debug Mode: falseServer:ERROR: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?errors pretty printing info```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
39643,0,9621,7,1,0,Levovar,0,"title:Docker daemon crashes (again) with ""fatal error: concurrent map read and map write"". description:---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------**Description**Docker process crashes randomly with a possible concurrency / race issue similar to one observed, and corrected a year ago.**Steps to reproduce the issue:**1. Install Docker CE 19.3.02. Configure overlayfs2 as storage driver3. Enable project quotas on an XFS filesystem4. Set Docker daemon level quota for the maximum size of the container's disk  5. Create containers, delete containers, observe the system for a time**Describe the results you received:**Docker daemon crashed with error:```-- Logs begin at Tue 2019-07-30 03:12:23 CEST, end at Wed 2019-07-31 15:37:29 CEST. --Jul 31 13:06:57 controller-1 dockerd[258948]: fatal error: concurrent map read and map writeJul 31 13:06:57 controller-1 dockerd[258948]: goroutine 1371198 [running]:Jul 31 13:06:57 controller-1 dockerd[258948]: runtime.throw(0x55f62389c0dc, 0x21)Jul 31 13:06:57 controller-1 dockerd[258948]:         /usr/local/go/src/runtime/panic.go:617 +0x74 fp=0xc000db2d08 sp=0xc000db2cd8 pc=0x55f621f6c1b4Jul 31 13:06:57 controller-1 dockerd[258948]: runtime.mapaccess2_faststr(0x55f62451a880, 0xc0008a0ff0, 0xc000b01680, 0x59, 0x0, 0x0)Jul 31 13:06:57 controller-1 dockerd[258948]:         /usr/local/go/src/runtime/map_faststr.go:116 +0x4ab fp=0xc000db2d78 sp=0xc000db2d08 pc=0x55f621f512fbJul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/daemon/graphdriver/quota.(*Control).SetQuota(0xc0005e3640, 0xc000b01680, 0x59, 0x80000000, 0x0, 0x0)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/graphdriver/quota/projectquota.go:170 +0x6c fp=0xc000db2e08 sp=0xc000db2d78 pc=0x55f623388e6cJul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/daemon/graphdriver/overlay2.(*Driver).create(0xc0005e8f00, 0xc0009159c0, 0x40, 0xc001605810, 0x45, 0xc001037fa0, 0x0, 0x0)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/graphdriver/overlay2/overlay.go:420 +0x96f fp=0xc000db3078 sp=0xc000db2e08 pc=0x55f623390cbfJul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/daemon/graphdriver/overlay2.(*Driver).CreateReadWrite(0xc0005e8f00, 0xc0009159c0, 0x40, 0xc001605810, 0x45, 0xc001037fa0, 0x0, 0xc000dd6170)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/graphdriver/overlay2/overlay.go:375 +0xf1 fp=0xc000db3100 sp=0xc000db3078 pc=0x55f62338ffb1Jul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/layer.(*layerStore).CreateRWLayer(0xc0006dc4e0, 0xc000915280, 0x40, 0xc0016057c0, 0x47, 0xc000ed1be0, 0x0, 0x0, 0x0, 0x0)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/layer/layer_store.go:550 +0x30d fp=0xc000db31d8 sp=0xc000db3100 pc=0x55f622b5113dJul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/daemon/images.(*ImageService).CreateLayer(0xc0004e0cf0, 0xc001999d40, 0xc000dd6170, 0x0, 0x0, 0xc000faf180, 0xc000dbb680)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/images/service.go:133 +0x143 fp=0xc000db3250 sp=0xc000db31d8 pc=0x55f622c78793Jul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/daemon.(*Daemon).create(0xc00000c780, 0xc0008b0c1d, 0x59, 0xc000faf180, 0xc000dbb680, 0x0, 0x0, 0x0, 0x0, 0x0, ...)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/create.go:191 +0x2c4 fp=0xc000db3320 sp=0xc000db3250 pc=0x55f62361f5b4Jul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/daemon.(*Daemon).containerCreate(0xc00000c780, 0xc0008b0c1d, 0x59, 0xc000faf180, 0xc000dbb680, 0x0, 0x0, 0x0, 0x0, 0x0, ...)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/create.go:93 +0x1c9 fp=0xc000db33f0 sp=0xc000db3320 pc=0x55f62361edf9Jul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/daemon.(*Daemon).ContainerCreate(0xc00000c780, 0xc0008b0c1d, 0x59, 0xc000faf180, 0xc000dbb680, 0x0, 0x0, 0x0, 0x0, 0x0, ...)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/create.go:40 +0xf3 fp=0xc000db34d8 sp=0xc000db33f0 pc=0x55f62361ea23Jul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/api/server/router/container.(*containerRouter).postContainersCreate(0xc00079b540, 0x55f6249678a0, 0xc00144a630, 0x55f624956ca0, 0xc001ee9500, 0xc001d0b700, 0xc00144a570, 0xc0000a2001, 0xc001740dc0)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/api/server/router/container/container_routes.go:502 +0x3e2 fp=0xc000db36e8 sp=0xc000db34d8 pc=0x55f6231f6212Jul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/api/server/router/container.(*containerRouter).postContainersCreate-fm(0x55f6249678a0, 0xc00144a630, 0x55f624956ca0, 0xc001ee9500, 0xc001d0b700, 0xc00144a570, 0x55f624741e00, 0x1)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/api/server/router/container/container_routes.go:453 +0x6b fp=0xc000db3740 sp=0xc000db36e8 pc=0x55f6231fb43bJul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/api/server/middleware.ExperimentalMiddleware.WrapHandler.func1(0x55f6249678a0, 0xc00144a630, 0x55f624956ca0, 0xc001ee9500, 0xc001d0b700, 0xc00144a570, 0x55f6249678a0, 0xc00144a630)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/api/server/middleware/experimental.go:26 +0x17b fp=0xc000db37c8 sp=0xc000db3740 pc=0x55f622ab51bbJul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/api/server/middleware.VersionMiddleware.WrapHandler.func1(0x55f6249678a0, 0xc00144a600, 0x55f624956ca0, 0xc001ee9500, 0xc001d0b700, 0xc00144a570, 0x203000, 0x203000)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/api/server/middleware/version.go:62 +0x60d fp=0xc000db38d8 sp=0xc000db37c8 pc=0x55f622ab581dJul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/pkg/authorization.(*Middleware).WrapHandler.func1(0x55f6249678a0, 0xc00144a600, 0x55f624956ca0, 0xc001ee9500, 0xc001d0b700, 0xc00144a570, 0x55f6249678a0, 0xc00144a600)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/pkg/authorization/middleware.go:59 +0x82f fp=0xc000db3a80 sp=0xc000db38d8 pc=0x55f6225e168fJul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/api/server.(*Server).makeHTTPHandler.func1(0x55f624956ca0, 0xc001ee9500, 0xc001d0b600)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/api/server/server.go:142 +0x225 fp=0xc000db3b60 sp=0xc000db3a80 pc=0x55f622aca9a5Jul 31 13:06:57 controller-1 dockerd[258948]: net/http.HandlerFunc.ServeHTTP(0xc0008e0b60, 0x55f624956ca0, 0xc001ee9500, 0xc001d0b600)Jul 31 13:06:57 controller-1 dockerd[258948]:         /usr/local/go/src/net/http/server.go:1995 +0x46 fp=0xc000db3b88 sp=0xc000db3b60 pc=0x55f62227eac6Jul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/vendor/github.com/gorilla/mux.(*Router).ServeHTTP(0xc000912540, 0x55f624956ca0, 0xc001ee9500, 0xc001d0b400)Jul 31 13:06:57 controller-1 dockerd[258948]:         /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/gorilla/mux/mux.go:212 +0xe5 fp=0xc000db3cb8 sp=0xc000db3b88 pc=0x55f6225ed635Jul 31 13:06:57 controller-1 dockerd[258948]: github.com/docker/docker/api/server.(*routerSwapper).ServeHTTP(0xc000b6f2b0, 0x55f624956ca0, 0xc001ee9500, 0xc001d0b400)...```**Describe the results you expected:**Docker never crashes.**Additional information you deem important (e.g. issue happens only occasionally):**The issue is eerily similar to the issue reported in https://github.com/moby/moby/issues/32893, although the top of the stack trace here is a little bit different.It seems to be related to the overlayfs2 storage driver.Recently there were a couple of PRs seemingly touching the area: https://github.com/moby/moby/pull/39135https://github.com/moby/moby/pull/38265The description of the PR mentions actually removing artificial locks (?) to speed-up container creation.Can't it be that you have accidentally removed a lock which was guarding against some real race conditions?@thaJeztah @kolyshkin @AkihiroSuda **Output of `docker version`:**```$ docker versionClient: Docker Engine - CommunityVersion:           19.03.0API version:       1.40Go version:        go1.12.5Git commit:        aeac9490dcBuilt:             Wed Jul 17 18:15:40 2019OS/Arch:           linux/amd64Experimental:      falseServer: Docker Engine - CommunityEngine:  Version:          19.03.0  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.5  Git commit:       aeac9490dc  Built:            Wed Jul 17 18:14:16 2019  OS/Arch:          linux/amd64  Experimental:     falsecontainerd:  Version:          1.2.6  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fbrunc:  Version:          1.0.0-rc8  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87fdocker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```$ docker infoClient:Debug Mode: falseServer:Containers: 30  Running: 27  Paused: 0  Stopped: 3Images: 18Server Version: 19.03.0Storage Driver: overlay2  Backing Filesystem: xfs  Supports d_type: true  Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 894b81a4b802e4eb2a91d1ce216b8817763c29fbrunc version: 425e105d5a03fabd737a126ad93d62a9eeede87finit version: fec3683Security Options:  seccomp   Profile: defaultKernel Version: 4.19.57Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 187.3GiBName: controller-1ID: JMXB:VTC6:4FDW:XNLI:RB2F:GS76:TJ4Z:ZCPN:C3UF:W6V2:2HLX:BWFSDocker Root Dir: /var/lib/dockerDebug Mode: falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries:  127.0.0.0/8Live Restore Enabled: true```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical server machine
"
39642,1,5623,0,0,0,urp,0,"title:apt config docker-gzip-indexes created by debootstrap contains syntax error. description:**Description**The script [moby/contrib/mkimage/debootstrap](https://github.com/moby/moby/blob/589f1dad8dad7a4124457b2071a8a0f5765ac99a/contrib/mkimage/debootstrap#L154) creates an apt configuration file `/etc/apt/apt.conf.d/docker-gzip-indexes` containing a line with illegal syntax.```Acquire::CompressionTypes::Order:: ""gz"";``` Legal [apt.conf](https://linux.die.net/man/5/apt.conf) list syntax would be one of- `Acquire::CompressionTypes::Order ""gz"";`or- `Acquire::CompressionTypes::Order {""gz"";};``cupt` (a reimplementation of apt) ignores the file because of the error while `apt` silently ignores it and successfully parses the file. **Steps to reproduce the issue:**1. Run docker [image](https://hub.docker.com/r/multiarch/debian-debootstrap)  ```  docker run -it --rm multiarch/debian-debootstrap:amd64-stretch-slim  ```2. Install cupt  ```  apt update && apt install -y cupt  ```3. `cupt update` reports syntax errors and skips files**Describe the results you received:**Executing cupt update inside the container produces  ```  root@e4a9be148f73:/# cupt updateE: syntax error: line 11, character 33: expected: option value (quoted string) or opening curly bracket ('{')E: unable to parse the config file '//etc/apt/apt.conf.d/docker-gzip-indexes'W: skipped the configuration file '//etc/apt/apt.conf.d/docker-gzip-indexes'#1: starting http://deb.debian.org/debian stretch-updates InRelease                                                                                                                                                                                                                                   #2: starting http://deb.debian.org/debian stretch InRelease                                                                                                                                                                                                                                           #2: not available                                                                                                                                                                                                                                                                                     #3: starting http://security.debian.org stretch/updates InRelease                                                                                                                                                                                                                                     #4: starting http://deb.debian.org/debian stretch Release                                                                                                                                                                                                                                             100% [#3 stretch/updates InRelease 0B][#4 stretch Release 0B]                                                                                                                                                                                                                      | 5689B/s | ETA: 0sW: the 'unxz' uncompressor is not available, not downloading 'http://deb.debian.org/debian/dists/stretch-updates/main/binary-amd64/Packages.xz'#5: starting http://deb.debian.org/debian stretch-updates/main Packages.gz [32.5KiB]                                                                                                                                                                                                                  #6: starting http://deb.debian.org/debian stretch Release.gpg                                                                                                                                                                                                                                         90% [#5 stretch-updates/main Packages.gz 0B/32.5KiB 0%][#6 stretch Release.gpg 0B]                                                                                                                                                                                               | 18.5KiB/s | ETA: 0sW: the 'unxz' uncompressor is not available, not downloading 'http://security.debian.org/dists/stretch/updates/main/binary-amd64/Packages.xz'#7: starting http://security.debian.org stretch/updates/main Packages.gz [610KiB]                                                                                                                                                                                                                     #8: starting http://deb.debian.org/debian stretch-updates/main i18n/Translation-en.bz2 [11.0KiB]                                                                                                                                                                                                      34% [#7 stretch/updates/main Packages.gz 0B/610KiB 0%][#8 stretch-updates/main i18n/Translation-en.bz2 0B/11.0KiB 0%]                                                                                                                                                            | 20.7KiB/s | ETA: 3sW: the 'unxz' uncompressor is not available, not downloading 'http://deb.debian.org/debian/dists/stretch/main/binary-amd64/Packages.xz'#9: starting http://deb.debian.org/debian stretch/main Packages.gz [9253KiB]                                                                                                                                                                                                                          #10: starting http://security.debian.org stretch/updates/main i18n/Translation-en.bz2 [218KiB]                                                                                                                                                                                                        #11: starting http://deb.debian.org/debian stretch/main i18n/Translation-en.bz2 [5258KiB]                                                                                                                                                                                                             Fetched 15.3MiB in 7s.                                                                                                                                                                                                                                                                                  ```**Describe the results you expected:**No error messages from `cupt`
"
39623,0,1635,26,1,1,robertmuehsig,0,"title:After Windows Server 2019 boot containers not starting. description:**Description**Windows Server 2019 does not start containers automatically on boot, even though the containers have been started with --restart always parameter.**Steps to reproduce the issue:**1. Open up elevated PowerShell.2. Create a custom Docker network (driver nat), named blaa.3. Run a container like this: docker run -d --restart always --name testcontainer -p 8080:80 mcr.microsoft.com/windows/servercore:ltsc2019.4. Execute Restart-Computer.When the machine starts up, execute docker ps.**Describe the results you received:**docker ps shows that no containers are running.**Describe the results you expected:**docker ps lists the container named testcontainer.**Additional information you deem important (e.g. issue happens only occasionally):**Happens all the time.Windows Event Log shows errors like this:Failed to delete container 80e440a586087ed6dd1bf14bb152061eadf15d5343a2dcf6b5b2dd14e0ad98fd from containerd [error=no such container]**Output of `docker version`:**```Client: Docker Engine - Enterprise Version:           19.03.1 API version:       1.40 Go version:        go1.12.5 Git commit:        f660560464 Built:             07/25/2019 20:59:52 OS/Arch:           windows/amd64 Experimental:      falseServer: Docker Engine - Enterprise Engine:  Version:          19.03.0  API version:      1.40 (minimum version 1.24)  Go version:       go1.12.5  Git commit:       87b1f470ad  Built:            07/16/2019 23:39:21  OS/Arch:          windows/amd64  Experimental:     false```**Output of `docker info`:**```PS C:\Users\Administrator> docker infoClient: Debug Mode: false Plugins:  cluster: Manage Docker clusters (Docker Inc., v1.0.1)Server: Containers: 1  Running: 1  Paused: 0  Stopped: 0 Images: 5 Server Version: 19.03.0 Storage Driver: windowsfilter  Windows: Logging Driver: json-file Plugins:  Volume: local  Network: ics l2bridge l2tunnel nat null overlay transparent  Log: awslogs etwlogs fluentd gcplogs gelf json-file local logentries splunk syslog Swarm: inactive Default Isolation: process Kernel Version: 10.0 17763 (17763.1.amd64fre.rs5_release.180914-1434) Operating System: Windows Server 2019 Standard Version 1809 (OS Build 17763.615) OSType: windows Architecture: x86_64 CPUs: 16 Total Memory: 31.95GiB Name: 14450hostserveu ID: IJUZ:NS4Z:QY3W:DGOK:TTC4:6ZYV:Z4GW:QWS4:OFDV:XWCF:JUGI:PWW7 Docker Root Dir: C:\ProgramData\docker Debug Mode: false Username: sevitechq Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Windows Server 2019 (Version 1809)The same stuff worked in a older Windows Server 2016 environment (with a much older docker version).I guess this is related to this issue:https://github.com/moby/moby/issues/38911I also tried this, but this should already be fixed :/ https://github.com/moby/moby/issues/33542My workaround (which only work in some scenarios): Use a scheduled task to start all stopped contains like this:    docker start $(docker ps -a -q -f status=exited)
"
39576,0,841,200,1,0,thaJeztah,0,"title:Windows ""integration"" tests report incorrect status. description:Seen on https://github.com/moby/moby/pull/39569#issuecomment-513266467RS5 _failed_ due to https://github.com/moby/moby/issues/39574, but integration tests are not marked as ""failed""https://jenkins.dockerproject.org/job/Docker-PRs-WoW-RS5-Process/3055/console```09:13:44 Running C:\gopath\src\github.com\docker\docker\integration\container09:13:45 INFO: Windows Base image is  microsoft/windowsservercore09:13:45 INFO: Testing against a local daemon...09:13:52 === RUN   TestHealthKillContainer09:13:59 --- FAIL: TestHealthKillContainer (7.58s)09:13:59     health_test.go:57: assertion failed: error is not nil: Error response from daemon: Invalid signal: SIGUSR1...09:16:21 --- SKIP: TestWaitBlocked (0.00s)09:16:21     wait_test.go:59: testEnv.DaemonInfo.OSType != ""linux""09:16:21 FAIL09:16:21 Running C:\gopath\src\github.com\docker\docker\integration\image```Then it continues with `test-integration-cli````10:22:01 OK: 524 passed, 548 skipped10:22:01 PASS10:22:01 ok  	github.com/docker/docker/integration-cli	3921.066s10:22:02 INFO: Integration tests ended at 07/19/2019 10:22:02. Duration:01:05:31.5617086```
"
39574,0,254,200,0,0,thaJeztah,0,"title:Testing: TestHealthKillContainer is broken on Windows. description:Interesting failure on WindowsRS5: https://jenkins.dockerproject.org/job/Docker-PRs-WoW-RS5-Process/3063/console```11:59:47 --- FAIL: TestHealthKillContainer (8.12s)11:59:47     health_test.go:57: assertion failed: error is not nil: Error response from daemon: Invalid signal: SIGUSR1```That test was added recently in https://github.com/moby/moby/pull/39454, but rewritten in a commit in the same PR: https://github.com/moby/moby/commit/f8aef6a92f5961f2615ada37b7d108774a0821e0 In that rewrite, there were some changes:- originally it was skipped on Windows, but the rewritten test doesn't have that skip:    ```go    testRequires(c, DaemonIsLinux) // busybox doesn't work on Windows    ```- the original test used `SIGINT`, but the new one uses `SIGUSR1`
"
39544,0,255,248,0,0,andrewhsu,0,"title:Flaky test: TestFrequency. description:First spotted in PR #39528 [windowsRS1 PR check](https://jenkins.dockerproject.org/job/Docker-PRs-WoW-RS1/25893/console):```--- FAIL: TestFrequency (0.53s)    splunk_test.go:929: Unexpected number of requests 8time=""2019-07-15T18:54:46Z"" level=warning msg=""Error while sending logs"" error=""splunk: failed to send event - 500 Internal Server Error - "" module=logger/splunk```Looks like the test is taking into account time for context switch: https://github.com/moby/moby/blob/9b0097a/daemon/logger/splunk/splunk_test.go#L927But not sure why it would be flaky...could there be extra windows services running in background that eats resources?cc @ddebroy 
"
39461,1,930,264,0,0,carlosedp,0,"title:[Risc-V] Interactive terminal and tail logs not working. description:Recently Risc-V architecture have been added to Docker (moby/moby) as PR #39327.We are using Docker with Containerd and [crun](https://github.com/giuseppe/crun) runtime since runc depends on CGO that's not available on this arch yet.I found-out that running a container with `-it` to get an interactive terminal doesn't provide the terminal and freezes the session. If the container is stopped, control is returned and all inputs given to the terminal is printed at once.Another problem that might be similar is that following the logs with `logs -f` also doesn't stream the data. It only prints what's already logged and freezes. If one cancel the log tail and run again, it prints all logged messages.To reproduce, I have packed a [Risc-V Qemu VM](https://drive.google.com/open?id=1O3dQouOqygnBtP5cZZ3uOghQO7hlrFhD) and the Docker, Crun and [Containerd binaries tarball](https://drive.google.com/open?id=1Op8l6yq6H_C_zpZUpvO-zHxwbtcrAGcQ). There is a install script in the tarball and more details in the [tracker repo](https://github.com/carlosedp/riscv-bringup).Versions:```carlosedp in ~ at fedora-unleashed闂?crun --versioncrun 0.6carlosedp in ~ at fedora-unleashed闂?containerd --versioncontainerd github.com/containerd/containerd 1.2.0+unknown闂?docker versionClient: Version:           unknown-version API version:       1.40 Go version:        devel +2bdba6c078 Fri May 24 18:40:32 2019 +0000 Git commit:        unknown-commit Built:             unknown-buildtime OS/Arch:           linux/riscv64 Experimental:      trueServer: Engine:  Version:          library-import  API version:      1.41 (minimum version 1.12)  Go version:       devel +f980a63fcb Fri May 24 20:26:57 2019 +1000  Git commit:       library-import  Built:            library-import  OS/Arch:          linux/riscv64  Experimental:     false containerd:  Version:          1.2.0+unknown  GitCommit: docker-init:  Version:          0.18.0  GitCommit:        3c53686```Cc. @tonistiigi 
"
39442,0,3830,247,0,0,AkihiroSuda,0,"title:BuildKit regression: User namespaces enabled, but no uid mappings found.. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**07b3aac9020f1f5e3f7af0cb691cfb6e2189c089 (https://github.com/moby/moby/pull/39349) broke buildkit**Steps to reproduce the issue:**```console$ cat DockerfileFROM busyboxRUN echo hello$ docker build -t foo --no-cache .[+] Building 7.8s (5/5) FINISHED => [internal] load build definition from Dockerfile                                                                                                                                0.0s => => transferring dockerfile: 71B                                                                                                                                                 0.0s => [internal] load .dockerignore                                                                                                                                                   0.0s => => transferring context: 2B                                                                                                                                                     0.0s => [internal] load metadata for docker.io/library/busybox:latest                                                                                                                   7.6s => CACHED [1/2] FROM docker.io/library/busybox@sha256:c94cf1b87ccb80f2e6414ef913c748b105060debda482058d2b8d0fce39f11b9                                                             0.0s => ERROR [2/2] RUN echo hello                                                                                                                                                      0.1s------ > [2/2] RUN echo hello:#5 0.062 User namespaces enabled, but no uid mappings found.------executor failed running [/bin/sh -c echo hello]: exit code: 1```**Describe the results you received:**Failed**Describe the results you expected:**Should not fail**Additional information you deem important (e.g. issue happens only occasionally):**Regression in 07b3aac9020f1f5e3f7af0cb691cfb6e2189c089 .**Output of `docker version`:**```Client: Version:           19.09.0-dev API version:       1.40 Go version:        go1.12.6 Git commit:        83aa71c4 Built:             Mon Jul  1 02:41:10 2019 OS/Arch:           linux/amd64 Experimental:      trueServer: Engine:  Version:          dev  API version:      1.41 (minimum version 1.12)  Go version:       go1.12.6  Git commit:       e105a74c54  Built:            Mon Jul  1 05:34:48 2019  OS/Arch:          linux/amd64  Experimental:     true containerd:  Version:          v1.2.7  GitCommit:        85f6aa58b8a3170aec9824568f7a31832878b603 runc:  Version:          1.0.0-rc8  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: false Plugins:  buildx: Build with BuildKit (Docker Inc., v0.2.1-6-g8b6dfbd.m)Server: Containers: 0  Running: 0  Paused: 0  Stopped: 0 Images: 3 Server Version: dev Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: crun kata runc runnc runsc runsc-kvm Default Runtime: runc Init Binary: docker-init containerd version: 85f6aa58b8a3170aec9824568f7a31832878b603 runc version: 425e105d5a03fabd737a126ad93d62a9eeede87f init version: fec3683 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 5.0.0-20-generic Operating System: Ubuntu 19.04 OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 3.826GiB Name: suda-ws01 ID: E2YB:EGZO:6BNW:EPHS:4WFQ:EIDV:ZZ6D:QBZK:6673:CIOR:DLZ6:SI3D Docker Root Dir: /var/lib/docker Debug Mode: true  File Descriptors: 22  Goroutines: 40  System Time: 2019-07-01T14:52:47.999303347+09:00  EventsListeners: 0 Username: akihirosuda Registry: https://index.docker.io/v1/ Labels: Experimental: true Insecure Registries:  127.0.0.0/8 Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
39402,1,717,200,0,0,thaJeztah,0,"title:CI Failing on Windows RS5 due to missing C:\go. description:Looks like RS5 is currently broken, failing with this error (e.g. in https://jenkins.dockerproject.org/job/Docker-PRs-WoW-RS5-Process/2805/console):```15:20:17 INFO: Extracting git...15:20:31 INFO: Expanding go...15:20:36 Remove-Item : Cannot find path 'C:\go\' because it does not exist.15:20:36 At C:\Windows\system32\WindowsPowerShell\v1.0\Modules\Microsoft.PowerShell.Arch15:20:36 ive\Microsoft.PowerShell.Archive.psm1:411 char:4615:20:36 + ...                 $expandedItems | % { Remove-Item $_ -Force -Recurse }15:20:36 +                                          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~15:20:36     + CategoryInfo          : ObjectNotFound: (C:\go\:String) [Remove-Item], I 15:20:36    temNotFoundException15:20:36     + FullyQualifiedErrorId : PathNotFound,Microsoft.PowerShell.Commands.Remov 15:20:36    eItemCommand15:20:36  ```Looks like the failure is triggered by this line; https://github.com/moby/moby/blob/6f446d041bfd690856e63e1515d0d9514f9b684a/Dockerfile.windows#L214-L215But the error is somewhere in a PowerShell module, which attempts to remove the target location (`C:\go` before extracting), but that location is not found?Could it be there's a recent change in that PowerShell module?
"
39399,1,5301,0,0,0,olivpass,0,"title:docker build with DOCKER_BUILDKIT=1 and registry mirror results in invalid URL escape ""%2F"" error. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**docker build with DOCKER_BUILDKIT=1 and registry mirror results in invalid URL escape ""%2F"" error<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**Configure dockerd with registry mirror like this: --registry-mirror https://registry-cache.olivnet.lan:5100**Describe the results you received:**```/ # DOCKER_BUILDKIT=1 docker build alpine[+] Building 0.0s (4/4) FINISHED                                                                                                                                                                                                                                        => [internal] load .dockerignore                                                                                                                                                                                                                                 0.0s => => transferring context: 2B                                                                                                                                                                                                                                   0.0s => [internal] load build definition from Dockerfile                                                                                                                                                                                                              0.0s => => transferring dockerfile: 49B                                                                                                                                                                                                                               0.0s => ERROR [internal] load metadata for docker.io/library/alpine:latest                                                                                                                                                                                            0.0s => ERROR [1/1] FROM docker.io/library/alpine:latest                                                                                                                                                                                                              0.0s => => resolve docker.io/library/alpine:latest                                                                                                                                                                                                                    0.0s------ > [internal] load metadata for docker.io/library/alpine:latest:------------ > [1/1] FROM docker.io/library/alpine:latest:------parse https://registry-cache.olivnet.lan:5100%2F/v2/library/alpine/manifests/latest: invalid URL escape ""%2F""```**Describe the results you expected:**```/ # docker build alpineSending build context to Docker daemon  2.048kBStep 1/1 : FROM alpinelatest: Pulling from library/alpine921b31ab772b: Pull complete Digest: sha256:ca1c944a4f8486a153024d9965aafbe24f5723c1d5c02f4964c045a16d19dc54Status: Downloaded newer image for alpine:latest ---> 4d90542f0623Successfully built 4d90542f0623```**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```/ # docker versionClient: Docker Engine - Community Version:           19.03.0-rc3 API version:       1.39 (downgraded from 1.40) Go version:        go1.12.5 Git commit:        27fcb77 Built:             Thu Jun 20 01:59:14 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.6  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.8  Git commit:       481bc77  Built:            Sat May  4 02:41:08 2019  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```/ # docker infoClient: Debug Mode: falseServer: Containers: 21  Running: 17  Paused: 0  Stopped: 4 Images: 42 Server Version: 18.09.6 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local nfs  Network: bridge host macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: active  NodeID: t5hvz89si7bw58ghbro1inrws  Is Manager: true  ClusterID: psblz85iv3zyni671b2mom1k5  Managers: 3  Nodes: 3  Default Address Pool: 10.0.0.0/8    SubnetSize: 24  Orchestration:   Task History Retention Limit: 5  Raft:   Snapshot Interval: 10000   Number of Old Snapshots to Retain: 0   Heartbeat Tick: 1   Election Tick: 10  Dispatcher:   Heartbeat Period: 5 seconds  CA Configuration:   Expiry Duration: 3 months   Force Rotate: 0  Autolock Managers: false  Root Rotation In Progress: false  Node Address: 192.168.2.11  Manager Addresses:   192.168.2.11:2377   192.168.2.12:2377   192.168.2.13:2377 Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: bb71b10fd8f58240ca47fbb579b9d1028eea7c84 runc version: 2b18fe1d885ee5083ef9f0838fee39b62d653e30 init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 4.14.85-rancher Operating System: RancherOS v1.5.1 OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 3.829GiB Name: swarm-1 ID: B6MB:FP4V:JPQO:P3OA:B6PH:MMDI:JEVO:3QNT:H7PU:65S2:PNBH:KCH5 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Registry Mirrors:  https://registry-cache.olivnet.lan:5100/ Live Restore Enabled: false Product License: Community Eng```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
39353,0,1367,0,0,0,daniyalj,0,"title:Docker crashes when creating namespaces with UID in /etc/subuid and /etc/subgid. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--I am trying to create docker namespaces for my container users. The container user is going to be different per environment aka ""dev"" ""qa"" and ""prod"". The UID (610) of the user will be the same across environments. When I add UID instead of username in /etc/subuid and /etc/subgid docker crashes.-->**Steps to reproduce the issue:**1. Create subuid and subgid:Here is what `/etc/subuid` and `/etc/subgid` look like:```$ cat /etc/subuid610:123000:65536``````$ cat /etc/subgid610:123000:65536```2. Create daemon.json:```# cat /etc/docker/daemon.json{    ""icc"": false,    ""live-restore"": true,    ""no-new-privileges"": true,    ""userland-proxy"": false,    ""userns-remap"": ""610""}```3. Restart docker**Describe the results you received:**Run `systemctl restart docker` and docker will crash.Run `journalctl -xe` to see the error:```Jun 11 12:19:22 mtldserint04.certapay.com dockerd[25538]: time=""2019-06-11T12:19:22.583112066-04:00"" level=info msg=""User namespaces: ID ranges will be mapped to subuid/subgid ranges of: dev:devJun 11 12:19:22 mtldserint04.certapay.com dockerd[25538]: Can't create ID mappings: No subuid ranges found for user ""dev""```**Describe the results you expected:**Docker restart doesnt crash**Additional information you deem important (e.g. issue happens only occasionally):**Here are my users```[root@mtldserint04 ~]# cat /etc/passwd | grep devdev:x:610:610:dev user:/home/dev:/bin/bash```**Output of `docker version`:**```docker versionClient: Version:           18.09.4 API version:       1.39 Go version:        go1.10.8 Git commit:        d14af54266 Built:             Wed Mar 27 18:34:51 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.4  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.8  Git commit:       d14af54  Built:            Wed Mar 27 18:04:46 2019  OS/Arch:          linux/amd64  Experimental:     false``````**Output of `docker info`:**```docker infoContainers: 24 Running: 0 Paused: 0 Stopped: 24Images: 15Server Version: 18.09.4Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: bb71b10fd8f58240ca47fbb579b9d1028eea7c84runc version: 2b18fe1d885ee5083ef9f0838fee39b62d653e30init version: fec3683Security Options: seccomp  Profile: default usernsKernel Version: 3.10.0-957.5.1.el7.x86_64Operating System: Red Hat Enterprise LinuxOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.638GiBName: m04.***ID: ***Docker Root Dir: /var/lib/docker/123000.123000Debug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: trueProduct License: Community EngineWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**On prem RHEL 7.6 virtual machine running on VMWare
"
39345,1,4245,18,0,0,Eijebong,0,"title:Panic when attaching a network to a container with disabled networking. description:```2019-06-10 15:26:50.548309 I | http: panic serving @: assignment to entry in nil mapgoroutine 1376 [running]:net/http.(*conn).serve.func1(0xc4211068c0)	/usr/local/go/src/net/http/server.go:1726 +0xd2panic(0x558939d7e1e0, 0x55893a0c4410)	/usr/local/go/src/runtime/panic.go:502 +0x22dgithub.com/docker/docker/daemon.(*Daemon).updateNetworkSettings(0xc42090c5a0, 0xc420fb6fc0, 0x55893a101140, 0xc4210e0540, 0xc42112aa80, 0xc4217d77a0, 0x0)	/go/src/github.com/docker/docker/daemon/container_operations.go:275 +0x40egithub.com/docker/docker/daemon.(*Daemon).updateNetworkConfig(0xc42090c5a0, 0xc420fb6fc0, 0x55893a101140, 0xc4210e0540, 0xc42112aa80, 0x55893a101101, 0xc4210e0540, 0x0)	/go/src/github.com/docker/docker/daemon/container_operations.go:683 +0x219github.com/docker/docker/daemon.(*Daemon).connectToNetwork(0xc42090c5a0, 0xc420fb6fc0, 0xc420e8290f, 0x40, 0xc42112aa80, 0x558937eabd01, 0x0, 0x0)	/go/src/github.com/docker/docker/daemon/container_operations.go:728 +0x1cbgithub.com/docker/docker/daemon.(*Daemon).ConnectToNetwork(0xc42090c5a0, 0xc420fb6fc0, 0xc420e8290f, 0x40, 0xc42112aa80, 0x0, 0x0)	/go/src/github.com/docker/docker/daemon/container_operations.go:1046 +0x2b3github.com/docker/docker/daemon.(*Daemon).ConnectContainerToNetwork(0xc42090c5a0, 0xc4214ca580, 0x40, 0xc420e8290f, 0x40, 0xc42112aa80, 0x2, 0xe600000000000001)	/go/src/github.com/docker/docker/daemon/network.go:450 +0xa1github.com/docker/docker/api/server/router/network.(*networkRouter).postNetworkConnect(0xc42121bbc0, 0x55893a0edee0, 0xc420de7cb0, 0x55893a0ec2e0, 0xc4207f0e00, 0xc420173600, 0xc420de7980, 0x5589394707cc, 0x5)	/go/src/github.com/docker/docker/api/server/router/network/network_routes.go:278 +0x330github.com/docker/docker/api/server/router/network.(*networkRouter).(github.com/docker/docker/api/server/router/network.postNetworkConnect)-fm(0x55893a0edee0, 0xc420de7cb0, 0x55893a0ec2e0, 0xc4207f0e00, 0xc420173600, 0xc420de7980, 0x558937fd89dc, 0x558939f2cec0)	/go/src/github.com/docker/docker/api/server/router/network/network.go:37 +0x6bgithub.com/docker/docker/api/server/middleware.ExperimentalMiddleware.WrapHandler.func1(0x55893a0edee0, 0xc420de7cb0, 0x55893a0ec2e0, 0xc4207f0e00, 0xc420173600, 0xc420de7980, 0x55893a0edee0, 0xc420de7cb0)	/go/src/github.com/docker/docker/api/server/middleware/experimental.go:26 +0xdagithub.com/docker/docker/api/server/middleware.VersionMiddleware.WrapHandler.func1(0x55893a0edee0, 0xc420de7a70, 0x55893a0ec2e0, 0xc4207f0e00, 0xc420173600, 0xc420de7980, 0x0, 0x0)	/go/src/github.com/docker/docker/api/server/middleware/version.go:62 +0x401github.com/docker/docker/pkg/authorization.(*Middleware).WrapHandler.func1(0x55893a0edee0, 0xc420de7a70, 0x55893a0ec2e0, 0xc4207f0e00, 0xc420173600, 0xc420de7980, 0x0, 0x558939640868)	/go/src/github.com/docker/docker/pkg/authorization/middleware.go:59 +0x7abgithub.com/docker/docker/api/server/middleware.DebugRequestMiddleware.func1(0x55893a0edee0, 0xc420de7a70, 0x55893a0ec2e0, 0xc4207f0e00, 0xc420173600, 0xc420de7980, 0x55893a0edee0, 0xc420de7a70)	/go/src/github.com/docker/docker/api/server/middleware/debug.go:53 +0x4b8github.com/docker/docker/api/server.(*Server).makeHTTPHandler.func1(0x55893a0ec2e0, 0xc4207f0e00, 0xc420173600)	/go/src/github.com/docker/docker/api/server/server.go:141 +0x19anet/http.HandlerFunc.ServeHTTP(0xc420e0c0e0, 0x55893a0ec2e0, 0xc4207f0e00, 0xc420173600)	/usr/local/go/src/net/http/server.go:1947 +0x46github.com/docker/docker/vendor/github.com/gorilla/mux.(*Router).ServeHTTP(0xc420ce5950, 0x55893a0ec2e0, 0xc4207f0e00, 0xc420173600)	/go/src/github.com/docker/docker/vendor/github.com/gorilla/mux/mux.go:103 +0x228github.com/docker/docker/api/server.(*routerSwapper).ServeHTTP(0xc421078330, 0x55893a0ec2e0, 0xc4207f0e00, 0xc420173600)	/go/src/github.com/docker/docker/api/server/router_swapper.go:29 +0x72net/http.serverHandler.ServeHTTP(0xc420902f70, 0x55893a0ec2e0, 0xc4207f0e00, 0xc420173600)	/usr/local/go/src/net/http/server.go:2697 +0xbenet/http.(*conn).serve(0xc4211068c0, 0x55893a0ede20, 0xc420d81440)	/usr/local/go/src/net/http/server.go:1830 +0x653created by net/http.(*Server).Serve	/usr/local/go/src/net/http/server.go:2798 +0x27d```Seems like `Networks` can be nil herehttps://github.com/moby/moby/blob/238f8eaa31aa74be843c81703fabf774863ec30c/daemon/container_operations.go#L274I'm guessing https://github.com/moby/moby/blob/238f8eaa31aa74be843c81703fabf774863ec30c/daemon/container_operations.go#L467 is never called because https://github.com/moby/moby/blob/238f8eaa31aa74be843c81703fabf774863ec30c/daemon/container_operations.go#L433 returns early
"
39344,0,1797,11,0,0,Davidrjx,0,"title:docker inspect hang. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead. If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->a kubernetes's node in NotReady status where docker inspect certain container with id but hangs. strace output does not have obvious problem and only futex syscall take long time and more calls. furthermore, please refer to stack dump goroutine lines abstract info from attachment files[goroutine_lines.log](https://github.com/moby/moby/files/3271415/goroutine_lines.log)**Steps to reproduce the issue:**1. docker inspect container_id**Describe the results you received:**docker inspection on certain container hangs**Describe the results you expected:**docker inspection not hang and quit quickly**Additional information you deem important (e.g. issue happens only occasionally):**have happened multiple times but not often**Output of `docker version`:**```Client: Version:           18.06.2-ce API version:       1.38 Go version:        go1.10.3 Git commit:        6d37f41 Built:             Sun Feb 10 03:47:42 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          18.06.2-ce  API version:      1.38 (minimum version 1.12)  Go version:       go1.10.3  Git commit:       6d37f41  Built:            Sun Feb 10 03:46:06 2019  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 6 Running: 4 Paused: 0 Stopped: 2Images: 13Server Version: 18.06.2-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: nvidia runcDefault Runtime: nvidiaInit Binary: docker-initcontainerd version: 468a545b9edcd5932818eb9de8e72413e616e86erunc version: 6635b4f0c6af3810594d2770f662f34ddc15b40d-dirty (expected: 69663f0bd4b60df09991c08812a60108003fa340)init version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 4.9.0-8-amd64Operating System: Debian GNU/Linux 9 (stretch)OSType: linuxArchitecture: x86_64CPUs: 56Total Memory: 251.8GiBName: ai-1080ti-47ID: Z75K:QNVD:W453:ZI3Z:2GA2:R7RQ:QO3E:JYVJ:G3JW:IV5T:6F6S:2FWPDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseHTTP Proxy: http://proxy:8787HTTPS Proxy: http://proxy:8787No Proxy: 127.0.0.1,localhostRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**bare metal
"
39301,0,2011,0,0,0,dohse,0,"title:User and group ids in /etc/subuid and /etc/subgid are not used in the order specified. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Moby currently sorts uid and gid ranges in id maps. This causes subuid and subgid files to be interpreted wrongly.**Steps to reproduce the issue:**1. Enable `userns-remap` for docker.2. Configure a subuid file which does not specify the host user id in ascending order. For instance:    ```> cat /etc/subuidjonas:100000:1000jonas:1000:1```3. Restart docker4. Check resulting host to container user namespace mapping with `docker run ubuntu cat /proc/self/uid_map`**Describe the results you received:**Host user id 1000 is mapped to container user id 0 (root) and host user ids 100000-100999 are mapped to container user ids 1-1000.```> docker run ubuntu cat /proc/self/uid_map         0       1000          1         1     100000       1000```**Describe the results you expected:**Host user id 1000 is mapped to container user id 1000 and host user ids 100000-100999 are mapped to container user ids 0-999.```> docker run ubuntu cat /proc/self/uid_map         0     100000       1000      1000       1000          1```**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```> docker versionClient: Version:           18.09.6 API version:       1.39 Go version:        go1.10.8 Git commit:        481bc77 Built:             Sat May  4 02:35:57 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.6  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.8  Git commit:       481bc77  Built:            Sat May  4 01:59:36 2019  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 2 Running: 0 Paused: 0 Stopped: 2Images: 1Server Version: 18.09.6Storage Driver: btrfs Build Version: Btrfs v4.7.3 Library Version: 101Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: bb71b10fd8f58240ca47fbb579b9d1028eea7c84runc version: 2b18fe1d885ee5083ef9f0838fee39b62d653e30init version: fec3683Security Options: apparmor seccomp  Profile: default usernsKernel Version: 4.15.0-50-genericOperating System: Ubuntu 18.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.43GiBName: MinunID: L3XT:OUUV:BHHA:S2QW:W3WN:TTHD:62AZ:K5BI:X4FJ:XW6R:ZQVD:DX6PDocker Root Dir: /var/lib/docker/1000.999Debug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community EngineWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
39274,0,8517,0,0,1,inosvaruag,0,"title:Docker json-file logging driver hangs when rotating files on Windows. description:**Description**Docker json-file logging driver hangs when rotating files on Windows. Once a container gets in hung state, no more log entries are saved for it unless docker or the container is restarted.PS> Get-EventLog -LogName Application -Source Docker shows the following error messages:```Failed to log msg """" for logger json-file: error removing oldest log file: remove C:\ProgramData\docker\containers\e9b7722458801aadcfdc6f37a7d44c077c36d3680a906a305dad878e9cf6a9ae\e9b7722458801aadcfdc6f37a7d44c077c36d3680a906a305dad878e9cf6a9ae-json.log.1: The process cannot access the file because it is being used by another process.```(REPEATED UNTIL MITIGATED) ```Failed to log msg """" for logger json-file: error closing file: close C:\ProgramData\docker\containers\e9b7722458801aadcfdc6f37a7d44c077c36d3680a906a305dad878e9cf6a9ae\e9b7722458801aadcfdc6f37a7d44c077c36d3680a906a305dad878e9cf6a9ae-json.log: file already closed.```The issue does not happen every time but happens quite frequently.**Steps to reproduce the issue:**0. Run a Windows 2019 OS VM with docker using named pipes.1. Run a docker container on the VM which outputs some log entries. Set this container to use json-file logging driver with 1M file size and 2 file-limit.2. Create another docker container which is has the docker named pipe mounted. Run periodic ContainerLogs API call for the container in step 1 in this container.3. Let the setup run until Event log entries start showing the error messages described above. Once this state is reached, no more logs are captured in the json files.**Describe the results you received:**1. Container logs stop getting captured on log file rotation.**Describe the results you expected:**1. Container logs should not get stuck.**Additional information you deem important (e.g. issue happens only occasionally):**This issue does not occur every time. But it happens very frequently when multiple containers are running on multiple VMs.**Output of `docker version`:**```> docker versionClient: Version:           18.09.3 API version:       1.39 Go version:        go1.10.8 Git commit:        142dfcedca Built:             02/28/2019 06:33:17 OS/Arch:           windows/amd64 Experimental:      falseServer: Engine:  Version:          18.09.3  API version:      1.39 (minimum version 1.24)  Go version:       go1.10.8  Git commit:       142dfcedca  Built:            02/28/2019 06:31:15  OS/Arch:          windows/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 4 Running: 4 Paused: 0 Stopped: 0Images: 4Server Version: 18.09.3Storage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: ics l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd gelf json-file local logentries splunk syslogSwarm: inactiveDefault Isolation: processKernel Version: 10.0 17763 (17763.1.amd64fre.rs5_release.180914-1434)Operating System: Windows Server 2019 Datacenter Version 1809 (OS Build 17763.316)OSType: windowsArchitecture: x86_64CPUs: 4Total Memory: 15GiBName: dc48a85165fcf24ID: KCKO:GJP5:M7R3:IE45:2LVF:FCYR:MOBJ:DFS7:BBV6:L4XV:DRZY:ZA5MDocker Root Dir: C:\ProgramData\dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Windows 2019 VM on GCPMitigations = restart affected container, or restart docker service on Windows.**docker inspect output on a container which got into this state**```> docker inspect e9b[    {        ""Id"": ""e9b7722458801aadcfdc6f37a7d44c077c36d3680a906a305dad878e9cf6a9ae"",        ""Created"": ""REDACTED"",        ""Path"": ""REDACTED"",        ""Args"": [           ""REDACTED""        ],        ""State"": {            ""Status"": ""running"",            ""Running"": true,            ""Paused"": false,            ""Restarting"": false,            ""OOMKilled"": false,            ""Dead"": false,            ""Pid"": 3648,            ""ExitCode"": 0,            ""Error"": """",            ""StartedAt"": ""2019-05-28T00:52:02.4274538Z"",            ""FinishedAt"": ""2019-05-28T00:52:00.7740957Z""        },        ""Image"": ""sha256:b301392b301239e154b21e03c8b77c03abd14e8ab3459835036a411998b60fd8"",        ""ResolvConfPath"": """",        ""HostnamePath"": """",        ""HostsPath"": """",        ""LogPath"": ""C:\\ProgramData\\docker\\containers\\e9b7722458801aadcfdc6f37a7d44c077c36d3680a906a305dad878e9cf6a9ae\\e9b7722458801aadcfdc6f37a7d44c077c36d3680a906a305dad878e9cf6a9ae-json.log"",        ""Name"": ""REDACTED"",        ""RestartCount"": 0,        ""Driver"": ""windowsfilter"",        ""Platform"": ""windows"",        ""MountLabel"": """",        ""ProcessLabel"": """",        ""AppArmorProfile"": """",        ""ExecIDs"": null,        ""HostConfig"": {            ""Binds"": [                ""REDACTED""            ],            ""ContainerIDFile"": """",            ""LogConfig"": {                ""Type"": ""json-file"",                ""Config"": {                    ""max-file"": ""2"",                    ""max-size"": ""1m""                }            },            ""NetworkMode"": ""nat"",            ""PortBindings"": null,            ""RestartPolicy"": {                ""Name"": ""unless-stopped"",                ""MaximumRetryCount"": 0            },            ""AutoRemove"": false,            ""VolumeDriver"": """",            ""VolumesFrom"": null,            ""CapAdd"": null,            ""CapDrop"": null,            ""Dns"": null,            ""DnsOptions"": null,            ""DnsSearch"": null,            ""ExtraHosts"": null,            ""GroupAdd"": null,            ""IpcMode"": """",            ""Cgroup"": """",            ""Links"": null,            ""OomScoreAdj"": 0,            ""PidMode"": """",            ""Privileged"": false,            ""PublishAllPorts"": false,            ""ReadonlyRootfs"": false,            ""SecurityOpt"": null,            ""UTSMode"": """",            ""UsernsMode"": """",            ""ShmSize"": 0,            ""ConsoleSize"": [                0,                0            ],            ""Isolation"": ""process"",            ""CpuShares"": 0,            ""Memory"": 0,            ""NanoCpus"": 0,            ""CgroupParent"": """",            ""BlkioWeight"": 0,            ""BlkioWeightDevice"": null,            ""BlkioDeviceReadBps"": null,            ""BlkioDeviceWriteBps"": null,            ""BlkioDeviceReadIOps"": null,            ""BlkioDeviceWriteIOps"": null,            ""CpuPeriod"": 0,            ""CpuQuota"": 0,            ""CpuRealtimePeriod"": 0,            ""CpuRealtimeRuntime"": 0,            ""CpusetCpus"": """",            ""CpusetMems"": """",            ""Devices"": null,            ""DeviceCgroupRules"": null,            ""DiskQuota"": 0,            ""KernelMemory"": 0,            ""MemoryReservation"": 0,            ""MemorySwap"": 0,            ""MemorySwappiness"": null,            ""OomKillDisable"": null,            ""PidsLimit"": 0,            ""Ulimits"": null,            ""CpuCount"": 0,            ""CpuPercent"": 0,            ""IOMaximumIOps"": 0,            ""IOMaximumBandwidth"": 0,            ""MaskedPaths"": null,            ""ReadonlyPaths"": null        },        ""GraphDriver"": {            ""Data"": {                ""dir"": ""C:\\ProgramData\\docker\\windowsfilter\\e9b7722458801aadcfdc6f37a7d44c077c36d3680a906a305dad878e9cf6a9ae""            },            ""Name"": ""windowsfilter""        },        ""Mounts"": [            {                ""Type"": ""bind"",                ""Source"": ""REDACTED"",                ""Destination"": ""REDACTED"",                ""Mode"": """",                ""RW"": true,                ""Propagation"": """"            }        ],        ""Config"": {            ""Hostname"": ""REDACTED"",            ""Domainname"": """",            ""User"": """",            ""AttachStdin"": false,            ""AttachStdout"": false,            ""AttachStderr"": false,            ""Tty"": false,            ""OpenStdin"": false,            ""StdinOnce"": false,            ""Env"": null,            ""Cmd"": [                ""REDACTED"",            ],            ""Image"": ""REDACTED"",            ""Volumes"": null,            ""WorkingDir"": """",            ""Entrypoint"": [],            ""OnBuild"": null,            ""Labels"": {                ""agent.config"": ""REDACTED"",                ""agent.managed"": ""true""            },            ""StopSignal"": ""SIGTERM""        },        ""NetworkSettings"": {            ""Bridge"": """",            ""SandboxID"": ""e9b7722458801aadcfdc6f37a7d44c077c36d3680a906a305dad878e9cf6a9ae"",            ""HairpinMode"": false,            ""LinkLocalIPv6Address"": """",            ""LinkLocalIPv6PrefixLen"": 0,            ""Ports"": {},            ""SandboxKey"": ""e9b7722458801aadcfdc6f37a7d44c077c36d3680a906a305dad878e9cf6a9ae"",            ""SecondaryIPAddresses"": null,            ""SecondaryIPv6Addresses"": null,            ""EndpointID"": """",            ""Gateway"": """",            ""GlobalIPv6Address"": """",            ""GlobalIPv6PrefixLen"": 0,            ""IPAddress"": """",            ""IPPrefixLen"": 0,            ""IPv6Gateway"": """",            ""MacAddress"": """",            ""Networks"": {                ""nat"": {                    ""IPAMConfig"": null,                    ""Links"": null,                    ""Aliases"": null,                    ""NetworkID"": ""93a8f0003991defdec723729ef537a49ecab734ede99e070a8dd1181ff79137e"",                    ""EndpointID"": ""8d8509776404f0d0532d5afe3132c5a4a63e94e0b5fcb94751d53f24e29e1f9a"",                    ""Gateway"": ""REDACTED"",                    ""IPAddress"": ""REDACTED"",                    ""IPPrefixLen"": 16,                    ""IPv6Gateway"": """",                    ""GlobalIPv6Address"": """",                    ""GlobalIPv6PrefixLen"": 0,                    ""MacAddress"": ""00:15:5d:02:1c:ff"",                    ""DriverOpts"": null                }            }        }    }]```
"
39109,1,0,279,0,0,cpuguy83,0,"title:runc regression - EPERM running containers from selinux. description:Trying to run containers on centOS with selinux enforcing on, runc gets a denial trying to access `/proc/self/attrs/keycreate`.This happens when `selinux-enabled=false` on dockerd, which is the default. When `selinux-enabled=true` all is OK.Reverting runc to an older commit (which does not mess with this file), everything starts up properly.
"
39025,0,3829,247,0,0,AkihiroSuda,0,"title:daemon takes 10 seconds to start up. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->daemon takes 10 seconds to start up**Steps to reproduce the issue:**```consolehost$ make binaryhost$ make shellroot@1aa83bab59da:/go/src/github.com/docker/docker# make installroot@1aa83bab59da:/go/src/github.com/docker/docker# dockerd --debug```**Describe the results you received:**```DEBU[2019-04-08T08:55:53.241071361Z] Listener created for HTTP on unix (/var/run/docker.sock)INFO[2019-04-08T08:55:53.243201836Z] libcontainerd: started new containerd process  pid=592...INFO[2019-04-08T08:55:53.292274462Z] loading plugin ""io.containerd.grpc.v1.tasks""...  type=io.containerd.grpc.v1INFO[2019-04-08T08:55:53.292454991Z] loading plugin ""io.containerd.grpc.v1.version""...  type=io.containerd.grpc.v1INFO[2019-04-08T08:55:53.292537567Z] loading plugin ""io.containerd.grpc.v1.introspection""...  type=io.containerd.grpc.v1INFO[2019-04-08T08:55:53.293552156Z] serving...                                    address=""/var/run/docker/containerd/containerd-debug.sock""INFO[2019-04-08T08:55:53.293893768Z] serving...                                    address=""/var/run/docker/containerd/containerd.sock""INFO[2019-04-08T08:55:53.294478682Z] containerd successfully booted in 0.029851sINFO[2019-04-08T08:55:53.302507167Z] pickfirstBalancer: HandleSubConnStateChange: 0xc000059ec0, READY  module=grpcDEBU[2019-04-08T08:55:53.385721472Z] garbage collected                             d=1.292334ms********** No log for 10 seconds **********DEBU[2019-04-08T08:56:03.307056671Z] Golang's threads limit set to 56610INFO[2019-04-08T08:56:03.308500716Z] parsed scheme: ""unix""                         module=grpcINFO[2019-04-08T08:56:03.308547727Z] scheme ""unix"" not registered, fallback to default scheme  module=grpcINFO[2019-04-08T08:56:03.308615281Z] parsed scheme: ""unix""                         module=grpcINFO[2019-04-08T08:56:03.308629612Z] scheme ""unix"" not registered, fallback to default scheme  module=grpc...DEBU[2019-04-08T08:56:03.756733049Z] Registering POST, /networks/pruneDEBU[2019-04-08T08:56:03.756932121Z] Registering DELETE, /networks/{id:.*}INFO[2019-04-08T08:56:03.759024954Z] API listen on /var/run/docker.sock```**Describe the results you expected:**Starts up quickly**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.06.2-ce API version:  1.30 Go version:   go1.8.3 Git commit:   cec0b72 Built:        Tue Sep  5 19:57:21 2017 OS/Arch:      linux/amd64Server: Version:      dev API version:  1.40 (minimum version 1.12) Go version:   go1.12.1 Git commit:   32923464b8 Built:        Mon Apr  8 08:53:02 2019 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: devStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: bb71b10fd8f58240ca47fbb579b9d1028eea7c84runc version: 2b18fe1d885ee5083ef9f0838fee39b62d653e30init version: fec3683Security Options: apparmor seccomp  Profile: defaultKernel Version: 4.15.0-47-genericOperating System: Debian GNU/Linux 9 (stretch) (containerized)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 7.767GiBName: 1aa83bab59daID: f20c35d8-e6e5-4628-b969-52fc3cd779ceDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 21 Goroutines: 44 System Time: 2019-04-08T08:56:24.011449372Z EventsListeners: 0Registry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit supportWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**Host: Ubuntu 18.04.2 kernel `4.15.0-47-generic #50-Ubuntu` running on VMware Fusion
"
39023,0,2910,101,0,0,StefanScherer,0,"title:19.03.0-beta1: docker service scale does not always wait to converge. description:**Description**I tested Docker CE 19.03.0-beta1 in swarm mode and `docker service scale` does not always wait until the service has converged. I also tried different version of Docker CLI 18.09.2 and 19.03.0-beta1, but both show the same behaviour.**Steps to reproduce the issue:**1. `docker swarm init`2. `docker service scale --name whoami -p 8080:8080 stefanscherer/whoami`3. `docker service scale whoami=8`4. `docker service scale whoami=1`5. repeat 3 and 4**Describe the results you received:****Describe the results you expected:**[![asciicast](https://asciinema.org/a/NujZowdrbeZ7EV2EeK88UPM7i.svg)](https://asciinema.org/a/NujZowdrbeZ7EV2EeK88UPM7i)**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Docker Engine - Community Version:           19.03.0-beta1 API version:       1.40 Go version:        go1.12.1 Git commit:        62240a9 Built:             Thu Apr  4 19:15:07 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          19.03.0-beta1  API version:      1.40 (minimum version 1.12)  Go version:       go1.12.1  Git commit:       62240a9  Built:            Thu Apr  4 19:22:34 2019  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.2.5  GitCommit:        bb71b10fd8f58240ca47fbb579b9d1028eea7c84 runc:  Version:          1.0.0-rc6+dev  GitCommit:        2b18fe1d885ee5083ef9f0838fee39b62d653e30 docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Client: Debug Mode: falseServer: Containers: 1  Running: 1  Paused: 0  Stopped: 0 Images: 1 Server Version: 19.03.0-beta1 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: active  NodeID: ld0yhhwtiw3r4rtk58xctd01w  Is Manager: true  ClusterID: ezhecyk9ipzrwfiazcw58kmfb  Managers: 1  Nodes: 1  Default Address Pool: 10.0.0.0/8    SubnetSize: 24  Data Path Port: 4789  Orchestration:   Task History Retention Limit: 5  Raft:   Snapshot Interval: 10000   Number of Old Snapshots to Retain: 0   Heartbeat Tick: 1   Election Tick: 10  Dispatcher:   Heartbeat Period: 5 seconds  CA Configuration:   Expiry Duration: 3 months   Force Rotate: 0  Autolock Managers: false  Root Rotation In Progress: false  Node Address: 192.168.99.100  Manager Addresses:   192.168.99.100:2377 Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: bb71b10fd8f58240ca47fbb579b9d1028eea7c84 runc version: 2b18fe1d885ee5083ef9f0838fee39b62d653e30 init version: fec3683 Security Options:  seccomp   Profile: default Kernel Version: 4.14.111-boot2docker Operating System: Boot2Docker 19.03.0-beta1 (TCL 8.2.1) OSType: linux Architecture: x86_64 CPUs: 1 Total Memory: 989.4MiB Name: v19.03.0-beta1 ID: 8b0c44ac-8def-47d2-a120-5fc4a16beabc Docker Root Dir: /mnt/sda1/var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels:  provider=virtualbox Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false Product License: Community Engine```**Additional environment details (AWS, VirtualBox, physical, etc.):**```docker-machine create -d virtualbox --virtualbox-boot2docker-url https://github.com/boot2docker/boot2docker/releases/download/v19.03.0-beta1/boot2docker.iso v19.03.0-beta1```
"
38995,0,0,8,0,0,arindamchoudhury,0,"title:docker cp returns 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墰缁犳梹绻?space left on device闂?if entire host filesystem is mounted. description:This is the definition of the docker container:    version: '2'    services:        alpine-test:           container_name: alpine-test           image: alpine:latest           command: tail -F /dev/null           volumes:               - /:/rootfsIf I try to copy a file from this container, eventually it returns ""Error response from daemon: no space left on device"" error:    # docker cp alpine-test:/etc/hostname /tmp/    # docker cp alpine-test:/etc/hostname /tmp/    # docker cp alpine-test:/etc/hostname /tmp/    Error response from daemon: no space left on device    #I am failed to find any workaround or explanation of this.Thanks
"
38982,0,3008,20,0,0,ralmn,0,"title:Buildkit copy in symbolic link failed. description:**Description**Copy the file into the children's folder of a symbolic link fails when buildkit is enabled**Steps to reproduce the issue:**1. Create files`Dockerfile` :```FROM ubuntu RUN mkdir -p /opt/origin/dir1/dir2RUN ln -s /opt/origin /opt/linkRUN ls -al /optCOPY test.1.txt /opt/origin/dir1/dir2/COPY test.2.txt /opt/link/COPY test.3.txt /opt/link/dir1/dir2/RUN ls -al /opt/link/dir1/dir2````test.1.txt`, `test.2.txt`, `test.3.txt` : ```test file```2. Enable buildkit `export DOCKER_BUILDKIT=1 `3. `docker build --no-cache .`**Describe the results you received:**Build failed``` => [7/8] COPY test.3.txt /opt/link/dir1/dir2/:#12 0.338 panic: mkdir opt/link: file exists#12 0.338 #12 0.338 goroutine 1 [running]:#12 0.338 main.main()#12 0.338 	/go/src/github.com/tonistiigi/copy/cmd/copy/main.go:57 +0x2af``` **Describe the results you expected:**Build OK``` => [6/8] COPY test.3.txt /opt/link/dir1/dir2/```**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:           18.09.4 API version:       1.39 Go version:        go1.10.8 Git commit:        d14af54266 Built:             Wed Mar 27 18:35:44 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.4  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.8  Git commit:       d14af54  Built:            Wed Mar 27 18:01:48 2019  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 7 Running: 0 Paused: 0 Stopped: 7Images: 31Server Version: 18.09.4Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: active NodeID: zs4kgdqguce206ypszfakqwfc Is Manager: true ClusterID: mrsvptvgablchrfxemnlfvh7e Managers: 1 Nodes: 1 Default Address Pool: 10.0.0.0/8   SubnetSize: 24 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 10 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 172.17.17.55 Manager Addresses:  172.17.17.55:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: bb71b10fd8f58240ca47fbb579b9d1028eea7c84runc version: 2b18fe1d885ee5083ef9f0838fee39b62d653e30init version: fec3683Security Options: apparmor seccomp  Profile: defaultKernel Version: 4.15.0-46-genericOperating System: Ubuntu 18.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 15.55GiBName: dsi-mhirelID: OWEW:UC76:M4D5:5SKC:VPDP:T4LG:FAXI:ZRJB:R72R:UDKK:UWUF:OISUDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community EngineWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**```lsb_release -aNo LSB modules are available.Distributor ID:	UbuntuDescription:	Ubuntu 18.04.2 LTSRelease:	18.04Codename:	bionic``` 
"
38978,0,1748,17,0,0,Supermathie,0,"title:docker cannot terminate a container when processes linger after TERM. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. Set up multiple containers in a sidecar style2. Attempt to restart one of the sidecars where one of the processes lingers after TERM**Describe the results you received:**1. `docker restart` hangs forever1. other commands to inspect state (exec, stats, top) also hang1. docker is unable to kill the container's processes**Describe the results you expected:**1. successful restart**Additional information you deem important (e.g. issue happens only occasionally):**Unloaded system, 100% reproducibleKilling the lingering process in the container allows the restart to happenSame setup works as expected on 17.06.2 on Ubuntu**Output of `docker version`:**```Client: Version:           18.09.3 API version:       1.39 Go version:        go1.10.8 Git commit:        774a1f4 Built:             Thu Feb 28 06:34:04 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.3  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.8  Git commit:       774a1f4  Built:            Thu Feb 28 05:59:55 2019  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 20 Running: 20 Paused: 0 Stopped: 0Images: 22Server Version: 18.09.3Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 173 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: e6b3f5632f50dbc4e9cb6288d911bf4f5e95b18erunc version: 6635b4f0c6af3810594d2770f662f34ddc15b40dinit version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 4.9.0-8-amd64Operating System: Debian GNU/Linux 9 (stretch)OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 15.5GiBName: tieinterceptor1aID: Z7MI:MQEK:2BAR:CAQO:VV6B:4HO6:6YDV:OP23:CMQK:CMOD:UZ3A:HP5VDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: trueProduct License: Community EngineWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**bare metal
"
38964,1,1734,144,0,0,Antiarchitect,0,"title:COPY and ADD with multiple <src> do not invalidate cache if Docker Buildkit is turned on.. description:**Description**BUG REPORT INFORMATION<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. Use Dockerfile with `ADD 1.txt 2.txt ./`2. Build it with DOCKER_BUILDKIT=13. Change 2.txt content4. Build again**Describe the results you received:**The result of the ADD step is cached**Describe the results you expected:**ADD step should not be cached**Additional information you deem important (e.g. issue happens only occasionally):**https://github.com/Antiarchitect/docker-buildkit-bug - Repo where you can reproduce**Output of `docker version`:**```Client: Version:           18.09.3 API version:       1.39 Go version:        go1.10.8 Git commit:        774a1f4 Built:             Thu Feb 28 06:34:10 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.3  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.8  Git commit:       774a1f4  Built:            Thu Feb 28 06:02:24 2019  OS/Arch:          linux/amd64  Experimental:     true```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 507Server Version: 18.09.3Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: e6b3f5632f50dbc4e9cb6288d911bf4f5e95b18erunc version: 6635b4f0c6af3810594d2770f662f34ddc15b40dinit version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 5.0.3-200.fc29.x86_64Operating System: Fedora 29 (Twenty Nine)OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 15.6GiBName: localhost.localdomainID: P5EM:M6NC:P7AY:35ET:CJUH:AITQ:CENP:LJB7:4IOL:ZQMC:YVJG:F7OKDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: antiarchitectRegistry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community Engine```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
38951,0,0,8,0,0,alexei38,0,"title:fluentd log driver failed parse last partial message. description:I use fluentd logging driverIn my containers the log it is more than 16 kbSuch the log are marked with partial_message flagfluent-plugin-concat waited for the message which came without partial_message from stopped to stick together the message for further transfer
"
38901,1,2414,0,0,0,dcourvoi,0,"title:""Docker network rm"" does not remove Resolver UDP port 53 for created gateway IP. description:**Description**When using docker-compose up without any network configuration in it, a new network is created by docker. A Gateway is also created which will resolve the container dns on that network. This creates a listening UDP port 53 on the gateway IP.When this network is deleted (for example using docker-compose down, or docker network rm commands), the listening UDP port 53 on that gateway IP is not unbound.Next time this gateway IP is chosen/used by docker, the resolver will not be started and containers within that network will not be reachable by name.When a gateway IP is reused on windows, the following event is logged:Resolver Setup/Start failed for container test_default, ""error in  opening name server socket listen udp 172.17.48.1:53: bind: Only one usage of  each socket address (protocol/network address/port) is normally permitted.""The command ""netstat -p UDP -a"" can be used to show all IP's previously used as gateway by docker.**Steps to reproduce the issue:**1. docker-compose up2. docker inspect one of the container to get the Gateway IP3. run ""netstat -p UDP -a"" and see all bound ports on the Gateway IP4. Shutdown containers using docker-compose down5. Run ""netstat -p UDP -a"" and observe that Gateway IP port 53 is still bound.**Describe the results you received:**Gateway IP port 53 is still bound**Describe the results you expected:**Gateway IP port 53 is not bound anymore**Additional information you deem important (e.g. issue happens only occasionally):**This seems to happen on various version of docker, linux (18.09.3), windows ee(18.09.3) and windows docker desktop(18.09.2). Restarting docker service will cleanup the ports 53.The issue in event logs looks sporadic as the same gateway IP needs to be reused in order for containers to be not reachable.See below a console log demonstrating using docker rm on a windows machine:```ADMIN PS C:\WINDOWS\system32> docker network lsNETWORK ID          NAME                             DRIVER              SCOPE63a50935c925        platform-tests_default           nat                 locala0c43e0cda13        nat                              nat                 local716818e83062        none                             null                localADMIN PS C:\WINDOWS\system32> netstat -p UDP -an | findstr 172.17.48.1  UDP    172.17.48.1:53         *:*  UDP    172.17.48.1:137        *:*  UDP    172.17.48.1:138        *:*  UDP    172.17.48.1:1900       *:*  UDP    172.17.48.1:57209      *:*ADMIN PS C:\WINDOWS\system32> docker network rm 63a50935c92563a50935c925ADMIN PS C:\WINDOWS\system32> netstat -p UDP -an | findstr 172.17.48.1  UDP    172.17.48.1:53         *:*```**Output of `docker version`:**```Client: Docker Engine - Community Version:           18.09.2 API version:       1.39 Go version:        go1.10.8 Git commit:        6247962 Built:             Sun Feb 10 04:12:31 2019 OS/Arch:           windows/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.2  API version:      1.39 (minimum version 1.24)  Go version:       go1.10.6  Git commit:       6247962  Built:            Sun Feb 10 04:28:48 2019  OS/Arch:          windows/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 9 Running: 0 Paused: 0 Stopped: 9Images: 28Server Version: 18.09.2Storage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: ics l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd gelf json-file local logentries splunk syslogSwarm: inactiveDefault Isolation: hypervKernel Version: 10.0 17763 (17763.1.amd64fre.rs5_release.180914-1434)Operating System: Windows 10 Enterprise Version 1809 (OS Build 17763.316)OSType: windowsArchitecture: x86_64CPUs: 12Total Memory: 31.74GiBName: DC-774374ID: DCUB:SOVD:3QXH:OW76:5R4G:R47C:KVLB:HHNJ:R45Y:OFYC:42NQ:VXDMDocker Root Dir: C:\ProgramData\DockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: -1 Goroutines: 96 System Time: 2019-03-19T10:34:41.067655+01:00 EventsListeners: 1Registry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community Engine```
"
38865,0,2252,15,0,0,Random-Liu,0,"title:Exec process doesn't preserve init process uid/gid/additionalgids since 18.06. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**```console$ docker run --group-add 1234 busybox id -G0 10 1234$ docker run --group-add 1234 -d busybox sleep 1000ded77fec7e0bc07542037ad4a669b7ffed3211d2762fc1d3381fa84af67f28c1$ docker exec de id -G0```**Describe the results you received:**Exec doesn't preserve uid/gid/additionalgids.**Describe the results you expected:**Exec should preserve it. With 17.03.2-ce:```$ docker run --group-add 1234 busybox id -G0 10 1234lantaol@e2e-test-lantaol-minion-group-cq8p ~ $ docker run --group-add 1234 -d busybox sleep 100087e52362a4962267f408d6646c3de4482b5f6247de5362103c309bbeadccc175lantaol@e2e-test-lantaol-minion-group-cq8p ~ $ docker exec 87 id -G0 10 1234```**Additional information you deem important (e.g. issue happens only occasionally):**This is introduced by https://github.com/moby/moby/commit/ddae20c032058a0fd42c34c2e9750ee8f6296ac8#diff-3ed197c0a6f7a9ca73a3ee424e448ac1.Before updating to containerd 1.0, when init process spec is preserved by default (uid/gid/additional gids are also preserved): https://github.com/moby/moby/commit/ddae20c032058a0fd42c34c2e9750ee8f6296ac8#diff-15c000aa4859d8b3bae42251a9a13b15L61However, after updating to containerd 1.0, the OCI `spec` is generated and passed to containerd directly https://github.com/moby/moby/commit/ddae20c032058a0fd42c34c2e9750ee8f6296ac8#diff-10e0e646b98a7523848294e49bce04ecR268, and the user field of OCI `spec` doesn't default to init process spec. (See https://github.com/moby/moby/commit/ddae20c032058a0fd42c34c2e9750ee8f6296ac8#diff-3ed197c0a6f7a9ca73a3ee424e448ac1R218 and https://github.com/moby/moby/commit/ddae20c032058a0fd42c34c2e9750ee8f6296ac8#diff-9e56cba9cecf8fa358ccc62d97eb6320R12).**Output of `docker version`:**```Client: Version:           18.09.1 API version:       1.39 Go version:        go1.10.6 Git commit:        4c52b90 Built:             Wed Jan  9 19:35:23 2019 OS/Arch:           linux/amd64 Experimental:      trueServer: Docker Engine - Community Engine:  Version:          18.09.3  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.8  Git commit:       774a1f4  Built:            Thu Feb 28 05:59:55 2019  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 6 Running: 3 Paused: 0 Stopped: 3Images: 201Server Version: 18.09.3Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 217 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 075e1ed4e0bbe6219c8ebbe57deace356970f1c7.mrunc version: 2b18fe1d885ee5083ef9f0838fee39b62d653e30init version: fec3683Security Options: apparmor seccomp  Profile: defaultKernel Version: 4.15.0-1021-gcpOperating System: Ubuntu 16.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 32Total Memory: 118GiBName: workspaceID: ZZQS:5I4Q:LHOK:XCBD:DOTJ:3ZTN:Y7PT:JIZI:TR6M:OQSO:INDV:WOEWDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community EngineWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
38817,1,8465,290,0,0,tonistiigi,0,"title:rootless: race on starting containers in dind. description:Tried to use dind in rootless mode. Starting dockerd with `--rootless`.There seems to be a race on doing `docker run`.  Very short lived containers work. Eg. `docker run alpine ls` and `docker run alpine usleep 500` works but `docker run alpine usleep 1000` fails.```docker: Error response from daemon: cgroups: cgroup deleted: unknown.ERRO[0000] error waiting for container: context canceled``````time=""2019-03-02T03:11:41.744381969Z"" level=debug msg=""Calling GET /_ping""time=""2019-03-02T03:11:41.745662780Z"" level=debug msg=""Calling POST /v1.30/containers/create""time=""2019-03-02T03:11:41.745994379Z"" level=debug msg=""form data: {\""AttachStderr\"":true,\""AttachStdin\"":false,\""AttachStdout\"":true,\""Cmd\"":[\""usleep\"",\""700\""],\""Domainname\"":\""\"",\""Entrypoint\"":null,\""Env\"":[],\""HostConfig\"":{\""AutoRemove\"":false,\""Binds\"":null,\""BlkioDeviceReadBps\"":null,\""BlkioDeviceReadIOps\"":null,\""BlkioDeviceWriteBps\"":null,\""BlkioDeviceWriteIOps\"":null,\""BlkioWeight\"":0,\""BlkioWeightDevice\"":null,\""CapAdd\"":null,\""CapDrop\"":null,\""Cgroup\"":\""\"",\""CgroupParent\"":\""\"",\""ConsoleSize\"":[0,0],\""ContainerIDFile\"":\""\"",\""CpuCount\"":0,\""CpuPercent\"":0,\""CpuPeriod\"":0,\""CpuQuota\"":0,\""CpuRealtimePeriod\"":0,\""CpuRealtimeRuntime\"":0,\""CpuShares\"":0,\""CpusetCpus\"":\""\"",\""CpusetMems\"":\""\"",\""DeviceCgroupRules\"":null,\""Devices\"":[],\""DiskQuota\"":0,\""Dns\"":[],\""DnsOptions\"":[],\""DnsSearch\"":[],\""ExtraHosts\"":null,\""GroupAdd\"":null,\""IOMaximumBandwidth\"":0,\""IOMaximumIOps\"":0,\""IpcMode\"":\""\"",\""Isolation\"":\""\"",\""KernelMemory\"":0,\""Links\"":null,\""LogConfig\"":{\""Config\"":{},\""Type\"":\""\""},\""Memory\"":0,\""MemoryReservation\"":0,\""MemorySwap\"":0,\""MemorySwappiness\"":-1,\""NanoCpus\"":0,\""NetworkMode\"":\""default\"",\""OomKillDisable\"":false,\""OomScoreAdj\"":0,\""PidMode\"":\""\"",\""PidsLimit\"":0,\""PortBindings\"":{},\""Privileged\"":false,\""PublishAllPorts\"":false,\""ReadonlyRootfs\"":false,\""RestartPolicy\"":{\""MaximumRetryCount\"":0,\""Name\"":\""no\""},\""SecurityOpt\"":null,\""ShmSize\"":0,\""UTSMode\"":\""\"",\""Ulimits\"":null,\""UsernsMode\"":\""\"",\""VolumeDriver\"":\""\"",\""VolumesFrom\"":null},\""Hostname\"":\""\"",\""Image\"":\""alpine\"",\""Labels\"":{},\""NetworkingConfig\"":{\""EndpointsConfig\"":{}},\""OnBuild\"":null,\""OpenStdin\"":false,\""StdinOnce\"":false,\""Tty\"":false,\""User\"":\""\"",\""Volumes\"":{},\""WorkingDir\"":\""\""}""time=""2019-03-02T03:11:41.772914021Z"" level=debug msg=""container mounted via layerStore: &{/var/lib/docker/overlay2/091d5321e74d78d91c7411147d451455553a4c77c10267777be705a3034288a9/merged 0x3abe3e0 0x3abe3e0}""time=""2019-03-02T03:11:41.796250222Z"" level=debug msg=""Calling POST /v1.30/containers/318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d/attach?stderr=1&stdout=1&stream=1""time=""2019-03-02T03:11:41.796477833Z"" level=debug msg=""attach: stderr: begin""time=""2019-03-02T03:11:41.796480789Z"" level=debug msg=""attach: stdout: begin""time=""2019-03-02T03:11:41.797821759Z"" level=debug msg=""Calling POST /v1.30/containers/318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d/wait?condition=next-exit""time=""2019-03-02T03:11:41.798828356Z"" level=debug msg=""Calling POST /v1.30/containers/318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d/start""time=""2019-03-02T03:11:41.800397892Z"" level=debug msg=""container mounted via layerStore: &{/var/lib/docker/overlay2/091d5321e74d78d91c7411147d451455553a4c77c10267777be705a3034288a9/merged 0x3abe3e0 0x3abe3e0}""time=""2019-03-02T03:11:41.800827456Z"" level=debug msg=""Assigning addresses for endpoint mystifying_engelbart's interface on network bridge""time=""2019-03-02T03:11:41.800897552Z"" level=debug msg=""RequestAddress(LocalDefault/172.18.0.0/16, <nil>, map[])""time=""2019-03-02T03:11:41.800947440Z"" level=debug msg=""Request address PoolID:172.18.0.0/16 App: ipam/default/data, ID: LocalDefault/172.18.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65533, Sequence: (0xc0000000, 1)->(0x0, 2046)->(0x1, 1)->end Curr:3 Serial:false PrefAddress:<nil> ""time=""2019-03-02T03:11:41.804302303Z"" level=debug msg=""Assigning addresses for endpoint mystifying_engelbart's interface on network bridge""time=""2019-03-02T03:11:41.808763153Z"" level=debug msg=""Programming external connectivity on endpoint mystifying_engelbart (af5c1dc2f12be9c3c9ac270e336630c1f5a2a841d1a0fb3ff056ad3bf2f46a42)""time=""2019-03-02T03:11:41.809488084Z"" level=debug msg=""EnableService 318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d START""time=""2019-03-02T03:11:41.809519968Z"" level=debug msg=""EnableService 318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d DONE""time=""2019-03-02T03:11:41.812112107Z"" level=debug msg=""bundle dir created"" bundle=/var/run/docker/containerd/318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d module=libcontainerd namespace=moby root=/var/lib/docker/overlay2/091d5321e74d78d91c7411147d451455553a4c77c10267777be705a3034288a9/mergedtime=""2019-03-02T03:11:41.815239507Z"" level=debug msg=""event published"" ns=moby topic=""/containers/create"" type=containerd.events.ContainerCreatetime=""2019-03-02T03:11:41.820351807Z"" level=info msg=""shim containerd-shim started"" address=""/containerd-shim/moby/318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d/shim.sock"" debug=true pid=9472time=""2019-03-02T03:11:41Z"" level=debug msg=""registering ttrpc server""time=""2019-03-02T03:11:41Z"" level=debug msg=""serving api on unix socket"" socket=""[inherited from parent]""time=""2019-03-02T03:11:41.991294876Z"" level=debug msg=""sandbox set key processing took 84.690029ms for container 318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d""time=""2019-03-02T03:11:42.093091891Z"" level=debug msg=""event published"" ns=moby topic=""/tasks/create"" type=containerd.events.TaskCreatetime=""2019-03-02T03:11:42.093682501Z"" level=debug msg=event module=libcontainerd namespace=moby topic=/tasks/createtime=""2019-03-02T03:11:42.114589886Z"" level=error msg=""stream copy error: read /proc/self/fd/22: file already closed""time=""2019-03-02T03:11:42.114699201Z"" level=error msg=""stream copy error: read /proc/self/fd/23: file already closed""time=""2019-03-02T03:11:42.114856615Z"" level=debug msg=""attach: stdout: end""time=""2019-03-02T03:11:42.114860048Z"" level=debug msg=""attach: stderr: end""time=""2019-03-02T03:11:42.114892957Z"" level=debug msg=""attach done""time=""2019-03-02T03:11:42.124127328Z"" level=error msg=""failed to delete task after fail start"" container=318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d error=""task must be stopped before deletion: running: failed precondition"" module=libcontainerd namespace=mobytime=""2019-03-02T03:11:42.132271569Z"" level=error msg=""failed to delete failed start container"" container=318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d error=""cannot delete running task 318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d: failed precondition""time=""2019-03-02T03:11:42.136896063Z"" level=debug msg=""Revoking external connectivity on endpoint mystifying_engelbart (af5c1dc2f12be9c3c9ac270e336630c1f5a2a841d1a0fb3ff056ad3bf2f46a42)""time=""2019-03-02T03:11:42.138816900Z"" level=debug msg=""DeleteConntrackEntries purged ipv4:0, ipv6:0""time=""2019-03-02T03:11:42.189818111Z"" level=debug msg=""event published"" ns=moby topic=""/tasks/exit"" type=containerd.events.TaskExittime=""2019-03-02T03:11:42.190200722Z"" level=debug msg=event module=libcontainerd namespace=moby topic=/tasks/exittime=""2019-03-02T03:11:42.190314159Z"" level=warning msg=""Ignoring Exit Event, no such exec command found"" container=318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d exec-id=318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d exec-pid=9489time=""2019-03-02T03:11:42.246756496Z"" level=debug msg=""Releasing addresses for endpoint mystifying_engelbart's interface on network bridge""time=""2019-03-02T03:11:42.246818581Z"" level=debug msg=""ReleaseAddress(LocalDefault/172.18.0.0/16, 172.18.0.2)""time=""2019-03-02T03:11:42.246877761Z"" level=debug msg=""Released address PoolID:LocalDefault/172.18.0.0/16, Address:172.18.0.2 Sequence:App: ipam/default/data, ID: LocalDefault/172.18.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65532, Sequence: (0xe0000000, 1)->(0x0, 2046)->(0x1, 1)->end Curr:3""time=""2019-03-02T03:11:42.321744393Z"" level=error msg=""318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d cleanup: failed to delete container from containerd: cannot delete running task 318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d: failed precondition""time=""2019-03-02T03:11:42.321810393Z"" level=error msg=""Handler for POST /v1.30/containers/318f521d01f16fe9391dee640df1c68c06501a9699fba28e28ad5eca0831d98d/start returned error: cgroups: cgroup deleted: unknown""```Version inside dind 8aca18d631f3f72d4c6e3dc01b6e5d468ad941b8 @AkihiroSuda 
"
38759,1,2658,296,0,0,cwrau,0,"title:Docker 18.09.1 doesn't work with iptables v1.8.2. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**When I try to deploy a container and expose it on a port it failed with this error:```docker run --rm -it -p 80:80 alpinedocker: Error response from daemon: driver failed programming external connectivity on endpoint unruffled_goldwasser (c99e441c46a8317bb62c99bbea46f289fe7a317b54bbe3abe51e83c21d709323):  (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0/0 --dport 80 -j DNAT --to-destination 172.17.0.2:80 ! -i docker0: iptables v1.8.2 (legacy): unknown option ""--to-destination""Try `iptables -h' or 'iptables --help' for more information. (exit status 2)).```**Steps to reproduce the issue:**1. Run the above command with iptables 1.8.2**Describe the results you received:**```docker run --rm -it -p 80:80 alpinedocker: Error response from daemon: driver failed programming external connectivity on endpoint unruffled_goldwasser (c99e441c46a8317bb62c99bbea46f289fe7a317b54bbe3abe51e83c21d709323):  (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0/0 --dport 80 -j DNAT --to-destination 172.17.0.2:80 ! -i docker0: iptables v1.8.2 (legacy): unknown option ""--to-destination""Try `iptables -h' or 'iptables --help' for more information. (exit status 2)).```**Output of `docker version`:**```Client: Version:           18.09.2-ce API version:       1.39 Go version:        go1.11.5 Git commit:        62479626f2 Built:             Mon Feb 11 23:58:17 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          18.09.1-ce  API version:      1.39 (minimum version 1.12)  Go version:       go1.11.4  Git commit:       4c52b901c6  Built:            Thu Jan 10 06:50:46 2019  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 2 Running: 1 Paused: 0 Stopped: 1Images: 32Server Version: 18.09.1-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9f2e07b1fc1342d1c48fe4d7bbb94cb6d1bf278b.mrunc version: ccb5efd37fb7c86364786e9137e22948751de7ed-dirtyinit version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 4.19.20-1-MANJAROOperating System: Arch LinuxOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 15.49GiBName: cwrID: TU5A:APOO:S4OL:RAZH:ZCRD:ZKPP:5DCX:JU56:RZH2:QH4X:NMDY:X33XDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Output of `iptables -V`:**```iptables v1.8.2 (legacy)```
"
38745,0,1878,85,0,0,pauldraper,0,"title:Docker errors if stdin is not fully read. description:**Description**Docker exits with an error is stdin is not fully consumed.**Steps to reproduce the issue:**Run```head -c 500000 /dev/zero | docker run --rm -i alpine:3.9 echo```**Describe the results you received:**Docker exits with 1 and prints on stderr.```read unix @->/var/run/docker.sock: read: connection reset by peer```**Describe the results you expected:**Docker exists with 0 and does not print on stderr.**Additional information you deem important (e.g. issue happens only occasionally):**N/A**Output of `docker version`:**```Client: Version:           18.09.1 API version:       1.39 Go version:        go1.10.6 Git commit:        4c52b90 Built:             Wed Jan  9 19:35:31 2019 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.1  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.6  Git commit:       4c52b90  Built:            Wed Jan  9 19:02:44 2019  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 17 Running: 1 Paused: 0 Stopped: 16Images: 173Server Version: 18.09.1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9754871865f7fe2f4e74d43e2fc7ccd237edcbcerunc version: 96ec2177ae841256168fcf76954f7177af9446ebinit version: fec3683Security Options: apparmor seccomp  Profile: default usernsKernel Version: 4.15.0-45-genericOperating System: Ubuntu 18.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 15.4GiBName: paulID: NPIE:SKNR:RFN7:JYOG:B63X:WVNA:5M67:HRRR:4N7N:M6WH:K6KJ:ZLDXDocker Root Dir: /var/lib/docker/1000.1000Debug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community EngineWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Host is Ubuntu 18.04.
"
38720,0,695,200,0,1,thaJeztah,0,"title:Flaky test: DockerDaemonSuite.TestDaemonRestartUnlessStopped. description:This test looks to have become flaky (recently updated in https://github.com/moby/moby/pull/35355)https://jenkins.dockerproject.org/job/Docker-PRs-experimental/44079/console```15:21:20 FAIL: docker_cli_daemon_test.go:118: DockerDaemonSuite.TestDaemonRestartUnlessStopped15:21:20 15:21:20 [d62b0ae349327] waiting for daemon to start15:21:20 [d62b0ae349327] daemon started15:21:20 15:21:20 docker_cli_daemon_test.go:157:15:21:20     // both stopped15:21:20     testRun(map[string]bool{""top1"": false, ""top2"": false, ""exit"": false}, """")15:21:20 docker_cli_daemon_test.go:140:15:21:20     c.Assert(strings.Contains(out, name), check.Equals, shouldRun, check.Commentf(format, prefix, name))15:21:20 ... obtained bool = true15:21:20 ... expected bool = false15:21:20 ... container ""exit"" is running15:21:20 15:21:20 [d62b0ae349327] exiting daemon```
"
38719,0,0,0,0,1,lowenna,1,"title:Windows: Leaks handles if init process fails to launch. description:Logging to remind me to fix. `reapProcess` won't be called in that case, so the container object itself will never be closed.
"
38702,0,2231,247,0,0,AkihiroSuda,0,"title:Rootful-Docker-in-Rootless-Docker doesn't work. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Rootful docker in Rootless docker does not work**Steps to reproduce the issue:**1. Start rootless docker2. Within rootless docker, start `dockerd` as the root(-in-userns).3. Run `docker run -it --rm busybox` against Rootful-Docker-in-Rootless-Docker**Describe the results you received:**```docker: Error response from daemon: OCI runtime create failed: container_linux.go:344: starting container process caused ""process_linux.go:275: applying cgroup configuration for process caused \""mkdir /sys/fs/cgroup/cpuset/docker: permission denied\"""": unknown.```**Describe the results you expected:**It should work**Additional information you deem important (e.g. issue happens only occasionally):**Running Rootful-Docker-in-Rootless-Docker daemon with `--experimental --rootless` doesn't make sense here currently, as it tries to use `$XDG_RUNTIME_DIR` and so on.Probably we should let `--rootless` disable cgroups but ignore `$XDG_RUNTIME_DIR` when `$USER==""root"" || $USER==""""`.**Output of `docker version`:**```Client: Docker Engine - Community Version:           18.09.1-rc1 API version:       1.39 Go version:        go1.10.5 Git commit:        bca0068 Built:             Fri Dec  7 05:28:04 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          dev  API version:      1.40 (minimum version 1.12)  Go version:       go1.11.5  Git commit:       93d994e29c  Built:  OS/Arch:          linux/amd64  Experimental:     false containerd:  Version:          v1.2.0-243-g6b25c1e4  GitCommit:        6b25c1e45c2b8246dba17de3b1d574f6720ce79f runc:  Version:          1.0.0-rc6+dev  GitCommit:        bbb17efcb4c0ab986407812a31ba333a7450064c docker-init:  Version:          0.18.0  GitCommit:        fec3683```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 1Server Version: devStorage Driver: vfsLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 6b25c1e45c2b8246dba17de3b1d574f6720ce79frunc version: bbb17efcb4c0ab986407812a31ba333a7450064cinit version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 4.15.0-45-genericOperating System: Ubuntu 18.04.1 LTS (containerized)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.829GiBName: e9a9508c8101ID: UZUL:JHFE:3567:N2FE:YUZL:XKRW:EKQB:I35U:MTDM:7Y3Z:3EO6:DWL5Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit supportWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
38631,1,1259,0,0,0,itsgk92,0,"title:Linux container with --cap-add SYS_NICE  or --privileged mode fails on windows.. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Linux containers with additional capabilities fail in windows 10 - 1607 with Docker version 18.09.1, build 4c52b90 . Linux containers which require thread priority scheduling requires SYS_NICE capability. This works fine on linux but fails on windows. This is not resolved even running on privileged mode.**Steps to reproduce the issue:**1. A strip down container testing thread scheduling available @ itsgk92/set_cap_test2. Run the container on Linux with SYS_NICE  capability or privileged mode; behavior as in  expected output below3. Run the same on Windows - fails with both cap-add and privileged.**Describe the results you received:**On Windows 10 - 1607 with Docker version 18.09.1, build 4c52b90>docker run -it  itsgk92/set_cap_testpthread_setschedparam: Operation not permitted>docker run -it --cap-add SYS_NICE itsgk92/set_cap_testpthread_setschedparam: Operation not permitted>docker run -it --privileged itsgk92/set_cap_testpthread_setschedparam: Operation not permitted**Describe the results you expected:**On Linux with Docker version 18.09.0, build 4d60db4:$ docker run -it  itsgk92/set_cap_testpthread_setschedparam: Operation not permitted$ docker run -it --cap-add SYS_NICE  itsgk92/set_cap_testScheduler settings of main thread    policy=SCHED_FIFO, priority=10Scheduler settings in 'attr'    policy=SCHED_RR, priority=20    inheritsched is EXPLICITScheduler attributes of new thread    policy=SCHED_RR, priority=20**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Docker version 18.09.1, build 4c52b90```**Output of `docker info`:**```Server Version: 18.09.1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9754871865f7fe2f4e74d43e2fc7ccd237edcbcerunc version: 96ec2177ae841256168fcf76954f7177af9446ebinit version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 4.9.125-linuxkitOperating System: Docker for WindowsOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.934GiBName: linuxkit-00155d561b07ID: CIKM:WSST:4QWU:7HKG:BOPS:AYG4:2BSM:YDYT:QXTW:HNOO:5Q4M:7N2ADocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 23 Goroutines: 47 System Time: 2019-01-24T11:52:37.7840477Z EventsListeners: 1Registry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community Engine```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
38618,0,5741,0,0,0,user121216,0,"title:Docker swarm problems with Mac OS X as nodes. description:**Description**With an CentOS as manager, it's only possible to join the swarm with one Mac OS X (10.13) at the same time otherwise the docker node engine is crashing (error stack see below).**Steps to reproduce the issue:**1. Init swarm on CentOS `docker swarm init --advertise-addr 192.168.5.10:2377`2. Copy & paste token on Mac OS X `docker swarm join --token #### 192.168.5.10:2377`3. Copy & paste token on another Mac OS X `docker swarm join --token #### 192.168.5.10:2377`4. After joining the other Mac OS X docker engine crashes**Describe the results you received:**```2019-01-22T13:08:24Z docker github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).rejoinClusterBootStrap(0xc421143320)2019-01-22T13:08:24Z docker 	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:305 +0x2d02019-01-22T13:08:24Z docker github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).(github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.rejoinClusterBootStrap)-fm()2019-01-22T13:08:24Z docker 	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:175 +0x2c2019-01-22T13:08:24Z docker github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).triggerFunc(0xc421143320, 0xdf8475800, 0xc4211f9320, 0xc420c38230)2019-01-22T13:08:24Z docker 	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:256 +0x1342019-01-22T13:08:24Z docker created by github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).clusterInit2019-01-22T13:08:24Z docker 	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:178 +0x8e92019-01-22T13:08:24Z docker + failed_to_start2019-01-22T13:08:24Z docker + tail /var/log/docker.log```**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**Server```Client: Version:	18.03.0-ce API version:	1.37 Go version:	go1.9.4 Git commit:	0520e24 Built:	Wed Mar 21 23:09:15 2018 OS/Arch:	linux/amd64 Experimental:	false Orchestrator:	swarmServer: Engine:  Version:	18.03.0-ce  API version:	1.37 (minimum version 1.12)  Go version:	go1.9.4  Git commit:	0520e24  Built:	Wed Mar 21 23:13:03 2018  OS/Arch:	linux/amd64  Experimental:	false```Mac OS X (other Mac OS X similar)```Client: Docker Engine - Community Version:           18.09.1 API version:       1.39 Go version:        go1.10.6 Git commit:        4c52b90 Built:             Wed Jan  9 19:33:12 2019 OS/Arch:           darwin/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.1  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.6  Git commit:       4c52b90  Built:            Wed Jan  9 19:41:49 2019  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**Server```Containers: 3 Running: 3 Paused: 0 Stopped: 0Images: 3Server Version: 18.03.0-ceStorage Driver: devicemapper Pool Name: docker-thinpool Pool Blocksize: 524.3kB Base Device Size: 10.74GB Backing Filesystem: xfs Udev Sync Supported: true Data Space Used: 843.1MB Data Space Total: 20.63GB Data Space Available: 19.79GB Metadata Space Used: 262.1kB Metadata Space Total: 213.9MB Metadata Space Available: 213.6MB Thin Pool Minimum Free Space: 2.063GB Deferred Removal Enabled: true Deferred Deletion Enabled: true Deferred Deleted Device Count: 0 Library Version: 1.02.140-RHEL7 (2017-05-03)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: i8e27383jrjxzc177ajyb75dv Is Manager: true ClusterID: 6xocuwj7cq44msuesxgy1z1hg Managers: 1 Nodes: 7 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 192.168.5.10 Manager Addresses:  192.168.5.10:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfd04396dc68220d1cecbe686a6cc3aa5ce3667crunc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-693.21.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.859GiBName: mac-os-swarmID: WD2E:56Q3:BOH6:FYL2:KVLY:RSY5:GRRL:XB5O:N3R2:Y2AA:K6NS:QSXMDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```Mac OS X (other Mac OS X similar)```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 18.09.1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9754871865f7fe2f4e74d43e2fc7ccd237edcbcerunc version: 96ec2177ae841256168fcf76954f7177af9446ebinit version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 4.9.125-linuxkitOperating System: Docker for MacOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 9.743GiBName: linuxkit-025000000001ID: HQI4:UTCZ:2RMS:IPQE:JEAQ:WAWM:E6KL:H2JM:RXJ5:QCLC:35JV:7464Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 24 Goroutines: 54 System Time: 2019-01-22T18:46:08.717538097Z EventsListeners: 2HTTP Proxy: gateway.docker.internal:3128HTTPS Proxy: gateway.docker.internal:3129Registry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community Engine```**Additional environment details (AWS, VirtualBox, physical, etc.):**The docker `Name: linuxkit-025000000001` is for all Mac OS X installations the same. Probably this won't work well together?!For testing I  added 2 CentOS nodes and these are working fine (also the name is equal to the real hostname).
"
38577,0,1513,0,0,0,dmitriykanarskiy,0,"title:LCOW healthcheck fails. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**When running linux container with a LCOW support enabled on a windows healthchecks fail. It seams that CMD command incorrectly picks up cmd.exe over sh/bash for linux OS.**Steps to reproduce the issue:**1. docker run --name=test -d -e ""ZOOKEEPER_SYNC_LIMIT=2"" -e ""ZOOKEEPER_TICK_TIME=2000"" -e ""ZOO_MAX_CLIENT_CNXNS=3000"" -e ""ZOOKEEPER_CLIENT_PORT=2181"" -e ""ZOOKEEPER_SERVER_ID=1"" --platform=linux --health-cmd=""echo 'ruok' | nc -w 2 -q 2 localhost 2181 | grep 'imok'"" confluentinc/cp-zookeeper:3.2.42. docker inspect --format ""{{json .State.Health }}"" \<containerId\>**Describe the results you received:**{""Status"":""starting"",""FailingStreak"":1,""Log"":[{""Start"":""2019-01-15T05:02:55.8202577-08:00"",""End"":""2019-01-15T05:02:56.712615-08:00"",""ExitCode"":-1,""Output"":""container 94291df1b6482abdb091ddda53bce7b492703522223bb430445b3f761de8f871 encountered an error during CreateProcess: failure in a Windows system call: Unspecified error (0x80004005)\n[Event Detail: failed to run runc create/exec call for container 94291df1b6482abdb091ddda53bce7b492703522223bb430445b3f761de8f871: exit status 1 Stack Trace: \ngithub.com/Microsoft/opengcs/service/gcs/runtime/runc.(*container).startProcess\n\t/go/src/github.com/Microsoft/opengcs/service/gcs/runtime/runc/runc.go:550\ngithub.com/Microsoft/opengcs/service/gcs/runtime/runc.(*container).runExecCommand\n\t/go/src/github.com/Microsoft/opengcs/service/gcs/runtime/runc/runc.go:492\ngithub.com/Microsoft/opengcs/service/gcs/runtime/runc.(*container).ExecProcess\n\t/go/src/github.com/Microsoft/opengcs/service/gcs/runtime/runc/runc.go:127\ngithub.com/Microsoft/opengcs/service/gcs/core/gcs.(*gcsCore).ExecProcess\n\t/go/src/github.com/Microsoft/opengcs/service/gcs/core/gcs/gcs.go:276\ngithub.com/Microsoft/opengcs/service/gcs/bridge.(*Bridge).execProcess\n\t/go/src/github.com/Microsoft/opengcs/service/gcs/bridge/bridge.go:391\ngithub.com/Microsoft/opengcs/service/gcs/bridge.(*Bridge).(github.com/Microsoft/opengcs/service/gcs/bridge.execProcess)-fm\n\t/go/src/github.com/Microsoft/opengcs/service/gcs/bridge/bridge.go:199\ngithub.com/Microsoft/opengcs/service/gcs/bridge.HandlerFunc.ServeMsg\n\t/go/src/github.com/Microsoft/opengcs/service/gcs/bridge/bridge.go:45\ngithub.com/Microsoft/opengcs/service/gcs/bridge.(*Mux).ServeMsg\n\t/go/src/github.com/Microsoft/opengcs/service/gcs/bridge/bridge.go:107\ngithub.com/Microsoft/opengcs/service/gcs/bridge.(*Bridge).ListenAndServe.func2.1\n\t/go/src/github.com/Microsoft/opengcs/service/gcs/bridge/bridge.go:262\nruntime.goexit\n\t/usr/lib/go/src/runtime/asm_amd64.s:2197 Provider: 00000000-0000-0000-0000-000000000000] extra info: {\""CommandArgs\"":[\""cmd\"",\""/S\"",\""/C\"",\""echo 'ruok' | nc -w 2 -q 2 localhost 2181 | grep 'imok'\""],\""WorkingDirectory\"":\""/\"",\""Environment\"":{\""APT_ALLOW_UNAUTHENTICATED\"":\""false\"",\""COMPONENT\"":\""zookeeper\"",\""CONFLUENT_DEB_VERSION\"":\""1\"",\""CONFLUENT_MAJOR_VERSION\"":\""3\"",\""CONFLUENT_MINOR_VERSION\"":\""2\"",\""CONFLUENT_PATCH_VERSION\"":\""1\"",\""CONFLUENT_VERSION\"":\""3.2.1\"",\""HOSTNAME\"":\""94291df1b648\"",\""KAFKA_VERSION\"":\""0.10.2.2\"",\""LANG\"":\""C.UTF-8\"",\""PATH\"":\""/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"",\""PYTHON_PIP_VERSION\"":\""8.1.2\"",\""PYTHON_VERSION\"":\""2.7.9-1\"",\""SCALA_VERSION\"":\""2.11\"",\""ZOOKEEPER_CLIENT_PORT\"":\""2181\"",\""ZOOKEEPER_SERVER_ID\"":\""1\"",\""ZOOKEEPER_SYNC_LIMIT\"":\""2\"",\""ZOOKEEPER_TICK_TIME\"":\""2000\"",\""ZOO_MAX_CLIENT_CNXNS\"":\""3000\"",\""ZULU_OPENJDK_VERSION\"":\""8=8.17.0.3\""},\""CreateStdInPipe\"":true,\""CreateStdOutPipe\"":true,\""CreateStdErrPipe\"":true,\""ConsoleSize\"":[0,0]}""}]}**Describe the results you expected:**Health check passes**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:           master-dockerproject-2019-01-14 API version:       1.40 Go version:        go1.11.4 Git commit:        a6e37bd6 Built:             Mon Jan 14 23:50:55 2019 OS/Arch:           windows/amd64 Experimental:      falseServer: Engine:  Version:          master-dockerproject-2019-01-14  API version:      1.40 (minimum version 1.24)  Go version:       go1.11.4  Git commit:       beef00c  Built:            Mon Jan 14 23:58:53 2019  OS/Arch:          windows/amd64  Experimental:     true```**Output of `docker info`:**```Containers: 10 Running: 5 Paused: 0 Stopped: 5Images: 11Server Version: master-dockerproject-2019-01-14Storage Driver: windowsfilter (windows) lcow (linux) Windows: LCOW:Logging Driver: json-filePlugins: Volume: local Network: ics l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd gcplogs gelf json-file local logentries splunk syslogSwarm: inactiveDefault Isolation: processKernel Version: 10.0 16299 (16299.637.amd64fre.rs3_release_svc.180808-1748)Operating System: Windows Server Datacenter Version 1709 (OS Build 16299.847)OSType: windowsArchitecture: x86_64CPUs: 4Total Memory: 16GiBName: testID: POXD:2BDL:BQAZ:2ZFO:S76H:DPWU:O4BU:M7IO:GC5M:RZZD:3UHW:7DPMDocker Root Dir: C:\ProgramData\DockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**VMWare virtual machine
"
38514,0,811,300,0,0,olljanat,0,"title:Flaky test: TestServiceWithDefaultAddressPoolInit. description:This error looks to happened at least three times on experimental on PRs:- #38138- #38487- #38490And at least once on Janky:- #38527```17:19:20 === RUN   TestServiceWithDefaultAddressPoolInit17:19:21 --- FAIL: TestServiceWithDefaultAddressPoolInit (1.28s)17:19:21     daemon.go:296: [d38c8a3f9fff9] waiting for daemon to start17:19:21     daemon.go:328: [d38c8a3f9fff9] daemon started17:19:21     service_test.go:420: TestServiceWithDefaultAddressPoolInit: NetworkInspect: {Name:saanvisthiraTestServiceWithDefaultAddressPoolInit ID:2e1jfqltui460afgk05cgwr5r Created:2019-01-08 17:19:21.726166875 +0000 UTC Scope:swarm Driver: EnableIPv6:false IPAM:{Driver: Options:map[] Config:[]} Internal:false Attachable:false Ingress:false ConfigFrom:{Network:} ConfigOnly:false Containers:map[] Options:map[] Labels:map[] Peers:[] Services:map[]}17:19:21     service_test.go:421: assertion failed: expression is false: len(out.IPAM.Config) > 0```
"
38504,1,8956,20,0,0,aaronjwood,0,"title:Docker stack traces with free(): invalid pointer when building an image. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Tried to do a docker build in the current directory, saw some crashes from C code which Go is calling.**Steps to reproduce the issue:**1. sudo docker build -t myimage .**Describe the results you received:**```free(): invalid pointerSIGABRT: abortPC=0x7fd698d61077 m=0 sigcode=18446744073709551610goroutine 0 [idle]:runtime: unknown pc 0x7fd698d61077stack: frame={sp:0x7ffd487fb930, fp:0x0} stack=[0x7ffd47ffcd50,0x7ffd487fbd80)00007ffd487fb830:  0000000000000000  00007fd60000000000007ffd487fb840:  00000000016fc2a0  00007fd698f7376e00007ffd487fb850:  00000000016f2a40  00000000487fb8a000007ffd487fb860:  0000000000000000  000000000000000000007ffd487fb870:  00007fd69897ea61  00007fd69898efb800007ffd487fb880:  0000000000000000  44474f0f4c34ce0000007ffd487fb890:  0000000000000004  000000000170510000007ffd487fb8a0:  00007ffd487fb948  000000000000000000007ffd487fb8b0:  0000000000000000  000000000000000000007ffd487fb8c0:  0000000000000000  00007fd698909de800007ffd487fb8d0:  0000000000000000  000000000000000000007ffd487fb8e0:  0000000000000000  44474f0f4c34ce0000007ffd487fb8f0:  0000000000000000  000000000000000200007ffd487fb900:  00007ffd487fbca0  44474f0f4c34ce0000007ffd487fb910:  0000000001705100  00007fd698929d3900007ffd487fb920:  0000000000000200  00007fd69890b58e00007ffd487fb930: <0000000000000000  00007fd698f73efc00007ffd487fb940:  0000000000000000  000000000000003f00007ffd487fb950:  00000000016f2a30  00007fd698fa3ce400007ffd487fb960:  00000000016f2a30  00000000016f2a4000007ffd487fb970:  00000000016fc170  000000000000000000007ffd487fb980:  00007fd6990ab200  00007fd69908b88700007ffd487fb990:  0000000000000200  00000000000000d700007ffd487fb9a0:  00000000016fb840  00007fd698fa3ce400007ffd487fb9b0:  fffffffe7fffffff  ffffffffffffffff00007ffd487fb9c0:  ffffffffffffffff  ffffffffffffffff00007ffd487fb9d0:  ffffffffffffffff  ffffffffffffffff00007ffd487fb9e0:  ffffffffffffffff  ffffffffffffffff00007ffd487fb9f0:  ffffffffffffffff  ffffffffffffffff00007ffd487fba00:  ffffffffffffffff  ffffffffffffffff00007ffd487fba10:  ffffffffffffffff  ffffffffffffffff00007ffd487fba20:  ffffffffffffffff  ffffffffffffffffruntime: unknown pc 0x7fd698d61077stack: frame={sp:0x7ffd487fb930, fp:0x0} stack=[0x7ffd47ffcd50,0x7ffd487fbd80)00007ffd487fb830:  0000000000000000  00007fd60000000000007ffd487fb840:  00000000016fc2a0  00007fd698f7376e00007ffd487fb850:  00000000016f2a40  00000000487fb8a000007ffd487fb860:  0000000000000000  000000000000000000007ffd487fb870:  00007fd69897ea61  00007fd69898efb800007ffd487fb880:  0000000000000000  44474f0f4c34ce0000007ffd487fb890:  0000000000000004  000000000170510000007ffd487fb8a0:  00007ffd487fb948  000000000000000000007ffd487fb8b0:  0000000000000000  000000000000000000007ffd487fb8c0:  0000000000000000  00007fd698909de800007ffd487fb8d0:  0000000000000000  000000000000000000007ffd487fb8e0:  0000000000000000  44474f0f4c34ce0000007ffd487fb8f0:  0000000000000000  000000000000000200007ffd487fb900:  00007ffd487fbca0  44474f0f4c34ce0000007ffd487fb910:  0000000001705100  00007fd698929d3900007ffd487fb920:  0000000000000200  00007fd69890b58e00007ffd487fb930: <0000000000000000  00007fd698f73efc00007ffd487fb940:  0000000000000000  000000000000003f00007ffd487fb950:  00000000016f2a30  00007fd698fa3ce400007ffd487fb960:  00000000016f2a30  00000000016f2a4000007ffd487fb970:  00000000016fc170  000000000000000000007ffd487fb980:  00007fd6990ab200  00007fd69908b88700007ffd487fb990:  0000000000000200  00000000000000d700007ffd487fb9a0:  00000000016fb840  00007fd698fa3ce400007ffd487fb9b0:  fffffffe7fffffff  ffffffffffffffff00007ffd487fb9c0:  ffffffffffffffff  ffffffffffffffff00007ffd487fb9d0:  ffffffffffffffff  ffffffffffffffff00007ffd487fb9e0:  ffffffffffffffff  ffffffffffffffff00007ffd487fb9f0:  ffffffffffffffff  ffffffffffffffff00007ffd487fba00:  ffffffffffffffff  ffffffffffffffff00007ffd487fba10:  ffffffffffffffff  ffffffffffffffff00007ffd487fba20:  ffffffffffffffff  ffffffffffffffffgoroutine 1 [syscall]:runtime.cgocall(0x4af510, 0xc420053cf0, 0x4286c4)        /usr/lib/go-1.10/src/runtime/cgocall.go:128 +0x64 fp=0xc420053cc0 sp=0xc420053c88 pc=0x403884github.com/docker/docker-credential-helpers/secretservice._Cfunc_free(0x16f0270)        _cgo_gotypes.go:111 +0x41 fp=0xc420053cf0 sp=0xc420053cc0 pc=0x4ad4f1github.com/docker/docker-credential-helpers/secretservice.Secretservice.List.func5(0x16f0270)        /build/golang-github-docker-docker-credential-helpers-ywm0S2/golang-github-docker-docker-credential-helpers-0.6.1/obj-x86_64-linux-gnu/src/github.com/docker/docker-credential-helpers/secretservice/secretservice_linux.go:96 +0x56 fp=0xc420053d28 sp=0xc420053cf0 pc=0x4aef26github.com/docker/docker-credential-helpers/secretservice.Secretservice.List(0x0, 0x4fc560, 0xc4200442f0)        /build/golang-github-docker-docker-credential-helpers-ywm0S2/golang-github-docker-docker-credential-helpers-0.6.1/obj-x86_64-linux-gnu/src/github.com/docker/docker-credential-helpers/secretservice/secretservice_linux.go:97 +0x1de fp=0xc420053dc8 sp=0xc420053d28 pc=0x4ae2eegithub.com/docker/docker-credential-helpers/secretservice.(*Secretservice).List(0x795368, 0x20, 0x28, 0xc420053ea8)        <autogenerated>:1 +0x35 fp=0xc420053df0 sp=0xc420053dc8 pc=0x4af355github.com/docker/docker-credential-helpers/credentials.List(0x4fc800, 0x795368, 0x4fc5c0, 0xc42000e018, 0x0, 0x10)        /build/golang-github-docker-docker-credential-helpers-ywm0S2/golang-github-docker-docker-credential-helpers-0.6.1/obj-x86_64-linux-gnu/src/github.com/docker/docker-credential-helpers/credentials/credentials.go:175 +0x3e fp=0xc420053e78 sp=0xc420053df0 pc=0x4acc9egithub.com/docker/docker-credential-helpers/credentials.HandleCommand(0x4fc800, 0x795368, 0x7ffd487fd8be, 0x4, 0x4fc5a0, 0xc42000e010, 0x4fc5c0, 0xc42000e018, 0x40638c, 0xc42007a058)        /build/golang-github-docker-docker-credential-helpers-ywm0S2/golang-github-docker-docker-credential-helpers-0.6.1/obj-x86_64-linux-gnu/src/github.com/docker/docker-credential-helpers/credentials/credentials.go:77 +0x13f fp=0xc420053ee8 sp=0xc420053e78 pc=0x4abe5fgithub.com/docker/docker-credential-helpers/credentials.Serve(0x4fc800, 0x795368)        /build/golang-github-docker-docker-credential-helpers-ywm0S2/golang-github-docker-docker-credential-helpers-0.6.1/obj-x86_64-linux-gnu/src/github.com/docker/docker-credential-helpers/credentials/credentials.go:58 +0x1b7 fp=0xc420053f68 sp=0xc420053ee8 pc=0x4abce7main.main()        /build/golang-github-docker-docker-credential-helpers-ywm0S2/golang-github-docker-docker-credential-helpers-0.6.1/secretservice/cmd/main_linux.go:9 +0x39 fp=0xc420053f88 sp=0xc420053f68 pc=0x4af3d9runtime.main()        /usr/lib/go-1.10/src/runtime/proc.go:198 +0x212 fp=0xc420053fe0 sp=0xc420053f88 pc=0x42ab22runtime.goexit()        /usr/lib/go-1.10/src/runtime/asm_amd64.s:2361 +0x1 fp=0xc420053fe8 sp=0xc420053fe0 pc=0x451d51rax    0x0rbx    0x7ffd487fbba0rcx    0x7fd698d61077rdx    0x0rdi    0x2rsi    0x7ffd487fb930rbp    0x7ffd487fbc80rsp    0x7ffd487fb930r8     0x0r9     0x7ffd487fb930r10    0x8r11    0x246r12    0x7ffd487fbba0r13    0x1000r14    0x7fd699113000r15    0x20rip    0x7fd698d61077rflags 0x246cs     0x33fs     0x0gs     0x0...<rest of expected docker build output is here>```**Describe the results you expected:**Build image without crashing in native code. It does look like the image is successfully built in the end, regardless of the stack traces.**Additional information you deem important (e.g. issue happens only occasionally):**Haven't seen this one before. I just installed Docker on my Ubuntu Cosmic server and tried to build an image.**Output of `docker version`:**```Client: Version:           18.09.0 API version:       1.39 Go version:        go1.10.4 Git commit:        4d60db4 Built:             Wed Nov  7 00:49:01 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.0  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.4  Git commit:       4d60db4  Built:            Wed Nov  7 00:16:44 2018  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 10Server Version: 18.09.0Storage Driver: btrfs Build Version: Btrfs v4.7.3 Library Version: 101Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: c4446665cb9c30056f4998ed953e6d4ff22c7c39runc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: fec3683Security Options: apparmor seccomp  Profile: default usernsKernel Version: 4.18.0-13-genericOperating System: Ubuntu 18.10OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 31.13GiBName: asu64ID: PWO5:PA62:3YTD:6CJ2:KTYF:RRJD:FRBE:EFVH:QSQ5:6YCS:2FV4:TDNTDocker Root Dir: /var/lib/docker/1000.1000Debug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community EngineWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical machine running 18.10. Installed Docker using the official instructions on the site but instead of relying on `$(lsb_release -cs)` I just used `bionic` since there is no published stable version for Bionic yet.
"
38488,0,1049,300,0,0,olljanat,0,"title:Images are removed from database even if cannot be delete from disk. description:**Description**I did troubleshooting for docker/for-win#745 issue and find out that it actually happens on Linux too if layers are protected on way that root cannot remove them**Steps to reproduce the issue:**1. Check that we have one image on disk:```# docker imagesREPOSITORY          TAG                 IMAGE ID            CREATED             SIZEalpine              latest              3f53bb00af94        13 days ago         4.41MB```2. Check that we can see only it on overlay2 folder:```# ls -l /var/lib/docker/overlay2/total 44drwx------ 3 root root  4096 Jan  4 00:06 a35faa4237b8ee1d5fda926505326ad77ae70e8b8e38b8b9d62d133fa80eecc3```3. Mark folder as immutable:```chattr +i /var/lib/docker/overlay2/a35faa4237b8ee1d5fda926505326ad77ae70e8b8e38b8b9d62d133fa80eecc3/```4. Try remove image:```# docker rmi alpineError response from daemon: remove /var/lib/docker/overlay2/a35faa4237b8ee1d5fda926505326ad77ae70e8b8e38b8b9d62d133fa80eecc3/diff: operation not permitted```**Describe the results you received:**Image is removed from database but still exists on disk:```# docker imagesREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE# ls -l /var/lib/docker/overlay2/total 44drwx------ 3 root root  4096 Jan  4 00:06 a35faa4237b8ee1d5fda926505326ad77ae70e8b8e38b8b9d62d133fa80eecc3```**Describe the results you expected:**Images should be either only removed from database when they are successfully removed from disk or they should be marked as waiting for removal and removed when *imageService.Cleanup()* is called.**Additional information you deem important (e.g. issue happens only occasionally):**Related to #38401Error message found from event log on combination of Windows Server 2016 + Docker 18.09:```Handler for DELETE /v1.39/images/5d4d99af0cf4 returned error: GetComputeSystems: The requested compute system operation is not valid in the current state.```if those 500 retries is not enough this is what happens on:https://github.com/moby/moby/blob/ea60a87fcfc8b4592a5d2dec60f021c44ebe6a05/daemon/graphdriver/windows/windows.go#L295-L309
"
38425,1,2233,0,0,0,apetres,0,"title:xcopy not working when isolation is process. description:**Description**When running xcopy in a windows container started with `--isolation=process` xcopy is crasing with `0xC0000139` without printing any output or copying any files.**Steps to reproduce the issue:**```PS C:\> docker run --isolation=hyperv --name hyperv mcr.microsoft.com/windows/servercore:ltsc2016 xcopy0 File(s) copiedInvalid number of parametersPS C:\> docker run --isolation=process --name process mcr.microsoft.com/windows/servercore:ltsc2016 xcopyPS C:\> docker ps -aCONTAINER ID        IMAGE                         COMMAND             CREATED             STATUS                               PORTS               NAMES973775c6893c        mcr.microsoft.com/windows/servercore:ltsc2016   ""xcopy""             13 seconds ago      Exited (3221225785) 11 seconds ago                       process5b821bbae304        mcr.microsoft.com/windows/servercore:ltsc2016   ""xcopy""             51 seconds ago      Exited (4) 35 seconds ago                                hyperv```**Expected**The second command has the same output and exit code as the first one.**Actual**The second command failed with 3221225785 (0xC0000139)**Additional information**May be related to #24880**Output of `docker version`:**```Client: Docker Engine - Community Version:           18.09.0 API version:       1.39 Go version:        go1.10.4 Git commit:        4d60db4 Built:             Wed Nov  7 00:47:51 2018 OS/Arch:           windows/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.0  API version:      1.39 (minimum version 1.24)  Go version:       go1.10.4  Git commit:       4d60db4  Built:            Wed Nov  7 00:56:41 2018  OS/Arch:          windows/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 3 Running: 0 Paused: 0 Stopped: 3Images: 8Server Version: 18.09.0Storage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: ics l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd gelf json-file local logentries splunk syslogSwarm: inactiveDefault Isolation: processKernel Version: 10.0 14393 (14393.693.amd64fre.rs1_release.161220-1747)Operating System: Windows Server 2016 Standard Evaluation Version 1607 (OS Build 14393.693)OSType: windowsArchitecture: x86_64CPUs: 1Total Memory: 7.999GiBName: hostnameID: idDocker Root Dir: C:\ProgramData\dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community Engine```
"
38363,1,3825,3,0,0,jjcorrea,0,"title:Swarm service update with --reserve-memory causes panic: runtime error. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**We tested the very same scenario in two different environments running the same docker-ce version, and only one of those makes the issue occur. 1. docker service create --name redis redis:3.0.62. docker service update redis --reserve-memory=128M**Describe the results you received:**```panic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x55726d231d63]goroutine 1 [running]:github.com/docker/cli/cli/command/service.updateService(0x55726e499960, 0xc4200cc020, 0x7fe224047120, 0xc4205c2100, 0xc4204d1c00, 0xc420227960, 0xc4201f0940, 0x19)	/go/src/github.com/docker/cli/cli/command/service/update.go:333 +0x513github.com/docker/cli/cli/command/service.runUpdate(0x55726e4b2200, 0xc4203cdb00, 0xc4204d1c00, 0xc42028c800, 0x7ffe115786a2, 0xf, 0x55726c91bbe0, 0xc420227c48)	/go/src/github.com/docker/cli/cli/command/service/update.go:172 +0x24egithub.com/docker/cli/cli/command/service.newUpdateCommand.func1(0xc42055a280, 0xc420586920, 0x1, 0x2, 0x0, 0x0)	/go/src/github.com/docker/cli/cli/command/service/update.go:33 +0x98github.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).execute(0xc42055a280, 0xc4200d0120, 0x2, 0x2, 0xc42055a280, 0xc4200d0120)	/go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:762 +0x46agithub.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc4203d3b80, 0xc42023dfa0, 0x55726e16c6c0, 0xc42023dfb0)	/go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:852 +0x30cgithub.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).Execute(0xc4203d3b80, 0xc4203d3b80, 0x55726e473180)	/go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:800 +0x2dmain.main()	/go/src/github.com/docker/cli/cmd/docker/docker.go:180 +0xde```**Describe the results you expected:**The memory reservation being applied to the service.**Output of `docker version`:**```Client: Version:           18.09.0 API version:       1.39 Go version:        go1.10.4 Git commit:        4d60db4 Built:             Wed Nov  7 00:49:01 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.0  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.4  Git commit:       4d60db4  Built:            Wed Nov  7 00:16:44 2018  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 4 Running: 3 Paused: 0 Stopped: 1Images: 4Server Version: 18.09.0Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: active NodeID: 3stzeriddfxiemidbnihe5tsk Is Manager: true ClusterID: m55vlytzzhdype3xq7e4a2pp4 Managers: 4 Nodes: 4 Default Address Pool: 10.0.0.0/8   SubnetSize: 24 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 10 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 172.31.55.57Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: c4446665cb9c30056f4998ed953e6d4ff22c7c39runc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: fec3683Security Options: apparmor seccomp  Profile: defaultKernel Version: 4.15.0-1021-awsOperating System: Ubuntu 18.04.1 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.41GiBName: ip-172-31-55-57ID: TBJB:ZCWP:TBTN:3GLR:36X7:KHOP:5LPB:6DUK:PP5T:QBU6:PXIU:VYHRDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community EngineWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Our swarm is operating 100% in AWS EC2 instances. 
"
38358,0,1464,0,0,1,hongyu69,0,"title:Default Docker NAT network gateway is missing on Windows Server 2019. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Docker default nat network gateway is missing after startup, restart the dockerd service can help fix the issue on Windows server 2019. However the issue will come back after reboot. Is there any approach that can make sure dockerd nat network gateway is filled even after reboot? **Steps to reproduce the issue:**1. Install Docker [18.09.0](https://download.docker.com/components/engine/windows-server/18.09/docker-18.09.0.zip) per the steps [https://docs.docker.com/install/windows/docker-ee/#use-a-script-to-install-docker-ee](https://docs.docker.com/install/windows/docker-ee/#use-a-script-to-install-docker-ee)2. After start dockerd the first time, the subnet of nat network is 0.0.0.0/0, and the gateway is missing3. Restart dockerd could fix the issue4. However, this issue will come back again after reboot..**Describe the results you received:**PS C:\Users\jesun> docker inspect nat[    {        ""Name"": ""nat"",        ""Id"": ""b7b85981ae2d7f843a9c5fe9535a0bf9f2053dc7de84d825c66e699427b7a275"",        ""Created"": ""2018-12-12T14:20:06.3060877Z"",        ""Scope"": ""local"",        ""Driver"": ""nat"",        ""EnableIPv6"": false,        ""IPAM"": {            ""Driver"": ""windows"",            ""Options"": null,            ""Config"": [                {                    ""Subnet"": ""0.0.0.0/0""                }            ]        },        ""Internal"": false,        ""Attachable"": false,        ""Ingress"": false,        ""ConfigFrom"": {            ""Network"": """"        },        ""ConfigOnly"": false,        ""Containers"": {},        ""Options"": {            ""com.docker.network.windowsshim.hnsid"": ""B145BBB5-14C3-4DE2-9309-73FF64067014"",            ""com.docker.network.windowsshim.networkname"": ""nat""        },        ""Labels"": {}    }]**Describe the results you expected:**PS C:\Users\jesun> Restart-Service dockerPS C:\Users\jesun> docker inspect nat[    {        ""Name"": ""nat"",        ""Id"": ""1490d59f1065f4aa1986425f25953bd8128a6c159a7c4b0d57f52af724253c5c"",        ""Created"": ""2018-12-12T14:59:28.8669915Z"",        ""Scope"": ""local"",        ""Driver"": ""nat"",        ""EnableIPv6"": false,        ""IPAM"": {            ""Driver"": ""windows"",            ""Options"": null,            ""Config"": [                {                    ""Subnet"": ""172.22.48.0/20"",                    ""Gateway"": ""172.22.48.1""                }            ]        },        ""Internal"": false,        ""Attachable"": false,        ""Ingress"": false,        ""ConfigFrom"": {            ""Network"": """"        },        ""ConfigOnly"": false,        ""Containers"": {},        ""Options"": {            ""com.docker.network.windowsshim.hnsid"": ""B145BBB5-14C3-4DE2-9309-73FF64067014"",            ""com.docker.network.windowsshim.networkname"": ""nat""        },        ""Labels"": {}    }]*The subnet and gateway information here should not be gone after reboot. Ideally the gateway should never be missing.***Additional information you deem important (e.g. issue happens only occasionally):**I ran into the same missing gateway issue on Windows server 2016(10.0.14393.0), and restart dockerd could fix the issue. Most importantly, it seems on Windows server 2016 the fixed gateway and subnet will be persisted, and will not be gone even after reboot. Also Get-NetNat on Windows server 2019 returns nothing even docker nat network is good.**Output of `docker version`:**```PS C:\Users\jesun> docker versionClient: Version:           18.09.0 API version:       1.39 Go version:        go1.10.3 Git commit:        33a45cd0a2 Built:             unknown-buildtime OS/Arch:           windows/amd64 Experimental:      falseServer: Engine:  Version:          18.09.0  API version:      1.39 (minimum version 1.24)  Go version:       go1.10.3  Git commit:       33a45cd0a2  Built:            11/07/2018 00:24:12  OS/Arch:          windows/amd64  Experimental:     false```**Output of `docker info`:**```PS C:\Users\jesun> docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 18.09.0Storage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: ics l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd gelf json-file local logentries splunk syslogSwarm: inactiveDefault Isolation: processKernel Version: 10.0 17763 (17763.1.amd64fre.rs5_release.180914-1434)Operating System: Windows Server 2019 Datacenter Version 1809 (OS Build 17763.134)OSType: windowsArchitecture: x86_64CPUs: 2Total Memory: 4GiBName: jesun-19ID: FTGG:C47Y:IXRL:7QZ7:5XS7:HWXO:QSM5:U6DV:BLRN:63VL:XALV:UQENDocker Root Dir: C:\ProgramData\dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Azure VM and Physical machines
"
38352,0,13085,10,0,0,farrukh-aftab-khan,0,"title:{{.State.OOMKilled}} not being correctly set for kernel 4.19+. description:**Description**Hello,Apologies if the reported bug is a duplicate of another issue. I tried searching through the issues but didn't find anything similar.There were some improvements made to OOM killer in kernel 4.19 to make it more 'cgroup aware'. You can find the relevant commits under [1] in the additional information section. After the change went in, Docker isn't setting the `.State.OOMKilled` flag correctly despite OOM killer being invoked. To reproduce this, I have created a sample image named `fakhan/sl7:oom-test`. The entrypoint of the image is a program that consumes around 1024MB of memory. Creating this container with anything lower should trigger OOM killer. I have provided more information below on the bug.BUG REPORT INFORMATION shown below:**Steps to reproduce the issue:**1. First on an older kernel:```# docker image pull fakhan/sl7:oom-testoom-test: Pulling from fakhan/sl7Digest: sha256:6d0f60ad535ba61767073c8414a26416a1304651e3621689a4a8aac621eb39d2Status: Image is up to date for fakhan/sl7:oom-test# uname -r3.10.0-862.11.6.el7.x86_64# docker container run --network host --name fkhan-test1 --memory 512m --memory-swap 512m fakhan/sl7:oom-test# docker container inspect fkhan-test1 --format='{{.State.OOMKilled}}'true```2. Then on a newer kernel```# docker image pull fakhan/sl7:oom-testoom-test: Pulling from fakhan/sl7Digest: sha256:6d0f60ad535ba61767073c8414a26416a1304651e3621689a4a8aac621eb39d2Status: Image is up to date for fakhan/sl7:oom-test# uname -r4.19.4-1.el7.elrepo.x86_64# docker container run --network host --name fkhan-test2 --memory 512m --memory-swap 512m fakhan/sl7:oom-test# docker container inspect fkhan-test2 --format='{{.State.OOMKilled}}'false```I have posted the snippets from `/var/log/messages` for both these instances under the additional information section.**Describe the results you received:**As shown above, OOMKilled evaluates to 'False' on kernel 4.19**Describe the results you expected:**OOMKilled should have evaluated to 'True' on kernel 4.19 just like the on the previous versions**Additional information you deem important (e.g. issue happens only occasionally):**[1]https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=dc0b58643aff8b378086f25cce6789ccba68cbcbhttps://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=5989ad7b5ede38d605c588981f634c08252abfc3https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=3d8b38eb81cac81395f6a823f6bf401b327268e6[2]`/var/log/messages` snippets are as follows. First for the older kernel```Dec 11 10:48:08 fkhan-test-kernelv3 dockerd: time=""2018-12-11T10:48:08-06:00"" level=info msg=""shim docker-containerd-shim started"" address=""/containerd-shim/moby/91091d5382d54a44e697e224ebccba7f587c43184bfb51b123cf8c16920598d9/shim.sock"" debug=false pid=11532Dec 11 10:48:09 fkhan-test-kernelv3 kernel: thrash invoked oom-killer: gfp_mask=0xd0, order=0, oom_score_adj=0Dec 11 10:48:09 fkhan-test-kernelv3 kernel: thrash cpuset=91091d5382d54a44e697e224ebccba7f587c43184bfb51b123cf8c16920598d9 mems_allowed=0-1Dec 11 10:48:09 fkhan-test-kernelv3 kernel: CPU: 2 PID: 11554 Comm: thrash Kdump: loaded Tainted: G          I    ------------ T 3.10.0-862.11.6.el7.x86_64 #1Dec 11 10:48:09 fkhan-test-kernelv3 kernel: Hardware name: System Manufacturer System Product Name/KFSN4-DRE, BIOS 1013 11/18/2008Dec 11 10:48:09 fkhan-test-kernelv3 kernel: Call Trace:Dec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa21135d4>] dump_stack+0x19/0x1bDec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa210e79f>] dump_header+0x90/0x229Dec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa1b9a7b6>] ? find_lock_task_mm+0x56/0xc0Dec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa1c0f5b8>] ? try_get_mem_cgroup_from_mm+0x28/0x60Dec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa1b9ac64>] oom_kill_process+0x254/0x3d0Dec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa1c133c6>] mem_cgroup_oom_synchronize+0x546/0x570Dec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa1c12840>] ? mem_cgroup_charge_common+0xc0/0xc0Dec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa1b9b4f4>] pagefault_out_of_memory+0x14/0x90Dec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa210c941>] mm_fault_error+0x6a/0x157Dec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa2120846>] __do_page_fault+0x496/0x4f0Dec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa21208d5>] do_page_fault+0x35/0x90Dec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa211ca96>] ? error_swapgs+0xa7/0xbdDec 11 10:48:09 fkhan-test-kernelv3 kernel: [<ffffffffa211c758>] page_fault+0x28/0x30Dec 11 10:48:09 fkhan-test-kernelv3 kernel: Task in /docker/91091d5382d54a44e697e224ebccba7f587c43184bfb51b123cf8c16920598d9 killed as a result of limit of /docker/91091d5382d54a44e697e224ebccba7f587c43184bfb51b123cf8c16920598d9Dec 11 10:48:09 fkhan-test-kernelv3 kernel: memory: usage 524288kB, limit 524288kB, failcnt 17Dec 11 10:48:09 fkhan-test-kernelv3 kernel: memory+swap: usage 524288kB, limit 524288kB, failcnt 0Dec 11 10:48:09 fkhan-test-kernelv3 kernel: kmem: usage 820kB, limit 9007199254740988kB, failcnt 0Dec 11 10:48:09 fkhan-test-kernelv3 kernel: Memory cgroup stats for /docker/91091d5382d54a44e697e224ebccba7f587c43184bfb51b123cf8c16920598d9: cache:0KB rss:523468KB rss_huge:0KB mapped_file:0KB swap:0KB inactive_anon:46080KB active_anon:477388KB inactive_file:0KB active_file:0KB unevictable:0KBDec 11 10:48:09 fkhan-test-kernelv3 kernel: [ pid ]   uid  tgid total_vm      rss nr_ptes swapents oom_score_adj nameDec 11 10:48:09 fkhan-test-kernelv3 kernel: [11554]     0 11554   263196   130965     263        0             0 thrashDec 11 10:48:09 fkhan-test-kernelv3 kernel: Memory cgroup out of memory: Kill process 11554 (thrash) score 1001 or sacrifice childDec 11 10:48:09 fkhan-test-kernelv3 kernel: Killed process 11554 (thrash) total-vm:1052784kB, anon-rss:523464kB, file-rss:396kB, shmem-rss:0kBDec 11 10:48:10 fkhan-test-kernelv3 dockerd: time=""2018-12-11T10:48:10-06:00"" level=info msg=""shim reaped"" id=91091d5382d54a44e697e224ebccba7f587c43184bfb51b123cf8c16920598d9Dec 11 10:48:10 fkhan-test-kernelv3 dockerd: time=""2018-12-11T10:48:10.336767875-06:00"" level=info msg=""ignoring event"" module=libcontainerd namespace=moby topic=/tasks/delete type=""*events.TaskDelete""```Then for the newer kernel```Dec 11 10:49:37 fkhan-test-kernelv4 kernel: thrash invoked oom-killer: gfp_mask=0x6000c0(GFP_KERNEL), nodemask=(null), order=0, oom_score_adj=0Dec 11 10:49:37 fkhan-test-kernelv4 kernel: thrash cpuset=cc6b369add7d52448ae406800daa01f4836195e51190d9ee922fd685446f8368 mems_allowed=0-1Dec 11 10:49:37 fkhan-test-kernelv4 kernel: CPU: 40 PID: 32276 Comm: thrash Not tainted 4.19.4-1.el7.elrepo.x86_64 #1Dec 11 10:49:37 fkhan-test-kernelv4 kernel: Hardware name: Supermicro Super Server/X10DRL-iT, BIOS 2.0a 01/13/2017Dec 11 10:49:37 fkhan-test-kernelv4 kernel: Call Trace:Dec 11 10:49:37 fkhan-test-kernelv4 kernel: dump_stack+0x63/0x88Dec 11 10:49:37 fkhan-test-kernelv4 kernel: dump_header+0x78/0x2a4Dec 11 10:49:37 fkhan-test-kernelv4 kernel: ? mem_cgroup_scan_tasks+0x9c/0xf0Dec 11 10:49:37 fkhan-test-kernelv4 kernel: oom_kill_process+0x262/0x290Dec 11 10:49:37 fkhan-test-kernelv4 kernel: out_of_memory+0x140/0x4b0Dec 11 10:49:37 fkhan-test-kernelv4 kernel: mem_cgroup_out_of_memory+0x4b/0x80Dec 11 10:49:37 fkhan-test-kernelv4 kernel: try_charge+0x667/0x6f0Dec 11 10:49:37 fkhan-test-kernelv4 kernel: ? __alloc_pages_nodemask+0xf8/0x260Dec 11 10:49:37 fkhan-test-kernelv4 kernel: mem_cgroup_try_charge+0x8c/0x1e0Dec 11 10:49:37 fkhan-test-kernelv4 kernel: mem_cgroup_try_charge_delay+0x22/0x50Dec 11 10:49:37 fkhan-test-kernelv4 kernel: do_anonymous_page+0x11a/0x650Dec 11 10:49:37 fkhan-test-kernelv4 kernel: __handle_mm_fault+0xc5e/0xef0Dec 11 10:49:37 fkhan-test-kernelv4 kernel: handle_mm_fault+0x102/0x220Dec 11 10:49:37 fkhan-test-kernelv4 kernel: __do_page_fault+0x212/0x4e0Dec 11 10:49:37 fkhan-test-kernelv4 kernel: do_page_fault+0x37/0x140Dec 11 10:49:37 fkhan-test-kernelv4 kernel: ? page_fault+0x8/0x30Dec 11 10:49:37 fkhan-test-kernelv4 kernel: page_fault+0x1e/0x30Dec 11 10:49:37 fkhan-test-kernelv4 kernel: RIP: 0033:0x400728Dec 11 10:49:37 fkhan-test-kernelv4 kernel: Code: eb 4d 48 c7 45 e8 00 00 00 00 eb 34 48 c7 45 e0 00 00 00 00 eb 1b 48 8b 45 e0 48 c1 e0 0c 48 03 45 e8 48 03 45 d0 48 8b 55 e8 <88> 10 48 83 45 e0 01 48 8b 45 e0 48 3b 45 f0 7c db 48 83 45 e8 01Dec 11 10:49:37 fkhan-test-kernelv4 kernel: RSP: 002b:00007ffe86af6ca0 EFLAGS: 00010206Dec 11 10:49:37 fkhan-test-kernelv4 kernel: RAX: 0000000021b18000 RBX: 0000000000000000 RCX: 0000000000000012Dec 11 10:49:37 fkhan-test-kernelv4 kernel: RDX: 0000000000000000 RSI: 000000007fffffed RDI: 0000000000000000Dec 11 10:49:37 fkhan-test-kernelv4 kernel: RBP: 00007ffe86af6ce0 R08: 0000000000000000 R09: 00007fcf1403214dDec 11 10:49:37 fkhan-test-kernelv4 kernel: R10: 0000000000000022 R11: 0000000000000000 R12: 0000000000400530Dec 11 10:49:37 fkhan-test-kernelv4 kernel: R13: 00007ffe86af6de0 R14: 0000000000000000 R15: 0000000000000000Dec 11 10:49:37 fkhan-test-kernelv4 kernel: Task in /docker/cc6b369add7d52448ae406800daa01f4836195e51190d9ee922fd685446f8368 killed as a result of limit of /docker/cc6b369add7d52448ae406800daa01f4836195e51190d9ee922fd685446f8368Dec 11 10:49:37 fkhan-test-kernelv4 kernel: memory: usage 524288kB, limit 524288kB, failcnt 0Dec 11 10:49:37 fkhan-test-kernelv4 kernel: memory+swap: usage 524288kB, limit 524288kB, failcnt 34Dec 11 10:49:37 fkhan-test-kernelv4 kernel: kmem: usage 1888kB, limit 9007199254740988kB, failcnt 0Dec 11 10:49:37 fkhan-test-kernelv4 kernel: Memory cgroup stats for /docker/cc6b369add7d52448ae406800daa01f4836195e51190d9ee922fd685446f8368: cache:0KB rss:522208KB rss_huge:520192KB shmem:0KB mapped_file:0KB dirty:0KB writeback:0KB swap:0KB inactive_anon:226260KB active_anon:296032KB inactive_file:0KB active_file:0KB unevictable:0KBDec 11 10:49:37 fkhan-test-kernelv4 kernel: Tasks state (memory values in pages):Dec 11 10:49:37 fkhan-test-kernelv4 kernel: [  pid  ]   uid  tgid total_vm      rss pgtables_bytes swapents oom_score_adj nameDec 11 10:49:37 fkhan-test-kernelv4 kernel: [  32276]     0 32276   263199   130814  1097728        0             0 thrashDec 11 10:49:37 fkhan-test-kernelv4 kernel: Memory cgroup out of memory: Kill process 32276 (thrash) score 1000 or sacrifice childDec 11 10:49:37 fkhan-test-kernelv4 kernel: Killed process 32276 (thrash) total-vm:1052796kB, anon-rss:522108kB, file-rss:1148kB, shmem-rss:0kBDec 11 10:49:37 fkhan-test-kernelv4 kernel: oom_reaper: reaped process 32276 (thrash), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kBDec 11 10:49:37 fkhan-test-kernelv4 dockerd: time=""2018-12-11T10:49:37-06:00"" level=info msg=""shim reaped"" id=cc6b369add7d52448ae406800daa01f4836195e51190d9ee922fd685446f8368Dec 11 10:49:37 fkhan-test-kernelv4 dockerd: time=""2018-12-11T10:49:37.430951185-06:00"" level=info msg=""ignoring event"" module=libcontainerd namespace=moby topic=/tasks/delete type=""*events.TaskDelete""```**Output of `docker version`:**Docker version on both machines is the same (18.06)```# uname -r && docker version3.10.0-862.11.6.el7.x86_64Client: Version:           18.06.1-ce API version:       1.38 Go version:        go1.10.3 Git commit:        e68fc7a Built:             Tue Aug 21 17:23:03 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          18.06.1-ce  API version:      1.38 (minimum version 1.12)  Go version:       go1.10.3  Git commit:       e68fc7a  Built:            Tue Aug 21 17:25:29 2018  OS/Arch:          linux/amd64  Experimental:     false# uname -r && docker version4.19.4-1.el7.elrepo.x86_64Client: Version:           18.06.1-ce API version:       1.38 Go version:        go1.10.3 Git commit:        e68fc7a Built:             Tue Aug 21 17:23:03 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          18.06.1-ce  API version:      1.38 (minimum version 1.12)  Go version:       go1.10.3  Git commit:       e68fc7a  Built:            Tue Aug 21 17:25:29 2018  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```# docker infoContainers: 1 Running: 0 Paused: 0 Stopped: 1Images: 1Server Version: 18.06.1-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 468a545b9edcd5932818eb9de8e72413e616e86erunc version: 69663f0bd4b60df09991c08812a60108003fa340init version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 3.10.0-862.11.6.el7.x86_64Operating System: Scientific Linux 7.5 (Nitrogen)OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 23.39GiBName: fkhan-test-kernelv3.fnal.govID: RHNY:DX45:JKGJ:EDBY:IENF:E5DT:VX7R:MLGL:M765:43XU:3V2W:NTLPDocker Root Dir: /storage/local/data1/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false``````# docker infoContainers: 1 Running: 0 Paused: 0 Stopped: 1Images: 1Server Version: 18.06.1-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 468a545b9edcd5932818eb9de8e72413e616e86erunc version: 69663f0bd4b60df09991c08812a60108003fa340init version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 4.19.4-1.el7.elrepo.x86_64Operating System: Scientific Linux 7.5 (Nitrogen)OSType: linuxArchitecture: x86_64CPUs: 56Total Memory: 251.8GiBName: fkhan-test-kernelv4.fnal.govID: ITUE:KSPJ:33PN:3NHA:XPJ6:C2K7:DSNY:6WKW:BSR5:5BAM:BQ25:QAFPDocker Root Dir: /storage/local/data1/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**Nothing special about the environment. I am running these commands on two bare metal boxes with different kernels.
"
38346,0,1664,13,0,0,doron-cohen,0,"title:Docker start <container_name> returns ""id already in use"". description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**`docker start redis-server` fails on this error message:    Error response from daemon: id already in use    Error: failed to start containers: redis-serverNotice I dont get ""HASH is already in use"" like in #36145. also the docker version here is 18.06That container is stopped and not running. We run this command via SSH on an AWS instance which is stopped and started by demand.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**This bug happens occasionally so I didn't succeed reproducing it but the original flow was:1. `docker run -d -v /redis/redis.conf:/usr/local/etc/redis/redis.conf --restart on-failure:3 --name redis-server --publish 6379:6379 redis:3.0 redis-server /usr/local/etc/redis/redis.conf`2. stop redis container3. stop AWS instance4. start AWS instance5. `docker start redis-server`**Describe the results you received:**    Error response from daemon: id already in use    Error: failed to start containers: redis-server**Describe the results you expected:**running redis container**Additional information you deem important (e.g. issue happens only occasionally):**issue happens only occasionally**Output of `docker version`:**```Client: Version:           18.06.1-ce API version:       1.38 Go version:        go1.10.3 Git commit:        e68fc7a Built:             Tue Aug 21 17:24:58 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          18.06.1-ce  API version:      1.38 (minimum version 1.12)  Go version:       go1.10.3  Git commit:       e68fc7a  Built:            Tue Aug 21 17:23:24 2018  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 2 Running: 2 Paused: 0 Stopped: 0Images: 3Server Version: 18.06.1-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 23 Dirperm1 Supported: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 468a545b9edcd5932818eb9de8e72413e616e86erunc version: 69663f0bd4b60df09991c08812a60108003fa340init version: fec3683Security Options: apparmorKernel Version: 3.13.0-161-genericOperating System: Ubuntu 14.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 992.3MiBName: ip-172-31-11-76ID: DG3V:VWIJ:KQ4X:W7X5:E5WR:RM6A:SQUE:EMG5:TT3K:MCHT:6SRX:PJXFDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Running on a `t2.micro` instance in AWS
"
38306,1,11793,273,0,1,tfenster,0,"title:Process isolation not working for me on Win 10 1809. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**I try to get a process isolated container on Win 10 1809 (17763.107) but it hangs on startup. Might very well be something on my side, I just don't know where to start looking**Steps to reproduce the issue:**1. Install Docker Desktop 2.0.0.02. Replace docker.exe and dockerd.exe with the files from https://master.dockerproject.com/ (https://master.dockerproject.com/windows/x86_64/docker.exe and https://master.dockerproject.com/windows/x86_64/dockerd.exe)3. Start the daemon like this to get debug output: `""C:\Program Files\Docker\Docker\Resources\dockerd.exe"" -G FUM-GLOBAL\tfenster -H npipe:////./pipe/docker_engine_windows -D` (FUM-GLOBAL\tfenster is my user account)4. docker run a container using process isolation like `docker run -ti --isolation=process mcr.microsoft.com/windows/nanoserver:1809`**Describe the results you received:**The container hangs on startup, nothing happens for more than 60 minutes:```C:\WINDOWS\system32>docker run -ti --isolation=process mcr.microsoft.com/windows/nanoserver:1809```Hyper-v isolation works fine:```C:\WINDOWS\system32>docker run mcr.microsoft.com/windows/nanoserver:1809Microsoft Windows [Version 10.0.17763.134](c) 2018 Microsoft Corporation. All rights reserved.C:\>```**Describe the results you expected:**A container running with process isolation**Additional information you deem important (e.g. issue happens only occasionally):**Daemon log looks like this:```DEBU[2018-11-30T17:41:55.826424900+01:00] Calling GET /_pingDEBU[2018-11-30T17:41:55.828426800+01:00] Calling POST /v1.40/containers/createDEBU[2018-11-30T17:41:55.828945200+01:00] form data: {""AttachStderr"":true,""AttachStdin"":true,""AttachStdout"":true,""Cmd"":null,""Domainname"":"""",""Entrypoint"":null,""Env"":[],""HostConfig"":{""AutoRemove"":false,""Binds"":null,""BlkioDeviceReadBps"":null,""BlkioDeviceReadIOps"":null,""BlkioDeviceWriteBps"":null,""BlkioDeviceWriteIOps"":null,""BlkioWeight"":0,""BlkioWeightDevice"":[],""CapAdd"":null,""CapDrop"":null,""Cgroup"":"""",""CgroupParent"":"""",""ConsoleSize"":[30,120],""ContainerIDFile"":"""",""CpuCount"":0,""CpuPercent"":0,""CpuPeriod"":0,""CpuQuota"":0,""CpuRealtimePeriod"":0,""CpuRealtimeRuntime"":0,""CpuShares"":0,""CpusetCpus"":"""",""CpusetMems"":"""",""DeviceCgroupRules"":null,""Devices"":[],""DiskQuota"":0,""Dns"":[],""DnsOptions"":[],""DnsSearch"":[],""ExtraHosts"":null,""GroupAdd"":null,""IOMaximumBandwidth"":0,""IOMaximumIOps"":0,""IpcMode"":"""",""Isolation"":""process"",""KernelMemory"":0,""Links"":null,""LogConfig"":{""Config"":{},""Type"":""""},""MaskedPaths"":null,""Memory"":0,""MemoryReservation"":0,""MemorySwap"":0,""MemorySwappiness"":-1,""NanoCpus"":0,""NetworkMode"":""default"",""OomKillDisable"":false,""OomScoreAdj"":0,""PidMode"":"""",""PidsLimit"":0,""PortBindings"":{},""Privileged"":false,""PublishAllPorts"":false,""ReadonlyPaths"":null,""ReadonlyRootfs"":false,""RestartPolicy"":{""MaximumRetryCount"":0,""Name"":""no""},""SecurityOpt"":null,""ShmSize"":0,""UTSMode"":"""",""Ulimits"":null,""UsernsMode"":"""",""VolumeDriver"":"""",""VolumesFrom"":null},""Hostname"":"""",""Image"":""mcr.microsoft.com/windows/nanoserver:1809"",""Labels"":{},""NetworkingConfig"":{""EndpointsConfig"":{}},""OnBuild"":null,""OpenStdin"":true,""StdinOnce"":true,""Tty"":true,""User"":"""",""Volumes"":{},""WorkingDir"":""""}DEBU[2018-11-30T17:41:55.832462500+01:00] hcsshim::GetLayerMountPath path C:\ProgramData\docker\windowsfilter\ecca0170f401bd3132a4b0fa72abea915e0f6ef94003dff5c00e6d3f93fc149bDEBU[2018-11-30T17:41:55.832462500+01:00] Calling proc (1)DEBU[2018-11-30T17:41:55.833955300+01:00] Calling proc (2)DEBU[2018-11-30T17:41:55.834484400+01:00] hcsshim::GetLayerMountPath succeeded path=C:\ProgramData\docker\windowsfilter\ecca0170f401bd3132a4b0fa72abea915e0f6ef94003dff5c00e6d3f93fc149b mountPath=C:\ProgramData\docker\windowsfilter\ecca0170f401bd3132a4b0fa72abea915e0f6ef94003dff5c00e6d3f93fc149bDEBU[2018-11-30T17:41:55.835987900+01:00] hcsshim::CreateScratchLayer path C:\ProgramData\docker\windowsfilter\c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668DEBU[2018-11-30T17:41:55.836428300+01:00] hcsshim::NameToGuid name:ecca0170f401bd3132a4b0fa72abea915e0f6ef94003dff5c00e6d3f93fc149b guid:010df3e1-7918-5616-b7ed-f330ad22e0d8DEBU[2018-11-30T17:41:55.837448500+01:00] hcsshim::NameToGuid name:7be5fa817a7ea239fa1b0e1a18f4587794dc8a043761eb25b7659026a9bdf0f1 guid:44ee543c-e9f7-5ac3-a463-d6dc23dde7ceDEBU[2018-11-30T17:41:55.858979500+01:00] hcsshim::CreateScratchLayer - succeeded path=C:\ProgramData\docker\windowsfilter\c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668DEBU[2018-11-30T17:41:55.894773700+01:00] Calling POST /v1.40/containers/c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668/attach?stderr=1&stdin=1&stdout=1&stream=1DEBU[2018-11-30T17:41:55.895270900+01:00] attach: stderr: beginDEBU[2018-11-30T17:41:55.895270900+01:00] attach: stdout: beginDEBU[2018-11-30T17:41:55.895270900+01:00] attach: stdin: beginDEBU[2018-11-30T17:41:55.898773300+01:00] Calling POST /v1.40/containers/c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668/wait?condition=next-exitDEBU[2018-11-30T17:41:55.899770000+01:00] Calling POST /v1.40/containers/c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668/startDEBU[2018-11-30T17:41:55.899770000+01:00] WindowsGraphDriver Get() id c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668 mountLabelDEBU[2018-11-30T17:41:55.900773200+01:00] hcsshim::ActivateLayer path C:\ProgramData\docker\windowsfilter\c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668DEBU[2018-11-30T17:41:55.949367600+01:00] hcsshim::ActivateLayer  - succeeded path=C:\ProgramData\docker\windowsfilter\c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668DEBU[2018-11-30T17:41:55.949868400+01:00] hcsshim::PrepareLayer path C:\ProgramData\docker\windowsfilter\c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668DEBU[2018-11-30T17:41:55.960868200+01:00] hcsshim::NameToGuid name:ecca0170f401bd3132a4b0fa72abea915e0f6ef94003dff5c00e6d3f93fc149b guid:010df3e1-7918-5616-b7ed-f330ad22e0d8DEBU[2018-11-30T17:41:55.962865900+01:00] hcsshim::NameToGuid name:7be5fa817a7ea239fa1b0e1a18f4587794dc8a043761eb25b7659026a9bdf0f1 guid:44ee543c-e9f7-5ac3-a463-d6dc23dde7ceDEBU[2018-11-30T17:41:56.025371000+01:00] hcsshim::PrepareLayer succeeded path=C:\ProgramData\docker\windowsfilter\c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668DEBU[2018-11-30T17:41:56.025869300+01:00] hcsshim::GetLayerMountPath path C:\ProgramData\docker\windowsfilter\c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668DEBU[2018-11-30T17:41:56.028867900+01:00] Calling proc (1)DEBU[2018-11-30T17:41:56.032366700+01:00] Calling proc (2)DEBU[2018-11-30T17:41:56.036873900+01:00] hcsshim::GetLayerMountPath succeeded path=C:\ProgramData\docker\windowsfilter\c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668 mountPath=\\?\Volume{31306e05-d5d7-4817-a68b-b130040e464e}DEBU[2018-11-30T17:41:56.038868100+01:00] container mounted via layerStore: &{\\?\Volume{31306e05-d5d7-4817-a68b-b130040e464e} 0x30a3660 0x30a3660}DEBU[2018-11-30T17:41:56.041371300+01:00] Assigning addresses for endpoint pensive_mclaren's interface on network natDEBU[2018-11-30T17:41:56.041869300+01:00] RequestAddress(172.21.16.0/20, <nil>, map[])DEBU[2018-11-30T17:41:56.042370400+01:00] endpointStruct.EnableInternalDNS =[false]DEBU[2018-11-30T17:41:56.043369700+01:00] [POST]=>[/endpoints/] Request : {""VirtualNetwork"":""5A07FB7B-7843-457C-A526-06488B0CEDB2"",""EnableInternalDNS"":true}DEBU[2018-11-30T17:41:56.064871200+01:00] Network Response : {""ActivityId"":""0ACFD905-8FF9-4529-8A72-BB1C4022C5A7"",""AdditionalParams"":{},""CreateProcessingStartTime"":131880697160558684,""DNSServerList"":""172.21.16.1,192.168.1.1"",""DNSSuffix"":""fritz.box"",""EnableInternalDNS"":true,""EnableLowInterfaceMetric"":true,""GatewayAddress"":""172.21.16.1"",""Health"":{""LastErrorCode"":0,""LastUpdateTime"":131880697160503678},""ID"":""E21F82A3-5D83-499C-BBD8-82F17C4CC000"",""IPAddress"":""172.21.17.9"",""MacAddress"":""00-15-5D-D6-F0-69"",""Name"":""Ethernet"",""Policies"":[],""PrefixLength"":20,""Resources"":{""AdditionalParams"":{},""AllocationOrder"":0,""Health"":{""LastErrorCode"":0,""LastUpdateTime"":131880697160503678},""ID"":""0ACFD905-8FF9-4529-8A72-BB1C4022C5A7"",""PortOperationTime"":0,""State"":1,""SwitchOperationTime"":0,""VfpOperationTime"":0,""parentId"":""84CD3469-F8E3-4173-A661-62168B8B249B""},""SharedContainers"":[],""State"":1,""Type"":""nat"",""Version"":38654705665,""VirtualNetwork"":""5A07FB7B-7843-457C-A526-06488B0CEDB2"",""VirtualNetworkName"":""nat""}DEBU[2018-11-30T17:41:56.082369200+01:00] Assigning addresses for endpoint pensive_mclaren's interface on network natDEBU[2018-11-30T17:41:56.097867700+01:00] hcsshim::OpenComputeSystem ID=c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668DEBU[2018-11-30T17:41:56.106369700+01:00] Programming external connectivity on endpoint pensive_mclaren (5e65471111572ed913df6eee44e2cea33caaa379d06614a57c3447aff3fa2b58)DEBU[2018-11-30T17:41:56.106369700+01:00] EnableService c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668 STARTDEBU[2018-11-30T17:41:56.117368200+01:00] EnableService c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668 DONEDEBU[2018-11-30T17:41:56.133868500+01:00] hcsshim::NameToGuid name:ecca0170f401bd3132a4b0fa72abea915e0f6ef94003dff5c00e6d3f93fc149b guid:010df3e1-7918-5616-b7ed-f330ad22e0d8DEBU[2018-11-30T17:41:56.144368900+01:00] hcsshim::NameToGuid name:7be5fa817a7ea239fa1b0e1a18f4587794dc8a043761eb25b7659026a9bdf0f1 guid:44ee543c-e9f7-5ac3-a463-d6dc23dde7ceDEBU[2018-11-30T17:41:56.145376400+01:00] hcsshim::CreateComputeSystem ID=c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668 config={""SystemType"":""Container"",""Name"":""c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668"",""Owner"":""docker"",""VolumePath"":""\\\\?\\Volume{31306e05-d5d7-4817-a68b-b130040e464e}"",""IgnoreFlushesDuringBoot"":true,""LayerFolderPath"":""C:\\ProgramData\\docker\\windowsfilter\\c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668"",""Layers"":[{""ID"":""010df3e1-7918-5616-b7ed-f330ad22e0d8"",""Path"":""C:\\ProgramData\\docker\\windowsfilter\\ecca0170f401bd3132a4b0fa72abea915e0f6ef94003dff5c00e6d3f93fc149b""},{""ID"":""44ee543c-e9f7-5ac3-a463-d6dc23dde7ce"",""Path"":""C:\\ProgramData\\docker\\windowsfilter\\7be5fa817a7ea239fa1b0e1a18f4587794dc8a043761eb25b7659026a9bdf0f1""}],""HostName"":""c80bd23ea18a"",""HvPartition"":false,""EndpointList"":[""E21F82A3-5D83-499C-BBD8-82F17C4CC000""],""AllowUnqualifiedDNSQuery"":true}DEBU[2018-11-30T17:41:56.548869900+01:00] hcsshim::CreateComputeSystem succeeded id=c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668 handle=56164288DEBU[2018-11-30T17:41:56.549369900+01:00] starting container                            container=c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668 module=libcontainerd namespace=mobyDEBU[2018-11-30T17:41:56.553868900+01:00] hcsshim::ComputeSystem::Start ID=c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668WARN[2018-11-30T17:45:56.555017400+01:00] StartComputeSystem c80bd23ea18aac62251e61762e2781365ac8d2bfd7b7f5a2c5707332a0fa3668:: Did not complete within 4m0s. This may indicate a platform issue. If it appears to be making no forward progress, obtain the stacks and see is there is a syscall stuck in the platform API for a significant length of time.```**Output of `docker version`:**```C:\WINDOWS\system32>docker versionClient: Version:           master-dockerproject-2018-11-29 API version:       1.40 Go version:        go1.11.1 Git commit:        504cecf2 Built:             Thu Nov 29 23:50:48 2018 OS/Arch:           windows/amd64 Experimental:      falseServer: Engine:  Version:          master-dockerproject-2018-11-29  API version:      1.40 (minimum version 1.24)  Go version:       go1.11.2  Git commit:       baab736  Built:            Thu Nov 29 23:59:33 2018  OS/Arch:          windows/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 3 Running: 0 Paused: 0 Stopped: 3Images: 1Server Version: master-dockerproject-2018-11-29Storage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: ics l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd gcplogs gelf json-file local logentries splunk syslogSwarm: inactiveDefault Isolation: hypervKernel Version: 10.0 17763 (17763.1.amd64fre.rs5_release.180914-1434)Operating System: Windows 10 Enterprise Version 1809 (OS Build 17763.107)OSType: windowsArchitecture: x86_64CPUs: 8Total Memory: 7.927GiBName: DE00INDE044L1ID: KYRQ:XK2M:COIT:DBL5:TDPF:CJIW:D4OQ:K5PV:W44E:A5FZ:3RCW:QSNQDocker Root Dir: C:\ProgramData\dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: -1 Goroutines: 22 System Time: 2018-11-30T22:17:58.826596+01:00 EventsListeners: 0Registry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical Surface laptop
"
38303,0,2637,0,0,0,lbndev,0,"title:Buildkit in docker 18.09 won't allow insecure registry with self-signed TLS. description:**Description**Docker 18.09 with buildkit activated fails to pull from my private ""insecure"" registry.When buildkit is deactivated, the same Dockerfile builds fine.I originally posted this as a comment to https://github.com/moby/buildkit/issues/606 , I did more tests since then : I've found that the problem only occurs when activating the experimental syntax (to allow using RUN --mount).[ EDIT : the above isn't true : actually both builds fail if I properly delete all images before testing ]**Steps to reproduce the issue:**1. In daemon.json, declare private mirror + insecure registry and activate buildkit :```{  ""registry-mirrors"": [""https://repo.mycompany.com""],  ""insecure-registries"" : [""repo.mycompany.com""],  ""features"":{    ""buildkit"": true  }}```2. Build the following Dockerfile - it works :[ Edit : this was beause I had maven:3.5.3-alpine available locally, if I remove it and retry, it fails ]```FROM maven:3.5.3-alpineRUN mvn dependency:help```3. Now modify the Dockerfile to add the experimental syntax and a --mount argument to RUN :```# syntax=docker/dockerfile:experimentalFROM maven:3.5.3-alpineRUN --mount=target=/root/.m2,type=cache mvn dependency:help```**Describe the results you received:**This second build fails with :```[+] Building 0.4s (3/3) FINISHED => [internal] load build definition from Dockerfile => => transferring dockerfile: 169B => [internal] load .dockerignore => => transferring context: 2B => ERROR resolve image config for docker.io/docker/dockerfile:experimental------ > resolve image config for docker.io/docker/dockerfile:experimental:------failed to do request: Head https://repo.mycompany.com/v2/docker/dockerfile/manifests/experimental: x509: certificate signed by unknown authority```**Describe the results you expected:**I was expecting the image to build without error.As a bonus I'm also expecting that if I delete the generated image, and build it again, the maven dependencies will not need to be downloaded again, and fetched from the mounted cache instead, making my build a lot faster (which is the main reason why I want to use this feature).**Additional information you deem important (e.g. issue happens only occasionally):**Note that if I do `docker pull docker/dockerfile:experimental` (which works) and retry, the error will now be on pulling maven:3.5.3-slim as part of the build. [ Edit : this was because I had done `docker images -q | xargs docker rmi` between the tests ]I've also tested with dockerfile:1.0-experimental instead of dockerfile:experimental (as found in https://docs.docker.com/develop/develop-images/build_enhancements/#new-docker-build-secret-information) - with the same result.**Output of `docker version`:**```Client: Version:           18.09.0 API version:       1.39 Go version:        go1.10.4 Git commit:        4d60db4 Built:             Wed Nov  7 00:49:01 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.0  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.4  Git commit:       4d60db4  Built:            Wed Nov  7 00:16:44 2018  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 497Server Version: 18.09.0Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: c4446665cb9c30056f4998ed953e6d4ff22c7c39runc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: fec3683Security Options: apparmor seccomp  Profile: defaultKernel Version: 4.15.0-38-genericOperating System: Ubuntu 18.04.1 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 9.754GiBName: picID: JMTB:MV5N:DFIK:T6VA:BMPB:46DT:R6XZ:CLOJ:7NDD:ZVVP:BYXY:7L2FDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: repo.mycompany.com 127.0.0.0/8Registry Mirrors: https://repo.mycompany.com/Live Restore Enabled: falseProduct License: Community EngineWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**VM on VMWare ESXi 6.5.The ""insecure"" registry is our internal instance of Sonatype Nexus OSS 3.11.0 behind a reverse-proxy handling SSL with a letsencrypt-issued certificate. Above, I've replaced the real server address by repo.mycompany.com. 
"
38293,1,3987,247,0,0,AkihiroSuda,0,"title:TestRenameAnonymousContainer consistently fails locally. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->`integration/container.TestRenameAnonymousContainer` consistently fails locally**Steps to reproduce the issue:**```console$ TESTFLAGS=""-test.run TestRenameAnonymousContainer -test.count 10"" make test-integration...=== RUN   TestRenameAnonymousContainer--- FAIL: TestRenameAnonymousContainer (14.30s)    rename_test.go:165: timeout hit after 10s: waiting for container to be one of (exited), currently running=== RUN   TestRenameAnonymousContainer--- FAIL: TestRenameAnonymousContainer (13.34s)    rename_test.go:165: timeout hit after 10s: waiting for container to be one of (exited), currently running=== RUN   TestRenameAnonymousContainer--- FAIL: TestRenameAnonymousContainer (13.39s)    rename_test.go:165: timeout hit after 10s: waiting for container to be one of (exited), currently running=== RUN   TestRenameAnonymousContainer--- FAIL: TestRenameAnonymousContainer (13.36s)    rename_test.go:165: timeout hit after 10s: waiting for container to be one of (exited), currently running=== RUN   TestRenameAnonymousContainer--- FAIL: TestRenameAnonymousContainer (13.44s)    rename_test.go:165: timeout hit after 10s: waiting for container to be one of (exited), currently running=== RUN   TestRenameAnonymousContainer--- FAIL: TestRenameAnonymousContainer (13.39s)    rename_test.go:165: timeout hit after 10s: waiting for container to be one of (exited), currently running=== RUN   TestRenameAnonymousContainer--- FAIL: TestRenameAnonymousContainer (13.48s)    rename_test.go:165: timeout hit after 10s: waiting for container to be one of (exited), currently running=== RUN   TestRenameAnonymousContainer--- FAIL: TestRenameAnonymousContainer (13.84s)    rename_test.go:165: timeout hit after 10s: waiting for container to be one of (exited), currently running=== RUN   TestRenameAnonymousContainer--- FAIL: TestRenameAnonymousContainer (13.60s)    rename_test.go:165: timeout hit after 10s: waiting for container to be one of (exited), currently running=== RUN   TestRenameAnonymousContainer--- FAIL: TestRenameAnonymousContainer (13.78s)    rename_test.go:165: timeout hit after 10s: waiting for container to be one of (exited), currently runningFAIL...```https://github.com/moby/moby/blob/852542b3976754f62232f1fafca7fd35deeb1da3/integration/container/rename_test.go#L155-L165Tested on 852542b3976754f62232f1fafca7fd35deeb1da3, with Ubuntu 18.04.1 kernel 4.15.0-39-generic**Describe the results you received:**The test failed**Describe the results you expected:**The test should success**Additional information you deem important (e.g. issue happens only occasionally):**CI does not seem hitting the issue**Output of `docker version`:**```Client: Version:           master-dockerproject-2018-11-28 API version:       1.40 Go version:        go1.11.1 Git commit:        69bd2728 Built:             Wed Nov 28 23:39:38 2018 OS/Arch:           linux/amd64 Experimental:      trueServer: Engine:  Version:          master-dockerproject-2018-11-28  API version:      1.40 (minimum version 1.12)  Go version:       go1.11.2  Git commit:       852542b  Built:            Wed Nov 28 23:48:23 2018  OS/Arch:          linux/amd64  Experimental:     true```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 37Server Version: master-dockerproject-2018-11-28Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: kata runc runnc runsc runsc-kvmDefault Runtime: runcInit Binary: docker-initcontainerd version: de1f167ab96338a9f5c2b17347abf84bdf1dd411runc version: b1068fb9258d2cc5aa59505fbb703d914120013dinit version: fec3683Security Options: apparmor seccomp  Profile: defaultKernel Version: 4.15.0-39-genericOperating System: Ubuntu 18.04.1 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.829GiBName: suda-ws01ID: MTEP:U62V:AHM4:G7PE:XLR6:W4WR:WL4B:G5MY:VM5S:2MAV:GP25:ETL6Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 22 Goroutines: 43 System Time: 2018-11-29T13:59:54.443932021+09:00 EventsListeners: 0Username: akihirosudaRegistry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
38254,1,4121,200,0,0,thaJeztah,0,"title:BuildKit doesn't handle Dockerfile from stdin, when using remote context. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**When building from a remote source, but with a local Dockerfile from stdin, `docker build` fails when using buildkit;```bashDOCKER_BUILDKIT=1 docker build -t statx --no-cache -f- https://github.com/whotwagner/statx-fun.git <<-EOFFROM ubuntu:18.04RUN apt-get update && apt-get install -y gcc makeRUN mkdir /src/WORKDIR /src/COPY . .RUN makeEOF```Results in buildkit attempting to use a file named `-` as Dockerfile;```[+] Building 1.2s (1/1) FINISHED                                                                                                                                                                                            => [internal] load git source https://github.com/whotwagner/statx-fun.git                                                                                                                                            1.2sfailed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount863221464/-: no such file or directory```Wheras building without buildkit correctly handles `-` to use the Dockerfile from `stdin`;```bashDOCKER_BUILDKIT=0 docker build -t statx --no-cache -f- https://github.com/whotwagner/statx-fun.git <<-EOFFROM ubuntu:18.04RUN apt-get update && apt-get install -y gcc makeRUN mkdir /src/WORKDIR /src/COPY . .RUN makeEOF``````Sending build context to Docker daemon  110.6kBStep 1/6 : FROM ubuntu:18.04 ---> cd6d8154f1e1Step 2/6 : RUN apt-get update && apt-get install -y gcc make ---> Running in dcec0e12771eGet:1 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB]Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [83.2 kB]Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]Get:4 http://security.ubuntu.com/ubuntu bionic-security/universe Sources [26.0 kB]Get:5 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [1364 B]```**Output of `docker version`:**```Client: Docker Engine - Community Version:           18.09.0 API version:       1.39 Go version:        go1.10.4 Git commit:        4d60db4 Built:             Wed Nov  7 00:47:43 2018 OS/Arch:           darwin/amd64 Experimental:      trueServer: Docker Engine - Community Engine:  Version:          18.09.0  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.4  Git commit:       4d60db4  Built:            Wed Nov  7 00:55:00 2018  OS/Arch:          linux/amd64  Experimental:     true```**Output of `docker info`:**Not relevant, but included below;```Containers: 10 Running: 5 Paused: 0 Stopped: 5Images: 127Server Version: 18.09.0Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: active NodeID: g5l8yjyurr8xpie3k9xb08uqz Is Manager: true ClusterID: jrnii2o76lmneq8jrt9nz72ye Managers: 1 Nodes: 1 Default Address Pool: 10.0.0.0/8   SubnetSize: 24 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 10 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 192.168.65.3 Manager Addresses:  192.168.65.3:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 468a545b9edcd5932818eb9de8e72413e616e86erunc version: 69663f0bd4b60df09991c08812a60108003fa340init version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 4.9.125-linuxkitOperating System: Docker for MacOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952GiBName: linuxkit-025000000001ID: L3VR:6SGF:FS5T:YB7O:7IJZ:IOK3:2F2I:73K6:M5MP:55PZ:YDMN:YHUTDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 62 Goroutines: 214 System Time: 2018-11-22T19:25:52.274061223Z EventsListeners: 4HTTP Proxy: gateway.docker.internal:3128HTTPS Proxy: gateway.docker.internal:3129Registry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community Engine```</details>
"
38249,0,1562,0,0,1,ankul-shippable,0,"title:Failed to start container: id already in use (after reboot). description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Container with `restart=always` fails to restart after machine is rebooted**Steps to reproduce the issue:**1. Install docker version `18.03.1-ce` on ubuntu 16.04 LTS machine.2. Start a container with `restart=always`3. Reboot the machine several times.**Describe the results you received:**After sometime our container does not restart and fails with the error:```Nov 12 04:59:42 node-962a1238 dockerd[1290]: time=""2018-11-12T04:59:42.510523865Z"" level=info msg=""Removing stale sandbox bf8038ecbf612879caeaa224f80f9995b6f62409cf66ac45fc707b96204d7afc (79c6ec76a773791ea3cdcbc88c9664ccfc0580a5c8a73faf12f23a1dd2323879)""Nov 12 04:59:42 node-962a1238 dockerd[1290]: time=""2018-11-12T04:59:42.542730939Z"" level=info msg=""Removing stale endpoint reqProc-5be8e8137551a306007999a1 (d553bcbfc82c4e9fb776fddf1bf9f77595a8936234132c731c9dbc2d839c78a0)""Nov 12 04:59:42 node-962a1238 dockerd[1290]: time=""2018-11-12T04:59:42.547410154Z"" level=info msg=""Fixing inconsistent endpoint_cnt for network bridge. Expected=0, Actual=1""Nov 12 04:59:42 node-962a1238 dockerd[1290]: time=""2018-11-12T04:59:42.611847891Z"" level=info msg=""Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address""Nov 12 04:59:42 node-962a1238 dockerd[1290]: time=""2018-11-12T04:59:42.999414691Z"" level=error msg=""Failed to start container 79c6ec76a773791ea3cdcbc88c9664ccfc0580a5c8a73faf12f23a1dd2323879: id already in use""```**Additional information you deem important (e.g. issue happens only occasionally):** It happens randomly.**Output of `docker version`:**```Client: Version:      18.03.1-ce API version:  1.37 Go version:   go1.9.5 Git commit:   9ee9f40 Built:        Thu Apr 26 07:17:20 2018 OS/Arch:      linux/amd64 Experimental: false Orchestrator: swarmServer: Engine:  Version:      18.03.1-ce  API version:  1.37 (minimum version 1.12)  Go version:   go1.9.5  Git commit:   9ee9f40  Built:        Thu Apr 26 07:15:30 2018  OS/Arch:      linux/amd64  Experimental: false```
"
38233,1,0,300,0,0,sboeuf,0,"title:Exiting the container does not trigger a `runtime delete` from Docker. description:**Description**Kata Containers was working great with Docker `18.06`, but when moved to `18.09` I realized that our container (VM in our case) was not properly destroyed. This being tied to the fact that when the container process terminates (let's say `exit` from the shell), we expect `docker` (and `containerd`) to call into `runtime delete <container-id>` after it detected the container process terminated.Apparently the logic seems to have changed because the behavior is now different and docker does not try to `delete` my container.
"
38222,0,224,10,0,0,quilir,0,"title:Response for container create has null value for non-nullable field. description:**Description**Docker API returns null value for Warnings field.According to a definition it probably should never be null. It has `x-nullable: falsehttps://github.com/moby/moby/blob/master/api/swagger.yaml#L4659-L4676**Steps to reproduce the issue:**1. Send correct, /containers/create request to API https://docs.docker.com/engine/api/v1.37/#operation/ContainerCreate2. Check responseExample response's body:```json{    ""Id"": ""6ce9cb39c1d6a905c0fc7909235b74491d5a0f184ff097bb73ffe9a30cd7743a"",    ""Warnings"": null}```instead of:```json{    ""Id"": ""6ce9cb39c1d6a905c0fc7909235b74491d5a0f184ff097bb73ffe9a30cd7743a"",    ""Warnings"": []}```
"
38220,1,1824,293,1,1,andyzhangx,0,"title:[Windows Update servicing fix due March 2019] Absolute path of symlink does not work on Windows volume mapping. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**The original symlink issue(https://github.com/moby/moby/issues/28401) has been fixed in windows 1803, while only relative symlink issue is fixed, symlink with **absolute** path is not fixed.**Steps to reproduce the issue:**1. Create a text file in `c:\test` directory```mkdir C:\testcd c:\testecho ""Symlink Test"" > test.txt```2. Create a symlink pointing to the text file with **absolute** path```cmd /c mklink symtmp.txt c:\test\test.txtc:\test>type symtmp.txt""Symlink Test""```3. Run powershellcontainer and mount the working directory as volume```docker run --rm -v c:\test:c:\test -it mcr.microsoft.com/powershell cmd```**Describe the results you received:**Inside the container run```c:\test>dir...11/19/2018  05:57 AM    <SYMLINK>      symtmp.txt [c:\test\test.txt]...c:\test>type symtmp.txtThe create operation failed because the name contained at least one mount point which resolves to a volume to which the specified device object is not attached.```Actually here target path `c:\test\test.txt` exists inside container, while we cannot access symtmp.txt inside container.**Describe the results you expected:**```C:\test> type .\symtmp.txtSymlink Test```**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.06.2-ee-16 API version:  1.30 Go version:   go1.8.7 Git commit:   9ef4f0a Built:        Thu Jul 26 16:43:19 2018 OS/Arch:      windows/amd64Server: Engine:  Version:      17.06.2-ee-16  API version:  1.30 (minimum version 1.24)  Go version:   go1.8.7  Git commit:   9ef4f0a  Built:        Thu Jul 26 16:52:17 2018  OS/Arch:      windows/amd64  Experimental: false```**Output of `docker info`:**```Containers: 3 Running: 2 Paused: 0 Stopped: 1Images: 19Server Version: 17.06.2-ee-16Storage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd json-file logentries splunk syslogSwarm: inactiveDefault Isolation: processKernel Version: 10.0 17134 (17134.1.amd64fre.rs4_release.180410-1804)Operating System: Windows Server DatacenterOSType: windowsArchitecture: x86_64CPUs: 2Total Memory: 7GiBName: 18986k8s9000ID: PE4S:FFYI:L5Z3:XPNN:RSF6:WZCK:NZZN:3PFZ:D5NQ:S6MO:4QTR:EW56Docker Root Dir: C:\ProgramData\dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**winver : Windows 1803  (OS Build 10.0.17134.228)@PatrickLang
"
38208,0,1833,100,0,0,sheerun,0,"title:docker system prune doesn't accept ""until"" filter anymore. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Following worked in 18.06.1-ce but doesn't work in 18.09.0:```docker system prune --filter ""until=24h"" --forceError response from daemon: failed to prune build cache: Invalid filter 'until'```**Output of `docker version`:**```Client: Version:           18.09.0 API version:       1.39 Go version:        go1.10.4 Git commit:        4d60db4 Built:             Wed Nov  7 00:48:57 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Docker Engine - Community Engine:  Version:          18.09.0  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.4  Git commit:       4d60db4  Built:            Wed Nov  7 00:16:44 2018  OS/Arch:          linux/amd64  Experimental:     false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 18.09.0Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: c4446665cb9c30056f4998ed953e6d4ff22c7c39runc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: fec3683Security Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.127-mainline-rev1Operating System: Ubuntu 16.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.752GiBName: gitlab-alphaID: KG5Y:N3O2:DSR2:MLGY:S2B7:GWAX:DXHW:CS3Z:TCUS:2MHA:E72H:QGASDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community Engine```**Additional environment details (AWS, VirtualBox, physical, etc.):**Barebones cloud computer
"
38175,1,16124,5,1,1,DutchessNicole,0,"title:docker-ce segmentation fault on Raspbian (v18.09.03). description:Since two days ago docker will no longer start, after I updated the version that worked to Version: 5:18.09.0~3-0~raspbian-stretch.After that the docker daemon will no longer start.strace -f dockerd reports ```root@raspberrypi:~# strace -f dockerdexecve(""/usr/bin/dockerd"", [""dockerd""], [/* 27 vars */]) = 0brk(NULL)                               = 0x3b13000uname({sysname=""Linux"", nodename=""raspberrypi"", ...}) = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)mmap2(NULL, 12288, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb6f6e000access(""/etc/ld.so.preload"", R_OK)      = 0open(""/etc/ld.so.preload"", O_RDONLY|O_CLOEXEC) = 3fstat64(3, {st_mode=S_IFREG|0644, st_size=42, ...}) = 0mmap2(NULL, 42, PROT_READ|PROT_WRITE, MAP_PRIVATE, 3, 0) = 0xb6f6d000close(3)                                = 0open(""/usr/lib/arm-linux-gnueabihf/libarmmem.so"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0\210\5\0\0004\0\0\0""..., 512) = 512lseek(3, 20868, SEEK_SET)               = 20868read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1000) = 1000lseek(3, 20540, SEEK_SET)               = 20540read(3, ""A,\0\0\0aeabi\0\1\""\0\0\0\0056\0\6\6\10\1\t\1\n\3\f\1\22\4\24""..., 45) = 45fstat64(3, {st_mode=S_IFREG|0644, st_size=21868, ...}) = 0mmap2(NULL, 86080, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6f2b000mprotect(0xb6f30000, 61440, PROT_NONE)  = 0mmap2(0xb6f3f000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x4000) = 0xb6f3f000close(3)                                = 0munmap(0xb6f6d000, 42)                  = 0open(""/etc/ld.so.cache"", O_RDONLY|O_CLOEXEC) = 3fstat64(3, {st_mode=S_IFREG|0644, st_size=28101, ...}) = 0mmap2(NULL, 28101, PROT_READ, MAP_PRIVATE, 3, 0) = 0xb6f67000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/lib/arm-linux-gnueabihf/libsystemd.so.0"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0\0\0\0\0004\0\0\0""..., 512) = 512lseek(3, 493188, SEEK_SET)              = 493188read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1320) = 1320lseek(3, 492748, SEEK_SET)              = 492748read(3, ""A2\0\0\0aeabi\0\1(\0\0\0\0056\0\6\6\10\1\t\1\n\2\f\3\22\4\23""..., 51) = 51fstat64(3, {st_mode=S_IFREG|0644, st_size=494508, ...}) = 0mmap2(NULL, 499173, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6eb1000mmap2(0xb6f28000, 12288, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x76000) = 0xb6f28000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/lib/arm-linux-gnueabihf/libpthread.so.0"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\3\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0dI\0\0004\0\0\0""..., 512) = 512lseek(3, 125740, SEEK_SET)              = 125740read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1560) = 1560lseek(3, 90536, SEEK_SET)               = 90536read(3, ""A.\0\0\0aeabi\0\1$\0\0\0\0056\0\6\6\10\1\t\1\n\2\22\4\23\1\24""..., 47) = 47fstat64(3, {st_mode=S_IFREG|0755, st_size=127300, ...}) = 0mmap2(NULL, 164432, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6e88000mprotect(0xb6e9e000, 61440, PROT_NONE)  = 0mmap2(0xb6ead000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x15000) = 0xb6ead000mmap2(0xb6eaf000, 4688, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0xb6eaf000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/lib/arm-linux-gnueabihf/libseccomp.so.2"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0\344\272\0\0004\0\0\0""..., 512) = 512lseek(3, 139840, SEEK_SET)              = 139840read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1040) = 1040lseek(3, 139504, SEEK_SET)              = 139504read(3, ""A,\0\0\0aeabi\0\1\""\0\0\0\0056\0\6\6\10\1\t\1\n\2\22\4\24\1\25""..., 45) = 45fstat64(3, {st_mode=S_IFREG|0644, st_size=140880, ...}) = 0mmap2(NULL, 205044, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6e55000mprotect(0xb6e6c000, 65536, PROT_NONE)  = 0mmap2(0xb6e7c000, 49152, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17000) = 0xb6e7c000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/lib/arm-linux-gnueabihf/libc.so.6"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0@h\1\0004\0\0\0""..., 512) = 512lseek(3, 1231820, SEEK_SET)             = 1231820read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 2880) = 2880lseek(3, 1228284, SEEK_SET)             = 1228284read(3, ""A.\0\0\0aeabi\0\1$\0\0\0\0056\0\6\6\10\1\t\1\n\2\22\4\23\1\24""..., 47) = 47fstat64(3, {st_mode=S_IFREG|0755, st_size=1234700, ...}) = 0mmap2(NULL, 1303872, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6d16000mprotect(0xb6e3f000, 65536, PROT_NONE)  = 0mmap2(0xb6e4f000, 12288, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x129000) = 0xb6e4f000mmap2(0xb6e52000, 9536, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0xb6e52000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/lib/arm-linux-gnueabihf/libselinux.so.1"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0hN\0\0004\0\0\0""..., 512) = 512lseek(3, 136448, SEEK_SET)              = 136448read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1160) = 1160lseek(3, 136088, SEEK_SET)              = 136088read(3, ""A,\0\0\0aeabi\0\1\""\0\0\0\0056\0\6\6\10\1\t\1\n\2\22\4\24\1\25""..., 45) = 45fstat64(3, {st_mode=S_IFREG|0644, st_size=137608, ...}) = 0mmap2(NULL, 208496, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6ce3000mprotect(0xb6d03000, 65536, PROT_NONE)  = 0mmap2(0xb6d13000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x20000) = 0xb6d13000mmap2(0xb6d15000, 3696, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0xb6d15000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/lib/arm-linux-gnueabihf/librt.so.1"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\3\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0 \27\0\0004\0\0\0""..., 512) = 512lseek(3, 25352, SEEK_SET)               = 25352read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1280) = 1280lseek(3, 24940, SEEK_SET)               = 24940read(3, ""A.\0\0\0aeabi\0\1$\0\0\0\0056\0\6\6\10\1\t\1\n\2\22\4\23\1\24""..., 47) = 47fstat64(3, {st_mode=S_IFREG|0644, st_size=26632, ...}) = 0mmap2(NULL, 90640, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6ccc000mprotect(0xb6cd2000, 61440, PROT_NONE)  = 0mmap2(0xb6ce1000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x5000) = 0xb6ce1000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/lib/arm-linux-gnueabihf/liblzma.so.5"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0\230\""\0\0004\0\0\0""..., 512) = 512lseek(3, 131848, SEEK_SET)              = 131848read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1080) = 1080lseek(3, 131500, SEEK_SET)              = 131500read(3, ""A,\0\0\0aeabi\0\1\""\0\0\0\0056\0\6\6\10\1\t\1\n\2\22\4\24\1\25""..., 45) = 45fstat64(3, {st_mode=S_IFREG|0644, st_size=132928, ...}) = 0mmap2(NULL, 197040, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6c9b000mprotect(0xb6cbb000, 61440, PROT_NONE)  = 0mmap2(0xb6cca000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1f000) = 0xb6cca000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/usr/lib/arm-linux-gnueabihf/liblz4.so.1"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0\300\32\0\0004\0\0\0""..., 512) = 512lseek(3, 66052, SEEK_SET)               = 66052read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1040) = 1040lseek(3, 65748, SEEK_SET)               = 65748read(3, ""A,\0\0\0aeabi\0\1\""\0\0\0\0056\0\6\6\10\1\t\1\n\2\22\4\24\1\25""..., 45) = 45fstat64(3, {st_mode=S_IFREG|0644, st_size=67092, ...}) = 0mmap2(NULL, 131288, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6c7a000mprotect(0xb6c8a000, 61440, PROT_NONE)  = 0mmap2(0xb6c99000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xf000) = 0xb6c99000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/lib/arm-linux-gnueabihf/libgcrypt.so.20"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0\0\\\0\0004\0\0\0""..., 512) = 512lseek(3, 787796, SEEK_SET)              = 787796read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1120) = 1120lseek(3, 787437, SEEK_SET)              = 787437read(3, ""A,\0\0\0aeabi\0\1\""\0\0\0\0056\0\6\6\10\1\t\1\n\7\f\3\22\4\24""..., 45) = 45fstat64(3, {st_mode=S_IFREG|0644, st_size=788916, ...}) = 0mmap2(NULL, 853676, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6ba9000mprotect(0xb6c65000, 65536, PROT_NONE)  = 0mmap2(0xb6c75000, 20480, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xbc000) = 0xb6c75000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/lib/arm-linux-gnueabihf/libgcc_s.so.1"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0\200\321\0\0004\0\0\0""..., 512) = 512lseek(3, 115292, SEEK_SET)              = 115292read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1080) = 1080lseek(3, 114944, SEEK_SET)              = 114944read(3, ""A,\0\0\0aeabi\0\1\""\0\0\0\0056\0\6\6\10\1\t\1\n\2\22\4\24\1\25""..., 45) = 45fstat64(3, {st_mode=S_IFREG|0644, st_size=116372, ...}) = 0mmap2(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb6f65000mmap2(NULL, 180536, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6b7c000mprotect(0xb6b98000, 61440, PROT_NONE)  = 0mmap2(0xb6ba7000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1b000) = 0xb6ba7000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/lib/arm-linux-gnueabihf/libpcre.so.3"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0004\20\0\0004\0\0\0""..., 512) = 512lseek(3, 426320, SEEK_SET)              = 426320read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1040) = 1040lseek(3, 426012, SEEK_SET)              = 426012read(3, ""A,\0\0\0aeabi\0\1\""\0\0\0\0056\0\6\6\10\1\t\1\n\2\22\4\24\1\25""..., 45) = 45fstat64(3, {st_mode=S_IFREG|0644, st_size=427360, ...}) = 0mmap2(NULL, 491604, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6b03000mprotect(0xb6b6b000, 61440, PROT_NONE)  = 0mmap2(0xb6b7a000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x67000) = 0xb6b7a000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/lib/arm-linux-gnueabihf/libdl.so.2"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0P\t\0\0004\0\0\0""..., 512) = 512lseek(3, 8680, SEEK_SET)                = 8680read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1120) = 1120lseek(3, 8328, SEEK_SET)                = 8328read(3, ""A.\0\0\0aeabi\0\1$\0\0\0\0056\0\6\6\10\1\t\1\n\2\22\4\23\1\24""..., 47) = 47fstat64(3, {st_mode=S_IFREG|0644, st_size=9800, ...}) = 0mmap2(NULL, 73912, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6af0000mprotect(0xb6af2000, 61440, PROT_NONE)  = 0mmap2(0xb6b01000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1000) = 0xb6b01000close(3)                                = 0access(""/etc/ld.so.nohwcap"", F_OK)      = -1 ENOENT (No such file or directory)open(""/lib/arm-linux-gnueabihf/libgpg-error.so.0"", O_RDONLY|O_CLOEXEC) = 3read(3, ""\177ELF\1\1\1\0\0\0\0\0\0\0\0\0\3\0(\0\1\0\0\0H\37\0\0004\0\0\0""..., 512) = 512lseek(3, 61836, SEEK_SET)               = 61836read(3, ""\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 1120) = 1120lseek(3, 61472, SEEK_SET)               = 61472read(3, ""A.\0\0\0aeabi\0\1$\0\0\0\0056\0\6\6\10\1\t\1\n\2\22\4\23\1\24""..., 47) = 47fstat64(3, {st_mode=S_IFREG|0644, st_size=62956, ...}) = 0mmap2(NULL, 127064, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0xb6ad0000mprotect(0xb6adf000, 61440, PROT_NONE)  = 0mmap2(0xb6aee000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0xe000) = 0xb6aee000close(3)                                = 0mmap2(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb6f63000set_tls(0xb6f634c0, 0xb6f63c88, 0xb6f72050, 0xb6f634c0, 0xb6f72050) = 0mprotect(0xb6e4f000, 8192, PROT_READ)   = 0mprotect(0xb6aee000, 4096, PROT_READ)   = 0mprotect(0xb6b01000, 4096, PROT_READ)   = 0mprotect(0xb6ead000, 4096, PROT_READ)   = 0mprotect(0xb6b7a000, 4096, PROT_READ)   = 0mprotect(0xb6ba7000, 4096, PROT_READ)   = 0mprotect(0xb6c75000, 4096, PROT_READ)   = 0mprotect(0xb6c99000, 4096, PROT_READ)   = 0mprotect(0xb6cca000, 4096, PROT_READ)   = 0mprotect(0xb6ce1000, 4096, PROT_READ)   = 0mprotect(0xb6d13000, 4096, PROT_READ)   = 0mprotect(0xb6e7c000, 45056, PROT_READ)  = 0mprotect(0xb6f28000, 8192, PROT_READ)   = 0mprotect(0xb6f2b000, 20480, PROT_READ|PROT_WRITE) = 0mprotect(0xb6f2b000, 20480, PROT_READ|PROT_EXEC) = 0cacheflush(0xb6f2b000, 0xb6f30000, 0, 0x15, 0) = 0mprotect(0xb6f3f000, 4096, PROT_READ)   = 0mprotect(0x1e44000, 16830464, PROT_READ) = 0mprotect(0xb6f71000, 4096, PROT_READ)   = 0munmap(0xb6f67000, 28101)               = 0set_tid_address(0xb6f63068)             = 2357set_robust_list(0xb6f63070, 12)         = 0rt_sigaction(SIGRTMIN, {sa_handler=0xb6e8c2b0, sa_mask=[], sa_flags=SA_RESTORER|SA_SIGINFO, sa_restorer=0xb6d426c0}, NULL, 8) = 0rt_sigaction(SIGRT_1, {sa_handler=0xb6e8c390, sa_mask=[], sa_flags=SA_RESTORER|SA_RESTART|SA_SIGINFO, sa_restorer=0xb6d426c0}, NULL, 8) = 0rt_sigprocmask(SIG_UNBLOCK, [RTMIN RT_1], NULL, 8) = 0ugetrlimit(RLIMIT_STACK, {rlim_cur=8192*1024, rlim_max=RLIM_INFINITY}) = 0brk(NULL)                               = 0x3b13000brk(0x3b34000)                          = 0x3b34000statfs(""/sys/fs/selinux"", 0xbea4e5cc)   = -1 ENOENT (No such file or directory)statfs(""/selinux"", 0xbea4e5cc)          = -1 ENOENT (No such file or directory)open(""/proc/filesystems"", O_RDONLY)     = 3fstat64(3, {st_mode=S_IFREG|0444, st_size=0, ...}) = 0read(3, ""nodev\tsysfs\nnodev\trootfs\nnodev\tr""..., 1024) = 310read(3, """", 1024)                       = 0close(3)                                = 0access(""/etc/selinux/config"", F_OK)     = -1 ENOENT (No such file or directory)--- SIGSEGV {si_signo=SIGSEGV, si_code=SEGV_MAPERR, si_addr=0x884a59} ---+++ killed by SIGSEGV +++Segmentation fault```Similar to other reports all I get when running dockerd manually is ""segmentation fault"" and the logs report nothing interesting.Docker version installed:```root@raspberrypi:~# docker versionClient: Version:           18.09.0 API version:       1.39 Go version:        go1.10.4 Git commit:        4d60db4 Built:             Wed Nov  7 00:57:21 2018 OS/Arch:           linux/arm Experimental:      falseCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?```Kernel info:```Linux raspberrypi 4.14.71+ #1145 Fri Sep 21 15:06:38 BST 2018 armv6l GNU/Linux```_Originally posted by @DutchessNicole in https://github.com/moby/moby/issues/29347#issuecomment-437581438_
"
38156,1,0,0,0,0,pszczekutowicz,0,"title:Unable to install containerd.io 1.2.0-1 from download.docker.com/linux/ubuntu repository. description:**Description**Latest available version of containerd.io package in Ubuntu repository is  1.2.0~rc.2-1. **Steps to reproduce the issue:**1. Add the repository according to the instruction from  https://docs.docker.com/install/linux/docker-ce/ubuntu/2. Execute sudo apt install containerd.io**Describe the results you received:**Version 1.2.0~rc.2-1 of containerd.io is installed  **Describe the results you expected:**Version 1.2.0-1 should be installed.**Additional information you deem important (e.g. issue happens only occasionally):**Tested in Ubuntu 18.04.1Following file is present: https://download.docker.com/linux/ubuntu/dists/bionic/pool/stable/amd64/containerd.io_1.2.0-1_amd64.deb
"
38140,0,2469,200,1,0,thaJeztah,0,"title:Service create API returns 5xx status instead of 4xx. description:(as reported by @waseemshahwan in https://github.com/moby/moby/issues/31909#issuecomment-435742609)Looks like a regression was introduced somewhere between Docker 17.07 and 17.09.1, causing the status code for a ""conflict"" to change from a 409 to a 500;To reproduce; run a ""service create"" request _twice_ (second time should return a ""conflict"";```bashcurl -v \  --unix-socket /var/run/docker.sock \  -X POST \  ""http://localhost/v1.30/services/create"" \  -H ""Content-Type: application/json"" \  -d '{""EndpointSpec"":{""Mode"":""vip""},""Labels"":{},""Mode"":{""Replicated"":{}},""Name"":""testing"",""TaskTemplate"":{""ContainerSpec"":{""DNSConfig"":{},""Image"":""nginx:alpine@sha256:ae5da813f8ad7fa785d7668f0b018ecc8c3a87331527a61d83b3b5e816a0f03c"",""Init"":false},""ForceUpdate"":0,""Placement"":{""Platforms"":[{""Architecture"":""amd64"",""OS"":""linux""},{""OS"":""linux""},{""Architecture"":""arm64"",""OS"":""linux""},{""Architecture"":""386"",""OS"":""linux""},{""Architecture"":""ppc64le"",""OS"":""linux""},{""Architecture"":""s390x"",""OS"":""linux""}]},""Resources"":{""Limits"":{},""Reservations"":{}}}}'```On Docker 17.07.0-ce```> POST /v1.30/services/create HTTP/1.1> Host: localhost> User-Agent: curl/7.61.1> Accept: */*> Content-Type: application/json> Content-Length: 536> * upload completely sent off: 536 out of 536 bytes< HTTP/1.1 409 Conflict< Api-Version: 1.31< Content-Type: application/json< Docker-Experimental: false< Ostype: linux< Server: Docker/17.07.0-ce (linux)< Date: Mon, 05 Nov 2018 16:10:58 GMT< Content-Length: 86< {""message"":""rpc error: code = Unknown desc = name conflicts with an existing object""}```On Docker 17.09.1-ce```> POST /v1.30/services/create HTTP/1.1> Host: localhost> User-Agent: curl/7.61.1> Accept: */*> Content-Type: application/json> Content-Length: 536> * upload completely sent off: 536 out of 536 bytes< HTTP/1.1 500 Internal Server Error< Api-Version: 1.32< Content-Type: application/json< Docker-Experimental: false< Ostype: linux< Server: Docker/17.09.1-ce (linux)< Date: Mon, 05 Nov 2018 16:11:59 GMT< Content-Length: 86< {""message"":""rpc error: code = Unknown desc = name conflicts with an existing object""}```On 18.06.1-ce (still reproduces)```*   Trying /var/run/docker.sock...* Connected to localhost (/var/run/docker.sock) port 80 (#0)> POST /v1.30/services/create HTTP/1.1> Host: localhost> User-Agent: curl/7.61.1> Accept: */*> Content-Type: application/json> Content-Length: 536> * upload completely sent off: 536 out of 536 bytes< HTTP/1.1 500 Internal Server Error< Api-Version: 1.38< Content-Type: application/json< Docker-Experimental: false< Ostype: linux< Server: Docker/18.06.1-ce (linux)< Date: Mon, 05 Nov 2018 10:31:29 GMT< Content-Length: 86< {""message"":""rpc error: code = Unknown desc = name conflicts with an existing object""}* Connection #0 to host localhost left intact```
"
38118,1,501,294,0,0,sudo-bmitch,0,"title:Documentation needed on DOCKER_HOST behavior change. description:**Description**While attempting an update to 18.09.0-beta5, I'm seeing the DOCKER_HOST handling has changed to require `tcp://` in front of the URL. This change may break user scripts and should be documented in the release notes. Previous releases were much more relaxed on the parsing of the DOCKER_HOST variable, including 18.06.1.**Steps to reproduce the issue:**```export DOCKER_HOST=127.0.0.1:2376docker info```**Describe the results you received:**I'm seeing the below error message from the docker client now:```parse 127.0.0.1:2376: first path segment in URL cannot contain colon```**Describe the results you expected:**Successfully connect to the dockerd daemon. Release notes informing the user to change their host variable to include a `tcp://` in the beginning, e.g. `DOCKER_HOST=tcp://<host_name_or_ip>:<port>` would be appropriate if this is a permanent change.**Additional information you deem important (e.g. issue happens only occasionally):**This appears to be a breaking changing in the 18.09 upgrade.**Output of `docker version`:**Docker engine is not able to start yet (separate issues may be pending). Debian Linux install from Docker's test repo.```$ DOCKER_HOST=tcp://127.0.0.1:2376 docker versionClient: Version:           18.09.0-beta5 API version:       1.39 Go version:        go1.10.4 Git commit:        e1910c5 Built:             Tue Oct 23 22:25:34 2018 OS/Arch:           linux/amd64 Experimental:      trueCannot connect to the Docker daemon at tcp://127.0.0.1:2376. Is the docker daemon running?```**Output of `docker info`:**See above.**Additional environment details (AWS, VirtualBox, physical, etc.):**Local physical machine.
"
38114,1,596,200,0,0,thaJeztah,0,"title:WindowsRS5 CI is borked. description:For example on https://github.com/moby/moby/pull/38103; https://jenkins.dockerproject.org/job/Docker-PRs-WoW-RS5-Process/237/console```23:11:20 INFO: Base image for tests is microsoft/windowsservercore23:11:20 INFO: Loading windowsservercore .tar from disk into the daemon under test. This may take some time...23:12:08 23:12:08 23:12:08 ERROR: Failed 'ERROR: Failed to load c:\baseimages\windowsservercore.tar into daemon under test' at 10/30/2018 23:12:0823:12:08 At C:\gopath\src\github.com\docker\docker\hack\ci\windows.ps1:705 char:2123:12:08 + ...             Throw $(""ERROR: Failed to load $readBaseFrom`:\baseimages ...23:12:08 +                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~```These scripts were last updated in https://github.com/moby/moby/pull/37715, but I'm not sure if that's related, or if it's something with the machines.ping @ddebroy @jhowardmsft @johnstep PTAL
"
38059,1,2029,0,0,0,darkk,0,"title:docker build does not accept uncompressed tar from stdin anymore. description:**Description**`docker build` was previously accepting output of `git archive --format=tar` to build an image, but it does not accept it anymore.It still accepts `git archive --format=tgz`.Moreover, there was [a request for a test](https://github.com/moby/moby/pull/5715#issuecomment-43275427) to verify that it continues to accept uncompressed tar, so it seems to be a regression.**Steps to reproduce the issue:**1. `git clone https://github.com/ooni/api.git`2. `cd api`3. `git archive --format=tar 210e8603aea57e03e3fc6066d5967c2bf53879a9 | docker build -t openobservatory/api:latest -`**Describe the results you received:**```Sending build context to Docker daemon  8.521MBError response from daemon: Syntax error - can't find = in ""relationship('Label',"". Must be of the form: name=value```**Describe the results you expected:**```Sending build context to Docker daemon  2.271MBStep 1/14 : FROM python:3.5.2-slim ---> 783dcbbe2366Step 2/14 : ENV PYTHONUNBUFFERED 1...```**Additional information you deem important (e.g. issue happens only occasionally):**- Issue is 100% reproducible.- It worked okay before upgrade from `docker-engine=17.05.0~ce-0~ubuntu-xenial` to `docker-ce=18.06.1~ce~3-0~ubuntu`.**Output of `docker version`:**```Client: Version:           18.06.1-ce API version:       1.38 Go version:        go1.10.3 Git commit:        e68fc7a Built:             Tue Aug 21 17:24:56 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          18.06.1-ce  API version:      1.38 (minimum version 1.12)  Go version:       go1.10.3  Git commit:       e68fc7a  Built:            Tue Aug 21 17:23:21 2018  OS/Arch:          linux/amd64  Experimental:     true```**Output of `docker info`:**```Containers: 1 Running: 0 Paused: 0 Stopped: 1Images: 71Server Version: 18.06.1-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 96 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 468a545b9edcd5932818eb9de8e72413e616e86erunc version: 69663f0bd4b60df09991c08812a60108003fa340init version: fec3683Security Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-137-genericOperating System: Ubuntu 16.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.54GiBName: darkk-ya-laptopID: 35BR:WVWC:6V2X:UQVF:OTSA:F7AN:26ZI:3TWB:3H3J:ROK3:OADI:SGEEDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: darkkRegistry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**That's ordinary physical node with Ubuntu 16.04 desktop.The issue also exists on MacOS build according to https://github.com/ooni/sysadmin/issues/229
"
37920,0,2941,0,0,0,shin-,0,"title:[18.09.0-ce-beta1] /build/prune API endpoint broken in latest beta. description:**Description**POSTing to the `/build/prune` API endpoint with default parameters fails with a 500 error **Steps to reproduce the issue:**1. Expose docker daemon over local HTTP (e.g. `sudo dockerd -H tcp://127.0.0.1:48888`)2. Issue the following CURL command: `curl -v -XPOST 127.0.0.1:48888/v1.37/build/prune`**Describe the results you received:**```$ curl -v -XPOST 127.0.0.1:48888/v1.37/build/prune*   Trying 127.0.0.1...* TCP_NODELAY set* Connected to 127.0.0.1 (127.0.0.1) port 48888 (#0)> POST /v1.37/build/prune HTTP/1.1> Host: 127.0.0.1:48888> User-Agent: curl/7.58.0> Accept: */*> < HTTP/1.1 500 Internal Server Error< Api-Version: 1.39< Content-Type: application/json< Docker-Experimental: true< Ostype: linux< Server: Docker/18.09.0-ce-beta1 (linux)< Date: Wed, 26 Sep 2018 21:57:06 GMT< Content-Length: 112< {""message"":""keep-storage is in bytes and expects an integer, got : strconv.Atoi: parsing \""\"": invalid syntax""}```**Describe the results you expected:**Successful command with 2xx HTTP status**Additional information you deem important (e.g. issue happens only occasionally):**Note that the HTTP exposing part isn't necessary to reproduce the issue (same failure occurs over a UNIX socket). It just makes it easier to test with CURL.**Output of `docker version`:**```Client: Version:           18.09.0-ce-beta1 API version:       1.39 Go version:        go1.10.4 Git commit:        78a6bdb Built:             Thu Sep  6 22:46:29 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          18.09.0-ce-beta1  API version:      1.39 (minimum version 1.12)  Go version:       go1.10.4  Git commit:       78a6bdb  Built:              OS/Arch:          linux/amd64  Experimental:     true```**Output of `docker info`:**```Containers: 45 Running: 0 Paused: 0 Stopped: 45Images: 94Server Version: 18.09.0-ce-beta1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 446 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: active NodeID: thwfebu1ugl68j0249j04bip3 Is Manager: true ClusterID: dmsd9999ny9mccwkd8daqoek6 Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 10 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 192.168.100.222 Manager Addresses:  192.168.100.222:2377Runtimes: containerd runcDefault Runtime: containerdInit Binary: docker-initcontainerd version: ce243288e27971e324363de8f322d221635a8521 (expected: 468a545b9edcd5932818eb9de8e72413e616e86e)runc version: 70ca035aa6ecfc496e13365fdef20383408501ba (expected: 69663f0bd4b60df09991c08812a60108003fa340)init version: fec3683Security Options: apparmorKernel Version: 4.15.0-34-genericOperating System: Ubuntu 18.04.1 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.492GiBName: yunaID: YZQG:AKYJ:JQXJ:CEHT:62DP:PMWA:S43W:5X47:SSOE:UXGG:XHWS:555FDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community Engine```**Additional environment details (AWS, VirtualBox, physical, etc.):**N/A
"
37916,1,4808,26,0,0,Sarke,0,"title:Error on build: double free or corruption (out) SIGABRT: abort PC=0x7f7464f01e97 m=0 sigcode=18446744073709551610 signal arrived during cgo execution. description:**Description**See error below.**Steps to reproduce the issue:**1. `sudo docker build -t site-watcher .`**Describe the results you received:**```double free or corruption (out)SIGABRT: abortPC=0x7f3e05499e97 m=0 sigcode=18446744073709551610signal arrived during cgo executiongoroutine 1 [syscall, locked to thread]:runtime.cgocall(0x4afd50, 0xc42004fcc0, 0xc42004fce8)	/usr/lib/go-1.8/src/runtime/cgocall.go:131 +0xe2 fp=0xc42004fc90 sp=0xc42004fc50github.com/docker/docker-credential-helpers/secretservice._Cfunc_free(0xc6a920)	github.com/docker/docker-credential-helpers/secretservice/_obj/_cgo_gotypes.go:111 +0x41 fp=0xc42004fcc0 sp=0xc42004fc90github.com/docker/docker-credential-helpers/secretservice.Secretservice.List.func5(0xc6a920)	/build/golang-github-docker-docker-credential-helpers-cMhSy1/golang-github-docker-docker-credential-helpers-0.5.0/obj-x86_64-linux-gnu/src/github.com/docker/docker-credential-helpers/secretservice/secretservice_linux.go:96 +0x60 fp=0xc42004fcf8 sp=0xc42004fcc0github.com/docker/docker-credential-helpers/secretservice.Secretservice.List(0x0, 0x756060, 0xc4200123c0)	/build/golang-github-docker-docker-credential-helpers-cMhSy1/golang-github-docker-docker-credential-helpers-0.5.0/obj-x86_64-linux-gnu/src/github.com/docker/docker-credential-helpers/secretservice/secretservice_linux.go:97 +0x217 fp=0xc42004fda0 sp=0xc42004fcf8github.com/docker/docker-credential-helpers/secretservice.(*Secretservice).List(0x77e548, 0xc42004fe88, 0x410022, 0xc420012320)	<autogenerated>:4 +0x46 fp=0xc42004fde0 sp=0xc42004fda0github.com/docker/docker-credential-helpers/credentials.List(0x756ba0, 0x77e548, 0x7560e0, 0xc42000e018, 0x0, 0x10)	/build/golang-github-docker-docker-credential-helpers-cMhSy1/golang-github-docker-docker-credential-helpers-0.5.0/obj-x86_64-linux-gnu/src/github.com/docker/docker-credential-helpers/credentials/credentials.go:145 +0x3e fp=0xc42004fe68 sp=0xc42004fde0github.com/docker/docker-credential-helpers/credentials.HandleCommand(0x756ba0, 0x77e548, 0x7ffd71137855, 0x4, 0x7560a0, 0xc42000e010, 0x7560e0, 0xc42000e018, 0x40e398, 0x4d35c0)	/build/golang-github-docker-docker-credential-helpers-cMhSy1/golang-github-docker-docker-credential-helpers-0.5.0/obj-x86_64-linux-gnu/src/github.com/docker/docker-credential-helpers/credentials/credentials.go:60 +0x16d fp=0xc42004fed8 sp=0xc42004fe68github.com/docker/docker-credential-helpers/credentials.Serve(0x756ba0, 0x77e548)	/build/golang-github-docker-docker-credential-helpers-cMhSy1/golang-github-docker-docker-credential-helpers-0.5.0/obj-x86_64-linux-gnu/src/github.com/docker/docker-credential-helpers/credentials/credentials.go:41 +0x1cb fp=0xc42004ff58 sp=0xc42004fed8main.main()	/build/golang-github-docker-docker-credential-helpers-cMhSy1/golang-github-docker-docker-credential-helpers-0.5.0/secretservice/cmd/main_linux.go:9 +0x4f fp=0xc42004ff88 sp=0xc42004ff58runtime.main()	/usr/lib/go-1.8/src/runtime/proc.go:185 +0x20a fp=0xc42004ffe0 sp=0xc42004ff88runtime.goexit()	/usr/lib/go-1.8/src/runtime/asm_amd64.s:2197 +0x1 fp=0xc42004ffe8 sp=0xc42004ffe0goroutine 17 [syscall, locked to thread]:runtime.goexit()	/usr/lib/go-1.8/src/runtime/asm_amd64.s:2197 +0x1rax    0x0rbx    0x7ffd711368c0rcx    0x7f3e05499e97rdx    0x0rdi    0x2rsi    0x7ffd71136650rbp    0x7ffd711369c0rsp    0x7ffd71136650r8     0x0r9     0x7ffd71136650r10    0x8r11    0x246r12    0x7ffd711368c0r13    0x1000r14    0x0r15    0x30rip    0x7f3e05499e97rflags 0x246cs     0x33fs     0x0gs     0x0Sending build context to Docker daemon  18.43kBStep 1/8 : FROM node:10-slim ---> c33688dea543```Rest of build proceeds normally.**Describe the results you expected:**Not seeing the error info.**Additional information you deem important (e.g. issue happens only occasionally):**It takes about 20 seconds before the output above appears.  It happens every time, and I've tried with different projects.**Output of `docker version`:**```Docker version 18.06.1-ce, build e68fc7a```same thing happened with an earlier version```Docker version 17.12.1-ce, build 7390fc6```**Output of `docker info`:**```Containers: 2 Running: 1 Paused: 0 Stopped: 1Images: 15Server Version: 18.06.1-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 468a545b9edcd5932818eb9de8e72413e616e86erunc version: 69663f0bd4b60df09991c08812a60108003fa340init version: fec3683Security Options: apparmor seccomp  Profile: defaultKernel Version: 4.15.0-33-genericOperating System: Ubuntu 18.04.1 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.35GiBName: peter-officeID: Y2JB:LSMD:DZPK:E5UG:T6ZW:4SD6:FYVT:ZFDO:KKEV:3ADM:2MHP:KNGXDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**physical
"
37914,1,3356,6,0,0,underscorgan,0,"title:LCOW: mounting a volume when `VOLUME` is specified in the docker file fails. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**When I try to start a container using a named volume mapped to the same path as specified with a  `VOLUME <path>` in the image's dockerfile, the container fails to start with ```Error response from daemon: container <id> encountered an error during CreateContainer: failure in a Windows system call: The object already exists. (0x1392)```This caused a problem when trying to run the postgres container. To get a minimal reproduction I created an image based off the alpine:latest image adding `VOLUME /srv` to the [dockerfile](https://github.com/underscorgan/docker_scratchspace/blob/master/windows_volume_mounting/Dockerfile#L3)**Steps to reproduce the issue:**1. Create a named volume: `docker volume create --name test -d local`2. Try to run the container using that volume: `docker run --rm -v test:/srv underscorgan/alpine:volume-test`**Describe the results you received:**```C:\Users\puppet\test> docker run -it --rm -v test:/srv/ underscorgan/alpine:volume-testC:\Program Files\docker\docker.exe: Error response from daemon: container 5c03d327e4eff8fbc5cf9d79309d3ffac9daf9fb453a26bf2f4c240169081efb encountered an error during CreateContainer: failure in a Windows system call: The object already exists. (0x1392) extra info: {""SystemType"":""container"",""Name"":""5c03d327e4eff8fbc5cf9d79309d3ffac9daf9fb453a26bf2f4c240169081efb"",""Owner"":""docker"",""LayerFolderPath"":""C:\\ProgramData\\docker\\lcow\\5c03d327e4eff8fbc5cf9d79309d3ffac9daf9fb453a26bf2f4c240169081efb"",""Layers"":[{""ID"":""eeff4893-55b5-5576-aa05-9e7592905d63"",""Path"":""C:\\ProgramData\\docker\\lcow\\717873d290e6a45d26cc7b8a735126d9fb7704be6a3cc71a994481ad4c03b4e7\\layer.vhd""}],""MappedDirectories"":[{""HostPath"":""C:\\ProgramData\\docker\\volumes\\test\\_data"",""ContainerPath"":""/tmp/gcs/5c03d327e4eff8fbc5cf9d79309d3ffac9daf9fb453a26bf2f4c240169081efb/binds/srv"",""ReadOnly"":false,""BandwidthMaximum"":0,""IOPSMaximum"":0,""CreateInUtilityVM"":true},{""HostPath"":""C:\\ProgramData\\docker\\volumes\\93c9259e44e22f586dd51e0bf432225196c4dc724dd4766d65d8f0533ed56495\\_data"",""ContainerPath"":""/tmp/gcs/5c03d327e4eff8fbc5cf9d79309d3ffac9daf9fb453a26bf2f4c240169081efb/binds/srv"",""ReadOnly"":false,""BandwidthMaximum"":0,""IOPSMaximum"":0,""CreateInUtilityVM"":true}],""HvPartition"":true,""EndpointList"":[""5f45a7c8-9ee6-4307-881c-821ac22e90d4""],""HvRuntime"":{""ImagePath"":""C:\\Program Files\\Linux Containers"",""LinuxInitrdFile"":""initrd.img"",""LinuxKernelFile"":""kernel""},""AllowUnqualifiedDNSQuery"":true,""ContainerType"":""linux"",""TerminateOnLastHandleClosed"":true}.```**Describe the results you expected:**I expect the container to start successfully.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**``` C:\Users\puppet\test> docker version Client: Version:           master-dockerproject-2018-09-03 API version:       1.39 Go version:        go1.10.4 Git commit:        3ea56aa0 Built:             Mon Sep  3 23:53:23 2018 OS/Arch:           windows/amd64 Experimental:      false Server: Engine: Version:          master-dockerproject-2018-09-03 API version:      1.39 (minimum version 1.24) Go version:       go1.10.4 Git commit:       8af9176 Built:            Tue Sep  4 00:02:00 2018 OS/Arch:          windows/amd64 Experimental:     true```**Output of `docker info`:**```C:\Users\puppet\test> docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 83Server Version: master-dockerproject-2018-09-03Storage Driver: windowsfilter (windows) lcow (linux) Windows: LCOW:Logging Driver: json-filePlugins: Volume: local Network: ics l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd gcplogs gelf json-file local logentries splunk syslogSwarm: inactiveDefault Isolation: hypervKernel Version: 10.0 16299 (16299.637.amd64fre.rs3_release_svc.180808-1748)Operating System: Windows 10 Pro Version 1709 (OS Build 16299.665)OSType: windowsArchitecture: x86_64CPUs: 4Total Memory: 16GiBName: pupperwareID: VQWA:Y5TW:RNVF:GBSU:JKSH:LLAX:IHSR:G465:7OEH:3EJ3:7JJ3:CWRTDocker Root Dir: C:\ProgramData\dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Running on Windows 10 Pro, Version 1709, OS Build 16299.665. On Azure with Hyper-V support, using LCOW.
"
37870,0,1646,291,0,0,felixfontein,0,"title:docker exec -i sometimes hangs if stdin is empty. description:**Description**When running `docker exec -i <container> /bin/bash -c cat` (or something else which is waiting for input from stdin) and pipe an empty file into it, this often hangs.**Steps to reproduce the issue:**1. `docker run -d --name docker-test ubuntu:latest /bin/bash -c ""sleep 1h""`2. Repeatedly run `cat /dev/null | docker exec -i docker-test /bin/bash -c cat`3. Wait until one of the calls hangs**Describe the results you received:**Sometimes, `cat /dev/null | docker exec -i docker-test /bin/bash -c cat` hangs indefinitely.**Describe the results you expected:**`cat /dev/null | docker exec -i docker-test /bin/bash -c cat` always returns immediately.**Additional information you deem important (e.g. issue happens only occasionally):**---**Output of `docker version`:**```Client: Version:           18.06.1-ce API version:       1.38 Go version:        go1.11 Git commit:        e68fc7a215 Built:             Fri Sep  7 11:26:59 2018 OS/Arch:           linux/amd64 Experimental:      falseServer: Engine:  Version:          18.06.1-ce  API version:      1.38 (minimum version 1.12)  Go version:       go1.11  Git commit:       e68fc7a215  Built:            Fri Sep  7 11:26:11 2018  OS/Arch:          linux/amd64  Experimental:     false```(This has also been observed with other versions of docker: https://github.com/ansible/ansible/issues/36725)**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 77Server Version: 18.06.1-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 468a545b9edcd5932818eb9de8e72413e616e86erunc version: 69663f0bd4b60df09991c08812a60108003fa340init version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 4.18.7-arch1-1-ARCHOperating System: Arch LinuxOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.57GiBName: mymachineID: JFYF:V2G4:IYL3:HDXW:FM4Y:R6XI:IFAX:QL6P:7OBG:OJNL:Y4O3:O5A3Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: felixfonteinRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```
"
37842,1,1554,10,0,1,slithernix,0,"title:After deploying ~150+ services to swarm, swarm fails catastrophically. description:**Description**We are doing a swarm pilot and it's been going well, until we deployed about ~150 services (the last time I looked before the crash it was at 151) to it and then the manager crashes, and will not come back up. The only way I can fix it is by removing /var/lib/docker, re installing, and re-creating the swarm. The fatal error during startup is ""panic: assertion failed: write: circular dependency occurred"". the containers continued to run on the worker nodes. I have hit this on [ =17.12.1  =18.03.1  =18.06.1 ] all on amazon linux from the amazon-linux-extras repo. I am running the docker-volume-netshare plugin, which works great, but it's worth noting because it's not stock.**Steps to reproduce the issue:**1. Deploy 150-200 services to swarm2. Fail3.**Describe the results you received:**Manager dies and can't come back up**Describe the results you expected:**Manager doesn't crash**Additional information you deem important (e.g. issue happens only occasionally):**Just the netshare volume plugin**Output of `docker version`:**```Client: Version:           18.06.1-ce API version:       1.38 Go version:        go1.10.3 Git commit:        e68fc7a215d7133c34aa18e3b72b4a21fd0c6136 Built:             Wed Sep  5 18:57:40 2018 OS/Arch:           linux/amd64 Experimental:      false```**Output of `docker info`:**Can't run it on the manager but here it is from one of the workers```Containers: 770 Running: 93 Paused: 0 Stopped: 677Images: 14Server Version: 18.06.1-ceStorage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: efs local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: an1f7b2r5266lguoa19yqgirr Is Manager: false Node Address: 172.31.5.247 Manager Addresses:  172.31.5.170:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 468a545b9edcd5932818eb9de8e72413e616e86erunc version: 69663f0bd4b60df09991c08812a60108003fa340init version: fec3683Security Options: seccomp  Profile: defaultKernel Version: 4.14.62-70.117.amzn2.x86_64Operating System: Amazon Linux 2OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 59.96GiBName: ip-172-31-5-247.online.berklee.eduID: NH5J:7DOA:RMSB:J5HZ:YMKV:7FMV:VVTO:MHOF:6A2V:6UMY:TZHE:L5DSDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```This is in AWS.
"
37747,0,1892,0,1,0,burdakovd,0,"title:awslogs log driver: occasionally attempts to upload batch that is too large. description:**Description**With `aws-logs` log driver, Docker occasionally drops logs due to errors like ""InvalidParameterException: Upload too large: 1188330 bytes exceeds limit of 1048576"".It seems it fails to estimate size of request correctly, and to split request to AWS into smaller requests.**Steps to reproduce the issue:**1. Configure Docker to send logs to awslogs (see config below)2. Run the following command to produce demo logs: `docker run ubuntu bash -c 'for x in 1 2 3 4 5 6 7 8; do cat /dev/urandom | tr -d ""\n"" | head -c 131050; echo; done' | gzip | wc -c`**Describe the results you received:**Observe logs did not get sent to awslogs, but instead in `/var/log/messages` we have `InvalidParameterException: Upload too large: 1188330 bytes exceeds limit of 1048576`**Describe the results you expected:**Logs to get into awslogs without errors.**Additional information you deem important (e.g. issue happens only occasionally):**Furthermore, it appears Docker somehow doubles the payload size. I.e. initially I was planning to do the following as repro: `docker run ubuntu bash -c 'for x in 1 2 3 4; do cat /dev/urandom | tr -d ""\n"" | head -c 262140; echo; done' | gzip | wc -c` - but it failed with ""InvalidParameterException: Log event too large: 476138 bytes exceeds limit of 262144"", indicating that Docker is sending log event that is 2x bigger than the original log line.The repro steps of course are just random data, but I observe this issue happening once or twice a day with logs from ipfs daemon (in debug mode, so it is sending quite significant amount of logs).Apart from seemingly wrong strategy of splitting data to send to AWS, it would also be great if Docker was dumping the failed blobs somewhere. It would help to diagnose this particular issue better, and also would be better from audit perspective, as currently if someone gets in the container that is monitored using awslogs, they can flood it in order to cause logs loss, and therefore hide their activity.Config that I'm using to send data to awslogs:```cat /etc/docker/daemon.json{  ""log-driver"": ""awslogs"",  ""log-opts"": {    ""awslogs-region"": ""us-east-1"",    ""awslogs-group"": ""docker.i-019b04c8046828f2d"",    ""awslogs-create-group"": ""true"",    ""tag"": ""{{.Name}}-{{.ID}}""  }}```This is similar to https://github.com/moby/moby/issues/35725 - but I decided to open a new issue instead of reopening that one as it is quite old.**Output of `docker version`:**```Client: Version:      18.03.1-ce API version:  1.37 Go version:   go1.9.6 Git commit:   3dfb8343b139d6342acfd9975d7f1068b5b1c3d3 Built:        Wed Jul 25 00:48:56 2018 OS/Arch:      linux/amd64 Experimental: false Orchestrator: swarmServer: Engine:  Version:      18.03.1-ce  API version:  1.37 (minimum version 1.12)  Go version:   go1.9.6  Git commit:   7390fc6/18.03.1-ce  Built:        Wed Jul 25 00:51:07 2018  OS/Arch:      linux/amd64  Experimental: false```**Output of `docker info`:**```Containers: 26 Running: 4 Paused: 0 Stopped: 22Images: 68Server Version: 18.03.1-ceStorage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: trueLogging Driver: awslogsCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 773c489c9c1b21a6d78b5c538cd395416ec50f88runc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.14.62-70.117.amzn2.x86_64Operating System: Amazon Linux 2OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.853GiBName: ip-172-31-9-51.ec2.internalID: XCDZ:TO2M:DBAZ:BNT2:KKTY:3IMX:IYHT:ZOLU:FCP6:QZRK:3UVJ:7CHKDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**AWS AMI Linux 2
"
37676,0,50257,139,0,0,tiborvass,1,"title:TestContainerStartOnDaemonRestart fails when dockerd becomes subreaper . description:Buildkit sets subreaper to 1 and https://github.com/moby/moby/pull/37620 vendors that code, effectively setting dockerd as a subreaper, which causes problems. This issue is to track it.Here's how to reproduce:```$ git fetch git@github.com:tiborvass/docker debug-subreaper3$ git checkout FETCH_HEAD$ make shellroot# SUBREAPER=1 TEST_INTEGRATION_DIR=./integration/container TESTFLAGS='-test.run TestContainerStartOnDaemonRestart -test.v' ./hack/make.sh dynbinary test-integration...INFO: Testing against a local daemon=== RUN   TestContainerStartOnDaemonRestart=== PAUSE TestContainerStartOnDaemonRestart=== CONT  TestContainerStartOnDaemonRestart--- FAIL: TestContainerStartOnDaemonRestart (1.83s)	daemon.go:289: [d3212059849e4] waiting for daemon to start	daemon.go:321: [d3212059849e4] daemon started	daemon.go:289: [d3212059849e4] waiting for daemon to start	daemon.go:321: [d3212059849e4] daemon started	daemon_linux_test.go:65: assertion failed: error is not nil: Error response from daemon: mkdir /var/run/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/89573952a64357960bddc8f55722856e30a3f42e1cdf7ac401560535df7b9bc2: file exists: already exists: failed to start test container	daemon.go:279: [d3212059849e4] exiting daemonFAIL...``````root# cat ./bundles/test-integration/d3212059849e4/docker.logtime=""2018-08-20T18:16:25.718888702Z"" level=warning msg=""Error while setting daemon root propagation, this is not generally critical but may cause some functionality to not work or fallback to less desirable behavior"" dir=/go/src/github.com/docker/docker/bundles/test-integration/d3212059849e4/root error=""error writing file to signal mount cleanup on shutdown: open /tmp/docker-execroot/d3212059849e4/unmount-on-shutdown: no such file or directory""time=""2018-08-20T18:16:25.719226115Z"" level=debug msg=""Listener created for HTTP on unix (/tmp/docker-integration/d3212059849e4.sock)""time=""2018-08-20T18:16:25.720763152Z"" level=debug msg=""Golang's threads limit set to 115380""time=""2018-08-20T18:16:25.721626604Z"" level=info msg=""parsed scheme: \""unix\"""" module=grpctime=""2018-08-20T18:16:25.721654792Z"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpctime=""2018-08-20T18:16:25.721771385Z"" level=info msg=""ccResolverWrapper: sending new addresses to cc: [{unix:///var/run/docker/containerd/docker-containerd.sock 0  <nil>}]"" module=grpctime=""2018-08-20T18:16:25.721802980Z"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpctime=""2018-08-20T18:16:25.721863058Z"" level=info msg=""pickfirstBalancer: HandleSubConnStateChange: 0xc42026b800, CONNECTING"" module=grpctime=""2018-08-20T18:16:25.721861937Z"" level=info msg=""parsed scheme: \""unix\"""" module=grpctime=""2018-08-20T18:16:25.721923019Z"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpctime=""2018-08-20T18:16:25.723685974Z"" level=info msg=""ccResolverWrapper: sending new addresses to cc: [{unix:///var/run/docker/containerd/docker-containerd.sock 0  <nil>}]"" module=grpctime=""2018-08-20T18:16:25.723747200Z"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpctime=""2018-08-20T18:16:25.724074163Z"" level=info msg=""pickfirstBalancer: HandleSubConnStateChange: 0xc4201b8ec0, CONNECTING"" module=grpctime=""2018-08-20T18:16:25.724185149Z"" level=debug msg=""Using default logging driver json-file""time=""2018-08-20T18:16:25.724230092Z"" level=debug msg=""[graphdriver] trying provided driver: aufs""time=""2018-08-20T18:16:25.725066441Z"" level=info msg=""pickfirstBalancer: HandleSubConnStateChange: 0xc42026b800, READY"" module=grpctime=""2018-08-20T18:16:25.725618098Z"" level=info msg=""pickfirstBalancer: HandleSubConnStateChange: 0xc4201b8ec0, READY"" module=grpctime=""2018-08-20T18:16:25.726012691Z"" level=debug msg=""processing event stream"" module=libcontainerd namespace=plugins.mobytime=""2018-08-20T18:16:25.726097678Z"" level=debug msg=""Initialized graph driver aufs""time=""2018-08-20T18:16:25.732966945Z"" level=info msg=""Graph migration to content-addressability took 0.00 seconds""time=""2018-08-20T18:16:25.733390176Z"" level=warning msg=""Your kernel does not support swap memory limit""time=""2018-08-20T18:16:25.733561538Z"" level=warning msg=""Your kernel does not support cgroup rt period""time=""2018-08-20T18:16:25.733595360Z"" level=warning msg=""Your kernel does not support cgroup rt runtime""time=""2018-08-20T18:16:25.734247993Z"" level=debug msg=""Max Concurrent Downloads: 3""time=""2018-08-20T18:16:25.734425195Z"" level=debug msg=""Max Concurrent Uploads: 5""time=""2018-08-20T18:16:25.734457805Z"" level=info msg=""Loading containers: start.""time=""2018-08-20T18:16:25.734553154Z"" level=debug msg=""Option Experimental: false""time=""2018-08-20T18:16:25.734568813Z"" level=debug msg=""Option DefaultDriver: bridge""time=""2018-08-20T18:16:25.734578314Z"" level=debug msg=""Option DefaultNetwork: bridge""time=""2018-08-20T18:16:25.734588244Z"" level=debug msg=""Network Control Plane MTU: 1500""time=""2018-08-20T18:16:25.734604874Z"" level=debug msg=""processing event stream"" module=libcontainerd namespace=mobytime=""2018-08-20T18:16:25.762461870Z"" level=warning msg=""Running modprobe nf_nat failed with message: ``, error: exec: \""modprobe\"": executable file not found in $PATH""time=""2018-08-20T18:16:25.762763102Z"" level=warning msg=""Running modprobe xt_conntrack failed with message: ``, error: exec: \""modprobe\"": executable file not found in $PATH""time=""2018-08-20T18:16:25.762912603Z"" level=debug msg=""Fail to initialize firewalld: Failed to connect to D-Bus system bus: dial unix /var/run/dbus/system_bus_socket: connect: no such file or directory, using raw iptables instead""time=""2018-08-20T18:16:25.768205357Z"" level=debug msg=""/sbin/iptables, [--wait -t filter -n -L DOCKER-USER]""time=""2018-08-20T18:16:25.771717136Z"" level=debug msg=""/sbin/iptables, [--wait -t filter -C DOCKER-USER -j RETURN]""time=""2018-08-20T18:16:25.775161169Z"" level=debug msg=""/sbin/iptables, [--wait -t filter -C FORWARD -j DOCKER-USER]""time=""2018-08-20T18:16:25.777587608Z"" level=debug msg=""/sbin/iptables, [--wait -D FORWARD -j DOCKER-USER]""time=""2018-08-20T18:16:25.780034401Z"" level=debug msg=""/sbin/iptables, [--wait -I FORWARD -j DOCKER-USER]""time=""2018-08-20T18:16:25.788217792Z"" level=debug msg=""/sbin/iptables, [--wait -t filter -n -L DOCKER-USER]""time=""2018-08-20T18:16:25.790356984Z"" level=debug msg=""/sbin/iptables, [--wait -t filter -C DOCKER-USER -j RETURN]""time=""2018-08-20T18:16:25.791884215Z"" level=debug msg=""/sbin/iptables, [--wait -t filter -C FORWARD -j DOCKER-USER]""time=""2018-08-20T18:16:25.794134660Z"" level=debug msg=""/sbin/iptables, [--wait -D FORWARD -j DOCKER-USER]""time=""2018-08-20T18:16:25.796827029Z"" level=debug msg=""/sbin/iptables, [--wait -I FORWARD -j DOCKER-USER]""time=""2018-08-20T18:16:25.800075589Z"" level=info msg=""Default bridge (docker0) is assigned with an IP address 172.18.0.0/16. Daemon option --bip can be used to set a preferred IP address""time=""2018-08-20T18:16:25.800165306Z"" level=debug msg=""Allocating IPv4 pools for network bridge (2836ffbe26dad9e6561c82801dce7c4d42067335063075ff77bbf7e3a6db7d25)""time=""2018-08-20T18:16:25.800196407Z"" level=debug msg=""RequestPool(LocalDefault, 172.18.0.0/16, , map[], false)""time=""2018-08-20T18:16:25.800284797Z"" level=debug msg=""RequestAddress(LocalDefault/172.18.0.0/16, 172.18.0.1, map[RequestAddressType:com.docker.network.gateway])""time=""2018-08-20T18:16:25.800353939Z"" level=debug msg=""Request address PoolID:172.18.0.0/16 App: ipam/default/data, ID: LocalDefault/172.18.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65534, Sequence: (0x80000000, 1)->(0x0, 2046)->(0x1, 1)->end Curr:0 Serial:false PrefAddress:172.18.0.1 ""time=""2018-08-20T18:16:25.804956172Z"" level=debug msg=""/sbin/iptables, [--wait -t filter -n -L DOCKER-USER]""time=""2018-08-20T18:16:25.806482725Z"" level=debug msg=""/sbin/iptables, [--wait -t filter -C DOCKER-USER -j RETURN]""time=""2018-08-20T18:16:25.808102790Z"" level=debug msg=""/sbin/iptables, [--wait -t filter -C FORWARD -j DOCKER-USER]""time=""2018-08-20T18:16:25.810832595Z"" level=debug msg=""/sbin/iptables, [--wait -D FORWARD -j DOCKER-USER]""time=""2018-08-20T18:16:25.814517865Z"" level=debug msg=""/sbin/iptables, [--wait -I FORWARD -j DOCKER-USER]""time=""2018-08-20T18:16:25.826014064Z"" level=info msg=""Loading containers: done.""time=""2018-08-20T18:16:25.857361055Z"" level=info msg=""Docker daemon"" commit=e65ae8273f graphdriver(s)=aufs version=devtime=""2018-08-20T18:16:25.857602670Z"" level=info msg=""Daemon has completed initialization""time=""2018-08-20T18:16:25.864775293Z"" level=debug msg=""Registering routers""time=""2018-08-20T18:16:25.864811390Z"" level=debug msg=""Registering GET, /containers/{name:.*}/checkpoints""time=""2018-08-20T18:16:25.864988498Z"" level=debug msg=""Registering POST, /containers/{name:.*}/checkpoints""time=""2018-08-20T18:16:25.865122945Z"" level=debug msg=""Registering DELETE, /containers/{name}/checkpoints/{checkpoint}""time=""2018-08-20T18:16:25.865312355Z"" level=debug msg=""Registering HEAD, /containers/{name:.*}/archive""time=""2018-08-20T18:16:25.865460302Z"" level=debug msg=""Registering GET, /containers/json""time=""2018-08-20T18:16:25.865556225Z"" level=debug msg=""Registering GET, /containers/{name:.*}/export""time=""2018-08-20T18:16:25.865695504Z"" level=debug msg=""Registering GET, /containers/{name:.*}/changes""time=""2018-08-20T18:16:25.865854523Z"" level=debug msg=""Registering GET, /containers/{name:.*}/json""time=""2018-08-20T18:16:25.865970964Z"" level=debug msg=""Registering GET, /containers/{name:.*}/top""time=""2018-08-20T18:16:25.866103309Z"" level=debug msg=""Registering GET, /containers/{name:.*}/logs""time=""2018-08-20T18:16:25.866232837Z"" level=debug msg=""Registering GET, /containers/{name:.*}/stats""time=""2018-08-20T18:16:25.866348971Z"" level=debug msg=""Registering GET, /containers/{name:.*}/attach/ws""time=""2018-08-20T18:16:25.866472073Z"" level=debug msg=""Registering GET, /exec/{id:.*}/json""time=""2018-08-20T18:16:25.866598265Z"" level=debug msg=""Registering GET, /containers/{name:.*}/archive""time=""2018-08-20T18:16:25.866725199Z"" level=debug msg=""Registering POST, /containers/create""time=""2018-08-20T18:16:25.866818416Z"" level=debug msg=""Registering POST, /containers/{name:.*}/kill""time=""2018-08-20T18:16:25.866938188Z"" level=debug msg=""Registering POST, /containers/{name:.*}/pause""time=""2018-08-20T18:16:25.867066802Z"" level=debug msg=""Registering POST, /containers/{name:.*}/unpause""time=""2018-08-20T18:16:25.867194858Z"" level=debug msg=""Registering POST, /containers/{name:.*}/restart""time=""2018-08-20T18:16:25.867319306Z"" level=debug msg=""Registering POST, /containers/{name:.*}/start""time=""2018-08-20T18:16:25.867469746Z"" level=debug msg=""Registering POST, /containers/{name:.*}/stop""time=""2018-08-20T18:16:25.867591311Z"" level=debug msg=""Registering POST, /containers/{name:.*}/wait""time=""2018-08-20T18:16:25.867714829Z"" level=debug msg=""Registering POST, /containers/{name:.*}/resize""time=""2018-08-20T18:16:25.867837558Z"" level=debug msg=""Registering POST, /containers/{name:.*}/attach""time=""2018-08-20T18:16:25.867995134Z"" level=debug msg=""Registering POST, /containers/{name:.*}/copy""time=""2018-08-20T18:16:25.868114782Z"" level=debug msg=""Registering POST, /containers/{name:.*}/exec""time=""2018-08-20T18:16:25.868234640Z"" level=debug msg=""Registering POST, /exec/{name:.*}/start""time=""2018-08-20T18:16:25.868340845Z"" level=debug msg=""Registering POST, /exec/{name:.*}/resize""time=""2018-08-20T18:16:25.868447844Z"" level=debug msg=""Registering POST, /containers/{name:.*}/rename""time=""2018-08-20T18:16:25.868562892Z"" level=debug msg=""Registering POST, /containers/{name:.*}/update""time=""2018-08-20T18:16:25.868684656Z"" level=debug msg=""Registering POST, /containers/prune""time=""2018-08-20T18:16:25.868778300Z"" level=debug msg=""Registering POST, /commit""time=""2018-08-20T18:16:25.868866278Z"" level=debug msg=""Registering PUT, /containers/{name:.*}/archive""time=""2018-08-20T18:16:25.869016311Z"" level=debug msg=""Registering DELETE, /containers/{name:.*}""time=""2018-08-20T18:16:25.869157488Z"" level=debug msg=""Registering GET, /images/json""time=""2018-08-20T18:16:25.869243856Z"" level=debug msg=""Registering GET, /images/search""time=""2018-08-20T18:16:25.869339478Z"" level=debug msg=""Registering GET, /images/get""time=""2018-08-20T18:16:25.869455561Z"" level=debug msg=""Registering GET, /images/{name:.*}/get""time=""2018-08-20T18:16:25.869577458Z"" level=debug msg=""Registering GET, /images/{name:.*}/history""time=""2018-08-20T18:16:25.869695129Z"" level=debug msg=""Registering GET, /images/{name:.*}/json""time=""2018-08-20T18:16:25.869825618Z"" level=debug msg=""Registering POST, /images/load""time=""2018-08-20T18:16:25.869910010Z"" level=debug msg=""Registering POST, /images/create""time=""2018-08-20T18:16:25.869989877Z"" level=debug msg=""Registering POST, /images/{name:.*}/push""time=""2018-08-20T18:16:25.870107105Z"" level=debug msg=""Registering POST, /images/{name:.*}/tag""time=""2018-08-20T18:16:25.870206983Z"" level=debug msg=""Registering POST, /images/prune""time=""2018-08-20T18:16:25.870288550Z"" level=debug msg=""Registering DELETE, /images/{name:.*}""time=""2018-08-20T18:16:25.870397985Z"" level=debug msg=""Registering OPTIONS, /{anyroute:.*}""time=""2018-08-20T18:16:25.870471745Z"" level=debug msg=""Registering GET, /_ping""time=""2018-08-20T18:16:25.870521576Z"" level=debug msg=""Registering GET, /events""time=""2018-08-20T18:16:25.870568688Z"" level=debug msg=""Registering GET, /info""time=""2018-08-20T18:16:25.870615260Z"" level=debug msg=""Registering GET, /version""time=""2018-08-20T18:16:25.870658015Z"" level=debug msg=""Registering GET, /system/df""time=""2018-08-20T18:16:25.870740686Z"" level=debug msg=""Registering POST, /auth""time=""2018-08-20T18:16:25.870794233Z"" level=debug msg=""Registering GET, /volumes""time=""2018-08-20T18:16:25.870851255Z"" level=debug msg=""Registering GET, /volumes/{name:.*}""time=""2018-08-20T18:16:25.870932372Z"" level=debug msg=""Registering POST, /volumes/create""time=""2018-08-20T18:16:25.870995579Z"" level=debug msg=""Registering POST, /volumes/prune""time=""2018-08-20T18:16:25.871047911Z"" level=debug msg=""Registering DELETE, /volumes/{name:.*}""time=""2018-08-20T18:16:25.871123453Z"" level=debug msg=""Registering POST, /build""time=""2018-08-20T18:16:25.871165564Z"" level=debug msg=""Registering POST, /build/prune""time=""2018-08-20T18:16:25.871214245Z"" level=debug msg=""Registering POST, /build/cancel""time=""2018-08-20T18:16:25.871267310Z"" level=debug msg=""Registering POST, /session""time=""2018-08-20T18:16:25.871316360Z"" level=debug msg=""Registering POST, /swarm/init""time=""2018-08-20T18:16:25.871367369Z"" level=debug msg=""Registering POST, /swarm/join""time=""2018-08-20T18:16:25.871413186Z"" level=debug msg=""Registering POST, /swarm/leave""time=""2018-08-20T18:16:25.871463200Z"" level=debug msg=""Registering GET, /swarm""time=""2018-08-20T18:16:25.871507390Z"" level=debug msg=""Registering GET, /swarm/unlockkey""time=""2018-08-20T18:16:25.871555565Z"" level=debug msg=""Registering POST, /swarm/update""time=""2018-08-20T18:16:25.871602777Z"" level=debug msg=""Registering POST, /swarm/unlock""time=""2018-08-20T18:16:25.871655752Z"" level=debug msg=""Registering GET, /services""time=""2018-08-20T18:16:25.871706811Z"" level=debug msg=""Registering GET, /services/{id}""time=""2018-08-20T18:16:25.871770380Z"" level=debug msg=""Registering POST, /services/create""time=""2018-08-20T18:16:25.871821621Z"" level=debug msg=""Registering POST, /services/{id}/update""time=""2018-08-20T18:16:25.872104089Z"" level=debug msg=""Registering DELETE, /services/{id}""time=""2018-08-20T18:16:25.872310734Z"" level=debug msg=""Registering GET, /services/{id}/logs""time=""2018-08-20T18:16:25.872655343Z"" level=debug msg=""Registering GET, /nodes""time=""2018-08-20T18:16:25.872966973Z"" level=debug msg=""Registering GET, /nodes/{id}""time=""2018-08-20T18:16:25.873467763Z"" level=debug msg=""Registering DELETE, /nodes/{id}""time=""2018-08-20T18:16:25.873635302Z"" level=debug msg=""Registering POST, /nodes/{id}/update""time=""2018-08-20T18:16:25.873849107Z"" level=debug msg=""Registering GET, /tasks""time=""2018-08-20T18:16:25.874014139Z"" level=debug msg=""Registering GET, /tasks/{id}""time=""2018-08-20T18:16:25.874174092Z"" level=debug msg=""Registering GET, /tasks/{id}/logs""time=""2018-08-20T18:16:25.874527577Z"" level=debug msg=""Registering GET, /secrets""time=""2018-08-20T18:16:25.874680591Z"" level=debug msg=""Registering POST, /secrets/create""time=""2018-08-20T18:16:25.874877394Z"" level=debug msg=""Registering DELETE, /secrets/{id}""time=""2018-08-20T18:16:25.875110248Z"" level=debug msg=""Registering GET, /secrets/{id}""time=""2018-08-20T18:16:25.875273577Z"" level=debug msg=""Registering POST, /secrets/{id}/update""time=""2018-08-20T18:16:25.875519752Z"" level=debug msg=""Registering GET, /configs""time=""2018-08-20T18:16:25.875786917Z"" level=debug msg=""Registering POST, /configs/create""time=""2018-08-20T18:16:25.875988799Z"" level=debug msg=""Registering DELETE, /configs/{id}""time=""2018-08-20T18:16:25.876139046Z"" level=debug msg=""Registering GET, /configs/{id}""time=""2018-08-20T18:16:25.876346472Z"" level=debug msg=""Registering POST, /configs/{id}/update""time=""2018-08-20T18:16:25.876582439Z"" level=debug msg=""Registering GET, /plugins""time=""2018-08-20T18:16:25.876761418Z"" level=debug msg=""Registering GET, /plugins/{name:.*}/json""time=""2018-08-20T18:16:25.876959252Z"" level=debug msg=""Registering GET, /plugins/privileges""time=""2018-08-20T18:16:25.877215129Z"" level=debug msg=""Registering DELETE, /plugins/{name:.*}""time=""2018-08-20T18:16:25.877817509Z"" level=debug msg=""Registering POST, /plugins/{name:.*}/enable""time=""2018-08-20T18:16:25.877944694Z"" level=debug msg=""Registering POST, /plugins/{name:.*}/disable""time=""2018-08-20T18:16:25.878346564Z"" level=debug msg=""Registering POST, /plugins/pull""time=""2018-08-20T18:16:25.878450407Z"" level=debug msg=""Registering POST, /plugins/{name:.*}/push""time=""2018-08-20T18:16:25.878578843Z"" level=debug msg=""Registering POST, /plugins/{name:.*}/upgrade""time=""2018-08-20T18:16:25.878717232Z"" level=debug msg=""Registering POST, /plugins/{name:.*}/set""time=""2018-08-20T18:16:25.878847581Z"" level=debug msg=""Registering POST, /plugins/create""time=""2018-08-20T18:16:25.878938752Z"" level=debug msg=""Registering GET, /distribution/{name:.*}/json""time=""2018-08-20T18:16:25.879094789Z"" level=debug msg=""Registering GET, /networks""time=""2018-08-20T18:16:25.879192719Z"" level=debug msg=""Registering GET, /networks/""time=""2018-08-20T18:16:25.879281722Z"" level=debug msg=""Registering GET, /networks/{id:.+}""time=""2018-08-20T18:16:25.879430346Z"" level=debug msg=""Registering POST, /networks/create""time=""2018-08-20T18:16:25.879540913Z"" level=debug msg=""Registering POST, /networks/{id:.*}/connect""time=""2018-08-20T18:16:25.879675774Z"" level=debug msg=""Registering POST, /networks/{id:.*}/disconnect""time=""2018-08-20T18:16:25.879841269Z"" level=debug msg=""Registering POST, /networks/prune""time=""2018-08-20T18:16:25.879974488Z"" level=debug msg=""Registering DELETE, /networks/{id:.*}""time=""2018-08-20T18:16:25.880606103Z"" level=info msg=""API listen on /tmp/docker-integration/d3212059849e4.sock""time=""2018-08-20T18:16:26.192484587Z"" level=debug msg=""Calling GET /_ping""time=""2018-08-20T18:16:26.193260053Z"" level=debug msg=""Calling GET /info""time=""2018-08-20T18:16:26.244273797Z"" level=debug msg=""Calling POST /v1.39/images/load?quiet=1""time=""2018-08-20T18:16:26.432295045Z"" level=debug msg=""Applied tar sha256:0271b8eebde3fa9a6126b1f2335e170f902731ab4942f9f1914e77016540c7bb to dd8942717ce89a57f397d65d5c6d29c01b6761371c2fe2f3cf17446e6152f2ee, size: 1129289""time=""2018-08-20T18:16:26.441655128Z"" level=debug msg=""Calling POST /v1.39/containers/create""time=""2018-08-20T18:16:26.442219165Z"" level=debug msg=""form data: {\""AttachStderr\"":false,\""AttachStdin\"":false,\""AttachStdout\"":false,\""Cmd\"":[\""top\""],\""Domainname\"":\""\"",\""Entrypoint\"":null,\""Env\"":null,\""HostConfig\"":{\""AutoRemove\"":false,\""Binds\"":null,\""BlkioDeviceReadBps\"":null,\""BlkioDeviceReadIOps\"":null,\""BlkioDeviceWriteBps\"":null,\""BlkioDeviceWriteIOps\"":null,\""BlkioWeight\"":0,\""BlkioWeightDevice\"":null,\""CapAdd\"":null,\""CapDrop\"":null,\""Cgroup\"":\""\"",\""CgroupParent\"":\""\"",\""ConsoleSize\"":[0,0],\""ContainerIDFile\"":\""\"",\""CpuCount\"":0,\""CpuPercent\"":0,\""CpuPeriod\"":0,\""CpuQuota\"":0,\""CpuRealtimePeriod\"":0,\""CpuRealtimeRuntime\"":0,\""CpuShares\"":0,\""CpusetCpus\"":\""\"",\""CpusetMems\"":\""\"",\""DeviceCgroupRules\"":null,\""Devices\"":null,\""DiskQuota\"":0,\""Dns\"":null,\""DnsOptions\"":null,\""DnsSearch\"":null,\""ExtraHosts\"":null,\""GroupAdd\"":null,\""IOMaximumBandwidth\"":0,\""IOMaximumIOps\"":0,\""IpcMode\"":\""\"",\""Isolation\"":\""\"",\""KernelMemory\"":0,\""Links\"":null,\""LogConfig\"":{\""Config\"":null,\""Type\"":\""\""},\""MaskedPaths\"":null,\""Memory\"":0,\""MemoryReservation\"":0,\""MemorySwap\"":0,\""MemorySwappiness\"":null,\""NanoCpus\"":0,\""NetworkMode\"":\""\"",\""OomKillDisable\"":null,\""OomScoreAdj\"":0,\""PidMode\"":\""\"",\""PidsLimit\"":0,\""PortBindings\"":null,\""Privileged\"":false,\""PublishAllPorts\"":false,\""ReadonlyPaths\"":null,\""ReadonlyRootfs\"":false,\""RestartPolicy\"":{\""MaximumRetryCount\"":0,\""Name\"":\""\""},\""SecurityOpt\"":null,\""ShmSize\"":0,\""UTSMode\"":\""\"",\""Ulimits\"":null,\""UsernsMode\"":\""\"",\""VolumeDriver\"":\""\"",\""VolumesFrom\"":null},\""Hostname\"":\""\"",\""Image\"":\""busybox\"",\""Labels\"":null,\""NetworkingConfig\"":{\""EndpointsConfig\"":null},\""OnBuild\"":null,\""OpenStdin\"":false,\""StdinOnce\"":false,\""Tty\"":false,\""User\"":\""\"",\""Volumes\"":null,\""WorkingDir\"":\""\""}""time=""2018-08-20T18:16:26.479990679Z"" level=debug msg=""container mounted via layerStore: &{/go/src/github.com/docker/docker/bundles/test-integration/d3212059849e4/root/aufs/mnt/96dfcaa9e71b57c7f43a916cd01282152a243642ee985ce8c1d7c47307a017d7 0x324cd40 0x324cd40}""time=""2018-08-20T18:16:26.500098900Z"" level=debug msg=""Calling POST /v1.39/containers/89573952a64357960bddc8f55722856e30a3f42e1cdf7ac401560535df7b9bc2/start""time=""2018-08-20T18:16:26.501560995Z"" level=debug msg=""container mounted via layerStore: &{/go/src/github.com/docker/docker/bundles/test-integration/d3212059849e4/root/aufs/mnt/96dfcaa9e71b57c7f43a916cd01282152a243642ee985ce8c1d7c47307a017d7 0x324cd40 0x324cd40}""time=""2018-08-20T18:16:26.502120047Z"" level=debug msg=""Assigning addresses for endpoint pedantic_knuth's interface on network bridge""time=""2018-08-20T18:16:26.502145578Z"" level=debug msg=""RequestAddress(LocalDefault/172.18.0.0/16, <nil>, map[])""time=""2018-08-20T18:16:26.502196490Z"" level=debug msg=""Request address PoolID:172.18.0.0/16 App: ipam/default/data, ID: LocalDefault/172.18.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65533, Sequence: (0xc0000000, 1)->(0x0, 2046)->(0x1, 1)->end Curr:0 Serial:false PrefAddress:<nil> ""time=""2018-08-20T18:16:26.506036366Z"" level=debug msg=""Assigning addresses for endpoint pedantic_knuth's interface on network bridge""time=""2018-08-20T18:16:26.511047893Z"" level=debug msg=""Programming external connectivity on endpoint pedantic_knuth (f973c59460352360198e93fe5c43f98bce86c09f86925927980eed33bcc03794)""time=""2018-08-20T18:16:26.511778072Z"" level=debug msg=""EnableService 89573952a64357960bddc8f55722856e30a3f42e1cdf7ac401560535df7b9bc2 START""time=""2018-08-20T18:16:26.511799485Z"" level=debug msg=""EnableService 89573952a64357960bddc8f55722856e30a3f42e1cdf7ac401560535df7b9bc2 DONE""time=""2018-08-20T18:16:26.514678287Z"" level=debug msg=""bundle dir created"" bundle=/tmp/docker-execroot/d3212059849e4/containerd/89573952a64357960bddc8f55722856e30a3f42e1cdf7ac401560535df7b9bc2 module=libcontainerd namespace=moby root=/go/src/github.com/docker/docker/bundles/test-integration/d3212059849e4/root/aufs/mnt/96dfcaa9e71b57c7f43a916cd01282152a243642ee985ce8c1d7c47307a017d7time=""2018-08-20T18:16:26.717331473Z"" level=debug msg=""sandbox set key processing took 82.634737ms for container 89573952a64357960bddc8f55722856e30a3f42e1cdf7ac401560535df7b9bc2""time=""2018-08-20T18:16:26.825271060Z"" level=debug msg=event module=libcontainerd namespace=moby topic=/tasks/createtime=""2018-08-20T18:16:26.845180535Z"" level=debug msg=event module=libcontainerd namespace=moby topic=/tasks/starttime=""2018-08-20T18:16:26.858966410Z"" level=debug msg=""Calling GET /v1.39/containers/89573952a64357960bddc8f55722856e30a3f42e1cdf7ac401560535df7b9bc2/json""time=""2018-08-20T18:16:26.889937131Z"" level=debug msg=""Listener created for HTTP on unix (/tmp/docker-integration/d3212059849e4.sock)""time=""2018-08-20T18:16:26.892479453Z"" level=debug msg=""Golang's threads limit set to 115380""time=""2018-08-20T18:16:26.894049069Z"" level=info msg=""parsed scheme: \""unix\"""" module=grpctime=""2018-08-20T18:16:26.894070102Z"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpctime=""2018-08-20T18:16:26.894146046Z"" level=info msg=""parsed scheme: \""unix\"""" module=grpctime=""2018-08-20T18:16:26.894161467Z"" level=info msg=""scheme \""unix\"" not registered, fallback to default scheme"" module=grpctime=""2018-08-20T18:16:26.894303898Z"" level=info msg=""ccResolverWrapper: sending new addresses to cc: [{unix:///var/run/docker/containerd/docker-containerd.sock 0  <nil>}]"" module=grpctime=""2018-08-20T18:16:26.894359729Z"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpctime=""2018-08-20T18:16:26.894464535Z"" level=info msg=""pickfirstBalancer: HandleSubConnStateChange: 0xc420418a90, CONNECTING"" module=grpctime=""2018-08-20T18:16:26.894469017Z"" level=info msg=""blockingPicker: the picked transport is not ready, loop back to repick"" module=grpctime=""2018-08-20T18:16:26.894362759Z"" level=debug msg=""Using default logging driver json-file""time=""2018-08-20T18:16:26.894561555Z"" level=debug msg=""[graphdriver] trying provided driver: aufs""time=""2018-08-20T18:16:26.894776831Z"" level=info msg=""pickfirstBalancer: HandleSubConnStateChange: 0xc420418a90, READY"" module=grpctime=""2018-08-20T18:16:26.894838968Z"" level=debug msg=""processing event stream"" module=libcontainerd namespace=plugins.mobytime=""2018-08-20T18:16:26.895977060Z"" level=debug msg=""Initialized graph driver aufs""time=""2018-08-20T18:16:26.896859393Z"" level=info msg=""ccResolverWrapper: sending new addresses to cc: [{unix:///var/run/docker/containerd/docker-containerd.sock 0  <nil>}]"" module=grpctime=""2018-08-20T18:16:26.897475981Z"" level=info msg=""ClientConn switching balancer to \""pick_first\"""" module=grpctime=""2018-08-20T18:16:26.897893889Z"" level=info msg=""pickfirstBalancer: HandleSubConnStateChange: 0xc4201963f0, CONNECTING"" module=grpctime=""2018-08-20T18:16:26.899157419Z"" level=info msg=""Graph migration to content-addressability took 0.00 seconds""time=""2018-08-20T18:16:26.899117668Z"" level=info msg=""pickfirstBalancer: HandleSubConnStateChange: 0xc4201963f0, READY"" module=grpctime=""2018-08-20T18:16:26.899508166Z"" level=warning msg=""Your kernel does not support swap memory limit""time=""2018-08-20T18:16:26.899588283Z"" level=warning msg=""Your kernel does not support cgroup rt period""time=""2018-08-20T18:16:26.899613605Z"" level=warning msg=""Your kernel does not support cgroup rt runtime""time=""2018-08-20T18:16:26.900257742Z"" level=debug msg=""Max Concurrent Downloads: 3""time=""2018-08-20T18:16:26.900283613Z"" level=debug msg=""Max Concurrent Uploads: 5""time=""2018-08-20T18:16:26.900318584Z"" level=info msg=""Loading containers: start.""time=""2018-08-20T18:16:26.900740415Z"" level=debug msg=""processing event stream"" module=libcontainerd namespace=mobytime=""2018-08-20T18:16:26.901602399Z"" level=debug msg=""Loaded container 89573952a64357960bddc8f55722856e30a3f42e1cdf7ac401560535df7b9bc2, isRunning: true""time=""2018-08-20T18:16:26.907872874Z"" level=debug msg=""restoring container"" container=89573952a64357960bddc8f55722856e30a3f42e1cdf7ac401560535df7b9bc2 paused=false running=truetime=""2018-08-20T18:16:26.909655423Z"" level=debug msg=""restored container"" alive=false container=89573952a64357960bddc8f55722856e30a3f42e1cdf7ac401560535df7b9bc2 module=libcontainerd namespace=moby pid=0time=""2018-08-20T18:16:26.973449048Z"" level=debug msg=""container mounted via layerStore: &{/go/src/github.com/docker/docker/bundles/test-integration/d3212059849e4/root/aufs/mnt/96dfcaa9e71b57c7f43a916cd01282152a243642ee985ce8c1d7c47307a017d7 0x324cd40 0x324cd40}""time=""2018-08-20T18:16:26.988837103Z"" level=debug msg=""Option Experimental: false""time=""2018-08-20T18:16:26.988892099Z"" level=debug msg=""Option DefaultDriver: bridge""time=""2018-08-20T18:16:26.988910663Z"" level=debug msg=""Option DefaultNetwork: bridge""time=""2018-08-20T18:16:26.988926977Z"" level=debug msg=""Network Control Plane MTU: 1500""time=""2018-08-20T18:16:26.990216911Z"" level=debug msg=""Network (2836ffb) restored""time=""2018-08-20T18:16:26.990602428Z"" level=debug msg=""Endpoint (f973c59) restored to network (2836ffb)""time=""2018-08-20T18:16:27.016523528Z"" level=debug msg=""Allocating IPv4 pools for network bridge (2836ffbe26dad9e6561c82801dce7c4d42067335063075ff77bbf7e3a6db7d25)""time=""2018-08-20T18:16:27.016577384Z"" level=debug msg=""RequestPool(LocalDefault, 172.18.0.0/16, , map[], false)""time=""2018-08-20T18:16:27.016635030Z"" level=debug msg=""RequestAddress(LocalDefault/172.18.0.0/16, 172.18.0.1, map[RequestAddressType:com.docker.network.gateway])""time=""2018-08-20T18:16:27.016722790Z"" level=debug msg=""Request address PoolID:172.18.0.0/16 App: ipam/default/data, ID: LocalDefault/172.18.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65534, Sequence: (0x80000000, 1)->(0x0, 2046)->(0x1, 1)->end Curr:0 Serial:false PrefAddress:172.18.0.1 ""time=""2018-08-20T18:16:27.017148119Z"" level=debug msg=""Assigning addresses for endpoint pedantic_knuth's interface on network bridge""time=""2018-08-20T18:16:27.017179889Z"" level=debug msg=""RequestAddress(LocalDefault/172.18.0.0/16, 172.18.0.2, map[])""time=""2018-08-20T18:16:27.017211382Z"" level=debug msg=""Request address PoolID:172.18.0.0/16 App: ipam/default/data, ID: LocalDefault/172.18.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65533, Sequence: (0xc0000000, 1)->(0x0, 2046)->(0x1, 1)->end Curr:0 Serial:false PrefAddress:172.18.0.2 ""time=""2018-08-20T18:16:27.304443358Z"" level=info msg=""Removing stale sandbox 2450291bac53de42734983c99c05e7bf21d6b09483660f899a2f70577f39fb8b (89573952a64357960bddc8f55722856e30a3f42e1cdf7ac401560535df7b9bc2)""time=""2018-08-20T18:16:27.304552676Z"" level=debug msg=""Revoking external connectivity on endpoint pedantic_knuth (f973c59460352360198e93fe5c43f98bce86c09f86925927980eed33bcc03794)""time=""2018-08-20T18:16:27.306398885Z"" level=debug msg=""DeleteConntrackEntries purged ipv4:0, ipv6:0""time=""2018-08-20T18:16:27.308898736Z"" level=warning msg=""Error (Unable to complete atomic operation, key modified) deleting object [endpoint 2836ffbe26dad9e6561c82801dce7c4d42067335063075ff77bbf7e3a6db7d25 f973c59460352360198e93fe5c43f98bce86c09f86925927980eed33bcc03794], retrying....""time=""2018-08-20T18:16:27.310406872Z"" level=debug msg=""Releasing addresses for endpoint pedantic_knuth's interface on network bridge""time=""2018-08-20T18:16:27.310458673Z"" level=debug msg=""ReleaseAddress(LocalDefault/172.18.0.0/16, 172.18.0.2)""time=""2018-08-20T18:16:27.310510563Z"" level=debug msg=""Released address PoolID:LocalDefault/172.18.0.0/16, Address:172.18.0.2 Sequence:App: ipam/default/data, ID: LocalDefault/172.18.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65532, Sequence: (0xe0000000, 1)->(0x0, 2046)->(0x1, 1)->end Curr:0""time=""2018-08-20T18:16:27.325575221Z"" level=debug msg=""releasing IPv4 pools from network bridge (2836ffbe26dad9e6561c82801dce7c4d42067335063075ff77bbf7e3a6db7d25)""time=""2018-08-20T18:16:27.325628573Z"" level=debug msg=""ReleaseAddress(LocalDefault/172.18.0.0/16, 172.18.0.1)""time=""2018-08-20T18:16:27.325678600Z"" level=debug msg=""Released address PoolID:LocalDefault/172.18.0.0/16, Address:172.18.0.1 Sequence:App: ipam/default/data, ID: LocalDefault/172.18.0.0/16, DBIndex: 0x0, Bits: 65536, Unselected: 65533, Sequence: (0xc0000000, 1)->(0x0, 2046)->(0x1, 1)->end Curr:0""time=""2018-08-20T18:16:27.325713125Z"" level=debug msg=""ReleasePool(LocalDefault/172.18.0.0/16)""time=""2018-08-20T18:16:27.326592406Z"" level=debug msg=""cleanupServiceDiscovery for network:2836ffbe26dad9e6561c82801dce7c4d42067335063075ff77bbf7e3a6db7d25""time=""2018-08-20T18:16:27.328300373Z"" level=info msg=""Default bridge (docker0) is assigned with an IP address 172.18.0.0/16. Daemon option --bip can be used to set a preferred IP address""time=""2018-08-20T18:16:27.328360937Z"" level=debug msg=""Allocating IPv4 pools for network bridge (89d549b29258edac5be3cba9c0d226e7ef09dbfa86bc0643411f2528fd76ec67)""time=""2018-08-20T18:16:27.328391553Z"" level=debug msg=""RequestPool(LocalDefault, 172.18.0.0/16, , map[], false)""time=""2018-08-20T18:16:27.328508708Z"" level=debug msg=""RequestAddress(LocalDefault/172.18.0.0/16, 172.18.0.1, map[RequestAddressType:com.docker.network.gateway])""time=""2018-08-20T18:16:27.328556076Z"" level=debug msg=""Request address PoolID:172.18.0.0/16 App: ipam/default/data, ID: LocalDefault/172.18.0.0/16, "
37325,0,1608,0,0,0,abhi,0,"title:No error if  build args are missing during docker build . description:**Description**It appears that if the build args is not passed to docker build and the Dockerfile consumes this argument, docker build doesnt report an error even thought the build args are missing.This has been seen on docker 17.09-ce till 18.05-ce. On 17.06-ee, this would report the following error. ```Step 5/8 : FROM ${ALPINE}invalid reference format```**Steps to reproduce the issue:****Describe the results you received:**Dockerfile:```ARG SOMETHINGARG ALPINEFROM ${SOMETHING} as builder# No actual build steps, just copyingFROM ${ALPINE}EXPOSE 8080``````$ docker build --build-arg SOMETHING=redis -f Dockerfile .Sending build context to Docker daemon  2.048kBStep 1/5 : ARG SOMETHINGStep 2/5 : ARG ALPINEStep 3/5 : FROM ${SOMETHING} as builderlatest: Pulling from library/redisf2aa67a397c4: Pull complete298c0b953ff5: Pull complete54481933a13d: Pull completee236faec6ff6: Pull complete93540029cb59: Pull complete1c88aa70d0e2: Pull completeDigest: sha256:c389a35832492c42f4719776471f9a42d2fc5a8ba0077ba25746626b09eab880Status: Downloaded newer image for redis:latest ---> 55cb7014c24fStep 4/5 : FROM ${ALPINE} --->Step 5/5 : EXPOSE 8080 ---> Running in 428dd57f037dRemoving intermediate container 428dd57f037d ---> e0f93b8c2347Successfully built e0f93b8c2347```**Describe the results you expected:**```$ docker build --build-arg SOMETHING=redis -f Dockerfile .Sending build context to Docker daemon  2.048kBStep 1/5 : ARG SOMETHINGStep 2/5 : ARG ALPINEStep 3/5 : FROM ${SOMETHING} as builderlatest: Pulling from library/redisf2aa67a397c4: Pull complete298c0b953ff5: Pull complete54481933a13d: Pull completee236faec6ff6: Pull complete93540029cb59: Pull complete1c88aa70d0e2: Pull completeDigest: sha256:c389a35832492c42f4719776471f9a42d2fc5a8ba0077ba25746626b09eab880Status: Downloaded newer image for redis:latest ---> 55cb7014c24fStep 4/5 : FROM ${ALPINE} invalid reference format```**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```(paste your output here)```**Output of `docker info`:**```(paste your output here)```**Additional environment details (AWS, VirtualBox, physical, etc.):**ping @tonistiigi 
"
37283,1,2295,136,0,0,cmeeren,0,"title:Incorrect time in containers. description:**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->I experience incorrect time in containers based on various images. Put shortly, it seems that for many images, the container time always start at the same time regardless of host time.Here are CMD commands/output that demonstrate the problem and can be used for reproduction:```C:\Users\Christer>timeThe current time is:  9.32.03,72Enter the new time: <Ctrl-C>C:\Users\Christer>docker run -it microsoft/nanoserver:1803 cmdMicrosoft Windows [Version 10.0.17134.48](c) 2018 Microsoft Corporation. All rights reserved.C:\>timeThe current time is: 18:23:46.36Enter the new time: <Ctrl-C>C:\>exitC:\Users\Christer>timeThe current time is:  9.32.30,37Enter the new time: <Ctrl-C>C:\Users\Christer>docker run -it microsoft/nanoserver:1803 cmdMicrosoft Windows [Version 10.0.17134.48](c) 2018 Microsoft Corporation. All rights reserved.C:\>timeThe current time is: 18:23:46.12Enter the new time:```As you can see, the container's time always seem to start at the same time regardless of host time. This means it does not not seem related to timezones.I experience this consistently e.g. with `microsoft/nanoserver:1803` as well as `microsoft/nanoserver:1709`, but `microsoft/nanoserver:sac2016` works fine.However, when I posted the steps in [this MSDN thread](https://social.msdn.microsoft.com/Forums/en-US/6b13bf8e-d3fb-450a-b0f3-db1aed4fb041/some-windows-server-core-docker-images-report-incorrect-times?referrer=http://social.msdn.microsoft.com/Forums/en-US/6b13bf8e-d3fb-450a-b0f3-db1aed4fb041/some-windows-server-core-docker-images-report-incorrect-times?forum=windowscontainers), another poster was unable to reproduce it. This makes me think it's not related to the images themselves. And since the closing comment of the seemingly similar issue https://github.com/docker/for-win/issues/1288 made it clear that moby was the right place for such a bug report, here I am, quite lost and unable to figure out how to proceed.As mentioned in the MSDN thread I linked to, I tried running the images with process isolation, but it seems that's not possible:```C:\Users\Christer>docker run --isolation process -it microsoft/nanoserver:1803 cmddocker: Error response from daemon: Windows client operating systems only supportHyper-V containers.See 'docker run --help'.```I'll happily provide more info and do more testing, just tell me what's necessary.**Output of `docker version`:**```Client: Version:      18.03.1-ce API version:  1.37 Go version:   go1.9.5 Git commit:   9ee9f40 Built:        Thu Apr 26 07:12:48 2018 OS/Arch:      windows/amd64 Experimental: false Orchestrator: swarmServer: Engine:  Version:      18.03.1-ce  API version:  1.37 (minimum version 1.24)  Go version:   go1.9.5  Git commit:   9ee9f40  Built:        Thu Apr 26 07:21:42 2018  OS/Arch:      windows/amd64  Experimental: false```**Output of `docker info`:**```Containers: 54 Running: 0 Paused: 0 Stopped: 54Images: 28Server Version: 18.03.1-ceStorage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: ics l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd gelf json-file logentries splunk syslogSwarm: inactiveDefault Isolation: hypervKernel Version: 10.0 17134 (17134.1.amd64fre.rs4_release.180410-1804)Operating System: Windows 10 ProOSType: windowsArchitecture: x86_64CPUs: 4Total Memory: 15.89GiBName: NaviID: VUXH:PMCX:6USB:3B7W:QTEP:WQT3:BV42:6VJN:XOYG:RQRO:QW4K:SZERDocker Root Dir: C:\ProgramData\DockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: -1 Goroutines: 23 System Time: 2018-06-14T15:14:57.4023897+02:00 EventsListeners: 0Registry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```
"
37246,0,3246,200,0,0,thaJeztah,0,"title:Flaky test: TestRunContainerWithBridgeNone. description:For example, https://jenkins.dockerproject.org/job/Docker-PRs-experimental/40976/console (https://github.com/moby/moby/pull/37172)Looks like there's a race in this test, because it compares network interfaces on the host with network interfaces inside the container; if interfaces are removed between checking both (e.g. due to other containers being spun up), comparisson wil fail, and thust the test```04:05:55 FAIL: docker_cli_daemon_test.go:1490: DockerDaemonSuite.TestRunContainerWithBridgeNone04:05:55 04:05:55 [dea931f9f6e6a] waiting for daemon to start04:05:55 [dea931f9f6e6a] daemon started04:05:55 04:05:55 docker_cli_daemon_test.go:1514:04:05:55     c.Assert(out, check.Equals, fmt.Sprintf(""%s"", stdout),04:05:55         check.Commentf(""The network interfaces in container should be the same with host when --net=host when bridge network is disabled: %s"", out))04:05:55 ... obtained string = """" +04:05:55 ...     ""1: lo\n"" +04:05:55 ...     ""7: docker_gwbridge\n"" +04:05:55 ...     ""3904: br-9cec5b58de72\n"" +04:05:55 ...     ""100: br-32891016ebfa\n"" +04:05:55 ...     ""101: br-20cf078fc3bf\n"" +04:05:55 ...     ""103: br-0c74ccf3066a\n"" +04:05:55 ...     ""106: br-b41655ed3763\n"" +04:05:55 ...     ""107: br-8e2071e5cfa1\n"" +04:05:55 ...     ""109: br-fc16417d16c9\n"" +04:05:55 ...     ""130: dm-a418cd2b76fb\n"" +04:05:55 ...     ""133: dm-69b475baeb0d\n"" +04:05:55 ...     ""136: dm-a740bf78a2dc\n"" +04:05:55 ...     ""144: eth0@di-ca915dccc0d0\n"" +04:05:55 ...     ""145: di-ca915dccc0d0\n"" +04:05:55 ...     ""148: di-1a2bd995b101\n"" +04:05:55 ...     ""151: di-d5caa148a467\n"" +04:05:55 ...     ""154: di-5ab9f2f5e708\n"" +04:05:55 ...     ""157: di-bbbd5834f313\n"" +04:05:55 ...     ""162: di-85471b0e62aa\n"" +04:05:55 ...     ""167: di-4713fc55f525\n"" +04:05:55 ...     ""169: di-32d4cea211ec\n""04:05:55 ... expected string = """" +04:05:55 ...     ""1: lo\n"" +04:05:55 ...     ""7: docker_gwbridge\n"" +04:05:55 ...     ""3904: br-9cec5b58de72\n"" +04:05:55 ...     ""100: br-32891016ebfa\n"" +04:05:55 ...     ""101: br-20cf078fc3bf\n"" +04:05:55 ...     ""103: br-0c74ccf3066a\n"" +04:05:55 ...     ""106: br-b41655ed3763\n"" +04:05:55 ...     ""107: br-8e2071e5cfa1\n"" +04:05:55 ...     ""109: br-fc16417d16c9\n"" +04:05:55 ...     ""130: dm-a418cd2b76fb\n"" +04:05:55 ...     ""133: dm-69b475baeb0d\n"" +04:05:55 ...     ""136: dm-a740bf78a2dc\n"" +04:05:55 ...     ""144: eth0@if145\n"" +04:05:55 ...     ""145: di-ca915dccc0d0\n"" +04:05:55 ...     ""148: di-1a2bd995b101\n"" +04:05:55 ...     ""151: di-d5caa148a467\n"" +04:05:55 ...     ""154: di-5ab9f2f5e708\n"" +04:05:55 ...     ""157: di-bbbd5834f313\n"" +04:05:55 ...     ""162: di-85471b0e62aa\n"" +04:05:55 ...     ""167: di-4713fc55f525\n"" +04:05:55 ...     ""169: di-32d4cea211ec\n""04:05:55 ... The network interfaces in container should be the same with host when --net=host when bridge network is disabled: 1: lo04:05:55 7: docker_gwbridge04:05:55 3904: br-9cec5b58de7204:05:55 100: br-32891016ebfa04:05:55 101: br-20cf078fc3bf04:05:55 103: br-0c74ccf3066a04:05:55 106: br-b41655ed376304:05:55 107: br-8e2071e5cfa104:05:55 109: br-fc16417d16c904:05:55 130: dm-a418cd2b76fb04:05:55 133: dm-69b475baeb0d04:05:55 136: dm-a740bf78a2dc04:05:55 144: eth0@di-ca915dccc0d004:05:55 145: di-ca915dccc0d004:05:55 148: di-1a2bd995b10104:05:55 151: di-d5caa148a46704:05:55 154: di-5ab9f2f5e70804:05:55 157: di-bbbd5834f31304:05:55 162: di-85471b0e62aa04:05:55 167: di-4713fc55f52504:05:55 169: di-32d4cea211ec04:05:55 04:05:55 04:05:55 [dea931f9f6e6a] exiting daemon04:05:58 ```
"
37245,0,1243,200,0,0,thaJeztah,0,"title:Flaky test: TestServiceGet . description:Windows https://jenkins.dockerproject.org/job/Docker-PRs-WoW-RS1/21104/console failed on a test that looks racy; seen it fail on some others, and looks like it's comparing timestamps (which can obviously fail);```17:47:17 ok  	github.com/docker/docker/volume/mounts	0.084s	coverage: 66.9% of statements17:47:17 --- FAIL: TestServiceGet (0.09s)17:47:17 	service_test.go:144: assertion failed: 17:47:17 		{*types.Volume}.CreatedAt:17:47:17 			-: ""2018-06-08T17:46:53Z""17:47:17 			+: ""2018-06-08T17:46:54Z""17:47:17 		17:47:17 time=""2018-06-08T17:46:54Z"" level=warning msg=""could not determine size of volume"" error=""GetFileAttributesEx fake: The system cannot find the file specified."" volume=test17:47:17 time=""2018-06-08T17:46:54Z"" level=warning msg=""could not determine size of volume"" error=""GetFileAttributesEx fake: The system cannot find the file specified."" volume=test17:47:17 time=""2018-06-08T17:46:54Z"" level=warning msg=""could not determine size of volume"" error=""GetFileAttributesEx fake: The system cannot find the file specified."" volume=test17:47:17 time=""2018-06-08T17:46:54Z"" level=warning msg=""could not determine size of volume"" error=""GetFileAttributesEx fake: The system cannot find the file specified."" volume=test317:47:17 time=""2018-06-08T17:46:54Z"" level=warning msg=""could not determine size of volume"" error=""GetFileAttributesEx fake: The system cannot find the file specified."" volume=test17:47:17 FAIL```
"
37164,0,647,4,0,0,chris-crone,0,"title:Build output between 17.06 and 18.06 differs for COPY step. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Build output when copying a file differs between 17.06 and 18.06, see: https://github.com/docker/cli/pull/1064#discussion_r189900011.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**```bash$ cd image$ lsDockerfile something$ cat DockerfileFROM alpineCOPY something /$ docker build -t copy .```1. Build Dockerfile that contains `COPY` using 17.06 engine2. Build Dockerfile that contains `COPY` using 18.06 engine**Describe the results you received:**17.06:```bash$ docker build -t copy .Sending build context to Docker daemon   2.56kBStep 1/2 : FROM alpine ---> 3fd9065eaf02Step 2/2 : COPY something / ---> 577b61f8471bRemoving intermediate container 86ec5fc54328Successfully built 577b61f8471bSuccessfully tagged copy:latest```18.06:```bash$ docker build -t copy .Sending build context to Docker daemon   2.56kBStep 1/2 : FROM alpine ---> 3fd9065eaf02Step 2/2 : COPY something / ---> 93321d321367Successfully built 93321d321367Successfully tagged copy:latest```**Describe the results you expected:**18.06 output should contain the ""Removing intermediate container"" line.**Additional information you deem important (e.g. issue happens only occasionally):**Believe this is present in 18.03 too.
"
37150,0,56,0,0,0,arm64b,0,"title:Flaky test `TestExternalGraphDriver/pull`?. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description****Recently** I found that couple of CI failures for `TestExternalGraphDriver/pull` test case, for example:- https://jenkins.dockerproject.org/job/Docker-PRs-powerpc/9978/console> 03:28:44     --- FAIL: TestExternalGraphDriver/pull (0.93s)03:28:44     	external_test.go:402: assertion failed: error is not nil: Error: No such image: busybox:latest- https://jenkins.dockerproject.org/job/Docker-PRs-s390x/9884/console> 03:16:04     --- FAIL: TestExternalGraphDriver/pull (1.08s)03:16:04     	external_test.go:402: assertion failed: error is not nil: Error: No such image: busybox:latest- #37141 (comment)<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1.2.3.**Describe the results you received:****Describe the results you expected:****Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```(paste your output here)```**Output of `docker info`:**```(paste your output here)```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
37132,0,1071,200,0,0,thaJeztah,0,"title:Flaky test: TestServicePlugin, TestCreateServiceSecretFileMode. description:This has been failing on several PR's- https://github.com/moby/moby/pull/36906 (https://github.com/moby/moby/pull/36906#issuecomment-385516999)- https://github.com/moby/moby/pull/36944 (https://github.com/moby/moby/pull/36944#issuecomment-384735408)- others that I didn't register 婵犵妲呴崑鎾跺緤娴犲鐤い鏍剳缂?https://github.com/moby/moby/pull/37086 was increasing the timeout for swarm tests (but that was removed in favor of changing the timeout on a test-by-test base (https://github.com/moby/moby/pull/37086#discussion_r189062007))```00:49:31 === RUN   TestServicePlugin00:50:30 --- FAIL: TestServicePlugin (59.53s)00:50:30 	daemon.go:285: [d1e7868f8b0ee] waiting for daemon to start00:50:30 	daemon.go:317: [d1e7868f8b0ee] daemon started00:50:30 	daemon.go:275: [d1e7868f8b0ee] exiting daemon00:50:30 	daemon.go:285: [d828dcf4073c4] waiting for daemon to start00:50:30 	daemon.go:317: [d828dcf4073c4] daemon started00:50:30 	daemon.go:285: [d409f87ad25cc] waiting for daemon to start00:50:30 	daemon.go:317: [d409f87ad25cc] daemon started00:50:30 	daemon.go:285: [d3b90e73c9588] waiting for daemon to start00:50:30 	daemon.go:317: [d3b90e73c9588] daemon started00:50:30 	plugin_test.go:92: timeout hit after 30s: plugin ""test"" exists00:50:30 	daemon.go:275: [d3b90e73c9588] exiting daemon00:50:30 	daemon.go:275: [d409f87ad25cc] exiting daemon00:50:30 	daemon.go:275: [d828dcf4073c4] exiting daemon00:50:30 FAIL```Other failures observed (https://github.com/moby/moby/pull/42923):```=== RUN   TestCreateServiceSecretFileMode    create_test.go:291: assertion failed: 3 (int) != 1 (int)--- FAIL: TestCreateServiceSecretFileMode (14.33s)```
"
37128,0,4376,9,0,0,rcjsuen,0,"title:Incomplete Dockerfile variable seems to pass the parser. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Dockerfiles support the replacement of variables with a Bash-like syntax (such as `${variable:-word}`). One would expect that a missing `}` would cause the builder to complain but it doesn't.**Steps to reproduce the issue:**1. Create the following seemingly malformed Dockerfile.```DockerfileFROM scratchARG var=${aaa:-bbb```2. Build it. It succeeds. Okay. Maybe `var` is just pointing at the raw string `${aaa:-bbb` as is...?```$ docker build .Sending build context to Docker daemon  1.693MBStep 1/2 : FROM scratch --->Step 2/2 : ARG var=${aaa:-bbb ---> Running in 6fce8a055a31Removing intermediate container 6fce8a055a31 ---> 079813df835cSuccessfully built 079813df835c```**Describe the results you received:**If you run `docker inspect 079813df835c`, the `var` variable is actually `bbb`...?```$ docker inspect 079813df835c[    {        ""Id"": ""sha256:079813df835ca2e3e93e24925e4b8945a16035886651d3f0ccb432a4296721c7"",        ""RepoTags"": [],        ""RepoDigests"": [],        ""Parent"": """",        ""Comment"": """",        ""Created"": ""2018-05-22T22:43:52.70708892Z"",        ""Container"": ""6fce8a055a314364378975a968099e58f2a256519d98a445b4e4fefe1c34e304"",        ""ContainerConfig"": {            ""Hostname"": ""6fce8a055a31"",            ""Domainname"": """",            ""User"": """",            ""AttachStdin"": false,            ""AttachStdout"": false,            ""AttachStderr"": false,            ""Tty"": false,            ""OpenStdin"": false,            ""StdinOnce"": false,            ""Env"": [                ""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin""            ],            ""Cmd"": [                ""/bin/sh"",                ""-c"",                ""#(nop) "",                ""ARG var=bbb""            ],            ""Image"": """",            ""Volumes"": null,            ""WorkingDir"": """",            ""Entrypoint"": null,            ""OnBuild"": null,            ""Labels"": null        },        ""DockerVersion"": ""17.12.0-ce"",        ""Author"": """",        ""Config"": {            ""Hostname"": """",            ""Domainname"": """",            ""User"": """",            ""AttachStdin"": false,            ""AttachStdout"": false,            ""AttachStderr"": false,            ""Tty"": false,            ""OpenStdin"": false,            ""StdinOnce"": false,            ""Env"": [                ""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin""            ],            ""Cmd"": null,            ""Image"": """",            ""Volumes"": null,            ""WorkingDir"": """",            ""Entrypoint"": null,            ""OnBuild"": null,            ""Labels"": null        },        ""Architecture"": ""amd64"",        ""Os"": ""linux"",        ""Size"": 0,        ""VirtualSize"": 0,        ""GraphDriver"": {            ""Data"": null,            ""Name"": ""overlay2""        },        ""RootFS"": {            ""Type"": ""layers""        },        ""Metadata"": {            ""LastTagTime"": ""0001-01-01T00:00:00Z""        }    }]```**Describe the results you expected:**I was expecting the build a) to fail or b) to produce `""ARG var=${aaa:-bbb""`**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```$ docker versionClient: Version:       17.12.0-ce API version:   1.35 Go version:    go1.9.2 Git commit:    c97c6d6 Built: Wed Dec 27 20:05:38 2017 OS/Arch:       linux/amd64Server: Engine:  Version:      17.12.0-ce  API version:  1.35 (minimum version 1.12)  Go version:   go1.9.2  Git commit:   c97c6d6  Built:        Wed Dec 27 20:12:29 2017  OS/Arch:      linux/amd64  Experimental: true```**Output of `docker info`:**```$ docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 1Server Version: 17.12.0-ceStorage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-96-genericOperating System: Alpine Linux v3.7 (containerized)OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.4GiBName: node1ID: CMW4:R5L3:R3JK:XY45:5C6N:FP5O:3S5M:7S4J:RHPM:EG26:CT3S:W454Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 20 Goroutines: 34 System Time: 2018-05-22T22:50:03.301170942Z EventsListeners: 0Registry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.1 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit supportWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**Tested online with [Play with Docker](https://labs.play-with-docker.com/).
"
37109,0,318,200,0,0,thaJeztah,0,"title:Flaky test: TestContainerAPITop. description:Seen this fail a few times; https://jenkins.dockerproject.org/job/Docker-PRs-powerpc/9921/console- https://github.com/moby/moby/pull/32268#issuecomment-291645360- https://github.com/moby/moby/pull/36511#issuecomment-382216564- https://github.com/moby/moby/pull/37106#issuecomment-390403351```11:31:27 FAIL: docker_api_containers_test.go:435: DockerSuite.TestContainerAPITop11:31:27 11:31:27 docker_api_containers_test.go:453:11:31:27     c.Assert(top.Processes[0][10], checker.Equals, ""/bin/sh -c top"")11:31:27 ... obtained string = ""top""11:31:27 ... expected string = ""/bin/sh -c top""11:31:27 ```
"
37083,0,2288,0,0,0,agoulti,0,"title:docker run --mount creates a directory owned by root if directory is removed at a wrong time. description:**Description**If a ""docker run"" is started using ""--mount"" and the mounted directory is removed at a certain point during the invocation, it will create a directory owned by root.This seems a race condition, since the timing or directory removal matters**Steps to reproduce the issue:**The following script has a good chance of reproducing the issue. Changing the timing of ""sleep 0.5"" changes the possibility of problems.```sudo rm -rf /tmp/try/nnnmkdir -p /tmp/try/nnnecho ""before start:""  `ls -ld /tmp/try/nnn`docker run -u 277174:89939 --mount type=bind,src=/tmp/try/nnn,dst=/test debian  sleep 3 &sleep 0.5rm -rf /tmp/try/nnnecho ""before sleep:""  `ls -ld /tmp/try/nnn`sleep 3echo ""after sleep:""  `ls -ld /tmp/try/nnn````**Describe the results you received:**More often than not, this results in the following messages:```before start: drwxr-x--- 2 agoulti primarygroup 4096 May 16 14:48 /tmp/try/nnnafter start: drwxr-x--- 2 agoulti primarygroup 4096 May 16 14:48 /tmp/try/nnnls: cannot access '/tmp/try/nnn': No such file or directorybefore sleep:after sleep: drwxr-xr-x 2 root root 4096 May 16 14:48 /tmp/try/nnn```**Describe the results you expected:**--mount is said not to create a directory if it doesn't exist.I am creating bad running conditions, so I expect docker to fail.However, I expect `/tmp/try/nnn` to never be created.**Additional information you deem important (e.g. issue happens only occasionally):**This is a race condition, so the results are not guaranteed.On my machine I get a problem around half the time. Changing ""sleep 0.5"" duration changes the behaviour, you might need to tune it to reproduce on another machine.Too short and it correctly executes with:`docker: Error response from daemon: invalid mount config for type ""bind"": bind source path does not exist.`Too long and it correctly executes with:`docker: Error response from daemon: OCI runtime create failed: container_linux.go:348: starting container process caused ""process_linux.go:402: container init caused \""rootfs_linux.go:58: mounting \\\""/tmp/try/nnn\\\"" to rootfs \\\""/usr/[...]merged\\\"" at \\\""/test\\\"" caused \\\""stat /tmp/try/nnn: no such file or directory\\\""\"""": unknown.`**Output of `docker version`:**```Client: Version:       18.03.0-ce API version:   1.37 Go version:    go1.9.4 Git commit:    0520e24 Built: Wed Mar 21 23:10:06 2018 OS/Arch:       linux/amd64 Experimental:  false Orchestrator:  swarmServer: Engine:  Version:      18.03.0-ce  API version:  1.37 (minimum version 1.12)  Go version:   go1.9.4  Git commit:   0520e24  Built:        Wed Mar 21 23:08:35 2018  OS/Arch:      linux/amd64  Experimental: false```**Output of `docker info`:**```Containers: 813 Running: 0 Paused: 0 Stopped: 813Images: 26Server Version: 18.03.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfd04396dc68220d1cecbe686a6cc3aa5ce3667crunc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.9.0-6-amd64Operating System: Debian GNU/Linux buster/sidOSType: linuxArchitecture: x86_64CPUs: 12Total Memory: 31.35GiBName: agoulti.wat.corp.google.comID: MMPA:UN32:XDPC:C6LU:IQ4F:WXSG:S2TS:23E4:GW73:4WSB:PKW5:RMWWDocker Root Dir: /usr/local/google/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Desktop Linux machine
"
37077,0,2606,0,0,0,tallandtree,0,"title:inodes not freed after repeated builds - overlay. description:This seems to be a regression of #9755.I'm seeing this issue on a Docker build server with docker 18.03.0-ce.**Description**The error we get during a build: ""no space left on device"". This is due to the number of inodes 100% in use.**Steps to reproduce the issue:**1. Build in Jenkins with jenkinsfile using docker agents 2. Daily clean all unused images and containers3. After a while all inodes are in use**Describe the results you received:**```root@nldt-17836:/data/docker# df -iFilesystem                           Inodes    IUsed   IFree IUse% Mounted onudev                                4098065      504 4097561    1% /devtmpfs                               4103142      697 4102445    1% /run/dev/mapper/ccv360--yoda2--vg-root 30736384 30484641  251743  100% /tmpfs                               4103142        1 4103141    1% /dev/shmtmpfs                               4103142        3 4103139    1% /run/locktmpfs                               4103142       16 4103126    1% /sys/fs/cgroup/dev/sda2                            124928      309  124619    1% /boot/dev/sda1                                 0        0       0     - /boot/efitmpfs                               4103142        4 4103138    1% /run/user/1001```I tried cleaning everything after stopping all containers:```$ docker container prune $ docker image prune --all$ docker volume prune```There were still 64708689 files in /var/lib/docker/overlay. There are 6786 folders inside /var/lib/docker/overlay. A lot of those folders only contain 6 files. Some contain over 60000 files (a complete filesystem).I need to:```# rm -fr /var/lib/docker ```And redeploy the environment again to solve the issue.**Describe the results you expected:**All files in /var/lib/docker/overlay would be have been removed.**Additional information you deem important (e.g. issue happens only occasionally):**Issues happens only on buildservers that use jenkinsfile and build on docker nodes**Output of `docker version`:**```Client: Version:       18.03.0-ce API version:   1.37 Go version:    go1.9.4 Git commit:    0520e24 Built: Wed Mar 21 23:10:01 2018 OS/Arch:       linux/amd64 Experimental:  false Orchestrator:  swarmServer: Engine:  Version:      18.03.0-ce  API version:  1.37 (minimum version 1.12)  Go version:   go1.9.4  Git commit:   0520e24  Built:        Wed Mar 21 23:08:31 2018  OS/Arch:      linux/amd64  Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 18.03.0-ceStorage Driver: overlay Backing Filesystem: extfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfd04396dc68220d1cecbe686a6cc3aa5ce3667crunc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-124-genericOperating System: Ubuntu 16.04.4 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.3GiBName: nldt-17836.ccveu.localID: SOVT:HYKE:SNF4:E6QV:DYH3:C7YL:COGM:X54D:WAMK:2S3A:MCCU:5HUZDocker Root Dir: /data/docker/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels: debops.ccv.architecture=Ubuntu 16.04 debops.ccv.environment=productionExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical server, Ubuntu 16.04We are using storage-driver: ""overlay"".I will switch now to ""overlay2"" and see if this makes a difference, but it may take a while to find out..
"
37037,1,2227,264,0,0,jefflill,0,"title:docker service update --reserve-cpu/--reserve-memory cannot be changed independently. description:**Description**Updating a service's `--reserve-cpu` and `--reserve-memory` options independently clears the option not being set.**Steps to reproduce the issue:**1. `docker service create --name=test --reserve-cpu=2 --reserve-memory=64000000 alpine sleep 1000000`2.  `docker service inspect test`     Note that the two resource reservations are correct.3. `docker service update --reserve-cpu=1 test`4.  `docker service inspect test`Note that the **NanoCPUs** was updated but **MemoryBytes** was removed.  The same thing happens to **NanoCPUs** when **MemoryBytes** is updated by itself.**Describe the results you received:**Updating one of  `--reserve-cpu` and `--reserve-memory` at a time removes the other setting.**Describe the results you expected:**I expected the setting not being changed to remain intact,**Output of `docker version`:**```Client: Version:       18.03.0-ce API version:   1.37 Go version:    go1.9.4 Git commit:    0520e24 Built: Wed Mar 21 23:10:01 2018 OS/Arch:       linux/amd64 Experimental:  false Orchestrator:  swarmServer: Engine:  Version:      18.03.0-ce  API version:  1.37 (minimum version 1.12)  Go version:   go1.9.4  Git commit:   0520e24  Built:        Wed Mar 21 23:08:31 2018  OS/Arch:      linux/amd64  Experimental: false```**Output of `docker info`:**```Containers: 17 Running: 12 Paused: 0 Stopped: 5Images: 11Server Version: 18.03.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: fluentdCgroup Driver: cgroupfsPlugins: Volume: local neon Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: wkig9gwkqa0959kt2je5wkph9 Is Manager: true ClusterID: labusuluolb19eemctgazutkm Managers: 1 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 10.50.0.30 Manager Addresses:  10.50.0.30:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfd04396dc68220d1cecbe686a6cc3aa5ce3667crunc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-112-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 3.936GiBName: manager-0ID: M7PA:BNOJ:BZ2Z:XU3C:GABZ:6TXZ:LUXK:UXTU:PTXP:QIJ2:PQ4B:FMHADocker Root Dir: /mnt/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Registry Mirrors: https://manager-0.neon-registry-cache.cluster:5001/ https://registry-1.docker.io/Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Hosted on Ubuntu 16.04 running on Windows 10 Hyper-V.
"
37036,1,2227,264,0,0,jefflill,0,"title:docker service update --limit-cpu/--limit-memory cannot be changed independently. description:**Description**Updating a service's `--limit-cpu` and `--limit-memory` options independently clears the option not being set.**Steps to reproduce the issue:**1. `docker service create --name=test --limit-cpu=2 --limit-memory=64000000 alpine sleep 1000000`2.  `docker service inspect test`     Note that the two resource limits are correct.3. `docker service update --limit-cpu=1 test`4.  `docker service inspect test`Note that the **NanoCPUs** was updated but **MemoryBytes** was removed.  The same thing happens to **NanoCPUs** when **MemoryBytes** is updated by itself.**Describe the results you received:**Updating one of  `--limit-cpu` and `--limit-memory` at a time removes the other setting.**Describe the results you expected:**I expected the setting not being changed to remain intact,.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:       18.03.0-ce API version:   1.37 Go version:    go1.9.4 Git commit:    0520e24 Built: Wed Mar 21 23:10:01 2018 OS/Arch:       linux/amd64 Experimental:  false Orchestrator:  swarmServer: Engine:  Version:      18.03.0-ce  API version:  1.37 (minimum version 1.12)  Go version:   go1.9.4  Git commit:   0520e24  Built:        Wed Mar 21 23:08:31 2018  OS/Arch:      linux/amd64  Experimental: false```**Output of `docker info`:**```Containers: 17 Running: 12 Paused: 0 Stopped: 5Images: 11Server Version: 18.03.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: fluentdCgroup Driver: cgroupfsPlugins: Volume: local neon Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: wkig9gwkqa0959kt2je5wkph9 Is Manager: true ClusterID: labusuluolb19eemctgazutkm Managers: 1 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 10.50.0.30 Manager Addresses:  10.50.0.30:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfd04396dc68220d1cecbe686a6cc3aa5ce3667crunc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-112-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 3.936GiBName: manager-0ID: M7PA:BNOJ:BZ2Z:XU3C:GABZ:6TXZ:LUXK:UXTU:PTXP:QIJ2:PQ4B:FMHADocker Root Dir: /mnt/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Registry Mirrors: https://manager-0.neon-registry-cache.cluster:5001/ https://registry-1.docker.io/Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Hosted on Ubuntu 16.04 running on Windows 10 Hyper-V.
"
37035,1,2227,264,0,0,jefflill,0,"title:docker service update --host-rm/--host-add: doesn't persist new value. description:**Description**I'm writing a specialized Ansible module for managing Docker swarm services.  During my testing, I tried to use `docker service update` to modify a service host/IP mapping by specifying `--host-rm` and `--host-add` in the same command.This didn't work.  It appears that Docker added the new host entry but then deleted all entries with for that host name afterwards resulting in no host entries.  This was discussed in #35325 and @thaJeztah mentioned he was going to file an issue but I couldn't find it.**Steps to reproduce the issue:**1. `docker service create --name=test --host=foo.com:1.1.1.1 alpine sleep 10000000`2. `docker service update --host-rm=foo.com:1.1.1.1 --host-add=foo.com:2.2.2.2 test`3. `docker service inspect test`**Describe the results you received:**The results from `docker service inspect test` do not include `Spec.TaskTemplate.ContainerSpec.Hosts` entries.**Describe the results you expected:**Expected a `2.2.2.2 foo.com` hosts entry.**Output of `docker version`:**```Client: Version:       18.03.0-ce API version:   1.37 Go version:    go1.9.4 Git commit:    0520e24 Built: Wed Mar 21 23:10:01 2018 OS/Arch:       linux/amd64 Experimental:  false Orchestrator:  swarmServer: Engine:  Version:      18.03.0-ce  API version:  1.37 (minimum version 1.12)  Go version:   go1.9.4  Git commit:   0520e24  Built:        Wed Mar 21 23:08:31 2018  OS/Arch:      linux/amd64  Experimental: false```**Output of `docker info`:**```Containers: 17 Running: 12 Paused: 0 Stopped: 5Images: 11Server Version: 18.03.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: fluentdCgroup Driver: cgroupfsPlugins: Volume: local neon Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: wkig9gwkqa0959kt2je5wkph9 Is Manager: true ClusterID: labusuluolb19eemctgazutkm Managers: 1 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 10.50.0.30 Manager Addresses:  10.50.0.30:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfd04396dc68220d1cecbe686a6cc3aa5ce3667crunc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-112-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 3.936GiBName: manager-0ID: M7PA:BNOJ:BZ2Z:XU3C:GABZ:6TXZ:LUXK:UXTU:PTXP:QIJ2:PQ4B:FMHADocker Root Dir: /mnt/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Registry Mirrors: https://manager-0.neon-registry-cache.cluster:5001/ https://registry-1.docker.io/Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Running on Ubuntu 16.04 hosted on Windows 10 Hyper-V.
"
37032,0,316,268,0,0,kolyshkin,1,"title:Inability to use bind mounts if source is on /. description:1. When running a recent version of docker-ce, it is not possible to create a bind mount for a directory which is on / (i.e. a root mount point):> docker run -ti -v /var/lib/kubelet:/dummy:shared,z ubuntu /bin/bash> docker: Error response from daemon: linux mounts: Could not find source mount of /var/lib/kubelet.2. There is a warning on daemon start (reported https://github.com/docker/for-linux/issues/290#issuecomment-386625728):> 5闂?04 22:49:29 docularxu-Precision-7520 dockerd[9003]: time=""2018-05-04T22:49:29.592148011+08:00"" level=warning msg=""Error while setting daemon root propagation, this is not generally critical but may cause some functionality to not work or fallback to less desirable behavior"" dir=/var/lib/docker error=""error getting daemon root's parent mount: Could not find source mount of /var/lib/docker""## WorkaroundFor those suffering from the issue (only Docker CE 18.05 is affected), a quick workaround is to bind mount the directory on the host to itself, i.e. do `mount --bind $dir $dir` before starting a container. Here's a full example:```# docker run -ti -v /var/lib/kubelet:/dummy:shared,z ubuntu /bin/bashdocker: Error response from daemon: linux mounts: Could not find source mount of /var/lib/kubelet.# mount --bind /var/lib/kubelet /var/lib/kubelet# docker run -ti -v /var/lib/kubelet:/dummy:shared,z ubuntu /bin/bashroot@984f30b36d51:/#```
"
37027,1,4567,264,0,0,jefflill,0,"title:docker service create: ignores --rollback-* options. description:**Description**Deploying a swarm service with the docker-cli seems to ignore `--rollback-*` command line options.**Steps to reproduce the issue:**1. `docker service create --name=test --rollback-failure-action=continue --rollback-max-failure-ratio=0.5 --rollback-monitor=3000000000ns --rollback-order=start-first --rollback-parallelism=2 neoncluster/test`2. `docker service inspect test`**Describe the results you received:**```[    {        ""ID"": ""kdecfz7i4t31ue7jxfj3qttpt"",        ""Version"": {            ""Index"": 3982        },        ""CreatedAt"": ""2018-05-09T20:36:33.256545768Z"",        ""UpdatedAt"": ""2018-05-09T20:36:33.256545768Z"",        ""Spec"": {            ""Name"": ""test"",            ""Labels"": {},            ""TaskTemplate"": {                ""ContainerSpec"": {                    ""Image"": ""neoncluster/test:latest@sha256:1fb2a2e5c438061c300752d75caa1bd7c6187636660975c24bb0781763bfa7e2"",                    ""StopGracePeriod"": 10000000000,                    ""DNSConfig"": {},                    ""Isolation"": ""default""                },                ""Resources"": {                    ""Limits"": {},                    ""Reservations"": {}                },                ""RestartPolicy"": {                    ""Condition"": ""any"",                    ""Delay"": 5000000000,                    ""MaxAttempts"": 0                },                ""Placement"": {                    ""Platforms"": [                        {                            ""Architecture"": ""amd64"",                            ""OS"": ""linux""                        }                    ]                },                ""ForceUpdate"": 0,                ""Runtime"": ""container""            },            ""Mode"": {                ""Replicated"": {                    ""Replicas"": 1                }            },            ""UpdateConfig"": {                ""Parallelism"": 1,                ""FailureAction"": ""pause"",                ""Monitor"": 5000000000,                ""MaxFailureRatio"": 0,                ""Order"": ""stop-first""            },            ""RollbackConfig"": {                ""Parallelism"": 1,                ""FailureAction"": ""pause"",                ""Monitor"": 5000000000,                ""MaxFailureRatio"": 0,                ""Order"": ""stop-first""            },            ""EndpointSpec"": {                ""Mode"": ""vip""            }        },        ""Endpoint"": {            ""Spec"": {}        }    }]```**Describe the results you expected:**Notice that the **RollbackConfig** section doesn't include the rollback settings I specified on the command line.  I was expecting to look something like:```            ""RollbackConfig"": {                ""Parallelism"": 2,                ""FailureAction"": ""continue"",                ""Monitor"": 3000000000,                ""MaxFailureRatio"": 0.5,                ""Order"": ""start-first""            },```**Output of `docker version`:**```Client: Version:       18.03.0-ce API version:   1.37 Go version:    go1.9.4 Git commit:    0520e24 Built: Wed Mar 21 23:10:01 2018 OS/Arch:       linux/amd64 Experimental:  false Orchestrator:  swarmServer: Engine:  Version:      18.03.0-ce  API version:  1.37 (minimum version 1.12)  Go version:   go1.9.4  Git commit:   0520e24  Built:        Wed Mar 21 23:08:31 2018  OS/Arch:      linux/amd64  Experimental: false```**Output of `docker info`:**```Containers: 17 Running: 12 Paused: 0 Stopped: 5Images: 12Server Version: 18.03.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: fluentdCgroup Driver: cgroupfsPlugins: Volume: local neon Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: wkig9gwkqa0959kt2je5wkph9 Is Manager: true ClusterID: labusuluolb19eemctgazutkm Managers: 1 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 10.50.0.30 Manager Addresses:  10.50.0.30:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfd04396dc68220d1cecbe686a6cc3aa5ce3667crunc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-112-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 3.936GiBName: manager-0ID: M7PA:BNOJ:BZ2Z:XU3C:GABZ:6TXZ:LUXK:UXTU:PTXP:QIJ2:PQ4B:FMHADocker Root Dir: /mnt/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Registry Mirrors: https://manager-0.neon-registry-cache.cluster:5001/ https://registry-1.docker.io/Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Hosted on an Ubuntu 16.04 cluster hosted locally on Hyper-V.
"
36996,0,2464,155,0,0,ijc,0,"title:docker build --label ignore when --target is used. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**Given:```$ cat DockerfileARG TARGET=AFROM busybox AS aRUN echo A > /fooFROM busybox AS bRUN echo B > /fooFROM ${TARGET}```Then```$ docker build -t foo --label foo=bar .[...]Step 7/7 : LABEL ""foo""='bar'[...]Successfully tagged foo:latest```Tags labels the image `foo:latest` correctly:```$ docker inspect foo | jq .[].Config.Labels{  ""foo"": ""bar""}```However ```$ docker build -t foo --label foo=bar --target=a .Sending build context to Docker daemon  3.072kBStep 1/3 : ARG TARGET=aStep 2/3 : FROM busybox AS a ---> 8ac48589692aStep 3/3 : RUN echo A > /foo ---> Using cache ---> ef4eb60aa8bfSuccessfully built ef4eb60aa8bfSuccessfully tagged foo:latest$ docker inspect foo | jq .[].Config.Labelsnull```The same is true for `--target=b`.Using the build-arg works though:```$ docker build -t foo --label foo=bar --build-arg TARGET=a .[...]Step 7/7 : LABEL ""foo""='bar'[...]Successfully tagged foo:latest$ docker inspect foo | jq .[].Config.Labels{  ""foo"": ""bar""}```**Describe the results you received:**When using `--target=` the `--label` does not take effect.**Describe the results you expected:**I expected the images built with `--target` to have the label on them.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:	18.04.0-ce API version:	1.37 Go version:	go1.9.4 Git commit:	3d479c0 Built:	Tue Apr 10 18:22:52 2018 OS/Arch:	linux/amd64 Experimental:	true Orchestrator:	swarmServer: Engine:  Version:	18.04.0-ce  API version:	1.37 (minimum version 1.12)  Go version:	go1.9.4  Git commit:	3d479c0  Built:	Tue Apr 10 18:20:59 2018  OS/Arch:	linux/amd64  Experimental:	true```Also seen with 18.03.0-ce**Output of `docker info`:**```Containers: 3 Running: 1 Paused: 0 Stopped: 2Images: 126Server Version: 18.04.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 773c489c9c1b21a6d78b5c538cd395416ec50f88runc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.14.0-3-amd64Operating System: Debian GNU/Linux buster/sidOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.53GiBName: bokrugID: AU33:BO7D:7VGM:MOLB:RSDF:IBRV:GCWT:THHM:OEVM:TX3C:BNLM:WHARDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: ijc25Registry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Native on Linux (Debian)./cc @tonistiigi 
"
36990,0,1467,285,0,0,natalieparellano,0,"title:Publishing container ports in Windows Server 2019 does not work. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Publishing a container port in Windows Server 2019 does not work. We expect that a listening process running inside a container can be made available on the host IP address via Docker's `-p` flag. However, when doing this with the Windows Server 2019 technical preview, connecting to the published port does not work.**Steps to reproduce the issue:**1. `docker run -d -p 40000:8080 microsoft/windowsservercore-insider:10.0.17650.1001 powershell -command '$l = [system.net.sockets.tcplistener]8080; $l.start(); sleep(10000)'`2. `test-netconnection -computername <host ip address> -port 40000`3. Network connection test fails**Describe the results you received:**We noticed in the latest technical preview of Windows Server 2019 that container ports cannot be published to the host. This behavior used to work just fine in Windows Server 1709.Note that testing the connection to the container IP and port works just fine -- so we know that there is a listening process. Just the publishing fails to work.**Describe the results you expected:**We expect that publishing a port will allow container processes to be reached from the host's IP address.**Additional information you deem important (e.g. issue happens only occasionally):**Issue happens consistently.**Output of `docker version`:**```Client: Version:      master-dockerproject-2018-05-01 API version:  1.37 Go version:   go1.9.5 Git commit:   f42c66bd Built:        Tue May  1 23:50:33 2018 OS/Arch:      windows/amd64 Experimental: false Orchestrator: swarmServer: Engine:  Version:      master-dockerproject-2018-05-01  API version:  1.37 (minimum version 1.24)  Go version:   go1.10.1  Git commit:   fe2d3a1  Built:        Tue May  1 23:59:43 2018  OS/Arch:      windows/amd64  Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 7Server Version: master-dockerproject-2018-05-01Storage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: ics l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd gelf json-file logentries splunk syslogSwarm: inactiveDefault Isolation: processKernel Version: 10.0 17650 (17650.1001.amd64fre.rs_prerelease.180414-2140)Operating System: Windows Server Standard Version 1803 (OS Build 17650.1001)OSType: windowsArchitecture: x86_64CPUs: 4Total Memory: 3.999GiBName: WIN-FAPQVPA02FAID: 5PHV:N4QL:BHCU:E74V:QCXB:3KCK:54PG:M6VA:JWNW:RB2W:6QL7:5RUEDocker Root Dir: C:\ProgramData\dockerDebug Mode (client): falseDebug Mode (server): falseUsername: pivotalgreenhouseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```
"
36956,0,2457,13,0,0,douglasmiranda,0,"title:Multi-stage builds: target name can't be uppercase. description:**Description**When using multi-stage builds, I can name a stage with an uppercase string `BUILDER`, for example.**Steps to reproduce the issue:**Dockerfile```DockerfileFROM alpine AS BUILDERRUN touch file.txtFROM alpine AS DEVCMD [""ls""]```Let's build this image stopping at `DEV` stage. [more about stopping at a specific stage](https://docs.docker.com/develop/develop-images/multistage-build/#stop-at-a-specific-build-stage)```$ docker build --target=DEV -t devimagex .Sending build context to Docker daemon  2.048kBError response from daemon: failed to reach build target DEV in Dockerfile```But even **without** rename the target to lowercase in the Dockerfile, I can achieve the desired behavior by building setting the `--target` as lowercase `dev`.```docker build --target=dev -t devimagex .Sending build context to Docker daemon  2.048kBStep 1/4 : FROM alpine AS BUILDER ---> 3fd9065eaf02Step 2/4 : RUN touch file.txt ---> Using cache ---> c3cb5e472065Step 3/4 : FROM alpine AS DEV ---> 3fd9065eaf02Step 4/4 : CMD [""ls""] ---> Using cache ---> fd71f6b3c81cSuccessfully built fd71f6b3c81cSuccessfully tagged devimagex:latest```**More info:*** Dockerfile instructions are not case-sensitive, but it's a convention to use them as UPPERCASE. A target name it's not an instruction so I should use lowercase.* Since a target name can be used as an image to subsequent stages, it's another reason to use them as lowercase since image names are required to be lowercase. (although target names are just a reference to the id of that temporary stage image, right?)BUT, the thing is, we CAN name a stage with an uppercase string, and it works inside the Dockerfile, but when used with `docker build --target=` or even in Docker Compose, I must refer to them as lowercase even though it's uppercase in the Dockerfile.So, maybe a solution better than put in the docs more info about this, is to throw a better error message than: `Error response from daemon: failed to reach build target DEV in Dockerfile`Since enforcing this to change on Dockerfiles now could break a lot, maybe enforce when using  `docker build --target`, something like: `Error response from daemon: failed to reach build target DEV in Dockerfile. Target names must be lowercase`.Or, if that's not a big of a deal, just allow uppercase on Docker command line and Docker Compose.```docker build --target=DEV ...```I hope I didn't miss something.Docs related:* https://docs.docker.com/engine/reference/builder/#from* https://docs.docker.com/develop/develop-images/multistage-build/#stop-at-a-specific-build-stage* https://docs.docker.com/compose/compose-file/#target---**Output of `docker version`:**  Click to expand```Client: Version:	18.03.0-ce API version:	1.37 Go version:	go1.9.4 Git commit:	0520e24 Built:	Wed Mar 21 23:06:22 2018 OS/Arch:	darwin/amd64 Experimental:	false Orchestrator:	swarmServer: Engine:  Version:	18.03.0-ce  API version:	1.37 (minimum version 1.12)  Go version:	go1.9.4  Git commit:	0520e24  Built:	Wed Mar 21 23:14:32 2018  OS/Arch:	linux/amd64  Experimental:	true```</details>---**Output of `docker info`:**  Click to expand```Containers: 22 Running: 0 Paused: 0 Stopped: 22Images: 207Server Version: 18.03.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfd04396dc68220d1cecbe686a6cc3aa5ce3667crunc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.87-linuxkit-aufsOperating System: Docker for MacOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.952GiBName: linuxkit-025000000001ID: EUQE:3BXM:4ESD:MFIT:QAA6:DKAJ:2JQU:F5JM:GBK6:ZXAR:NZBI:WPUKDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 28 Goroutines: 57 System Time: 2018-04-26T20:18:21.1274233Z EventsListeners: 3HTTP Proxy: docker.for.mac.http.internal:3128HTTPS Proxy: docker.for.mac.http.internal:3129Registry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```</details>
"
36917,0,813,50,0,0,Sh4d1,0,"title:Error when escapeKeys is empty (pkg/term/proxy.go). description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**I have a bug using `pkg/term` in scaleway cli. It is because `escaeProxy` struct have an empty array.PR is coming :smiley: **Steps to reproduce the issue:**1. Install scaleway cli2. Run an instance3. Attach to an instance and type something `scw --attach <insatnce-id>Issue opened here: https://github.com/scaleway/scaleway-cli/issues/497**Describe the results you received:**```panic: runtime error: index out of rangegoroutine 54 [running]:github.com/scaleway/scaleway-cli/vendor/github.com/moby/moby/pkg/term.(*escapeProxy).Read(0xc4201c9110, 0xc4204fc700, 0x80, 0x80, 0xc42009a000, 0x0, 0x0)        /home/patrik/go/src/github.com/scaleway/scaleway-cli/vendor/github.com/moby/moby/pkg/term/proxy.go:54 +0x5f5github.com/scaleway/scaleway-cli/vendor/github.com/moul/gotty-client.(*Client).writeLoop(0xc420132600, 0xc420301f90, 0x0)        /home/patrik/go/src/github.com/scaleway/scaleway-cli/vendor/github.com/moul/gotty-client/gotty-client.go:352 +0x398created by github.com/scaleway/scaleway-cli/vendor/github.com/moul/gotty-client.(*Client).Loop        /home/patrik/go/src/github.com/scaleway/scaleway-cli/vendor/github.com/moul/gotty-client/gotty-client.go:238 +0x110```**Describe the results you expected:**Not an error**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**Not relevant**Output of `docker info`:**Not relevant**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
36814,0,179128,16,0,0,dcharbonnier,0,"title:fatal error: concurrent map read and map write. description:Crash of the docker daemon, swarm mode version 17.12.1```Apr  9 00:05:00 sd-134674 dockerd[4192]: time=""2018-04-09T00:05:00.882007546+02:00"" level=warning msg=""memberlist: Refuting a suspect message (from: 00799e0b24d8)""Apr  9 00:05:05 sd-134674 dockerd[4192]: time=""2018-04-09T00:05:05.987812379+02:00"" level=info msg=""memberlist: Marking 4cf39be48795 as failed, suspect timeout reached (3 peer confirmations)""Apr  9 00:05:05 sd-134674 dockerd[4192]: time=""2018-04-09T00:05:05.987962182+02:00"" level=info msg=""Node 4cf39be48795/xxx.xxx.xxx.001, left gossip cluster""Apr  9 00:05:05 sd-134674 dockerd[4192]: time=""2018-04-09T00:05:05.988068049+02:00"" level=info msg=""Node 4cf39be48795 change state NodeActive --> NodeFailed""Apr  9 00:05:06 sd-134674 dockerd[4192]: time=""2018-04-09T00:05:06.529417883+02:00"" level=info msg=""Node 4cf39be48795/xxx.xxx.xxx.001, added to failed nodes list""Apr  9 00:05:06 sd-134674 dockerd[4192]: time=""2018-04-09T00:05:06.529711195+02:00"" level=warning msg=""peerDbDelete transient condition - Key:10.255.0.6 02:42:0a:ff:00:06 cardinality:1 db state:Set{{80f7613b8a79cc440d521a0d9645d5e0596186138ced76fec8caa7ae4b6e1676 xxx.xxx.xxx.002 16 32 false}}""Apr  9 00:05:06 sd-134674 dockerd[4192]: time=""2018-04-09T00:05:06.529720898+02:00"" level=info msg=""Node 4cf39be48795/xxx.xxx.xxx.001, joined gossip cluster""Apr  9 00:05:07 sd-134674 dockerd[4192]: fatal error: concurrent map read and map writeApr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 346 [running]:Apr  9 00:05:07 sd-134674 dockerd[4192]: runtime.throw(0x2a86949, 0x21)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/runtime/panic.go:605 +0x95 fp=0xc4beabf960 sp=0xc4beabf940 pc=0x11a1ea5Apr  9 00:05:07 sd-134674 dockerd[4192]: runtime.mapaccess1_faststr(0x2785fe0, 0xc420a16450, 0xc462563df0, 0xc, 0x578)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/runtime/hashmap_fast.go:217 +0x43a fp=0xc4beabf9b8 sp=0xc4beabf960 pc=0x1181c9aApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).gossip(0xc420c40000)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:437 +0x638 fp=0xc4beabfe68 sp=0xc4beabf9b8 pc=0x1ea6c38Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).(github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.gossip)-fm()Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:165 +0x2a fp=0xc4beabfe80 sp=0xc4beabfe68 pc=0x1ed198aApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).triggerFunc(0xc420c40000, 0xbebc200, 0xc4203c1800, 0xc42027a7e0, 0xc42016ccf0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:248 +0x11f fp=0xc4beabffb8 sp=0xc4beabfe80 pc=0x1ea57bfApr  9 00:05:07 sd-134674 dockerd[4192]: runtime.goexit()Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/runtime/asm_amd64.s:2337 +0x1 fp=0xc4beabffc0 sp=0xc4beabffb8 pc=0x11d3331Apr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).clusterInitApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:171 +0x90cApr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 1 [chan receive, 55145 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: main.(*DaemonCli).start(0xc420248540, 0xc420171c70, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/cmd/dockerd/daemon.go:314 +0x1b0aApr  9 00:05:07 sd-134674 dockerd[4192]: main.runDaemon(0xc420171c70, 0xc420108ab0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/cmd/dockerd/docker.go:78 +0x76Apr  9 00:05:07 sd-134674 dockerd[4192]: main.newDaemonCommand.func1(0xc42009e480, 0x392bc30, 0x0, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/cmd/dockerd/docker.go:29 +0x5bApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).execute(0xc42009e480, 0xc4200101b0, 0x0, 0x0, 0xc42009e480, 0xc4200101b0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:646 +0x44dApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc42009e480, 0x27d2f20, 0x2aec701, 0xc42016d230)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:742 +0x30eApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).Execute(0xc42009e480, 0xc42016d230, 0x2a53000)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:695 +0x2bApr  9 00:05:07 sd-134674 dockerd[4192]: main.main()Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/cmd/dockerd/docker.go:105 +0xe1Apr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 6 [syscall, 55145 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: os/signal.signal_recv(0x14a2d40)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/runtime/sigqueue.go:131 +0xa6Apr  9 00:05:07 sd-134674 dockerd[4192]: os/signal.loop()Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/os/signal/signal_unix.go:22 +0x22Apr  9 00:05:07 sd-134674 dockerd[4192]: created by os/signal.init.0Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/os/signal/signal_unix.go:28 +0x41Apr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 69 [syscall, 55145 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: syscall.Syscall6(0xf7, 0x1, 0x106b, 0xc42002f5a0, 0x1000004, 0x0, 0x0, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/syscall/asm_linux_amd64.s:44 +0x5Apr  9 00:05:07 sd-134674 dockerd[4192]: os.(*Process).blockUntilWaitable(0xc42014a960, 0xc42002f6f8, 0x1179b50, 0xc4203e2bf8)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/os/wait_waitid.go:31 +0xa5Apr  9 00:05:07 sd-134674 dockerd[4192]: os.(*Process).wait(0xc42014a960, 0xc420019900, 0xc42002f728, 0xc4203e2b01)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/os/exec_unix.go:22 +0x42Apr  9 00:05:07 sd-134674 dockerd[4192]: os.(*Process).Wait(0xc42014a960, 0x2aeedc8, 0xc42002f760, 0x24ce60b)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/os/exec.go:115 +0x2bApr  9 00:05:07 sd-134674 dockerd[4192]: os/exec.(*Cmd).Wait(0xc4203f06e0, 0xc42002f7b8, 0x1a9bc39)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/os/exec/exec.go:446 +0x62Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/libcontainerd.(*remote).startContainerd.func1(0xc4203f06e0, 0xc4203e76c0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/libcontainerd/remote_daemon.go:243 +0x2fApr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/libcontainerd.(*remote).startContainerdApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/libcontainerd/remote_daemon.go:241 +0x432Apr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 73 [select, 55145 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc.newClientStream.func3(0x38b4a60, 0xc4205dc780, 0xc4202601a0, 0xc420500580, 0xc42056e000)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:241 +0x1cdApr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/vendor/google.golang.org/grpc.newClientStreamApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:240 +0xc7cApr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 38 [IO wait]:Apr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.runtime_pollWait(0x7f26faa6cdf0, 0x72, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/runtime/netpoll.go:173 +0x57Apr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.(*pollDesc).wait(0xc42032c098, 0x72, 0xffffffffffffff00, 0x3896720, 0x3887298)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +0xaeApr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.(*pollDesc).waitRead(0xc42032c098, 0xc420174000, 0x8000, 0x8000)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +0x3dApr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.(*FD).Read(0xc42032c080, 0xc420174000, 0x8000, 0x8000, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/internal/poll/fd_unix.go:126 +0x18aApr  9 00:05:07 sd-134674 dockerd[4192]: net.(*netFD).Read(0xc42032c080, 0xc420174000, 0x8000, 0x8000, 0x10, 0x10, 0x27d28a0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/net/fd_unix.go:202 +0x52Apr  9 00:05:07 sd-134674 dockerd[4192]: net.(*conn).Read(0xc42000e008, 0xc420174000, 0x8000, 0x8000, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/net/net.go:176 +0x6dApr  9 00:05:07 sd-134674 dockerd[4192]: bufio.(*Reader).Read(0xc42030e060, 0xc42015e038, 0x9, 0x9, 0x181f07f, 0xc480ed8908, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/bufio/bufio.go:213 +0x30bApr  9 00:05:07 sd-134674 dockerd[4192]: io.ReadAtLeast(0x3889160, 0xc42030e060, 0xc42015e038, 0x9, 0x9, 0x9, 0xc42004ddc8, 0x20, 0xc420499500)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/io/io.go:309 +0x86Apr  9 00:05:07 sd-134674 dockerd[4192]: io.ReadFull(0x3889160, 0xc42030e060, 0xc42015e038, 0x9, 0x9, 0xc42004de09, 0xc480ed8d50, 0xc46c38b200)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/io/io.go:327 +0x58Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/golang.org/x/net/http2.readFrameHeader(0xc42015e038, 0x9, 0x9, 0x3889160, 0xc42030e060, 0x0, 0x0, 0xc480ed8d20, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:237 +0x7bApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/golang.org/x/net/http2.(*Framer).ReadFrame(0xc42015e000, 0xc, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:492 +0xa4Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*framer).readFrame(0xc4201442a0, 0xc480ed8d50, 0xc480ed8d50, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http_util.go:544 +0x2fApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*http2Client).reader(0xc4203c6d80)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http2_client.go:1057 +0xc0Apr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/vendor/google.golang.org/grpc/transport.newHTTP2ClientApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http2_client.go:250 +0xb8dApr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 39 [select]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*http2Client).controller(0xc4203c6d80)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http2_client.go:1130 +0x142Apr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/vendor/google.golang.org/grpc/transport.newHTTP2ClientApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http2_client.go:280 +0xf4cApr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 40 [select, 55145 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc.(*addrConn).transportMonitor(0xc4203e7ba0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:891 +0x1deApr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/vendor/google.golang.org/grpc.(*ClientConn).resetAddrConnApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:608 +0x6efApr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 22 [chan receive]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/libcontainerd.(*remote).monitorConnection(0xc4203e76c0, 0xc4205100e0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/libcontainerd/remote_daemon.go:270 +0x9fApr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/libcontainerd.NewApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/libcontainerd/remote_daemon.go:116 +0x601Apr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 23 [select, 55145 minutes, locked to thread]:Apr  9 00:05:07 sd-134674 dockerd[4192]: runtime.gopark(0x2aeec80, 0x0, 0x2a52adc, 0x6, 0x18, 0x1)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/runtime/proc.go:287 +0x12cApr  9 00:05:07 sd-134674 dockerd[4192]: runtime.selectgo(0xc420130750, 0xc4204f03c0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/runtime/select.go:395 +0x1149Apr  9 00:05:07 sd-134674 dockerd[4192]: runtime.ensureSigM.func1()Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/runtime/signal_unix.go:511 +0x220Apr  9 00:05:07 sd-134674 dockerd[4192]: runtime.goexit()Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/runtime/asm_amd64.s:2337 +0x1Apr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 24 [chan receive, 55145 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/pkg/signal.Trap.func1(0xc420258240, 0x388d620, 0xc42008a190, 0xc420371b00)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/pkg/signal/trap.go:38 +0x65Apr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/pkg/signal.TrapApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/pkg/signal/trap.go:36 +0x122Apr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 42 [chan receive]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/daemon/stats.(*Collector).Run(0xc420140c00)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/daemon/stats/collector.go:60 +0x1f9Apr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/daemon.(*Daemon).newStatsCollectorApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/daemon/stats_collector.go:24 +0x7fApr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 26 [chan receive, 55145 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/daemon.(*Daemon).setupDumpStackTrap.func1(0xc420258300, 0x2a60227, 0xf)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/daemon/debugtrap_unix.go:18 +0x4eApr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/daemon.(*Daemon).setupDumpStackTrapApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/daemon/debugtrap_unix.go:17 +0xc9Apr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 31 [IO wait, 55145 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.runtime_pollWait(0x7f26faa6cd30, 0x72, 0xffffffffffffffff)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/runtime/netpoll.go:173 +0x57Apr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.(*pollDesc).wait(0xc420152398, 0x72, 0xc42019bc00, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +0xaeApr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.(*pollDesc).waitRead(0xc420152398, 0xffffffffffffff00, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +0x3dApr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.(*FD).Accept(0xc420152380, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/internal/poll/fd_unix.go:335 +0x1e2Apr  9 00:05:07 sd-134674 dockerd[4192]: net.(*netFD).accept(0xc420152380, 0xc400000020, 0xc42019be48, 0x11873a8)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/net/fd_unix.go:238 +0x42Apr  9 00:05:07 sd-134674 dockerd[4192]: net.(*UnixListener).accept(0xc42044d470, 0x128b1aa, 0x2912fe0, 0xc4202b6090)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/net/unixsock_posix.go:162 +0x32Apr  9 00:05:07 sd-134674 dockerd[4192]: net.(*UnixListener).Accept(0xc42044d470, 0xc420012018, 0x276a2c0, 0x3864f60, 0x2a1af60)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/net/unixsock.go:241 +0x49Apr  9 00:05:07 sd-134674 dockerd[4192]: net/http.(*Server).Serve(0xc420408000, 0x38a9ae0, 0xc42044d470, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/net/http/server.go:2695 +0x1b2Apr  9 00:05:07 sd-134674 dockerd[4192]: net/http.Serve(0x38a9ae0, 0xc42044d470, 0x388e9e0, 0xc42044d4a0, 0x11a9c68, 0x2aeeb00)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/net/http/server.go:2323 +0x73Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/daemon.(*Daemon).listenMetricsSock.func1(0x38a9ae0, 0xc42044d470, 0xc42044d4a0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/daemon/metrics_unix.go:31 +0x4bApr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/daemon.(*Daemon).listenMetricsSockApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/daemon/metrics_unix.go:30 +0x193Apr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 85 [select, 55145 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*recvBufferReader).Read(0xc42040a100, 0xc42014c110, 0x5, 0x5, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/transport.go:144 +0x2ecApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*Stream).Read(0xc420372000, 0xc42014c110, 0x5, 0x5, 0x0, 0x0, 0xc4202bf018)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/transport.go:332 +0x5cApr  9 00:05:07 sd-134674 dockerd[4192]: io.ReadAtLeast(0x388e0a0, 0xc420372000, 0xc42014c110, 0x5, 0x5, 0x5, 0x28c7000, 0xc4202b6300, 0x240000000030)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/io/io.go:309 +0x86Apr  9 00:05:07 sd-134674 dockerd[4192]: io.ReadFull(0x388e0a0, 0xc420372000, 0xc42014c110, 0x5, 0x5, 0x7f26faac9b20, 0xc420267c20, 0x1186c47)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/io/io.go:327 +0x58Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc.(*parser).recvMsg(0xc42014c100, 0x7fffffff, 0x0, 0xbc827319853b67e7, 0xc42050e518, 0x27d1420, 0xc420267c50, 0x11873a8)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/rpc_util.go:218 +0x69Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc.recv(0xc42014c100, 0x38ab220, 0x392bc30, 0xc420372000, 0x0, 0x0, 0x2910420, 0xc42040a180, 0x7fffffff, 0x0, ...)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/rpc_util.go:314 +0x4dApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc.(*clientStream).RecvMsg(0xc42025e2c0, 0x2910420, 0xc42040a180, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:376 +0xdaApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/github.com/containerd/containerd/api/services/events/v1.(*eventsSubscribeClient).Recv(0xc420146310, 0xc420267f60, 0x1, 0x1)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/github.com/containerd/containerd/api/services/events/v1/events.pb.go:213 +0x62Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/libcontainerd.(*client).processEventStream(0xc42019e230, 0x38ab9e0, 0xc420150040)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/libcontainerd/client_daemon.go:745 +0x434Apr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/libcontainerd.(*remote).NewClientApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/libcontainerd/remote_daemon.go:136 +0x292Apr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 82 [IO wait, 35 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.runtime_pollWait(0x7f26faa6cc70, 0x72, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/runtime/netpoll.go:173 +0x57Apr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.(*pollDesc).wait(0xc420152718, 0x72, 0xffffffffffffff00, 0x3896720, 0x3887298)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +0xaeApr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.(*pollDesc).waitRead(0xc420152718, 0xc4202a8000, 0x8000, 0x8000)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +0x3dApr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.(*FD).Read(0xc420152700, 0xc4202a8000, 0x8000, 0x8000, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/internal/poll/fd_unix.go:126 +0x18aApr  9 00:05:07 sd-134674 dockerd[4192]: net.(*netFD).Read(0xc420152700, 0xc4202a8000, 0x8000, 0x8000, 0x11, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/net/fd_unix.go:202 +0x52Apr  9 00:05:07 sd-134674 dockerd[4192]: net.(*conn).Read(0xc4202100a8, 0xc4202a8000, 0x8000, 0x8000, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/net/net.go:176 +0x6dApr  9 00:05:07 sd-134674 dockerd[4192]: bufio.(*Reader).Read(0xc420258840, 0xc4202b0038, 0x9, 0x9, 0x9, 0x0, 0xc42003dd58)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/bufio/bufio.go:213 +0x30bApr  9 00:05:07 sd-134674 dockerd[4192]: io.ReadAtLeast(0x3889160, 0xc420258840, 0xc4202b0038, 0x9, 0x9, 0x9, 0xc4203bc600, 0xc42003de18, 0x11a0e38)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/io/io.go:309 +0x86Apr  9 00:05:07 sd-134674 dockerd[4192]: io.ReadFull(0x3889160, 0xc420258840, 0xc4202b0038, 0x9, 0x9, 0x0, 0xc42005a080, 0x3)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/io/io.go:327 +0x58Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/golang.org/x/net/http2.readFrameHeader(0xc4202b0038, 0x9, 0x9, 0x3889160, 0xc420258840, 0x0, 0x0, 0xc4203bc300, 0x2aeedc8)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:237 +0x7bApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/golang.org/x/net/http2.(*Framer).ReadFrame(0xc4202b0000, 0xc42029e2a0, 0x388e160, 0xc4aa5e4690, 0xc4aa5e4690)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:492 +0xa4Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*framer).readFrame(0xc42029e180, 0xc43e34c900, 0xc43e34c900, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http_util.go:544 +0x2fApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*http2Client).reader(0xc4203bc480)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http2_client.go:1057 +0xc0Apr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/vendor/google.golang.org/grpc/transport.newHTTP2ClientApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http2_client.go:250 +0xb8dApr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 83 [select, 35 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*http2Client).controller(0xc4203bc480)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http2_client.go:1130 +0x142Apr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/vendor/google.golang.org/grpc/transport.newHTTP2ClientApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http2_client.go:280 +0xf4cApr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 84 [select, 55145 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc.(*addrConn).transportMonitor(0xc4200844e0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:891 +0x1deApr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/vendor/google.golang.org/grpc.(*ClientConn).resetAddrConnApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:608 +0x6efApr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 99 [select, 55145 minutes]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc.newClientStream.func3(0x38b4a60, 0xc4203bc480, 0xc420084340, 0xc42025e2c0, 0xc420372000)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:241 +0x1cdApr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/vendor/google.golang.org/grpc.newClientStreamApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:240 +0xc7cApr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 43 [chan receive]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/daemon.(*Daemon).execCommandGC(0xc420522200)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/daemon/exec.go:281 +0x158Apr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/daemon.NewDaemonApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/daemon/daemon.go:896 +0x285aApr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 49 [select]:Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*recvBufferReader).Read(0xc42031e0c0, 0xc4205101b0, 0x5, 0x5, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/transport.go:144 +0x2ecApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*Stream).Read(0xc42056e000, 0xc4205101b0, 0x5, 0x5, 0xc489ef6dc0, 0xc420019970, 0xc420019900)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/transport.go:332 +0x5cApr  9 00:05:07 sd-134674 dockerd[4192]: io.ReadAtLeast(0x388e0a0, 0xc42056e000, 0xc4205101b0, 0x5, 0x5, 0x5, 0xc4205dc400, 0xc421991b00, 0xc421991b98)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/io/io.go:309 +0x86Apr  9 00:05:07 sd-134674 dockerd[4192]: io.ReadFull(0x388e0a0, 0xc42056e000, 0xc4205101b0, 0x5, 0x5, 0x0, 0x0, 0x7f26c275e148)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/io/io.go:327 +0x58Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc.(*parser).recvMsg(0xc4205101a0, 0x7fffffff, 0xc42000c0e0, 0xc47d099980, 0x9d, 0xc421991c68, 0x11a1116, 0x2aeedd0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/rpc_util.go:218 +0x69Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc.recv(0xc4205101a0, 0x38ab220, 0x392bc30, 0xc42056e000, 0x0, 0x0, 0x2910420, 0xc4d3592a80, 0x7fffffff, 0x0, ...)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/rpc_util.go:314 +0x4dApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/google.golang.org/grpc.(*clientStream).RecvMsg(0xc420500580, 0x2910420, 0xc4d3592a80, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:376 +0xdaApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/github.com/containerd/containerd/api/services/events/v1.(*eventsSubscribeClient).Recv(0xc42019c070, 0xc421991f10, 0x1, 0x1)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/github.com/containerd/containerd/api/services/events/v1/events.pb.go:213 +0x62Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/libcontainerd.(*client).processEventStream(0xc420106690, 0x38ab9e0, 0xc420150040)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/libcontainerd/client_daemon.go:745 +0x434Apr  9 00:05:07 sd-134674 dockerd[4192]: created by github.com/docker/docker/libcontainerd.(*remote).NewClientApr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/libcontainerd/remote_daemon.go:136 +0x292Apr  9 00:05:07 sd-134674 dockerd[4192]: goroutine 46 [IO wait]:Apr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.runtime_pollWait(0x7f26faa6cbb0, 0x72, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/runtime/netpoll.go:173 +0x57Apr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.(*pollDesc).wait(0xc42032c398, 0x72, 0xffffffffffffff00, 0x3896720, 0x3887298)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/internal/poll/fd_poll_runtime.go:85 +0xaeApr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.(*pollDesc).waitRead(0xc42032c398, 0xc42027c000, 0x8000, 0x8000)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/internal/poll/fd_poll_runtime.go:90 +0x3dApr  9 00:05:07 sd-134674 dockerd[4192]: internal/poll.(*FD).Read(0xc42032c380, 0xc42027c000, 0x8000, 0x8000, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/internal/poll/fd_unix.go:126 +0x18aApr  9 00:05:07 sd-134674 dockerd[4192]: net.(*netFD).Read(0xc42032c380, 0xc42027c000, 0x8000, 0x8000, 0x10, 0x10, 0x27d28a0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/net/fd_unix.go:202 +0x52Apr  9 00:05:07 sd-134674 dockerd[4192]: net.(*conn).Read(0xc4201481e8, 0xc42027c000, 0x8000, 0x8000, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/net/net.go:176 +0x6dApr  9 00:05:07 sd-134674 dockerd[4192]: bufio.(*Reader).Read(0xc4203e24e0, 0xc4202b02d8, 0x9, 0x9, 0x181f07f, 0xc4ae5b99e8, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/bufio/bufio.go:213 +0x30bApr  9 00:05:07 sd-134674 dockerd[4192]: io.ReadAtLeast(0x3889160, 0xc4203e24e0, 0xc4202b02d8, 0x9, 0x9, 0x9, 0xc450f1cdc8, 0x20, 0xc4205dc600)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/io/io.go:309 +0x86Apr  9 00:05:07 sd-134674 dockerd[4192]: io.ReadFull(0x3889160, 0xc4203e24e0, 0xc4202b02d8, 0x9, 0x9, 0xc450f1ce09, 0xc4ae5b9f20, 0xc471f3e120)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/usr/local/go/src/io/io.go:327 +0x58Apr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/golang.org/x/net/http2.readFrameHeader(0xc4202b02d8, 0x9, 0x9, 0x3889160, 0xc4203e24e0, 0x0, 0x0, 0xc4ae5b9e90, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:237 +0x7bApr  9 00:05:07 sd-134674 dockerd[4192]: github.com/docker/docker/vendor/golang.org/x/net/http2.(*Framer).ReadFrame(0xc4202b02a0, 0xc, 0x0, 0x0, 0x0)Apr  9 00:05:07 sd-134674 dockerd[4192]: #011/go/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:492 +0xa4Apr  9 00:05:07 "
36798,0,508,0,0,0,stevvooe,0,"title:daemon: deadlock on startup. description:Running current master, one can arrive at a deadlock on startup. Most goroutines are blocked semaphore acquire, attempting to restore (not checkpoint/restore) containers running in containerd.Reproduce by running a number of containers with health checks enabled:```for i in $(seq 1 50); do docker run -d --health-cmd 'sh -c ""sleep 1""' --health-interval 1s --health-timeout 10s ubuntu sleep 1000000; done```Then shutdown and restart the daemon.Goroutine dump is available at https://gist.github.com/stevvooe/80a15efb43993cc9353496a4af2b6d1d```console~/g/s/g/d/docker 闂傚倸鍊烽悞锕€顭囧▎鎾崇；闁糕剝绋戦崹鍌涖亜韫囨挸顏撮柣鏂挎閺屾稑鐣濋埀顒勫磻濞戭潿鈧?./bundles/binary-daemon/dockerd --version                                                                                                                                                                                                                          闂?limit-healthcheck-concurrency 闂?闂?闂傚倸鍊风粈渚€鎮块崶顒€纾婚柟閭﹀枟閸忔粓鏌ｉ弽褏宕er version dev, build 7a672a7a5c```
"
36787,1,809,0,0,1,subbu165,0,"title:Docker with Systemd - ExecStop not working during container Stop. description:I have been working on running systemd within a container and have customer service start/stop defined as part of systemd service.I had tried hard to fix this up and I couldn't do so. So I had systemd running inside docker like below (DockerFile content):```Dockerfile#Setting up systemdENV container dockerRUN (cd /lib/systemd/system/sysinit.target.wants/; for i in *; do [ $i == systemd-tmpfiles-setup.service ] || rm -f $i; done); \rm -f /lib/systemd/system/multi-user.target.wants/*;\rm -f /etc/systemd/system/*.wants/*;\rm -f /lib/systemd/system/local-fs.target.wants/*; \rm -f /lib/systemd/system/sockets.target.wants/*udev*; \rm -f /lib/systemd/system/sockets.target.wants/*initctl*; \rm -f /lib/systemd/system/basic.target.wants/*;\rm -f /lib/systemd/system/anaconda.target.wants/*;VOLUME [ ""/sys/fs/cgroup"" ]CMD [""/usr/sbin/init""]```I have a service file saved like below in /etc/systemd/system/test.service (inside the container)```[Unit]Description=Setup Platform[Service]Type=oneshotRemainAfterExit=trueExecStart=/bin/echo ""My Test Start!""ExecStop=/bin/echo ""My Test Stop!""[Install]WantedBy=multi-user.target```So now every time the container starts, the ""My Test Start!"" is called successfully. But where as every time when container stops, I could never see the 'My Test Stop!', which means ExecStop never been called during container stop. I have googled Extensively on this issue for the past 2 days. Tried various work arounds, nothing seems to be working. I came across one post too (https://developers.redhat.com/blog/2016/09/13/running-systemd-in-a-non-privileged-container/), where they have said, docker stop sends SIGTERM which is not good enough for systemd to shutdown and we should actually configure stop signal to '--stop-signal SIGRTMIN+3', even this doesn't work for me.I'm using `FROM centos:7.4.1708`, systemd 219 and Docker version 17.12.1-ce, build 7390fc6. I have been slogging it out for past 2/3 days without any success.I'm using `journalctl -u test.service -f` to see the logs and to watch out for ""my Test stop' to be printed before the container exits. But container exits without printing the 'My Test Stop'. This is how I'm verifying.
"
36776,1,2925,42,0,0,codestation,0,"title:docker stack deploy --prune with empty name removes all the swarm services. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Running `docker stack deploy --prune -c docker-compose.yml ''` (the empty name can be done on purpose by using empty quotes or by mistake by passing a empty string as a command line argument) will wipe the entire swarm services and their containers. Docker shouldn't allow to continue the command if the stack name is empty.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. Deploy some services/stacks on the swarm.2. Run `docker stack deploy --prune -c docker-compose.yml ''` with a valid `docker-compose.yml` file**Describe the results you received:**```$ /usr/bin/docker stack deploy --prune -c docker-compose.yml  --with-registry-authRemoving service blog_blogRemoving service consul_consulRemoving service drone_agentRemoving service drone_serverRemoving service gitea_giteaRemoving service gitea_postgresRemoving service gopkg_serverRemoving service monitoring_alertmanagerRemoving service monitoring_cadvisorRemoving service monitoring_grafanaRemoving service monitoring_nodeRemoving service monitoring_prometheusRemoving service portainer_portainerRemoving service registry_privateRemoving service registry_proxyRemoving service traefik_traefikRemoving service traefik_traefik_initCreating service _blogfailed to create service _blog: Error response from daemon: rpc error: code = InvalidArgument desc = name must be valid as a DNS name component```**Describe the results you expected:**The command shouldn't accept an empty stack name, and give an error.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:	18.03.0-ce API version:	1.37 Go version:	go1.9.2 Git commit:	0520e24 Built:	Wed Mar 21 23:05:52 2018 OS/Arch:	linux/amd64 Experimental:	false Orchestrator:	swarmServer: Engine:  Version:	18.03.0-ce  API version:	1.37 (minimum version 1.12)  Go version:	go1.9.4  Git commit:	0520e24  Built:	Wed Mar 21 23:08:31 2018  OS/Arch:	linux/amd64  Experimental:	false```**Output of `docker info`:**```Containers: 22 Running: 17 Paused: 0 Stopped: 5Images: 46Server Version: 18.03.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: 1imyhfi7svxwy3yku8bo5xcwh Is Manager: true ClusterID: u5h6mtutkrzcj7j6f1ynsgrjf Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 10.132.129.222 Manager Addresses:  10.132.129.222:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfd04396dc68220d1cecbe686a6cc3aa5ce3667crunc version: 4fc53a81fb7c994640722ac585fa9ca548971871init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-116-genericOperating System: Ubuntu 16.04.4 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.953GiBName: megpoidID: BPKC:TWAS:YNIR:KFPJ:VRNF:5VR3:OXEO:6NNE:TLM2:4P6D:BGEP:3S5FDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**DigitalOcean droplet, 2vCPU, 2GiB RAM, Ubuntu 16.04 LTS.
"
36772,0,7597,279,0,0,dhaavi,0,"title:fatal error: concurrent map iteration and map write. description:**Description**Docker crashed with a fatal error:```fatal error: concurrent map iteration and map writegoroutine 71835668 [running]:runtime.throw(0x561fd25ae7bf, 0x26)        /usr/lib/go/src/runtime/panic.go:596 +0x97 fp=0xc4272e7110 sp=0xc4272e70f0runtime.mapiternext(0xc4272e7480)        /usr/lib/go/src/runtime/hashmap.go:737 +0x7f0 fp=0xc4272e71c0 sp=0xc4272e7110runtime.mapiterinit(0x561fd2bb2140, 0xc44003ba10, 0xc4272e7480)        /usr/lib/go/src/runtime/hashmap.go:727 +0x2b5 fp=0xc4272e7218 sp=0xc4272e71c0github.com/docker/docker/daemon.(*Daemon).transformContainer(0xc420482800, 0xc42033ae00, 0xc45217c540, 0x0, 0x0, 0x0)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/daemon/list.go:592 +0x844 fp=0xc4272e74f0 sp=0xc4272e7218github.com/docker/docker/daemon.(*Daemon).(github.com/docker/docker/daemon.transformContainer)-fm(0xc42033ae00, 0xc45217c540, 0x0, 0xc420482800, 0x561fd2546700)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/daemon/list.go:115 +0x40 fp=0xc4272e7530 sp=0xc4272e74f0github.com/docker/docker/daemon.(*Daemon).reducePsContainer(0xc420482800, 0xc42033ae00, 0xc45217c540, 0xc4272e7670, 0x20, 0x0, 0xc42114e650)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/daemon/list.go:224 +0x85 fp=0xc4272e7580 sp=0xc4272e7530github.com/docker/docker/daemon.(*Daemon).reduceContainers(0xc420482800, 0xc43fa54ec0, 0xc4272e7670, 0xc42114e680, 0xc42114e680, 0x8, 0x40, 0x561fd2d4b260)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/daemon/list.go:192 +0x114 fp=0xc4272e7630 sp=0xc4272e7580github.com/docker/docker/daemon.(*Daemon).Containers(0xc420482800, 0xc43fa54ec0, 0x561fd256ea05, 0x5, 0x561fd3743f20, 0xc42114e6e8, 0x561fd14200aa)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/daemon/list.go:115 +0x5f fp=0xc4272e7690 sp=0xc4272e7630github.com/docker/docker/api/server/router/container.(*containerRouter).getContainersJSON(0xc421300200, 0x7f72e4f23070, 0xc447e0cab0, 0x561fd36d25e0, 0xc420cfc1c0, 0xc45e1f0c00, 0xc447e0ca20, 0x561fd256db67, 0x4)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/api/server/router/container/container_routes.go:51 +0x211 fp=0xc4272e7728 sp=0xc4272e7690github.com/docker/docker/api/server/router/container.(*containerRouter).(github.com/docker/docker/api/server/router/container.getContainersJSON)-fm(0x7f72e4f23070, 0xc447e0cab0, 0x561fd36d25e0, 0xc420cfc1c0, 0xc45e1f0c00, 0xc447e0ca20, 0x7f72e4f23070, 0xc447e0cab0)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/api/server/router/container/container.go:44 +0x6b fp=0xc4272e7780 sp=0xc4272e7728github.com/docker/docker/api/server/middleware.ExperimentalMiddleware.WrapHandler.func1(0x7f72e4f23070, 0xc447e0cab0, 0x561fd36d25e0, 0xc420cfc1c0, 0xc45e1f0c00, 0xc447e0ca20, 0x7f72e4f23070, 0xc447e0cab0)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/api/server/middleware/experimental.go:27 +0xda fp=0xc4272e77e8 sp=0xc4272e7780github.com/docker/docker/api/server/middleware.VersionMiddleware.WrapHandler.func1(0x7f72e4f23070, 0xc447e0ca80, 0x561fd36d25e0, 0xc420cfc1c0, 0xc45e1f0c00, 0xc447e0ca20, 0xc43fa54a80, 0xc42114ea00)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/api/server/middleware/version.go:48 +0x55f fp=0xc4272e7910 sp=0xc4272e77e8github.com/docker/docker/pkg/authorization.(*Middleware).WrapHandler.func1(0x7f72e4f23070, 0xc447e0ca80, 0x561fd36d25e0, 0xc420cfc1c0, 0xc45e1f0c00, 0xc447e0ca20, 0x7f72e4f23070, 0xc447e0ca80)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/pkg/authorization/middleware.go:54 +0x873 fp=0xc4272e7ac8 sp=0xc4272e7910github.com/docker/docker/api/server.(*Server).makeHTTPHandler.func1(0x561fd36d25e0, 0xc420cfc1c0, 0xc45e1f0c00)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/api/server/server.go:140 +0x21c fp=0xc4272e7bc0 sp=0xc4272e7ac8net/http.HandlerFunc.ServeHTTP(0xc427a50440, 0x561fd36d25e0, 0xc420cfc1c0, 0xc45e1f0c00)        /usr/lib/go/src/net/http/server.go:1942 +0x46 fp=0xc4272e7be8 sp=0xc4272e7bc0github.com/docker/docker/vendor/github.com/gorilla/mux.(*Router).ServeHTTP(0xc428636410, 0x561fd36d25e0, 0xc420cfc1c0, 0xc45e1f0c00)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/vendor/github.com/gorilla/mux/mux.go:103 +0x257 fp=0xc4272e7cd8 sp=0xc4272e7be8github.com/docker/docker/api/server.(*routerSwapper).ServeHTTP(0xc427a5fce0, 0x561fd36d25e0, 0xc420cfc1c0, 0xc45e1f0c00)        /home/buildozer/aports/community/docker/src/moby-17.05.0-ce/.gopath/src/github.com/docker/docker/api/server/router_swapper.go:29 +0x72 fp=0xc4272e7d10 sp=0xc4272e7cd8net/http.serverHandler.ServeHTTP(0xc42014ce70, 0x561fd36d25e0, 0xc420cfc1c0, 0xc45e1f0c00)        /usr/lib/go/src/net/http/server.go:2568 +0x94 fp=0xc4272e7d58 sp=0xc4272e7d10net/http.(*conn).serve(0xc4256735e0, 0x561fd36d4120, 0xc45070ca00)        /usr/lib/go/src/net/http/server.go:1825 +0x614 fp=0xc4272e7fc8 sp=0xc4272e7d58runtime.goexit()        /usr/lib/go/src/runtime/asm_amd64.s:2197 +0x1 fp=0xc4272e7fd0 sp=0xc4272e7fc8created by net/http.(*Server).Serve        /usr/lib/go/src/net/http/server.go:2668 +0x2d0```**Steps to reproduce the issue:**not able to reproduce**Describe the results you received:**docker crashed**Describe the results you expected:**no crashing ;)**Additional information you deem important (e.g. issue happens only occasionally):**Single server, swarm mode. Has been running for months with occasional high load. Almost no load when crash happened.**Output of `docker version`:**```Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.8.1 Git commit:   v17.05.0-ce Built:        Tue May 16 10:10:15 2017 OS/Arch:      linux/amd64Server: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.8.1 Git commit:   v17.05.0-ce Built:        Tue May 16 10:10:15 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 42 Running: 22 Paused: 0 Stopped: 20Images: 17Server Version: 17.05.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: 9b86viugse9yh6v2zxemg1cqq Is Manager: true ClusterID: avuiyle3b90t8usyebc9auosl Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.205.1 Manager Addresses:  192.168.205.1:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6facb77383876aeff8a6944dde66b3089574Kernel Version: 4.9.32-0-virthardenedOperating System: Alpine Linux v3.6OSType: linuxArchitecture: x86_64CPUs: 32Total Memory: 62.83GiBName: REDACTEDID: NMFE:I2XP:2RZD:D7IT:PMTF:ANAA:365S:PQ2G:CPHI:X4X5:P4MK:JAV5Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: REDACTEDRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**run on an ESXI instance
"
36764,0,6976,2,0,0,notanaverageman,0,"title:Multistage COPY operations in LCOW fails if the source image has more than 56 commands.. description:**Description**While building an image with over 50 COPY operations from other images docker gives following error:`COPY failed: Forbidden path outside the build context: test ()`Docker does not write the full error. I have changed the codes to print the actual error message. It is something like this:```failed to copy files: svm.runProcess: command mount -t overlay overlay -olowerdir=/tmp/ac584b2bf23b1850f95d26f5f9fe788fdb38f024f4b588706f9adab142745ebb:/tmp/b058ef8dc02f3b0704255e7c07b3d26f129152c614ae3f10dcdb40129aef4cee:/tmp/9856e8860ee641e2b09a48d0acccad741f8a8b54d29323c275c68a70aee2db66:/tmp/5e90b26e0577694a8437a6ebab87a95d93eea574a1b93c24ee4a5127d83c83c7:/tmp/d8225f78bcc6df46b3d0c497bb68562333595a9a656e117d675616e31129ffa8:/tmp/8308a98b961813400977fc3d77f7dd4a3e2f20208a5318f65771fc4357c26b53:/tmp/697752da9f17759760387aab800cf3ab464cc265d48f65dfd9c44b4b38dbf391:/tmp/90e1f09e3cb8a8e439ef666d35c66aa9e1dabcb47f5bea1587b81839f54ad14e:/tmp/c3b039f5cc7b34d22b074337e0795120bbade74d8e0881e1f952551ed557638d:/tmp/9b780c238fec09f08e90fa795abb20770a40e705556dd16eb86948fda4d95b7c:/tmp/657d3026000e51f70581b7ec09085f45090995cbb4156b5f375396ff5410ebcc:/tmp/0748ffb8e4c5a0841bc02d0d95dca7e36d913e20b405a0110665ff927123665b:/tmp/049697104d295f71dbd35643a4d192c0cb9aa781d17d558f82639b123e32572c:/tmp/e55677c04935443363320fea8a96ff46179d7ac01e808b9e0a9b0c5461b4fded:/tmp/d0dc7843a71f2c4e3ec55a72787b7ab01289b97d711cb376f442f306c514ae79:/tmp/44467e4bf1377f6bbdac2521e36f450c9076f59f3f47dc365a98c0bf94319451:/tmp/25a556a92ebe834674bf1be93a27559b2c842ef85207e8277378911abe800c6e:/tmp/b27320c9edea679af71e97c2c27d4c9ec6b55e66ca129a58f9d5b819cee4a794:/tmp/68310bbebb145246a72ac691c5215760f540974fb26a955963a99899ebf4a224:/tmp/8c44e31e47470672ab7cd8f019fc1c593089e9562f24222c6b7d1006458ca949:/tmp/2f6507b01201917261fab6b1b32cbef01ec37174497a2eabb0e62da9d5b7e8ab:/tmp/9b990bfc7f2b9ba92278f278a167be25234cbced2b19cd3fbbcced5302839efe:/tmp/734e90b481e8fdd2da47d07f3ad7afbc6cd9b9151c2f67599920803d805a7b29:/tmp/a8253cca3540f9e76a48c05b4671ccd91617e9f604b25ace22f483cae504157e:/tmp/a1b00e00886530fbd2b3d10c2debafe02be083b35da394a8818d129bac9a27a8:/tmp/8e983c37b0676ba63650b8aaa2266493a6c03dcd7e741169318b06670c9176d4:/tmp/67248fa878d70e85c59e3018b129383e130dbe5984f73cf65b18879e380adceb:/tmp/f8b42faebe52c312b5b0c76dcbfafb8f3cab5f6742cc430e6add02b7e86f34d1:/tmp/396fab63cd4baf815dd559c83275aa1cd7254b22005a939cd3eb943ce37dbaff:/tmp/4d8a4b6c43ccb2549385b6456e9945209911fa2b45c7301f79f810a91781b8e4:/tmp/db02eff6417ce29a8fa8d5df8c5bc0fb2db9c763a7350952db777f6b3e9f8456:/tmp/610b6e7c27d57847da697fc26f0ceffdb8e66d6fd8ab78b377db521008b361f9:/tmp/3b1e8147b693b273c044d31a194524f6aefc1dd6708ac6a1c00cdd817fcb0004:/tmp/d1f370bc1f5db4830e585a05dbd005e4f5d2f27f7c240c9f486ddb0d7eb6954c:/tmp/46d7abc3697064e1f7018e5fb5b2085571e5fbe74332570635a6e571966c7c29:/tmp/23e068193b591383271b78eec92998114e811111eb933fd5808302631ce32843:/tmp/e7cec04e351a1976ca396c5bcfbf60b21565012c66ba8dec053cfdcf1a158bc6:/tmp/00bb41e122a67e8d98795522a141ff586b0d71737f33104c621563cd6843afad:/tmp/27a8ae212bee8b1abdff4eba0e7fe8ea1d572efcf1bc1ac93d75f2a9308c0809:/tmp/70bcb1394a8f7d6667929b4a1bdc57ffd54d8a8a423e391e0ce6d9c8b205f86e:/tmp/d88fbf9b75e88420304344114086a3a151c89a0224d1d0ec6e28edea840f2c60:/tmp/416def6231e4b02156867f939ac9f2fd5ddc211f6dcab54feb66094754152db2:/tmp/8aa5294cb21aab7c28a346fac88b90490ef567c28c96604f045e7855bcf86018:/tmp/510de218389e5787030c46436840b85a7669a971cd8b7893d871076d05bcb440:/tmp/c312c8301aa15f06f087f62b6d50e5f682bb49d1c1c85f4af0572532ae4d3135:/tmp/06136625ac03b1f3fbe3ed16fac5d763a0237719265965108432d38b6f43af11:/tmp/48266d4870e9a65a2196312a1df7df6d54834e1901e83ee7a89cf6d15c3d6aef:/tmp/ce31a3bbe0cfd6ba58c04d897d6475d166908b78231b3432092011bb62d3da36:/tmp/d6ffd30a4becac380a7525f67e1843e9f781f1f70c58c7c204d7e9f1c4002a83:/tmp/d9c872d1b12db539acd24ea950392d93858ee4992220eb60d10e6474fc08161d:/tmp/a340b040978521cb0df4ce2b1789e52d08781d568e915dff07abd8e73d063781:/tmp/82c2dadae70bd0e14da45c34bf23d92b7d167579860f2fac690b9de7a9e72890:/tmp/ff9373e51335733a04219a47e32b8013d437409efb46933ec1364c4b21ce2296:/tmp/239e42b6555538224b25f90184da2e1231471caac31fdd057d949188123af61b:/tmp/39e11597839e77447636789025fd9c028f297414ad880003d60108449cfc61dc:/tmp/36b6a2ccc55d35201c4428d7c38b0dee5de7aabd6d41ac0869c1c082cb99f594,upperdir=/tmp/f70353ec17f61ed4ecb87904cb38cf32091d6deebb9833ee2fda58a3ce681442/upper,workdir=/tmp/f70353ec17f61ed4ecb87904cb38cf32091d6deebb9833ee2fda58a3ce681442/work /tmp/f70353ec17f61ed4ecb87904cb38cf32091d6deebb9833ee2fda58a3ce681442-mount failed with exit code 255```I think the cause is the length of the command, which is over 4096. Probably, this is the limit for command line arguments and the command cannot be executed correctly.**Steps to reproduce the issue:**Run the follwing Dockerfile with: `docker build --platform=linux .````DockerfileFROM alpine as firstRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testRUN echo test > /testFROM alpineCOPY --from=first /test /test```**Output of `docker version`:**```Client: Version:       18.03.0-ce API version:   1.37 Go version:    go1.9.4 Git commit:    0520e24 Built: Wed Mar 21 23:06:28 2018 OS/Arch:       windows/amd64 Experimental:  false Orchestrator:  swarmServer: Engine:  Version:      18.03.0-ce  API version:  1.37 (minimum version 1.24)  Go version:   go1.9.4  Git commit:   0520e24  Built:        Wed Mar 21 23:21:06 2018  OS/Arch:      windows/amd64  Experimental: true```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 123Server Version: 18.03.0-ceStorage Driver: windowsfilter (windows) lcow (linux) Windows: LCOW:Logging Driver: json-filePlugins: Volume: local Network: ics l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd gelf json-file logentries splunk syslogSwarm: inactiveDefault Isolation: hypervKernel Version: 10.0 16299 (16299.15.amd64fre.rs3_release.170928-1534)Operating System: Windows 10 EnterpriseOSType: windowsArchitecture: x86_64CPUs: 8Total Memory: 15.89GiBName: YUSUFG-PCID: 7BCW:GTLJ:2FQB:KV3J:NRRE:IHTW:6C3B:YOCE:65GK:NKHJ:IS3D:3LNJDocker Root Dir: C:\ProgramData\DockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Windows 10 1709 physical machine.
"
36661,0,2199,94,1,0,jahkeup,0,"title:Container HEALTHCHECKs can lead to hanging API calls and bad State. description:**Description**Occasionally the Docker daemon stops responding to interactions with a containers that have HEALTHCHECKs. The problem presents itself in [several older versions of Docker and the latest packaged versions on Ubuntu and v17.12.0-ce on Amazon Linux](https://github.com/jahkeup/health-stats-repro#tested-against).By our observations, this looks to be a race condition that is met with a deadlock that prevents further calls against affected containers.This observed issue may be related to https://github.com/moby/moby/issues/35933 . I'm working on bisecting the releases (using https://github.com/docker/docker-ce) using this repro to narrow down the problem further in any case.**Steps to reproduce the issue:**A repro case has been [built and run against several version of docker](https://github.com/jahkeup/health-stats-repro) with positive results after a few rounds of execution (I recommend 10-20 rounds to tickle the bug). There likely isn't anything specific about the 2 containers, but it has been positively triggering the bug for this test.1. Build container image with HEALTHCHECK defined (`echo hello` every `1s`)2. Start 2 containers using image3. Wait some time (`10s` in our test)4. Stop containers5. Inspect containers**Describe the results you received:**Started containers appear to continue running and to be healthy despite being non-responsive. ```bashubuntu@ip-172-31-37-156:~$ docker psCONTAINER ID        IMAGE                      COMMAND               CREATED             STATUS                    PORTS               NAMES0cf518c205f7        docker-poke:healthchecks   ""sh -c 'sleep 30m'""   17 minutes ago      Up 17 minutes (healthy)                       sad_hugleubuntu@ip-172-31-37-156:~$ docker inspect 0cf518c205f7^C```Additionally, the output of `docker ps`  will continue reporting that the container is still up and running even though the process will exit after 30m (started with `sleep 30m`).```bash0cf518c205f7        docker-poke:healthchecks   ""sh -c 'sleep 30m'""   37 minutes ago      Up 37 minutes (healthy)                               sad_hugle```**Describe the results you expected:**I expected that I would be able to inspect this container.```bashdocker inspect 0cf518c205f7{   ...}```**Additional information you deem important (e.g. issue happens only occasionally):**This issue is readily made apparent with a few concurrent runs, but otherwise lies dormant even with many serial runs.**Output of `docker version`:**```Client: Version:       17.12.1-ce API version:   1.35 Go version:    go1.9.4 Git commit:    7390fc6 Built: Tue Feb 27 22:17:40 2018 OS/Arch:       linux/amd64Server: Engine:  Version:      17.12.1-ce  API version:  1.35 (minimum version 1.12)  Go version:   go1.9.4  Git commit:   7390fc6  Built:        Tue Feb 27 22:16:13 2018  OS/Arch:      linux/amd64  Experimental: false```**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 5Server Version: 17.12.1-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 4 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9b55aab90508bd389d7654c4baf173a981477d55runc version: 9f9c96235cc97674e935002fc3d78361b696a69einit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-1052-awsOperating System: Ubuntu 16.04.4 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.625GiBName: ip-172-31-37-156ID: L4W4:V4WA:OHSS:QTGL:DRJG:32GX:7DKK:FFLO:WKR2:IJYV:NKDG:GWRADocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Ubuntu 16.04 on AWS EC2 using the [repro runner](https://github.com/jahkeup/health-stats-repro#ubuntu)Thanks @samuelkarp!| Package                   | Result ||---------------------------|--------|| `17.09.1~ce-0~ubuntu`     | pass   || `17.10.0~ce-0~ubuntu`     | pass   || `17.11.0~ce-0~ubuntu`     | pass   || `17.12.0~ce~rc1-0~ubuntu` | fail   || `17.12.0~ce-0~ubuntu`     | fail   || `17.12.1~ce-0~ubuntu`     | fail   || `18.01.0~ce-0~ubuntu`     | fail   || `18.02.0~ce-0~ubuntu`     | fail   || `18.03.0~ce~rc4-0~ubuntu` | fail   |Amazon Linux on AWS EC2 using the [repro runner](https://github.com/jahkeup/health-stats-repro#amazon-linux)Thanks @jhaynes!| Package      | Result ||--------------|--------|| `17.12.0-ce` | fail   || `17.09.1-ce` | pass   |
"
36628,0,2142,0,0,0,tobbenb,0,"title:Host owner:group not honored in container for devices in Docker CE 17.12.1. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**When passing through a device with the device tag `--device=`, host user:group are not honored in the container. It's changed to root:root regardless of what is set for the device in host.This doesn't happen in 17.12.0.Problem happens on both Ubuntu 16.04.04 LTS and unRAID 6.5 (Linux 4.14.26-unRAID x86_64). They both use different kernel version, so problem is in Docker, as verified by installing different versions.This is the permissions in host:```saarg@UbuntuVMDev:~$ ls -la /dev/ttyUSB0crw-rw---- 1 root dialout 188, 0 mars  18 15:41 /dev/ttyUSB0```This is the permissions in the container on 17.12.1:```saarg@UbuntuVMDev:~$ docker exec -it oscam bashroot@9e49a208106c:/$ ls -la /dev/ttyUSB0 crw-rw---- 1 root root 188, 0 Mar 18 15:07 /dev/ttyUSB0```**Steps to reproduce the issue:**1. Install Docker CE 17.12.12. Create a container with a device passed through not owned by root:root`docker run -d --name=oscam -v /home/saarg/config/:/config -e PGID=1000 -e PUID=1000 -p 8888:8888 --device=/dev/ttyUSB0 linuxserver/oscam`**Describe the results you received:**```saarg@UbuntuVMDev:~$ docker exec -it oscam bashroot@9e49a208106c:/$ ls -la /dev/ttyUSB0 crw-rw---- 1 root root 188, 0 Mar 18 15:07 /dev/ttyUSB0```**Describe the results you expected:**```saarg@UbuntuVMDev:~$ ls -la /dev/ttyUSB0crw-rw---- 1 root dialout 188, 0 mars  18 15:41 /dev/ttyUSB0```**Additional information you deem important (e.g. issue happens only occasionally):**In my example I'm using a USB smartcard reader passed through to linuxserver/oscam container, but you can pass through a DVB card, GPU or other device to a container and get the same result.**Output of `docker version`:**```saarg@UbuntuVMDev:~$ docker versionClient: Version:	17.12.1-ce API version:	1.35 Go version:	go1.9.4 Git commit:	7390fc6 Built:	Tue Feb 27 22:17:40 2018 OS/Arch:	linux/amd64Server: Engine:  Version:	17.12.1-ce  API version:	1.35 (minimum version 1.12)  Go version:	go1.9.4  Git commit:	7390fc6  Built:	Tue Feb 27 22:16:13 2018  OS/Arch:	linux/amd64  Experimental:	false```**Output of `docker info`:**```saarg@UbuntuVMDev:~$ docker infoContainers: 6 Running: 1 Paused: 0 Stopped: 5Images: 20Server Version: 17.12.1-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 61 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9b55aab90508bd389d7654c4baf173a981477d55runc version: 9f9c96235cc97674e935002fc3d78361b696a69einit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-59-genericOperating System: Ubuntu 16.04.4 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.859GiBName: UbuntuVMDevID: MZ4C:VHPR:JLKH:AG4E:GZOK:O2ZG:3BET:4KGH:VRWJ:PZRF:NB6A:42ZDDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
36608,0,393,0,0,0,lowenna,0,"title:#36519 causes daemon to continually spin CPU. description:https://github.com/moby/moby/pull/36519 changed daemon/stats/collector.go so that `Run()` sits in a tight loop spinning the CPU. Just starting the docker daemon is enough, no client operations neededIt spins as follows:```1	for {		// it does not make sense in the first iteration,		// but saves allocations in further iterations2		pairs = pairs[:0]3		s.m.Lock()4		for container, publisher := range s.publishers {			// copy pointers here to release the lock ASAP			pairs = append(pairs, publishersPair{container, publisher})		}5		s.m.Unlock()6		if len(pairs) == 0 {7			continue --> 1		}```@stevvooe  @thaJeztah 
"
36579,1,925,22,0,0,dgageot,0,"title:Segmentation violation with `docker build --compress --stream`. description:Running `echo ""FROM alpine"" | docker build --compress --stream . -f -` from an empty (or non-empty) folder produces this error:```panic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x4554000]goroutine 50 [running]:github.com/docker/cli/cli/command/image/build.Compress.func1(0xc42000e040, 0x0, 0x0)	/go/src/github.com/docker/cli/cli/command/image/build/context.go:389 +0x70created by github.com/docker/cli/cli/command/image/build.Compress	/go/src/github.com/docker/cli/cli/command/image/build/context.go:384 +0x102``````docker versionClient: Version:	18.02.0-ce-rc1 API version:	1.35 Go version:	go1.9.2 Git commit:	5e1d90a Built:	Thu Jan 25 00:33:50 2018 OS/Arch:	darwin/amd64 Experimental:	true Orchestrator:	kubernetesServer: Engine:  Version:	18.02.0-ce-rc1  API version:	1.36 (minimum version 1.12)  Go version:	go1.9.3  Git commit:	5e1d90a  Built:	Thu Jan 25 00:40:43 2018  OS/Arch:	linux/amd64  Experimental:	true```
"
36576,0,521,298,0,0,runcom,0,"title:Memory leak with authorization plugins. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. enable any authorization plugin2. docker cp container:/ /local/root3. watch the OOM (which causes docker to restart)- craete a vm with 2G RAM and no swapuse this reproducer:```#!/bin/bashset -xeuo pipefaildocker run --detach --name cnt docker.io/openshift/origin:v3.7.1 sleep infinity || truefor i in $(seq 10); do  docker cp cnt:/ /tmp/oc-usrdone```**Describe the results you received:**OOM panic```github.com/docker/docker/pkg/authorization.(*responseModifier).Write(0xc4229c9000, 0xc422248000, 0x8000, 0x8000, 0x8000, 0x0, 0x0)/builddir/build/BUILD/docker-774336db27bb8931c1705e47781b3842d290c968/_build/src/github.com/docker/docker/pkg/authorization/response.go:124 +0x125 fp=0xc4202c73f0 sp=0xc4202c7388```**Describe the results you expected:**no OOM**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```latest```**Output of `docker info`:**```latest```**Additional environment details (AWS, VirtualBox, physical, etc.):**if you disable the authorization plugin, no oom happening@cpuguy83 
"
36561,0,4108,298,0,0,vdemeester,1,"title:Daemon panics on container export after a restart. description:**Description**Unable to export a container after a daemon restart. The daemon panics.**Steps to reproduce the issue:**1. `docker run --name mynginx -d nginx`2. restart the docker daemon3. `docker export mynginx > foo.tar**Describe the results you received:**```error during connect: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.35/containers/e6891c6c5c89fe91631d252b707563041f5106bef051c801c56cbb5a9c1ad9f9/export: EOF```Daemon panics with the following stack```2018-03-12 12:37:17.409021 I | http: panic serving @: runtime error: invalid memory address or nil pointer dereferencegoroutine 7405 [running]:net/http.(*conn).serve.func1(0xc420c099a0)	/usr/local/go/src/net/http/server.go:1697 +0xd2panic(0x21655c0, 0x2e71f70)	/usr/local/go/src/runtime/panic.go:491 +0x287github.com/docker/docker/daemon.(*Daemon).containerExport(0xc420448240, 0xc420448480, 0x0, 0x0, 0x0, 0x0)	/go/src/github.com/docker/docker/daemon/export.go:69 +0x31agithub.com/docker/docker/daemon.(*Daemon).ContainerExport(0xc420448240, 0xc4202480d6, 0xc, 0x2e9e020, 0xc42137e000, 0x0, 0x0)	/go/src/github.com/docker/docker/daemon/export.go:37 +0x2f4github.com/docker/docker/api/server/router/container.(*containerRouter).getContainersExport(0xc4201343c0, 0x7fcfcd3a53c8, 0xc421b62e40, 0x2eb8be0, 0xc42137e000, 0xc42140e500, 0xc421b62d50, 0x190b3c6, 0x4)	/go/src/github.com/docker/docker/api/server/router/container/container_routes.go:159 +0xd3github.com/docker/docker/api/server/router/container.(*containerRouter).(github.com/docker/docker/api/server/router/container.getContainersExport)-fm(0x7fcfcd3a53c8, 0xc421b62e40, 0x2eb8be0, 0xc42137e000, 0xc42140e500, 0xc421b62d50, 0x7fcfcd3a53c8, 0xc421b62e40)	/go/src/github.com/docker/docker/api/server/router/container/container.go:37 +0x6bgithub.com/docker/docker/api/server/middleware.ExperimentalMiddleware.WrapHandler.func1(0x7fcfcd3a53c8, 0xc421b62e40, 0x2eb8be0, 0xc42137e000, 0xc42140e500, 0xc421b62d50, 0x7fcfcd3a53c8, 0xc421b62e40)	/go/src/github.com/docker/docker/api/server/middleware/experimental.go:27 +0xdagithub.com/docker/docker/api/server/middleware.VersionMiddleware.WrapHandler.func1(0x7fcfcd3a53c8, 0xc421b62db0, 0x2eb8be0, 0xc42137e000, 0xc42140e500, 0xc421b62d50, 0xc420248b00, 0xc422326000)	/go/src/github.com/docker/docker/api/server/middleware/version.go:62 +0x425github.com/docker/docker/pkg/authorization.(*Middleware).WrapHandler.func1(0x7fcfcd3a53c8, 0xc421b62db0, 0x2eb8be0, 0xc42137e000, 0xc42140e500, 0xc421b62d50, 0x10, 0x401557)	/go/src/github.com/docker/docker/pkg/authorization/middleware.go:59 +0x83dgithub.com/docker/docker/api/server/middleware.DebugRequestMiddleware.func1(0x7fcfcd3a53c8, 0xc421b62db0, 0x2eb8be0, 0xc42137e000, 0xc42140e500, 0xc421b62d50, 0x7fcfcd3a53c8, 0xc421b62db0)	/go/src/github.com/docker/docker/api/server/middleware/debug.go:22 +0x180github.com/docker/docker/api/server.(*Server).makeHTTPHandler.func1(0x2eb8be0, 0xc42137e000, 0xc42140e500)	/go/src/github.com/docker/docker/api/server/server.go:137 +0x1c8net/http.HandlerFunc.ServeHTTP(0xc420bb9260, 0x2eb8be0, 0xc42137e000, 0xc42140e500)	/usr/local/go/src/net/http/server.go:1918 +0x46github.com/docker/docker/vendor/github.com/gorilla/mux.(*Router).ServeHTTP(0xc420b27e00, 0x2eb8be0, 0xc42137e000, 0xc42140e500)	/go/src/github.com/docker/docker/vendor/github.com/gorilla/mux/mux.go:103 +0x22dgithub.com/docker/docker/api/server.(*routerSwapper).ServeHTTP(0xc420db5f00, 0x2eb8be0, 0xc42137e000, 0xc42140e500)	/go/src/github.com/docker/docker/api/server/router_swapper.go:29 +0x72net/http.serverHandler.ServeHTTP(0xc420335790, 0x2eb8be0, 0xc42137e000, 0xc42140e500)	/usr/local/go/src/net/http/server.go:2619 +0xb6net/http.(*conn).serve(0xc420c099a0, 0x2eba8a0, 0xc421258b00)	/usr/local/go/src/net/http/server.go:1801 +0x71fcreated by net/http.(*Server).Serve	/usr/local/go/src/net/http/server.go:2720 +0x28a```**Describe the results you expected:**No error :stuck_out_tongue_closed_eyes: **Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:       17.12.0-ce API version:   1.35 Go version:    go1.9.3 Git commit:    486a48d2701493bb65385788a291e36febb44ec1 Built: Fri Jan 26 03:13:34 2018 OS/Arch:       linux/amd64 Experimental:  trueServer: Engine:  Version:      17.12.0-ce  API version:  1.36 (minimum version 1.12)  Go version:   go1.9.3  Git commit:   486a48d2701493bb65385788a291e36febb44ec1  Built:        Thu Jan  1 00:00:01 1970  OS/Arch:      linux/amd64  Experimental: true```But this is also true for version after that (tested on 18.03 RCs)
"
36547,0,347,200,0,0,thaJeztah,0,"title:Flaky test TestServiceWithPredefinedNetwork. description:This test was added recently in https://github.com/moby/moby/pull/36316, but is failing on a lot of PR's with:```13:46:02 --- FAIL: TestServiceWithPredefinedNetwork (12.36s)13:46:02 	daemon.go:283: [d47ab7ceb5568] waiting for daemon to start13:46:02 	daemon.go:315: [d47ab7ceb5568] daemon started13:46:02 	service_test.go:52: timeout hit after 10s: task count at 1 waiting for 013:46:02 	daemon.go:273: [d47ab7ceb5568] exiting daemon13:46:02 FAIL```Failure is in the teardown of the test; https://github.com/moby/moby/blob/0b0af855ae28698f8e3dc97cdc2a46e714ce6b6a/integration/network/service_test.go#L52/cc @selansen
"
36535,1,1553,101,0,0,krasi-georgiev,0,"title:docker -H unix:///var/run/docker.sock tries to connect through https. description:I have docker-machine installed and it has now set the env variables that the client talks to a remote docker daemon. I also have a local docker daemon install and trying to  make the client talk to the local daemon again.```docker -H unix:///var/run/docker.sock ps```returns an error```error during connect: Get https://%2Fvar%2Frun%2Fdocker.sock/v1.35/containers/json: dial tcp: lookup /var/run/docker.sock: no such host```to my surprise the client still tries to talk via https , but why? after a bit of troubleshooting I found out that this bug is caused by the `DOCKER_TLS_VERIFY` variable.so if I `unset DOCKER_TLS_VERIFY`  it all works as expected and I can talk to the local daemon using```docker -H unix:///var/run/docker.sock ps``````Docker version 18.02.0-ce-rc1, build 5e1d90a``````Containers: 13 Running: 0 Paused: 0 Stopped: 13Images: 7Server Version: 18.02.0-ce-rc1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9b55aab90508bd389d7654c4baf173a981477d55runc version: 9f9c96235cc97674e935002fc3d78361b696a69einit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.14.14-300.fc27.x86_64Operating System: Fedora 27 (Workstation Edition)OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 30.8GiBName: lenovo-p50ID: ATCS:YLF5:PWGI:BGCD:YHDE:65H6:JCRZ:NC6E:TQBG:DJVZ:D626:RESNDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseThis is fedora 27Linux lenovo-p50 4.14.14-300.fc27.x86_64 #1 SMP Fri Jan 19 13:19:54 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux```
"
36500,0,443,200,0,0,thaJeztah,0,"title:Flaky test: TestLogsContainerMuchBiggerThanPage (on s390x?). description:Seen this failing a couple of times; https://jenkins.dockerproject.org/job/Docker-PRs-s390x/8775/console```23:25:43 ----------------------------------------------------------------------23:25:43 FAIL: docker_cli_logs_test.go:29: DockerSuite.TestLogsContainerMuchBiggerThanPage23:25:43 23:25:43 docker_cli_logs_test.go:30:23:25:43     testLogsContainerPagination(c, 33000)23:25:43 docker_cli_logs_test.go:38:23:25:43     c.Assert(out, checker.HasLen, testLen+1)23:25:43 ... obtained string = """"23:25:43 ... n int = 3300123:25:43 ```
"
36497,1,1766,9,0,0,rreinurm,0,"title:Can't add label without format key=value to container. description:**Description**Since version 18.03.0-ce-rc1, its not possible to add labels to containers just specifying key-only meaning with empty string as described here https://docs.docker.com/engine/reference/commandline/run/#set-metadata-on-container--l-label-label-fileI think issue was introduced byhttps://github.com/docker/cli/pull/838because validation function https://github.com/docker/cli/blob/2bfac7fcdafeafbd2f450abb6d1bb3106e4f3ccb/opts/opts.go#L268-L275 checks presence of  `=`**Steps to reproduce the issue:**1. docker run --rm --label mylabel alpine true**Describe the results you received:**invalid argument ""mylabel"" for ""-l, --label"" flag: bad attribute format: mylabel**Describe the results you expected:**Container should be created with provided label key as mylabel and value as empty string**Output of `docker version`:**```Client: Version:	18.03.0-ce-rc1 API version:	1.37 Go version:	go1.9.4 Git commit:	c160c73 Built:	Thu Feb 22 02:34:03 2018 OS/Arch:	darwin/amd64 Experimental:	false Orchestrator:	swarmServer: Engine:  Version:	18.03.0-ce-rc1  API version:	1.37 (minimum version 1.12)  Go version:	go1.9.4  Git commit:	c160c73  Built:	Thu Feb 22 02:42:37 2018  OS/Arch:	linux/amd64  Experimental:	true```**Output of `docker info`:**```ontainers: 6 Running: 4 Paused: 0 Stopped: 2Images: 8Server Version: 18.03.0-ce-rc1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfd04396dc68220d1cecbe686a6cc3aa5ce3667crunc version: 6c55f98695e902427906eed2c799e566e3d3dfb5init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.75-linuxkit-aufsOperating System: Docker for MacOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952GiBName: linuxkit-025000000001ID: CQKC:26XS:WAJZ:CGOV:VLVH:QB23:LCGD:6OCQ:77NQ:FDZI:ZG36:LMQ4Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 47 Goroutines: 61 System Time: 2018-03-06T12:41:31.913991655Z EventsListeners: 3HTTP Proxy: docker.for.mac.http.internal:3128HTTPS Proxy: docker.for.mac.http.internal:3129Registry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Docker-for-Mac
"
36496,1,2343,0,0,0,KamilKopaczyk,0,"title:""unless-stopped"" containers are not started after daemon restart. description:**Description**Containers with restart policy ""unless-stopped"" are stopped after restarting docker daemon. Please take a look at `docker info` output, as it's printing confusing information versus what `docker ps` shows.**Steps to reproduce the issue:**1. Run container with restart policy set to ""unless-stopped""2. Execute `service docker restart`3. Execute `docker ps`**Describe the results you received:**```CONTAINER ID        IMAGE                                                                                        COMMAND                  CREATED             STATUS                          PORTS                           NAMES```**Describe the results you expected:**```CONTAINER ID        IMAGE                                                                                        COMMAND                  CREATED             STATUS                          PORTS                           NAMES<list of containers that were running before restart>```**Additional information you deem important (e.g. issue happens only occasionally):**--**Output of `docker version`:**```Client: Version:	18.02.0-ce API version:	1.36 Go version:	go1.9.3 Git commit:	fc4de44 Built:	Wed Feb  7 21:16:37 2018 OS/Arch:	linux/amd64 Experimental:	false Orchestrator:	swarmServer: Engine:  Version:	18.02.0-ce  API version:	1.36 (minimum version 1.12)  Go version:	go1.9.3  Git commit:	fc4de44  Built:	Wed Feb  7 21:15:09 2018  OS/Arch:	linux/amd64  Experimental:	false```**Output of `docker info`:****Please note that `docker info` shows that 99 containers are running**```Containers: 124 Running: 99 Paused: 0 Stopped: 25Images: 174Server Version: 18.02.0-ceStorage Driver: overlay2 Backing Filesystem: xfs Supports d_type: false Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9b55aab90508bd389d7654c4baf173a981477d55runc version: 9f9c96235cc97674e935002fc3d78361b696a69einit version: 949e6faKernel Version: 4.9.0-0.bpo.5-amd64Operating System: Debian GNU/Linux 8 (jessie)OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 11.85GiBName: intID: QNEP:YJM4:DFBS:Y7RO:GVQS:YDSB:S77P:SEXL:NZ6X:LI6P:3JFG:4Y6QDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels: provider=genericExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: overlay2: the backing xfs filesystem is formatted without d_type support, which leads to incorrect behavior.         Reformat the filesystem with ftype=1 to enable d_type support.         Running without d_type support will not be supported in future releases.WARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Linux int 4.9.0-0.bpo.5-amd64 #1 SMP Debian 4.9.65-3+deb9u2~bpo8+1 (2017-01-05) x86_64 GNU/Linux
"
36483,0,1721,0,1,1,shapiroj,0,"title:container shell does not have correct initial value for COLUMNS variable. description:**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Docker is no longer line-wrapping correctly after upgrading to 17.12.1-ce. **Steps to reproduce the issue:**1. Create a new container2. From terminal on host, echo $COLUMNS:root@198.18.55.163:~# echo $COLUMNS1953. Attach to container:root@172.25.1.1:~# docker exec -t -i 240116fb2be5 /bin/bash**Describe the results you received:**4. Show columns.  This should be the same as the host.  It's incorrectwhich makes lines wrap incorrectly for long commands. root@240116fb2be5:/usr/local/bin/# echo $COLUMNS805. Resize terminal.  Columns is set correctly.root@240116fb2be5:/usr/local/bin/# echo $COLUMNS164**Describe the results you expected:**same steps on a much older version (1.12.6)4. Show columns.  $COLUMNS now matches host value.root@172.25.1.1:~# docker exec -t -i d21241ca559c /bin/bashroot@d21241ca559c:/usr/local/bin# echo $COLUMNS1955. Resizing terminal sets columns correctly as well.root@d21241ca559c:/usr/local/bin# echo $COLUMNS                                                                                                    164**Additional information you deem important (e.g. issue happens only occasionally):**I know there are other similar issues here, namely https://github.com/moby/moby/issues/33910.  However, we are using the static binaries: https://download.docker.com/linux/static/stable/x86_64/.  It's unclear to me if this is the same since I don't believe those binaries are gentoo, and best I can tell, the issue is fixed in the code that those binaries were built from.**Output of `docker version`:**```# docker versionClient: Version:	17.12.1-ce API version:	1.35 Go version:	go1.9.4 Git commit:	7390fc6 Built:	Tue Feb 27 22:13:43 2018 OS/Arch:	linux/amd64Server: Engine:  Version:	17.12.1-ce  API version:	1.35 (minimum version 1.12)  Go version:	go1.9.4  Git commit:	7390fc6  Built:	Tue Feb 27 22:20:43 2018  OS/Arch:	linux/amd64  Experimental:	false```**Output of `docker info`:**```Containers: 21 Running: 21 Paused: 0 Stopped: 0Images: 218Server Version: 17.12.1-ceStorage Driver: zfs Zpool: docker Zpool Health: ONLINE Parent Dataset: docker/gc2-docker Space Used By Parent: 14209576960 Space Available: 200538787840 Parent Quota: 214748364800 Compression: offLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9b55aab90508bd389d7654c4baf173a981477d55runc version: 9f9c96235cc97674e935002fc3d78361b696a69einit version: 949e6faSecurity Options: seccomp  Profile: default usernsKernel Version: 4.4.46-4.4.0-amd64-e3e7779462756894Operating System: Ubuntu 14.04 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 15.65GiBName: a198-18-55-163.mytech.comID: J6H6:76CA:W4UM:FMEO:IN6C:KHWH:UPA5:RKSU:VCKB:QMQ7:CSQM:ZBWODocker Root Dir: /var/run/docker/100000.100000Debug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No kernel memory limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**physical
"
36467,0,1538,14,0,0,vivkong,0,"title:Cannot run ""docker exec"" on Linux on Z. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Cannot create another bash session using ""docker exec"" on a running container on Ubuntu 16.04 on Linux on IBM Z**Steps to reproduce the issue:**1. Create a container using `docker run -dit --name ub1604_test s390x/ubuntu:16.04 /bin/bash`2. Try to launch another bash session using `docker exec -it <container_id> /bin/bash`**Describe the results you received:**Got this error: `OCI runtime exec failed: exec failed: container_linux.go:348: starting container process caused ""open /dev/pts/4294967296: no such file or directory"": unknown`**Describe the results you expected:**Should be able to launch another bash session.**Additional information you deem important (e.g. issue happens only occasionally):**I uninstalled Docker CE v17.12.1 and install v17.09 but still saw the same error.  However if I then downgraded to v17.06 and I was able to create another bash session using `docker exec`.**Output of `docker version`:**```# docker versionClient: Version:	17.12.1-ce API version:	1.35 Go version:	go1.9.4 Git commit:	7390fc6 Built:	Tue Feb 27 22:17:54 2018 OS/Arch:	linux/s390xServer: Engine:  Version:	17.12.1-ce  API version:	1.35 (minimum version 1.12)  Go version:	go1.9.4  Git commit:	7390fc6  Built:	Tue Feb 27 22:16:59 2018  OS/Arch:	linux/s390x  Experimental:	false```**Output of `docker info`:**```# docker infoContainers: 1 Running: 1 Paused: 0 Stopped: 0Images: 8Server Version: 17.12.1-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9b55aab90508bd389d7654c4baf173a981477d55runc version: 9f9c96235cc97674e935002fc3d78361b696a69einit version: 949e6faSecurity Options: apparmorKernel Version: 4.4.0-109-genericOperating System: Ubuntu 16.04.1 LTSOSType: linuxArchitecture: s390xCPUs: 8Total Memory: 31.3GiBName: csz25089ID: 3QQF:5HN3:HPS3:L25Z:EWGX:2LR4:HVPT:JY7T:NCHR:J72O:ILZQ:3Z5LDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
36464,0,2145,0,0,0,xiagujinqiao,0,"title:centos7闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈惧瘜閺佸﹪鏌熼崜渚囩唨temd-219闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈鹃檮閸嬧晝鐥婵堫仩ker-ce 17.12.1-ce,If journalctl is restarted, the docker log can not be written to journald. description:Hi**Description**OS闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟鐑橆殢閺佸嫮鈧湱顭堝鐪汷S Linux release 7.2.1511 (Core)systemd闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟鐑橆殢閺佸棝鏌ｉ垾鏌ユ浆temd-219-42.el7_4.4.x86_64docker version闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟鐑橆殕閸嬨倝鏌ｉ妸銈嗕純ker-ce-17.12.1.ce-1.el7.centos.x86_64#systemctl show docker | grep SIGPIPEIgnoreSIGPIPE=yesGo version:	go1.9.4If journalctl is restarted, the docker log can not be written to journald.**Steps to reproduce the issue:**1.systemctl start dockerdocker log send to journald and  /var/log/messages;2.systemctl restart systemd-journaldno docker log ,whether in journald or message3.systemctl restart dockernew docker log write  journald and  /var/log/messagesI guess it is the sigpipe cause of the errorthanks **Output of `docker version`:**```Client: Version:	17.12.1-ce API version:	1.35 Go version:	go1.9.4 Git commit:	7390fc6 Built:	Tue Feb 27 22:15:20 2018 OS/Arch:	linux/amd64Server: Engine:  Version:	17.12.1-ce  API version:	1.35 (minimum version 1.12)  Go version:	go1.9.4  Git commit:	7390fc6  Built:	Tue Feb 27 22:17:54 2018  OS/Arch:	linux/amd64  Experimental:	false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 1Server Version: 17.12.1-ceStorage Driver: devicemapper Pool Name: docker-253:0-203499693-pool Pool Blocksize: 65.54kB Base Device Size: 10.74GB Backing Filesystem: xfs Udev Sync Supported: true Data file: /dev/loop0 Metadata file: /dev/loop1 Data loop file: /var/lib/docker/devicemapper/devicemapper/data Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata Data Space Used: 11.8MB Data Space Total: 107.4GB Data Space Available: 45.42GB Metadata Space Used: 581.6kB Metadata Space Total: 2.147GB Metadata Space Available: 2.147GB Thin Pool Minimum Free Space: 10.74GB Deferred Removal Enabled: true Deferred Deletion Enabled: true Deferred Deleted Device Count: 0 Library Version: 1.02.140-RHEL7 (2017-05-03)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9b55aab90508bd389d7654c4baf173a981477d55runc version: 9f9c96235cc97674e935002fc3d78361b696a69einit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-693.5.2.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.641GiBName: vm-os-centos7ID: AORO:INMV:6G7P:DJ7N:X2ND:SCNK:XIZJ:ILMW:GMZZ:NJBW:RM2H:UKPFDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Output of `systemctl show docker|grep SIGPIPE`:**IgnoreSIGPIPE=yes
"
36458,1,2249,4,0,0,artiomchi,0,"title:Docker 18.03 Linux based images built using LCOW can't be deployed to registries. description:**Description**Bringing this from docker/for-win#1769, was told by @carlfischer1 that it should be reported here intead.. Hey! 婵犵妲呴崑鎾跺緤娴犲鐤い鏍剳缂?So I've narrowed this down to as small an example as I could. I created a small hello world repo here: https://github.com/artiomchi/HelloWorldWhen building the app using a linux image, while running 18.03 in Windows Container mode, the image builds successfully and can be started locally. But it fails when trying to deploy it to a remote registry.The top layer will fail to push immediately, and will enter a ""Retrying"" loop with an ever increasing delay. It will finally give up with an error**Steps to reproduce the issue:**I have a simple repository that I used to reproduce it on several machines.```powershellgit clone https://github.com/artiomchi/HelloWorld.gitcd HelloWorld/HelloWorlddocker build --rm -f Dockerfile-lin-alpine -t helloworld:alpine . --no-cachedocker tag helloworld:alpine artiomchi/helloworld:alpinedocker push artiomchi/helloworld:alpine```**Describe the results you received:**The top layer retries multiple times, until eventually gives up with the following:```powershellPS D:\Development\HelloWorld\HelloWorld> docker push artiomchi/helloworld:alpineThe push refers to repository [docker.io/artiomchi/helloworld]d140feb78cc6: Pushing [==================================================>]  262.7kB/262.7kB154dc7e00f30: Layer already existsc5de6b3aa838: Layer already exists9dfa40a0da3b: Layer already existsopen \tmp\8797231b7737236ea8608ab3f7e63846a37cbfea164db833fbbbce80f392fceb-mount\app\HelloWorld.deps.json: The system cannot find the path specified.```**Describe the results you expected:**`docker push ` should successfully push the image to the docker registry**Additional information you deem important (e.g. issue happens only occasionally):**This only happens when running linux builds in Windows Container mode. When I switch docker to run in Linux Container mode (uses the Hyper-V VM), the build and publish succeed.**Output of `docker version`:**```Client: Version:       18.03.0-ce-rc1 API version:   1.37 Go version:    go1.9.4 Git commit:    c160c73 Built: Thu Feb 22 02:34:04 2018 OS/Arch:       windows/amd64 Experimental:  false Orchestrator:  swarmServer: Engine:  Version:      18.03.0-ce-rc1  API version:  1.37 (minimum version 1.24)  Go version:   go1.9.4  Git commit:   c160c73  Built:        Thu Feb 22 02:41:20 2018  OS/Arch:      windows/amd64  Experimental: true```**Output of `docker info`:**```Containers: 4 Running: 0 Paused: 0 Stopped: 4Images: 98Server Version: 18.03.0-ce-rc1Storage Driver: windowsfilter (windows) lcow (linux) Windows: LCOW:Logging Driver: json-filePlugins: Volume: local Network: ics l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd gelf json-file logentries splunk syslogSwarm: inactiveDefault Isolation: hypervKernel Version: 10.0 16299 (16299.15.amd64fre.rs3_release.170928-1534)Operating System: Windows 10 ProOSType: windowsArchitecture: x86_64CPUs: 16Total Memory: 15.93GiBName: FlexLabs-RogID: AOEB:4SFW:5ZHH:SEF6:BLKG:UBKZ:4ADD:RAQR:SF6T:E752:64KZ:ZVWVDocker Root Dir: C:\ProgramData\DockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: -1 Goroutines: 29 System Time: 2018-03-01T19:34:01.1776121Z EventsListeners: 1Registry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Running on Windows 10 with the 1709 Fall creator's update
"
36457,0,0,27,0,0,fadams,0,"title:Docker version 17.12.1-ce mounts /dev/snd devices as group root - breaks alsa applications. description:In Docker version 17.12.0-ce when using `--device=/dev/snd` in docker run the devices are mounted owned by root but in group audio - this can be seen by doing `ls -al /dev/snd` in a container that uses `--device=/dev/snd`.I've just upgraded to Docker version 17.12.1-ce via my distro updater and my application has stopped working, upon investigation I noticed that when doing `ls -al /dev/snd` the devices have both owner and group as root, which is the most likely culprit. This was proved by execing into the container as  uid 0 and manually doing `chown root:audio *` in /dev/sndDon't know if other devices are affected by this though I'd be surprised if it was just /dev/snd
"
36456,0,2232,8,0,0,aly-saleh,0,"title:apparmor profile is not effect. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!---->When I apply a custom apparmor to a container that uses docker-ce 17.12 docker neglects the apparmor profile as if it uses the docker-default apparmor profile.This behaviour is ONLY reproducible with docker-ce 17.12.0~ce-0~ubuntu, but it works correctly with docker-ce 17.09.1~ce-0~ubuntu**Steps to reproduce the issue:**1. Add a custom apparmor profile that denies writes under /tmp/:```$ apparmor_parser -q -r <<EOF#include <tunables/global>profile deny-write flags=(attach_disconnected) {  #include <abstractions/base>  file,  network,  deny /tmp/** w,  capability,}EOF```2. Run any test container with the ""deny-write"" apparmor profile:```$ docker run -itd --security-opt ""apparmor=deny-write"" --name httpd-aa httpd```3. Exec into the container:```$ docker exec -it httpd-aa bashroot@e48cf7443752:/usr/local/apache2#```4- Create a dir/file under /tmp```$ root@e48cf7443752:/usr/local/apache2# mkdir /tmp/test```**Describe the results you received:**```root@e48cf7443752:/usr/local/apache2# mkdir /tmp/testroot@e48cf7443752:/usr/local/apache2#```**Describe the results you expected:**```root@e48cf7443752:/usr/local/apache2# mkdir /tmp/testmkdir: cannot create directory '/tmp/test': Permission deniedroot@e48cf7443752:/usr/local/apache2#   ```**Additional information you deem important (e.g. issue happens only occasionally):**This happens with docker-ce 17.12.0~ce-0~ubuntu, and does not happen with docker-ce 17.09.1~ce-0~ubuntu**Output of `docker version`:**```Client: Version:	17.12.0-ce API version:	1.35 Go version:	go1.9.2 Git commit:	c97c6d6 Built:	Wed Dec 27 20:11:19 2017 OS/Arch:	linux/amd64Server: Engine:  Version:	17.12.0-ce  API version:	1.35 (minimum version 1.12)  Go version:	go1.9.2  Git commit:	c97c6d6  Built:	Wed Dec 27 20:09:53 2017  OS/Arch:	linux/amd64  Experimental:	false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 4Server Version: 17.12.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 11 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-1052-awsOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 7.303GiBName: ip-10-66-97-65ID: IIXT:5RGZ:QLTU:JXGI:B2W3:JJXD:Q6H7:KQMY:OATP:DSOI:SDUY:4XQ2Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**AWS EC2 m3.largeUbuntu 16.04.3 LTSKernel: 4.4.0-1052-aws
"
36367,0,389,279,0,0,cpuguy83,0,"title:Killing containerd breaks interaction with running containers. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->When containerd is killed/restarted, I am no longer able to interact with any running containers.**Steps to reproduce the issue:**1. `docker run -d --name test busybox top`2. `pkill -9 docker-containerd`3. wait for docker to restart containerd4. `docker kill test`**Describe the results you received:**Receive this error in the logs: ```ERRO[2018-02-21T15:15:48.365281200Z] Handler for POST /v1.30/containers/test/kill returned error: Cannot kill container: test: Cannot kill container d542dc766a7b7e1a20d4c01a5b581339dfc84c46df691b2b0351fde082f0ecaa: grpc: the client connection is closing: failed precondition```If I manually kill the task with ```docker-containerd-ctr --namespace=moby --address /run/docker/containerd/docker-containerd.sock t kill <id> ```The event is observed in dockerd, so the client is active, but then dockerd tries to cleanup the container state in containerd and is unable to and gets the same error.Tracking this down, it looks like an issue due to the way docker is caching container/task objects created from the old client. These objects have the client embedded in them and need to be recreated.
"
36278,1,1992,159,0,0,hgl,0,"title:Unable to copy file from a multi-stage build . description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**If I build this to an image named `foo````FROM alpine:3.7FROM scratchCOPY --from=0 /usr/bin/cal /usr/local/bin```I can't copy file from `foo` in another multi-stage build```FROM fooFROM alpine:3.7COPY --from=0 /usr/local/bin/cal /usr/local/bin```It fails with ```COPY failed: Forbidden path outside the build context: usr/local/bin/cal ()```<!--Briefly describe the problem you are having in a few paragraphs.-->**Output of `docker version`:**```Client: Version:	18.02.0-ce API version:	1.36 Go version:	go1.9.3 Git commit:	fc4de44 Built:	Wed Feb  7 21:13:05 2018 OS/Arch:	darwin/amd64 Experimental:	false Orchestrator:	swarmServer: Engine:  Version:	18.02.0-ce  API version:	1.36 (minimum version 1.12)  Go version:	go1.9.3  Git commit:	fc4de44  Built:	Wed Feb  7 21:20:15 2018  OS/Arch:	linux/amd64  Experimental:	true```**Output of `docker info`:**```Containers: 13 Running: 5 Paused: 0 Stopped: 8Images: 57Server Version: 18.02.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9b55aab90508bd389d7654c4baf173a981477d55runc version: 9f9c96235cc97674e935002fc3d78361b696a69einit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.75-linuxkit-aufsOperating System: Docker for MacOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.952GiBName: linuxkit-025000000001ID: GXQ5:VFVV:Q6HN:2SQO:6DOO:DMLL:L6JQ:DS5I:5DJE:SJI6:VUTU:J6A4Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 30 Goroutines: 56 System Time: 2018-02-10T15:29:38.248015454Z EventsListeners: 2HTTP Proxy: docker.for.mac.http.internal:3128HTTPS Proxy: docker.for.mac.http.internal:3129Registry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**I'm using Docker for Mac
"
36247,0,3646,43,0,0,albers,0,"title:[18.02.0] Swarm service cannot attach to host network - ""only one instance of ""host"" network is allowed"". description:According to the [compose file docs](https://docs.docker.com/compose/compose-file/#host-or-none), this fragment should create a swarm service whose instances are connected to the host`s network:```yamlservices:  web:    ...    networks:      hostnet: {}networks:  hostnet:    external:      name: host```This used to work for me up to Docker 18.01.0-ce:```bashuser@docker4:~$ cat hostnet.ymlversion: '3.4'services:  web:    image: nginx    networks:      hostnet: {}networks:  hostnet:    external:      name: hostuser@docker4:~$ docker stack deploy -c hostnet.yml hostnetCreating service hostnet_webuser@docker4:~$ docker service ps hostnet_webID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR               PORTSekh2x9fiftwn        hostnet_web.1       nginx:latest        docker4             Running             Running 10 seconds ago```WIth Docker 18.02.0, deployment fails with *only one instance of \""host\"" network is allowed""*:```bashuser@docker4:~$ docker stack deploy -c hostnet.yml hostnetCreating service hostnet_webuser@docker4:~$ docker service ps hostnet_webID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE            ERROR                              PORTStbrwxomncmxh        hostnet_web.1       nginx:latest        docker4             Ready               Rejected 2 seconds ago   ""only one instance of ""host"" n闂?5wfft46phw7n         \_ hostnet_web.1   nginx:latest        docker4             Shutdown            Rejected 7 seconds ago   """"only one instance of """"host"""" n闂?""o95qdlf4w029         \_ hostnet_web.1   nginx:latest        docker4             Shutdown            Rejected 8 seconds ago   """"only one instance of """"host"""" n闂?""```Log output:    ERRO[2018-02-08T15:46:59.635485455+01:00] fatal task error   error=""""only one instance of \""""host\"""" network is allowed"""" module=node/agent/taskmanager node.id=[...] task.id=[...]  Output of `docker version````Client: Version:       18.02.0-ce API version:   1.36 Go version:    go1.9.3 Git commit:    fc4de44 Built: Wed Feb  7 21:16:33 2018 OS/Arch:       linux/amd64 Experimental:  false Orchestrator:  swarmServer: Engine:  Version:      18.02.0-ce  API version:  1.36 (minimum version 1.12)  Go version:   go1.9.3  Git commit:   fc4de44  Built:        Wed Feb  7 21:15:05 2018  OS/Arch:      linux/amd64  Experimental: false```</details>  Output of `docker info````Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 133Server Version: 18.02.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 222 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: 5tgj049z74d8bigq4osjujr1b Is Manager: true ClusterID: oy18buvxbbqb00libidep5kx9 Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 10.0.1.51 Manager Addresses:  10.0.1.51:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9b55aab90508bd389d7654c4baf173a981477d55runc version: 9f9c96235cc97674e935002fc3d78361b696a69einit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-112-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 11.72GiBName: docker4ID: BHDU:YEDX:7NMN:QIHK:PFXZ:MWOX:5WZF:FZTK:3RDE:GAEY:U7L2:NP72Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```</details>**Additional environment details (AWS"
36030,0,0,279,0,1,cpuguy83,0,"title:Ensure CPU quota/period updates are sent to runc. description:Fixes an issue where if cpu quota/period is sent via the update API, thevalues are updated in the stored container data but not actually sent tothe running container.Closes docker/for-linux#201
"
36029,0,1711,0,0,0,vglushak,0,"title:docker exec does not terminate process. description:**Description**After update to 17.12.0-ce-mac47 (21805) version, `docker exec -t` doesn't terminate container's process.**Steps to reproduce the issue:**1. Run `docker exec -t <img> ps`**Describe the results you received:**It displays list of processes but does not close the session. **Describe the results you expected:**Process should be terminated.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:	17.12.0-ce API version:	1.35 Go version:	go1.9.2 Git commit:	c97c6d6 Built:	Wed Dec 27 20:03:51 2017 OS/Arch:	darwin/amd64Server: Engine:  Version:	17.12.0-ce  API version:	1.35 (minimum version 1.12)  Go version:	go1.9.2  Git commit:	c97c6d6  Built:	Wed Dec 27 20:12:29 2017  OS/Arch:	linux/amd64  Experimental:	true```**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 2Server Version: 17.12.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.60-linuxkit-aufsOperating System: Docker for MacOSType: linuxArchitecture: x86_64CPUs: 6Total Memory: 14.67GiBName: linuxkit-025000000001ID: AWH6:LQFH:CR2X:GNQJ:RFHM:EXIL:7CVX:C7C5:2GCS:GSBA:FVLC:J75FDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 34 Goroutines: 69 System Time: 2018-01-16T13:16:07.032469044Z EventsListeners: 2HTTP Proxy: docker.for.mac.http.internal:3128HTTPS Proxy: docker.for.mac.http.internal:3129Registry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Local macbook. System Version:	macOS 10.13.2 (17C88)  Kernel Version:	Darwin 17.3.0  Boot Volume:	Macintosh HDD
"
36028,1,3650,5,0,0,zarnovican,0,"title:swarm: stack deploy needlessly updates service which was force-updated before. description:**Description**After service is force-updated via `docker service update test_redis --force`, the next `docker stack deploy ..` will needlessy update it again.**Steps to reproduce the issue:**1. create a config for test stack```bashcat >test.yaml <<EOFversion: ""3.3""services:    redis:        image: redis:3.2.8EOF```2. deploy the stack```bashdocker stack deploy -c test.yaml test```3. force update the service```bashdocker service update test_redis --force```4. do a noop stack deploy again```bashdocker stack deploy -c test.yaml test```**Describe the results you received:**In step 4, redis is redeployed even if there are no change in configuration or image.**Describe the results you expected:**No update should occur (IMHO).**Additional information you deem important (e.g. issue happens only occasionally):**It is 100% reproducible, even on single-node cluster.This is a minor issue. Actually, it may be a feature, not a bug.Here is the PreviousSpec vs Spec diff..```diff                     },+                    ""StopGracePeriod"": 10000000000,+                    ""DNSConfig"": {},                     ""Isolation"": ""default""                 },                 ""Resources"": {},+                ""RestartPolicy"": {+                    ""Condition"": ""any"",+                    ""Delay"": 5000000000,+                    ""MaxAttempts"": 0+                },                 ""Placement"": {                     ""Platforms"": [                         {@@ -33,7 +40,7 @@                         ]                     }                 ],-                ""ForceUpdate"": 1,+                ""ForceUpdate"": 0,                 ""Runtime"": ""container""             },             ""Mode"": {@@ -41,6 +48,20 @@                     ""Replicas"": 1                 }             },+            ""UpdateConfig"": {+                ""Parallelism"": 1,+                ""FailureAction"": ""pause"",+                ""Monitor"": 5000000000,+                ""MaxFailureRatio"": 0,+                ""Order"": ""stop-first""+            },+            ""RollbackConfig"": {+                ""Parallelism"": 1,+                ""FailureAction"": ""pause"",+                ""Monitor"": 5000000000,+                ""MaxFailureRatio"": 0,+                ""Order"": ""stop-first""+            },```**Output of `docker version`:**```Client: Version:	17.12.0-ce API version:	1.35 Go version:	go1.9.2 Git commit:	c97c6d6 Built:	Wed Dec 27 20:11:19 2017 OS/Arch:	linux/amd64Server: Engine:  Version:	17.12.0-ce  API version:	1.35 (minimum version 1.12)  Go version:	go1.9.2  Git commit:	c97c6d6  Built:	Wed Dec 27 20:09:53 2017  OS/Arch:	linux/amd64  Experimental:	false```**Output of `docker info`:**```Containers: 3 Running: 1 Paused: 0 Stopped: 2Images: 1Server Version: 17.12.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: journaldCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: ncwi18bjrpdrwgimx87u9o6xk Is Manager: true ClusterID: ghhzm7l9q47gvfak6l7j5a95t Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 192.168.122.15 Manager Addresses:  192.168.122.15:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-97-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 992.2MiBName: vm5ID: ER3S:H3RW:SCXE:EH4N:XZNA:XSS7:7CXI:JWKR:4TTJ:U3YB:ISV5:S236Docker Root Dir: /mnt/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
36027,1,2341,37,0,0,JoshuaSjoding,0,"title:Dockerfile ""ENV <key> <value>"" unexpectedly removes quotes. description:**Description**When using `ENV` in the form `ENV <key> <value>` both single and double quotes are beingstripped from `<value>`.According to [the documentation](https://docs.docker.com/engine/reference/builder/#env):> The `ENV` instruction has two forms. The first form, `ENV <key> <value>`, will set a single variable to a value. The entire string after the first space will be treated as the `<value>` - including characters such as spaces and quotes.I'm seeing double and single quotes being stripped from entries such as these:```ENV DQUOTE One ""two two"" three fourENV SQUOTE One 'two two' three four```Backslashes are also being interpreted:```ENV SBACKSLASH One two\ two three fourENV DBACKSLASH One two\\ two three four```**Steps to reproduce the issue:**1. `git clone git@github.com:gentlemanautomaton/docker-env-quote-test.git`2. `cd docker-env-quote-test`3. `docker build -t gentlemanautomaton/docker-env-quote-test:latest .`4. `docker inspect gentlemanautomaton/docker-env-quote-test:latest`**Describe the results you received:**```""Env"": [	""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"",	""DQUOTE=One two two three four"",	""SQUOTE=One two two three four"",	""SBACKSLASH=One two two three four"",	""DBACKSLASH=One two\\ two three four"",	""BACKTICK=One `two two` three four""],```**Describe the results you expected:**```""Env"": [	""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"",	""DQUOTE=One \""two two\"" three four"",	""SQUOTE=One 'two two' three four"",	""SBACKSLASH=One two\\ two three four"",	""DBACKSLASH=One two\\\\ two three four"",	""BACKTICK=One `two two` three four""],```**Additional information you deem important (e.g. issue happens only occasionally):**In the hope that it's useful, I created a test `Dockerfile` for reproduction in this repo:* https://github.com/gentlemanautomaton/docker-env-quote-test**Output of `docker version`:**```Client: Version:       18.01.0-ce API version:   1.35 Go version:    go1.9.2 Git commit:    03596f5 Built: Wed Jan 10 20:13:21 2018 OS/Arch:       linux/amd64 Experimental:  false Orchestrator:  swarmServer: Engine:  Version:      18.01.0-ce  API version:  1.35 (minimum version 1.12)  Go version:   go1.9.2  Git commit:   03596f5  Built:        Wed Jan 10 20:11:47 2018  OS/Arch:      linux/amd64  Experimental: false```**Output of `docker info`:**```Containers: 3 Running: 0 Paused: 0 Stopped: 3Images: 361Server Version: 18.01.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.13.0-25-genericOperating System: Ubuntu 17.10OSType: linuxArchitecture: x86_64CPUs: 16Total Memory: 31.47GiBName: REDACTEDID: SVWR:PGRT:4NZT:KVIT:DVBE:EKDI:GG2T:46U2:5PEW:X4UL:LGQZ:SEL4Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**The test was performed with `docker-ce` running on physical hardware.
"
36010,0,2175,19,0,0,phsiao,0,"title:docker-runc does not terminate and leave docker-shim hanging in 17.12. description:**Description**This seems to be new to 17.12.docker-runc hangs sometimes and needs to be killed in order for the rest of the system to continue to work properly.  Because we run Kubernetes, the most noticeable symptom for us is kubelet on the host would start to show PLEG timeout.  It appears the docker-shim responsible for the runc and the container stops responding.We can still interact with docker for the most part, and I don't believe we see issues other than kubelet not able to report container events.  `docker ps -a` would show the container ID with status created (but not `docker ps`, but `docker inspect` the container would hang.  `docker-containerd-ctr` shows the container in stopped state.Another thing that is strange is so far the affected container is kubernetes' infra container.  I have yet to see other container being left in such state.**Steps to reproduce the issue:**Can't reproduce it reliably, but happens several times a day across 150 or so docker installations.**Describe the results you received:**docker-runc does not terminate, and `docker inspect <cid>` hangs.**Describe the results you expected:**docker-runc should terminate, and `docker inspect <cid>` should not hang.**Additional information you deem important (e.g. issue happens only occasionally):**Issue happens occasionally, but killing the hung docker-runc process restores the system.Here is what strace of the stuck docker-runcc looks like```# strace -p 43620strace: Process 43620 attachedopenat(AT_FDCWD, ""/var/run/docker/runtime-runc/moby/fc2da052c68f4f0a120184ad8eea49fec3e903dd6da9db848bb722f94fb25ba4/exec.fifo"", O_RDONLY|O_CLOEXEC```**Output of `docker version`:**```Client: Version:	17.12.0-ce API version:	1.35 Go version:	go1.9.2 Git commit:	c97c6d6 Built:	Wed Dec 27 20:10:14 2017 OS/Arch:	linux/amd64Server: Engine:  Version:	17.12.0-ce  API version:	1.35 (minimum version 1.12)  Go version:	go1.9.2  Git commit:	c97c6d6  Built:	Wed Dec 27 20:12:46 2017  OS/Arch:	linux/amd64  Experimental:	false```**Output of `docker info`:**```Containers: 15 Running: 13 Paused: 0 Stopped: 2Images: 13Server Version: 17.12.0-ceStorage Driver: devicemapper Pool Name: docker-images Pool Blocksize: 65.54kB Base Device Size: 10.74GB Backing Filesystem: xfs Udev Sync Supported: true Data Space Used: 3.437GB Data Space Total: 797.8GB Data Space Available: 794.4GB Metadata Space Used: 8.884MB Metadata Space Total: 566.2MB Metadata Space Available: 557.3MB Thin Pool Minimum Free Space: 79.78GB Deferred Removal Enabled: true Deferred Deletion Enabled: true Deferred Deleted Device Count: 0 Library Version: 1.02.140-RHEL7 (2017-05-03)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: seccomp  Profile: default selinuxKernel Version: 4.14.13-1.el7.elrepo.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 56Total Memory: 125.8GiBName: bnbvxk2ID: L3JD:VTHD:IQKY:E5IJ:TA3F:PBKH:XYYQ:APCB:LWL3:SHVZ:QKMU:ACJ3Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels: techops.site=slukd1Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: true```**Additional environment details (AWS, VirtualBox, physical, etc.):**Servers are all bare-metal running CentOS 7.4.1708 with kernel 4.14.11 to 4.14.13.
"
36002,0,9141,200,0,0,thaJeztah,0,"title:Killing docker-containerd breaks interaction with containers. description:When killing `docker-containerd`, interacting with containers (`docker exec`, `docker stop`, `docker kill`) fails:```bashdocker kill testingError response from daemon: Cannot kill container: testing: Cannot kill container 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359: connection error: desc = ""transport: dial unix /var/run/docker/containerd/docker-containerd.sock: connect: connection refused"": unknowndocker rm -f lucid_yalowError response from daemon: Could not kill running container 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359, cannot remove - Cannot kill container 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359: connection error: desc = ""transport: dial unix /var/run/docker/containerd/docker-containerd.sock: connect: connection refused"": unknown```But killing `dockerd` (either by `killall -9 dockerd` or a `SIGHUP`; `killall -HUP dockerd`) restores functionality.This problem could explain some reports about ""unkillable"" containers, where everything appears to be running, but interaction is not possible (possibly after `containerd` was OOM killed, but could have different causes).### Steps to reproduce / informationHave docker running, start a container, and check output of `ps auxf`: `docker-containerd` and `docker-containerd-shim` are child-processes of `dockerd`:```root     11468  1.1  3.4 468232 71036 ?        Ssl  11:56   0:01 /usr/bin/dockerd -H fd://root     11473  0.4  1.3 236512 27856 ?        Ssl  11:56   0:00  \_ docker-containerd --config /var/run/docker/containerd/containerd.tomlroot     11918  0.0  0.1   7516  3788 ?        Sl   11:57   0:00      \_ docker-containerd-shim -namespace moby -workdir /var/lib/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359 -address /var/run/docker/containerd/docker-containerd.sock -containerd-binary /usr/bin/docker-containerd -runtime-root /var/run/docker/runtime-runcroot     11933  0.1  0.0   1236     4 pts/0    Ss+  11:57   0:00          \_ sh```Now, kill `docker-containerd` (`killall -9 docker-containerd`).`docker-containerd` is restarted (by `dockerd`); observe that `docker-containerd-shim` and the container process(es) are reparented (I haven't checked what the new parent process is, and if this is relevant). The `docker-containerd-shim` processes are no longer child-process of `docker-containerd`;```root     11468  160  3.6 470984 74664 ?        Ssl  11:56  19:55 /usr/bin/dockerd -H fd://root     11979  0.1  1.2 300992 25980 ?        Ssl  11:58   0:01  \_ docker-containerd --config /var/run/docker/containerd/containerd.tomlroot     11918  0.0  0.2   7516  4688 ?        Sl   11:57   0:00 docker-containerd-shim -namespace moby -workdir /var/lib/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359 -address /var/run/docker/containerd/docker-containerd.sock -containerd-binary /usr/bin/docker-containerd -runtime-root /var/run/docker/runtime-runcroot     11933  0.0  0.0   1236     4 pts/0    Ss+  11:57   0:00  \_ sh```At this point, interacting with containers is now broken..Containers still show up as running:```bashdocker psCONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMES9bfdba3fc8ee        busybox             ""sh""                About a minute ago   Up About a minute                       testing```Inspecting the container still works, and shows the `pid` of the container;```bashdocker inspect --format '{{json .State}}' testing | jq .{  ""Status"": ""running"",  ""Running"": true,  ""Paused"": false,  ""Restarting"": false,  ""OOMKilled"": false,  ""Dead"": false,  ""Pid"": 11933,  ""ExitCode"": 0,  ""Error"": """",  ""StartedAt"": ""2018-01-12T11:57:47.687627373Z"",  ""FinishedAt"": ""0001-01-01T00:00:00Z""}```But any interaction with the containers is broken;```bashdocker kill testingError response from daemon: Cannot kill container: testing: Cannot kill container 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359: connection error: desc = ""transport: dial unix /var/run/docker/containerd/docker-containerd.sock: connect: connection refused"": unknowndocker rm -f lucid_yalowError response from daemon: Could not kill running container 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359, cannot remove - Cannot kill container 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359: connection error: desc = ""transport: dial unix /var/run/docker/containerd/docker-containerd.sock: connect: connection refused"": unknown```When directly connecting to containerd, containers still show:```bashdocker-containerd-ctr --namespace=moby --address /var/run/docker/containerd/docker-containerd.sock containers lsCONTAINER                                                           IMAGE    RUNTIME                           9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359    -        io.containerd.runtime.v1.linux    ```And can be inspected;```bashdocker-containerd-ctr --namespace=moby --address /var/run/docker/containerd/docker-containerd.sock containers info 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359......```Shims are still up:```netstat -x | grep shimunix  2      [ ]         STREAM     CONNECTED     64641    @/containerd-shim/moby/9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359/shim.sockunix  3      [ ]         STREAM     CONNECTED     64019    @/containerd-shim/moby/9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359/shim.sock``````bashdocker-runc --root /var/run/docker/runtime-runc/moby/ state 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359{  ""ociVersion"": ""1.0.0"",  ""id"": ""9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359"",  ""pid"": 11933,  ""status"": ""running"",  ""bundle"": ""/run/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359"",  ""rootfs"": ""/var/lib/docker/overlay2/9c0e355304db9fb85f7c1281b11008eea23bd4dbb142f11f551066c9fdb2e70e/merged"",  ""created"": ""2018-01-12T11:57:47.631870877Z"",  ""owner"": """"}```And the container is still functional, when using `docker-runc`;```bashdocker-runc --root /var/run/docker/runtime-runc/moby/ exec 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359 ls -latotal 44drwxr-xr-x    1 root     root          4096 Jan 12 11:57 .drwxr-xr-x    1 root     root          4096 Jan 12 11:57 ..-rwxr-xr-x    1 root     root             0 Jan 12 11:57 .dockerenvdrwxr-xr-x    2 root     root         12288 Jan  8 21:14 bindrwxr-xr-x    5 root     root           360 Jan 12 11:57 devdrwxr-xr-x    1 root     root          4096 Jan 12 11:57 etcdrwxr-xr-x    2 nobody   nogroup       4096 Jan  8 21:14 homedr-xr-xr-x  125 root     root             0 Jan 12 11:57 procdrwxr-xr-x    2 root     root          4096 Jan  8 21:14 rootdr-xr-xr-x   13 root     root             0 Jan 12 11:57 sysdrwxrwxrwt    2 root     root          4096 Jan  8 21:14 tmpdrwxr-xr-x    3 root     root          4096 Jan  8 21:14 usrdrwxr-xr-x    4 root     root          4096 Jan  8 21:14 var```### restore functionalityKill `dockerd` (`killall -9 dockerd`) or `SIGHUP` (`killall -HUP dockerd`).Observe that shims are not re-parented (which is probably expected);```root     11918  0.0  0.2   7516  4688 ?        Sl   11:57   0:00 docker-containerd-shim -namespace moby -workdir /var/lib/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359 -address /var/run/docker/containerd/docker-containerd.sock -containerd-binary /usr/bin/docker-contairoot     11933  0.0  0.0   1236     4 pts/0    Ss+  11:57   0:00  \_ shroot     12287  1.1  2.8 446232 57824 ?        Ssl  12:55   0:00 /usr/bin/dockerd -H fd://root     12293  0.7  1.1 300928 22616 ?        Ssl  12:55   0:00  \_ docker-containerd --config /var/run/docker/containerd/containerd.toml```But now it's possible again to interact with them:```docker exec testing ls -latotal 44drwxr-xr-x    1 root     root          4096 Jan 12 11:57 .drwxr-xr-x    1 root     root          4096 Jan 12 11:57 ..-rwxr-xr-x    1 root     root             0 Jan 12 11:57 .dockerenvdrwxr-xr-x    2 root     root         12288 Jan  8 21:14 bindrwxr-xr-x    5 root     root           360 Jan 12 11:57 devdrwxr-xr-x    1 root     root          4096 Jan 12 11:57 etcdrwxr-xr-x    2 nobody   nogroup       4096 Jan  8 21:14 homedr-xr-xr-x  126 root     root             0 Jan 12 11:57 procdrwxr-xr-x    1 root     root          4096 Jan 12 12:58 rootdr-xr-xr-x   13 root     root             0 Jan 12 11:57 sysdrwxrwxrwt    2 root     root          4096 Jan  8 21:14 tmpdrwxr-xr-x    3 root     root          4096 Jan  8 21:14 usrdrwxr-xr-x    4 root     root          4096 Jan  8 21:14 var```## Version of docker and containerdTested on Ubuntu 16.04 on DigitalOcean;```docker-containerd --versioncontainerd github.com/containerd/containerd v1.0.0 89623f28b87a6004d4b785663257362d1658a729``````Client: Version:	18.01.0-ce API version:	1.35 Go version:	go1.9.2 Git commit:	03596f5 Built:	Wed Jan 10 20:11:05 2018 OS/Arch:	linux/amd64 Experimental:	false Orchestrator:	swarmServer: Engine:  Version:	18.01.0-ce  API version:	1.35 (minimum version 1.12)  Go version:	go1.9.2  Git commit:	03596f5  Built:	Wed Jan 10 20:09:37 2018  OS/Arch:	linux/amd64  Experimental:	false``````Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 2Server Version: 18.01.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-108-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.953GiBName: ubuntu-2gb-ams3-01ID: KIY5:X5P2:5FI5:GEPC:Q2OO:XF4P:KFB2:S22T:A76T:DVFV:UIFB:ZATYDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```
"
35991,1,0,3,0,0,wenlxie,0,"title:device not work well when start container with --privileged option #35991. description:## DescriptionWhen I try to run container with command: `docker run -it --device=/dev/sdc4:/dev/xvdc --privileged ubuntu /bin/bash`There is supposed to have device /dev/xvdc inside the container, but I just saw device /dev/sdc4.When I removed the `--privileged` option,I  can find device `/dev/xvdc`  exists.## Steps to reproduce the issueRun container with `--device` and `--privileged` option## Describe the results you expectedWhen run container with option `--device` and `--privileged` option,  can see the specified device inside the container*Docker version*`1.12.6`
"
35977,0,3404,1,0,0,nlowe,0,"title:Contents of the windows certificate store no longer added to MobyVM. description:**Description**Extra `Trusted Root Certification Authorities` from the windows certificate store are no longer added to the MobyVM ca-certificates store in recent versions of docker-ce.**Steps to reproduce the issue:**1. Install docker-ce for windows2. Start docker in linux container mode3. Attempt to pull from or login to a private registry whose certificate is signed by an extra CA added to the `Trusted Root Certification Authorities` Store**Describe the results you received:**```bashError response from daemon: Get https://my.registry/v2/: x509: certificate signed by unknown authority```**Describe the results you expected:**```bashLogin Succeeded```**Additional information you deem important (e.g. issue happens only occasionally):**If you start the docker daemon in windows container mode, you can login and push/pull images to/from this registry successfully.**Output of `docker version`:**Working```Client: Version:      17.06.2-ce API version:  1.30 Go version:   go1.8.3 Git commit:   cec0b72 Built:        Tue Sep  5 19:57:19 2017 OS/Arch:      windows/amd64Server: Version:      17.06.2-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   cec0b72 Built:        Tue Sep  5 19:59:19 2017 OS/Arch:      linux/amd64 Experimental: true```</details>Broken```Client: Version:       17.12.0-ce API version:   1.35 Go version:    go1.9.2 Git commit:    c97c6d6 Built: Wed Dec 27 20:05:22 2017 OS/Arch:       windows/amd64Server: Engine:  Version:      17.12.0-ce  API version:  1.35 (minimum version 1.12)  Go version:   go1.9.2  Git commit:   c97c6d6  Built:        Wed Dec 27 20:12:29 2017  OS/Arch:      linux/amd64  Experimental: true```</details>**Output of `docker info`:**Working```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 17.06.2-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 6e23458c129b551d5c9871e5174f6b1b7f6d1170runc version: 810190ceaa507aa2727d7ae6f4790c76ec150bd2init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.41-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.934GiBName: mobyID: 3725:YPWW:A3WM:KDZ5:D5XN:LXBF:J57Z:ZLFI:FNEK:AF5B:OSRQ:ZRY5Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 15 Goroutines: 25 System Time: 2018-01-10T20:10:30.4549742Z EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```</details>Broken```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 17.12.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.60-linuxkit-aufsOperating System: Docker for WindowsOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.934GiBName: linuxkit-00155d102f05ID: LDU6:6RMV:U5FG:R4ZD:LTLL:54FJ:IFFS:GKYP:EBJ6:6AEB:KN6B:M6BPDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 19 Goroutines: 35 System Time: 2018-01-10T20:13:52.5306543Z EventsListeners: 1Registry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```</details>**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical Windows 10 machine. I did not see anything interesting in the docker logs but if you need something specific, please let me know. I believe the last version I used when this was working was `17.09.0-ce` or `17.09.1-ce`. I do not have the installer on hand at the moment to verify this though.
"
35933,0,2443,0,0,0,Timunas,0,"title:Can't stop docker container. description:**Description**Can't stop container.I'm starting and removing containers concurrently using docker-compose.Sometimes it fails to remove the containers.I checked that I can't docker stop the container. The command hangs and after change docker daemon to debug I just see this line when I run the command.`dockerd[101922]: time=""2018-01-04T15:54:07.406980654Z"" level=debug msg=""Calling POST /v1.35/containers/4c2b5e7f466c/stop""`**Steps to reproduce the issue:**1. Run tests in jenkins2. Eventually it fails to remove containers.**Describe the results you received:**Can't stop container.**Describe the results you expected:**Container should have been stopped. And then removed.**Additional information you deem important (e.g. issue happens only occasionally):**Issue happens only occasionally**Output of `docker version`:**```Client: Version:	17.12.0-ce API version:	1.35 Go version:	go1.9.2 Git commit:	c97c6d6 Built:	Wed Dec 27 20:10:14 2017 OS/Arch:	linux/amd64Server: Engine:  Version:	17.12.0-ce  API version:	1.35 (minimum version 1.12)  Go version:	go1.9.2  Git commit:	c97c6d6  Built:	Wed Dec 27 20:12:46 2017  OS/Arch:	linux/amd64  Experimental:	false```**Output of `docker info`:**```Containers: 6 Running: 1 Paused: 0 Stopped: 5Images: 75Server Version: 17.12.0-ceStorage Driver: devicemapper Pool Name: docker-253:0-33643212-pool Pool Blocksize: 65.54kB Base Device Size: 10.74GB Backing Filesystem: xfs Udev Sync Supported: true Data file: /dev/loop0 Metadata file: /dev/loop1 Data loop file: /var/lib/docker/devicemapper/devicemapper/data Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata Data Space Used: 31.43GB Data Space Total: 107.4GB Data Space Available: 75.95GB Metadata Space Used: 35.81MB Metadata Space Total: 2.147GB Metadata Space Available: 2.112GB Thin Pool Minimum Free Space: 10.74GB Deferred Removal Enabled: true Deferred Deletion Enabled: true Deferred Deleted Device Count: 1 Library Version: 1.02.140-RHEL7 (2017-05-03)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-693.11.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 36Total Memory: 117.9GiBName: jenkins-node.comID: 5M6L:G2KF:732H:Y7RF:QHNO:3XM4:U6RV:U5QR:ANPA:7XRZ:M3S4:GUZCDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 37 Goroutines: 51 System Time: 2018-01-04T16:02:36.54459153Z EventsListeners: 0Registry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: devicemapper: usage of loopback devices is strongly discouraged for production use.         Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.```
"
35931,0,1657,0,0,0,Foxsa,0,"title:Filter ""before"" stopped working. description:**Description**When I try to use filter before to find earlier containers I got:```Error response from daemon: no such container <container_name>```**Steps to reproduce the issue:**1. docker run -d --name=ubuntu -it ubuntu bash2. docker ps -a -f name=ubuntu3. docker ps -a -f before=ubuntu**Describe the results you received:**when filter is ```name=ubuntu``` then i get container in listand when filter is: ```before=ubuntu``` i get the error**Describe the results you expected:**nothing or container created before this one**Output of `docker version`:**```Client: Version:	17.12.0-ce API version:	1.35 Go version:	go1.9.2 Git commit:	c97c6d6 Built:	Wed Dec 27 20:11:19 2017 OS/Arch:	linux/amd64Server: Engine:  Version:	17.12.0-ce  API version:	1.35 (minimum version 1.12)  Go version:	go1.9.2  Git commit:	c97c6d6  Built:	Wed Dec 27 20:09:53 2017  OS/Arch:	linux/amd64  Experimental:	false```**Output of `docker info`:**```Containers: 14 Running: 11 Paused: 0 Stopped: 3Images: 8Server Version: 17.12.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.58-xxxx-std-ipv6-64Operating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 16Total Memory: 62.87GiBName: temp1ID: DJML:ZOE7:4LM3:A46E:CECU:ZN6J:7PRD:QCS6:E3PW:5V2B:XXPK:PGKCDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No cpu cfs quota supportWARNING: No cpu cfs period support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical machine**PS** On old docker-ce 17.03.1-ce it works perfectly  
"
35920,0,1715,277,0,0,joke,0,"title:Docker ps: filter container by health=starting. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**The filter option of docker ps should support filtering containers by health=starting as stated in the [docker ps documentation](https://docs.docker.com/engine/reference/commandline/ps/#filtering).Unfortunately the output listing is empty even though containers are currently in health check state starting.**Steps to reproduce the issue:**1. Start a container with health check2. Make sure the container is health check state starting3. Run `docker ps -f health=starting`4. Make sure the container is still in health check state starting and did change state in the meantime**Describe the results you received:**Step 3. should display a list of running containers current in health check starting state.**Describe the results you expected:**Step 3. simply returns an empty table with no containers at all.**Additional information you deem important (e.g. issue happens only occasionally):**Filtering for `health=healthy`, `health=unhealthy`, `health=none` is working correctly.The Filter option `health=starting` is understood correctly. `health=stopping` returns ""Unrecognised filter value"".**Output of `docker version`:**```Client: Version:       17.12.0-ce API version:   1.35 Go version:    go1.9.2 Git commit:    c97c6d6 Built: Wed Dec 27 20:10:45 2017 OS/Arch:       linux/amd64Server: Engine:  Version:      17.12.0-ce  API version:  1.35 (minimum version 1.12)  Go version:   go1.9.2  Git commit:   c97c6d6  Built:        Wed Dec 27 20:09:19 2017  OS/Arch:      linux/amd64  Experimental: false```**Output of `docker info`:**```Containers: 4 Running: 0 Paused: 0 Stopped: 4Images: 65Server Version: 17.12.0-ceStorage Driver: aufs Root Dir: /app/docker/aufs Backing Filesystem: extfs Dirs: 126 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.10.0-37-genericOperating System: Ubuntu 17.04OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.2GiBName: ets-20170744ID: UQEP:CSSG:3PZN:ONR7:TR5Y:RSDZ:4I7I:5EL2:WYJE:O57Y:X5C4:N4XHDocker Root Dir: /app/dockerDebug Mode (client): falseDebug Mode (server): falseHTTP Proxy: http://localhost:3128/HTTPS Proxy: http://localhost:3128No Proxy: localhost,127.0.0.1,mgrsfxrepned001.fx.eos.lclRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical on Ubuntu 17.04
"
35891,0,3971,0,0,0,nscheer,0,"title:After upgrading to 17.12.0-ce containers are reported as ""unknown"" on start. description:**Description**Just upgraded to docker 17.12.0-ce on one of our CentOS VPS-boxes. Everything seems to run fine so far, but a `journalctl -u docker` shows errors about ""unknown"" containers, e.g.:```Dec 28 21:11:37 ***** dockerd[20364]: time=""2017-12-28T21:11:37.395119873+01:00"" level=warning msg=""unknown container"" container=380a254343d466da3481d10a9eb00b5ceb0246d5af80ed458875b4cff0ce5272 module=libcontainerd namespace=plugins.moby```Apparently it complains about every container that runs on the machine. I tried to recreate all the containers, but that does not change anything. After a short investigation I noticed, that this message is emitted on every container creation, at least in our setup.**Steps to reproduce the issue:**1. docker pull alpine:3.72. docker run --rm -it alpine:3.7 sh3. [ctrl+d]**Describe the results you received:**On container start, I get:```Dec 28 21:37:16 ***** dockerd[20364]: time=""2017-12-28T21:37:16.078480737+01:00"" level=info msg=""ignoring event"" module=libcontainerd namespace=moby topic=/containers/create type=""*events.ContainerCreate""Dec 28 21:37:16 ***** dockerd[20364]: time=""2017-12-28T21:37:16+01:00"" level=info msg=""shim docker-containerd-shim started"" address=""/containerd-shim/moby/3c63b33d715570dd874f244f3dc4dba4ac606f1420ce7e24d52401fbcdcb3402/shim.sock"" debug=false module=""containerd/tasks"" pid=22712Dec 28 21:37:16 ***** dockerd[20364]: time=""2017-12-28T21:37:16.278804687+01:00"" level=warning msg=""unknown container"" container=3c63b33d715570dd874f244f3dc4dba4ac606f1420ce7e24d52401fbcdcb3402 module=libcontainerd namespace=plugins.mobyDec 28 21:37:16 ***** dockerd[20364]: time=""2017-12-28T21:37:16.313901450+01:00"" level=warning msg=""unknown container"" container=3c63b33d715570dd874f244f3dc4dba4ac606f1420ce7e24d52401fbcdcb3402 module=libcontainerd namespace=plugins.moby```On container stop:```Dec 28 21:37:28 ***** dockerd[20364]: time=""2017-12-28T21:37:28.254949107+01:00"" level=warning msg=""unknown container"" container=3c63b33d715570dd874f244f3dc4dba4ac606f1420ce7e24d52401fbcdcb3402 module=libcontainerd namespace=plugins.mobyDec 28 21:37:28 ***** dockerd[20364]: time=""2017-12-28T21:37:28+01:00"" level=info msg=""shim reaped"" id=3c63b33d715570dd874f244f3dc4dba4ac606f1420ce7e24d52401fbcdcb3402 module=""containerd/tasks""Dec 28 21:37:28 ***** dockerd[20364]: time=""2017-12-28T21:37:28.330940300+01:00"" level=info msg=""ignoring event"" module=libcontainerd namespace=plugins.moby topic=/tasks/delete type=""*events.TaskDelete""Dec 28 21:37:28 ***** dockerd[20364]: time=""2017-12-28T21:37:28.331907436+01:00"" level=info msg=""ignoring event"" module=libcontainerd namespace=moby topic=/tasks/delete type=""*events.TaskDelete""Dec 28 21:37:28 ***** dockerd[20364]: time=""2017-12-28T21:37:28.376950290+01:00"" level=info msg=""ignoring event"" module=libcontainerd namespace=moby topic=/containers/delete type=""*events.ContainerDelete""```**Describe the results you expected:**There should be no warnings.**Output of `docker version`:**```Client: Version:       17.12.0-ce API version:   1.35 Go version:    go1.9.2 Git commit:    c97c6d6 Built: Wed Dec 27 20:10:14 2017 OS/Arch:       linux/amd64Server: Engine:  Version:      17.12.0-ce  API version:  1.35 (minimum version 1.12)  Go version:   go1.9.2  Git commit:   c97c6d6  Built:        Wed Dec 27 20:12:46 2017  OS/Arch:      linux/amd64  Experimental: false```**Output of `docker info`:**```Containers: 6 Running: 4 Paused: 0 Stopped: 2Images: 48Server Version: 17.12.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.4.27-x86_64-jb1Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.903GiBName: **************ID: VBJF:EXSO:5X7A:CY5M:ITIS:6SNX:5JIK:HXKR:YHBY:QUNE:245Q:5LJGDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: nscheerRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**The environment is provided by our hoster, as is the kernel. I've tested another machine using CentOS 7.4 as well, but with a elrepo kernel (4.13.8-1.el7.elrepo.x86_64), but IMHO this does not look like a kernel issue.The daemon.json is quite simple, so no surprises here:```{    ""storage-driver"": ""overlay2"",    ""log-driver"": ""json-file"",    ""log-opts"":    {        ""max-size"": ""10m"",        ""max-file"": ""3""    }}```
"
35843,0,1630,2,0,0,MarkusMattinen,0,"title:Health check no longer uses the container's working directory. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Previously if a working directory was defined for a container, health checks would also use that as their working directory. This is no longer the case with v17.12.0-ce-rc3. Health checks now ignore the working directory configuration and just use `/` as their working directory.**Steps to reproduce the issue:**1. `docker run -d -w /tmp --name health_check_test --health-cmd pwd --health-interval 5s busybox tail -f /dev/null`2. `sleep 6 && docker inspect --format '{{ (index (.State.Health.Log) 0).Output }}' health_check_test`The result is also the same if the working directory and health check are defined at the image level instead of at the container level.**Describe the results you received:**Health check uses working directory `/`.**Describe the results you expected:**Health check should use working directory `/tmp` as defined in the container configuration.**Additional information you deem important (e.g. issue happens only occasionally):**Health check uses the correct working directory at least in v17.11.0-ce.**Output of `docker version`:**```Client: Version:	17.12.0-ce-rc3 API version:	1.35 Go version:	go1.9.2 Git commit:	80c8033 Built:	Thu Dec 14 00:39:46 2017 OS/Arch:	darwin/amd64Server: Engine:  Version:	17.12.0-ce-rc3  API version:	1.35 (minimum version 1.12)  Go version:	go1.9.2  Git commit:	80c8033  Built:	Thu Dec 14 00:45:43 2017  OS/Arch:	linux/amd64  Experimental:	true```**Output of `docker info`:**```Containers: 8 Running: 7 Paused: 0 Stopped: 1Images: 637Server Version: 17.12.0-ce-rc3Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.60-linuxkit-aufsOperating System: Docker for MacOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.855GiBName: linuxkit-025000000001ID: RQDH:HHCP:TGAI:HZ2P:ATR2:KY3M:X3MS:52Y6:FKRB:LBBU:GARN:O4ONDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 43 Goroutines: 70 System Time: 2017-12-20T11:35:55.352479601Z EventsListeners: 2Registry: https://index.docker.io/v1/Labels:Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Docker on Mac
"
35821,0,576,200,1,0,thaJeztah,0,"title:docker container start creates host-directory for mount, but shouldn't. description:As reported by @h45rd in https://github.com/moby/moby/issues/13121#issuecomment-352373883;**Description**The `--mount type=bind` option requires the host-directory/file to exist, and produce an error if the path is not found.Docker correctly produces an error on `docker run` and `docker container create`, but when _starting_ the container (`docker container start`), no error is produced, and the host-path is created instead.**Steps to reproduce the issue:**Create a container that bind mounts a non-existing host-directory;```bash$ mkdir repro-35821 && cd repro-35821$ docker create --name repro-35821 \  --mount type=bind,source=""$(pwd)""/once-existed,target=/app \  busyboxError response from daemon: invalid mount config for type ""bind"": bind source path does not exist```During create, an error is produced (as expected); this is the correct behaviour.Now, creating the directory to allow `docker create` to succeed, but _don't start_ the container;```bash$ mkdir once-existed$ docker create --name repro-35821 \   --mount type=bind,source=""$(pwd)""/once-existed,target=/app \   busyboxa7b4d510d1afd3eabea59414b94e9565af2927606f8a79f27aa855f3a8ea2817```Now, remove the directory, and verify the directory is gone;```bash$ rm -r once-existed$ ls(empty)```Start the container, and observe that no error is produced, but host directory is being created;```bash$ docker start repro-35821repro-13121$ lsonce-existed```**Describe the results you received:**`docker start` / `docker container start` does not produce an error, but creates the host directory**Describe the results you expected:**`docker start` / `docker container start` to produce an error and refusing to start if the host directory does not exist.**Output of `docker version`:**Reproduced on  Docker 17.11.0, but likely to still exist on current master (can update the issue after updating this machine)
"
35815,0,0,279,0,0,cpuguy83,0,"title:vfs graphdriver fails to initialize due to projectquota. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->A failure to setup the project quota can make the vfs driver fail to initialize and abort daemon startup.**Steps to reproduce the issue:**1. Start daemon with vfs driver backed by osxfs**Describe the results you received:**> Error starting daemon: error initializing graphdriver: Failed to mknod /go/src/github.com/docker/docker/bundles/test-integration/d6bcf6de610e9/root/vfs/backingFsBlockDev: function not implemented**Describe the results you expected:**Daemon should start even though the project quota setup failed
"
35774,1,1359,300,0,0,pearofducks,0,"title:Multistage builds persist data from previous steps. description:When building a multistage image, artifacts from previous stages persist to later ones (when they logically shouldn't).Quick example:```FROM alpine as builder...do stuffFROM alpine...problem here!```At `problem here`, data is visible from the `builder` step, even if it wasn't copied.**Steps to reproduce the issue:**1. Clone and build https://github.com/pearofducks/docker-multistage-bugVerbose version:1. `docker build -t bug .`2. `docker run -it bug ls`3. Verify output is `Dockerfile  bar         baz         foo`**Describe the results you received:**The `/app` directory is populated with content from the first build's COPY step.**Describe the results you expected:**The `/app` directory should be clean (empty) since we're using `FROM` a base image.As in - `alpine`s `/app` directory is empty, so a build step stating `FROM alpine` should have an empty `/app` directory.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Docker version 17.09.1-ce, build 19e2cf6```**Output of `docker info`:**```Containers: 1 Running: 0 Paused: 0 Stopped: 1Images: 6Server Version: 17.09.1-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 3f2f8b84a77f73d38244dd690525642a72156c64init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.49-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.952GiBName: mobyID: 2BNX:GJ22:RWF7:2PKN:H6VC:4WWY:MLB6:MTGK:EPJD:ENXS:MS2C:PNA5Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 19 Goroutines: 31 System Time: 2017-12-12T13:42:59.872222193Z EventsListeners: 1No Proxy: *.local, 169.254/16Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```
"
35757,0,1516,233,0,1,mpalmer,0,"title:Restarting dockerd causes IPv6 networking to be deconfigured in all containers. description:**Description**When `dockerd` is restarted, and the `--live-restore=true` flag is in use, existing containers are not restarted (good!), but any IPv6 networking configuration the containers have is completely destroyed (bad!).  A restart of the container is required to reinstate IPv6 networking.**Steps to reproduce the issue:**1. Install the latest version of Docker (`curl https://get.docker.com | sh`).  I used an Ubuntu 14.04.5 x64 Digital Ocean droplet for my reproduction test, as it is fairly close to our production environment.2. Set `DOCKER_OPTS` in `/etc/default/docker` to something like        DOCKER_OPTS=""--ipv6 --fixed-cidr-v6=2001:db8::/64 -s aufs --bip 172.17.0.1/16 --log-opt max-size=1m --log-opt max-file=2 --live-restore=true --raw-logs""3. Restart docker with `service docker restart`4. Create a container:        # docker run -dit --name test busybox sh5. Verify that it does, in fact, have some IPv6ness going on:        # docker exec test ip -6 ad sh        1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536             inet6 ::1/128 scope host                valid_lft forever preferred_lft forever        10: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500             inet6 2001:db8::242:ac11:2/64 scope global flags 02                valid_lft forever preferred_lft forever            inet6 fe80::42:acff:fe11:2/64 scope link                valid_lft forever preferred_lft forever        # docker exec test ip -6 ro sh        2001:db8::/64 dev eth0  metric 256         fe80::/64 dev eth0  metric 256         default via 2001:db8::1 dev eth0  metric 1024         unreachable default dev lo  metric -1  error -101        ff00::/8 dev eth0  metric 256         unreachable default dev lo  metric -1  error -1016. Restart docker:        # service docker restart7. Verify that the container didn't restart:        # docker ps        CONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMES        70e3de2aed43        busybox             ""sh""                About a minute ago   Up About a minute                       test8. Check IPv6 networking:        # docker exec test ip -6 ad sh        # docker exec test ip -6 ro sh        unreachable default dev lo  metric -1  error -101        unreachable default dev lo  metric -1  error -101**Describe the results you received:**None of my containers had IPv6 networking until they were manually restarted.**Describe the results you expected:**My containers had IPv6 networking, without needing to restart.**Output of `docker version`:**```Client: Version:      17.11.0-ce API version:  1.34 Go version:   go1.8.3 Git commit:   1caf76c Built:        Mon Nov 20 18:36:37 2017 OS/Arch:      linux/amd64Server: Version:      17.11.0-ce API version:  1.34 (minimum version 1.12) Go version:   go1.8.3 Git commit:   1caf76c Built:        Mon Nov 20 18:35:10 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 1Server Version: 17.11.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 3 Dirperm1 Supported: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 992280e8e265f491f7a624ab82f3e238be086e49runc version: 0351df1c5a66838d0c392b4ac4cf9450de844e2dinit version: 949e6faSecurity Options: apparmorKernel Version: 3.13.0-135-genericOperating System: Ubuntu 14.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 993.9MiBName: docker-fuckup-testID: AQLH:V7FG:MRUD:7DD2:VVAA:JX5F:RRQS:4X4H:ZOEP:XE3N:EOWI:X37UDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: true```**Additional environment details (AWS, VirtualBox, physical, etc.):**This reproduction was carried out in a DigitalOcean droplet created just now from the Ubuntu 14.04.5 x64 base image, running the above Docker version.  Our production environment, in which this problem manifested itself, is Ubuntu 14.04.5 running on bare metal, on Docker 17.06.2-ce (commit `cec0b72`).  We had previously upgraded from Docker 1.12, so the problem could have been introduced anywhere between 1.12 and 17.06.2-ce.
"
35725,0,2578,94,0,1,jahkeup,0,"title:awslogs batch size exceeds service limits . description:**Description**awslogs driver improperly batches log messages that are too large for CloudWatch to accept. This is due to incorrect accounting of the total size of the message being logged. The overhead and total byte size calculation is not maintained between the scopes that evaluate the service limit.I have prepared a patch to fix this issue ~~and will open a pull request~~ [link here](https://github.com/moby/moby/pull/35726).**Steps to reproduce the issue:**1. Run docker container with awslogs driver.2. Log a message larger than the allowed limit (1048576), such as 1048685 bytes from that container.3. Observe docker log output.**Describe the results you received:**Container log messages are not logged to CloudWatch and are instead dropped by the driver due to an ""exception"" (error). This is error is printed in the Docker log:```time=""2017-12-06T23:34:21.421389421Z"" level=error msg=""Failed to put log events"" errorCode=InvalidParameterException logGroupName=cbcab4da0300039d1d8e10b40b053ea5 logStreamName=""klines/klines/5c8ae105-9de2-40ab-ab8d-7b0bfd46a01a"" message=""Upload too large: 1048815 bytes exceeds limit of 1048576"" origError=<nil> time=""2017-12-06T23:34:21.421436838Z"" level=error msg=""InvalidParameterException: Upload too large: 1048815 bytes exceeds limit of 1048576\n\tstatus code: 400, request id: fc4705d1-dadd-11e7-8ef0-21e93a30f134"" ```**Describe the results you expected:**I expected the log messages to be split as needed to log the message to CloudWatch Logs.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.06.2-ce API version:  1.30 Go version:   go1.8.4 Git commit:   3dfb8343b139d6342acfd9975d7f1068b5b1c3d3 Built:        Fri Nov 10 00:50:37 2017 OS/Arch:      linux/amd64Server: Version:      17.06.2-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.4 Git commit:   402dd4a/17.06.2-ce Built:        Fri Nov 10 00:51:08 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 3 Running: 1 Paused: 0 Stopped: 2Images: 3Server Version: 17.06.2-ceStorage Driver: devicemapper Pool Name: docker-docker--pool Pool Blocksize: 524.3kB Base Device Size: 10.74GB Backing Filesystem: ext4 Data file:  Metadata file:  Data Space Used: 1.239GB Data Space Total: 23.33GB Data Space Available: 22.09GB Metadata Space Used: 593.9kB Metadata Space Total: 25.17MB Metadata Space Available: 24.57MB Thin Pool Minimum Free Space: 2.333GB Udev Sync Supported: true Deferred Removal Enabled: true Deferred Deletion Enabled: true Deferred Deleted Device Count: 0 Library Version: 1.02.135-RHEL7 (2016-11-16)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 6e23458c129b551d5c9871e5174f6b1b7f6d1170runc version: 810190ceaa507aa2727d7ae6f4790c76ec150bd2init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.62-21.56.amzn1.x86_64Operating System: Amazon Linux AMI 2017.09OSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 1.955GiBName: ip-172-31-38-65ID: XNRA:RMA2:5VQ5:NLVZ:WAWS:VJFF:24R7:RZNS:32X4:DRF2:SA2S:WP7CDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**AWS on a t2.small
"
35709,0,1974,12,0,0,zibok,0,"title:[Build] File deletion does not work in userns enabled engine. description:**Description**In docker with userns-remap option activated, removing a file from a previous layer is not taken into account. In syslog, we find errors like:```Can't add file /var/lib/docker/500000.500000/overlay2/xxxx/diff/path/to/file to tar: Host ID 0 cannot be mapped to a container ID```**Steps to reproduce the issue:**1. Run docker with `--user-remap=default`2. Use the Dockerfile```FROM busyboxRUN echo ""foo"" > /barRUN rm -f /barRUN ls -la /bar```3. `docker build --cache .`**Describe the results you received:**You will see the last step still shows /bar existsIn syslog, you find a:```msg=""Can't add file /var/lib/docker/500000.500000/overlay2/ae3d56600bb897918129265a43f0b54a7693d190ce1a4d8ab333787673c41dd0/diff/bar to tar: Host ID 0 cannot be mapped to a container ID""```**Describe the results you expected:**/bar should not be visible in the last layer**Additional information you deem important (e.g. issue happens only occasionally):**Issue is reproductible**Output of `docker version`:**```Client: Version:      17.09.0-ce API version:  1.32 Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:42:09 2017 OS/Arch:      linux/amd64Server: Version:      17.09.0-ce API version:  1.32 (minimum version 1.12) Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:40:48 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 1 Running: 0 Paused: 0 Stopped: 1Images: 47Server Version: 17.09.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 3f2f8b84a77f73d38244dd690525642a72156c64init version: 949e6faSecurity Options: seccomp  Profile: default usernsKernel Version: 4.9.0-4-amd64Operating System: Debian GNU/Linux 9 (stretch)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 492.4MiBName: stretchID: HJSC:OKNJ:FNOI:2G52:OYNL:KULV:C3P5:W5YC:Y4NX:LH2C:QZVB:SQCNDocker Root Dir: /var/lib/docker/500000.500000Debug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Reproductible on a vagrant box running Debian 9
"
35649,1,2438,1,0,0,romanlevin,0,"title:fatal error: concurrent map writes. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**When running Docker on a Vagrant box based off of ubuntu/xenial64, all containers hang and Docker can't stop them. Looking at the daemon logs reveals a fatal error (attached below). Though the logs state that the Daemon has been restarted, the problem persists until `service docker restart`.My host machine is a mid-2015 MacBook Pro 15"" running High Sierra.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**Seems to happen randomly, but at least twice a day. As far as I can tell this only happens while running a Docker Compose swarm, but the two might not be related because I usually run containers using Docker Compose.**Output of `docker version`:**```Client: Version:      17.11.0-ce API version:  1.34 Go version:   go1.8.3 Git commit:   1caf76c Built:        Mon Nov 20 18:37:39 2017 OS/Arch:      linux/amd64Server: Version:      17.11.0-ce API version:  1.34 (minimum version 1.12) Go version:   go1.8.3 Git commit:   1caf76c Built:        Mon Nov 20 18:36:09 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 15 Running: 15 Paused: 0 Stopped: 0Images: 140Server Version: 17.11.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 992280e8e265f491f7a624ab82f3e238be086e49runc version: 0351df1c5a66838d0c392b4ac4cf9450de844e2dinit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-101-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 3.859GiBName: turbo-devID: 6JA3:MIAP:ICRO:OGAD:HRKZ:LIN5:GPUM:LA3T:AZD3:7OZF:EBYO:7VZ2Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Docker log excerpt**```Nov 30 11:00:03 turbo-dev dockerd[1197]: fatal error: concurrent map writesNov 30 11:00:03 turbo-dev dockerd[1197]: goroutine 21510 [running]:Nov 30 11:00:03 turbo-dev dockerd[1197]: runtime.throw(0x2a8410d, 0x15)Nov 30 11:00:03 turbo-dev dockerd[1197]:         /usr/local/go/src/runtime/panic.go:596 +0x95 fp=0xc420a9d7d8 sp=0xc420a9d7b8Nov 30 11:00:03 turbo-dev dockerd[1197]: runtime.mapassign(0x27991a0, 0xc4201f2ea0, 0xc420a9d8b8, 0x40)Nov 30 11:00:03 turbo-dev dockerd[1197]:         /usr/local/go/src/runtime/hashmap.go:499 +0x667 fp=0xc420a9d878 sp=0xc420a9d7d8Nov 30 11:00:03 turbo-dev dockerd[1197]: github.com/docker/docker/daemon.(*Daemon).registerExecPidUnlocked(0xc42046c800, 0xc4212146c0, 0xc4200d5200)Nov 30 11:00:03 turbo-dev dockerd[1197]:         /go/src/github.com/docker/docker/daemon/exec.go:39 +0x218 fp=0xc420a9d918 sp=0xc420a9d878...```The full stack trace is here: https://pastebin.com/7DxBSs0v
"
35641,0,2263,1,0,0,vlk-charles,0,"title:Files leaking to other images in a multi-stage build. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Files can leak from one image to a different one in a multi-stage build process. I was able to isolate the bug to the following minimalist case.**Steps to reproduce the issue:**1. `echo 'This file should only appear in the first image.' >afile`2. `echo 'This file should only appear in the second image.' >bfile`3. Save this `Dockerfile`:```FROM alpineWORKDIR /rootCOPY afile .FROM alpineWORKDIR /rootCOPY bfile .```4. `docker build .`5. `docker run --rm <second image> ls`**Describe the results you received:**```afilebfile```**Describe the results you expected:**```bfile```**Additional information you deem important (e.g. issue happens only occasionally):**The bug is consistent on this machine but is not present on a different virtual server with CentOS 7, XFS, and devicemapper.As can be seen from the log, the `WORKDIR` instruction is cached:```Sending build context to Docker daemon  4.096kBStep 1/6 : FROM alpine ---> 665ffb03bfaeStep 2/6 : WORKDIR /root ---> 24e2272aca94Removing intermediate container ebdaacce5267Step 3/6 : COPY afile . ---> 9507351e2ff4Step 4/6 : FROM alpine ---> 665ffb03bfaeStep 5/6 : WORKDIR /root ---> Using cache ---> 24e2272aca94Step 6/6 : COPY bfile . ---> b7a5fa8bdc29Successfully built b7a5fa8bdc29````ls` lists no files on the common intermediate layer (24e2272aca94).If I add another unique no-op instruction before the `COPY` to break the caching at that layer:```FROM alpineWORKDIR /rootRUN echo no-op layer 1COPY afile .FROM alpineWORKDIR /rootRUN echo no-op layer 2COPY bfile .```, the files are where they should be. I will be using this approach as a work-around for now.**Output of `docker version`:**```Client: Version:      17.09.0-ce API version:  1.32 Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:42:18 2017 OS/Arch:      linux/amd64Server: Version:      17.09.0-ce API version:  1.32 (minimum version 1.12) Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:40:56 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 11 Running: 11 Paused: 0 Stopped: 0Images: 190Server Version: 17.09.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 3f2f8b84a77f73d38244dd690525642a72156c64init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.8.0-58-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 25.51GiBName: ubuntu1ID: ZSC7:3VAV:U3JD:XIUN:OLEV:HS2T:GTYX:RE6E:WQHC:4CDB:WGWI:IQKFDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**This on a physical server. `/etc/docker/daemon.json` only contains:```{""storage-driver"": ""overlay2""}```
"
35626,0,2389,0,0,0,ikarpovich,0,"title:Logentries log driver line-only option breaks backwards compatibility. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/moby/moby/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support for **docker** can be found at the following locations:- Docker Support Forums - https://forums.docker.com- Slack - community.docker.com #general channel- Post a question on StackOverflow, using the Docker tagGeneral support for **moby** can be found at the following locations:- Moby Project Forums - https://forums.mobyproject.org- Slack - community.docker.com #moby-project channel- Post a question on StackOverflow, using the Moby tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**New log driver option `line-only` for Logentries driver described in #31726 allows to dump raw data to Logentries without wrapping it into container data. However this flag breaks backwards compatibility so you won't be able to launch new container without specifying `--log-opt line-only=true/false` and all your swarm stacks will stop working with the engine update.**Steps to reproduce the issue:**`docker run --log-driver=logentries --log-opt logentries-token=... alpine`**Describe the results you received:**`docker: Error response from daemon: failed to initialize logging driver: error parsing lineonly option: strconv.ParseBool: parsing """": invalid syntax.`**Describe the results you expected:**No error should be produced, old behaviour (line-only=false) should be the default**Output of `docker version`:**```Client: Version:      17.09.0-ce API version:  1.32 Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:39:28 2017 OS/Arch:      linux/amd64Server: Version:      17.09.0-ce API version:  1.32 (minimum version 1.12) Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:45:38 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 10 Running: 7 Paused: 0 Stopped: 3Images: 59Server Version: 17.09.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: i1hl69si1y513f8f64fcnccpu Is Manager: true ClusterID: zbyn1azkfdoi9rzbhedmd6kuv Managers: 5 Nodes: 8 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 172.37.38.140 Manager Addresses:  172.37.12.237:2377  172.37.18.17:2377  172.37.33.179:2377  172.37.38.140:2377  172.37.8.184:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 3f2f8b84a77f73d38244dd690525642a72156c64init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.49-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 3.67GiBName: ip-172-37-38-140.eu-west-1.compute.internalID: 6ETS:MRMJ:VQNJ:4AN7:IWCT:JWG3:IRMH:FUKM:S7ZC:42ZJ:5LOH:TP2PDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 140 Goroutines: 1193 System Time: 2017-11-28T09:12:43.721232058Z EventsListeners: 3Registry: https://index.docker.io/v1/Labels: os=linux region=eu-west-1 availability_zone=eu-west-1c instance_type=m3.medium node_type=managerExperimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**This is Docker for AWS 17.09-ce (Stable)
"
35613,0,3201,0,0,0,stszap,0,"title:docker crashes when using gelf log driver in tcp mode and logging server becomes unavailable. description:**Description**I experimented with new tcp mode for gelf log driver and found out that docker crashes when log server goes down.**Steps to reproduce the issue:**1. start something to imitate log server ex: ""nc -l -p 12000""2. start container ""docker run  --rm -it --log-driver gelf --log-opt gelf-address=tcp://127.0.0.1:12000  debian bash""3. type something in the container's terminal (generate some logs)4. stop the nc process5. type something again in the container's terminal (generate some more logs)**Describe the results you received:**Docker crashes with the following logs:```panic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x58 pc=0x2455211]goroutine 210 [running]:github.com/docker/docker/vendor/github.com/Graylog2/go-gelf/gelf.(*TCPWriter).writeToSocketWithReconnectAttempts(0xc421d57490, 0xc421d59800, 0x1b5, 0x400, 0x0, 0x0, 0xc4205d0d40)	/var/tmp/portage/app-emulation/docker-17.11.0/work/docker-17.11.0/src/github.com/docker/docker/vendor/github.com/Graylog2/go-gelf/gelf/tcpwriter.go:83 +0x71github.com/docker/docker/vendor/github.com/Graylog2/go-gelf/gelf.(*TCPWriter).WriteMessage(0xc421d57490, 0xc421b29200, 0x1d, 0x100)	/var/tmp/portage/app-emulation/docker-17.11.0/work/docker-17.11.0/src/github.com/docker/docker/vendor/github.com/Graylog2/go-gelf/gelf/tcpwriter.go:53 +0x92github.com/docker/docker/daemon/logger/gelf.(*gelfLogger).Log(0xc4204b8700, 0xc421d1c0e0, 0x1d, 0x4000)	/var/tmp/portage/app-emulation/docker-17.11.0/work/docker-17.11.0/src/github.com/docker/docker/daemon/logger/gelf/gelf.go:186 +0x255github.com/docker/docker/daemon/logger.(*Copier).copySrc(0xc421c4fc40, 0x2a462be, 0x6, 0x7f754d89dc10, 0xc421c4fa40)	/var/tmp/portage/app-emulation/docker-17.11.0/work/docker-17.11.0/src/github.com/docker/docker/daemon/logger/copier.go:100 +0x471created by github.com/docker/docker/daemon/logger.(*Copier).Run	/var/tmp/portage/app-emulation/docker-17.11.0/work/docker-17.11.0/src/github.com/docker/docker/daemon/logger/copier.go:46 +0x118```**Describe the results you expected:**No crash.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.11.0-ce API version:  1.34 Go version:   go1.8.3 Git commit:   1caf76c Built:        Mon Nov 27 10:56:33 2017 OS/Arch:      linux/amd64Server: Version:      17.11.0-ce API version:  1.34 (minimum version 1.12) Go version:   go1.8.3 Git commit:   1caf76c Built:        Mon Nov 27 10:55:29 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 4 Running: 4 Paused: 0 Stopped: 0Images: 747Server Version: 17.11.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 992280 (expected: 992280e8e265f491f7a624ab82f3e238be086e49)runc version: 0351df1 (expected: 0351df1c5a66838d0c392b4ac4cf9450de844e2d)init version: v0.16.1 (expected: 949e6facb77383876aeff8a6944dde66b3089574)Security Options: seccomp  Profile: defaultKernel Version: 4.9.16-gentooOperating System: Gentoo/LinuxOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 7.673GiBName: stas.officeID: 6XIR:QBFD:VPGE:A6QA:6EIA:OOE4:CWZB:4ODI:IOZF:THCT:HOP4:AYXSDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 18 Goroutines: 34 System Time: 2017-11-27T20:31:26.54513255+05:00 EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**physical
"
35588,0,1951,17,0,0,bryanlarsen,0,"title:fatal error: concurrent map writes. description:**Description**Docker crashes under heavy load with fatal error: concurrent map writes**Steps to reproduce the issue:**~20 or so simultaneous docker builds, along with some docker-compose action.**Describe the results you received:**Docker crashes.   (backtrace attached)**Describe the results you expected:**It keeps working**Additional information you deem important (e.g. issue happens only occasionally):**it happened twice already today, upgraded to 17.11 this morning.**Output of `docker version`:**```Client: Version:      17.11.0-ce API version:  1.34 Go version:   go1.8.3 Git commit:   1caf76c Built:        Mon Nov 20 18:37:39 2017 OS/Arch:      linux/amd64Server: Version:      17.11.0-ce API version:  1.34 (minimum version 1.12) Go version:   go1.8.3 Git commit:   1caf76c Built:        Mon Nov 20 18:36:09 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 17.11.0-ceStorage Driver: devicemapper Pool Name: docker-thinpool Pool Blocksize: 524.3kB Base Device Size: 10.74GB Backing Filesystem: xfs Udev Sync Supported: true Data Space Used: 20.45MB Data Space Total: 427.2GB Data Space Available: 427.2GB Metadata Space Used: 516.1kB Metadata Space Total: 4.496GB Metadata Space Available: 4.496GB Thin Pool Minimum Free Space: 42.72GB Deferred Removal Enabled: true Deferred Deletion Enabled: true Deferred Deleted Device Count: 0 Library Version: 1.02.110 (2015-10-30)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 992280e8e265f491f7a624ab82f3e238be086e49runc version: 0351df1c5a66838d0c392b4ac4cf9450de844e2dinit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.10.0-40-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.36GiBName: dev037ID: G3I4:4LA6:2C4Y:LFJN:6R3M:KPS6:XELU:LEJO:T4KV:XQNF:E62X:MBUODocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**physical.Intel(R) Core(TM) i7-4790K CPU @ 4.00GHzbacktrace:  https://gist.github.com/bryanlarsen/e8eb30dabb37a429d9b82c1fb12e66de
"
35575,0,0,2,0,0,sylvainmouquet,0,"title:Docker daemon crash . description:The sock is not available in a container :`Provider connection error Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?, retrying in 10.20560755s`[logs.txt](https://github.com/moby/moby/files/1496491/logs.txt)Docker swarm version> $ docker version> Client:>  Version:      17.11.0-ce>  API version:  1.34>  Go version:   go1.8.3>  Git commit:   1caf76c>  Built:        Mon Nov 20 18:37:39 2017>  OS/Arch:      linux/amd64> > Server:>  Version:      17.11.0-ce>  API version:  1.34 (minimum version 1.12)>  Go version:   go1.8.3>  Git commit:   1caf76c>  Built:        Mon Nov 20 18:36:09 2017>  OS/Arch:      linux/amd64>  Experimental: false> 
"
35561,1,7251,0,0,1,hongbin,0,"title:exec_resize on an exited exec instance return 500. description:**Description**Call exec_resize return 500 if the exec instance finishes execution.**Steps to reproduce the issue:**```$ docker run -d --name test nginx$ cat > test.py <<EOFimport dockercontainer_id='test'client = docker.APIClient(base_url='unix://var/run/docker.sock')create_res = client.exec_create(    container_id, 'ls', stdin=True, tty=True)exec_id = create_res['Id']client.exec_start(exec_id, False, False, False)client.exec_resize(exec_id, height=100, width=100)EOF$ python test.pyTraceback (most recent call last):  File ""test.py"", line 9, in <module>    client.exec_resize(exec_id, height=100, width=100)  File ""/usr/local/lib/python2.7/dist-packages/docker/utils/decorators.py"", line 34, in wrapper    return f(self, *args, **kwargs)  File ""/usr/local/lib/python2.7/dist-packages/docker/api/exec_api.py"", line 110, in exec_resize    self._raise_for_status(res)  File ""/usr/local/lib/python2.7/dist-packages/docker/api/client.py"", line 222, in _raise_for_status    raise create_api_error_from_http_exception(e)  File ""/usr/local/lib/python2.7/dist-packages/docker/errors.py"", line 31, in create_api_error_from_http_exception    raise cls(e, response=response, explanation=explanation)docker.errors.APIError: 500 Server Error: Internal Server Error (""rpc error: code = Unknown desc = containerd: process not found for container"")```**Describe the results you received:**I received 500 response.**Describe the results you expected:**I expect an 4xx response.**Additional information you deem important (e.g. issue happens only occasionally):**Here is a snapshot of log in server side:```Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.229040663Z"" level=debug msg=""Calling POST /v1.30/containers/test/exec""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.229176122Z"" level=debug msg=""form data: {\""AttachStderr\"":true,\""AttachStdin\"":true,\""AttachStdout\"":true,\""Cmd\"":[\""ls\""],\""Container\"":\""test\"",\""Privileged\"":false,\""Tty\"":true,\""User\"":\""\""}""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.231375609Z"" level=debug msg=""Calling POST /v1.30/exec/266f1f75d23c7e8f462c9a4d413a71b18719ca9ed9ac7564bd30c22d4c97ff7e/start""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.231444040Z"" level=debug msg=""form data: {\""Detach\"":false,\""Tty\"":false}""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.231528622Z"" level=debug msg=""starting exec command 266f1f75d23c7e8f462c9a4d413a71b18719ca9ed9ac7564bd30c22d4c97ff7e in container 0d717293dc2dbd58d17fe06c3a207f4d4170dd58cc7a911aa795ce0c93f8f270""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.233078476Z"" level=debug msg=""attach: stdin: begin""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.233188759Z"" level=debug msg=""attach: stderr: begin""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.233223916Z"" level=debug msg=""attach: stdout: begin""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.295980963Z"" level=debug msg=""libcontainerd: received containerd event: &types.Event{Type:\""start-process\"", Id:\""0d717293dc2dbd58d17fe06c3a207f4d4170dd58cc7a911aa795ce0c93f8f270\"", Status:0x0, Pid:\""266f1f75d23c7e8f462c9a4d413a71b18719ca9ed9ac7564bd30c22d4c97ff7e\"", Timestamp:(*timestamp.Timestamp)(0xc421168cd0)}""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.296009501Z"" level=debug msg=""containerd: process exited"" id=0d717293dc2dbd58d17fe06c3a207f4d4170dd58cc7a911aa795ce0c93f8f270 pid=266f1f75d23c7e8f462c9a4d413a71b18719ca9ed9ac7564bd30c22d4c97ff7e status=0 systemPid=12973Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.296048185Z"" level=debug msg=""libcontainerd: event unhandled: type:\""start-process\"" id:\""0d717293dc2dbd58d17fe06c3a207f4d4170dd58cc7a911aa795ce0c93f8f270\"" pid:\""266f1f75d23c7e8f462c9a4d413a71b18719ca9ed9ac7564bd30c22d4c97ff7e\"" timestamp:<seconds:1511281433 nanos:295722318 > ""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.296735251Z"" level=debug msg=""libcontainerd: received containerd event: &types.Event{Type:\""exit\"", Id:\""0d717293dc2dbd58d17fe06c3a207f4d4170dd58cc7a911aa795ce0c93f8f270\"", Status:0x0, Pid:\""266f1f75d23c7e8f462c9a4d413a71b18719ca9ed9ac7564bd30c22d4c97ff7e\"", Timestamp:(*timestamp.Timestamp)(0xc4211008b0)}""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.297072488Z"" level=debug msg=""attach: stderr: end""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.297096565Z"" level=debug msg=""attach: stdout: end""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.297185407Z"" level=debug msg=""attach: stdin: end""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.299189913Z"" level=debug msg=""Closing buffered stdin pipe""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.299475512Z"" level=debug msg=""Calling POST /v1.30/exec/266f1f75d23c7e8f462c9a4d413a71b18719ca9ed9ac7564bd30c22d4c97ff7e/resize?h=100&w=100""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.300042233Z"" level=debug msg=""FIXME: Got an API for which error does not match any expected type!!!: rpc error: code = Unknown desc = containerd: process not found for container"" error_type=""*status.statusError"" module=apiNov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.300068970Z"" level=error msg=""Handler for POST /v1.30/exec/266f1f75d23c7e8f462c9a4d413a71b18719ca9ed9ac7564bd30c22d4c97ff7e/resize returned error: rpc error: code = Unknown desc = containerd: process not found for container""Nov 21 16:23:53 testzun dockerd[7712]: time=""2017-11-21T16:23:53.300084713Z"" level=debug msg=""FIXME: Got an API for which error does not match any expected type!!!: rpc error: code = Unknown desc = containerd: process not found for container"" error_type=""*status.statusError"" module=api```**Output of `docker version`:**```Client: Version:      17.09.0-ce API version:  1.32 Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:42:18 2017 OS/Arch:      linux/amd64Server: Version:      17.09.0-ce API version:  1.32 (minimum version 1.12) Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:40:56 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 2 Running: 2 Paused: 0 Stopped: 0Images: 17Server Version: 17.09.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host kuryr macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 3f2f8b84a77f73d38244dd690525642a72156c64init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-79-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.796GiBName: testzunID: CDMS:AE4D:KXXN:NDM3:2R33:OS6F:2O7C:Z6XK:CMVK:YFDK:KYZ3:BCLHDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 34 Goroutines: 41 System Time: 2017-11-21T16:28:57.211780408Z EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: falseCluster Store: etcd://10.0.0.3:2379Insecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**VM created by OpenStack. OS: Ubuntu 16.04
"
35472,1,2276,241,1,0,davidxia,0,"title:Remote API: rename container responds with HTTP 400, should be HTTP 409. description:**Description**Remote API: rename container responds with HTTP 400, should be HTTP 409. This happens on both 17.10 and 17.09.**Steps to reproduce the issue:**Create two containers.Rename one container. (For example, to ""foo"".)Using the remote API, POST to /containers/(id or name)/rename?name=foo, i.e. rename the second container to the same name as the first.**Describe the results you received:**The request fails with HTTP 400 bad request.{""message"":""Error when allocating new name: Conflict. The container name \""/1afabc65711aace8-6bf9bc24d807db13\"" is already in use by container \""ca4a1c2132f5debe445c791216bae7c7d0ecacee62b1f5393df2ec21501b37e5\"". You have to remove (or rename) that container to be able to reuse that name.""}**Describe the results you expected:**The request fails with HTTP 409 Conflict, message name already assigned, as described in the [remote API docs][api-doc].  [api-doc]: https://docs.docker.com/engine/api/v1.33/#operation/ContainerRename**Output of `docker version`:**```Client: Version:      17.10.0-ce API version:  1.33 Go version:   go1.8.3 Git commit:   f4ffd25 Built:        Tue Oct 17 19:00:43 2017 OS/Arch:      darwin/amd64Server: Version:      17.10.0-ce API version:  1.33 (minimum version 1.12) Go version:   go1.8.3 Git commit:   f4ffd25 Built:        Tue Oct 17 19:05:23 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 288 Running: 1 Paused: 0 Stopped: 287Images: 121Server Version: 17.10.0-ceStorage Driver: aufs Root Dir: /mnt/sda1/var/lib/docker/aufs Backing Filesystem: extfs Dirs: 729 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: lpzh1yir70ysu8q5y5h1pzug1 Is Manager: true ClusterID: rxvk8l7smfzkcfy99g03q91ce Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: true Root Rotation In Progress: false Node Address: 127.0.0.1 Manager Addresses:  127.0.0.1:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 0351df1c5a66838d0c392b4ac4cf9450de844e2dinit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.4.93-boot2dockerOperating System: Boot2Docker 17.10.0-ce (TCL 7.2); HEAD : 34fe485 - Wed Oct 18 17:16:34 UTC 2017OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.955GiBName: 17.10.0ID: ORAB:O2DJ:HFXW:BCAA:RCAU:3UTJ:JTY2:3G4Z:VMQJ:4DY3:425W:HM5ADocker Root Dir: /mnt/sda1/var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 216 Goroutines: 331 System Time: 2017-11-13T01:24:12.130585157Z EventsListeners: 0Registry: https://index.docker.io/v1/Labels: provider=virtualboxExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```A similar issue was [reported here ](https://github.com/moby/moby/issues/21016) before.
"
35455,0,0,268,1,0,kolyshkin,0,"title:""docker run --tmpfs /dev/shm"" fails with ""Duplicate mount point"". description:(Originally reported here: https://github.com/moby/moby/issues/6758#issuecomment-342939512)It is not possible to add a /dev/shm mount using `--tmpfs` flag: > $ docker run --tmpfs /dev/shm busybox sh> docker: Error response from daemon: linux mounts: Duplicate mount point '/dev/shm'.The reason is, /dev/shm mount is added to the list of mounts twice, by `TmpfsMounts()` and by `IpcMounts()`.## Known workarounds1. Use `--ipc none` together with `--tmpfs` (if supported).2. Use `--mount` instead of `--tmpfs`## VersionsThis is reproducible on docker-ce-17.03 as well as docker-ce-17.11. Judging by the comments in https://github.com/moby/moby/issues/6758 is was working in some version, but following the commits I can't see it was working.
"
35413,0,3149,162,0,0,djs55,0,"title:docker build exits successfully but fails to build image. description:**Description**My `docker build -t test .` invocation exits with code 0 but the build is not completed and the tag is not created.**Steps to reproduce the issue:**Using the `Dockerfile`:```FROM alpine AS baseFROM scratchCOPY --from=base /bin /LABEL foo=bar# This line is never executed:CMD /sh```Run the command:```$ docker build -t test .```**Describe the results you received:**```Sending build context to Docker daemon  31.19MBStep 1/5 : FROM alpine AS baselatest: Pulling from library/alpineb56ae66c2937: Pull complete Digest: sha256:d6bfc3baf615dc9618209a8d607ba2a8103d9c8a405b3bd8741d88b4bef36478Status: Downloaded newer image for alpine:latest ---> 053cde6e8953Step 2/5 : FROM scratch ---> Step 3/5 : COPY --from=base /bin / ---> b9b01ebc02ceStep 4/5 : LABEL foo=bar$ echo $?0```Notice how- the last step to execute is 4/5- no tag is created- the command succeedsIf I remove the `COPY` then it succeeds properly. If I permute the last 2 lines (the `LABEL` and the `CMD` after the `COPY`) then it fails in the same way: always at step 4/5. If I insert additional `COPY` steps then they execute successfully (but the overall build still fails to complete)**Describe the results you expected:**On `17.09.0-ce` it works as follows:```$ docker build -t test .Sending build context to Docker daemon  31.19MBStep 1/5 : FROM alpine AS baselatest: Pulling from library/alpineb56ae66c2937: Pull complete Digest: sha256:d6bfc3baf615dc9618209a8d607ba2a8103d9c8a405b3bd8741d88b4bef36478Status: Downloaded newer image for alpine:latest ---> 053cde6e8953Step 2/5 : FROM scratch ---> Step 3/5 : COPY --from=base /bin / ---> f6ca610bcf97Step 4/5 : LABEL foo bar ---> Running in 8b63bfa48014 ---> 1046dd92658eRemoving intermediate container 8b63bfa48014Step 5/5 : CMD /sh ---> Running in 764e0e54304c ---> 1e6bade266fdRemoving intermediate container 764e0e54304cSuccessfully built 1e6bade266fdSuccessfully tagged test:latest$ echo $?0```Notice- all 5/5 steps are executed- the tag is created- the command exits successfully**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```$ docker versionClient: Version:      17.11.0-ce-rc2 API version:  1.34 Go version:   go1.8.4 Git commit:   d7062e5 Built:        Wed Nov  1 22:08:25 2017 OS/Arch:      darwin/amd64Server: Version:      17.11.0-ce-rc2 API version:  1.34 (minimum version 1.12) Go version:   go1.8.5 Git commit:   d7062e5 Built:        Wed Nov  1 22:14:52 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```$ docker infoContainers: 10 Running: 0 Paused: 0 Stopped: 10Images: 104Server Version: 17.11.0-ce-rc2Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: v1.0.0-beta.2-53-g992280e8 (expected: 992280e8e265f491f7a624ab82f3e238be086e49)runc version: 0351df1c5a66838d0c392b4ac4cf9450de844e2dinit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.44-linuxkit-aufsOperating System: Docker for MacOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.952GiBName: linuxkit-025000000001ID: 5QEB:AR7F:CK5A:RJXE:YARC:SWGG:OK56:EMXW:2NTY:HY74:OWT6:6UKEDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 23 Goroutines: 42 System Time: 2017-11-06T13:51:06.52057428Z EventsListeners: 2No Proxy: *.local, 169.254.0.0/16, *.ioRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**This is Docker for Mac with 17.11.0-ce-rc2.```Version 17.11.0-ce-rc2-mac37 (20033)Channel: edged7d657d636```
"
35407,0,1109,200,0,0,thaJeztah,0,"title:Docker Exec does not resize terminal. description:I noticed this on both `master` (and docker 17.11-rc2, both on Ubuntu and Docker for Mac);```Client: Version:      17.11.0-ce-rc2 API version:  1.34 Go version:   go1.8.3 Git commit:   d7062e5 Built:        Wed Nov  1 22:11:59 2017 OS/Arch:      linux/amd64Server: Version:      17.11.0-ce-rc2 API version:  1.34 (minimum version 1.12) Go version:   go1.8.3 Git commit:   d7062e5 Built:        Wed Nov  1 22:10:29 2017 OS/Arch:      linux/amd64 Experimental: false```When running `docker exec`, the terminal doesn't resize:```console$ docker run -d --name foo nginx:alpine$ docker exec -it foo sh/ # 01234567890123456789012345678901234567890123456789012345678901234567890123456789```Checking the size with `stty size` _does_ show the correct dimensions:```console/ # stty size93 410```This only happens on `docker exec`; doing `docker run -it` works correct:```console$ docker run -it --rm nginx:alpine sh/ # 01234567890123456789012345678901234567890123456789012345678901234567890123456789```(and shows the same output for `stty size`):```console/ # stty size93 410```Checking the daemon logs, the resize parameters are passed to the API for both `docker run` and `docker exec`;```time=""2017-11-04T00:17:19.801321056Z"" level=debug msg=""Calling POST /v1.34/containers/378120448a6af3b289c12574445dde6f7a5a8f6fb09a311a46d1ffc735fab010/resize?h=93&w=410""time=""2017-11-04T00:16:37.697677138Z"" level=debug msg=""Calling POST /v1.34/exec/c57124724228e4af259281af94206ce9f02c64e472408198f665b342c1347f03/resize?h=93&w=410""```ping @vieux @mlaventure @crosbymichael 
"
35391,0,1664,2,0,0,delissonjunio,0,"title:Docker fails to build with --stream with a large context. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Docker fails to build with --stream with a large context, it fails when context is a few hundred megabytes.**Steps to reproduce the issue:**1. `cd $(mktemp -d)`2. `echo -e 'FROM scratch\nCOPY largefile /' >Dockerfile`3. `dd if=/dev/zero of=largefile bs=1m count=1000`3. `docker build .; echo 'stream: '; docker build --stream .`**Describe the results you received:**Sending build context to Docker daemon  1.049GBStep 1/2 : FROM scratch ---> Step 2/2 : COPY asd / ---> 50788e98b45dSuccessfully built 50788e98b45dstream: Streaming build context to Docker daemon   450.6MBError response from daemon: failed to copy to /var/lib/docker/builder/4a1266e2e29104f0568c2ac922bb2915c3b03ab7564ee4434114747fc778b73d: rpc error: code = DeadlineExceeded desc = context deadline exceeded**Describe the results you expected:**Docker should build the image correctly, without timeout, as happens when not using --stream flag.**Additional information you deem important (e.g. issue happens only occasionally):**It doesn't seem to be a matter directly of size - when timing the docker builds, they all seemto fail around the 5 second mark, with varying amount of data being streamed. The issue also appears on Linux hosts.**Output of `docker version`:**```Client: Version:      17.10.0-ce API version:  1.33 Go version:   go1.8.3 Git commit:   f4ffd25 Built:        Tue Oct 17 19:00:43 2017 OS/Arch:      darwin/amd64Server: Version:      17.10.0-ce API version:  1.33 (minimum version 1.12) Go version:   go1.8.3 Git commit:   f4ffd25 Built:        Tue Oct 17 19:05:23 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 3Server Version: 17.10.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 0351df1c5a66838d0c392b4ac4cf9450de844e2dinit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.44-linuxkit-aufsOperating System: Docker for MacOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952GiBName: linuxkit-025000000001ID: EFEJ:FQC3:F7ZD:5HC5:4ZJY:DCIQ:2F6C:TB2J:HED6:VAWL:S4B4:37OCDocker Root Dir: /var/lib/dockerDebug Mode (client): trueDebug Mode (server): true File Descriptors: 20 Goroutines: 32 System Time: 2017-11-03T04:37:36.093403793Z EventsListeners: 2No Proxy: *.local, 169.254/16Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Running on physical host, also happens under virtualized environments
"
35308,0,3529,279,0,0,cpuguy83,0,"title:libnetwork panic on master. description:Libnetwork paniced on a CI run: https://jenkins.dockerproject.org/job/Docker-PRs/46197/consoleping @fcrisciani ```time=""2017-10-25T21:09:55.252549097Z"" level=debug msg=""Did not find any interface with name br-n3lapw5yeouc: Link not found""panic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x10 pc=0x122a050]goroutine 350 [running]:github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*networkConfiguration).conflictsWithNetworks(0xc4202cd8c0, 0xc42048f280, 0x19, 0xc42080b010, 0x2, 0x2, 0x0, 0x410bc8)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge.go:349 +0xf0github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*driver).createNetwork(0xc4203b11d0, 0xc4202cd8c0, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge.go:686 +0x9b3github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*driver).CreateNetwork(0xc4203b11d0, 0xc42048f280, 0x19, 0xc42129fd40, 0x2b78d80, 0xc420825d40, 0xc4212dac90, 0x1, 0x1, 0x2c13940, ...)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge.go:610 +0x21cgithub.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).addNetwork(0xc42047a800, 0xc420825d40, 0xc4211a95a0, 0xc420825d40)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:945 +0x157github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).NewNetwork(0xc42047a800, 0xc420833820, 0x6, 0xc420833800, 0xd, 0xc42048f280, 0x19, 0xc420e141e0, 0x9, 0xc, ...)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:807 +0xb00github.com/docker/docker/daemon.(*Daemon).createNetwork(0xc4202eea00, 0x1, 0xc420833820, 0x6, 0x1da01eb, 0x5, 0x0, 0xc421267560, 0x0, 0x0, ...)	/go/src/github.com/docker/docker/daemon/network.go:361 +0x5c0github.com/docker/docker/daemon.(*Daemon).CreateManagedNetwork(0xc4202eea00, 0xc42048f280, 0x19, 0x1, 0xc420833820, 0x6, 0x1da01eb, 0x5, 0x0, 0xc421267560, ...)	/go/src/github.com/docker/docker/daemon/network.go:258 +0x8fgithub.com/docker/docker/daemon/cluster/executor/container.(*containerAdapter).createNetworks(0xc4212663c0, 0x7f06e0eca390, 0xc420fd1f00, 0x0, 0x0)	/go/src/github.com/docker/docker/daemon/cluster/executor/container/adapter.go:152 +0x126github.com/docker/docker/daemon/cluster/executor/container.(*controller).Prepare(0xc4211c5220, 0x7f06e0eca390, 0xc420fd1f00, 0xc4212d4718, 0x2ba0980)	/go/src/github.com/docker/docker/daemon/cluster/executor/container/controller.go:102 +0x85github.com/docker/docker/vendor/github.com/docker/swarmkit/agent/exec.Do(0x7f06e0eca390, 0xc420fd1f00, 0xc421380b40, 0x2ba0980, 0xc4211c5220, 0x0, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/agent/exec/controller.go:308 +0x9a0github.com/docker/docker/vendor/github.com/docker/swarmkit/agent.(*taskManager).run.func2(0x7f06e1f0c0f0, 0xc421237b90, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/agent/task.go:134 +0xe1github.com/docker/docker/vendor/github.com/docker/swarmkit/agent.runctx(0x7f06e1f0c0f0, 0xc421237b90, 0xc4203a4a20, 0xc4201f5bc0, 0xc420fe20c0)	/go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/agent/helpers.go:9 +0x55created by github.com/docker/docker/vendor/github.com/docker/swarmkit/agent.(*taskManager).run	/go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/agent/task.go:150 +0x5cd```
"
35302,0,5432,19,0,0,peterschen,0,"title:dockerd panic when running LCOW container on 1709. description:**Description**When trying running a linux container on Windows Server 1709 dockerd arrives at a panic.**Steps to reproduce the issue:**1. Setup LCOW/LinuxKit as per https://blog.docker.com/2017/09/preview-linux-containers-on-windows/ and https://gist.github.com/rn/6bfade1ba98e22691cb287cc8c23609b2. ```.\dockerd.exe -D --experimental -H 0.0.0.0:12375 --data-root ""C:\lcow""```3. ```docker run -H localhost:12375 tomcat```**Describe the results you received:**CLI output:```error during connect: Post http://app1:12375/v1.34/containers/3a6eeaa74074db85672d44bfa35b6acdb245dd2f6a8e11c1024cc201b573c880/start: EOF.```dockerd output:```2017-10-26 09:50:18.095017 I | http: panic serving 10.4.0.253:50557: runtime error: invalid memory address or nilpointer dereferencegoroutine 228 [running]:net/http.(*conn).serve.func1(0xc0423da500)        /usr/local/go/src/net/http/server.go:1721 +0xd7panic(0x1809ac0, 0x24d2ed0)        /usr/local/go/src/runtime/panic.go:489 +0x2ddgithub.com/docker/docker/daemon.(*Daemon).createSpec(0xc042446400, 0xc042106480, 0x0, 0x0, 0x0)        /go/src/github.com/docker/docker/daemon/oci_windows.go:220 +0x1208github.com/docker/docker/daemon.(*Daemon).containerStart(0xc042446400, 0xc042106480, 0x0, 0x0, 0x0, 0x0, 0x2520801,0x0, 0x0)        /go/src/github.com/docker/docker/daemon/start.go:156 +0x279github.com/docker/docker/daemon.(*Daemon).ContainerStart(0xc042446400, 0xc042418407, 0x40, 0x0, 0x0, 0x0, 0x0, 0x0,0x176e060, 0xc043181601)        /go/src/github.com/docker/docker/daemon/start.go:94 +0x1c3github.com/docker/docker/api/server/router/container.(*containerRouter).postContainersStart(0xc0423709c0, 0x480c8e8,0xc042752060, 0x2485940, 0xc0421081c0, 0xc0423f2a00, 0xc04272fec0, 0x1a636f1, 0x4)        /go/src/github.com/docker/docker/api/server/router/container/container_routes.go:163 +0x26fgithub.com/docker/docker/api/server/router/container.(*containerRouter).(github.com/docker/docker/api/server/router/container.postContainersStart)-fm(0x480c8e8, 0xc042752060, 0x2485940, 0xc0421081c0, 0xc0423f2a00, 0xc04272fec0,0x480c8e8, 0xc042752060)        /go/src/github.com/docker/docker/api/server/router/container/container.go:66 +0x70github.com/docker/docker/api/server/middleware.ExperimentalMiddleware.WrapHandler.func1(0x480c8e8, 0xc042752060,0x2485940, 0xc0421081c0, 0xc0423f2a00, 0xc04272fec0, 0x480c8e8, 0xc042752060)        /go/src/github.com/docker/docker/api/server/middleware/experimental.go:27 +0xdfgithub.com/docker/docker/api/server/middleware.VersionMiddleware.WrapHandler.func1(0x480c8e8, 0xc04272ff50, 0x2485940,0xc0421081c0, 0xc0423f2a00, 0xc04272fec0, 0x10, 0x10)        /go/src/github.com/docker/docker/api/server/middleware/version.go:62 +0x4b2github.com/docker/docker/pkg/authorization.(*Middleware).WrapHandler.func1(0x480c8e8, 0xc04272ff50, 0x2485940,0xc0421081c0, 0xc0423f2a00, 0xc04272fec0, 0xc042af5ab0, 0x756ea152ce6e8f)        /go/src/github.com/docker/docker/pkg/authorization/middleware.go:59 +0x878github.com/docker/docker/api/server/middleware.DebugRequestMiddleware.func1(0x480c8e8, 0xc04272ff50, 0x2485940,0xc0421081c0, 0xc0423f2a00, 0xc04272fec0, 0x480c8e8, 0xc04272ff50)        /go/src/github.com/docker/docker/api/server/middleware/debug.go:25 +0x9b9github.com/docker/docker/api/server.(*Server).makeHTTPHandler.func1(0x2485940, 0xc0421081c0, 0xc0423f2a00)        /go/src/github.com/docker/docker/api/server/server.go:137 +0x221net/http.HandlerFunc.ServeHTTP(0xc0427c8240, 0x2485940, 0xc0421081c0, 0xc0423f2a00)        /usr/local/go/src/net/http/server.go:1942 +0x4bgithub.com/docker/docker/vendor/github.com/gorilla/mux.(*Router).ServeHTTP(0xc04245e0f0, 0x2485940, 0xc0421081c0,0xc0423f2a00)        /go/src/github.com/docker/docker/vendor/github.com/gorilla/mux/mux.go:103 +0x25cgithub.com/docker/docker/api/server.(*routerSwapper).ServeHTTP(0xc042a42210, 0x2485940, 0xc0421081c0, 0xc0423f2a00)        /go/src/github.com/docker/docker/api/server/router_swapper.go:29 +0x77net/http.serverHandler.ServeHTTP(0xc0423c2f20, 0x2485940, 0xc0421081c0, 0xc0423f2a00)        /usr/local/go/src/net/http/server.go:2568 +0x99net/http.(*conn).serve(0xc0423da500, 0x2487480, 0xc042371a40)        /usr/local/go/src/net/http/server.go:1825 +0x619created by net/http.(*Server).Serve        /usr/local/go/src/net/http/server.go:2668 +0x2d5```**Describe the results you expected:**Running container**Output of `docker version`:**```Client: Version:      master-dockerproject-2017-10-25 API version:  1.34 Go version:   go1.8.4 Git commit:   9b7656c Built:        Thu Oct 26 00:05:37 2017 OS/Arch:      windows/amd64Server: Version:      master-dockerproject-2017-10-25 API version:  1.34 (minimum version 1.24) Go version:   go1.8.4 Git commit:   074b1fc Built:        Thu Oct 26 00:09:38 2017 OS/Arch:      windows/amd64 Experimental: true```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: master-dockerproject-2017-10-25Storage Driver: windowsfilter (windows) lcow (linux) LCOW:Logging Driver: json-filePlugins: Volume: local Network: ics l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd json-file logentries splunk syslogSwarm: inactiveDefault Isolation: processKernel Version: 10.0 16299 (16299.15.amd64fre.rs3_release.170928-1534)Operating System: Windows Server StandardOSType: windowsArchitecture: x86_64CPUs: 2Total Memory: 9.999GiBName: APP1ID: WIFB:YLX2:BFTR:4UDU:DENY:YKWJ:ZL7D:MDAS:Q3MR:URDS:GMZU:GUKODocker Root Dir: C:\lcowDebug Mode (client): falseDebug Mode (server): true File Descriptors: -1 Goroutines: 30 System Time: 2017-10-26T09:55:41.3030541+02:00 EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**The docker host running Windows Server 1709 is nested within a Windows 10 1709. I'm not sure if this is relevant to this issue.
"
35271,0,262,2,0,0,EliSnow,0,"title:tmpfs-size not working for service mount. description:Using tmpfs as a workaround for #26714, no longer seems to work.I used the following command to start a service with a tmpfs mount on `/dev/shm`:```docker service create \  --name tmpfstest \  --mount type=tmpfs,dst=/dev/shm,tmpfs-size=1000000000 \  --tty \  debian:stretch-slim cat```This worked as of Docker 17.06.2, but there appears to be a regression and starting at least with 17.09-rc1 (I tested it with 17.09 and 17.10 as well) it no longer works.Using `df -k /dev/shm` I get the following output on new versions of Docker:```Filesystem     1K-blocks  Used Available Use% Mounted ontmpfs              65536     4     65532   1% /dev/shm```**Additional environment details (AWS, VirtualBox, physical, etc.):**I don't think it matters for this issue, but this was all tested in boot2docker VirtualBox VM.
"
35242,1,1579,2,0,0,delissonjunio,0,"title:Docker fails to build when outside build context directory when using --stream. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Docker fails to build image when using --stream and setting a different parameter for build context location.**Steps to reproduce the issue:**1. `mkdir loc1; mkdir loc1/env`2. `echo -e 'FROM ubuntu\nRUN sleep 1' >loc1/env/Dockerfile`3. `cd loc1/; docker build env; echo 'stream: '; docker build --stream env`**Describe the results you received:**Sending build context to Docker daemon  2.048kBStep 1/2 : FROM ubuntu ---> 747cb2d60bbeStep 2/2 : RUN sleep 1 ---> Using cache ---> 4cfe7feea9fbSuccessfully built 4cfe7feea9fbstream: failed to open Dockerfile: open Dockerfile: no such file or directory**Describe the results you expected:**Docker should find the Dockerfile in the specified build context directory, as happens when not using --stream flag.**Additional information you deem important (e.g. issue happens only occasionally):**If you create a symbolic link called Dockerfile in loc1 and run build with --stream, it works**Output of `docker version`:**```Client: Version:      17.09.0-ce API version:  1.32 Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:42:18 2017 OS/Arch:      linux/amd64Server: Version:      17.09.0-ce API version:  1.32 (minimum version 1.12) Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:40:56 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 3 Running: 0 Paused: 0 Stopped: 3Images: 12Server Version: 17.09.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 3f2f8b84a77f73d38244dd690525642a72156c64init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-96-genericOperating System: elementary OS 0.4.1 LokiOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 15.54GiBName: pc-concertbh-delissonID: CQP4:APCT:RY4B:AVDG:BDUK:E54F:JWWS:OJNI:FW3B:T73Y:5UVX:OP4HDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Running on physical host, also happens under virtualized environments
"
35145,0,0,274,0,0,samuelkarp,0,"title:Docker no longer rejects API requests with version greater than daemon maximum. description:**Description**Docker stopped rejecting API requests with version numbers greater than the maximum version supported by the daemon. This happened in https://github.com/moby/moby/commit/e98e4a71110fd33852bb755a9b8b4ebc9df904db#diff-14051df1b5de1608aaba3a983f2a87e3 as part of https://github.com/moby/moby/pull/27745 and has affected every version of Docker since 1.13.0.This change breaks the capability detection logic used by the Amazon ECS agent. The Amazon ECS agent is designed to work with all Docker versions >= 1.5.0, and we enable or disable features depending on the capabilities of the Docker version used. We use Remote API version as we expected this to be more stable than the daemon version; the daemon version has gone through a few changes since we started (roughly semver-like to year-month plus edition). We currently call the `/_ping` API with a range of different versions to discover which API versions are supported by the Docker daemon, but this change makes it so that every request with an API version >= 1.12 will result in success. This is causing incorrect behavior where features are being enabled with incompatible Docker versions; see https://github.com/aws/amazon-ecs-agent/issues/1008 .In https://docs.docker.com/engine/api/version-history/#v125-api-changes , I see a note about a new header returned that specifies the maximum API version of the daemon. However, I do not see a note about the change in behavior to start accepting requests that have a specified version greater than the maximum.**Steps to reproduce the issue:**Run `curl --verbose --unix-socket /var/run/docker.sock http://localhost/v9999.9999/_ping`**Describe the results you received:**On Docker versions prior to 1.13.0, you'll see an HTTP 400 with an error message ""client is newer than server""On Docker versions 1.13.0 or greater, you'll see an HTTP 200 OK.**Describe the results you expected:**I expected all versions of Docker to reject the API call because the specified API version was too new.
"
35116,0,1904,0,0,0,shin-,0,"title:[17.10-rc1] Build containers not being removed after failing build. description:**Description**A failing `docker build` now preserves all intermediary build containers, while previous versions removed them.**Steps to reproduce the issue:**1. Create failing `Dockerfile`:```FROM busybox:latestLABEL com.docker.compose.test_image=trueLABEL com.docker.compose.test_failing_image=trueRUN exit 1```2. Run `docker build --no-cache . | grep ""Running in"" | cut -d' ' -f5 | xargs docker inspect | grep '""Id""'`3. Note how all 3 containers have been preserved.**Describe the results you received:**Build containers remained**Describe the results you expected:**Build containers are removed```$ ~/engines/docker-1.10.2 build --no-cache . | grep ""Running in"" | cut -d' ' -f5 | xargs ~/engines/docker-1.10.2 inspectError: No such image or container: 1ce422fe7da2```**Additional information you deem important (e.g. issue happens only occasionally):**This error also affects Compose (https://github.com/docker/compose/issues/5242), so it's not a CLI bug.**Output of `docker version`:**```$ docker versionClient: Version:      17.10.0-ce-rc1 API version:  1.33 Go version:   go1.8.3 Git commit:   d866876 Built:        Wed Oct  4 21:45:54 2017 OS/Arch:      linux/amd64Server: Version:      17.10.0-ce-rc1 API version:  1.33 (minimum version 1.12) Go version:   go1.8.3 Git commit:   d866876 Built:        Wed Oct  4 21:44:33 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 17 Running: 0 Paused: 0 Stopped: 17Images: 372Server Version: 17.10.0-ce-rc1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 446 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 0351df1c5a66838d0c392b4ac4cf9450de844e2dinit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-92-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.499GiBName: yunaID: YZQG:AKYJ:JQXJ:CEHT:62DP:PMWA:S43W:5X47:SSOE:UXGG:XHWS:555FDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```
"
35114,0,0,2,0,0,dsheets,0,"title:Daemon config reloading fails and recovers without config file. description:**Description**When one sends `SIGHUP` to `dockerd` and the daemon's config file (usually `/etc/docker/daemon.json`) does not exist, an error is emitted to the logs and the reload does not occur.**Steps to reproduce the issue:**1. Start `dockerd` without a config file (config 0)2. Create `/etc/docker/daemon.json` and populate it with some new configuration3. Send `SIGHUP` to `dockerd` and notice the new configuration is picked up (config 1)4. Delete `/etc/docker/daemon.json`5. Send `SIGHUP` to `dockerd` and notice that the configuration does not change (config 1)**Describe the results you received:**Missing config file is allowed when starting daemon but not when reloading configuration.**Describe the results you expected:**Missing config file is allowed when starting daemon and when reloading configuration.Edit: occurs in Docker 17.06, Docker 17.09, etc.
"
35108,1,2298,0,0,0,pszczekutowicz,0,"title:[17.09] Missing error on stack deploy when config exists and content is changed. description:**Description**Docker Engine 17.06 show error message `Error response from daemon: rpc error: code = 3 desc = only updates to Labels are allowed` when stack deploy was trying to change content of existing config. Docker 17.09 does not show this message, result code is 0. **Steps to reproduce the issue:**1. Create simple docker-compose.yml```ymlversion: ""3.3""services:  service:    image: alpine    command: ping google.com    configs:      - source: test_conf        target: /test.confconfigs:  test_conf:    file: test.conf```2. Create test.conf file with some content 3. Deploy stack: docker stack deploy -c docker-compose.yml test4. Change content of file test.conf5. Redeploy stack: docker stack deploy -c docker-compose.yml test**Describe the results you received:**No error message is shown, status code is 0**Describe the results you expected:**Error message should be shown and status code should be non 017.06 message is: `Error response from daemon: rpc error: code = 3 desc = only updates to Labels are allowed`**Output of `docker version`:**```Client: Version:      17.09.0-ce API version:  1.32 Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:42:45 2017 OS/Arch:      linux/amd64Server: Version:      17.09.0-ce API version:  1.32 (minimum version 1.12) Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:41:24 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 5 Running: 2 Paused: 0 Stopped: 3Images: 3Server Version: 17.09.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: r7w1wimto7bvod96gm0n4ftz6 Is Manager: true ClusterID: xaccljf41l46g5emobp77p17x Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 10.57.206.96 Manager Addresses:  10.57.206.96:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 3f2f8b84a77f73d38244dd690525642a72156c64init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.10.0-33-genericOperating System: Ubuntu 17.04OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.54GiBName: fp-pc2514.fp.lanID: G244:BV5P:3LAX:PHPJ:DVPH:GHYC:RC2X:AZLG:JSTN:EQEI:HLVP:W7LLDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```
"
35101,0,6977,55,0,0,daledude,0,"title:Error response from daemon: configuration network 8-2 is in use. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->It seems when an IPAM driver fails and the container is removed the network that used the IPAM driver becomes stuck and can no longer be removed. rm -rf /var/lib/docker is necessary (unless some way to edit the .db file?).**Steps to reproduce the issue:**1. docker network create -d macvlan  --subnet 8.2.250.0/24 --gateway 8.2.250.3 -o parent=public  --ipam-driver arp-ipam3 --config-only 8-22. docker network create -d macvlan --scope swarm --config-from 8-2 --attachable public-8-23. docker service create ... --network public-8-2 ... my-service4. ipam driver crashes during RequestAddress.5. service create is in pending state for a long time.6. CTRL-C7. docker service rm my-service. Succeeds.8. docker network rm public-8-2. Succeeds but errors in logs that network doesn't exist?9. docker network rm 8-2. This produces the titled error. Only way to remove network now is to rm -rf /var/lib/docker/**Describe the results you received:**Cannot remove network.**Describe the results you expected:**Network should be removed.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.09.0-ce API version:  1.32 Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:42:18 2017 OS/Arch:      linux/amd64Server: Version:      17.09.0-ce API version:  1.32 (minimum version 1.12) Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:40:56 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 2Server Version: 17.09.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: vz74i89jega7k0ccyekpplgwq Is Manager: true ClusterID: qrpx9z4664ts79a6eamvrrxnw Managers: 1 Nodes: 2 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 10.0.21.39 Manager Addresses:  10.0.21.39:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 3f2f8b84a77f73d38244dd690525642a72156c64init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.11.0-14-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 40Total Memory: 141.6GiBName: container1ID: IMGD:TF6D:E4FH:AT2H:SZ5C:YNIU:IB57:ATV7:Y6KU:JBIG:Z5PF:ZBMFDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Logs:```level=warning msg=""Unable to connect to plugin: 8.2.250.40:8181/IpamDriver.RequestAddress: Post http://8.2.250.40:8181/IpamDriver.RequestAddress: dial tcp 8.2.250.40:8181: getsockopt: connection refused, retrying in 2s""level=warning msg=""Unable to connect to plugin: 8.2.250.40:8181/IpamDriver.RequestAddress: Post http://8.2.250.40:8181/IpamDriver.RequestAddress: dial tcp 8.2.250.40:8181: getsockopt: connection refused, retrying in 4s""level=warning msg=""Unable to connect to plugin: 8.2.250.40:8181/IpamDriver.RequestAddress: Post http://8.2.250.40:8181/IpamDriver.RequestAddress: dial tcp 8.2.250.40:8181: getsockopt: connection refused, retrying in 8s""level=info msg=""Node join event for container2-ba0d08b08afe/10.0.21.40""level=error msg=""fatal task error"" error=""starting container failed: Post http://8.2.250.40:8181/IpamDriver.RequestAddress: dial tcp 8.2.250.40:8181: getsockopt: connection refused"" module=""node/agent/taskmanager"" node.id=vz74i89jega7k0ccyekpplgwq service.id=scogq490jtph6f5ahigrmvxl7 task.id=f97hf1oyokft44dbusddw3os1level=warning msg=""underweighting node vz74i89jega7k0ccyekpplgwq for service scogq490jtph6f5ahigrmvxl7 because it experienced 5 failures or rejections within 5m0s"" module=node node.id=vz74i89jega7k0ccyekpplgwqlevel=warning msg=""underweighting node awvo1u8zp17i30jb0tze4cebj for service scogq490jtph6f5ahigrmvxl7 because it experienced 5 failures or rejections within 5m0s"" module=node node.id=vz74i89jega7k0ccyekpplgwqlevel=warning msg=""Unable to connect to plugin: 8.2.250.40:8181/IpamDriver.ReleaseAddress: Post http://8.2.250.40:8181/IpamDriver.ReleaseAddress: dial tcp 8.2.250.40:8181: getsockopt: connection refused, retrying in 1s""level=info msg=""Node join event for container2-ba0d08b08afe/10.0.21.40""level=warning msg=""Unable to connect to plugin: 8.2.250.40:8181/IpamDriver.ReleaseAddress: Post http://8.2.250.40:8181/IpamDriver.ReleaseAddress: dial tcp 8.2.250.40:8181: getsockopt: connection refused, retrying in 2s""level=error msg=""fatal task error"" error=""starting container failed: No such network: public-8-2"" module=""node/agent/taskmanager"" node.id=vz74i89jega7k0ccyekpplgwq service.id=scogq490jtph6f5ahigrmvxl7 task.id=y3w4ai1tyirxtqumrp98bzadvlevel=warning msg=""Unable to connect to plugin: 8.2.250.40:8181/IpamDriver.ReleaseAddress: Post http://8.2.250.40:8181/IpamDriver.ReleaseAddress: dial tcp 8.2.250.40:8181: getsockopt: connection refused, retrying in 4s""level=error msg=""network public-8-2 remove failed: No such network: public-8-2"" module=""node/agent"" node.id=vz74i89jega7k0ccyekpplgwqlevel=error msg=""remove task failed"" error=""No such network: public-8-2"" module=""node/agent"" node.id=vz74i89jega7k0ccyekpplgwq task.id=njtqop3cb81v080k7f4lg5x88level=error msg=""network public-8-2 remove failed: No such network: public-8-2"" module=""node/agent"" node.id=vz74i89jega7k0ccyekpplgwqlevel=error msg=""remove task failed"" error=""No such network: public-8-2"" module=""node/agent"" node.id=vz74i89jega7k0ccyekpplgwq task.id=jizmlx0lgbmdo5bjg5ae2dkfslevel=warning msg=""Unable to connect to plugin: 8.2.250.40:8181/IpamDriver.ReleaseAddress: Post http://8.2.250.40:8181/IpamDriver.ReleaseAddress: dial tcp 8.2.250.40:8181: getsockopt: connection refused, retrying in 8s""level=warning msg=""Failed to release gateway ip address 8.2.250.3 on delete of network public-8-2 (8jcmhqcq34jaeoa8qy2iguiw2): Post http://8.2.250.40:8181/IpamDriver.ReleaseAddress: dial tcp 8.2.250.40:8181: getsockopt: connection refused""level=warning msg=""Unable to connect to plugin: 8.2.250.40:8181/IpamDriver.ReleasePool: Post http://8.2.250.40:8181/IpamDriver.ReleasePool: dial tcp 8.2.250.40:8181: getsockopt: connection refused, retrying in 1s""level=warning msg=""Unable to connect to plugin: 8.2.250.40:8181/IpamDriver.ReleasePool: Post http://8.2.250.40:8181/IpamDriver.ReleasePool: dial tcp 8.2.250.40:8181: getsockopt: connection refused, retrying in 2s""level=warning msg=""Unable to connect to plugin: 8.2.250.40:8181/IpamDriver.ReleasePool: Post http://8.2.250.40:8181/IpamDriver.ReleasePool: dial tcp 8.2.250.40:8181: getsockopt: connection refused, retrying in 4s""level=info msg=""Node join event for container2-ba0d08b08afe/10.0.21.40""level=warning msg=""Unable to connect to plugin: 8.2.250.40:8181/IpamDriver.ReleasePool: Post http://8.2.250.40:8181/IpamDriver.ReleasePool: dial tcp 8.2.250.40:8181: getsockopt: connection refused, retrying in 8s""level=warning msg=""Failed to release address pool 8.2.250.0/24 on delete of network public-8-2 (8jcmhqcq34jaeoa8qy2iguiw2): Post http://8.2.250.40:8181/IpamDriver.ReleasePool: dial tcp 8.2.250.40:8181: getsockopt: connection refused""level=warning msg=""Unable to connect to plugin: 8.2.250.40:8181/IpamDriver.RequestPool: Post http://8.2.250.40:8181/IpamDriver.RequestPool: dial tcp 8.2.250.40:8181: getsockopt: connection refused, retrying in 1s""```
"
35099,0,2462,55,0,0,daledude,0,"title:Unable to locate plugin: , retrying in 1s. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Whenever a new service is created the following logs are output by Docker:```level=warning msg=""Unable to locate plugin: , retrying in 1s""level=warning msg=""Unable to locate plugin: , retrying in 2s""level=warning msg=""Unable to locate plugin: , retrying in 4s""level=warning msg=""Unable to locate plugin: , retrying in 8s""level=error msg=""Error handling plugin refcount operation"" driver= error=""plugin \""\"" not found"" mode=1```This delays the service starting for 15 seconds.**Steps to reproduce the issue:**1. docker service create ...**Describe the results you received:**None**Describe the results you expected:**None**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.09.0-ce API version:  1.32 Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:42:18 2017 OS/Arch:      linux/amd64Server: Version:      17.09.0-ce API version:  1.32 (minimum version 1.12) Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:40:56 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 2 Running: 2 Paused: 0 Stopped: 0Images: 2Server Version: 17.09.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: vz74i89jega7k0ccyekpplgwq Is Manager: true ClusterID: qrpx9z4664ts79a6eamvrrxnw Managers: 1 Nodes: 2 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 10.0.21.39 Manager Addresses:  10.0.21.39:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 3f2f8b84a77f73d38244dd690525642a72156c64init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.11.0-14-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 40Total Memory: 141.6GiBName: container1-la.xcastlabs.netID: IMGD:TF6D:E4FH:AT2H:SZ5C:YNIU:IB57:ATV7:Y6KU:JBIG:Z5PF:ZBMFDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
35050,0,1641,0,0,0,yuval-p,0,"title:Docker daemon crash after using the command docker logs and docker service logs. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->We have docker swarm with dameon version 17.06.We configured some services with log-opt to use several labels for example:docker service create --name log-test --log-driver json-file --log-opt labels=bla.name.com,capitalString,bla2.name.com,aaa,bbb --container-label bla.name.com=label1 --container-label capitalString=True --container-label bla2.name.com=label2 --container-label aaa=aaa --container-label bbb=bbb --log-opt env=ENVE -e ENVE=12 grafana/grafanaafter configuring the service, and using the command:docker service logs -f log-test --detailsthe damon crashes..<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. install 17.062. docker service create --name log-test --log-driver json-file --log-opt labels=bla.name.com,capitalString,bla2.name.com,aaa,bbb --container-label bla.name.com=label1 --container-label capitalString=True --container-label bla2.name.com=label2 --container-label aaa=aaa --container-label bbb=bbb --log-opt env=ENVE -e ENVE=12 grafana/grafana 3. docker service logs -f log-test --details**Describe the results you received:**sometimes I received the desired logs and sometimes ""unexpected EOF""**Describe the results you expected:**The service logs**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**Client: Version:      17.06.1-ce API version:  1.30 Go version:   go1.8.3 Git commit:   874a737 Built:        Thu Aug 17 22:53:49 2017 OS/Arch:      linux/amd64Server: Version:      17.06.1-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   874a737 Built:        Thu Aug 17 23:01:50 2017 OS/Arch:      linux/amd64 Experimental: false``````**Output of `docker info`:**```Containers: 22 Running: 6 Paused: 0 Stopped: 16Images: 12Server Version: 17.06.1-ceStorage Driver: overlay Backing Filesystem: xfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: 5kvv1ow27racgwtw4nj49dufo Is Manager: true ClusterID: u48fva9t3af9eeuu9w6hg91w8 Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Root Rotation In Progress: false Node Address: 192.168.0.153 Manager Addresses:  192.168.0.153:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 6e23458c129b551d5c9871e5174f6b1b7f6d1170runc version: 810190ceaa507aa2727d7ae6f4790c76ec150bd2init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.el7.x86_64Operating System: Red Hat Enterprise Linux Server 7.3 (Maipo)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.339GiBName: localhost.localdomainID: GRWT:JVBR:YJVC:TPLR:ONSE:RVE7:ZPGI:KB4L:UPRY:LPIJ:EQOR:NQBYDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```It happens on several environments, bare metal and virtual machine The daemon logs:Oct  1 10:19:30 localhost dockerd: goroutine 12580 [running]:Oct  1 10:19:30 localhost dockerd: runtime.throw(0x1a4d584, 0x26)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/runtime/panic.go:596 +0x95 fp=0xc4211ebbc8 sp=0xc4211ebba8Oct  1 10:19:30 localhost dockerd: runtime.mapiternext(0xc4211ebdd8)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/runtime/hashmap.go:737 +0x7ee fp=0xc4211ebc78 sp=0xc4211ebbc8Oct  1 10:19:30 localhost dockerd: github.com/docker/docker/daemon/cluster/executor/container.(*controller).Logs(0xc4200ffb80, 0x7f5afc623128, 0xc421214540, 0x262a520, 0xc4213ae480, 0xc420978ae0, 0x2, 0x2, 0x1, 0x0, ...)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/cluster/executor/container/controller.go:530 +0x4fe fp=0xc4211ebeb8 sp=0xc4211ebc78Oct  1 10:19:30 localhost dockerd: github.com/docker/docker/vendor/github.com/docker/swarmkit/agent.(*taskManager).Logs(0xc4203e2a20, 0x7f5afc623128, 0xc421214540, 0xc420978ae0, 0x2, 0x2, 0x1, 0x0, 0x0, 0x262a520, ...)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/agent/task.go:72 +0x110 fp=0xc4211ebf40 sp=0xc4211ebeb8Oct  1 10:19:30 localhost dockerd: github.com/docker/docker/vendor/github.com/docker/swarmkit/agent.(*worker).Subscribe.func2(0xc420978b90, 0x7f5afc624478, 0xc420c50e40, 0xc4215badb0, 0x262a520, 0xc4213ae480, 0xc4203e2a20)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/agent/worker.go:544 +0xac fp=0xc4211ebfa8 sp=0xc4211ebf40Oct  1 10:19:30 localhost dockerd: runtime.goexit()Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/runtime/asm_amd64.s:2197 +0x1 fp=0xc4211ebfb0 sp=0xc4211ebfa8Oct  1 10:19:30 localhost dockerd: created by github.com/docker/docker/vendor/github.com/docker/swarmkit/agent.(*worker).SubscribeOct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/agent/worker.go:545 +0x874Oct  1 10:19:30 localhost dockerd: goroutine 1 [chan receive, 490 minutes]:Oct  1 10:19:30 localhost dockerd: main.(*DaemonCli).start(0xc4204395f0, 0x0, 0x1a2db34, 0x17, 0xc420092000, 0xc42043e7c0, 0xc42043a3f0, 0x0, 0x0)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/cmd/dockerd/daemon.go:294 +0x1d25Oct  1 10:19:30 localhost dockerd: main.runDaemon(0x0, 0x1a2db34, 0x17, 0xc420092000, 0xc42043e7c0, 0xc42043a3f0, 0x0, 0x0)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/cmd/dockerd/docker.go:91 +0x8cOct  1 10:19:30 localhost dockerd: main.newDaemonCommand.func1(0xc42008c480, 0x26ae7f0, 0x0, 0x0, 0x0, 0x0)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/cmd/dockerd/docker.go:42 +0x6fOct  1 10:19:30 localhost dockerd: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).execute(0xc42008c480, 0xc4200101c0, 0x0, 0x0, 0xc42008c480, 0xc4200101c0)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:646 +0x44eOct  1 10:19:30 localhost dockerd: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc42008c480, 0x17d4ee0, 0x1, 0xc4204299b0)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:742 +0x349Oct  1 10:19:30 localhost dockerd: github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).Execute(0xc42008c480, 0xc4204299b0, 0x0)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:695 +0x2bOct  1 10:19:30 localhost dockerd: main.main()Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/cmd/dockerd/docker.go:118 +0xe6Oct  1 10:19:30 localhost dockerd: goroutine 17 [syscall, 490 minutes, locked to thread]:Oct  1 10:19:30 localhost dockerd: runtime.goexit()Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/runtime/asm_amd64.s:2197 +0x1Oct  1 10:19:30 localhost dockerd: goroutine 31 [IO wait, 490 minutes]:Oct  1 10:19:30 localhost dockerd: net.runtime_pollWait(0x7f5afc593cc0, 0x72, 0x0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/runtime/netpoll.go:164 +0x59Oct  1 10:19:30 localhost dockerd: net.(*pollDesc).wait(0xc420127e98, 0x72, 0x0, 0xc4201b84a0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/net/fd_poll_runtime.go:75 +0x38Oct  1 10:19:30 localhost dockerd: net.(*pollDesc).waitRead(0xc420127e98, 0xffffffffffffffff, 0x0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/net/fd_poll_runtime.go:80 +0x34Oct  1 10:19:30 localhost dockerd: net.(*netFD).accept(0xc420127e30, 0x0, 0x2628020, 0xc4201b84a0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/net/fd_unix.go:430 +0x1e5Oct  1 10:19:30 localhost dockerd: net.(*UnixListener).accept(0xc420260ab0, 0xc4201bac30, 0x177cac0, 0x26010f0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/net/unixsock_posix.go:162 +0x32Oct  1 10:19:30 localhost dockerd: net.(*UnixListener).Accept(0xc420260ab0, 0xc4201bac00, 0x177cac0, 0x26010f0, 0x18bb620)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/net/unixsock.go:237 +0x49Oct  1 10:19:30 localhost dockerd: net/http.(*Server).Serve(0xc42009e370, 0x263dc60, 0xc420260ab0, 0x0, 0x0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/net/http/server.go:2643 +0x228Oct  1 10:19:30 localhost dockerd: net/http.Serve(0x263dc60, 0xc420260ab0, 0x26278a0, 0xc420260ae0, 0x437978, 0x1a9a1a0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/net/http/server.go:2307 +0x78Oct  1 10:19:30 localhost dockerd: github.com/docker/docker/daemon.(*Daemon).listenMetricsSock.func1(0x263dc60, 0xc420260ab0, 0xc420260ae0)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/metrics_unix.go:31 +0x4bOct  1 10:19:30 localhost dockerd: created by github.com/docker/docker/daemon.(*Daemon).listenMetricsSockOct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/daemon/metrics_unix.go:32 +0x196Oct  1 10:19:30 localhost dockerd: goroutine 6 [syscall]:Oct  1 10:19:30 localhost dockerd: os/signal.signal_recv(0x2633f20)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/runtime/sigqueue.go:116 +0x104Oct  1 10:19:30 localhost dockerd: os/signal.loop()Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/os/signal/signal_unix.go:22 +0x22Oct  1 10:19:30 localhost dockerd: created by os/signal.init.1Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/os/signal/signal_unix.go:28 +0x41Oct  1 10:19:30 localhost dockerd: goroutine 11 [syscall, 490 minutes]:Oct  1 10:19:30 localhost dockerd: syscall.Syscall6(0xf7, 0x1, 0x71cb, 0xc42013fdb0, 0x1000004, 0x0, 0x0, 0x0, 0x0, 0x0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/syscall/asm_linux_amd64.s:44 +0x5Oct  1 10:19:30 localhost dockerd: os.(*Process).blockUntilWaitable(0xc420260450, 0x0, 0x0, 0x0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/os/wait_waitid.go:28 +0xa5Oct  1 10:19:30 localhost dockerd: os.(*Process).wait(0xc420260450, 0x0, 0x0, 0x0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/os/exec_unix.go:22 +0x4dOct  1 10:19:30 localhost dockerd: os.(*Process).Wait(0xc420260450, 0x0, 0xc420416b60, 0x1a9a468)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/os/exec.go:115 +0x2bOct  1 10:19:30 localhost dockerd: os/exec.(*Cmd).Wait(0xc4204d14a0, 0x1a9a1a0, 0x0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/os/exec/exec.go:435 +0x62Oct  1 10:19:30 localhost dockerd: github.com/docker/docker/libcontainerd.(*remote).runContainerdDaemon.func1(0xc4204d14a0, 0xc420079380)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/libcontainerd/remote_unix.go:479 +0x2bOct  1 10:19:30 localhost dockerd: created by github.com/docker/docker/libcontainerd.(*remote).runContainerdDaemonOct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/libcontainerd/remote_unix.go:481 +0xb7cOct  1 10:19:30 localhost dockerd: goroutine 14 [chan receive]:Oct  1 10:19:30 localhost dockerd: github.com/docker/docker/libcontainerd.(*remote).handleConnectionChange(0xc420079380)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/libcontainerd/remote_unix.go:187 +0xe2Oct  1 10:19:30 localhost dockerd: created by github.com/docker/docker/libcontainerd.NewOct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/libcontainerd/remote_unix.go:130 +0x651Oct  1 10:19:30 localhost dockerd: goroutine 13 [select, 490 minutes]:Oct  1 10:19:30 localhost dockerd: github.com/docker/docker/vendor/google.golang.org/grpc.(*addrConn).transportMonitor(0xc4204d1600)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:751 +0x666Oct  1 10:19:30 localhost dockerd: github.com/docker/docker/vendor/google.golang.org/grpc.(*ClientConn).resetAddrConn.func1(0xc4204d1600)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:506 +0x1d9Oct  1 10:19:30 localhost dockerd: created by github.com/docker/docker/vendor/google.golang.org/grpc.(*ClientConn).resetAddrConnOct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:507 +0x372Oct  1 10:19:30 localhost dockerd: goroutine 16 [IO wait]:Oct  1 10:19:30 localhost dockerd: net.runtime_pollWait(0x7f5afc593d80, 0x72, 0x7)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/runtime/netpoll.go:164 +0x59Oct  1 10:19:30 localhost dockerd: net.(*pollDesc).wait(0xc420127958, 0x72, 0x262da20, 0x2621460)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/net/fd_poll_runtime.go:75 +0x38Oct  1 10:19:30 localhost dockerd: net.(*pollDesc).waitRead(0xc420127958, 0xc420208000, 0x8000)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/net/fd_poll_runtime.go:80 +0x34Oct  1 10:19:30 localhost dockerd: net.(*netFD).Read(0xc4201278f0, 0xc420208000, 0x8000, 0x8000, 0x0, 0x262da20, 0x2621460)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/net/fd_unix.go:250 +0x1b7Oct  1 10:19:30 localhost dockerd: net.(*conn).Read(0xc42042c308, 0xc420208000, 0x8000, 0x8000, 0x0, 0x0, 0x0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/net/net.go:181 +0x70Oct  1 10:19:30 localhost dockerd: bufio.(*Reader).Read(0xc4204f72c0, 0xc4203de858, 0x9, 0x9, 0x0, 0x0, 0x1)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/bufio/bufio.go:213 +0x312Oct  1 10:19:30 localhost dockerd: io.ReadAtLeast(0x2623220, 0xc4204f72c0, 0xc4203de858, 0x9, 0x9, 0x9, 0x26270e0, 0xc421a6fbc0, 0xc421a6fbc0)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/io/io.go:307 +0xa9Oct  1 10:19:30 localhost dockerd: io.ReadFull(0x2623220, 0xc4204f72c0, 0xc4203de858, 0x9, 0x9, 0xc420010070, 0x105000000000002, 0x2)Oct  1 10:19:30 localhost dockerd: /usr/local/go/src/io/io.go:325 +0x58Oct  1 10:19:30 localhost dockerd: github.com/docker/docker/vendor/golang.org/x/net/http2.readFrameHeader(0xc4203de858, 0x9, 0x9, 0x2623220, 0xc4204f72c0, 0x0, 0x0, 0x0, 0x26239e0)Oct  1 10:19:30 localhost systemd: docker.service: main process exited, code=exited, status=2/INVALIDARGUMENTOct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:237 +0x7bOct  1 10:19:30 localhost dockerd: github.com/docker/docker/vendor/golang.org/x/net/http2.(*Framer).ReadFrame(0xc4203de820, 0x0, 0x0, 0x0, 0x0)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:469 +0xa4Oct  1 10:19:30 localhost dockerd: github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*framer).readFrame(0xc4202606c0, 0xc421a6fb60, 0xc421a6fb60, 0x0, 0x0)Oct  1 10:19:30 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http_util.go:508 +0x2fOct  1 10:19:30 localhost dockerd: github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*http2Client).reader(0xc4204f9c20)....
"
35035,1,6205,2,0,0,coughlanio,0,"title:Segmentation Fault in Swarm. description:**Description**Encountered a segmentation fault this evening in our swarm environment, forcing the docker daemon on one of our nodes to restart.**Steps to reproduce the issue:**1. Run a swarm service2. :man_shrugging: **Describe the results you received:**Segmentation fault.**Describe the results you expected:**No Segmentation fault.**Additional information you deem important (e.g. issue happens only occasionally):**```Sep 29 06:30:01 prod-algo-swarm-2 dockerd[13215]: time=""2017-09-29T06:30:01.196700285Z"" level=info msg=""Node join event for prod-algo-swarm-1-bfafd2df1b36/10.146.0Sep 29 06:30:31 prod-algo-swarm-2 dockerd[13215]: time=""2017-09-29T06:30:31.198286477Z"" level=info msg=""Node join event for prod-algo-swarm-1-bfafd2df1b36/10.146.0Sep 29 06:31:01 prod-algo-swarm-2 dockerd[13215]: time=""2017-09-29T06:31:01.200051526Z"" level=info msg=""Node join event for prod-algo-swarm-1-bfafd2df1b36/10.146.0Sep 29 06:31:31 prod-algo-swarm-2 dockerd[13215]: time=""2017-09-29T06:31:31.201748198Z"" level=info msg=""Node join event for prod-algo-swarm-1-bfafd2df1b36/10.146.0Sep 29 06:32:01 prod-algo-swarm-2 dockerd[13215]: time=""2017-09-29T06:32:01.204480637Z"" level=info msg=""Node join event for prod-algo-swarm-1-bfafd2df1b36/10.146.0Sep 29 06:33:01 prod-algo-swarm-2 dockerd[13215]: time=""2017-09-29T06:33:01.207387727Z"" level=info msg=""Node join event for prod-algo-swarm-1-bfafd2df1b36/10.146.0Sep 29 06:34:01 prod-algo-swarm-2 dockerd[13215]: time=""2017-09-29T06:34:01.210787217Z"" level=info msg=""Node join event for prod-algo-swarm-1-bfafd2df1b36/10.146.0Sep 29 06:35:01 prod-algo-swarm-2 dockerd[13215]: time=""2017-09-29T06:35:01.214222654Z"" level=info msg=""Node join event for prod-algo-swarm-1-bfafd2df1b36/10.146.0Sep 29 06:36:01 prod-algo-swarm-2 dockerd[13215]: time=""2017-09-29T06:36:01.217369241Z"" level=info msg=""Node join event for prod-algo-swarm-1-bfafd2df1b36/10.146.0Sep 29 06:37:01 prod-algo-swarm-2 dockerd[13215]: time=""2017-09-29T06:37:01.219562834Z"" level=info msg=""Node join event for prod-algo-swarm-1-bfafd2df1b36/10.146.0Sep 29 06:37:31 prod-algo-swarm-2 dockerd[13215]: time=""2017-09-29T06:37:31.221348387Z"" level=info msg=""Node join event for prod-algo-swarm-1-bfafd2df1b36/10.146.0Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]: time=""2017-09-29T06:38:01.223254438Z"" level=info msg=""Node join event for prod-algo-swarm-1-bfafd2df1b36/10.146.0Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]: panic: runtime error: invalid memory address or nil pointer dereferenceSep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0xcad160]Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]: goroutine 3232831 [running]:Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]: github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).purgeSameNode(0xc42028e9c0, 0Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/delegate.go:65 +0x90Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]: github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).handleNodeEvent(0xc42028e9c0,Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/delegate.go:108 +0x184Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]: github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*delegate).MergeRemoteState(0xc420308230,Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]:         /go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/delegate.go:499 +0x27fSep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]: github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).mergeRemoteState(0xc42093e1e0, 0x26Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]:         /go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/net.go:989 +0x495Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]: github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).handleConn(0xc42093e1e0, 0x2625980,Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]:         /go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/net.go:233 +0xa76Sep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]: created by github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).streamListenSep 29 06:38:01 prod-algo-swarm-2 dockerd[13215]:         /go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/net.go:192 +0x114Sep 29 06:38:01 prod-algo-swarm-2 systemd[1]: docker.service: Main process exited, code=exited, status=2/INVALIDARGUMENTSep 29 06:38:01 prod-algo-swarm-2 systemd[1]: docker.service: Unit entered failed state.Sep 29 06:38:01 prod-algo-swarm-2 systemd[1]: docker.service: Failed with result 'exit-code'.```**Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:23:31 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:19:04 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 2 Running: 0 Paused: 0 Stopped: 2Images: 4Server Version: 17.06.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: journaldCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: ryri1m674ecv5h0yw2qocr5bm Is Manager: false Node Address: 10.146.0.6 Manager Addresses:  10.146.0.5:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.10.0-35-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 14.68GiBName: prod-algo-swarm-2ID: N6WL:JHGC:TRIQ:KZJD:NHLR:SUEA:AXVG:R7WU:3CT2:Q24W:XDTQ:RRE5Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**GCE Instance, two node swarm.
"
35023,0,435,0,0,0,lowenna,0,"title:Windows: Possible HNS regression: Does not error on duplicate port mappings in RS3 builds. description:@msabansal As per offline email, opening issue here. I'll temporarily disable the test (TestRunAttachFailedNoLeak - https://github.com/moby/moby/blob/master/integration-cli/docker_cli_run_test.go#L4012-L4036) to bring up RS3 CI pending further investigation.RS1:```docker run --rm -p 8000:8000 microsoft/windowsservercore cmd /s /c exit 0e:\go\src\github.com\docker\cli\binary\docker.exe: Error response from daemon: failed to create endpoint pedantic_lovelace on network nat: HNS failed with error : The object already exists```RS3:```docker run -d --name=test -p 8000:8000 microsoft/windowsservercore powershell sleep 600docker run --rm -p 8000:8000 microsoft/windowsservercore cmd /s /c exit 0```@johnstep FYI
"
34996,0,3995,0,0,0,aleskurlovich,0,"title:Worker cannot be joined to swarm cluster. description:**Description**Worker cannot be joined to swarm manager.**Steps to reproduce the issue:**1. Create manager node:```docker swarm init```2. Create worker node:```docker swarm join --token SWMTKN-1-1m7h3jnhycq46r5qzunx8gwvjjr4f30ckfqet2uqgdj60x3a9a-7kr5m1c3syidtmpgouh54f0fo <ip>:2377```**Describe the results you received:**```Sep 27 13:07:18 q4de3csye43 dockerd[10836]: time=""2017-09-27T13:07:18.304422384+02:00"" level=error msg=""failed to retrieve remote root CA certificate"" error=""rpc error: code = Unavailable desc = grpc: the connection is unavailable"" module=nodeSep 27 13:07:20 q4de3csye43 dockerd[10836]: time=""2017-09-27T13:07:20.307296581+02:00"" level=error msg=""failed to retrieve remote root CA certificate"" error=""rpc error: code = Unavailable desc = grpc: the connection is unavailable"" module=nodeSep 27 13:07:22 q4de3csye43 dockerd[10836]: time=""2017-09-27T13:07:22.309839445+02:00"" level=error msg=""failed to retrieve remote root CA certificate"" error=""rpc error: code = Unavailable desc = grpc: the connection is unavailable"" module=nodeSep 27 13:07:24 q4de3csye43 dockerd[10836]: time=""2017-09-27T13:07:24.312388683+02:00"" level=error msg=""failed to retrieve remote root CA certificate"" error=""rpc error: code = Unavailable desc = grpc: the connection is unavailable"" module=nodeSep 27 13:07:26 q4de3csye43 dockerd[10836]: time=""2017-09-27T13:07:26.315234191+02:00"" level=error msg=""failed to retrieve remote root CA certificate"" error=""rpc error: code = Unavailable desc = grpc: the connection is unavailable"" module=nodeSep 27 13:07:28 q4de3csye43 dockerd[10836]: time=""2017-09-27T13:07:28.315699672+02:00"" level=error msg=""cluster exited with error: rpc error: code = Unavailable desc = grpc: the connection is unavailable""Sep 27 13:07:28 q4de3csye43 dockerd[10836]: time=""2017-09-27T13:07:28.316059555+02:00"" level=error msg=""Handler for POST /v1.32/swarm/join returned error: rpc error: code = Unavailable desc = grpc: the connection is unavailable""```**Describe the results you expected:**Worker is joined.**Additional information you deem important (e.g. issue happens only occasionally):**We faced to this issue after Docker was upgraded from 17.06.2-ce to 17.09.0-ce. Now it is not possible to join any worker to the swarm.**Output of `docker version`:**```Client: Version:      17.09.0-ce API version:  1.32 Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:41:23 2017 OS/Arch:      linux/amd64Server: Version:      17.09.0-ce API version:  1.32 (minimum version 1.12) Go version:   go1.8.3 Git commit:   afdb6d4 Built:        Tue Sep 26 22:42:49 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 15Server Version: 17.09.0-ceStorage Driver: overlay Backing Filesystem: extfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: keosiajh7onqpn42u3ixsrmb3 Is Manager: true ClusterID: qe8cswquhtjl817eiu4gtzyio Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Autolock Managers: false Root Rotation In Progress: false Node Address: 10.33.177.47 Manager Addresses:  <ip>:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 3f2f8b84a77f73d38244dd690525642a72156c64init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.21.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 9.601GiBName: q4de3csye47ID: 2FXY:XP3H:UWFL:3R7U:CF5H:THXJ:XC5K:SZTS:U4LV:AY7D:3JNV:FOJFDocker Root Dir: /dockerDebug Mode (client): falseDebug Mode (server): falseHttp Proxy: http://<ip>:3128/Https Proxy: http://<ip>:3128/No Proxy: <ip>,registryRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 10.33.177.26:5000 registry:5000 127.0.0.0/8Live Restore Enabled: falseWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**OS: Centos 7Linux q4de3csye43 3.10.0-693.2.2.el7.x86_64 #1 SMP Tue Sep 12 22:26:13 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
"
34862,0,2837,4,0,0,chris-crone,0,"title:Changes to build on master.dockerproject.org break test. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Recently the version of the daemon hosted on https://master.dockerproject.org changed format from `17.06.0-dev` to `master-dockerproject-2017-09-14`. This breaks the `DockerSuite.TestGetVersion` test found in `integration-cli/docker_api_version_test.go` when it is run against a downloaded daemon.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. Download daemon from https://master.dockerproject.org2. Build integration tests3. Run tests against downloaded daemon**Describe the results you received:**Output from the test is:```----------------------------------------------------------------------FAIL: /go/src/github.com/docker/docker/integration-cli/docker_api_version_test.go:11: DockerSuite.TestGetVersion/go/src/github.com/docker/docker/integration-cli/docker_api_version_test.go:17:    ...open /go/src/github.com/docker/docker/integration-cli/docker_api_version_test.go: no such file or directory... obtained string = ""master-dockerproject-2017-09-14""... expected string = ""17.06.0-dev""... Version mismatch----------------------------------------------------------------------```**Describe the results you expected:**Test to pass**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```docker versionClient: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:15:15 2017 OS/Arch:      linux/amd64Server: Version:      master-dockerproject-2017-09-14 API version:  1.32 (minimum version 1.12) Go version:   go1.8.3 Git commit:   0300fa7 Built:        Thu Sep 14 23:46:27 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 8Server Version: master-dockerproject-2017-09-14Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 6 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: objqsv79krsz3aie5yy39fu1n Is Manager: true ClusterID: yjkvuonbgwj6hnnrelawa18pg Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Root Rotation In Progress: false Node Address: 192.168.99.100 Manager Addresses:  192.168.99.100:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 06b9cb35161009dcb7123345749fef02f7cea8e0runc version: 1c81e2a794c6e26a4c650142ae8893c47f619764init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-72-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 1.953GiBName: dev-0ID: NN6W:JRZ5:6UOE:BDZT:OYQQ:KEP7:TA4A:L6K5:SEDA:XIRN:UUGE:46ZCDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 36 Goroutines: 142 System Time: 2017-09-15T02:02:24.895616479-07:00 EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**This was found while containerizing the integration tests: https://github.com/moby/moby/pull/34805
"
34827,0,2365,7,0,0,alexanderkjeldaas,0,"title:single manager docker swarm stuck in Down state after reboot. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**A single-manager swarm cluster gets into the following state after a abrupt reboot:```# docker node lsID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUSux3enftr6krhlrp8bbodo2q1l *   wsdocker6           Down                Active              Leader```The manager can't leave the swarm, as the `docker swarm leave --force` command times out.The above state shouldn't be possible to be in.  By printing the above, the node must be a manager, and since there's only one manager, it has to infer that itself is that manager, and it thus can't be `Down`.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1.  Create a swarm with 1 manager2.  Abruptly reboot3. Profit**Describe the results you received:****Describe the results you expected:****Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**``` docker versionClient: Version:      17.06.2-ce API version:  1.30 Go version:   go1.8.3 Git commit:   cec0b72 Built:        Tue Sep  5 20:00:17 2017 OS/Arch:      linux/amd64Server: Version:      17.06.2-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   cec0b72 Built:        Tue Sep  5 19:59:11 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```root@wsdocker6:/etc/systemd/system# docker infoContainers: 83 Running: 1 Paused: 0 Stopped: 82Images: 103Server Version: 17.06.2-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: pending NodeID: ux3enftr6krhlrp8bbodo2q1l Is Manager: true ClusterID: nhkjyh6xo2jdu2txkjt95xfua Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Root Rotation In Progress: false Node Address: x.x.x.x Manager Addresses:  x.x.x.x:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 6e23458c129b551d5c9871e5174f6b1b7f6d1170runc version: 810190ceaa507aa2727d7ae6f4790c76ec150bd2init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-93-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 15.63GiBName: wsdocker6ID: KRY5:PQU2:2KPP:7QR6:4EXD:QFXT:KKVB:CZVN:OQUU:S5A3:Z5ZT:XQGNDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: xxxRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
34792,0,207,298,0,1,runcom,0,"title:volume: evaluate symlinks before relabeling mount source. description:Simple reproducer:```sh$ mkdir /var/foo$ touch /var/foo/test$ ln -s /var/foo /var/bar$ docker run -ti -v /var/bar:/var/bar:Z fedora shsh-4.3# ls -lZ /var/bar/ls: cannot open directory '/var/bar/': Permission denied```@cpuguy83 PTALSigned-off-by: Antonio Murdaca <runcom@redhat.com><!--Please make sure you've read and understood our contributing guidelines;https://github.com/docker/docker/blob/master/CONTRIBUTING.md** Make sure all your commits include a signature generated with `git commit -s` **For additional information on our contributing process, read our contributingguide https://docs.docker.com/opensource/code/If this is a bug fix, make sure your description includes ""fixes #xxxx"", or""closes #xxxx""Please provide the following information:-->**- What I did****- How I did it****- How to verify it****- Description for the changelog**<!--Write a short (one line) summary that describes the changes in thispull request for inclusion in the changelog:-->**- A picture of a cute animal (not mandatory but encouraged)**
"
34749,0,1907,0,0,1,JWEdwards-TCS,0,"title:Splunk logger not transmitting log data when tag is empty. description:**Description**Running Docker with the Splunk log driver in raw mode and tag="""" I don't see any data in Splunk from my application.daemon/logger/splunk/splunk.go implies tag="""" will cause the tag to be omitted and log entries will be sent to Splunk.If I set tag=""-"" or some other string the logs from my application are visible in Splunk with the tag prefix.**Steps to reproduce the issue:**1. Have a docker image which sends some data to stdout2. ```docker run --rm --log-driver=splunk \--log-opt splunk-format=raw \--log-opt splunk-index=lab \--log-opt splunk-insecureskipverify=true \--log-opt splunk-source=""test"" \--log-opt splunk-token=<my splunk token>\--log-opt splunk-url=<my splunk url> \--log-opt tag="""" \ <imageId>```**Describe the results you received:**I see logs from my application appearing in stdout.I do not see any of those appearing in splunk**Describe the results you expected:**I expect Splunk to contain an exact replica of the content of stdout**Additional information you deem important (e.g. issue happens only occasionally):**Using --log-opt tag=""-"" \I see entries in Splunk with the prefix ""- "".**Output of `docker version`:**```Client: Version:      17.06.2-ce API version:  1.30 Go version:   go1.8.3 Git commit:   cec0b72 Built:        Tue Sep  5 20:12:06 2017 OS/Arch:      darwin/amd64Server: Version:      17.06.2-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   cec0b72 Built:        Tue Sep  5 19:59:19 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 11Server Version: 17.06.2-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 6e23458c129b551d5c9871e5174f6b1b7f6d1170runc version: 810190ceaa507aa2727d7ae6f4790c76ec150bd2init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.41-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952GiBName: mobyID: VSP6:DTQJ:CRIQ:JSTP:QETN:HCXZ:CHD3:YTPB:P7ZO:6DNQ:M5SE:UPWODocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 18 Goroutines: 31 System Time: 2017-09-06T16:33:17.602339091Z EventsListeners: 1Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
34683,0,2015,0,0,0,mlaventure,1,"title:Exec orphans are not reaped correctly. description:**Description**When doing an exec that will spawn children that inherits its IO and outlive the initial exec process. Upon that initial process exiting, if an orphan exits it is not properly reaped by `docker-containerd-shim` until all the other children that held the IO are gone (and hence allowing the shim to exit, causing those orphan to be reaped by init).**Steps to reproduce the issue:**1. `docker run --name test -tid busybox sh`2. `docker run exec -ti test sh````/ # sleep 100 &/ # sleep 1 &/ # exit```3. `ps afx -o pid,ppid,cmd````27680  2041      \_ docker-containerd-shim 233ff9b18f96635dbf03d7904ecb9b3298f43d6d87151f798c7ddc70ff981928 /var/run/docker/libcontainerd/233ff9b18f96635dbf03d7904ecb9b3298f43d6d87151f798c7ddc70ff981928 docker-runc27708 27680          \_ sleep 10027709 27680          \_ [sleep] <defunct>```**Describe the results you received:**`sleep 1` became a defunct process**Describe the results you expected:**The `sleep 1` should have been reaped by the shim**Output of `docker version`:**```Client: Version:      17.06.1-ce API version:  1.30 Go version:   go1.8.3 Git commit:   874a737 Built:        Thu Aug 17 22:53:09 2017 OS/Arch:      linux/amd64Server: Version:      17.06.1-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   874a737 Built:        Thu Aug 17 22:51:03 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 10 Running: 4 Paused: 0 Stopped: 6Images: 348Server Version: 17.06.1-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 264 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 6e23458c129b551d5c9871e5174f6b1b7f6d1170runc version: 810190ceaa507aa2727d7ae6f4790c76ec150bd2init version: 949e6faSecurity Options: apparmorKernel Version: 4.4.0-92-genericOperating System: Ubuntu 14.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.704GiBName: toraID: PGAP:WNSD:3V37:HM5N:XILR:YTPC:QASH:KPI2:5ZMK:BSN5:PCOA:DWM6Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 66 Goroutines: 105 System Time: 2017-08-30T09:28:03.982021297-07:00 EventsListeners: 0Username: mlaventureRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: trueWARNING: No swap limit support```
"
34591,0,5305,33,0,0,jetgeng,0,"title:Docker 17.06-ce crash with memory address or nil pointer dereference on libnetwork networkdb.(*NetworkDB).purgeSameNode(. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**BUG REPORT INFORMATION****Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:20:36 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:21:56 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Server Version: 17.06.0-ceStorage Driver: overlay Backing Filesystem: xfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: i0yeddylzskjngac1d15obfnz Is Manager: true ClusterID: hxe9l5dhkjg5uz9nvbpzqdk3p Managers: 1 Nodes: 2 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Root Rotation In Progress: false Node Address: 192.168.0.25 Manager Addresses:  192.168.0.25:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.21.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 62.76GiBName: localhostID: PLVD:VDG5:KEG2:WLIZ:N3CD:7Z77:4UZQ:LS2L:HBUJ:YM2C:N2YS:2R4FDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 192.168.0.22:5000 127.0.0.0/8Registry Mirrors: https://qkgqg5da.mirror.aliyuncs.com/Live Restore Enabled: false```the server was working , someday the server is crash at early morning. and no some special action on the server. the log as follow:```Aug 21 00:37:48 localhost dockerd: panic: runtime error: invalid memory address or nil pointer dereferenceAug 21 00:37:48 localhost dockerd: [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0xcacee0]Aug 21 00:37:48 localhost dockerd: goroutine 340 [running]:Aug 21 00:37:48 localhost dockerd: github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).purgeSameNode(0xc420bec9c0, 0x0)Aug 21 00:37:48 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/delegate.go:65 +0x90Aug 21 00:37:48 localhost dockerd: github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).handleNodeEvent(0xc420bec9c0, 0xc420cedb70, 0x100)Aug 21 00:37:48 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/delegate.go:108 +0x184Aug 21 00:37:48 localhost dockerd: github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*delegate).MergeRemoteState(0xc4202e2868, 0xc4214f4400, 0xfc, 0xfc, 0x0)Aug 21 00:37:48 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/delegate.go:499 +0x27fAug 21 00:37:48 localhost dockerd: github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).mergeRemoteState(0xc4201e72c0, 0xc421c08000, 0xc4212581c0, 0x2, 0x2, 0xc4214f4400, 0xfc, 0xfc, 0xfc, 0xfc)Aug 21 00:37:48 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/net.go:989 +0x495Aug 21 00:37:48 localhost dockerd: github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).pushPullNode(0xc4201e72c0, 0xc421c08000, 0x11, 0x0, 0x0, 0x0)Aug 21 00:37:48 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/state.go:560 +0x1a8Aug 21 00:37:48 localhost dockerd: github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).pushPull(0xc4201e72c0)Aug 21 00:37:48 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/state.go:545 +0x119Aug 21 00:37:48 localhost dockerd: github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).pushPullTrigger(0xc4201e72c0, 0xc421577bc0)Aug 21 00:37:48 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/state.go:157 +0x1a0Aug 21 00:37:48 localhost dockerd: created by github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).scheduleAug 21 00:37:48 localhost dockerd: /root/rpmbuild/BUILD/src/engine/.gopath/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/state.go:100 +0x347Aug 21 00:37:48 localhost systemd: docker.service: main process exited, code=exited, status=2/INVALIDARGUMENTAug 21 00:37:48 localhost systemd: Unit docker.service entered failed state.Aug 21 00:37:48 localhost systemd: docker.service failed.Aug 21 00:37:49 localhost systemd: docker.service holdoff time over, scheduling restart.```
"
34564,1,2338,69,0,0,jaloren,0,"title:multistage builds leak linux semaphore arrays which prevent creating images or containers. description:---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------**Description**I have a dockerfile that uses the multistage build feature. During the docker build, over 128 linux semaphore arrays are generated which exhausts the linux kernal limit. **Steps to reproduce the issue:**1. create a docker file that performs a multistage build where the base image is centos 7.2. run docker build.**Describe the results you received:**Docker build fails to create an image because the linux semaphore arrays are exhausted.**Describe the results you expected:**docker build successfully creates the image.**Additional information you deem important (e.g. issue happens only occasionally):**This is occurring with the device mapper storage layer. Here's the docker build file i used.```FROM private-registry:8082/centos-7 as buildRUN set -x \    && yum install -y perl make automake gcc gmp-devel libffi zlib xz tar git gnupg FROM private-registry:8082/centos-7COPY --from=build /root/ /tmp/root```I am using centos 7.3. Here's uname information:```Linux build-slave-9 3.10.0-514.21.2.el7.x86_64 #1 SMP Tue Jun 20 12:24:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux```**Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:20:36 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:21:56 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 26Server Version: 17.06.0-ceStorage Driver: devicemapper Pool Name: docker-thinpool Pool Blocksize: 524.3kB Base Device Size: 10.74GB Backing Filesystem: xfs Data file:  Metadata file:  Data Space Used: 9.473GB Data Space Total: 25.5GB Data Space Available: 16.02GB Metadata Space Used: 1.098MB Metadata Space Total: 264.2MB Metadata Space Available: 263.1MB Thin Pool Minimum Free Space: 2.55GB Udev Sync Supported: true Deferred Removal Enabled: false Deferred Deletion Enabled: false Deferred Deleted Device Count: 0 Library Version: 1.02.135-RHEL7 (2016-11-16)Logging Driver: journaldCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.21.2.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 7.639GiBName: build-slaveID: DUDO:TN33:WPJY:DM5Z:TZXZ:F6JU:I24K:2A62:XO2G:GC7V:IQKL:W775Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```
"
34532,1,1364,24,0,0,martinmine,0,"title:Using --mount instead of -v complains about invalid characters in local volume name. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Following the documentation on using [binded volumes](https://docs.docker.com/engine/admin/volumes/bind-mounts/#start-a-container-with-a-bind-mount), using --mount instead of -v does not allow / in the source path and gives me the error: ```docker: Error response from daemon: create /home/martinmine/Documents/target: ""/home/martinmine/Documents/target"" includes invalid characters for a local volume name, only ""[a-zA-Z0-9][a-zA-Z0-9_.-]"" are allowed. If you intended to pass a host directory, use absolute path.See 'docker run --help'.```Running  `docker run -d -it --name devtest -v $(pwd)/target:/app nginx:latest` works fine and mounts the `target` directory just find. However, running `docker run -d -it --name devtest --mount source=$(pwd)/target,target=/app nginx:latest` gives me the error above.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. `mkdir target`2. `docker run -d -it --name devtest --mount source=$(pwd)/target,target=/app nginx:lates`**Describe the results you received:**See error message above.**Describe the results you expected:**I expect the same behavior as with the -v option, [as the documentation states](https://docs.docker.com/engine/admin/volumes/bind-mounts/#start-a-container-with-a-bind-mount).**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Docker version 17.05.0-ce, build 89658be```**Output of `docker info`:**```Containers: 3 Running: 3 Paused: 0 Stopped: 0Images: 22Server Version: 17.05.0-ceStorage Driver: overlay Backing Filesystem: extfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.10.2.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 16Total Memory: 28.6GiBName: xxxxxxxxxxxID: 6OYY:KN5X:OBD3:SOUB:7CXB:5RL4:XUOZ:7ZEJ:CIOB:U6ZZ:PLYF:6P2XDocker Root Dir: /mnt/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Happens on both a virtual machine through Openstack (CentOS7), and on my laptop (Fedora).
"
34515,1,5429,31,1,0,lox,0,"title:Docker 17.06.0-ce crash with http: panic serving @: runtime error: invalid memory address or nil pointer dereference. description:We are encountering this issue when using Docker 17.05.0-ce on Amazon Linux, as described in https://github.com/moby/moby/issues/25663. We are running docker in an autoscaling group that runs CI jobs in fairly large volumes. Around 10% of runs will fail on new docker hosts during the creation of the first network with `docker-compose run`:```017-08-15T01:39:57.809Z 2017-08-15 01:39:57.811935 I | http: panic serving @: runtime error: invalid memory address or nil pointer dereference2017-08-15T01:39:57.809Z goroutine 212 [running]:2017-08-15T01:39:57.809Z net/http.(*conn).serve.func1(0xc4203da280)	/usr/local/go/src/net/http/server.go:1721 +0xd02017-08-15T01:39:57.809Z panic(0x1845f60, 0x26c7940)	/usr/local/go/src/runtime/panic.go:489 +0x2cf2017-08-15T01:39:57.809Z github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*networkConfiguration).conflictsWithNetworks(0xc420eba0b0, 0xc420cd63c0, 0x40, 0xc4201ecf20, 0x3, 0x3, 0x0, 0x4124a8)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge.go:349 +0xf02017-08-15T01:39:57.809Z github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*driver).createNetwork(0xc420476c30, 0xc420eba0b0, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge.go:686 +0x9b62017-08-15T01:39:57.809Z github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge.(*driver).CreateNetwork(0xc420476c30, 0xc420cd63c0, 0x40, 0xc420e7c5d0, 0x26ef760, 0xc420eaa000, 0xc420e7c990, 0x1, 0x1, 0x27801b0, ...)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/drivers/bridge/bridge.go:610 +0x21c2017-08-15T01:39:57.809Z github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).addNetwork(0xc4202b8b00, 0xc420eaa000, 0xc420e97080, 0xc420eaa000)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:945 +0x1572017-08-15T01:39:57.809Z github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).NewNetwork(0xc4202b8b00, 0x1a9fba1, 0x6, 0xc420a28940, 0x31, 0xc420cd63c0, 0x40, 0xc420e7c540, 0x6, 0x6, ...)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:807 +0xb002017-08-15T01:39:57.809Z github.com/docker/docker/daemon.(*Daemon).createNetwork(0xc420380000, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...)	/go/src/github.com/docker/docker/daemon/network.go:349 +0x5c02017-08-15T01:39:57.809Z github.com/docker/docker/daemon.(*Daemon).CreateNetwork(0xc420380000, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...)	/go/src/github.com/docker/docker/daemon/network.go:280 +0x872017-08-15T01:39:57.809Z github.com/docker/docker/api/server/router/network.(*networkRouter).postNetworkCreate(0xc4200fd140, 0x7f1df0643000, 0xc4204cf8f0, 0x2707fe0, 0xc4201042a0, 0xc420480800, 0xc4204cf770, 0x1a9e63d, 0x5)	/go/src/github.com/docker/docker/api/server/router/network/network_routes.go:195 +0x1ed2017-08-15T01:39:57.809Z github.com/docker/docker/api/server/router/network.(*networkRouter).(github.com/docker/docker/api/server/router/network.postNetworkCreate)-fm(0x7f1df0643000, 0xc4204cf8f0, 0x2707fe0, 0xc4201042a0, 0xc420480800, 0xc4204cf770, 0x7f1df0643000, 0xc4204cf8f0)	/go/src/github.com/docker/docker/api/server/router/network/network.go:37 +0x692017-08-15T01:39:57.809Z github.com/docker/docker/api/server/middleware.ExperimentalMiddleware.WrapHandler.func1(0x7f1df0643000, 0xc4204cf8f0, 0x2707fe0, 0xc4201042a0, 0xc420480800, 0xc4204cf770, 0x7f1df0643000, 0xc4204cf8f0)	/go/src/github.com/docker/docker/api/server/middleware/experimental.go:27 +0xd82017-08-15T01:39:57.809Z github.com/docker/docker/api/server/middleware.VersionMiddleware.WrapHandler.func1(0x7f1df0643000, 0xc4204cf7d0, 0x2707fe0, 0xc4201042a0, 0xc420480800, 0xc4204cf770, 0x47, 0xc420483220)	/go/src/github.com/docker/docker/api/server/middleware/version.go:48 +0x55d2017-08-15T01:39:57.809Z github.com/docker/docker/pkg/authorization.(*Middleware).WrapHandler.func1(0x7f1df0643000, 0xc4204cf7d0, 0x2707fe0, 0xc4201042a0, 0xc420480800, 0xc4204cf770, 0x0, 0x756ea11b601fbb)	/go/src/github.com/docker/docker/pkg/authorization/middleware.go:54 +0x8712017-08-15T01:39:57.809Z github.com/docker/docker/api/server/middleware.DebugRequestMiddleware.func1(0x7f1df0643000, 0xc4204cf7d0, 0x2707fe0, 0xc4201042a0, 0xc420480800, 0xc4204cf770, 0x7f1df0643000, 0xc4204cf7d0)	/go/src/github.com/docker/docker/api/server/middleware/debug.go:53 +0x5272017-08-15T01:39:57.809Z github.com/docker/docker/api/server.(*Server).makeHTTPHandler.func1(0x2707fe0, 0xc4201042a0, 0xc420480800)	/go/src/github.com/docker/docker/api/server/server.go:139 +0x21a2017-08-15T01:39:57.809Z net/http.HandlerFunc.ServeHTTP(0xc42046c900, 0x2707fe0, 0xc4201042a0, 0xc420480800)	/usr/local/go/src/net/http/server.go:1942 +0x442017-08-15T01:39:57.809Z github.com/docker/docker/vendor/github.com/gorilla/mux.(*Router).ServeHTTP(0xc4203f2640, 0x2707fe0, 0xc4201042a0, 0xc420480800)	/go/src/github.com/docker/docker/vendor/github.com/gorilla/mux/mux.go:103 +0x2552017-08-15T01:39:57.809Z github.com/docker/docker/api/server.(*routerSwapper).ServeHTTP(0xc420108b80, 0x2707fe0, 0xc4201042a0, 0xc420480800)	/go/src/github.com/docker/docker/api/server/router_swapper.go:29 +0x702017-08-15T01:39:57.809Z net/http.serverHandler.ServeHTTP(0xc420095970, 0x2707fe0, 0xc4201042a0, 0xc420480800)	/usr/local/go/src/net/http/server.go:2568 +0x922017-08-15T01:39:57.809Z net/http.(*conn).serve(0xc4203da280, 0x2709b60, 0xc420a28640)	/usr/local/go/src/net/http/server.go:1825 +0x6122017-08-15T01:39:57.809Z created by net/http.(*Server).Serve	/usr/local/go/src/net/http/server.go:2668 +0x2ce```The full docker.log is here https://gist.github.com/lox/7669bd18a80a48a5c83f4cb96ff40d95. 
"
34512,1,2077,8,0,0,DavidObando,0,"title:Multi-stage build fails when CLI invoked with --pull. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**The docker daemon will try to go to the docker registry and pull newer images during build operations when the docker CLI is invoked with the `--pull` flag. When using a multi-stage build, the daemon is attempting to fetch the intermediate stages from the public registry, and fails with the following message:```invalid from flag value vpbuilder: repository sha256 not found: does not exist or no pull access```**Steps to reproduce the issue:**You can reproduce with the following simple files:### Dockerfile```DockerfileFROM golang:1.8 as vpbuilderWORKDIR /go/src/vpCOPY . .RUN GOOS=linux GOARCH=amd64 CGO_ENABLED=0 go build -v -a -o vp .FROM alpine:3.4WORKDIR /vp/COPY --from=vpbuilder /go/src/vp/vp .ENTRYPOINT ./vp```### main.go```gopackage mainimport (        ""fmt"")func main() {        fmt.Println(""Hello, bug report!"")}```Then, execute the following command:```bashdocker build --pull -t vp1 .```**Describe the results you received:**The build fails, and I see the following message:```invalid from flag value vpbuilder: repository sha256 not found: does not exist or no pull access```**Describe the results you expected:**The build should succeed just as when I call docker build without the `--pull` flag.**Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:17:04 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:15:57 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 1 Running: 0 Paused: 0 Stopped: 1Images: 11Server Version: 17.06.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 16 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: apparmorKernel Version: 4.8.0-59-genericOperating System: Ubuntu 16.10OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 11.72GiBName: daobando-u1ID: S4FY:DU3O:TGZJ:XGVH:CQAO:TAW7:C3YS:KGYU:E2VD:RTWO:ZKXN:7JQPDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```
"
34491,0,0,247,0,0,AkihiroSuda,0,"title:Migrate integration-cli-on-swarm to integration-on-swarm. description:Currently, `integration-cli-on-swarm` does not execute non-CLI tests under the `integration` directory.No need to hurry, as the `integration` directory contains only a few tests ATM.Tasks:- s/integration-cli-on-swarm/integration-on-swarm/- hack/integration-on-swarm/host: Enumerate tests under the `integration` directory- hack/integration-on-swarm/agent/worker: Support tests that are not `go-check` suites#dibs
"
34476,0,2405,200,0,0,thaJeztah,0,"title:Invalid registry-mirrors in daemon.json silently ignored. description:**Description**When configuring registry-mirrors through the `daemon.json` configuration-file, invalid mirrors are silently ignored.While there is validation when specifying a mirror through the --registry-mirror`, and pull-request https://github.com/moby/moby/pull/29650 (https://github.com/moby/moby/commit/5b9348c553d183bc62f6e7cc8f934766fac162bd) added the possibility to reload mirrors without restarting the daemon (which _does_ validate the option), a regular start of the daemon just ignores the value.**Steps to reproduce the issue:**Starting the daemon manually, and setting the `--registry-mirror` flag, the value is validated correctly:```bash$ dockerd --debug --registry-mirror=""example.com:5000""Status: invalid argument ""example.com:5000"" for --registry-mirror=example.com:5000: invalid mirror: unsupported scheme ""example.com"" in ""example.com:5000""```Doing the same through the `daemon.json` configuration file however, silently ignores the invalid option. No message is logged as well (even in debug mode (not shown in the example output below));```bash$ mkdir -p /etc/docker/ && echo '{""registry-mirrors"": [""example.com:5000""]}' > /etc/docker/daemon.json$ dockerdWARN[0000] could not change group /var/run/docker.sock to docker: group docker not foundINFO[0000] libcontainerd: new containerd process, pid: 91INFO[0001] [graphdriver] using prior storage driver: aufsINFO[0001] Graph migration to content-addressability took 0.00 secondsINFO[0001] Loading containers: start.INFO[0001] Default bridge (docker0) is assigned with an IP address 172.18.0.0/16. Daemon option --bip can be used to set a preferred IP addressWARN[0001] Running modprobe nf_nat failed with message: `modprobe: can't change directory to '/lib/modules': No such file or directory`, error: exit status 1WARN[0001] Running modprobe xt_conntrack failed with message: `modprobe: can't change directory to '/lib/modules': No such file or directory`, error: exit status 1WARN[0001] Failed to create DOCKER-USER chain: Iptables not foundINFO[0001] Loading containers: done.WARN[0001] Couldn't run auplink before unmount /var/lib/docker/tmp/docker-aufs-union121916784: exec: ""auplink"": executable file not found in $PATHINFO[0001] Daemon has completed initializationINFO[0001] Docker daemon                                 commit=02c1d87 graphdriver=aufs version=17.06.0-ceINFO[0001] API listen on /var/run/docker.sock```However, when _reloading_ the same configuration, an error is logged, stating that the configuration is invalid and will not be reloaded:```bash$ kill -HUP $(pidof dockerd)INFO[0304] Got signal to reload configuration, reloading from: /etc/docker/daemon.jsonERRO[0304] Error reconfiguring the daemon: invalid mirror: unsupported scheme ""example.com"" in ""example.com:5000""```Note that users can discover that the option is ignored by watching the output of `docker info`; in case of an invalid mirror, the mirror is not shown in the output:```Insecure Registries: 127.0.0.0/8Live Restore Enabled: false```While with a _correct_ configuration, the mirror is shown:```Insecure Registries: 127.0.0.0/8Registry Mirrors: https://example.com:5000/Live Restore Enabled: false```**Describe the results you received:**No error message, and the option silently ignored**Describe the results you expected:**The daemon refusing to start, printing an error message that the configuration is invalid.**Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:15:15 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:51:55 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**not relevant; not platform dependent
"
34459,0,4764,23,0,0,tossmilestone,0,"title:Create duplicated network expect 409 response but get 500. description:**Description**When create a network with name already existed using docker-py, and set arg `check_duplicated=True`, the error should be `409 Conflict`, but `500 Internal Server Error` returns.**Steps to reproduce the issue:**In python console```>>> import docker>>> c = docker.from_env()>>> c.networks.create('net1')<Network: 4c7d2d08e3>>>> c.networks.create('net1', check_duplicate=True)```**Describe the results you received:**```>>> c.networks.create('net1', check_duplicate=True)Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""/usr/lib/python2.7/site-packages/docker/models/networks.py"", line 144, in create    resp = self.client.api.create_network(name, *args, **kwargs)  File ""/usr/lib/python2.7/site-packages/docker/utils/decorators.py"", line 35, in wrapper    return f(self, *args, **kwargs)  File ""/usr/lib/python2.7/site-packages/docker/api/network.py"", line 134, in create_network    return self._result(res, json=True)  File ""/usr/lib/python2.7/site-packages/docker/api/client.py"", line 220, in _result    self._raise_for_status(response)  File ""/usr/lib/python2.7/site-packages/docker/api/client.py"", line 216, in _raise_for_status    raise create_api_error_from_http_exception(e)  File ""/usr/lib/python2.7/site-packages/docker/errors.py"", line 30, in create_api_error_from_http_exception    raise cls(e, response=response, explanation=explanation)docker.errors.APIError: 500 Server Error: Internal Server Error for url: http+docker://localunixsocket/v1.24/networks/create (""network with name net1 already exists"")>>> ```**Describe the results you expected:**```>>> c.networks.create('net1', check_duplicate=True)Traceback (most recent call last):  File ""<stdin>"", line 1, in <module>  File ""/usr/lib/python2.7/site-packages/docker/models/networks.py"", line 144, in create    resp = self.client.api.create_network(name, *args, **kwargs)  File ""/usr/lib/python2.7/site-packages/docker/utils/decorators.py"", line 35, in wrapper    return f(self, *args, **kwargs)  File ""/usr/lib/python2.7/site-packages/docker/api/network.py"", line 134, in create_network    return self._result(res, json=True)  File ""/usr/lib/python2.7/site-packages/docker/api/client.py"", line 220, in _result    self._raise_for_status(response)  File ""/usr/lib/python2.7/site-packages/docker/api/client.py"", line 216, in _raise_for_status    raise create_api_error_from_http_exception(e)  File ""/usr/lib/python2.7/site-packages/docker/errors.py"", line 30, in create_api_error_from_http_exception    raise cls(e, response=response, explanation=explanation)docker.errors.APIError: 409 Client Error: Conflict for url: http+docker://localunixsocket/v1.24/networks/create (""network with name net1 already exists"")>>> ```**Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:20:36 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:21:56 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 1Server Version: 17.06.0-ceStorage Driver: overlay Backing Filesystem: xfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: 7ty93f9vgo9gb2nmwk4km10hb Is Manager: true ClusterID: fofqp1rgom60nftnc5fwkz1st Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Root Rotation In Progress: false Node Address: 192.168.249.129 Manager Addresses:  192.168.249.129:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 472.5MiBName: swarm_managerID: YRD2:DTIW:AKEF:RXJY:RKXM:OJU2:N7B6:K7JK:XDOG:4E5S:NWFU:SGWYDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 40 Goroutines: 184 System Time: 2017-08-08T14:20:57.288514678+08:00 EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 10.27.37.40:5000 10.37.210.125:5001 127.0.0.0/8Registry Mirrors: https://2h3po24q.mirror.aliyuncs.com/Live Restore Enabled: falseWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**```docker-py version 2.1.0```
"
34307,0,1567,0,0,0,ChenMin46,0,"title:""docker run --net,--pid,--ipc"" to a container is invalid after rename and restart. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1.docker run -tid --name=test0 ubuntu bash2.docker run -tid --name=test1 --net=container:test0 ubuntu bash3.docker rename test0 test24.docker restart test1**Describe the results you received:**Error response from daemon: Cannot restart container test1: No such container: test0When replace the ""--net"" to ""--pid"" or ""--ipc"" will get :Post http://%2Fvar%2Frun%2Fdocker.sock/v1.29/containers/test3/restart: EOF**Describe the results you expected:**test1 restart succuss**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.7.5 Git commit:   89658be Built:        Fri May  5 15:36:11 2017 OS/Arch:      linux/amd64Server: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   89658be Built:        Fri May  5 15:36:11 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 15 Running: 13 Paused: 0 Stopped: 2Images: 60Server Version: 17.05.0-ceStorage Driver: overlay2 Backing Filesystem: xfs Supports d_type: false Native Overlay Diff: falseLogging Driver: journaldCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlayRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.21.2.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 7.639GiBName: 16ID: 5PRJ:JAJY:H6IP:OBMF:7QQ6:AQJ2:JHGD:KOHN:K4PZ:ETTR:JPUA:KZ2PDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 95 Goroutines: 128 System Time: 2017-07-30T02:26:57.040522467+08:00 EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: falseInsecure Registries: demoregistry.dataman-inc.com 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
34296,0,0,0,0,1,mixja,0,"title:Fix awslogs driver repeating last event - #34292. description:Signed-off-by: Justin Menga <justin.menga@gmail.com><!--Please make sure you've read and understood our contributing guidelines;https://github.com/docker/docker/blob/master/CONTRIBUTING.md** Make sure all your commits include a signature generated with `git commit -s` **For additional information on our contributing process, read our contributingguide https://docs.docker.com/opensource/code/If this is a bug fix, make sure your description includes ""fixes #xxxx"", or""closes #xxxx""Please provide the following information:-->**- What I did**Fixes #34292**- How I did it**Ensure event buffer used for storing log events is properly flushed**- How to verify it**The modifications to the test case in this PR fail with the old code and pass with the new code.See #34292 for details on how to replicate the issue (I have verified this is no longer an issue with this PR)**- Description for the changelog**<!--Write a short (one line) summary that describes the changes in thispull request for inclusion in the changelog:-->Fix awslogs driver repeating last event**- A picture of a cute animal (not mandatory but encouraged)**![scared-bug](https://user-images.githubusercontent.com/3351083/28709876-26ec7508-73d6-11e7-8a7f-50552238e0d4.jpg)
"
34282,0,2256,164,0,0,mbentley,0,"title:docker top fails when large PIDs exceed 5 figures. description:**Description**On a system that supports greater than 5 figures, `docker top` on the container will fail due to what appears to be a parsing failure of the returned values:```docker run -it --rm --name health health``````$ docker top healthError response from daemon: Unexpected pid '103005root': strconv.Atoi: parsing ""103005root"": invalid syntax``````time=""2017-07-27T07:50:58.385629919-04:00"" level=error msg=""Handler for GET /v1.30/containers/health/top returned error: Unexpected pid '103005root': strconv.Atoi: parsing \""103005root\"": invalid syntax""```**Steps to reproduce the issue:**1. Check `pid_max` to see if your kernel supports a 6 figures number:    ```    $ cat /proc/sys/kernel/pid_max    131072    # if not, change it:    $ echo 131072 > /proc/sys/kernel/pid_max    ```2. Run enough processes to get to large PIDs; I'd expect some sort of `for` loop should do this pretty quickly3. Attempt to run `docker top`:Docker client output:    ```    $ docker top health    Error response from daemon: Unexpected pid '103005root': strconv.Atoi: parsing ""103005root"": invalid syntax    ```**Describe the results you received:**Did not give me top output**Describe the results you expected:**I should get `docker top` output**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```$ docker versionClient: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:15:15 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:51:55 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```$ docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 290Server Version: 17.06.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.33Operating System: Alpine Linux v3.6OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.94GiBName: alpineID: ANNE:4FUU:XCPW:GM7X:3OBN:E4KZ:VY63:ZB6H:NS3W:MAOI:54XZ:RBHLDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: mbentleyRegistry: https://index.docker.io/v1/Labels: foo=barExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**VMware Fusion VM
"
34270,0,1948,0,0,0,shin-,0,"title:Container that failed creation prevents creating new container with the same name. description:**Description**A seemingly non-existent (previously removed?) container prevents a new container from being created with the same name.```$ docker create --name composetest_db_1 busyboxError response from daemon: Conflict. The container name ""/composetest_db_1"" is already in use by container ""f7d0040ec93b85f749109e150d744e347984ea082d183a1c506aa6ccd4e70d00"". You have to remove (or rename) that container to be able to reuse that name.$ docker inspect f7d00[]Error: No such object: f7d00```**Steps to reproduce the issue:**1. (Run docker/compose test suite -- I do not know yet if it's a specific sequence of instructions that causes the issue to arise, but the test suite seems to exhibit it 100% of the time)2. Run `docker create --name composetest_db_1 busybox`**Describe the results you received:**An error occurs claiming the name is already in use by another container. When trying to inspect said container, the resource can not be found.**Describe the results you expected:**The container is created normally.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.07.0-ce-rc1 API version:  1.31 Go version:   go1.8.3 Git commit:   8c4be39 Built:        Wed Jul 26 03:46:39 2017 OS/Arch:      linux/amd64Server: Version:      17.07.0-ce-rc1 API version:  1.31 (minimum version 1.12) Go version:   go1.8.3 Git commit:   8c4be39 Built:        Wed Jul 26 03:45:32 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 383Server Version: 17.07.0-ce-rc1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 617 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 3addd840653146c90a254301d6c3a663c7fd6429runc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-87-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.499GiBName: yunaID: YZQG:AKYJ:JQXJ:CEHT:62DP:PMWA:S43W:5X47:SSOE:UXGG:XHWS:555FDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```Ubuntu 16.04 LTS Desktop
"
34265,1,0,0,0,0,Deepak-Vohra,0,"title:docker ps <service> lists tasks for all services starting with service name <service>. description:https://github.com/docker/for-aws/issues/77From docker/for-aws
"
34260,0,2762,28,0,0,justincormack,0,"title:symlinks not part of build context hash. description:create the following Dockerfile:```FROM alpine AS alpineRUN touch aRUN ln -s a /tmp/bRUN ln -s a /tmp/cFROM scratchCOPY --from=alpine /bin /binCOPY --from=alpine /lib /libCOPY --from=alpine /usr /usrCOPY --from=alpine /tmp /tmpRUN ls /tmp```build with `docker build .`then comment out one `ln`:```FROM alpine AS alpineRUN touch aRUN ln -s a /tmp/b#RUN ln -s a /tmp/cFROM scratchCOPY --from=alpine /bin /binCOPY --from=alpine /lib /libCOPY --from=alpine /usr /usrCOPY --from=alpine /tmp /tmpRUN ls /tmp```build again and notice the output is:```Step 1/9 : FROM alpine AS alpine ---> 665ffb03bfaeStep 2/9 : RUN touch a ---> Using cache ---> 0801a30708b5Step 3/9 : RUN ln -s a /tmp/b ---> Using cache ---> 1fa1bebaae04Step 4/9 : FROM scratch ---> Step 5/9 : COPY --from=alpine /bin /bin ---> Using cache ---> 524b53bbe62aStep 6/9 : COPY --from=alpine /lib /lib ---> Using cache ---> a2f12072d943Step 7/9 : COPY --from=alpine /usr /usr ---> Using cache ---> 5d09b665f011Step 8/9 : COPY --from=alpine /tmp /tmp ---> Using cache ---> aa9cb5d399d5Step 9/9 : RUN ls /tmp ---> Using cache ---> dcbc13560636Successfully built dcbc13560636```ie it all came from cache, and indeed both symlinks are in the output, when only one is correct (eg if built with `no-cache`)```Client: Version:      17.06.1-ce-rc1 API version:  1.30 Go version:   go1.8.3 Git commit:   77b4dce Built:        Fri Jul 14 07:38:15 2017 OS/Arch:      darwin/amd64Server: Version:      17.06.1-ce-rc1 API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   77b4dce Built:        Fri Jul 14 07:33:35 2017 OS/Arch:      linux/amd64 Experimental: true``````Containers: 155 Running: 0 Paused: 0 Stopped: 155Images: 989Server Version: 17.06.1-ce-rc1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 6e23458c129b551d5c9871e5174f6b1b7f6d1170runc version: 810190ceaa507aa2727d7ae6f4790c76ec150bd2init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.38-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952GiBName: mobyID: 62QR:HC6P:CL3A:X2OU:VT2R:D4OH:K7PC:W2TG:X6JP:OFZE:PJKA:F2D3Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 18 Goroutines: 30 System Time: 2017-07-26T14:25:31.789026387Z EventsListeners: 1No Proxy: *.local, 169.254/16Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```cc @tonistiigi 
"
34243,0,392,15,0,0,ergoithz,0,"title:Cannot ADD tgz from URL without decompression. description:Docker command **ADD** now extract archives retrieved from URLs (version version 17.06.0-ce, arch build 3dfb8343), and due COPY not supporting URLs, this should be considered a regression of issue #4391My workaround for envconsul.```ENV ENVCONSUL_VERSION 0.6.2ADD \  https://releases.hashicorp.com/envconsul/${ENVCONSUL_VERSION}/envconsul_${ENVCONSUL_VERSION}_linux_amd64.tgz \  /tmp/envconsul.tgzRUN set -x \    && if [ -f ""/tmp/envconsul.tgz/envconsul"" ]; then \        cp /tmp/envconsul.tgz/envconsul /usr/bin/envconsul; \    else \        tar -xf /tmp/envconsul.tgz -C /usr/bin envconsul; \    fi ```
"
34242,1,3175,5,0,0,zarnovican,0,"title:swarm: needless update with --resolve-image changed. description:**Description**Stack deploy with `--resolve-image changed` will update the service even if the image/tag has not changed.The first `docker stack deploy..` after tag change will update the service as expected. The next deploy will update the service again, even if the tag has not changed. Any subsequent deploy won't update the service (as expected).**Steps to reproduce the issue:**1. create stack config `test.yaml````version: ""3.3""services:    redis:        image: redis:3.2.8```2. deploy stack (first deploy)```docker stack deploy -c test.yaml --resolve-image changed test```3. deploy same config again (second deploy)```docker stack deploy -c test.yaml --resolve-image changed test```**Describe the results you received:**In step 3, service `redis` is re-deployed.```$ docker service ps test_redisID                  NAME                IMAGE               NODE                DESIRED STATE       CURRENT STATE             ERROR               PORTSs6f5clqoq9jv        test_redis.1        redis:3.2.8         ip-10-72-178-242    Running             Running 42 seconds agokg95b9zje4x2         \_ test_redis.1    redis:3.2.8         ip-10-72-178-242    Shutdown            Shutdown 45 seconds ago```**Describe the results you expected:**Service should not re-deploy, since the tag has not changed.**Additional information you deem important (e.g. issue happens only occasionally):**Presumably, it is because on first deploy (and any tag change), Docker will make a lookup to registry and store image id with sha256 hash. After the second deploy, you can observe that the current image is without the sha256, while the previous spec has it..```         ""Spec"": {            ""Name"": ""test_redis"",            ""TaskTemplate"": {                ""ContainerSpec"": {                    ""Image"": ""redis:3.2.8"",...        ""PreviousSpec"": {            ""Name"": ""test_redis"",            ""TaskTemplate"": {                ""ContainerSpec"": {                    ""Image"": ""redis:3.2.8@sha256:8eb0cd22644dc1218680db876411f45baac493ac9a0bfd391d6efdef0767ea6b"",```Subsequent deploy will not make that lookup and it will asume the image is `redis:3.2.8`. Which will not trigger any update.**Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:23:31 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:19:04 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 7 Running: 2 Paused: 0 Stopped: 5Images: 3Server Version: 17.06.0-ceStorage Driver: aufs Root Dir: /mnt/docker/aufs Backing Filesystem: extfs Dirs: 47 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: p13y70uqdo83gzma54cha3aua Is Manager: true ClusterID: km78r0i9lti4ihw7y4clj6pn9 Managers: 3 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Root Rotation In Progress: false Node Address: 10.73.190.96 Manager Addresses:  10.72.178.242:2377  10.73.190.96:2377  10.76.153.210:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-1020-awsOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 1.611GiBName: ip-10-73-190-96ID: PZGW:KBDE:X3UR:U43Z:R74J:LCGE:JYQZ:SEJ2:IYYU:U2GF:O5LW:PYNQDocker Root Dir: /mnt/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**AWS
"
34207,0,3053,0,0,0,georgyturevich,0,"title:Unexpected Docker Daemon shutdown due to ServeAPI error ""The pipe is being closed"" when docker stats was used. description:**Description**Docker Daemon stopped when I tried to use following command:```docker stats --no-stream --format 'table{{.BlockIO}}\t{{.Name}}' $(docker ps -qa)```**Steps to reproduce the issue:**1. Restart Docker daemon in debug mode```Stop-Service dockerdockerd -D > daemon.log 2>&1```2. Pull microsoft/iis image if you do not have it```docker pull microsoft/iis;```3. In first Powershell console fun script which starts 100 iis containers and then simulate some activity by restarting containers in an infinite loop```for ($i=0; $i -le 100; $i++) {`	$cname = ""test_iis$i""; `	docker stop $cname; `	docker rm $cname; `	$ExtPort = 10000 + $i;`	docker run -d --name $cname -p $ExtPort`:80 microsoft/iis ping -t localhost; `}`$K=0;`while($True) {` 	$K++;	$M=0;`	$Containers = $(docker ps --format ""{{.Names}}"");`	$Count = ($Containers).count;`	$Containers | foreach { `		$M++; `		$Start = Get-Date; echo ""$Start`: Restarting #$M/$K (of $Count) $_ ...""; `		docker restart $_; `		$Stop = Get-Date; echo ""$stop`: #$M (of $Count) $_ started in $(($Stop - $Start).TotalSeconds) s.""; `	}`}```4. In second Powershell console run another script which executes `docker stats` command in an infinite loop```$i=0;`while($True) {` 	$i++; echo ""$(date): #$i""; docker stats --no-stream --format 'table{{.BlockIO}}\t{{.Name}}' $(docker ps -qa);` }```5. After all 100 containers are started during next 10-20 minutes Docker Daemon will be stopped. Inside daemon.log I see following information:```time=""2017-07-20T19:25:47.500023900Z"" level=debug msg=""Calling GET /v1.27/containers/cc9d64ef144e/stats?stream=0"" ... (hundreds of stats requests)time=""2017-07-20T19:25:47.572026200Z"" level=debug msg=""Calling GET /v1.27/containers/2c8d33c286b1/stats?stream=0"" time=""2017-07-20T19:25:47.573027100Z"" level=debug msg=""Calling GET /v1.27/containers/e558e6949cec/stats?stream=0"" time=""2017-07-20T19:25:47.574026600Z"" level=error msg=""ServeAPI error: The pipe is being closed."" time=""2017-07-20T19:25:47.578027500Z"" level=debug msg=""start clean shutdown of all containers with a 15 seconds timeout..."" ...time=""2017-07-20T20:52:36.830675700Z"" level=error msg=""Force shutdown daemon"" dockerd : Shutting down due to ServeAPI error: The pipe is being closed.```Interesting thing that if I run container without exposing ports (`-p $ExtPort:80`) then I can not reproduce this issue quickly. So may be it is related somehow to HNS/networking.Initially this issue was caught on Docker Daemon `17.03.1-ee-3` and then reproduced by me with `17.06.0-ce`**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:30:30 2017 OS/Arch:      windows/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.24) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 22:19:00 2017 OS/Arch:      windows/amd64 Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 14Server Version: 17.06.0-ceStorage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd json-file logentries splunk syslogSwarm: inactiveDefault Isolation: processKernel Version: 10.0 14393 (14393.1358.amd64fre.rs1_release.170602-2252)Operating System: Windows Server 2016 DatacenterOSType: windowsArchitecture: x86_64CPUs: 4Total Memory: 16GiBName: EC2AMAZ-N2GM0M9ID: LH3O:5PAX:ATLN:NPF3:THQV:MUQ4:ZIPT:SAYQ:RV53:SG3B:QXGT:6C2IDocker Root Dir: E:\docker_storage_1_13Debug Mode (client): falseDebug Mode (server): true File Descriptors: -1 Goroutines: 20 System Time: 2017-07-20T20:39:05.3530276Z EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**It is AWS m4.xlarge instance (1 socket, 4 virtual CPUs, 16 Gib memory)
"
34181,0,1058,200,0,0,thaJeztah,0,"title:POST /volumes/create returns 500 if body is empty. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**The API returns a `500 Internal Server Error` if the body is empty when creating a volume.**Steps to reproduce the issue:**```bash$ curl --unix-socket /var/run/docker.sock -v -X POST http://localhost/volumes/create*   Trying /var/run/docker.sock...* Connected to localhost (/Users/sebastiaan/Library/Containers/com.dock) port 80 (#0)> POST /volumes/create HTTP/1.1> Host: localhost> User-Agent: curl/7.51.0> Accept: */*>< HTTP/1.1 500 Internal Server Error< Api-Version: 1.30< Content-Length: 18< Content-Type: application/json< Date: Wed, 19 Jul 2017 11:29:26 GMT< Docker-Experimental: true< Ostype: linux< Server: Docker/17.06.0-ce (linux)<{""message"":""EOF""}* Curl_http_done: called premature == 0* Connection #0 to host localhost left intact```**Describe the results you received:**The API returns a `500 Internal Server Error`**Describe the results you expected:**he API handles the error, and returns a 4xx error code (`400 Bad Request`)**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:31:53 2017 OS/Arch:      darwin/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:51:55 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**not relevant
"
34141,0,5271,25,0,1,kinghuang,0,"title:dockerd stopped responding to API requests; no installed keys could decrypt message. description:**Description**I have a 10 node Docker swarm running Docker CE 17.06.0. One of the controllers stopped responding to API commands, and all ten nodes started logging messages about ```memberlist: failed to receive: No installed keys could decrypt the message from=闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柛婵嗗閺嬫牗銇勯埡浣规嚃. The swarm was in a broken state until the node that stopped responding was restarted.**Steps to reproduce the issue:**Not sure how to reproduce the issue. This is on a 10-node Docker swarm that is heavily used for development.**Describe the results you received:**On the node that stopped responding, the daemon outputted log lines that it could not decrypt messages from the other 9 nodes.```Jul 16 10:02:56 itrmsdev02.ucalgary.ca dockerd[1142]: time=""2017-07-16T10:02:56.003807997-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.137:56134""Jul 16 10:02:56 itrmsdev02.ucalgary.ca dockerd[1142]: time=""2017-07-16T10:02:56.013832761-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.147:39506""Jul 16 10:02:56 itrmsdev02.ucalgary.ca dockerd[1142]: time=""2017-07-16T10:02:56.036012506-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.148:40842""Jul 16 10:02:56 itrmsdev02.ucalgary.ca dockerd[1142]: time=""2017-07-16T10:02:56.275404103-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.84:49264""Jul 16 10:02:56 itrmsdev02.ucalgary.ca dockerd[1142]: time=""2017-07-16T10:02:56.644752645-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.87:35600""Jul 16 10:02:56 itrmsdev02.ucalgary.ca dockerd[1142]: time=""2017-07-16T10:02:56.691320840-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.149:44430""Jul 16 10:02:56 itrmsdev02.ucalgary.ca dockerd[1142]: time=""2017-07-16T10:02:56.811744743-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.152:37456""```On the other 9 nodes, they all outputted log lines that they could not decrypt messages from the misbehaving node.```Jul 16 10:04:41 itrmsdev04.ucalgary.ca dockerd[1105]: time=""2017-07-16T10:04:41.417179382-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.139:59514""Jul 16 10:04:45 itrmsdev04.ucalgary.ca dockerd[1105]: time=""2017-07-16T10:04:45.417459159-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.139:59522""Jul 16 10:04:47 itrmsdev04.ucalgary.ca dockerd[1105]: time=""2017-07-16T10:04:47.417319707-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.139:59526""Jul 16 10:04:48 itrmsdev04.ucalgary.ca dockerd[1105]: time=""2017-07-16T10:04:48.417226763-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.139:59528""Jul 16 10:05:16 itrmsdev04.ucalgary.ca dockerd[1105]: time=""2017-07-16T10:05:16.417069436-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.139:59586""Jul 16 10:05:18 itrmsdev04.ucalgary.ca dockerd[1105]: time=""2017-07-16T10:05:18.417402441-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.139:59590""Jul 16 10:05:35 itrmsdev04.ucalgary.ca dockerd[1105]: time=""2017-07-16T10:05:35.417190950-06:00"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=10.41.149.139:59624""```Docker would not respond to any API calls on the failed node. I sent a `SIGUSR` signal to get a stack dump, and restarted dockerd. I'm not sure how to interpret the dump. It's attached as a zip file because the attachment size limit is 10 MB.[goroutine-stacks-2017-07-17T094958-0600.log.zip](https://github.com/moby/moby/files/1153270/goroutine-stacks-2017-07-17T094958-0600.log.zip)**Describe the results you expected:**The swarm should operate normally.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**This output is from the failed node after it was restarted.```-bash-4.2$ docker versionClient: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:20:36 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:21:56 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```-bash-4.2$ docker infoContainers: 63 Running: 12 Paused: 0 Stopped: 51Images: 488Server Version: 17.06.0-ceStorage Driver: overlay Backing Filesystem: xfs Supports d_type: trueLogging Driver: gelfCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: nj1kr88iu2ai9947u8neoskdw Is Manager: true ClusterID: m0gz05zqgmhx67noqdvko2npr Managers: 3 Nodes: 10 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Root Rotation In Progress: false Node Address: 10.41.149.139 Manager Addresses:  10.41.149.137:2377  10.41.149.138:2377  10.41.149.139:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.21.1.el7.x86_64Operating System: Red Hat Enterprise Linux Server 7.3 (Maipo)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.51GiBName: itrmsdev02.ucalgary.caID: VPME:AFML:SQU3:5WR5:UPXE:B5YZ:BBFP:JAEU:A5R4:UYGT:IFO5:AEKFDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**All 10 nodes are on VMs running RHEL 7.3.docker/swarmkit#1954 introduced a fix to avoid encryption key rotation on leader change, incorporated into 1.13.x. I don't know if that's the situation I ran into. This is the first time I've ever had a problem about decryption messages in any of my swarms.
"
34131,0,1232,20,0,0,wenjianhn,0,"title:./contrib/download-frozen-image-v2.sh failed to parse http redirect . description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->```# make BIND_DIR=. shell...parse error: Invalid numeric literal at line 1, column 3The command '/bin/sh -c ./contrib/download-frozen-image-v2.sh /docker-frozen-images     buildpack-deps:jessie@sha256:85b379ec16065e4fe4127eb1c5fb1bcc03c559bd36dbb2e22ff496de55925fa6   busybox:latest@sha256:32f093055929dbc23dec4d03e09dfe971f5973a9ca5cf059cbfb644c206aa83f      debian:jessie@sha256:72f784399fd2719b4cb4e16ef8e369a39dc67f53d978cd3e2e7bf4e502c7b793   hello-world:latest@sha256:c5515758d4c5e1e838e9cd307f6c6a0d620b5e07e6f927b07d05f6d12a1ac8d7' returned a non-zero code: 4make: *** [build] Error 4```**Steps to reproduce the issue:**1. Setup a https proxy to build docker dev env2. make BIND_DIR=. shell**Describe the results you received:**```parse error: Invalid numeric literal at line 1, column 3The command '/bin/sh -c ./contrib/download-frozen-image-v2.sh /docker-frozen-images     buildpack-deps:jessie@sha256:85b379ec16065e4fe4127eb1c5fb1bcc03c559bd36dbb2e22ff496de55925fa6   busybox:latest@sha256:32f093055929dbc23dec4d03e09dfe971f5973a9ca5cf059cbfb644c206aa83f      debian:jessie@sha256:72f784399fd2719b4cb4e16ef8e369a39dc67f53d978cd3e2e7bf4e502c7b793   hello-world:latest@sha256:c5515758d4c5e1e838e9cd307f6c6a0d620b5e07e6f927b07d05f6d12a1ac8d7' returned a non-zero code: 4make: *** [build] Error 4```**Describe the results you expected:**The script returns a zero code.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```(paste your output here)```**Output of `docker info`:**```(paste your output here)```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
34092,0,6124,17,0,0,vrevelas,0,"title:Difference in image extraction between Docker CE 17.05 and 17.06. description:**Description**Image extraction between Docker CE 17.05 and 17.06 results in different root filesystems. I am able to reproduce the issue with both aufs and overlay2 storage drivers.I ran into this issue with an image from a private repository. If the information that follows isn't enough to identify the issue, please let me know and I will attempt to create a public image that reproduces the behaviour described.**Steps to reproduce the issue:**Using Docker 17.06 CE1. `docker-machine create --virtualbox-boot2docker-url ""https://github.com/boot2docker/boot2docker/releases/download/v17.06.0-ce/boot2docker.iso"" -d virtualbox --engine-insecure-registry internal_repo 1706ce`2. `eval $(docker-machine env 1706ce)`3. `docker run --rm -ti internal_repo/image ls /`**Describe the results you received:**```#0001-gyp-always-install-into-PRODUCT_DIR.patch0002-gyp-apply-https-codereview.chromium.org-11361103.patch0003-gyp-don-t-use-links-at-all-just-copy-the-files-inste.patch2015-01-30.md@@iteratorAUTHORSAUTHORS.mdBufferList.jsCHANGELOG.mdCHANGESCHANGES.mdCONTRIBUTING.mdCOPYING.txtCodecMalformedException.java<~1000 output lines truncated>```**Describe the results you expected:**Using Docker 17.05 CE1. `docker-machine create --virtualbox-boot2docker-url ""https://github.com/boot2docker/boot2docker/releases/download/v17.05.0-ce/boot2docker.iso"" -d virtualbox --engine-insecure-registry internal_repo 1705ce`2. `eval $(docker-machine env 1705ce)`3. `docker run --rm -ti internal_repo/image ls /`result:```INFORMIXTMP  artifacts	bin  boot  database  dev  etc  home  lib  lib64  media	mnt  nohup.out	nonexistent  opt  proc	root  run  sbin  selinux  shared  srv  sys  tmp  usr  var```**Additional information**The filesystem in the 17.06 case is not completely flattened. It does contain the directories shown in the 17.05 output, and they do contain files.An excerpt follows showing the result of comparing file checksums/locations between the 17.06 and 17.05 cases:```< 00564742e3c70905fdb4d3318b01c827  /node_modules/es5-ext/.lint---> 00564742e3c70905fdb4d3318b01c827  /usr/lib/node_modules/npm/node_modules/node-gyp/node_modules/path-array/node_modules/array-index/node_modules/es6-symbol/node_modules/es5-ext/.lint145a146,147> 00564742e3c70905fdb4d3318b01c827  /usr/local/lib/node_modules/npm/node_modules/node-gyp/node_modules/path-array/node_modules/array-index/node_modules/es6-symbol/node_modules/es5-ext/.lint> 00564742e3c70905fdb4d3318b01c827  /usr/local/n/versions/node/7.0.0/lib/node_modules/npm/node_modules/node-gyp/node_modules/path-array/node_modules/array-index/node_modules/es6-symbol/node_modules/es5-ext/.lint322a325,327> 00ac2be339a766e2df37641d0350c63e  /usr/lib/node_modules/npm/node_modules/read-package-json/node_modules/glob/node_modules/path-is-absolute/package.json> 00ac2be339a766e2df37641d0350c63e  /usr/local/lib/node_modules/npm/node_modules/read-package-json/node_modules/glob/node_modules/path-is-absolute/package.json> 00ac2be339a766e2df37641d0350c63e  /usr/local/n/versions/node/7.0.0/lib/node_modules/npm/node_modules/read-package-json/node_modules/glob/node_modules/path-is-absolute/package.json492a498,500> 01028d57163f4901221a7a457774e202  /usr/lib/node_modules/npm/node_modules/init-package-json/node_modules/glob/node_modules/path-is-absolute/package.json> 01028d57163f4901221a7a457774e202  /usr/local/lib/node_modules/npm/node_modules/init-package-json/node_modules/glob/node_modules/path-is-absolute/package.json> 01028d57163f4901221a7a457774e202  /usr/local/n/versions/node/7.0.0/lib/node_modules/npm/node_modules/init-package-json/node_modules/glob/node_modules/path-is-absolute/package.json493a502> 0103318a939e4c2198689f6f143e556d  /usr/lib/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/formats/x509.js495c504,505< 0103318a939e4c2198689f6f143e556d  /x509.js---```It can be seen that several files are missing.`/usr/lib/node_modules/npm/node_modules/node-gyp/node_modules/path-array/node_modules/array-index/node_modules/es6-symbol/node_modules/es5-ext/.lint` under 17.05 moved to `/node_modules/es5-ext/.lint` in 17.06 and `/usr/lib/node_modules/npm/node_modules/request/node_modules/http-signature/node_modules/sshpk/lib/formats/x509.js` in 17.05 moved to `/x509.js` in 17.06. File contents are unaffected.Here is the output of `docker inspect internal_repo/image` for the 17.05 case:```[    {        ""Id"": ""sha256:a126cdbff382390a94be039424f1db5f6022ecb4444f6c4ea78853cc774dee12"",        ""RepoTags"": [            ""internal_repo/image:latest""        ],        ""RepoDigests"": [            ""internal_repo/image@sha256:bc287cd9d506ede8ccd4d5c083ba71b60157b85af90188044860e2cffa5b996d""        ],        ""Parent"": """",        ""Comment"": """",        ""Created"": ""2017-07-05T11:06:34.148937884Z"",        ""Container"": ""d802f466bfefc17dce309a7ec63ea22929377e70f3105f03754d01f298aba457"",        ""ContainerConfig"": {            ""Hostname"": ""d802f466bfef"",            ""Domainname"": """",            ""User"": """",            ""AttachStdin"": true,            ""AttachStdout"": true,            ""AttachStderr"": true,            ""Tty"": true,            ""OpenStdin"": true,            ""StdinOnce"": true,            ""Env"": null,            ""Cmd"": [                ""/bin/bash""            ],            ""Image"": ""internal_repo/image"",            ""Volumes"": null,            ""WorkingDir"": """",            ""Entrypoint"": null,            ""OnBuild"": null,            ""Labels"": {}        },        ""DockerVersion"": ""17.05.0-ce"",        ""Author"": """",        ""Config"": {            ""Hostname"": """",            ""Domainname"": """",            ""User"": """",            ""AttachStdin"": false,            ""AttachStdout"": false,            ""AttachStderr"": false,            ""Tty"": false,            ""OpenStdin"": false,            ""StdinOnce"": false,            ""Env"": null,            ""Cmd"": [                ""/bin/bash""            ],            ""Image"": """",            ""Volumes"": null,            ""WorkingDir"": """",            ""Entrypoint"": null,            ""OnBuild"": null,            ""Labels"": {}        },        ""Architecture"": ""amd64"",        ""Os"": ""linux"",        ""Size"": 3265786582,        ""VirtualSize"": 3265786582,        ""GraphDriver"": {            ""Data"": null,            ""Name"": ""aufs""        },        ""RootFS"": {            ""Type"": ""layers"",            ""Layers"": [                ""sha256:3cb5cef9e16b6c2fc4c25591b64c3a37ee728e41a9dbb02be96e94ee0784536d"",                ""sha256:cf19831f7cead5e80c994c75812f26e8010ad4d422b1693b73cd2b06e8890913"",                ""sha256:092bf598ac10f3529cb9225e560c903aaae3ed524e9e793c74b5c1ea71cf26de""            ]        }    }]```The only difference in the output for 17.06 is```<         ""Size"": 3265786582,<         ""VirtualSize"": 3265786582,--->         ""Size"": 3258003733,>         ""VirtualSize"": 3258003733,```I have confirmed that in both the 17.05 and 17.06 cases that the `/var/lib/docker/tmp/GetImageBlob*` files created have identical sha256sums, which means the same layers are being pulled from the repo in both cases.`/var/log/docker.log` does not show any usual errors or output when extracting in either case. Output from the 17.06 case:```time=""2017-07-13T09:19:18.115570865Z"" level=debug msg=""Downloaded 515ece5796b4 to tempfile /mnt/sda1/var/lib/docker/tmp/GetImageBlob669060717"" time=""2017-07-13T09:19:19.312413910Z"" level=debug msg=""Downloaded c10ec98cceed to tempfile /mnt/sda1/var/lib/docker/tmp/GetImageBlob298385640"" time=""2017-07-13T09:21:35.851669441Z"" level=debug msg=""Downloaded a697c759d873 to tempfile /mnt/sda1/var/lib/docker/tmp/GetImageBlob421049798"" time=""2017-07-13T09:22:55.763161662Z"" level=debug msg=""Applied tar sha256:3cb5cef9e16b6c2fc4c25591b64c3a37ee728e41a9dbb02be96e94ee0784536d to b60e75153572e514ebc5fa9f6f4589a3306f42d5bd4b738edba74e5b538e6124, size: 3250951555"" time=""2017-07-13T09:22:55.841672470Z"" level=debug msg=""Applied tar sha256:cf19831f7cead5e80c994c75812f26e8010ad4d422b1693b73cd2b06e8890913 to c6fb8d7b5c89bfb515dbc6f7ad1e3fc189319c2fb4e4255370883b186e7af36e, size: 807"" time=""2017-07-13T09:22:55.978860870Z"" level=debug msg=""Applied tar sha256:092bf598ac10f3529cb9225e560c903aaae3ed524e9e793c74b5c1ea71cf26de to efb16627adf62001b66723902dcc85b58fc4972ff314120ab18185b187c08e45, size: 7051371"" ```When reproducing the issue with overlay2, I can confirm that the `/diff` directory of the `a697c759d873` layer in `/var/lib/docker` contains the incorrectly extracted file paths before starting any containers.
"
34073,1,2408,96,0,0,sandersaares,0,"title:""docker stats"" on Linux uses process virtual memory size instead of reporting actually used memory. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**On Ubuntu Server 16.04, `docker stats` reports how much virtual memory a process is using, which is misleading if you are using managed runtimes like .NET/Java that allocate large chunks of virtual memory without actually using it.Detailed explanation: https://stackoverflow.com/questions/561245/virtual-memory-usage-from-java-under-linux-too-much-memory-used/561450#561450**Steps to reproduce the issue:**1. Run a container that executes an app using a managed runtime that performs its own memory management (e.g. `java -Xms1024m -Xmx4096m com.example.Hello` example from the above Stack Overflow post)2. `docker stats`**Describe the results you received:**`docker stats` reports very high memory usage, when actually this is just allocated virtual address space and not actually used memory. **Describe the results you expected:**`docker stats` reports actually used memory. I am given to understand that the best equivalent for the Windows ""working set"" metric is the sum of SHR and RES on Linux. This is what I expect to see.**Additional information you deem important (e.g. issue happens only occasionally):**Here is a `pmap` of a Mono executable that allocates around 700 MB of virtual address space but only uses around 75 MB of memory. Docker reports 700 MB as the usage, instead of the expected 75 MB.https://gist.github.com/sandersaares/e022a24e61ec02eac6930773d81238beHere is `top` output:```top - 10:36:50 up 57 days, 23:23,  0 users,  load average: 0.03, 0.06, 0.08Tasks:   6 total,   1 running,   5 sleeping,   0 stopped,   0 zombie%Cpu(s):  1.6 us,  2.7 sy,  0.8 ni, 94.1 id,  0.6 wa,  0.0 hi,  0.3 si,  0.0 stKiB Mem :  3521728 total,   196196 free,   780852 used,  2544680 buff/cacheKiB Swap:        0 total,        0 free,        0 used.  2323020 avail Mem  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND    1 root      20   0    4508    560    484 S  0.0  0.0   0:00.01 sh    5 root      20   0   18036   1548   1328 S  0.0  0.0   0:00.00 Entrypoint.sh   20 root      20   0   18028   1540   1324 S  0.0  0.0   0:00.00 ExecuteApp.sh   21 root      20   0  681272  69160   5000 S  0.0  2.0 716:21.97 mono 3778 root      20   0   18240   3228   2756 S  0.0  0.1   0:00.03 bash 3786 root      20   0   36768   3224   2616 R  0.0  0.1   0:00.00 top```**Output of `docker version`:**```Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:20:50 2017 OS/Arch:      linux/amd64Server: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:20:50 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 8 Running: 8 Paused: 0 Stopped: 0Images: 9Server Version: 17.05.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 71 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-75-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 3.359GiBName: host-linux-02ID: 5ZBQ:GJWC:PWH6:W7MM:O3B3:JONJ:DFQ2:OYC4:VEQW:67AC:RQWE:3IETDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Azure VM.
"
33975,1,4013,0,0,0,anydoby,0,"title:Running any container causes [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x457888]. description:**Description**I am on a virtual machine with RedHat Enterprise 7.3 installed. After docker installation everything worked fine until a certain moment when the following started to happen.Running any container will fail with the following stack trace:```docker run hello-worldpanic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x457888]goroutine 1 [running]:github.com/docker/cli/cli/command/container.runContainer(0xc4201db9e0, 0xc4203c4120, 0xc420399900, 0xc42043a180, 0x1583760, 0xc4200f40e0)	/go/src/github.com/docker/cli/cli/command/container/run.go:171 +0xa62github.com/docker/cli/cli/command/container.runRun(0xc4201db9e0, 0xc4200894d0, 0xc4203c4120, 0xc420399900, 0x0, 0x0)	/go/src/github.com/docker/cli/cli/command/container/run.go:94 +0x141github.com/docker/cli/cli/command/container.NewRunCommand.func1(0xc4203b5d40, 0xc420426410, 0x1, 0x1, 0x0, 0x0)	/go/src/github.com/docker/cli/cli/command/container/run.go:48 +0x109github.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).execute(0xc4203b5d40, 0xc4200101d0, 0x1, 0x1, 0xc4203b5d40, 0xc4200101d0)	/go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:646 +0x44egithub.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc420368480, 0xc420368900, 0xc42033fff0, 0xc42000e4b8)	/go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:742 +0x349github.com/docker/cli/vendor/github.com/spf13/cobra.(*Command).Execute(0xc420368480, 0xc420368480, 0x1585760)	/go/src/github.com/docker/cli/vendor/github.com/spf13/cobra/command.go:695 +0x2bmain.main()	/go/src/github.com/docker/cli/cmd/docker/docker.go:168 +0xc3```**Steps to reproduce the issue:**1. docker run &lt;anything&gt;Building containers works though**Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:20:36 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:21:56 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 12 Running: 0 Paused: 0 Stopped: 12Images: 84Server Version: 17.06.0-ceStorage Driver: devicemapper Pool Name: docker-253:6-583008320-pool Pool Blocksize: 65.54kB Base Device Size: 10.74GB Backing Filesystem: xfs Data file: /dev/loop0 Metadata file: /dev/loop1 Data Space Used: 9.666GB Data Space Total: 107.4GB Data Space Available: 97.71GB Metadata Space Used: 10.76MB Metadata Space Total: 2.147GB Metadata Space Available: 2.137GB Thin Pool Minimum Free Space: 10.74GB Udev Sync Supported: true Deferred Removal Enabled: false Deferred Deletion Enabled: false Deferred Deleted Device Count: 0 Data loop file: /var/lib/docker/devicemapper/devicemapper/data Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata Library Version: 1.02.135-RHEL7 (2016-11-16)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.16.1.el7.x86_64Operating System: Red Hat Enterprise Linux Server 7.3 (Maipo)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.51GiBName: devID: 6YKT:JELN:YKSV:EK3Q:KB4V:S2X4:B2SO:4EF2:YXBG:M4N5:RZEK:2R57Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseHttp Proxy: localhost:3128No Proxy: localhost,127.0.0.1,*.ing.netRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: devicemapper: usage of loopback devices is strongly discouraged for production use.         Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.WARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**The docker service runs in the private cloud (vRealize).
"
33974,0,3358,247,0,0,AkihiroSuda,0,"title:This multistage Dockerfile almost always results in `layer does not exist` error. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**The following Dockerfile almost always results in `layer does not exist` error:```dockerfileFROM golang:1.8-alpine AS go-build-baseENV PATH=/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binENV GOPATH=/goRUN apk add --no-cache g++ linux-headersRUN apk add --no-cache git makeFROM alpine:latest AS runc-gitRUN apk add --no-cache gitRUN git clone https://github.com/opencontainers/runc.git /go/src/github.com/opencontainers/runcWORKDIR /go/src/github.com/opencontainers/runcRUN git checkout -q v1.0.0-rc3FROM go-build-base AS runcCOPY --from=runc-git /go /goWORKDIR /go/src/github.com/opencontainers/runcRUN go build -o /usr/bin/runc ./FROM alpine:latest AS buildkit-gitRUN apk add --no-cache gitRUN git clone https://github.com/moby/buildkit.git /go/src/github.com/moby/buildkitWORKDIR /go/src/github.com/moby/buildkit# Jul 5, 2017RUN git checkout -q 8e2267320e0fb2b6ae3d22b3d999f6377b7b8758FROM go-build-base AS buildkit-srcCOPY --from=buildkit-git /go /goWORKDIR /go/src/github.com/moby/buildkitFROM buildkit-src AS buildd-standaloneRUN go build -o /bin/buildd-standalone -tags standalone ./cmd/builddFROM buildkit-src AS buildctlRUN go build -o /bin/buildctl ./cmd/buildctlFROM alpine:latestCOPY --from=buildctl /bin/buildctl /binCOPY --from=runc /usr/bin/runc /binCOPY --from=buildd-standalone /bin/buildd-standalone /binRUN ls -l /bin```**Steps to reproduce the issue:**1.  (Optional step for ensuring clean environment)Stop the daemon, do `rm -rf /var/lib/docker`, and start the daemon2. Do `docker build --no-cache .`**Describe the results you received:**```...Step 20/31 : FROM go-build-base AS buildkit-src ---> f234db884287                                        Step 21/31 : COPY --from=buildkit-git /go /go  failed to export image: failed to create image: failed to get layer sha256:102ac1be15dcaef8e5bdade6e75c71b6ec76a67eb9555987aaa5460dd2b7d3b2:layer does not exist```**Describe the results you expected:**No error**Additional information you deem important (e.g. issue happens only occasionally):**- When it fails, it seems always failing at `Step 21/31 : COPY --from=buildkit-git /go /go`- Happens on both overlay2 and aufs. So should not be related to graph driver.- `docker build .` sometimes succeeds but never seen successful `docker build --no-cache`.**Output of `docker version`:**```Client: Version:      unknown-version API version:  1.31 Go version:   go1.8 Git commit:   e672589e Built:        Thu Jul  6 06:23:30 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-dev API version:  1.31 (minimum version 1.12) Go version:   go1.8.3 Git commit:   9d95740db Built:        Thu Jul  6 05:14:08 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 1 Running: 0 Paused: 0 Stopped: 1Images: 35Server Version: 17.06.0-devStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 3addd840653146c90a254301d6c3a663c7fd6429runc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.10.0-26-genericOperating System: Ubuntu 17.04OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 29.45GiBName: ws01ID: SN3T:CNK6:JKQD:54CY:XKF2:BRX3:CIRU:DQBT:6DVZ:VWQ2:Q5ET:F23LDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 26 Goroutines: 43 System Time: 2017-07-06T06:52:16.093390156Z EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**cc @tonistiigi 
"
33958,0,2312,30,0,0,zigmund,0,"title:failed to register layer: Error processing tar file(exit status 1): chtimes /rc/lib: no such file or directory. description:**Description**On docker 17.06 cannot pull some images:```failed to register layer: Error processing tar file(exit status 1): chtimes /rc/lib: no such file or directory```**Steps to reproduce the issue:**1. Upgrade docker to 17.06 or fresh install2. docker pull zigmund/pub:r8**Describe the results you received:**```zigmund@docker-host:~$  docker pull zigmund/pub:r8r8: Pulling from zigmund/pub6f821164d5b7: Pull complete e8580501e1fa: Pull complete 90c325f7fe6a: Pull complete 2f4daf9f9ce2: Pull complete 4adbfe2315cf: Extracting [==================================================>]  124.3MB/124.3MB6bf8f972dbfc: Download complete 4f4fc94abdfa: Download complete 495fc8389d76: Download complete 473b636bf8bc: Download complete f53fa98eccc2: Download complete fab3c5f07ffc: Download complete 356a7a6a20cf: Download complete failed to register layer: Error processing tar file(exit status 1): chtimes /rc/lib: no such file or directory```**Describe the results you expected:**Normally pulled image.**Additional information you deem important (e.g. issue happens only occasionally):**Tried aufs and ovelay2 storage drivers - same result.Image built on docker 17.05. Only some images cannot be pulled. All that problem images can be pulled normally on docker 17.03 - 17.05.I pushed example to zigmund/pub:r8 for testing.As temporary solution - rebuild problem image.**Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:23:31 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:19:04 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 1Server Version: 17.06.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: gelfCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-83-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.796GiBName: docker-w5ID: SGAF:WNLR:GEHQ:3KAF:Q36I:SEV2:KQWC:BVHC:GPCX:LTRN:VQ5F:MIJFDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Ubuntu 16.04.2 LTS 4.4.0-83-generic. Virtual machine on Proxmox 4.4.
"
33948,1,1959,300,0,0,cblecker,0,"title:Docker hangs indefinitely when issuing a docker wait for non-existent container. description:**Description**After updating to Docker 17.06.0-ce, there is a functionality change in the `docker wait` command compared to 17.05, when issued against a container name that doesn't exist. I can't seem to find any documentation on this change, and am unsure if it's a bug (it appears to be).**Steps to reproduce the issue:**1. Upgrade to Docker 17.06.0-ce2. Issue `docker wait` for a container that doesn't exist3. Docker will hang.**Describe the results you received:**In 17.06, if you issue a `docker wait` for a container name that doesn't exist, the docker command will hang indefinitely.**Describe the results you expected:**In 17.05, if you issue a `docker wait` for a container name that doesn't exist, you get a non-zero exit with the following error:```$ docker wait kube-rsync-5095346036-5-v1.8.3-2Error response from daemon: No such container: kube-rsync-5095346036-5-v1.8.3-2```Similarly, if you issue a `docker kill` in either 17.06 or 17.05, you get a similar error (what I expect to be desired functionality):```docker kill kube-rsync-5095346036-5-v1.8.3-2Error response from daemon: Cannot kill container kube-rsync-5095346036-5-v1.8.3-2: No such container: kube-rsync-5095346036-5-v1.8.3-2```**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:31:53 2017 OS/Arch:      darwin/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:51:55 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 17.06.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.31-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952GiBName: mobyID: ZV2V:GX2D:5RZF:47YT:NFFB:TPFP:6KBC:QFF3:QJSN:EUAK:PKOP:3NVPDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 17 Goroutines: 28 System Time: 2017-07-04T20:07:55.056942415Z EventsListeners: 1No Proxy: *.local, 169.254/16Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
33946,0,1956,1,0,0,danielpanteleit,0,"title:docker build fails with multi-stage and --pull. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. Dockerfile```FROM alpine as stage1RUN echo ""hello"" > somefileFROM alpine          COPY --from=stage1 /somefile /CMD cat /somefile```2. docker build --pull .**Describe the results you received:**```Step 4/5 : COPY --from=stage1 /somefile /invalid from flag value stage1: repository sha256 not found: does not exist or no pull access```**Describe the results you expected:**The same result as without using `--pull`**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:31:53 2017 OS/Arch:      darwin/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:51:55 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 4 Running: 0 Paused: 0 Stopped: 4Images: 267Server Version: 17.06.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 234 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.31-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.952GiBName: mobyID: AKCO:4QMB:PGMG:SMFB:VWG5:MOED:VKB6:L2U6:EOJ4:E5C6:W6JN:4ENEDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 18 Goroutines: 30 System Time: 2017-07-04T14:43:52.523003135Z EventsListeners: 1Http Proxy: ...Https Proxy: ...No Proxy: ...Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
33945,0,2390,0,0,1,riaan53,0,"title:Docker stack recreating service randomly if more than one secret is specified. description:**Description**When specifying more than one secret for a service in the compose file and using docker stack to update the service it randomly recreates the service. It looks like the same issue that was fixed for the environmental variables in https://github.com/moby/moby/pull/32364 but for secrets.**Steps to reproduce the issue:**1. Create some secretsecho ""This is a secret"" | docker secret create secret1 -echo ""This is a secret"" | docker secret create secret2 -echo ""This is a secret"" | docker secret create secret3 -2. Create compose file```ymlversion: '3.3'services:  redis:    image: redis:alpine    secrets:      - secret1      - secret2      - secret3secrets:  secret1:    external: true  secret2:    external: true  secret3:    external: true```3. Create stackdocker stack deploy --compose-file docker-compose.yml test4. Update stack a few times and note the create time with docker psdocker stack deploy --compose-file docker-compose.yml testdocker stack deploy --compose-file docker-compose.yml testdocker stack deploy --compose-file docker-compose.yml testdocker stack deploy --compose-file docker-compose.yml testdocker stack deploy --compose-file docker-compose.yml test**Describe the results you received:**Service is recreated randomly. Note that when changing the compose file to only one secret that service is never recreated.**Describe the results you expected:**Service is not recreated if nothing changed.**Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:31:53 2017 OS/Arch:      darwin/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:51:55 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 5 Running: 1 Paused: 0 Stopped: 4Images: 1Server Version: 17.06.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: 1s53liygwu73cgkkrwpb11pbw Is Manager: true ClusterID: v34ixvlpqlsji69gw41l5gmmr Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Root Rotation In Progress: false Node Address: 192.168.65.2 Manager Addresses:  192.168.65.2:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.31-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 9.744GiBName: mobyID: XCBJ:EEN2:NDQK:TZCC:FOZV:L35K:KCMF:3QWG:7IYF:VTIT:6LOE:3TPDDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 44 Goroutines: 169 System Time: 2017-07-04T12:45:52.082943373Z EventsListeners: 2No Proxy: *.local, 169.254/16Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```Docker for mac used in this example but also seen on Ubuntu 16.04 LTS.
"
33900,1,1513,300,0,0,ylavoie,0,"title:Docker stats refresh. description:**Description**Docker stats does great for monitoring images. The list shown is calculated upon starting the monitoring and doesn't add new running images or substract stopped ones.**Steps to reproduce the issue:**1. run docker stats2. kill or start a new image**Describe the results you received:**Observe that killed images date id replaced by '--' but new images aren't added to the list**Describe the results you expected:**Refreshed list with actual running images**Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:18:10 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:17:03 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 12 Running: 11 Paused: 0 Stopped: 1Images: 67Server Version: 17.06.0-ceStorage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.11.0-rc7Operating System: Ubuntu 17.04OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 7.608GiBName: nameserverID: 3THI:2BKX:JERV:VW27:LI2P:POKD:I5NE:4AOB:RPZE:EUXK:ISRZ:F52YDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**N/A
"
33865,0,3478,11,0,0,shkrid,0,"title:""docker service update"" - updates service unconditionally. description:**Description**`docker service update` - updates service all time**Steps to reproduce the issue:**1. docker service create \  --name=swarm_gui \  --publish=9080:8080/tcp \  --constraint=node.role==manager \  --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \  dockersamples/visualizer2. docker service update swarm_gui3. docker service inspect swarm_gui > /tmp/before4. docker service update --image dockersamples/visualizer swarm_gui5. docker service inspect swarm_gui > /tmp/after**Describe the results you received:**Service updates unconditionally**Describe the results you expected:**Service should not be updated if nothing was changed**Additional information you deem important (e.g. issue happens only occasionally):**Why additional platform block added?`{""Architecture"": ""amd64"", ""OS"": ""linux""}````$ diff -u /tmp/before /tmp/after--- /tmp/before	2017-06-28 23:34:21.000000000 +0300+++ /tmp/after	2017-06-28 23:35:44.000000000 +0300@@ -2,10 +2,10 @@     {         ""ID"": ""wwc52rcsjlk1egh9m45ayut9i"",         ""Version"": {-            ""Index"": 842990+            ""Index"": 843004         },         ""CreatedAt"": ""2017-06-28T20:32:37.969352027Z"",-        ""UpdatedAt"": ""2017-06-28T20:33:46.379054444Z"",+        ""UpdatedAt"": ""2017-06-28T20:35:23.023603498Z"",         ""Spec"": {             ""Name"": ""swarm_gui"",             ""Labels"": {},@@ -39,6 +39,10 @@                         {                             ""Architecture"": ""amd64"",                             ""OS"": ""linux""+                        },+                        {+                            ""Architecture"": ""amd64"",+                            ""OS"": ""linux""                         }                     ]                 },@@ -152,6 +156,12 @@                     ""Addr"": ""10.255.0.2/16""                 }             ]+        },+        ""UpdateStatus"": {+            ""State"": ""completed"",+            ""StartedAt"": ""2017-06-28T20:35:02.669335975Z"",+            ""CompletedAt"": ""2017-06-28T20:35:23.023577205Z"",+            ""Message"": ""update completed""         }     } ]```**Output of `docker version`:**```Client: Version:      17.06.0-ce API version:  1.30 Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:31:53 2017 OS/Arch:      darwin/amd64Server: Version:      17.06.0-ce API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   02c1d87 Built:        Fri Jun 23 21:51:55 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 38 Running: 3 Paused: 0 Stopped: 35Images: 130Server Version: 17.06.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 415 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: 86pxfphstvmoffw6q9mo98r8k Is Manager: true ClusterID: x36csyrrl8vay1zwrjfn9blm3 Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Root Rotation In Progress: false Node Address: 192.168.65.2 Manager Addresses:  172.17.0.1:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.31-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.952GiBName: mobyID: TUZX:CVMS:RV4M:QM5Y:QVXT:7ZY3:LP4I:4WV5:TEOW:2C4C:F3H5:XI2KDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 61 Goroutines: 205 System Time: 2017-06-28T20:25:38.558095597Z EventsListeners: 4No Proxy: *.local, 169.254/16Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Docker-for-mac
"
33844,0,2667,21,0,0,tyx,0,"title:Impossible to mount secrets with `userns-remap` enabled. description:Hello guys**Description**Impossible to mount secrets  if docker engine run with `userns-remap` option enabled.**Steps to reproduce the issue:**1.  Enable `--userns-remap=default` on your docker engine2. `echo ""shhht"" | docker secret create secret-data -`3. `docker service  create --name=""redis"" --secret source=secret-data,target=secret-data redis:alpine`Already tried to pass `gid` and `uid` with `dockeremap` values and/or `mode` to 0777 to the `--secret`option.**Describe the results you received:**We get this kind of message:```container_linux.go:262: starting container process caused ""process_linux.go:339: container init caused \""rootfs_linux.go:57: mounting \\\""/var/lib/docker/231072.231072/containers/8cd2fe24b473606465afec29a62fc853924590ac3d1c5e340a72b6ba75b6f318/secrets/da22jy6xkdrq3vcxnkjiemmyv\\\"" to rootfs \\\""/var/lib/docker/231072.231072/aufs/mnt/b8b7847927a318e3cdddd9c2f6b5febcf2fb9840b0e5baeb01ac7250d5d0e89a\\\"" at \\\""/var/lib/docker/231072.231072/aufs/mnt/b8b7847927a318e3cdddd9c2f6b5febcf2fb9840b0e5baeb01ac7250d5d0e89a/run/secrets/website_building_eventstore_password\\\"" caused \\\""operation not permitted\\\""\""""```**Describe the results you expected:**It should mount secret without problem**Output of `docker version`:**```Client: Version:      17.06.0-ce-rc5 API version:  1.30 Go version:   go1.8.3 Git commit:   b7e4173 Built:        Tue Jun 20 07:13:24 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-ce-rc5 API version:  1.30 (minimum version 1.12) Go version:   go1.8.3 Git commit:   b7e4173 Built:        Tue Jun 20 07:12:15 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 5 Running: 0 Paused: 0 Stopped: 5Images: 15Server Version: 17.06.0-ce-rc5Storage Driver: overlay Backing Filesystem: extfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: s0k8crl0u5mzzlby48ducritq Is Manager: true ClusterID: yn71r0umggqp1hfdaopewwqab Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Root Rotation In Progress: false Node Address: 192.168.99.1 Manager Addresses:  192.168.99.1:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: cfb82a876ecc11b5ca0977d1733adbe58599088arunc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4init version: 949e6faSecurity Options: apparmor seccomp  Profile: default usernsKernel Version: 4.4.0-79-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.673GiBName: ubuntyxID: PEWA:5Q5N:KJYJ:YRUD:MLBW:OR5U:AGFV:CTS4:PCNX:DLD4:AMLX:U45ODocker Root Dir: /var/lib/docker/165536.165536Debug Mode (client): falseDebug Mode (server): falseUsername: tyxouRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```Thanks you and let me know I can test anything to help
"
33834,0,2785,260,0,0,schmichael,0,"title:syslog driver combines stderr and stdout. description:**Description**stdout and stderr get logged to the syslog driver with the same facility and severity (aka ""priority"" in some places).**Steps to reproduce the issue:**On 1. `docker run -d --log-driver=""syslog"" python:2-alpine python -c 'import sys; sys.stderr.write(""STDERRTEST"")'; sleep 1; journalctl -o verbose MESSAGE=STDERRTEST`2. `docker run -d --log-driver=""syslog"" python:2-alpine python -c 'import sys; sys.stderr.write(""STDOUTTEST"")'; sleep 1; journalctl -o verbose MESSAGE=STDOUTTEST`**Describe the results you received:**From 1 above:```Mon 2017-06-26 17:42:49.997757 PDT [s=785ccf7f72a24397843e29771a71bbff;i=105db7;b=a1871f72dd5d467485c10eda4286842d;...    PRIORITY=6    SYSLOG_FACILITY=3    _UID=0    _GID=0    _SYSTEMD_SLICE=system.slice    _CAP_EFFECTIVE=3fffffffff    _TRANSPORT=syslog    _PID=2059    _COMM=dockerd    _EXE=/usr/bin/dockerd    _CMDLINE=/usr/bin/dockerd -H fd://    _SYSTEMD_CGROUP=/system.slice/docker.service    _SYSTEMD_UNIT=docker.service    _SYSTEMD_INVOCATION_ID=4693661fde2d43ee801d7257da35b2d6    SYSLOG_PID=2059    MESSAGE=STDERRTEST    SYSLOG_IDENTIFIER=3276ddd33e00    _SOURCE_REALTIME_TIMESTAMP=1498524169997757```From 2:```Mon 2017-06-26 17:44:12.243358 PDT [s=785ccf7f72a24397843e29771a71bbff;i=105e15;b=a1871f72dd5d467485c10eda4286842d;...    PRIORITY=6    SYSLOG_FACILITY=3    _UID=0    _GID=0    _SYSTEMD_SLICE=system.slice    _CAP_EFFECTIVE=3fffffffff    _TRANSPORT=syslog    _PID=2059    _COMM=dockerd    _EXE=/usr/bin/dockerd    _CMDLINE=/usr/bin/dockerd -H fd://    _SYSTEMD_CGROUP=/system.slice/docker.service    _SYSTEMD_UNIT=docker.service    _SYSTEMD_INVOCATION_ID=4693661fde2d43ee801d7257da35b2d6    SYSLOG_PID=2059    SYSLOG_IDENTIFIER=a76fdfc70efb    MESSAGE=STDOUTTEST    _SOURCE_REALTIME_TIMESTAMP=1498524252243358```**Describe the results you expected:**https://github.com/moby/moby/blob/master/daemon/logger/syslog/syslog.go#L134-L141Leads me to believe `stderr` will get the priority level `error (3)`, but as you can see in the journalctl output both log lines are logged with priority level `info (6)`.**Output of `docker version`:**```Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:10:54 2017 OS/Arch:      linux/amd64Server: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:10:54 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 31 Running: 1 Paused: 0 Stopped: 30Images: 10Server Version: 17.05.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 131 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.10.0-24-genericOperating System: Ubuntu 17.04OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.54GiBName: rustyID: TMAJ:N37E:S6QE:JALC:N5WB:GXEG:TNPV:CGZP:6JYI:TRYZ:OI3S:76Y2Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Ubuntu 17.05 with systemd 232.
"
33761,0,0,16,0,1,pradipd,0,"title:Ports can be leaked when using host publishing mode for a service. description:**Description**Ports can be leaked when using host publishing mode for a service.If the if condition on Line 72 (https://github.com/docker/swarmkit/blob/master/manager/scheduler/nodeinfo.go#L72)is true, then we exit removeTask without deleting the port from nodeInfo.usedHostPorts (Line 86).**Steps to reproduce the issue:** Note: I have only validated this repros on Windows.  I can try linux later.1. docker swarm init --advertise-addr <your ip>2. docker service create --name iis_1 --mode global --endpoint-mode dnsrr   --publish mode=host,target=80,published=80 iis-site3. docker service rm iis_14. docker service create --name iis_1 --mode global --endpoint-mode dnsrr   --publish mode=host,target=80,published=80 iis-site**Describe the results you received:**Service doesn't start.Docker inspect shows:host-mode port already in use on 1 node**Describe the results you expected:**Service is successfully started.**Additional information you deem important (e.g. issue happens only occasionally):**I have only tried this on windows.  Have not tried on linux.**Output of `docker version`:**I'm using latest (or close to latest) master.Server: Version:      17.06.0-dev API version:  1.31 (minimum version 1.24) Go version:   go1.8.3 Git commit:   630b9a45d-unsupported Built:        06/20/2017 19:08:59 OS/Arch:      windows/amd64 Experimental: false**Output of `docker info`:**Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 6Server Version: 17.06.0-devStorage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: l2bridge l2tunnel nat null overlay transparent Log: awslogs etwlogs fluentd json-file logentries splunk syslogSwarm: active NodeID: 8rzw06i66nplugide0gp8owrz Is Manager: true ClusterID: r9bwm4wavfs042lpurih8zwkj Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Root Rotation In Progress: false Node Address: 10.137.196.224 Manager Addresses:  10.137.196.224:2377Default Isolation: processKernel Version: 10.0 16221 (16221.1000.amd64fre.rs_onecore_stack_sdn_dev1.170612-1700)Operating System: Windows Server 2016 StandardOSType: windowsArchitecture: x86_64CPUs: 12Total Memory: 1.999GiBName: STSTAIR-EMJ7OREID: AGWX:R2YA:QQC6:TU2U:5DYI:TJHN:3CIT:DUXG:56CX:EU4S:E25J:CVFPDocker Root Dir: C:\ProgramData\dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: -1 Goroutines: 129 System Time: 2017-06-20T23:18:18.5057094-07:00 EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false**Additional environment details (AWS, VirtualBox, physical, etc.):**WindowsI have a potential fix at:https://github.com/pradipd/swarmkit/commit/4a3a8f03a7f21b95fa6760c31a13c71ec71ea63bI can submit a PR is you'd like.Thanks,Pradip
"
33753,0,265,0,0,0,sgreenmsft,0,"title:Workdir in a multi-stage build isn't relative to the source stage. description:In a multi-stage build, workdir is relative to the previous stage instead of the source stage.  For example, consider:```FROM microsoft/aspnetcore as baseWORKDIR /srcRUN pwd#output is /srcFROM base AS c1WORKDIR c1RUN pwd#output is /src/c1FROM base AS c2WORKDIR c2RUN pwd#output is /src/c1/c2FROM base AS c3WORKDIR /src/c3RUN pwd#output is /src/c3```I expected c2's output to be /src/c2, but it is instead /src/c1/c2.  This isn't a major issue (because one can simply specify the rooted path, as in c3), but I'm curious to know whether, firstly, this was an intentional design decision and, secondly, what, if any, other context passes between stages.
"
33731,0,748,298,0,1,runcom,0,"title:container: update real-time resources. description:CPU real-time period and runtime are actually sent as part of an updatecommand via the cli:https://github.com/docker/cli/blob/master/cli/command/container/update.go#L20-L21This patch makes update effective because, until now, those settingsweren't actually updated in a container.Tested in on a real-time kernel, this fixes the issue. Can't add a testthough as I don't think CI has rt kernels enabled.Reproducer on a rt kernel:```root@xxx ~]# docker run -p 9090:9090 -itd --cpu-rt-runtime=790000--ulimit rtprio=99 --cap-add=sys_nice mytest[root@xxx ~]# docker exec -it awesome_edison /bin/bash[root@451a1aa4fd46 /]# cat /sys/fs/cgroup/cpu/cpu.rt_runtime_us790000[root@xxx ~]# docker update --cpu-rt-runtime=810000 awesome_edisonawesome_edison[root@xxx ~]# docker exec -it awesome_edison /bin/bash[root@451a1aa4fd46 /]# cat /sys/fs/cgroup/cpu/cpu.rt_runtime_us790000[root@xxx ~]# echo 811000 >/sys/fs/cgroup/cpu/system.slice/docker-451a1aa4fd468f3b67783c23d00e70558183456c775119484319c3f17d49e409.scope/cpu.rt_runtime_us[root@xxx ~]# docker exec -it awesome_edison /bin/bash[root@451a1aa4fd46 /]# cat /sys/fs/cgroup/cpu/cpu.rt_runtime_us811000```Signed-off-by: Antonio Murdaca <runcom@redhat.com><!--Please make sure you've read and understood our contributing guidelines;https://github.com/docker/docker/blob/master/CONTRIBUTING.md** Make sure all your commits include a signature generated with `git commit -s` **For additional information on our contributing process, read our contributingguide https://docs.docker.com/opensource/code/If this is a bug fix, make sure your description includes ""fixes #xxxx"", or""closes #xxxx""Please provide the following information:-->**- What I did****- How I did it****- How to verify it****- Description for the changelog**<!--Write a short (one line) summary that describes the changes in thispull request for inclusion in the changelog:-->**- A picture of a cute animal (not mandatory but encouraged)**
"
33706,1,2006,0,0,0,RomanSaveljev,0,"title:'--compress', '-f -' and context do not play along. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Docker build fails.A command like this will fail:```docker build -t xxx -f - --compress . <Dockerfile```**Steps to reproduce the issue:**1. My `Dockerfile` has a single `FROM alpine` statement2. There is no other files in the context (`.`) folder3. Run `docker build --verbose -t xxx -f - --compress . <Dockerfile`**Describe the results you received:**```$ docker build -t xxx -f - --compress . <DockerfileSending build context to Docker daemon error during connect: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.29/build?buildargs=%7B%7D&cachefrom=%5B%5D&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=.dockerfile.894e5d7100166c80399a&labels=%7B%7D&memory=0&memswap=0&networkmode=default&rm=1&shmsize=0&t=xxx&target=&ulimits=null: unexpected EOF```**Describe the results you expected:**Successful build**Additional information you deem important (e.g. issue happens only occasionally):**Happens every time**Output of `docker version`:**```Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:10:54 2017 OS/Arch:      linux/amd64Server: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:10:54 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 1018 Running: 0 Paused: 0 Stopped: 1018Images: 8576Server Version: 17.05.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 5187 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-64-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 990.6MiBName: systest-tools-releases-botID: MJ4N:O2KV:ZZXR:FHNU:TY6U:D57G:OKMV:KB2O:QLU4:DGYZ:MVLF:T336Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Docker engine runs in AWS node
"
33686,0,3012,4,0,0,ecnerwala,0,"title:Docker build with git ssh URLs (git@) is broken by golang 1.8. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Docker build used to work with `git@github.com:user/repo.git`. This breaks with golang 1.8 because `url.Parse` no longer accepts urls like this (https://golang.org/doc/go1.8#net_url)Relevant code at:- https://github.com/moby/moby/blob/b28cbed66df6ad06afd2d91b3c67245459ec37ff/builder/remotecontext/git/gitutils.go#L29- https://github.com/moby/moby/blob/b248de7e332b6e67b08a8981f68060e6ae629ccf/pkg/urlutil/urlutil.go#L11**Steps to reproduce the issue:**```$ docker build git@github.com:docker/docker.git```**Describe the results you received:**```unable to prepare context: unable to 'git clone' to temporary context directory: parse git@github.com:docker/docker.git: first path segment in URL cannot contain colon```**Describe the results you expected:**This used to clone and build the repository.**Additional information you deem important (e.g. issue happens only occasionally):**Requires golang 1.8**Output of `docker version`:**```> $ docker version                                                                                                                                                                                                                                                              Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.8.1 Git commit:   89658bed64 Built:        Fri May  5 22:40:58 2017 OS/Arch:      linux/amd64Server: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.8.1 Git commit:   89658bed64 Built:        Fri May  5 22:40:58 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```> $ docker info                                                                                                                                                                                                                                                                 Containers: 4 Running: 0 Paused: 0 Stopped: 4Images: 587Server Version: 17.05.0-ceStorage Driver: devicemapper Pool Name: docker-254:3-2491281-pool Pool Blocksize: 65.54kB Base Device Size: 10.74GB Backing Filesystem: xfs Data file: /dev/loop0 Metadata file: /dev/loop1 Data Space Used: 7.808GB Data Space Total: 107.4GB Data Space Available: 87.62GB Metadata Space Used: 40.81MB Metadata Space Total: 2.147GB Metadata Space Available: 2.107GB Thin Pool Minimum Free Space: 10.74GB Udev Sync Supported: true Deferred Removal Enabled: false Deferred Deletion Enabled: false Deferred Deleted Device Count: 0 Data loop file: /var/lib/docker/devicemapper/devicemapper/data Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata Library Version: 1.02.140 (2017-05-03)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.11.3-1-ARCHOperating System: Arch LinuxOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.704GiBName: pandacowID: YPJM:6M3G:BOXR:FTIE:X74P:E7DY:FKOB:BUKK:SUNI:QWHR:NUG3:B2YCDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: devicemapper: usage of loopback devices is strongly discouraged for production use.         Use `--storage-opt dm.thinpooldev` to specify a custom block storage device.```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
33661,0,4085,2,0,1,xihan88,0,"title:Network alias not working under certain steps. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**After created an overlay network, container aliases won't take effect in the network.**Steps to reproduce the issue:**```bashdocker network create -d overlay --attachable testdocker create --network test --name ng1 nginxdocker network connect --alias aaa test ng1docker start ng1docker create --network test --name ng2 nginxdocker network connect --alias bbb test ng2docker start ng2```**Describe the results you received:**network aliases (bbb) is missing by docker inspect ng2 after docker start```...""Networks"": {                ""test"": {                    ""IPAMConfig"": {                        ""IPv4Address"": ""10.0.4.3""                    },                    ""Links"": null,                    ""Aliases"": [                        ""0c4a9869d89f""                    ],                    ""NetworkID"": ""kz9n6u9fqosjaui1ybc02nw5x"",                    ""EndpointID"": ""c14340bd0e65e40519200d1db12bb76064b0fa2983b76c5c0cfc6f0b7747032c"",                    ""Gateway"": """",                    ""IPAddress"": ""10.0.4.3"",                    ""IPPrefixLen"": 24,                    ""IPv6Gateway"": """",                    ""GlobalIPv6Address"": """",                    ""GlobalIPv6PrefixLen"": 0,                    ""MacAddress"": ""02:42:0a:00:04:03""                }            }```**Describe the results you expected:**```...""Networks"": {                ""test"": {                    ""IPAMConfig"": {                        ""IPv4Address"": ""10.0.4.3""                    },                    ""Links"": null,                    ""Aliases"": [                        ""bbb"",  <--------------------- should have this                        ""0c4a9869d89f""                    ],                    ""NetworkID"": ""kz9n6u9fqosjaui1ybc02nw5x"",                    ""EndpointID"": ""c14340bd0e65e40519200d1db12bb76064b0fa2983b76c5c0cfc6f0b7747032c"",                    ""Gateway"": """",                    ""IPAddress"": ""10.0.4.3"",                    ""IPPrefixLen"": 24,                    ""IPv6Gateway"": """",                    ""GlobalIPv6Address"": """",                    ""GlobalIPv6PrefixLen"": 0,                    ""MacAddress"": ""02:42:0a:00:04:03""                }            }```**Additional information you deem important (e.g. issue happens only occasionally):**The problem is that all aliases (bbb ccc ...) added by **docker create + network connect --alias + start** (ng2 ng3 ...) won't take effect after the first one (ng1 is ok).There are many hacky ways to skip this. By **docker create --network-alias + start** ng2 alias is fine. And by **docker create + network disconnect + network connect --alias + start** ng2 alias is ok as well. Also by **docker create --network default/bridge + network connect --alias + start** it has the proper network aliases in test network but will be added into an extra bridge network which is not good.Hope the information above can help other people who is facing this issue.Another observation is by:```docker network create -d overlay --attachable test2docker create --network **none** --name ng1 nginxdocker network connect --alias aaa test2 ng1docker start ng1docker create --network **none** --name ng2 nginxdocker network connect --alias bbb test2 ng2```only connecting ng2 will report error:**Error response from daemon: container cannot be connected to multiple networks with one of the networks in private (none) mode**I guess the first container attached into a network is kinda special. This is also why aliases of ng1 above is working.**Output of `docker version`:**```Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:06:06 2017 OS/Arch:      linux/amd64Server: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:06:06 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 18 Running: 16 Paused: 0 Stopped: 2Images: 343Server Version: 17.05.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 322 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: e7gvsxeruiusmkmro82gsx99h Is Manager: true ClusterID: 1hwq82z13p4oxxx45t2nn63ca Managers: 1 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.99.1 Manager Addresses:  192.168.99.1:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: apparmorKernel Version: 4.4.0-79-genericOperating System: Ubuntu 14.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 19.48GiBName: xihan-ThinkPad-T460sID: BLXA:HPCE:AUU4:L2UI:W77D:4ROF:KNBF:ET74:QYZB:V7BB:AEE2:KHSADocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseExperimental: falseLive Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
33617,0,3372,143,0,1,aaronlehmann,1,"title:""Failed to retrieve docker-runc version"" log message. description:Starting the daemon, with moby master (c9f26eaaf8b9f7977319d6d596f8701bbc58a108) built with `make shell` and `hack/make.sh binary`:```WARN[0064] failed to retrieve docker-runc version: unknown output format: NAME:   runc - Open Container Initiative runtimerunc is a command line client for running applications packaged according tothe Open Container Initiative (OCI) format and is a compliant implementation of theOpen Container Initiative specification.runc integrates well with existing process supervisors to provide a productioncontainer runtime environment for applications. It can be used with yourexisting process monitoring tools and the container will be spawned as adirect child of the process supervisor.Containers are configured using bundles. A bundle for a container is a directorythat includes a specification file named ""config.json"" and a root filesystem.The root filesystem contains the contents of the container.To start a new instance of a container:    # runc run [ -b bundle ] <container-id>Where ""<container-id>"" is your name for the instance of the container that youare starting. The name you provide for the container instance must be unique onyour host. Providing the bundle directory using ""-b"" is optional. The defaultvalue for ""bundle"" is the current directory.USAGE:   docker-runc [global options] command [command options] [arguments...]VERSION:   1.0.0-rc3commit: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4spec: 1.0.0-rc5COMMANDS:     checkpoint  checkpoint a running container     create      create a container     delete      delete any resources held by the container often used with detached container     events      display container events such as OOM notifications, cpu, memory, and IO usage statistics     exec        execute new process inside the container     init        initialize the namespaces and launch the process (do not call it outside of runc)     kill        kill sends the specified signal (default: SIGTERM) to the container's init process     list        lists containers started by runc with the given root     pause       pause suspends all processes inside the container     ps          ps displays the processes running inside a container     restore     restore a container from a previous checkpoint     resume      resumes all processes that have been previously paused     run         create and run a container     spec        create a new specification file     start       executes the user defined process in a created container     state       output the state of a container     update      update container resource constraints     help, h     Shows a list of commands or help for one commandGLOBAL OPTIONS:   --debug             enable debug output for logging   --log value         set the log file path where internal debug information is written (default: ""/dev/null"")   --log-format value  set the format used by logs ('text' (default), or 'json') (default: ""text"")   --root value        root directory for storage of container state (this should be located in tmpfs) (default: ""/run/runc"")   --criu value        path to the criu binary used for checkpoint and restore (default: ""criu"")   --systemd-cgroup    enable systemd cgroup support, expects cgroupsPath to be of form ""slice:prefix:name"" for e.g. ""system.slice:runc:434234""   --help, -h          show help   --version, -v       print the version```The message repeats periodically every 20 seconds.
"
33613,0,2105,197,0,0,pboers1988,0,"title:Due to [signal SIGSEGV: segmentation violation code] all management nodes crash in swarm mode.. description:**Description**On the latest version of docker 17.05.0-ce in swarm-mode whilst doing a rollback of a service all the management nodes in the cluster crash and are not able to restart.**Steps to reproduce the issue:**1.  docker service update name_of_service --rollback**Describe the results you received:**All management nodes crasht simultaneously and due to the fact that our cluster only consists of three nodes that are managers and workers at the same time the cluster failed catastrophically. **_After the failure it was not possible to restart the docker daemon, even after a node reboot. I had to downgrade to a previous version of docker_**All nodes had similar output in /var/log/messages:Jun  9 15:02:33 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:33.664637652+02:00"" level=info msg=""3f651b434df29b4e [logterm: 212, index: 16787] sent MsgVote request to 61e553486e30b5fe at term 249"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:33 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:33.671321226+02:00"" level=info msg=""3f651b434df29b4e received MsgVoteResp from 61e553486e30b5fe at term 249"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:33 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:33.671360284+02:00"" level=info msg=""3f651b434df29b4e [quorum:2] has received 2 MsgVoteResp votes and 0 vote rejections"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:33 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:33.671378703+02:00"" level=info msg=""3f651b434df29b4e became leader at term 249"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:33 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:33.671390382+02:00"" level=info msg=""raft.node: 3f651b434df29b4e elected leader 3f651b434df29b4e at term 249"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:33 swarm-03-auto-prd dockerd: panic: runtime error: invalid memory address or nil pointer dereference**Jun  9 15:02:33 swarm-03-auto-prd dockerd: [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x14ad40f]**Jun  9 15:02:33 swarm-03-auto-prd dockerd: goroutine 550 [running]:Jun  9 15:02:33 swarm-03-auto-prd dockerd: panic(0x1726860, 0xc42000c050)Jun  9 15:02:33 swarm-03-auto-prd dockerd: /usr/local/go/src/runtime/panic.go:500 +0x1a1Jun  9 15:02:33 swarm-03-auto-prd dockerd: github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator.IsTaskDirty(0xc4219f9200, 0xc420931680, 0xc4233a41a0)Jun  9 15:02:33 swarm-03-auto-prd dockerd: /root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/task.go:66 +0x3fJun  9 15:02:33 swarm-03-auto-prd dockerd: github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update.(*Updater).isTaskDirty(0xc422f31c20, 0xc420931680, 0xc4230acf80)Jun  9 15:02:33 swarm-03-auto-prd dockerd: /root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update/updater.go:524 +0x39Jun  9 15:02:33 swarm-03-auto-prd dockerd: github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update.(*Updater).isSlotDirty(0xc422f31c20, 0xc42314af00, 0x1, 0x1, 0xc4201c1e10)Jun  9 15:02:33 swarm-03-auto-prd dockerd: /root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update/updater.go:528 +0x5cJun  9 15:02:33 swarm-03-auto-prd dockerd: github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update.(*Updater).Run(0xc422f31c20, 0x7f4ccfa344a8, 0xc42093cc00, 0xc423488b80, 0x1, 0x1)Jun  9 15:02:33 swarm-03-auto-prd dockerd: /root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update/updater.go:139 +0x113Jun  9 15:02:33 swarm-03-auto-prd dockerd: github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update.(*Supervisor).Update.func1(0xc422f31c20, 0x7f4ccfa344a8, 0xc42093cc00, 0xc423488b80, 0x1, 0x1, 0xc4230ab040, 0xc422b54a60, 0x19)Jun  9 15:02:33 swarm-03-auto-prd dockerd: /root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update/updater.go:67 +0x64Jun  9 15:02:33 swarm-03-auto-prd dockerd: created by github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update.(*Supervisor).UpdateJun  9 15:02:33 swarm-03-auto-prd dockerd: /root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update/updater.go:73 +0x1fbJun  9 15:02:33 swarm-03-auto-prd systemd: docker.service: main process exited, code=exited, status=2/INVALIDARGUMENTJun  9 15:02:33 swarm-03-auto-prd systemd: Unit docker.service entered failed state.Jun  9 15:02:33 swarm-03-auto-prd systemd: docker.service failed.Jun  9 15:02:33 swarm-03-auto-prd systemd: docker.service holdoff time over, scheduling restart.Jun  9 15:02:33 swarm-03-auto-prd systemd: Starting Docker Application Container Engine...Jun  9 15:02:33 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:33.940276621+02:00"" level=info msg=""libcontainerd: new containerd process, pid: 30803""Jun  9 15:02:34 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:34.941569569+02:00"" level=warning msg=""failed to rename /var/lib/docker/tmp for background deletion: %!s(<nil>). Deleting synchronously""Jun  9 15:02:34 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:34.944407027+02:00"" level=info msg=""[graphdriver] using prior storage driver: overlay""Jun  9 15:02:34 swarm-03-auto-prd docker-volume-local-persist: Capabilities Called... Get Called...     Found portainerJun  9 15:02:34 swarm-03-auto-prd docker-volume-local-persist: Get Called...     Found portainer-certJun  9 15:02:34 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:34.956746792+02:00"" level=info msg=""Graph migration to content-addressability took 0.00 seconds""Jun  9 15:02:34 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:34.957287282+02:00"" level=info msg=""Loading containers: start.""Jun  9 15:02:35 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:35.080343364+02:00"" level=info msg=""Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address""Jun  9 15:02:35 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:35.124944396+02:00"" level=info msg=""Loading containers: done.""Jun  9 15:02:35 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:35.157148419+02:00"" level=info msg=""Listening for local connections"" addr=""/var/run/docker/swarm/control.sock"" module=node node.id=fr737euehhjgy3zthfn18jqat proto=unixJun  9 15:02:35 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:35.157855367+02:00"" level=info msg=""Listening for connections"" addr=""145.145.64.119:2377"" module=node node.id=fr737euehhjgy3zthfn18jqat proto=tcpJun  9 15:02:35 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:35.310788586+02:00"" level=warning msg=""ignoring request to join cluster, because raft state already exists"" module=node node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:35 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:35.310858584+02:00"" level=info msg=""3f651b434df29b4e became follower at term 249"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:35 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:35.310875334+02:00"" level=info msg=""newRaft 3f651b434df29b4e [peers: [2914a2af982651d8,3f651b434df29b4e,61e553486e30b5fe], term: 249, commit: 16793, applied: 10000, lastindex: 16794, lastterm: 249]"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:38 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:38.941659728+02:00"" level=info msg=""3f651b434df29b4e [term: 249] received a MsgVote message with higher term from 61e553486e30b5fe [term: 251]"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:38 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:38.941754363+02:00"" level=info msg=""3f651b434df29b4e became follower at term 251"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:38 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:38.941776752+02:00"" level=info msg=""3f651b434df29b4e [logterm: 249, index: 16794, vote: 0] cast MsgVote for 61e553486e30b5fe [logterm: 249, index: 16794] at term 251"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:38 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:38.944272901+02:00"" level=info msg=""raft.node: 3f651b434df29b4e elected leader 61e553486e30b5fe at term 251"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:40 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:40.187210537+02:00"" level=error msg=""agent: session failed"" error=""session initiation timed out"" module=""node/agent"" node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:42 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:42.152122167+02:00"" level=info msg=""3f651b434df29b4e is starting a new election at term 251"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:42 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:42.152172620+02:00"" level=info msg=""3f651b434df29b4e became candidate at term 252"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:42 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:42.152186406+02:00"" level=info msg=""3f651b434df29b4e received MsgVoteResp from 3f651b434df29b4e at term 252"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:42 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:42.152198270+02:00"" level=info msg=""3f651b434df29b4e [logterm: 251, index: 16801] sent MsgVote request to 61e553486e30b5fe at term 252"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:42 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:42.152208395+02:00"" level=info msg=""3f651b434df29b4e [logterm: 251, index: 16801] sent MsgVote request to 2914a2af982651d8 at term 252"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:42 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:42.152218128+02:00"" level=info msg=""raft.node: 3f651b434df29b4e lost leader 61e553486e30b5fe at term 252"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:42 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:42.154724913+02:00"" level=info msg=""3f651b434df29b4e received MsgVoteResp from 61e553486e30b5fe at term 252"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:42 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:42.154765509+02:00"" level=info msg=""3f651b434df29b4e [quorum:2] has received 2 MsgVoteResp votes and 0 vote rejections"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:42 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:42.154782639+02:00"" level=info msg=""3f651b434df29b4e became leader at term 252"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:42 swarm-03-auto-prd dockerd: time=""2017-06-09T15:02:42.154793837+02:00"" level=info msg=""raft.node: 3f651b434df29b4e elected leader 3f651b434df29b4e at term 252"" module=raft node.id=fr737euehhjgy3zthfn18jqatJun  9 15:02:42 swarm-03-auto-prd dockerd: panic: runtime error: invalid memory address or nil pointer dereferenceJun  9 15:02:42 swarm-03-auto-prd dockerd: [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x14ad40f]Jun  9 15:02:42 swarm-03-auto-prd dockerd: goroutine 486 [running]:Jun  9 15:02:42 swarm-03-auto-prd dockerd: panic(0x1726860, 0xc42000c050)Jun  9 15:02:42 swarm-03-auto-prd dockerd: /usr/local/go/src/runtime/panic.go:500 +0x1a1Jun  9 15:02:42 swarm-03-auto-prd dockerd: github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator.IsTaskDirty(0xc420e225a0, 0xc422683680, 0xc422c40ff0)Jun  9 15:02:42 swarm-03-auto-prd dockerd: /root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/task.go:66 +0x3fJun  9 15:02:42 swarm-03-auto-prd dockerd: github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update.(*Updater).isTaskDirty(0xc42341b8b0, 0xc422683680, 0x41ee68)Jun  9 15:02:42 swarm-03-auto-prd dockerd: /root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update/updater.go:524 +0x39Jun  9 15:02:42 swarm-03-auto-prd dockerd: github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update.(*Updater).isSlotDirty(0xc42341b8b0, 0xc422c41160, 0x1, 0x1, 0x1)Jun  9 15:02:42 swarm-03-auto-prd dockerd: /root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update/updater.go:528 +0x5cJun  9 15:02:42 swarm-03-auto-prd dockerd: github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update.(*Updater).Run(0xc42341b8b0, 0x7f4ddd9c47e8, 0xc42092c3c0, 0xc4233ff680, 0x1, 0x1)Jun  9 15:02:42 swarm-03-auto-prd dockerd: /root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update/updater.go:139 +0x113Jun  9 15:02:42 swarm-03-auto-prd dockerd: github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update.(*Supervisor).Update.func1(0xc42341b8b0, 0x7f4ddd9c47e8, 0xc42092c3c0, 0xc4233ff680, 0x1, 0x1, 0xc422fbdee0, 0xc422ec9b40, 0x19)Jun  9 15:02:42 swarm-03-auto-prd dockerd: /root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update/updater.go:67 +0x64Jun  9 15:02:42 swarm-03-auto-prd dockerd: created by github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update.(*Supervisor).UpdateJun  9 15:02:42 swarm-03-auto-prd dockerd: /root/rpmbuild/BUILD/docker-engine/.gopath/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/orchestrator/update/updater.go:73 +0x1fbJun  9 15:02:42 swarm-03-auto-prd systemd: docker.service: main process exited, code=exited, status=2/INVALIDARGUMENTJun  9 15:02:42 swarm-03-auto-prd systemd: Failed to start Docker Application Container Engine.Jun  9 15:02:42 swarm-03-auto-prd systemd: Unit docker.service entered failed state.Jun  9 15:02:42 swarm-03-auto-prd systemd: docker.service failed.Jun  9 15:02:42 swarm-03-auto-prd systemd: docker.service holdoff time over, scheduling restart.Jun  9 15:02:42 swarm-03-auto-prd systemd: Starting Docker Application Container Engine...**Describe the results you expected:**We expected a rollback of the service and not a catastrofic cluster failure :)**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```[pboers@swarm-01-auto-prd ~]$ docker versionClient: Version:      17.05.0-ce API version:  1.29 Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:06:25 2017 OS/Arch:      linux/amd64Server: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:06:25 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```docker infoContainers: 1 Running: 1 Paused: 0 Stopped: 0Images: 21Server Version: 17.05.0-ceStorage Driver: overlay Backing Filesystem: extfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local local-persist Network: bridge host macvlan null overlaySwarm: active NodeID: zxk9layvgfupm364jobja9tvz Is Manager: true ClusterID: j1mm2qe05mpaebiwly21in590 Managers: 3 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: XXXXXXX Manager Addresses:  1XXXXXX:2377  XXXXXXX:2377  XXXXXXX:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.21.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.695GiBName: swarm-02-auto-prd.XXXXXXXID: 7DBR:PNQ4:LC7D:WESA:2T4C:NZ5V:YYA2:XXXXXXXXXXXXXXXDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseHttp Proxy: http://1XXXXXXXXXXX:3128/Https Proxy: http://XXXXXXXXX:3128/No Proxy: localhost,127.0.0.1,localaddress,.localdomain.comRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
33603,0,3228,0,0,0,moypray,0,"title:devicemapper:  When docker service run a long time, could not restart docker service.. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**We use `devicemapper` as graph driver and run stable test as below:1.  create/delete containers continuously.2.  restart docker service randomly.After one night, the docker could not startup.The error is```messages:2017-06-07T10:41:43.932549+00:00 V2R1C00B052-GUESTOS-FS-KVM-X64 docker: time=""2017-06-07T10:41:43.747631527Z"" level=debug msg=""devmapper: Error device setupBaseImage: devmapper: Base Device UUID and Filesystem verification failed: devicemapper: Can't set cookie dm_task_set_cookie failed""messages:2017-06-07T10:41:43.932765+00:00 V2R1C00B052-GUESTOS-FS-KVM-X64 docker: time=""2017-06-07T10:41:43.747827726Z"" level=fatal msg=""Error starting daemon: error initializing graphdriver: devmapper: Base Device UUID and Filesystem verification failed: devicemapper: Can't set cookie dm_task_set_cookie failed""```And more, I tried to use `dmsetup remove ` to remove some device:```V2R1C00B052-GUESTOS-FS-KVM-X64:~ # dmsetup remove docker-8:2-402190-9623ed2972fa4f700eec99e1404959a5b7e64eac65d3ff541b22f6271c2ee38aLimit for the maximum number of semaphores reached. You can check and set the limits in /proc/sys/kernel/sem.Command failedV2R1C00B052-GUESTOS-FS-KVM-X64:~ # ```So I use `ipcs` to check the ipcs:```V2R1C00B052-GUESTOS-FS-KVM-X64:~ # ipcs------ Message Queues --------key        msqid      owner      perms      used-bytes   messages------ Shared Memory Segments --------key        shmid      owner      perms      bytes      nattch     status------ Semaphore Arrays --------key        semid      owner      perms      nsems0x0d4d3358 238977024  root       600        10x0d4d0ec9 270172161  root       600        10x0d4dc02e 281640962  root       600        10x0d4db8d2 291045379  root       600        10x0d4d4e76 291864580  root       600        10x0d4d825a 292388869  root       600        10x0d4d93ee 294256646  root       600        10x0d4da4a1 294879239  root       600        10x0d4d4125 295305224  root       600        1.......-->  128 cookie leaks, not list here.......```And  use `dmsetup udevcookies` to see the same as ipcs.  `cat /proc/sys/kernel/sem````V2R1C00B052-GUESTOS-FS-KVM-X64:~ # cat /proc/sys/kernel/sem250     32000   32      128V2R1C00B052-GUESTOS-FS-KVM-X64:~ # ```It is `128`, so I echo an larger number of sem, it works:```echo 250 32000  32  1024 > /proc/sys/kernel/sem```And then Docker could startup.So I supposed that there are `semaphore leaks` in DM. But I am not sure how does it happen..And BTW, I could use `dmsetup udevcomplete_all` to cleanup all the leaks to recover the environment.But I think we should work out an solution against this situation.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1.   create/delete containers continuously.2.  kill docker randomly.After some time, use  `dmsetup udevcookies` to check if there is `semaphore leak` exists.On other environment, We found leaks too. but very small (less than 10). **Describe the results you received:**`semaphore leak` was found  and reached the limit number, docker could startup.**Describe the results you expected:**No `semaphore leak`, or cleanup it at docker startup.docker could works fine.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```root@localhost:~/workspace/huawei/docker# docker versionClient: Version:        1.11.2 API version:    1.23 Go version:     go1.7.1 Git commit:     ff25c8a Built:          Thu Jun  8 15:37:09 2017 OS/Arch:        linux/amd64Server: Version:        1.11.2 API version:    1.23 Go version:     go1.7.1 Git commit:     3515a27-unsupported Built:          Thu Jun  8 16:28:37 2017 OS/Arch:        linux/amd64```**Output of `docker info`:**```root@localhost:~/workspace/huawei/docker# docker infoContainers: 210 Running: 0 Paused: 0 Stopped: 210Images: 11Server Version: 1.11.2Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: falseLogging Driver: json-fileCgroup Driver: cgroupfsHugetlb Pagesize: 2MBPlugins: Volume: local Network: bridge null hostKernel Version: 4.6.0Operating System: Ubuntu 14.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.67 GiBName: localhostID: LB2C:RVJO:DK5F:GVNI:QFYC:DTII:C3UB:6QHS:754W:LE3G:BKPP:EUIYDocker Root Dir: /var/lib/dockerDebug mode (client): falseDebug mode (server): true File Descriptors: 12 Goroutines: 25 System Time: 2017-06-09T01:43:24.994823746+08:00 EventsListeners: 0Registry: https://index.docker.io/v1/Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
33591,0,2351,37,0,0,rdlf0,0,"title:Dangling filter doesn't work properly when used on images prune. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**I'm trying to remove all dangling images through the `Docker API`, using `cURL`, but the **dangling** filter doesn't seem to work as expected.**Steps to reproduce the issue:**When I execute `docker images` through the cli, I get this list:```REPOSITORY                                  TAG                 IMAGE ID            CREATED             SIZEmy.repository.com/project/image          master              31a8bb572943        About an hour ago   523 MBmy.repository.com/project/image          <none>              b1bf9e0bcee0        About an hour ago   523 MBmy.repository.com/project/image          <none>              ae59986ac910        4 hours ago         523 MBmy.repository.com/anotherproject/image   web                 6f5664d4e09c        2 days ago          45.7 MBmy.repository.com/anotherproject/image   <none>              05dde9468fad        2 days ago          42 MBmy.repository.com/anotherproject/image   <none>              5c51a672d505        2 days ago          42 MB```I have 4 running containers - 3 of them are using the first image `(my.repository.com/project/image:master)` and one is using `my.repository.com/anotherproject/image:web`. I removed all stopped containers, so there is no difference between the results of `docker ps` and `docker ps -a`, therefore the `<none>` images should be unused and untagged.According to [the documentation](https://docs.docker.com/engine/api/v1.29/#operation/ImagePrune) the **dangling** filter should be set to **true**, to match these **unused and untagged** images and prune them, but after few hours of tests it turned out that the images are matched and pruned only if the filter is set to **false**, which, according to the documentation, should work only with unused images. So, it turns out that my `<none>` images are tagged somehow.Here is the command I run, which successfully pruned my `<none>` images:```curl --unix-socket /var/run/docker.sock -G -X POST ""http:/v1.29/images/prune"" --data-urlencode 'filters={""dangling"":{""false"": true}}'```If this can help, the `<none>` images are result of pulling their new versions and recreation of `docker-compose` services.**Describe the results you received:**The `<none>` images aren't matched when using `dangling=true` filter. They are matched only with `dangling=false` filter.**Describe the results you expected:**The `<none>` images have to be matched and pruned when using `dangling=true` filter.**Additional information you deem important (e.g. issue happens only occasionally):**Happens all the time.**Output of `docker version`:**```Client: Version:      17.03.1-ce API version:  1.27 Go version:   go1.7.5 Git commit:   c6d412e Built:        Mon Mar 27 17:05:44 2017 OS/Arch:      linux/amd64Server: Version:      17.03.1-ce API version:  1.27 (minimum version 1.12) Go version:   go1.7.5 Git commit:   c6d412e Built:        Mon Mar 27 17:05:44 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 4 Running: 4 Paused: 0 Stopped: 0Images: 2Server Version: 17.03.1-ceStorage Driver: overlay2 Backing Filesystem: xfs Supports d_type: false Native Overlay Diff: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 4ab9917febca54791c5f071a9d1f404867857fccrunc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfeinit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.6.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 7.64 GiBName: mydockermachineID: IT5W:6NWN:PZ3F:PHPB:E4YE:V7VL:WJEL:PDGO:RZHU:LYKR:SJIH:QLKLDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical personal machine
"
33589,0,3037,56,0,0,soar,0,"title:Docker Swarm Mode service discovery is totally unstable. description:**Description**I have about 10 nodes, 4 master nodes, 7 overlay networks and about 70 services. And swarm is totally unstable now: it accidentally stops resolving names of my services:```consoleroot@balancer:/# nslookup backend 127.0.0.11Server:		127.0.0.11Address:	127.0.0.11#53** server can't find backend: NXDOMAIN```And this problem can exist for 10-20 minutes! All this time you'll see `502 Bad Gateway` error. And then you'll see messages like this:```textJun  8 15:04:16 node4 dockerd[840]: time=""2017-06-08T15:04:16.415822659+02:00"" level=warning msg=""Neighbor entry already present for IP 10.10.4.50, mac 02:42:0a:0a:04:32""Jun  8 15:04:16 node4 dockerd[840]: time=""2017-06-08T15:04:16.415898743+02:00"" level=warning msg=""Neighbor entry already present for IP <external-ip-here>, mac 02:42:0a:0a:04:32""Jun  8 15:04:16 node4 dockerd[840]: time=""2017-06-08T15:04:16.415971947+02:00"" level=warning msg=""Neighbor entry already present for IP 10.10.4.45, mac 02:42:0a:0a:04:2d""Jun  8 15:04:16 node4 dockerd[840]: time=""2017-06-08T15:04:16.415997559+02:00"" level=warning msg=""Neighbor entry already present for IP <external-ip-here>, mac 02:42:0a:0a:04:2d""...```... and then it will recover itself:```consoleroot@balancer:/# nslookup backend 127.0.0.11Server:		127.0.0.11Address:	127.0.0.11#53Non-authoritative answer:Name:	backendAddress: 10.0.0.16```For 1-2 hours. And then - cluster will become broken again.**Steps to reproduce the issue:**1. Create swarm2. Create services and networks3. Try to use it in production**Describe the results you received:**At this moment Swarm Mode is unusable for production environments.**Describe the results you expected:**I expected that it will!**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:04:27 2017 OS/Arch:      linux/amd64Server: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:04:27 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 3 Running: 2 Paused: 0 Stopped: 1Images: 3Server Version: 17.05.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 36 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: yidccbcki64epay4p4ugq6xm1 Is Manager: true ClusterID: hqvohft3etj4ajnkgubbnjwzp Managers: 4 Nodes: 15 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: <ip1> Manager Addresses:  <ip2>:2377  <ip3>:2377  <ip1>:2377  <ip4>:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faKernel Version: 3.16.0-4-amd64Operating System: Debian GNU/Linux 8 (jessie)OSType: linuxArchitecture: x86_64CPUs: 12Total Memory: 63.02GiBName: node5ID: JRVQ:2D26:NA5B:TJ5L:VWSC:TEAE:G4B2:UXYF:3TRR:F7YY:LRW5:3IWADocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: mybotRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No kernel memory limit supportWARNING: No cpu cfs quota supportWARNING: No cpu cfs period support```
"
33586,0,1648,21,0,0,SeidChr,0,"title:docker commit > invalid tar header. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Hi,After importing a couple of databases in the ms developer sql database image, then stopping it, and committing, i get the following error:```PS > docker commit ContainerXY my/tagError response from daemon: re-exec error: exit status 1: output: archive/tar: invalid tar header```The Databases are quite big though, but anyway, it should not fail like that.Is there any more info i can give you to solve that issue?**Steps to reproduce the issue:**1. Start ms developer sql database image2. import 120gig of databases (final findows filter directory size)3. commit the image**Describe the results you received:**```response from daemon: re-exec error: exit status 1: output: archive/tar: invalid tar header```**Describe the results you expected:**image comitted correctly**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version` & `docker info`:**```PS C:\Windows\system32> docker infoContainers: 2 Running: 0 Paused: 0 Stopped: 2Images: 209Server Version: 17.03.1-ee-3Storage Driver: windowsfilter Windows: Logging Driver: json-filePlugins:  Volume: local Network: l2bridge l2tunnel nat null overlay transparentSwarm: inactiveDefault Isolation: processKernel Version: 10.0 14393 (14393.1198.amd64fre.rs1_release_sec.170427-1353)Operating System: Windows Server 2016 StandardOSType: windowsArchitecture: x86_64CPUs: 12Total Memory: 63.92 GiBName: S6ID: 2OZY:DSZI:JEUU:4ISW:GJ23:F2TA:F5U3:XR4Z:YZKU:SAID:362W:MMXDDocker Root Dir: D:\System\Data\DockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: -1 Goroutines: 22 System Time: 2017-06-02T09:56:38.4659153+02:00 EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falsePS C:\Windows\system32> docker versionClient: Version:      17.03.1-ee-3 API version:  1.27 Go version:   go1.7.5 Git commit:   3fcee33 Built:        Thu Mar 30 19:31:22 2017 OS/Arch:      windows/amd64Server: Version:      17.03.1-ee-3 API version:  1.27 (minimum version 1.24) Go version:   go1.7.5 Git commit:   3fcee33 Built:        Thu Mar 30 19:31:22 2017 OS/Arch:      windows/amd64 Experimental: falsePS C:\Windows\system32> ```**Additional environment details (AWS, VirtualBox, physical, etc.):**Windows Server 2016 and updated dockerhttps://social.msdn.microsoft.com/Forums/en-US/14d2ad0c-1116-42c7-8449-29d495be4f30/docker-commit-invalid-tar-header?forum=windowscontainersScreenshot of windowsfilter folder properties https://social.msdn.microsoft.com/Forums/getfile/1080800
"
33584,0,6626,0,0,1,moypray,0,"title:[docker crash] when start lots of containers, restart docker, maybe crash/panic. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**When I start lots of containers with `--restart=always` options, maybe fail to restart docker service.Logs: ```2017-06-07T11:54:21.682390+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: panic: runtime error: invalid memory address or nil pointer dereference2017-06-07T11:54:21.682796+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: [signal SIGSEGV: segmentation violation code=0x1 addr=0x28 pc=0x594ae2]2017-06-07T11:54:21.683106+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: goroutine 156 [running]:2017-06-07T11:54:21.683432+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: panic(0x113d660, 0xc420010040)2017-06-07T11:54:21.683612+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /usr/lib/golang/src/runtime/panic.go:500 +0x1a1 fp=0xc4204cd510 sp=0xc4204cd4802017-06-07T11:54:21.683776+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: runtime.panicmem()2017-06-07T11:54:21.683936+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /usr/lib/golang/src/runtime/panic.go:62 +0x6d fp=0xc4204cd540 sp=0xc4204cd5102017-06-07T11:54:21.684186+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: runtime.sigpanic()2017-06-07T11:54:21.684433+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /usr/lib/golang/src/runtime/sigpanic_unix.go:24 +0x214 fp=0xc4204cd598 sp=0xc4204cd5402017-06-07T11:54:21.684663+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: github.com/docker/docker/daemon.(*Daemon).createSpec(0xc4204f6000, 0xc42074c000, 0x0, 0x0, 0xc4204f6000)2017-06-07T11:54:21.684903+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /home/abuild/rpmbuild/BUILD/docker/.gopath/src/github.com/docker/docker/daemon/oci_linux.go:692 +0x1b32 fp=0xc4204cdc30 sp=0xc4204cd5982017-06-07T11:54:21.685187+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: github.com/docker/docker/daemon.(*Daemon).containerStart(0xc4204f6000, 0xc42074c000, 0xc420025f00, 0x0, 0x0)2017-06-07T11:54:21.685432+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /home/abuild/rpmbuild/BUILD/docker/.gopath/src/github.com/docker/docker/daemon/start.go:139 +0x2ba fp=0xc4204cdea0 sp=0xc4204cdc302017-06-07T11:54:21.685668+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: github.com/docker/docker/daemon.(*Daemon).StateChanged.func1(0xc420833620, 0xc4204f6000, 0xc42074c000, 0xc420966eac, 0x4, 0x0, 0x0, 0x0, 0x0)2017-06-07T11:54:21.685891+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /home/abuild/rpmbuild/BUILD/docker/.gopath/src/github.com/docker/docker/daemon/monitor.go:55 +0x1eb fp=0xc4204cdf58 sp=0xc4204cdea02017-06-07T11:54:21.686128+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: runtime.goexit()2017-06-07T11:54:21.686409+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /usr/lib/golang/src/runtime/asm_amd64.s:2086 +0x1 fp=0xc4204cdf60 sp=0xc4204cdf582017-06-07T11:54:21.686631+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: created by github.com/docker/docker/daemon.(*Daemon).StateChanged2017-06-07T11:54:21.686818+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /home/abuild/rpmbuild/BUILD/docker/.gopath/src/github.com/docker/docker/daemon/monitor.go:65 +0x5ed2017-06-07T11:54:21.687027+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: goroutine 1 [semacquire]:2017-06-07T11:54:21.687239+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: runtime.gopark(0x13b5088, 0x1b5cfa0, 0x12e242e, 0xa, 0xc400000019, 0x4)2017-06-07T11:54:21.687424+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /usr/lib/golang/src/runtime/proc.go:259 +0x13a fp=0xc4208a2a30 sp=0xc4208a2a002017-06-07T11:54:21.687591+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: runtime.goparkunlock(0x1b5cfa0, 0x12e242e, 0xa, 0x8dbe19, 0x4)2017-06-07T11:54:21.687815+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /usr/lib/golang/src/runtime/proc.go:265 +0x5e fp=0xc4208a2a70 sp=0xc4208a2a302017-06-07T11:54:21.687981+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: runtime.semacquire(0xc4202c894c, 0x1)2017-06-07T11:54:21.688190+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /usr/lib/golang/src/runtime/sema.go:111 +0x20d fp=0xc4208a2ad8 sp=0xc4208a2a702017-06-07T11:54:21.688400+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: sync.runtime_Semacquire(0xc4202c894c)2017-06-07T11:54:21.688611+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /usr/lib/golang/src/runtime/sema.go:47 +0x30 fp=0xc4208a2af8 sp=0xc4208a2ad82017-06-07T11:54:21.688793+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: sync.(*WaitGroup).Wait(0xc4202c8940)2017-06-07T11:54:21.688986+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /usr/lib/golang/src/sync/waitgroup.go:131 +0x97 fp=0xc4208a2b48 sp=0xc4208a2af82017-06-07T11:54:21.698931+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: github.com/docker/docker/daemon.(*Daemon).restore(0xc4204f6000, 0x0, 0x0)2017-06-07T11:54:21.699164+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /home/abuild/rpmbuild/BUILD/docker/.gopath/src/github.com/docker/docker/daemon/daemon.go:270 +0x704 fp=0xc4208a32d8 sp=0xc4208a2b48--------------017-06-07T11:54:21.773198+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: github.com/docker/docker/daemon.(*Daemon).restore.func1(0xc4202c8940, 0xc4204f6000, 0xc4203da258, 0xc4202a7470, 0xc4202a7380, 0xc4203da251, 0xc4207f2000)2017-06-07T11:54:21.773321+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: /home/abuild/rpmbuild/BUILD/docker/.gopath/src/github.com/docker/docker/daemon/daemon.go:215 +0x2b3 fp=0xc4208d7f68 sp=0xc4208d7db82017-06-07T11:54:21.773435+00:00 V2R1C00B026-GUESTOS-FS-KVM-X64 docker: runtime.goexit()```Analysis:I think the issue is when docker is restoring containers, received an `init process exit` event from containerd. But the container is with `--restart=always`,  it will be started very soon.But when container startup, it will use `daemon.netController` and it may be not initialized.1. Startup container process, visit `daemon.netController`:    https://github.com/moby/moby/blob/master/daemon/oci_linux.go#L7772.  `daemon.netController` init in `daemon.restore` process:https://github.com/moby/moby/blob/master/daemon/daemon.go#L287I think the panic is terrible.  **And I will rise a PR to fix it.**<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1.  startup lots of containers with '--restart=always'2.  restart docker service.The more containers we have started, the easier to reproduce this issue.**Describe the results you received:**docker crashed**Describe the results you expected:**docker works fine.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```root@localhost:~/workspace/huawei/docker# docker versionClient: Version:        1.11.2 API version:    1.23 Go version:     go1.7.1 Git commit:     ff25c8a Built:          Thu Jun  8 15:37:09 2017 OS/Arch:        linux/amd64Server: Version:        1.11.2 API version:    1.23 Go version:     go1.7.1 Git commit:     3515a27-unsupported Built:          Thu Jun  8 16:28:37 2017 OS/Arch:        linux/amd64From the code, I think this issue exists on master branch.```**Output of `docker info`:**```root@localhost:~/workspace/huawei/docker# docker infoContainers: 210 Running: 0 Paused: 0 Stopped: 210Images: 11Server Version: 1.11.2Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: falseLogging Driver: json-fileCgroup Driver: cgroupfsHugetlb Pagesize: 2MBPlugins: Volume: local Network: bridge null hostKernel Version: 4.6.0Operating System: Ubuntu 14.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.67 GiBName: localhostID: LB2C:RVJO:DK5F:GVNI:QFYC:DTII:C3UB:6QHS:754W:LE3G:BKPP:EUIYDocker Root Dir: /var/lib/dockerDebug mode (client): falseDebug mode (server): true File Descriptors: 12 Goroutines: 25 System Time: 2017-06-09T01:43:24.994823746+08:00 EventsListeners: 0Registry: https://index.docker.io/v1/Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
33538,0,1520,3,0,0,stackempty,0,"title:Docker Swarm mode on Windows Containers: If --limit-cpu is specified the service does not get created.. description:**Description**In docker swarm mode on windows containers, if --limit-cpu is specified the service does not get created. fails with ""invalid option: Windows does not support CPUPeriod""**Steps to reproduce the issue:**1. Setup windows containers and swarm using the guides here https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode2. Create a service on docker on windows with the command below.``` docker service create --name iis --limit-cpu=0.25 microsoft/iis```3. View service details with ```docker service ps --no-trunc```**Describe the results you received:**Service tasks do not get started.```C:\docker>docker service ps --no-trunc iisID                         NAME       IMAGE                                                                                         NODE           DESIRED STATE  CURRENT STATE           ERROR                                                 PORTSzu114ig61kg7536jr4ubm2gtq  iis.1      microsoft/iis:latest@sha256:33903108e73e114f1c11c08292a9712dd9ae0020fae5175e616e9f2cb2011cb7  docker-win-02  Ready          Rejected 2 seconds ago  ""invalid option: Windows does not support CPUPeriod""twipa9qaydh80veqslr4xnh9w   \_ iis.1  microsoft/iis:latest@sha256:33903108e73e114f1c11c08292a9712dd9ae0020fae5175e616e9f2cb2011cb7  docker-win-02  Shutdown       Rejected 7 seconds ago  ""invalid option: Windows does not support CPUPeriod""o3ndl4ylo6ha9686e8ys80ipt   \_ iis.1  microsoft/iis:latest@sha256:33903108e73e114f1c11c08292a9712dd9ae0020fae5175e616e9f2cb2011cb7  docker-win-01  Shutdown       Rejected 8 seconds ago  ""invalid option: Windows does not support CPUPeriod""```**Describe the results you expected:**The service should get started with proper limits applied.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.03.1-ee-3 API version:  1.27 Go version:   go1.7.5 Git commit:   3fcee33 Built:        Thu Mar 30 19:31:22 2017 OS/Arch:      windows/amd64Server: Version:      17.03.1-ee-3 API version:  1.27 (minimum version 1.24) Go version:   go1.7.5 Git commit:   3fcee33 Built:        Thu Mar 30 19:31:22 2017 OS/Arch:      windows/amd64 Experimental: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**WindowsContainers running in a VMWare VM.
"
33501,0,1600,15,0,0,FrenchBen,0,"title:POST requests to start endpoint fails with ContentLength error. description:**Description**Making an API request to start a container with an empty JSON string in the body will return the following error:`{""message"":""starting container with non-empty request body was deprecated since v1.10 and removed in v1.12""}`This functionality worked in all previous versions of docker but is now broken in 17.06.0-rc1**Steps to reproduce the issue:**1. Create a container2. Send a request to start the container via the API and an empty JSON string `{}`3. Get the above error```$ docker create --name my-test alpine top$ curl -vvv --unix-socket /var/run/docker.sock -X POST -H 'Content-Type: application/json' -d '{}' http://1.29/containers/my-test/startNote: Unnecessary use of -X or --request, POST is already inferred.*   Trying /var/run/docker.sock......> POST /containers/my-test/start HTTP/1.1> Host: 1.29> User-Agent: curl/7.51.0> Accept: */*> Content-Type: application/json> Content-Length: 2>* upload completely sent off: 2 out of 2 bytes< HTTP/1.1 400 Bad Request< Api-Version: 1.30< Content-Length: 109< Content-Type: application/json< Date: Fri, 02 Jun 2017 21:57:20 GMT< Docker-Experimental: true< Ostype: linux< Server: Docker/17.06.0-ce-rc1 (linux)<{""message"":""starting container with non-empty request body was deprecated since v1.10 and removed in v1.12""}* Curl_http_done: called premature == 0* Connection #0 to host 1.29 left intact```To make it work:```$ curl --unix-socket /var/run/docker.sock -X POST -H 'Content-Type: application/json' -d '' http://1.29/containers/my-test/start```**Describe the results you received:**`{""message"":""starting container with non-empty request body was deprecated since v1.10 and removed in v1.12""}`**Describe the results you expected:**For the container to start**Additional information you deem important (e.g. issue happens only occasionally):**https://github.com/moby/moby/blob/master/api/server/router/container/container_routes.go#L144**Output of `docker version`:**```                                                                                                                                          Client: Version:      17.06.0-ce-rc1 API version:  1.30 Go version:   go1.8.1 Git commit:   7f8486a Built:        Wed May 31 02:56:01 2017 OS/Arch:      darwin/amd64Server: Version:      17.06.0-ce-rc1 API version:  1.30 (minimum version 1.12) Go version:   go1.8.1 Git commit:   7f8486a Built:        Wed May 31 03:00:14 2017 OS/Arch:      linux/amd64 Experimental: true```**Additional environment details (AWS, VirtualBox, physical, etc.):**Version 17.06.0-rc1-ce-mac13 (18169)
"
33490,1,598,0,1,1,erxian,0,"title:Reopen: docker cp gives 'operation not permitted' but does still copy file. description:Hi all,     When I do ""docker cp"" as a root user, the copy succeeds but the lchown afterward still fails and exports:```Error response from daemon: Error processing tar file(exit status 1): lchown /test.sh: operation not permitted```The same problem will reproduce in ""kubectl cp"", which output is:```tar: test.sh: Cannot change ownership to uid 0, gid 0: Operation not permittedtar: Exiting with failure status due to previous error```After checking docker issues, I find it's a long-standing problem locates in https://github.com/moby/moby/issues/3986 https://github.com/moby/moby/issues/4130 So I wonder why docker cp gives 'operation not permitted' but does still copy file, and how to fix it.**Output of `docker version`:**```Client: Version:      1.12.6 API version:  1.24 Go version:   go1.6.4 Git commit:   78d1802 Built:        Tue Jan 10 20:20:01 2017 OS/Arch:      linux/amd64Server: Version:      1.12.6 API version:  1.24 Go version:   go1.6.4 Git commit:   78d1802 Built:        Tue Jan 10 20:20:01 2017 OS/Arch:      linux/amd64```
"
33489,0,1918,23,0,0,sethfowler,0,"title:Malfunctioning tty with Docker 17.06.0-rc1-ce-mac13. description:I updated to Docker 17.06 today and discovered that the tty malfunctions whenever I try to `docker run bash`. It happens for any image I've tried it with. Here's an example of what I see (I'm just pressing enter repeatedly here):```闂?> docker run -it --rm sameersbn/squid bashroot@49f5fafc7145:/#                     root@49f5fafc7145:/#                                          root@49f5fafc7145:/#                                                               root@49f5fafc7145:/#```As you might imagine, applications like `top` are unusable.**Output of `docker version`:**```Client: Version:      17.06.0-ce-rc1 API version:  1.30 Go version:   go1.8.1 Git commit:   7f8486a Built:        Wed May 31 02:56:01 2017 OS/Arch:      darwin/amd64Server: Version:      17.06.0-ce-rc1 API version:  1.30 (minimum version 1.12) Go version:   go1.8.1 Git commit:   7f8486a Built:        Wed May 31 03:00:14 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 11Server Version: 17.06.0-ce-rc1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 3addd840653146c90a254301d6c3a663c7fd6429runc version: 992a5be178a62e026f4069f443c6164912adbf09init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.30-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 7.786GiBName: mobyID: ECB7:6K5D:MAZC:ALMM:IFXR:WSOR:MXUD:KYIO:NVT2:XZQW:YIQP:5RBRDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 24 Goroutines: 34 System Time: 2017-06-02T06:53:00.718486238Z EventsListeners: 1No Proxy: *.local, 169.254/16Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```
"
33425,0,2061,78,0,0,mitar,0,"title:dockerignore file does not respect / at the beginning of the pattern. description:**Description**Based on [documentation for dockerignore file](https://docs.docker.com/engine/reference/builder/#dockerignore-file) I was lead to expect that `/foo` and `foo` patterns match equally, a folder `foo` in the context root. But it seems this is not true.**Steps to reproduce the issue:**I have the following `.dockerignore` file:```/.git/.idea/.gitignore/.gitmodules/.dockerignore/Dockerfile/docker-compose.yml**/*.pyc**/__pycache__**/*.swp**/*.sublime-*/datasets/*````datasets` directory contains gigabytes of data.**Describe the results you received:**When I run:```docker build -t testimage .```The context sent to Docker daemon is huge.The same happens if I try:```/.git/.idea/.gitignore/.gitmodules/.dockerignore/Dockerfile/docker-compose.yml**/*.pyc**/__pycache__**/*.swp**/*.sublime-*datasets```But if I try:```.git.idea.gitignore.gitmodules.dockerignoreDockerfiledocker-compose.yml**/*.pyc**/__pycache__**/*.swp**/*.sublime-*datasets/*```Context sent is small as expected.**Describe the results you expected:**That the context is small for all variations of `.dockerfile` contents above.**Output of `docker version`:**```Client: Version:      17.03.1-ce API version:  1.27 Go version:   go1.7.5 Git commit:   c6d412e Built:        Tue Mar 28 00:40:02 2017 OS/Arch:      darwin/amd64Server: Version:      17.03.1-ce API version:  1.27 (minimum version 1.12) Go version:   go1.7.5 Git commit:   c6d412e Built:        Fri Mar 24 00:00:50 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 58Server Version: 17.03.1-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 4ab9917febca54791c5f071a9d1f404867857fccrunc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfeinit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.27-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 3.855 GiBName: mobyID: LCXW:QNBF:FEIN:FTYE:U7BQ:W3VI:N2IH:WNVQ:RFMT:PKET:VEM7:L3WBDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 41 Goroutines: 57 System Time: 2017-05-28T21:56:26.67475541Z EventsListeners: 1No Proxy: *.local, 169.254/16Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```
"
33419,0,2855,298,0,1,runcom,0,"title:libcontainerd: fix reaper goroutine position. description:It has observed defunct containerd processes accumulating overtime while dockerd was permanently failing to restart containerd.Due to a bug in the `runContainerdDaemon()` function, dockerd does not clean upits child process if containerd already exits very soon after the (re)start.The reproducer and analysis below comes from docker 1.12.x but bugstill applies on latest master.Analysis from Ulrich Obergfell.- from libcontainerd/remote_linux.go:```  329 func (r *remote) runContainerdDaemon() error {   :   :      // start the containerd child process   :  403     if err := cmd.Start(); err != nil {  404             return err  405     }   :   :      // If containerd exits very soon after (re)start, it ispossible   :      // that containerd is already in defunct state at the timewhen   :      // dockerd gets here. The setOOMScore() function tries towrite   :      // to /proc/PID_OF_CONTAINERD/oom_score_adj. However, thisfails   :      // with errno EINVAL because containerd is defunct. Please see   :      // snippets of kernel source code and further explanationbelow.   :  407     if err := setOOMScore(cmd.Process.Pid, r.oomScore); err != nil{  408             utils.KillProcess(cmd.Process.Pid)   :   :              // Due to the error from write() we return here. Asthe   :              // goroutine that would clean up the child has notbeen   :              // started yet, containerd remains in the defunctstate   :              // and never gets reaped.   :  409             return err  410     }   :  417     go func() {  418             cmd.Wait()  419             close(r.daemonWaitCh)  420     }() // Reap our child when needed   :  423 }```This is the kernel function that gets invoked when dockerd tries towriteto `/proc/PID_OF_CONTAINERD/oom_score_adj`.- from fs/proc/base.c:``` 1197 static ssize_t oom_score_adj_write(struct file *file, ... 1198                                         size_t count, loff_t*ppos) 1199 {   : 1223         task = get_proc_task(file_inode(file));   :   :          // The defunct containerd process does not have a virtual   :          // address space anymore, i.e. task->mm is NULL. Thus the   :          // following code returns errno EINVAL to dockerd.   : 1230         if (!task->mm) { 1231                 err = -EINVAL; 1232                 goto err_task_lock; 1233         }   : 1253 err_task_lock:   : 1257         return err < 0 ? err : count; 1258 }```The purpose of the following program is to demonstrate the behavior ofthe `oom_score_adj_write()` function in connection with a defunct process.```$ cat defunct_test.c#include <unistd.h>main(){    pid_t pid = fork();    if (pid == 0)        // child        _exit(0);    // parent    pause();}$ make defunct_testcc     defunct_test.c   -o defunct_test$ ./defunct_test &[1] 3142$ ps -f | grep defunct_test | grep -v greproot      3142  2956  0 13:04 pts/0    00:00:00 ./defunct_testroot      3143  3142  0 13:04 pts/0    00:00:00 [defunct_test] <defunct>$ echo ""ps 3143"" | crash -s  PID    PPID  CPU       TASK        ST  %MEM     VSZ    RSS  COMM  3143   3142   2  ffff880035def300  ZO   0.0       0      0defunct_test$ echo ""px ((struct task_struct *)0xffff880035def300)->mm"" | crash -s$1 = (struct mm_struct *) 0x0                          ^^^ task->mm is NULL$ cat /proc/3143/oom_score_adj0$ echo 0 > /proc/3143/oom_score_adj-bash: echo: write error: Invalid argument""```---This patch fixes the above issue by making sure we start the reapergoroutine as soon as possible.Signed-off-by: Antonio Murdaca <runcom@redhat.com>
"
33415,0,6434,4,0,0,eyz,0,"title:ipam-driver cannot be used with config-only network. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->While testing moby/moby#32981, I found that --ipam-driver does not appear to get set in the --config-only network, and thus the IPAM driver is not used in global scope. I also have noted this finding in moby/moby#32981**Steps to reproduce the issue:**1. when no --config-only flag is specified, --ipam-driver is used properly and I get a subnet and gateway from the IPAM driver2. when setting --config-only, the IPAM.Driver appears to not be set even though it is specified in my example with --ipam-driver**Describe the results you received:**```[root@centos7swarmtest01 ~]# docker versionClient: Version:      unknown-version API version:  1.30 Go version:   go1.7.4 Git commit:   883d28c Built:        Mon May 22 22:35:49 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-dev API version:  1.30 (minimum version 1.12) Go version:   go1.8.1 Git commit:   5648a1a-unsupported Built:        Mon May 22 22:30:30 2017 OS/Arch:      linux/amd64 Experimental: true```---Test-created network with --ipam-driver specified, without --config-only specified (still works fine)```[root@centos7swarmtest01 ~]# docker network create --ipam-driver=ishant8/sdip:latest -o parent=ens192 ipam_test_not_config_only684d3f26a279a43b6bbfe6e9103cb0c35bd39d4f986e487100147cd7c75570e3[root@centos7swarmtest01 ~]# docker network inspect 684[    {        ""Name"": ""ipam_test_not_config_only"",        ""Id"": ""684d3f26a279a43b6bbfe6e9103cb0c35bd39d4f986e487100147cd7c75570e3"",        ""Created"": ""2017-05-26T17:24:38.172971069-07:00"",        ""Scope"": ""local"",        ""Driver"": ""bridge"",        ""EnableIPv6"": false,        ""IPAM"": {            ""Driver"": ""ishant8/sdip:latest"",            ""Options"": {},            ""Config"": [                {                    ""Subnet"": ""192.168.10.2/24"",                    ""Gateway"": ""192.168.10.2""                }            ]        },        ""Internal"": false,        ""Attachable"": false,        ""Ingress"": false,        ""ConfigFrom"": {            ""Network"": """"        },        ""ConfigOnly"": false,        ""Containers"": {},        ""Options"": {            ""parent"": ""ens192""        },        ""Labels"": {}    }]```^^^ :+1: Driver is correctly set to ishant8/sdip:latest, and Subnet and Gateway are obtained from the IPAM plugin---Test-created network with --ipam-driver specified, with --config-only specified```[root@centos7swarmtest01 ~]# docker network create --config-only --ipam-driver=ishant8/sdip:latest -o parent=ens192 ipam_test_config_only1533b1b79cbafbd8c79ccaeb0d14116144a6f2e00eb5ee0f30bce1c5eebd14bc[root@centos7swarmtest01 ~]# docker network inspect 153[    {        ""Name"": ""ipam_test_config_only"",        ""Id"": ""1533b1b79cbafbd8c79ccaeb0d14116144a6f2e00eb5ee0f30bce1c5eebd14bc"",        ""Created"": ""2017-05-26T17:25:21.399703669-07:00"",        ""Scope"": ""local"",        ""Driver"": ""null"",        ""EnableIPv6"": false,        ""IPAM"": {            ""Driver"": """",            ""Options"": {},            ""Config"": []        },        ""Internal"": false,        ""Attachable"": false,        ""Ingress"": false,        ""ConfigFrom"": {            ""Network"": """"        },        ""ConfigOnly"": true,        ""Containers"": {},        ""Options"": {            ""parent"": ""ens192""        },        ""Labels"": {}    }][root@centos7swarmtest01 ~]# docker network create -d ipvlan --scope=swarm --config-from ipam_test_config_only --attachable ipam_test_swarmizmjnk9h9coyfesetvjto3ttq[root@centos7swarmtest01 ~]# docker network inspect iz[    {        ""Name"": ""ipam_test_swarm"",        ""Id"": ""izmjnk9h9coyfesetvjto3ttq"",        ""Created"": ""0001-01-01T00:00:00Z"",        ""Scope"": ""swarm"",        ""Driver"": ""ipvlan"",        ""EnableIPv6"": false,        ""IPAM"": {            ""Driver"": ""default"",            ""Options"": null,            ""Config"": []        },        ""Internal"": false,        ""Attachable"": true,        ""Ingress"": false,        ""ConfigFrom"": {            ""Network"": ""ipam_test_config_only""        },        ""ConfigOnly"": false,        ""Containers"": null,        ""Options"": null,        ""Labels"": null    }]```^^^ :-1: Driver is not set in config-only network, nor in global-scoped from config-only, and IPAM driver does not return Subnet nor Gateway**Describe the results you expected:**- I expected the IPAM Driver to be set in the config-only network, and available to the global-scoped network which references it**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      unknown-version API version:  1.30 Go version:   go1.7.4 Git commit:   883d28c Built:        Mon May 22 22:35:49 2017 OS/Arch:      linux/amd64Server: Version:      17.06.0-dev API version:  1.30 (minimum version 1.12) Go version:   go1.8.1 Git commit:   5648a1a-unsupported Built:        Mon May 22 22:30:30 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 2 Running: 2 Paused: 0 Stopped: 0Images: 8Server Version: 17.06.0-devStorage Driver: devicemapper Pool Name: docker-thinpool Pool Blocksize: 524.3kB Base Device Size: 10.74GB Backing Filesystem: xfs Data file:  Metadata file:  Data Space Used: 719.3MB Data Space Total: 40.8GB Data Space Available: 40.08GB Metadata Space Used: 225.3kB Metadata Space Total: 427.8MB Metadata Space Available: 427.6MB Thin Pool Minimum Free Space: 4.079GB Udev Sync Supported: true Deferred Removal Enabled: true Deferred Deletion Enabled: true Deferred Deleted Device Count: 0 Library Version: 1.02.135-RHEL7 (2016-11-16)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: active NodeID: vup71mijb1fzmb69vef61crvm Is Manager: true ClusterID: 2iesnqh9gwb91wy04hiagzlyz Managers: 1 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  Force Rotate: 0 Root Rotation In Progress: false Node Address: 10.210.102.215 Manager Addresses:  10.210.102.215:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 3addd840653146c90a254301d6c3a663c7fd6429runc version: 992a5be178a62e026f4069f443c6164912adbf09init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.4.66-1.el7.elrepo.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.859GiBName: tucevsswarmtest01ID: ROMP:6ZSZ:V5EG:XQBH:WW7L:KZSE:K3EY:V3XP:TINW:VYW6:23GD:BYTJDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**```[root@centos7swarmtest01 ~]# uname -aLinux centos7swarmtest01 4.4.66-1.el7.elrepo.x86_64 #1 SMP Thu May 4 08:30:11 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux[root@centos7swarmtest01 ~]# cat /etc/redhat-release CentOS Linux release 7.3.1611 (Core) [root@centos7swarmtest01 ~]# dmidecode | grep -i vmware	Manufacturer: VMware, Inc.	Product Name: VMware Virtual Platform	Serial Number: VMware-42 3c 12 5d c6 59 7d 3b-5d 02 8c a3 37 6b bb fd```
"
33380,0,6012,143,0,0,aaronlehmann,0,"title:Joining a cluster with wrong certificate hides error. description:I tried prepopulating self-signed certificates in `/var/lib/docker/swarm` and then trying to join a different swarm cluster. The `join` command waited for awhile, and I saw the agent trying to reconnect over and over in the daemon logs:```DEBU[0020] loaded node credentials                       module=""node/tls"" node.id=ly2go2wiow3bgab5ebs2wb62v node.role=swarm-managerDEBU[0020] next certificate renewal scheduled for 1421h23m36.546149707s from now  module=""node/tls"" node.id=ly2go2wiow3bgab5ebs2wb62v node.role=swarm-manager time=2017-07-22 22:59:00.00000025 +0000 UTCINFO[0020] Listening for connections                     addr=""[::]:2377"" module=node node.id=ly2go2wiow3bgab5ebs2wb62v proto=tcpINFO[0020] Listening for local connections               addr=""/var/run/docker/swarm/control.sock"" module=node node.id=ly2go2wiow3bgab5ebs2wb62v proto=unixDEBU[0020] (*Agent).run                                  module=""node/agent"" node.id=ly2go2wiow3bgab5ebs2wb62vINFO[0020] Stopping manager                              module=node node.id=ly2go2wiow3bgab5ebs2wb62vDEBU[0020] (*session).start                              module=""node/agent"" node.id=ly2go2wiow3bgab5ebs2wb62vERRO[0020] agent: session failed                         error=""rpc error: code = 13 desc = connection error: desc = \""transport: x509: certificate signed by unknown authority (possibly because of \\\""x509: ECDSA verification failure\\\"" while trying to verify candidate authority certificate \\\""swarm-ca\\\"")\"""" module=""node/agent"" node.id=ly2go2wiow3bgab5ebs2wb62vDEBU[0020] agent: rebuild session                        module=""node/agent"" node.id=ly2go2wiow3bgab5ebs2wb62vDEBU[0020] (*session).start                              module=""node/agent"" node.id=ly2go2wiow3bgab5ebs2wb62vERRO[0020] agent: session failed                         error=""rpc error: code = 13 desc = connection error: desc = \""transport: x509: certificate signed by unknown authority (possibly because of \\\""x509: ECDSA verification failure\\\"" while trying to verify candidate authority certificate \\\""swarm-ca\\\"")\"""" module=""node/agent"" node.id=ly2go2wiow3bgab5ebs2wb62vDEBU[0020] agent: rebuild session                        module=""node/agent"" node.id=ly2go2wiow3bgab5ebs2wb62vDEBU[0021] (*session).start                              module=""node/agent"" node.id=ly2go2wiow3bgab5ebs2wb62vERRO[0021] agent: session failed                         error=""rpc error: code = 13 desc = connection error: desc = \""transport: x509: certificate signed by unknown authority (possibly because of \\\""x509: ECDSA verification failure\\\"" while trying to verify candidate authority certificate \\\""swarm-ca\\\"")\"""" module=""node/agent"" node.id=ly2go2wiow3bgab5ebs2wb62v```The join command eventually returned:```Error response from daemon: Timeout was reached before node was joined. The attempt to join the swarm will continue in the background. Use the ""docker info"" command to see the current swarm status of your node.```I would expect the join to fail right away, and expose the certificate error, instead of continuing to retry in the background. I believe we're propagating the error for expired certificates, but apparently not for certificate verification failures.However, this might be tricky to get right, because we don't necessarily want to shutdown the node that was already part of a cluster if the agent gets a certificate verification failure. We might need to add something to the `join` process that verifies the certificate before setting up a `Node`.Also, when I shut down the joining daemon while it was in this state, it gave me a stack trace:```goroutine 1 [running]:github.com/docker/docker/pkg/signal.DumpStacks(0x0, 0x0, 0x0, 0x0, 0x0, 0x0)        /go/src/github.com/docker/docker/pkg/signal/trap.go:82 +0xd9github.com/docker/docker/daemon/cluster.(*Cluster).Cleanup(0xc4207be7e0)        /go/src/github.com/docker/docker/daemon/cluster/cluster.go:378 +0x1c0main.(*DaemonCli).start(0xc420428c00, 0x0, 0x1ab79d5, 0x17, 0xc42035f200, 0xc4204170c0, 0xc4200d1290, 0x0, 0x0)        /go/src/github.com/docker/docker/cmd/dockerd/daemon.go:290 +0x1bedmain.runDaemon(0x0, 0x1ab79d5, 0x17, 0xc42035f200, 0xc4204170c0, 0xc4200d1290, 0x1, 0x0)        /go/src/github.com/docker/docker/cmd/dockerd/docker.go:91 +0x8cmain.newDaemonCommand.func1(0xc420325d40, 0xc420423050, 0x0, 0x1, 0x0, 0x0)        /go/src/github.com/docker/docker/cmd/dockerd/docker.go:42 +0x6fgithub.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).execute(0xc420325d40, 0xc42000c1b0, 0x1, 0x1, 0xc420325d40, 0xc42000c1b0)        /go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:646 +0x44egithub.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc420325d40, 0x18646a0, 0x1, 0xc420422fe0)        /go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:742 +0x349github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).Execute(0xc420325d40, 0xc420422fe0, 0x0)        /go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:695 +0x2bmain.main()        /go/src/github.com/docker/docker/cmd/dockerd/docker.go:118 +0xe6...goroutine 189 [chan receive, 1 minutes]:github.com/docker/docker/vendor/github.com/docker/swarmkit/manager.(*Manager).Stop(0xc4202e6480, 0x7f2897a33128, 0xc420772f60, 0xc42004dc00)        /go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/manager/manager.go:570 +0x125github.com/docker/docker/vendor/github.com/docker/swarmkit/node.(*Node).runManager.func2(0xc4201c2e10, 0xc4202e6480, 0x7f2897a33128, 0xc420772f60, 0xc42004dccf, 0xc4201dd740)        /go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/node/node.go:856 +0x8fgithub.com/docker/docker/vendor/github.com/docker/swarmkit/node.(*Node).runManager(0xc4201c2e10, 0x7f2897a33128, 0xc420772f60, 0xc42036d4a0, 0xc42084f140, 0x34, 0xc42084f180, 0x34, 0xc42036d6e0, 0xc42036db60, ...)        /go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/node/node.go:873 +0x921github.com/docker/docker/vendor/github.com/docker/swarmkit/node.(*Node).superviseManager(0xc4201c2e10, 0x7f2897a33128, 0xc420772f60, 0xc42036d4a0, 0xc42084f140, 0x34, 0xc42084f180, 0x34, 0xc42036d6e0, 0xc420772ed0, ...)        /go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/node/node.go:900 +0x1a3github.com/docker/docker/vendor/github.com/docker/swarmkit/node.(*Node).run.func5(0xc420751990, 0xc4201c2e10, 0x7f2897a33128, 0xc420772f60, 0xc42036d4a0, 0xc42084f1c0, 0xc42036d6e0, 0xc420772ed0, 0xc420751910, 0xc4207c2d60)        /go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/node/node.go:404 +0x9ccreated by github.com/docker/docker/vendor/github.com/docker/swarmkit/node.(*Node).run        /go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/node/node.go:407 +0x951```It appears to be blocked on trying to shut down a `Manager` that was never started. Looks like the manager's `Run` returned an error before closing `started` (probably propagating an error from `JoinAndStart`).cc @cyli
"
33370,0,0,60,0,0,deviantony,0,"title:docker build using -f to specify the Dockerfile location fails on Windows. description:Hi there, I'm facing an issue when trying to build an image on my Windows server 2016 machine.On Linux, I can type `docker build -t myimage -f build/linux/Dockerfile .` and the image is built without trouble.![test2](https://cloud.githubusercontent.com/assets/5485061/26397200/c751d9f0-4075-11e7-95ba-918f04795353.png)But on Windows, it seems that it cannot locate the Dockerfile:![test1](https://cloud.githubusercontent.com/assets/5485061/26397212/d20beb42-4075-11e7-929e-f68830fc238e.png)I've tried to search for existing issues about this without success.Docker version on Windows 1.13 (I might retry later with latest version).
"
33340,0,2582,0,0,0,mightyroser,0,"title:Cannot connect services to overlay networks marked internal. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Starting at around version 17.05.0-ce it seems that services cannot be created using internal overlay networks.  This used to work in previous versions.  Please let me know if there is any additional information I can provide.**Steps to reproduce the issue:**Here is a short example compose file, docker-compose-internal-network.yml, that demonstrates the problem:```version: '3.1'services:  linux:    image: alpine:3.5    networks:      - network_internal    deploy:      replicas: 2networks:  network_internal:    ipam:      config:        - subnet: 10.0.2.0/24    internal: True```Running stack deploy with this compose file generates the following:```$ docker stack deploy -c docker-compose-internal-network.yml testCreating network test_network_internalCreating service test_linuxError response from daemon: rpc error: code = 3 desc = Service cannot be explicitly attached to ""test_network_internal"" network which is a swarm internal network```**Describe the results you received:**I get an error stating that the service cannot be attached to the network which is a swarm internal network.**Describe the results you expected:**I expect the service to be attached to the network.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```$ docker versionClient: Version:      17.03.1-ce API version:  1.27 Go version:   go1.7.5 Git commit:   c6d412e Built:        Tue Mar 28 00:40:02 2017 OS/Arch:      darwin/amd64Server: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:10:54 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```$ docker infoContainers: 7 Running: 3 Paused: 0 Stopped: 4Images: 5Server Version: 17.05.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 43 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: csiw0nl1oe9kixde3wlpec84r Is Manager: true ClusterID: qwv5h0qgjdar0oeg7dmk86psm Managers: 3 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 10.0.1.150 Manager Addresses:  10.0.1.131:2377  10.0.1.149:2377  10.0.1.150:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-62-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 992.3 MiBName: refsi-xID: HRHZ:OMEE:U5BX:WUVJ:2JML:HZZD:SU77:C6TC:BBF7:RYVL:3KSS:KVXPDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportLabels: provider=genericExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Docker is running in a Ubuntu VirtualBox vm.  The swarm has 3 nodes in it.
"
33334,0,1529,0,0,0,dmitrykuzmenkov,0,"title:Docker kill hangs when using different STOPSIGNAL and restart policy ALWAYS. description:**Description**When you define --stop-signal to SIGTERM (it could be SIGINT or whatever not default SIGKILL) and --restart always policy and use `docker kill` on that container `docker kill` does not exit and hangs forever but container killed and started again.**Steps to reproduce the issue:**1. `docker run --restart always --stop-signal SIGTERM --name test.stopsignal -it centos:7 python -m SimpleHTTPServer 8000`2. `docker kill test.stopsignal`3. Last command hangs forever while real container was killed and started again.All works fine with stop signal redefined and no --restart always argument**Describe the results you received:**Docker kill does not exit**Describe the results you expected:**Docker kill exit on success not hangs**Additional information you deem important (e.g. issue happens only occasionally):**Seems so the problem is in backend.**Output of `docker version`:**```Client: Version:      17.04.0-ce API version:  1.28 Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:07:42 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-ce API version:  1.28 (minimum version 1.12) Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:07:42 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 65 Running: 52 Paused: 0 Stopped: 13Images: 1152Server Version: 17.04.0-ceStorage Driver: overlay Backing Filesystem: extfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary:containerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-53-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.26GiBName: zoob0ID: NPQZ:ZGE6:CQTV:545M:FUHJ:X763:HE5U:XJF7:TAQZ:63ER:X6OU:XER5Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit supportWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```
"
33263,0,441,20,0,0,wenjianhn,0,"title:Failed to list checkpoints of a container. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->```[root@localhost ~]# docker checkpoint ls looperError response from daemon: checkpoint with name  already exists for container looper```**Steps to reproduce the issue:**1. docker run -d --name looper --security-opt seccomp:unconfined busybox           /bin/sh -c 'i=0; while true; do echo $i; i=$(expr $i + 1); sleep 1; done'2. docker checkpoint create looper checkpoint13. docker checkpoint ls looper**Describe the results you received:**```[root@localhost ~]# docker checkpoint ls looperError response from daemon: checkpoint with name  already exists for container looper```**Describe the results you expected:**```[root@localhost ~]# docker checkpoint ls looperCHECKPOINT NAMEcheckpoint1checkpoint2checkpoint3```**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Docker version 17.06.0-dev```**Output of `docker info`:**```(paste your output here)```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
33259,0,2066,44,1,0,dperny,0,"title:Ingress network from older versions is erroneously removed on `docker network prune`. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Doing `docker network prune` removes the ingress network if it is not currently being used, and it was created on an older version.**Steps to reproduce the issue:**<strike>1. `docker network prune`2. try to create service that uses ingress network</strike>See below: https://github.com/moby/moby/issues/33259#issuecomment-302252274**Describe the results you received:**Ingress network is gone**Describe the results you expected:**Ingress network should not be deleted.[I don't know what I expected](http://i0.kym-cdn.com/photos/images/newsfeed/000/617/851/56d.gif)**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.05.0-ce-rc1 API version:  1.29 Go version:   go1.7.5 Git commit:   2878a85 Built:        Tue Apr 11 20:55:05 2017 OS/Arch:      darwin/amd64Server: Version:      17.05.0-ce-rc1 API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   2878a85 Built:        Tue Apr 11 20:55:05 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 1197Server Version: 17.05.0-ce-rc1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 1008 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: wymf3aau8jhl8rnbwajou3421 Is Manager: true ClusterID: u77uiync8qrec2zvbnbzf0iv7 Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.65.2 Manager Addresses:  192.168.65.2:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.21-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952GiBName: mobyID: IJDB:XKO7:BYSL:RIBX:DN3F:VFCX:6BUA:QZA3:WZXA:ALWV:PKDQ:7FC2Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 101 Goroutines: 257 System Time: 2017-05-17T21:57:04.327922388Z EventsListeners: 1No Proxy: *.local, 169.254/16Username: dpernyRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Docker for Mac
"
33222,0,4750,293,1,0,JonasKs,0,"title:Service Logs fails on scale down. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Scaling down a service and calling for the logs will make logs fail, with errors from the service. @dperny asked me to create a own issue for this [here](https://github.com/moby/moby/issues/33203#issuecomment-301618701). <!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1) `docker service create  --name my-web --publish 9091:80 --replicas 2 nginx`2) Generate some log and traffic: `httperf --server <server ip> --port <nginx port> --num-conns 1000 --rate 10 --hog`3) Scale up and down. I used a simple bash script resulting in this with 5 second delays between each:```my-web scaled to 8my-web scaled to 17my-web scaled to 7```4) Get log-lines while doing this.  `docker service logs my-web | wc -l`**Describe the results you received:**```ubuntu@manager-project2:~$ docker service logs my-web | wc -l589ubuntu@manager-project2:~$ docker service logs my-web | wc -l623ubuntu@manager-project2:~$ docker service logs my-web | wc -lerror from daemon in stream: Error grabbing logs: rpc error: code = 2 desc = warning: incomplete log stream. some logs could not be retrieved for the following reasons: rpc error: code = 13 desc = grpc: failed to unmarshal the received message proto: illegal wireType 7661ubuntu@manager-project2:~$ docker service logs my-web | wc -lpanic: runtime error: makeslice: len out of rangegoroutine 1 [running]:panic(0xd45620, 0xc4203bd300)	/usr/local/go/src/runtime/panic.go:500 +0x1a1strings.Repeat(0xe44138, 0x1, 0xffffffffffffffff, 0xc4203bd2f0, 0xd)	/usr/local/go/src/strings/strings.go:420 +0x49github.com/docker/docker/cli/command/service.(*taskFormatter).format(0xc420451260, 0x7fe81f680028, 0xc420012258, 0xc42046a019, 0x19, 0xc42046a04f, 0x19, 0xc42046a082, 0x19, 0x0, ...)	/usr/src/docker/.gopath/src/github.com/docker/docker/cli/command/service/logs.go:204 +0x4d5github.com/docker/docker/cli/command/service.(*logWriter).Write(0xc420451290, 0xc42045e008, 0xf9, 0x8001, 0x404, 0x0, 0x0)	/usr/src/docker/.gopath/src/github.com/docker/docker/cli/command/service/logs.go:243 +0x392github.com/docker/docker/pkg/stdcopy.StdCopy(0x15158e0, 0xc420451290, 0x15158e0, 0xc4204512c0, 0x1516ca0, 0xc42045c080, 0x0, 0x0, 0x0)	/usr/src/docker/.gopath/src/github.com/docker/docker/pkg/stdcopy/stdcopy.go:174 +0x36fgithub.com/docker/docker/cli/command/service.runLogs(0xc4203b37a0, 0xc42037b340, 0x0, 0x0)	/usr/src/docker/.gopath/src/github.com/docker/docker/cli/command/service/logs.go:147 +0x70egithub.com/docker/docker/cli/command/service.newLogsCommand.func1(0xc4203fb680, 0xc420436280, 0x1, 0x1, 0x0, 0x0)	/usr/src/docker/.gopath/src/github.com/docker/docker/cli/command/service/logs.go:50 +0x6dgithub.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).execute(0xc4203fb680, 0xc42000c1f0, 0x1, 0x1, 0xc4203fb680, 0xc42000c1f0)	/usr/src/docker/.gopath/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:646 +0x26dgithub.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc42007fd40, 0xc4203b6240, 0xc42035bef0, 0xc4200264c8)	/usr/src/docker/.gopath/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:742 +0x377github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).Execute(0xc42007fd40, 0xc42007fd40, 0x1517260)	/usr/src/docker/.gopath/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:695 +0x2bmain.main()	/usr/src/docker/.gopath/src/github.com/docker/docker/cmd/docker/docker.go:169 +0xcb```**Describe the results you expected:**The log to just increase, and not bug up. Doing the same without scaling down has no issues.**Additional information you deem important (e.g. issue happens only occasionally):**I have not been able to scale up/down with my script without having this issue, though I'm not entirely sure if it happens on first attempt on scale down. **Output of `docker version`:**```Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:10:54 2017 OS/Arch:      linux/amd64Server: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:10:54 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 7Server Version: 17.05.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: n9svkw9tmii4bsapyuwc7kfuy Is Manager: true ClusterID: 862oj158u0rlkgbekg73rqrhn Managers: 1 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 10.1.0.118 Manager Addresses:  10.1.0.118:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-36-genericOperating System: Ubuntu 16.04.1 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.859GiBName: manager-project2ID: LKPP:MZU6:2WDY:Q4TS:34WD:BEZT:CQYL:D6PJ:GYK2:QFHG:PITJ:L4WYDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Openstack cloud node, with two joined nodes as workers to the swarm. 
"
33216,0,25670,0,0,0,splytech,0,"title:External CA is not being accepted by new swarm node. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Following the little documentation for setting a swarmkit cluster based on the following URL:https://docs.docker.com/engine/reference/commandline/swarm_init/While I am using RPi's to do this, I am doing nothing more than setting up a basic swarm cluster using an external CA with the cfssl service.I am using a local compiled version of cfssl: cfssl version:Version: 1.2.0Revision: devRuntime: go1.8.1I could be doing something wrong but I am not sure what I am missing. It appears to be a bug and there isn't much on setting up an external CA with swarmkit.**Steps to reproduce the issue:**1. Setup a CA cert with cfssl, on the manager node:ca-csr.json:```{    ""CN"": ""piworkernet"",    ""hosts"": [        ""piworkernet.net"",        ""www.piworkernet.net""    ],    ""key"": {        ""algo"": ""rsa"",        ""size"": 2048    },    ""names"": [        {            ""C"": ""US"",            ""ST"": ""CA"",            ""L"": ""London"",        ""O"": ""piworkernet"",        ""OU"": ""pidocker""        }    ]}```To create the ca itself:```cfssl gencert -initca ca-csr.json | cfssljson -bare ca -```2. Setup the cert on both the manager and the worker node:Copy and update the ca certificates globally:```sudo cp ~/ca.pem /usr/local/share/ca-certificates/piworkernet.crtcd /usr/local/share/ca-certificates/sudo mkdir piworkernet && cd piworkernetsudo cp ~/ca.pem ./ca.crtsudo update-ca-certificates```Yes, I copied it twice because I am not sure which one dockerd will pick up.3. Start cfssl server on manager:NOTE: Local IP for the manager: 10.0.20.130Command:```cfssl serve -ca ca.pem -ca-key ca-key.pem -config ca-config.json -address=10.0.20.130 ```Output:```2017/05/16 01:33:53 [INFO] Initializing signer2017/05/16 01:33:53 [WARNING] couldn't initialize ocsp signer: open : no such file or directory2017/05/16 01:33:53 [INFO] endpoint '/api/v1/cfssl/gencrl' is enabled2017/05/16 01:33:53 [INFO] bundler API ready2017/05/16 01:33:53 [INFO] endpoint '/api/v1/cfssl/bundle' is enabled2017/05/16 01:33:53 [WARNING] endpoint 'ocspsign' is disabled: signer not initialized2017/05/16 01:33:53 [INFO] endpoint '/' is enabled2017/05/16 01:33:53 [INFO] endpoint '/api/v1/cfssl/info' is enabled2017/05/16 01:33:53 [WARNING] endpoint 'crl' is disabled: cert db not configured (missing -db-config)2017/05/16 01:33:53 [WARNING] endpoint 'revoke' is disabled: cert db not configured (missing -db-config)2017/05/16 01:33:53 [INFO] endpoint '/api/v1/cfssl/sign' is enabled2017/05/16 01:33:53 [INFO] endpoint '/api/v1/cfssl/scan' is enabled2017/05/16 01:33:53 [INFO] endpoint '/api/v1/cfssl/newcert' is enabled2017/05/16 01:33:53 [INFO] endpoint '/api/v1/cfssl/certinfo' is enabled2017/05/16 01:33:53 [INFO] endpoint '/api/v1/cfssl/init_ca' is enabled2017/05/16 01:33:53 [INFO] endpoint '/api/v1/cfssl/scaninfo' is enabled2017/05/16 01:33:53 [WARNING] endpoint 'authsign' is disabled: {""code"":5200,""message"":""Invalid or unknown policy""}2017/05/16 01:33:53 [INFO] setting up key / CSR generator2017/05/16 01:33:53 [INFO] endpoint '/api/v1/cfssl/newkey' is enabled2017/05/16 01:33:53 [INFO] Handler set up complete.2017/05/16 01:33:53 [INFO] Now listening on 10.0.20.130:8888```4. Init Swarm Cluster on manager node:```docker swarm init --advertise-addr 10.0.20.130 --external-ca protocol=cfssl,url=http://10.0.20.130:8888/api/v1/cfssl/sign```Log output during init, w/ debug mode on:```May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.328995224Z"" level=debug msg=""Calling GET /_ping""May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.593284786Z"" level=debug msg=""Calling GET /_ping""May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.597594217Z"" level=debug msg=""Calling POST /v1.29/swarm/init""May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.599448415Z"" level=debug msg=""form data: {\""AdvertiseAddr\"":\""10.0.20.130\"",\""AutoLockManagers\"":false,\""Availability\"":\""\"",\""ForceNewCluster\"":false,\""ListenAddr\"":\""0.0.0.0:2377\"",\""Spec\"":{\""CAConfig\"":{\""ExternalCAs\"":[{\""Protocol\"":\""cfssl\"",\""URL\"":\""http://10.0.20.130:8888/api/v1/cfssl/sign\""}]},\""Dispatcher\"":{},\""EncryptionConfig\"":{\""AutoLockManagers\"":false},\""Labels\"":null,\""Orchestration\"":{},\""Raft\"":{\""ElectionTick\"":0,\""HeartbeatTick\"":0},\""TaskDefaults\"":{}}}""May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.755405921Z"" level=debug msg=""generated CA key and certificate"" module=nodeMay 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.755650762Z"" level=debug msg=""no node credentials found in: /var/lib/docker/swarm/certificates/swarm-node.crt"" error=""open /var/lib/docker/swarm/certificates/swarm-node.key: no such file or directory"" module=nodeMay 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.837578689Z"" level=debug msg=""issued new TLS certificate"" module=""node/tls"" node.id=t5pusiwwxwrpy16wddkg1d7a3 node.role=swarm-managerMay 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.839163254Z"" level=debug msg=""new node credentials generated: /var/lib/docker/swarm/certificates/swarm-node.crt"" module=""node/tls"" node.id=t5pusiwwxwrpy16wddkg1d7a3 node.role=swarm-managerMay 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.857974396Z"" level=debug msg=""next certificate renewal scheduled for 1631h54m42.142117478s from now"" module=""node/tls"" node.id=t5pusiwwxwrpy16wddkg1d7a3 node.role=swarm-manager time=2017-07-23 01:30:00.000002708 +0000 UTCMay 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.889961534Z"" level=info msg=""Listening for connections"" addr=""[::]:2377"" module=node node.id=t5pusiwwxwrpy16wddkg1d7a3 proto=tcpMay 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.890043147Z"" level=info msg=""Listening for local connections"" addr=""/var/run/docker/swarm/control.sock"" module=node node.id=t5pusiwwxwrpy16wddkg1d7a3 proto=unixMay 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.905902864Z"" level=info msg=""7340972b77480346 became follower at term 0"" module=raft node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.906074216Z"" level=info msg=""newRaft 7340972b77480346 [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"" module=raft node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.906171194Z"" level=info msg=""7340972b77480346 became follower at term 1"" module=raft node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.912924764Z"" level=info msg=""7340972b77480346 is starting a new election at term 1"" module=raft node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.913175646Z"" level=info msg=""7340972b77480346 became candidate at term 2"" module=raft node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.913323769Z"" level=info msg=""7340972b77480346 received MsgVoteResp from 7340972b77480346 at term 2"" module=raft node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.913440695Z"" level=info msg=""7340972b77480346 became leader at term 2"" module=raft node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.913517049Z"" level=info msg=""raft.node: 7340972b77480346 elected leader 7340972b77480346 at term 2"" module=raft node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.916513525Z"" level=info msg=""Creating default ingress network"" module=node node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.921649404Z"" level=debug msg=""RequestPool(GlobalDefault, 10.255.0.0/16, , map[], false)""May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.921907474Z"" level=debug msg=""RequestAddress(GlobalDefault/10.255.0.0/16, <nil>, map[RequestAddressType:com.docker.network.gateway])""May 16 01:35:17 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:17.931283462Z"" level=debug msg=""Updating security config due to change in cluster Root CA"" cluster.id=yxar145djq2bswnhyv71cpokb method=""(*Server).UpdateRootCA"" module=ca node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.008212852Z"" level=debug msg=""(*Agent).run"" module=""node/agent"" node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.044459577Z"" level=debug msg=""(*session).start"" module=""node/agent"" node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.048695311Z"" level=debug msg=""Root CA updated successfully"" cluster.id=yxar145djq2bswnhyv71cpokb method=""(*Server).UpdateRootCA"" module=ca node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.048897288Z"" level=debug msg=""Updating security config due to change in cluster Root CA or cluster spec"" cluster.id=yxar145djq2bswnhyv71cpokb method=""(*Server).UpdateRootCA"" module=ca node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.052690422Z"" level=debug msg=""RequestAddress(GlobalDefault/10.255.0.0/16, <nil>, map[])""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.054578005Z"" level=debug msg=""node status updated"" method=""(*Dispatcher).processUpdates"" module=dispatcher node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.073626747Z"" level=debug method=""(*session).logSubscriptions"" module=""node/agent"" node.id=t5pusiwwxwrpy16wddkg1d7a3 session.id=ncb3w5ocs8enxwab8ckrrn1wfMay 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.075372874Z"" level=debug method=""(*session).watch"" module=""node/agent"" node.id=t5pusiwwxwrpy16wddkg1d7a3 session.id=ncb3w5ocs8enxwab8ckrrn1wfMay 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.075617246Z"" level=debug msg=""(*session).heartbeat"" module=""node/agent"" node.id=t5pusiwwxwrpy16wddkg1d7a3 session.id=ncb3w5ocs8enxwab8ckrrn1wfMay 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.075372926Z"" level=debug msg=""(*session).listen"" module=""node/agent"" node.id=t5pusiwwxwrpy16wddkg1d7a3 session.id=ncb3w5ocs8enxwab8ckrrn1wfMay 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.077254519Z"" level=debug msg=""node registered"" method=""(*LogBroker).ListenSubscriptions"" node=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.078274507Z"" level=debug method=""(*Dispatcher).Assignments"" node.id=t5pusiwwxwrpy16wddkg1d7a3 node.session=ncb3w5ocs8enxwab8ckrrn1wfMay 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.082916278Z"" level=info msg=""Initializing Libnetwork Agent Listen-Addr=0.0.0.0 Local-addr=10.0.20.130 Adv-addr=10.0.20.130 Remote-addr =""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.083101172Z"" level=debug msg=""(*worker).Assign"" len(assignments)=0 module=""node/agent"" node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.083331429Z"" level=debug msg=""(*worker).reconcileSecrets"" len(removedSecrets)=0 len(updatedSecrets)=0 module=""node/agent"" node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.083433095Z"" level=debug msg=""(*worker).reconcileTaskState"" len(removedTasks)=0 len(updatedTasks)=0 module=""node/agent"" node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.087128522Z"" level=debug msg=""agent: registered"" module=""node/agent"" node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.087562423Z"" level=info msg=""Initializing Libnetwork Agent Listen-Addr=0.0.0.0 Local-addr=10.0.20.130 Adv-addr=10.0.20.130 Remote-addr =""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.087976637Z"" level=info msg=""Gossip cluster hostname pi3coreserver-477a29027df3""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.088236426Z"" level=debug msg=""Encryption key 1: f153a""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.088301321Z"" level=debug msg=""Encryption key 2: 8f4f1""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.088353143Z"" level=debug msg=""Encryption key 3: 31cb9""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.091135768Z"" level=debug msg=""Initial encryption keys: [(key: 44332, tag: 0xce33) (key: 55585, tag: 0xce32) (key: a8ba1, tag: 0xce34)]""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.093016528Z"" level=debug msg=""Initial encryption keys: [(key: 44332, tag: 0xce33) (key: 55585, tag: 0xce32) (key: a8ba1, tag: 0xce34)]""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.094449845Z"" level=debug msg=""Allocating IPv4 pools for network ingress (da6bdp3kszj1podctsott7wiw)""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.094595573Z"" level=debug msg=""RequestPool(LocalDefault, 10.255.0.0/16, , map[], false)""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.094941402Z"" level=debug msg=""RequestAddress(LocalDefault/10.255.0.0/16, 10.255.0.1, map[RequestAddressType:com.docker.network.gateway])""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.095132702Z"" level=debug msg=""overlay: Received vxlan IDs: 4096""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.095265409Z"" level=debug msg=""/sbin/iptables, [--wait -t mangle -C OUTPUT -p udp --dport 4789 -m u32 --u32 0>>22&0x3C@12&0xFFFFFF00=1048576 -j MARK --set-mark 13681891]""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.111976626Z"" level=debug msg=""Updating security config due to change in cluster Root CA or cluster spec"" cluster.id=yxar145djq2bswnhyv71cpokb method=""(*Server).UpdateRootCA"" module=node node.id=t5pusiwwxwrpy16wddkg1d7a3May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.118576760Z"" level=debug msg=""Calling GET /v1.29/nodes/t5pusiwwxwrpy16wddkg1d7a3""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.127713375Z"" level=debug msg=""/sbin/iptables, [--wait -t filter -C INPUT -m policy --dir in --pol ipsec -p udp --dport 4789 -m u32 --u32 0>>22&0x3C@12&0xFFFFFF00=1048576 -j ACCEPT]""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.130717820Z"" level=debug msg=""Calling GET /v1.29/swarm""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.139022778Z"" level=debug msg=""/sbin/iptables, [--wait -t filter -C INPUT -p udp --dport 4789 -m u32 --u32 0>>22&0x3C@12&0xFFFFFF00=1048576 -j DROP]""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.150966185Z"" level=debug msg=""pi3coreserver-477a29027df3: joined network da6bdp3kszj1podctsott7wiw""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.151092277Z"" level=debug msg=""pi3coreserver-477a29027df3: Initiating bulk sync with nodes [pi3coreserver-477a29027df3]""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.151707270Z"" level=debug msg=""/sbin/iptables, [--wait -t filter -L DOCKER-INGRESS]""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.357188070Z"" level=debug msg=""Assigning addresses for endpoint ingress-endpoint's interface on network ingress""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.357351662Z"" level=debug msg=""RequestAddress(LocalDefault/10.255.0.0/16, 10.255.0.2, map[])""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.363363001Z"" level=debug msg=""Assigning addresses for endpoint ingress-endpoint's interface on network ingress""May 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.370504118Z"" level=error msg=""Failed to create testvxlan interface: error creating vxlan interface: operation not supported""May 16 01:35:18 pi3coreserver kernel: [315751.833142] br0: renamed from ov-001000-da6bdMay 16 01:35:18 pi3coreserver dockerd[6236]: time=""2017-05-16T01:35:18.590359599Z"" level=error msg=""Failed joining ingress sandbox to ingress endpoint: subnet sandbox join failed for \""10.255.0.0/16\"": error creating vxlan interface: operation not supported""```5. Join the worker node:Command on worker:```docker swarm join \>     --token SWMTKN-1-3m1d6ra0gpj4gs5dyo1o5pd3t521m5a9t102zk18ojev2deqcd-8gltbkjrl8y98e0mrq33nljbz \>     10.0.20.130:2377```Log during worker failure:```May 16 01:26:36 pizdocker1 systemd[1]: Started Docker Application Container Engine.May 16 01:26:36 pizdocker1 dockerd[8522]: time=""2017-05-16T01:26:36.554780842Z"" level=info msg=""API listen on /var/run/docker.sock""May 16 01:26:36 pizdocker1 dockerd[8522]: time=""2017-05-16T01:26:36.555594842Z"" level=info msg=""API listen on 10.0.11.2:2376""May 16 01:26:43 pizdocker1 dockerd[8522]: time=""2017-05-16T01:26:43.066865555Z"" level=debug msg=""Calling GET /_ping""May 16 01:26:43 pizdocker1 dockerd[8522]: time=""2017-05-16T01:26:43.099027539Z"" level=debug msg=""Calling GET /v1.29/info""May 16 01:40:34 pizdocker1 dockerd[8522]: time=""2017-05-16T01:40:34.302342476Z"" level=debug msg=""Calling GET /_ping""May 16 01:40:34 pizdocker1 rsyslogd-2007: action 'action 17' suspended, next retry is Tue May 16 01:42:04 2017 [try http://www.rsyslog.com/e/2007 ]May 16 01:40:34 pizdocker1 dockerd[8522]: time=""2017-05-16T01:40:34.315925469Z"" level=debug msg=""Calling GET /v1.29/info""May 16 01:40:59 pizdocker1 dockerd[8522]: time=""2017-05-16T01:40:59.448975611Z"" level=debug msg=""Calling GET /_ping""May 16 01:41:00 pizdocker1 dockerd[8522]: time=""2017-05-16T01:41:00.060481322Z"" level=debug msg=""Calling GET /_ping""May 16 01:41:00 pizdocker1 dockerd[8522]: time=""2017-05-16T01:41:00.079034313Z"" level=debug msg=""Calling POST /v1.29/swarm/join""May 16 01:41:00 pizdocker1 dockerd[8522]: time=""2017-05-16T01:41:00.083550311Z"" level=debug msg=""form data: {\""AdvertiseAddr\"":\""\"",\""Availability\"":\""\"",\""JoinToken\"":\""*****\"",\""ListenAddr\"":\""0.0.0.0:2377\"",\""RemoteAddrs\"":[\""10.0.20.130:2377\""]}""May 16 01:41:00 pizdocker1 dockerd[8522]: time=""2017-05-16T01:41:00.458580134Z"" level=debug msg=""retrieved remote CA certificate: /var/lib/docker/swarm/certificates/swarm-root-ca.crt"" module=nodeMay 16 01:41:00 pizdocker1 dockerd[8522]: time=""2017-05-16T01:41:00.462288132Z"" level=debug msg=""downloaded CA certificate"" module=nodeMay 16 01:41:00 pizdocker1 dockerd[8522]: time=""2017-05-16T01:41:00.462953132Z"" level=debug msg=""no node credentials found in: /var/lib/docker/swarm/certificates/swarm-node.crt"" error=""open /var/lib/docker/swarm/certificates/swarm-node.key: no such file or directory"" module=nodeMay 16 01:41:01 pizdocker1 dockerd[8522]: time=""2017-05-16T01:41:01.038571860Z"" level=error msg=""failed to request save new certificate"" error=""x509: certificate signed by unknown authority"" module=""node/tls""May 16 01:41:01 pizdocker1 dockerd[8522]: time=""2017-05-16T01:41:01.042770858Z"" level=error msg=""cluster exited with error: x509: certificate signed by unknown authority""May 16 01:41:01 pizdocker1 dockerd[8522]: time=""2017-05-16T01:41:01.048404855Z"" level=error msg=""Handler for POST /v1.29/swarm/join returned error: x509: certificate signed by unknown authority""```Log from the manager for the same event:```May 16 01:39:30 pi3coreserver dockerd[6236]: time=""2017-05-16T01:39:30.551167183Z"" level=debug msg=""Calling GET /_ping""May 16 01:39:30 pi3coreserver dockerd[6236]: time=""2017-05-16T01:39:30.553821841Z"" level=debug msg=""Calling GET /v1.29/swarm""May 16 01:39:30 pi3coreserver dockerd[6236]: time=""2017-05-16T01:39:30.560401350Z"" level=debug msg=""Calling GET /v1.29/info""May 16 01:39:30 pi3coreserver dockerd[6236]: time=""2017-05-16T01:39:30.606321460Z"" level=debug msg=""Calling GET /v1.29/nodes/t5pusiwwxwrpy16wddkg1d7a3""May 16 01:39:30 pi3coreserver dockerd[6236]: time=""2017-05-16T01:39:30.613553098Z"" level=debug msg=""Calling GET /v1.29/swarm""May 16 01:39:56 pi3coreserver dockerd[6236]: time=""2017-05-16T01:39:56.004692216Z"" level=debug msg=""Calling GET /_ping""May 16 01:39:56 pi3coreserver dockerd[6236]: time=""2017-05-16T01:39:56.007612131Z"" level=debug msg=""Calling GET /v1.29/info""May 16 01:41:00 pi3coreserver dockerd[6236]: time=""2017-05-16T01:41:00.888428027Z"" level=debug msg=""RequestAddress(GlobalDefault/10.255.0.0/16, <nil>, map[])""May 16 01:41:00 pi3coreserver rsyslogd-2007: action 'action 17' suspended, next retry is Tue May 16 01:42:30 2017 [try http://www.rsyslog.com/e/2007 ]May 16 01:41:00 pi3coreserver dockerd[6236]: time=""2017-05-16T01:41:00.888368809Z"" level=debug msg=""new certificate entry added"" method=IssueNodeCertificate node.id=lupxyz3540mozq64ehvze47k3 node.role=WORKERMay 16 01:41:00 pi3coreserver dockerd[6236]: time=""2017-05-16T01:41:00.902339277Z"" level=debug msg=""started watching for certificate updates"" method=NodeCertificateStatus node.id=lupxyz3540mozq64ehvze47k3 status={PENDING }May 16 01:41:01 pi3coreserver dockerd[6236]: time=""2017-05-16T01:41:01.025868101Z"" level=debug msg=""certificate issued"" method=""(*Server).signNodeCert"" module=ca node.id=lupxyz3540mozq64ehvze47k3 node.role=WORKERMay 16 01:41:01 pi3coreserver dockerd[6236]: time=""2017-05-16T01:41:01.127878207Z"" level=debug msg=""certificate issued"" method=""(*Server).signNodeCert"" module=ca node.id=lupxyz3540mozq64ehvze47k3 node.role=WORKER```Log output from the cfssl server:```2017/05/16 01:41:00 [INFO] signature request received2017/05/16 01:41:01 [INFO] signed certificate with serial number 3194110672492063024776464054487830186255882844862017/05/16 01:41:01 [INFO] wrote response2017/05/16 01:41:01 [INFO] 10.0.20.130:57464 - ""POST /api/v1/cfssl/sign"" 2002017/05/16 01:41:01 [INFO] signature request received2017/05/16 01:41:01 [INFO] signed certificate with serial number 5364779455271959959957923219032260897526226705492017/05/16 01:41:01 [INFO] wrote response2017/05/16 01:41:01 [INFO] 10.0.20.130:57464 - ""POST /api/v1/cfssl/sign"" 200```**Describe the results you received:**The result was a simple and cryptic error from the worker:```Error response from daemon: x509: certificate signed by unknown authority```**Describe the results you expected:**A clean connection from the swarm worker to the manager with the external CA.**Additional information you deem important (e.g. issue happens only occasionally):**This is extremely repeatable. I put the cert all over the place on the system as well as added certs to the daemon config like so:```{        ""hosts"": [""tcp://10.0.20.130:2376"", ""unix:///var/run/docker.sock""],        ""dns"": [""8.8.8.8"", ""8.8.4.4""],        ""tlsverify"": true,        ""tlscacert"": ""/opt/certs/ca.pem"",        ""tlscert"": ""/opt/certs/pi3coreserver.pem"",        ""tlskey"": ""/opt/certs/pi3coreserver-key.pem"",        ""debug"": true}```I put the cert in the following locations:```/usr/local/share/ca-certificates/ca.crt/usr/local/share/ca-certificates/ca-local.crt/usr/local/share/ca-certificates/piworkernet.crt/usr/local/share/ca-certificates/piworkernet/ca.crt/etc/docker/certs.d/piworkernet/ca.crt```**Output of `docker version`:**For manager node:```Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:30:54 2017 OS/Arch:      linux/armServer: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:30:54 2017 OS/Arch:      linux/arm Experimental: false```For client node:```Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:30:54 2017 OS/Arch:      linux/armServer: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   89658be Built:        Thu May  4 22:30:54 2017 OS/Arch:      linux/arm Experimental: false```**Output of `docker info`:**For manager node after worker node connection attempt:```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 3Server Version: 17.05.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: t5pusiwwxwrpy16wddkg1d7a3 Is Manager: true ClusterID: yxar145djq2bswnhyv71cpokb Managers: 1 Nodes: 2 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  External CAs:    cfssl: http://10.0.20.130:8888/api/v1/cfssl/sign Node Address: 10.0.20.130 Manager Addresses:  10.0.20.130:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faKernel Version: 4.4.50-v7+Operating System: Raspbian GNU/Linux 8 (jessie)OSType: linuxArchitecture: armv7lCPUs: 4Total Memory: 925.5MiBName: pi3coreserverID: 3ZNS:66AM:54YT:D5BN:Z7GU:SPL4:ANPK:AA4B:5HCJ:2LCH:F7TN:YRTCDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 30 Goroutines: 124 System Time: 2017-05-16T01:49:59.739391665Z EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit supportWARNING: No kernel memory limit supportWARNING: No cpu cfs quota supportWARNING: No cpu cfs period supportWARNING: No cpuset support```For worker node after connection attempt:```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 2Server Version: 17.05.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faKernel Version: 4.9.24+Operating System: Raspbian GNU/Linux 8 (jessie)OSType: linuxArchitecture: armv6lCPUs: 1Total Memory: 481.7MiBName: pizdocker1ID: OBJL:BQ4U:YEDI:I4T2:VEIL:G5DA:3GJD:MUEX:T7AM:3JMQ:GOHT:IIXNDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 17 Goroutines: 23 System Time: 2017-05-16T01:53:55.055424678Z EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit supportWARNING: No cpu cfs quota supportWARNING: No cpu cfs period supportWARNING: No cpuset support```**Additional environment details (AWS, VirtualBox, physical, etc.):**There are 2 RPI's in use but it appears to matter little to allow this to work.
"
33181,1,2764,5,0,0,briantd,0,"title:Docker stack deploy creates external volumes if they do not already exist. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!---->Running `docker stack deploy -c <stackfile>` on a stackfile with external volumes results in the creation of those volumes.**Steps to reproduce the issue:**1. Confirm named-volume does NOT exist (i.e. `docker volume ls`)2. Prepare a stackfile with a service using an externally declared named-volume (i.e. `external: true`)3. Deploy stackfile and observe the creation of a local named-volume```$ docker volume lsDRIVER              VOLUME NAME$ cat dc-test-external-exits.ymlversion: ""3.1""services:  aservice:    image: busybox    volumes:      - test-vol:/tmp:zvolumes:  test-vol:    external: true$ docker stack deploy -c dc-test-external-exits.yml myappCreating network myapp_defaultCreating service myapp_aservice$ docker volume lsDRIVER              VOLUME NAMElocal               test-vol```**Describe the results you received:**`docker stack deploy` invocation succeeds; external named-volume created using local driver on nodes where the service was deployed.**Describe the results you expected:**`docker stack deploy` invocation fails with a message explaining the external named-volume could not be found.Failing when external **volumes** are missing would be consistent with how external **networks** and external **secrets** are handled.For example...```swarm-manager000000:~$ docker stack deploy -c dc-test-external-network-exits.yml myappnetwork ""myextnet"" is declared as external, but could not be found. You need to create the network before the stack is deployed (with overlay driver)```**Additional information you deem important (e.g. issue happens only occasionally):**Related -- this behavior is inconsistent with the documentation.  I filed a separate issue there --> https://github.com/docker/docker.github.io/issues/3141**Output of `docker version`:**```swarm-manager000000:~$ docker versionClient: Version:      17.04.0-ce API version:  1.28 Go version:   go1.7.5 Git commit:   4845c56 Built:        Tue Apr  4 00:37:25 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-ce API version:  1.28 (minimum version 1.12) Go version:   go1.7.5 Git commit:   4845c56 Built:        Tue Apr  4 00:37:25 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```swarm-manager000000:~$ docker infoContainers: 8 Running: 6 Paused: 0 Stopped: 2Images: 12Server Version: 17.04.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: syslogCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: h35071xklgf3x0cmpoh8wk2z0 Is Manager: true ClusterID: k859559qob9bdrm7j3vrcj9j3 Managers: 3 Nodes: 5 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 10.0.0.6 Manager Addresses:  10.0.0.6:2377  10.0.0.7:2377  10.0.0.8:2377Runtimes: runcDefault Runtime: runcInit Binary:containerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.19-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 6.794GiBName: swarm-manager000000ID: HJ5Y:V7C3:WFMA:BDYO:A3K3:5L2P:J5EK:ZILC:NO7O:VO7R:XI2D:KMJ5Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 89 Goroutines: 170 System Time: 2017-05-12T19:27:44.773838769Z EventsListeners: 1Registry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**This has been tested using Docker Azure.
"
33176,0,0,290,0,0,tonistiigi,0,"title:builder: workdir does not get reset between stages. description:https://github.com/linuxkit/linuxkit/issues/1807
"
33107,0,863,0,0,0,plebowski,0,"title:Builder skips changed files on COPY or ADD and uses cache. description:**DESCRIPTION**Builder skips changed files on COPY or ADD unless adding a new file or changing dockerfile**Steps to reproduce the issue:**1. Install docker on Windows Server 20162. Run a build with dockerfile copying/adding a directory to a container3. Change something in one of the files in the source folder4. Run the same build again and notice docker used cache not including changes made in step 3**Describe the results you received:**Docker skipped changes in the source folder and used cached resources.**Describe the results you expected:**Expected docker not to use cache on the copy/add step when changes were made in sources folder.**Additional information you deem important (e.g. issue happens only occasionally):**Originaly i stumbled upon this problem while testing VSTS integration with docker. When i had whole environment ready (agent with docker, docker host and a repository) i noticed that application that i deployed on Windows Server 2016 didn't want to work. When i checked everything i noticed that no changes are being made on neext builds after the initial one UNLESS i change something in the dockerfile (like changing copy to add) or add new files to the sources (then the build noticed changes and properly rebuilded the step). If you look at vsts docker page in the comments on 3/29/2017 theres a user who has exact same issue https://marketplace.visualstudio.com/items?itemName=ms-vscs-rm.docker.Another weird thing worth mentioning is that originaly this error occured to me at version 1.12 beta which came from Windows Server role installation. When i updated to current version 17.03.1 nothing has changed.**Output of `docker version`:**```Docker version 17.03.1-ee-3, build 3fcee33```**Output of `docker info`:**```Containers: 10 Running: 0 Paused: 0 Stopped: 10Images: 23Server Version: 17.03.1-ee-3Storage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: l2bridge l2tunnel nat null overlay transparentSwarm: inactiveDefault Isolation: processKernel Version: 10.0 14393 (14393.953.amd64fre.rs1_release_inmarket.170303-1614)Operating System: Windows Server 2016 DatacenterOSType: windowsArchitecture: x86_64CPUs: 1Total Memory: 3.5 GiBName: *******ID: QKZX:YNWS:EK57:L2W3:QXK5:6K2E:LWMB:RPVH:SLD6:AARX:WA55:M6LPDocker Root Dir: C:\ProgramData\dockerDebug Mode (client): falseDebug Mode (server): falseUsername: *********Registry: https://**************Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Windows Server 2016
"
33101,0,1780,300,0,0,tianon,1,"title:TTY Output Regression. description:**Description**When using a recent `master` build including https://github.com/moby/moby/pull/33007 (to help kick the tires on the updated console-handling code), TTY output comes out garbled (presumably due to the lack of `\r`):```console$ ./docker -H tcp://docker:2375 run -it --rm bashbash-4.4# echo hi                 hi                   bash-4.4# ```**Steps to reproduce the issue:**1. create a master build (builds from https://master.dockerproject.org appear to be broken since https://github.com/moby/moby/pull/32694 was merged)2. launch `dockerd`3. run a container with an interactive shell and then invoke a command or two**Describe the results you received:**Cascading output!**Describe the results you expected:**Output aligned on the left margin, as in previous releases.**Output of `docker version`:**```console$ ./docker -H tcp://docker:2375 versionClient: Version:      library-import API version:  1.30 Go version:   go1.8.1 Git commit:   library-import Built:        library-import OS/Arch:      linux/amd64Server: Version:      17.06.0-dev API version:  1.30 (minimum version 1.12) Go version:   go1.8.1 Git commit:   4b846a1 Built:        Tue May  9 05:00:50 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```console$ ./docker -H tcp://docker:2375 infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 1Server Version: 17.06.0-devStorage Driver: vfsLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: d24f39e203aa6be4944f06dd0fe38a618a36c764runc version: 992a5be178a62e026f4069f443c6164912adbf09init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.4.63-gentooOperating System: Alpine Linux v3.5 (containerized)OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.4GiBName: 33784326e3d3ID: QKJH:XFQL:UCOR:56QQ:RZES:4YEQ:625G:3RQF:BAJJ:3TUW:Z4IE:GKE6Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: tianonRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**I'm running the daemon via Docker-in-Docker, but my client is running directly on the host (connecting via TCP).  I also tried running my host's Docker client (17.04.0-ce) against the master daemon and got the same results.**Edit:** I've reproduced on both `4.4.63-gentoo` and `4.9.0-2-amd64` (from Debian).cc @crosbymichael @cyphar
"
33084,0,2147,123,0,1,cyphar,0,"title:docker exec -it with no TTY leaks execids. description:**NOTE** I've already debugged and fixed this problem. I'll submit a patch later (though it'll land in https://github.com/docker/cli).**Steps to reproduce the issue:**1. Do `docker exec -it` in a situation with no TTY.2. Inspect the container you're execing.**Describe the results you received:**The number of execIDs grows.**Describe the results you expected:**There should be none.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.04.0-ce API version:  1.28 Go version:   go1.7.5 Git commit:   78d1802 Built:        Thu Apr 27 14:10:53 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-ce API version:  1.28 (minimum version 1.12) Go version:   go1.7.5 Git commit:   78d1802 Built:        Thu Apr 27 14:10:53 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 12 Running: 0 Paused: 0 Stopped: 12Images: 186Server Version: 17.04.0-ceStorage Driver: devicemapper Pool Name: docker-0:41-8367155-pool Pool Blocksize: 65.54kB Base Device Size: 10.74GB Backing Filesystem: ext4 Data file: /dev/loop0 Metadata file: /dev/loop1 Data Space Used: 14.59GB Data Space Total: 107.4GB Data Space Available: 88.35GB Metadata Space Used: 14.86MB Metadata Space Total: 2.147GB Metadata Space Available: 2.133GB Thin Pool Minimum Free Space: 10.74GB Udev Sync Supported: true Deferred Removal Enabled: false Deferred Deletion Enabled: false Deferred Deleted Device Count: 0 Data loop file: /var/lib/docker/devicemapper/devicemapper/data Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata Library Version: 1.03.01 (2017-04-13)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: oci runcDefault Runtime: runcInit Binary: containerd version:  (expected: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73)runc version: N/A (expected: 9c2d8d184e5da67c95d601382adf14862e4f2228)init version: N/A (expected: 949e6facb77383876aeff8a6944dde66b3089574)Security Options: apparmor seccomp  Profile: defaultKernel Version: 4.10.12-1-defaultOperating System: openSUSE TumbleweedOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.69GiBName: baradurID: DOHI:RAQ5:MYV5:73JL:7UHU:6NXS:RWGD:IQ7D:IQZ2:COCW:BWJ6:HHYNDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
33067,0,616,23,0,0,jeverling,0,"title:docker build shows a warning for predefined ARG variables. description:**Description**I get a warning like `[Warning] One or more build-args [https_proxy] were not consumed` for variables that are predefined according to https://docs.docker.com/engine/reference/builder/#arg**Steps to reproduce the issue:**1. Create a minimal Dockerfile like this:```FROM busyboxARG http_proxyRUN env```2. Build this Dockerfile, passing `http_proxy` and `https_proxy`:```docker build --build-arg http_proxy=http_proxy --build-arg https_proxy=https_proxy -t deleteme .```**Describe the results you received:**I got a warning```    [Warning] One or more build-args [https_proxy] were not consumed```despite `https_proxy` being one of the predefined ARG variables, and it being actually set in the build env. **Describe the results you expected:**I don't expect to see a warning for predefined ARG variables**Output of `docker version`:**```Client: Version:      17.05.0-ce API version:  1.29 Go version:   go1.8.1 Git commit:   89658bed64 Built:        Fri May  5 22:40:58 2017 OS/Arch:      linux/amd64Server: Version:      17.05.0-ce API version:  1.29 (minimum version 1.12) Go version:   go1.8.1 Git commit:   89658bed64 Built:        Fri May  5 22:40:58 2017 OS/Arch:      linux/amd64 Experimental: false```
"
33021,0,2571,0,0,1,bparker98,0,"title:HEALTHCHECK fails due to ""invalid environment"". description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**In #31491 a change was made to bring environment variables into a HEALTHCHECK. However, proper checking is not done and if you have an environment variable without a value you get the following error:```rpc error: code = 2 desc = oci runtime error: exec failed: container_linux.go:247: starting container process caused \""invalid environment 'FOOBAR'\""\n""```In the file daemon/container.go: (https://github.com/moby/moby/blob/17.04.x/daemon/container.go#L240) there is a call to opts.ValidateEnv() call to ensure that no bad environment variables are passed down to the container. This should be done in daemon/health.go (https://github.com/moby/moby/blob/17.04.x/daemon/health.go#L81) in order to prevent health checks from failing when there is no value for an environment variable.This is a problem from 17.03.1 onward.This is preventing us from upgrading to the latest version of docker-ce, and a quick fix would be appreciated!<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. Create an image with this Dockerfile```FROM alpine:latestHEALTHCHECK --interval=5s --timeout=5s --retries=5 CMD /bin/sh -c ""sleep 1""ENTRYPOINT /bin/sh -c ""sleep 600""```And build it`docker build -t env_test .`2. Run the container with the -e parameter`docker run -e FOOBAR env_test`3. See that the container never becomes healthy with `docker ps`**Describe the results you received:**The container never becomes healthy when viewing it with `docker ps` and the docker logs contain the following lines:```May 04 10:50:23 cake dockerd[7933]: time=""2017-05-04T10:50:23.949217373-06:00"" level=warning msg=""Health check for container ce3525412a4a1b31cfb9de8ae8055cb1e9606635f24a6eb0726ec4ece03c3c90 error: rpc error: code = 2 desc = oci runtime error: exec failed: container_linux.go:247: starting container process caused \""invalid environment 'FOOBAR'\""\n""```**Describe the results you expected:**The healthcheck would pass and the container would become healthy.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.04.0-ce API version:  1.28 Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:07:42 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-ce API version:  1.28 (minimum version 1.12) Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:07:42 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 1 Running: 0 Paused: 0 Stopped: 1Images: 548Server Version: 17.04.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 1354 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: ckkq4hik2h150qnxm238w7ik6 Is Manager: true ClusterID: 17gwd1qpd0rtyvdzwbvi810i7 Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 172.19.9.98 Manager Addresses:  172.19.9.98:2377Runtimes: runcDefault Runtime: runcInit Binary: containerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-75-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 22.51GiBName: cakeID: A4YB:3DTQ:L64X:TUHB:FZKK:NYL6:YW62:HCEX:SH3S:VKWM:B65H:ZTQ7Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Ubuntu 16.04
"
32974,0,26203,0,0,0,cyli,0,"title:dockerd libnetwork panic during shutdown. description:Saw this in a powerpc `DockerSwarmSuite.TestSwarmClusterRotateUnlockKey` test failure:  https://jenkins.dockerproject.org/job/Docker-PRs-powerpc/2421/consoleDownloading the logs, I see on one of the daemons:```time=""2017-05-02T18:09:29.155646000Z"" level=info msg=""shutting down certificate renewal routine"" module=""node/tls"" node.id=hn06lqptpi9ti0y9lfovfr1b0 node.role=swarm-manager time=""2017-05-02T18:09:29.155672000Z"" level=info msg=""Stopping manager"" module=node node.id=hn06lqptpi9ti0y9lfovfr1b0 time=""2017-05-02T18:09:29.155903000Z"" level=debug msg=""(*Agent).run exited"" module=""node/agent"" node.id=hn06lqptpi9ti0y9lfovfr1b0 time=""2017-05-02T18:09:29.156142000Z"" level=debug msg=""stop transport"" time=""2017-05-02T18:09:29.156607000Z"" level=info msg=""Manager shut down"" module=node node.id=hn06lqptpi9ti0y9lfovfr1b0 time=""2017-05-02T18:09:29.156735000Z"" level=info msg=""Initializing Libnetwork Agent Listen-Addr=0.0.0.0 Local-addr=127.0.0.1 Adv-addr=127.0.0.1 Data-addr= Remote-addr-list=[127.0.0.1 127.0.0.1]"" time=""2017-05-02T18:09:29.156724000Z"" level=error msg=""cluster exited with error: manager stopped: context canceled"" time=""2017-05-02T18:09:29.156800000Z"" level=info msg=""Gossip cluster hostname 04a5c2ed704d-6c4078152bb1"" time=""2017-05-02T18:09:29.156795000Z"" level=debug msg=""start clean shutdown of all containers with a 15 seconds timeout..."" time=""2017-05-02T18:09:29.156837000Z"" level=debug msg=""Encryption key 1: dc120"" time=""2017-05-02T18:09:29.156850000Z"" level=debug msg=""Encryption key 2: 57d28"" time=""2017-05-02T18:09:29.156855000Z"" level=debug msg=""start clean shutdown of cluster resources..."" time=""2017-05-02T18:09:29.156865000Z"" level=debug msg=""Encryption key 3: 2b579"" panic: runtime error: index out of rangegoroutine 175 [running]:panic(0x11489bc0, 0xc420016090)	/usr/local/go/src/runtime/panic.go:500 +0x3a8github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).getKeys(0xc42000ae00, 0x116d9dca, 0x10, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/agent.go:269 +0x3b4github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).agentInit(0xc42000ae00, 0xc42076c450, 0x7, 0xc420a5a8f0, 0x9, 0xc420a5a8f0, 0x9, 0x0, 0x0, 0x0, ...)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/agent.go:333 +0x6a8github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).agentSetup(0xc42000ae00, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/agent.go:223 +0x59cgithub.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).clusterAgentInit(0xc42000ae00)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:326 +0x184created by github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).SetClusterProvider	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:252 +0xd4goroutine 1 [select]:main.shutdownDaemon(0xc42039a600)	/go/src/github.com/docker/docker/cmd/dockerd/daemon.go:398 +0x30cmain.(*DaemonCli).start(0xc420489e30, 0xc420489e00, 0x116e7f39, 0x17, 0xc420065800, 0xc420011090, 0xc42038c750, 0x0, 0x0)	/go/src/github.com/docker/docker/cmd/dockerd/daemon.go:336 +0x1f88main.runDaemon(0x11473e00, 0x116e7f39, 0x17, 0xc420065800, 0xc420011090, 0xc42038c750, 0x0, 0x0)	/go/src/github.com/docker/docker/cmd/dockerd/docker.go:91 +0x1c0main.newDaemonCommand.func1(0xc4200a8900, 0xc42039e460, 0x0, 0xe, 0x0, 0x0)	/go/src/github.com/docker/docker/cmd/dockerd/docker.go:42 +0x98github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).execute(0xc4200a8900, 0xc42000c100, 0xe, 0xe, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:646 +0x558github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc4200a8900, 0xc4200a8900, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:742 +0x40cgithub.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).Execute(0xc4200a8900, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:695 +0x34main.main()	/go/src/github.com/docker/docker/cmd/dockerd/docker.go:118 +0x170goroutine 17 [syscall, locked to thread]:runtime.goexit()	/usr/local/go/src/runtime/asm_ppc64x.s:1095 +0x4goroutine 6 [syscall]:os/signal.signal_recv(0x1207cc60)	/usr/local/go/src/runtime/sigqueue.go:116 +0x270os/signal.loop()	/usr/local/go/src/os/signal/signal_unix.go:22 +0x24created by os/signal.init.1	/usr/local/go/src/os/signal/signal_unix.go:28 +0x44goroutine 11 [chan receive]:github.com/docker/docker/libcontainerd.(*remote).handleConnectionChange(0xc420476340)	/go/src/github.com/docker/docker/libcontainerd/remote_unix.go:146 +0x128created by github.com/docker/docker/libcontainerd.New	/go/src/github.com/docker/docker/libcontainerd/remote_unix.go:120 +0x8bcgoroutine 10 [select]:github.com/docker/docker/vendor/google.golang.org/grpc.(*addrConn).transportMonitor(0xc4203a4b00)	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:751 +0x858github.com/docker/docker/vendor/google.golang.org/grpc.(*ClientConn).resetAddrConn.func1(0xc4203a4b00)	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:506 +0x234created by github.com/docker/docker/vendor/google.golang.org/grpc.(*ClientConn).resetAddrConn	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/clientconn.go:507 +0x7b4goroutine 36 [IO wait]:net.runtime_pollWait(0x3fffa004d0a8, 0x72, 0x0)	/usr/local/go/src/runtime/netpoll.go:160 +0x8cnet.(*pollDesc).wait(0xc42045c0d0, 0x72, 0x0, 0x0)	/usr/local/go/src/net/fd_poll_runtime.go:73 +0x40net.(*pollDesc).waitRead(0xc42045c0d0, 0x0, 0x0)	/usr/local/go/src/net/fd_poll_runtime.go:78 +0x3cnet.(*netFD).Read(0xc42045c070, 0xc420138000, 0x8000, 0x8000, 0x0, 0x120770a0, 0xc420016160)	/usr/local/go/src/net/fd_unix.go:243 +0x248net.(*conn).Read(0xc42042c000, 0xc420138000, 0x8000, 0x8000, 0x0, 0x0, 0x0)	/usr/local/go/src/net/net.go:173 +0xd4bufio.(*Reader).fill(0xc4202242a0)	/usr/local/go/src/bufio/bufio.go:97 +0x1f8bufio.(*Reader).Read(0xc4202242a0, 0xc420388038, 0x9, 0x9, 0x0, 0x0, 0x0)	/usr/local/go/src/bufio/bufio.go:209 +0x24cio.ReadAtLeast(0x1206c7a0, 0xc4202242a0, 0xc420388038, 0x9, 0x9, 0x9, 0x0, 0x0, 0x0)	/usr/local/go/src/io/io.go:307 +0xecio.ReadFull(0x1206c7a0, 0xc4202242a0, 0xc420388038, 0x9, 0x9, 0xc42003dbd0, 0x0, 0x0)	/usr/local/go/src/io/io.go:325 +0x60github.com/docker/docker/vendor/golang.org/x/net/http2.readFrameHeader(0xc420388038, 0x9, 0x9, 0x1206c7a0, 0xc4202242a0, 0x0, 0xc400000000, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:237 +0x88github.com/docker/docker/vendor/golang.org/x/net/http2.(*Framer).ReadFrame(0xc420388000, 0x0, 0x0, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/golang.org/x/net/http2/frame.go:469 +0xd8github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*framer).readFrame(0xc420418090, 0x0, 0x0, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http_util.go:508 +0x40github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*http2Client).reader(0xc42038e000)	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http2_client.go:937 +0x108created by github.com/docker/docker/vendor/google.golang.org/grpc/transport.newHTTP2Client	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http2_client.go:205 +0xa64goroutine 37 [select]:github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*http2Client).controller(0xc42038e000)	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http2_client.go:1015 +0x660created by github.com/docker/docker/vendor/google.golang.org/grpc/transport.newHTTP2Client	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/http2_client.go:235 +0x10c4goroutine 38 [select]:github.com/docker/docker/vendor/google.golang.org/grpc.newClientStream.func2(0x1208f4e0, 0xc42038e000, 0xc42041c000, 0xc42038e240)	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:204 +0x404created by github.com/docker/docker/vendor/google.golang.org/grpc.newClientStream	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:224 +0xe74goroutine 39 [select]:github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*recvBufferReader).Read(0xc42012c240, 0xc4203041f0, 0x5, 0x5, 0x0, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/transport.go:140 +0x750github.com/docker/docker/vendor/google.golang.org/grpc/transport.(*Stream).Read(0xc42041c000, 0xc4203041f0, 0x5, 0x5, 0xc42020ebd0, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/transport/transport.go:325 +0x74io.ReadAtLeast(0x120704a0, 0xc42041c000, 0xc4203041f0, 0x5, 0x5, 0x5, 0x0, 0x0, 0x0)	/usr/local/go/src/io/io.go:307 +0xecio.ReadFull(0x120704a0, 0xc42041c000, 0xc4203041f0, 0x5, 0x5, 0xc42020e9a0, 0x0, 0x0)	/usr/local/go/src/io/io.go:325 +0x60github.com/docker/docker/vendor/google.golang.org/grpc.(*parser).recvMsg(0xc4203041e0, 0x7fffffff, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/rpc_util.go:231 +0xacgithub.com/docker/docker/vendor/google.golang.org/grpc.recv(0xc4203041e0, 0x12087d60, 0x120e8900, 0xc42041c000, 0x0, 0x0, 0x115b4360, 0xc42005a0c0, 0x7fffffff, 0x0, ...)	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/rpc_util.go:315 +0x40github.com/docker/docker/vendor/google.golang.org/grpc.(*clientStream).RecvMsg(0xc42038e240, 0x115b4360, 0xc42005a0c0, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/google.golang.org/grpc/stream.go:312 +0xa8github.com/docker/docker/vendor/github.com/docker/containerd/api/grpc/types.(*aPIEventsClient).Recv(0xc4202fa0f0, 0x0, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/docker/containerd/api/grpc/types/api.pb.go:2093 +0x88github.com/docker/docker/libcontainerd.(*remote).handleEventStream(0xc420476340, 0x1208eb20, 0xc4202fa0f0)	/go/src/github.com/docker/docker/libcontainerd/remote_unix.go:293 +0x4ccreated by github.com/docker/docker/libcontainerd.(*remote).startEventsMonitor	/go/src/github.com/docker/docker/libcontainerd/remote_unix.go:287 +0x2d4goroutine 40 [select, locked to thread]:runtime.gopark(0x1183a9c8, 0x0, 0x116c81f7, 0x6, 0x18, 0x2)	/usr/local/go/src/runtime/proc.go:259 +0x19cruntime.selectgoImpl(0xc42003ff10, 0x0, 0x18)	/usr/local/go/src/runtime/select.go:423 +0xc74runtime.selectgo(0xc42003ff10)	/usr/local/go/src/runtime/select.go:238 +0x14runtime.ensureSigM.func1()	/usr/local/go/src/runtime/signal1_unix.go:304 +0x530runtime.goexit()	/usr/local/go/src/runtime/asm_ppc64x.s:1095 +0x4goroutine 51 [chan receive]:github.com/docker/docker/pkg/signal.Trap.func1(0xc420224540, 0xc420304300)	/go/src/github.com/docker/docker/pkg/signal/trap.go:37 +0x74created by github.com/docker/docker/pkg/signal.Trap	/go/src/github.com/docker/docker/pkg/signal/trap.go:67 +0x1f4goroutine 53 [chan receive]:github.com/docker/docker/daemon.(*Daemon).setupDumpStackTrap.func1(0xc420386780, 0x3fffce8cfa91, 0x22, 0xc42039a600)	/go/src/github.com/docker/docker/daemon/debugtrap_unix.go:18 +0x5ccreated by github.com/docker/docker/daemon.(*Daemon).setupDumpStackTrap	/go/src/github.com/docker/docker/daemon/debugtrap_unix.go:32 +0x100goroutine 54 [chan receive]:github.com/docker/docker/daemon/stats.(*Collector).Run(0xc420298c40)	/go/src/github.com/docker/docker/daemon/stats/collector.go:62 +0x84created by github.com/docker/docker/daemon.(*Daemon).newStatsCollector	/go/src/github.com/docker/docker/daemon/stats_collector.go:24 +0xb4goroutine 55 [chan receive]:github.com/docker/docker/daemon.(*Daemon).execCommandGC(0xc42039a600)	/go/src/github.com/docker/docker/daemon/exec.go:268 +0x70created by github.com/docker/docker/daemon.NewDaemon	/go/src/github.com/docker/docker/daemon/daemon.go:720 +0x2704goroutine 56 [select]:github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).watchLoop(0xc42000ae00)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/store.go:443 +0x114created by github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).startWatch	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/store.go:460 +0x12cgoroutine 452 [runnable]:github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).triggerFunc(0xc4214aa3c0, 0xbebc200, 0xc4214b2b40, 0xc4214b2a80, 0xc42126d400)	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/state.go:119created by github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).schedule	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/state.go:106 +0x368goroutine 429 [select]:github.com/docker/docker/daemon.(*Daemon).DaemonLeavesCluster(0xc42039a600)	/go/src/github.com/docker/docker/daemon/daemon.go:460 +0x190github.com/docker/docker/daemon.(*Daemon).Shutdown(0xc42039a600, 0x0, 0x0)	/go/src/github.com/docker/docker/daemon/daemon.go:858 +0x3b8main.shutdownDaemon.func1(0xc42039a600, 0xc4212cfda0)	/go/src/github.com/docker/docker/cmd/dockerd/daemon.go:390 +0x2ccreated by main.shutdownDaemon	/go/src/github.com/docker/docker/cmd/dockerd/daemon.go:392 +0x7cgoroutine 303 [select]:github.com/docker/docker/vendor/github.com/docker/go-events.(*Broadcaster).run(0xc4212d6820)	/go/src/github.com/docker/docker/vendor/github.com/docker/go-events/broadcast.go:117 +0x840created by github.com/docker/docker/vendor/github.com/docker/go-events.NewBroadcaster	/go/src/github.com/docker/docker/vendor/github.com/docker/go-events/broadcast.go:39 +0x198goroutine 450 [runnable]:github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).triggerFunc(0xc4214aa3c0, 0x3b9aca00, 0xc4214b2ae0, 0xc4214b2a80, 0xc42126d3f0)	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/state.go:119created by github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).schedule	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/state.go:94 +0x1bcgoroutine 349 [IO wait]:net.runtime_pollWait(0x3fffa004ce68, 0x72, 0xc420016160)	/usr/local/go/src/runtime/netpoll.go:160 +0x8cnet.(*pollDesc).wait(0xc420a98a00, 0x72, 0x0, 0x0)	/usr/local/go/src/net/fd_poll_runtime.go:73 +0x40net.(*pollDesc).waitRead(0xc420a98a00, 0x0, 0x0)	/usr/local/go/src/net/fd_poll_runtime.go:78 +0x3cnet.(*netFD).accept(0xc420a989a0, 0x0, 0x12071560, 0xc4214b9880)	/usr/local/go/src/net/fd_unix.go:419 +0x278net.(*TCPListener).accept(0xc42042c870, 0xc4202ddef0, 0x0, 0x0)	/usr/local/go/src/net/tcpsock_posix.go:132 +0x38net.(*TCPListener).AcceptTCP(0xc42042c870, 0x1183ab20, 0x0, 0x0)	/usr/local/go/src/net/tcpsock.go:209 +0xbcgithub.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*NetTransport).tcpListen(0xc420a98930, 0xc42042c870)	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/net_transport.go:225 +0xa0created by github.com/docker/docker/vendor/github.com/hashicorp/memberlist.NewNetTransport	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/net_transport.go:109 +0x9d8goroutine 351 [select]:github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).streamListen(0xc4214aa3c0)	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/net.go:190 +0x148created by github.com/docker/docker/vendor/github.com/hashicorp/memberlist.newMemberlist	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/memberlist.go:145 +0xc24goroutine 152 [chan receive]:main.(*DaemonCli).setupConfigReloadTrap.func1(0xc420af7b00, 0xc420489e30)	/go/src/github.com/docker/docker/cmd/dockerd/daemon_unix.go:55 +0x50created by main.(*DaemonCli).setupConfigReloadTrap	/go/src/github.com/docker/docker/cmd/dockerd/daemon_unix.go:58 +0xf0goroutine 350 [IO wait]:net.runtime_pollWait(0x3fffa004cc28, 0x72, 0x0)	/usr/local/go/src/runtime/netpoll.go:160 +0x8cnet.(*pollDesc).wait(0xc420a98ae0, 0x72, 0x0, 0x0)	/usr/local/go/src/net/fd_poll_runtime.go:73 +0x40net.(*pollDesc).waitRead(0xc420a98ae0, 0x0, 0x0)	/usr/local/go/src/net/fd_poll_runtime.go:78 +0x3cnet.(*netFD).readFrom(0xc420a98a80, 0xc421528000, 0x10000, 0x10000, 0x0, 0x0, 0x0, 0x120770a0, 0xc420016160)	/usr/local/go/src/net/fd_unix.go:270 +0x244net.(*UDPConn).readFrom(0xc42042c880, 0xc421528000, 0x10000, 0x10000, 0xc4202e1df0, 0x10000, 0x0, 0x0)	/usr/local/go/src/net/udpsock_posix.go:43 +0x58net.(*UDPConn).ReadFrom(0xc42042c880, 0xc421528000, 0x10000, 0x10000, 0x10000, 0x0, 0x0, 0x0, 0x0)	/usr/local/go/src/net/udpsock.go:97 +0xf0github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*NetTransport).udpListen(0xc420a98930, 0xc42042c880)	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/net_transport.go:247 +0xf0created by github.com/docker/docker/vendor/github.com/hashicorp/memberlist.NewNetTransport	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/net_transport.go:110 +0xa54goroutine 13 [IO wait]:net.runtime_pollWait(0x3fffa004cfe8, 0x72, 0xc420016160)	/usr/local/go/src/runtime/netpoll.go:160 +0x8cnet.(*pollDesc).wait(0xc4203f2300, 0x72, 0x0, 0x0)	/usr/local/go/src/net/fd_poll_runtime.go:73 +0x40net.(*pollDesc).waitRead(0xc4203f2300, 0x0, 0x0)	/usr/local/go/src/net/fd_poll_runtime.go:78 +0x3cnet.(*netFD).accept(0xc4203f22a0, 0x0, 0x12071560, 0xc42035a8c0)	/usr/local/go/src/net/fd_unix.go:419 +0x278net.(*UnixListener).accept(0xc420422400, 0x0, 0x0, 0x0)	/usr/local/go/src/net/unixsock_posix.go:158 +0x38net.(*UnixListener).Accept(0xc420422400, 0x0, 0x0, 0x0, 0x0)	/usr/local/go/src/net/unixsock.go:229 +0xc8github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).acceptClientConnections(0xc42000ae00, 0xc42048c7e0, 0x5c, 0x120867a0, 0xc420422400)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/sandbox_externalkey_unix.go:128 +0x44created by github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).startExternalKeyListener	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/sandbox_externalkey_unix.go:122 +0x27cgoroutine 456 [runnable]:github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).triggerFunc(0xc4201431e0, 0x3b9aca00, 0xc4214b2d20, 0xc4214b2ba0, 0xc42126d450)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:235created by github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).clusterInit	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:168 +0xbb0goroutine 451 [runnable]:github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).pushPullTrigger(0xc4214aa3c0, 0xc4214b2a80)	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/state.go:141created by github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).schedule	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/state.go:100 +0x2a8goroutine 352 [select]:github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).packetListen(0xc4214aa3c0)	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/net.go:270 +0x194created by github.com/docker/docker/vendor/github.com/hashicorp/memberlist.newMemberlist	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/memberlist.go:146 +0xc44goroutine 194 [select]:github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).clusterAgentInit(0xc42000ae00)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:316 +0x33ccreated by github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).SetClusterProvider	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:252 +0xd4goroutine 353 [select]:github.com/docker/docker/vendor/github.com/hashicorp/memberlist.(*Memberlist).packetHandler(0xc4214aa3c0)	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/net.go:352 +0x360created by github.com/docker/docker/vendor/github.com/hashicorp/memberlist.newMemberlist	/go/src/github.com/docker/docker/vendor/github.com/hashicorp/memberlist/memberlist.go:147 +0xc64goroutine 348 [select]:github.com/docker/docker/vendor/github.com/docker/go-events.(*Broadcaster).run(0xc4212d4e10)	/go/src/github.com/docker/docker/vendor/github.com/docker/go-events/broadcast.go:117 +0x840created by github.com/docker/docker/vendor/github.com/docker/go-events.NewBroadcaster	/go/src/github.com/docker/docker/vendor/github.com/docker/go-events/broadcast.go:39 +0x198goroutine 453 [runnable]:github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).triggerFunc(0xc4201431e0, 0x12a05f200, 0xc4214b2c00, 0xc4214b2ba0, 0xc42126d420)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:235created by github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).clusterInit	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:168 +0xbb0goroutine 454 [runnable]:github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).triggerFunc(0xc4201431e0, 0xbebc200, 0xc4214b2c60, 0xc4214b2ba0, 0xc42126d430)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:235created by github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).clusterInit	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:168 +0xbb0goroutine 402 [chan receive]:main.(*DaemonCli).start.func2()	/go/src/github.com/docker/docker/cmd/dockerd/daemon.go:258 +0x58github.com/docker/docker/pkg/signal.Trap.func1.1(0xc4202fa17c, 0xc420304300, 0x1207cc60, 0xc4214157e0)	/go/src/github.com/docker/docker/pkg/signal/trap.go:50 +0x190created by github.com/docker/docker/pkg/signal.Trap.func1	/go/src/github.com/docker/docker/pkg/signal/trap.go:65 +0x134goroutine 301 [chan receive]:github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).AgentInitWait(0xc42000ae00)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/controller.go:366 +0xacgithub.com/docker/docker/daemon.(*Daemon).setupIngress(0xc42039a600, 0xc420d8d1a0, 0xc421290ad0, 0x10, 0x10, 0x0, 0x0)	/go/src/github.com/docker/docker/daemon/network.go:163 +0x60github.com/docker/docker/daemon.(*Daemon).startIngressWorker.func1(0xc42039a600)	/go/src/github.com/docker/docker/daemon/network.go:122 +0xd0created by github.com/docker/docker/daemon.(*Daemon).startIngressWorker	/go/src/github.com/docker/docker/daemon/network.go:131 +0x74goroutine 458 [semacquire]:sync.runtime_notifyListWait(0xc4214a5410, 0xc400000000)	/usr/local/go/src/runtime/sema.go:267 +0x200sync.(*Cond).Wait(0xc4214a5400)	/usr/local/go/src/sync/cond.go:57 +0xe8github.com/docker/docker/vendor/github.com/docker/go-events.(*Queue).next(0xc421538990, 0x0, 0x0)	/go/src/github.com/docker/docker/vendor/github.com/docker/go-events/queue.go:103 +0x12cgithub.com/docker/docker/vendor/github.com/docker/go-events.(*Queue).run(0xc421538990)	/go/src/github.com/docker/docker/vendor/github.com/docker/go-events/queue.go:68 +0x38created by github.com/docker/docker/vendor/github.com/docker/go-events.NewQueue	/go/src/github.com/docker/docker/vendor/github.com/docker/go-events/queue.go:29 +0x1e8goroutine 459 [runnable]:github.com/docker/docker/vendor/github.com/docker/go-events.(*Queue).run(0xc421538a50)	/go/src/github.com/docker/docker/vendor/github.com/docker/go-events/queue.go:66created by github.com/docker/docker/vendor/github.com/docker/go-events.NewQueue	/go/src/github.com/docker/docker/vendor/github.com/docker/go-events/queue.go:29 +0x1e8goroutine 455 [runnable]:github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).triggerFunc(0xc4201431e0, 0x6fc23ac00, 0xc4214b2cc0, 0xc4214b2ba0, 0xc42126d440)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:235created by github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).clusterInit	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:168 +0xbb0goroutine 457 [runnable]:github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).triggerFunc(0xc4201431e0, 0x68c61714000, 0xc4214b2d80, 0xc4214b2ba0, 0xc42126d460)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:235created by github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb.(*NetworkDB).clusterInit	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/networkdb/cluster.go:168 +0xbb0goroutine 460 [runnable]:github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).handleTableEvents(0xc42000ae00, 0xc4214b2de0, 0xc42126d4b0)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/agent.go:734created by github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).agentInit	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/agent.go:329 +0x604goroutine 461 [runnable]:github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).handleTableEvents(0xc42000ae00, 0xc4214b2f00, 0xc42126d4c0)	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/agent.go:734created by github.com/docker/docker/vendor/github.com/docker/libnetwork.(*controller).agentInit	/go/src/github.com/docker/docker/vendor/github.com/docker/libnetwork/agent.go:330 +0x670```
"
32924,0,3656,2,0,1,bhuisgen,0,"title:IPv6 stack completely disabled if ipv6 option is not set (breaking existing dualstack network). description:**Description**I have a dualstack network configuration and if I start the docker engine without the ipv6 flag, the IPv6 stack is totally disabled on the system, breaking my network.If I don't want IPv6 on my containers why disabling all the IPv6 stack if ipv6 is not set ? In addition to this bad choice, if I set the flags ipv6=true + vip-cidr-ipv6 to fe80::1/64 for the default bridge, the daemon starts and disable all IPv6 ... In addition to breaking WLAN/LAN the localhost ::1 address is required for some network daemons like unbound DNS.**Steps to reproduce the issue:**1.use a  dualstack network with IPv6 + IPv42.start docker engine without ipv6 flag````/usr/bin/dockerd -H fd:// --storage-driver overlay2 --bip=172.30.0.1/24 --dns 8.8.8.8 --dns 8.8.4.4````3.ip addr show**Describe the results you received:**All network interfaces have their IPv6 addresses removed :````1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever2: eth0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc pfifo_fast state DOWN group default qlen 1000    link/ether 68:f7:28:b2:d6:8a brd ff:ff:ff:ff:ff:ff3: wlp4s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000    link/ether ac:7b:a1:82:e0:d8 brd ff:ff:ff:ff:ff:ff    inet 192.168.0.104/24 brd 192.168.0.255 scope global dynamic wlp4s0       valid_lft 84432sec preferred_lft 84432sec````````net.ipv6.conf.all.disable_ipv6 = 1net.ipv6.conf.default.disable_ipv6 = 1net.ipv6.conf.docker0.disable_ipv6 = 1net.ipv6.conf.eth0.disable_ipv6 = 1net.ipv6.conf.lo.disable_ipv6 = 1net.ipv6.conf.wlp4s0.disable_ipv6 = 1````**Describe the results you expected:**To have my IPv4/IPv6 dualstack for WLAN/LAN working and nothing with IPv6 for my containers so engine must start without changing anything.````1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host        valid_lft forever preferred_lft forever2: eth0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc pfifo_fast state DOWN group default qlen 1000    link/ether 68:f7:28:b2:d6:8a brd ff:ff:ff:ff:ff:ff3: wlp4s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000    link/ether ac:7b:a1:82:e0:d8 brd ff:ff:ff:ff:ff:ff    inet 192.168.0.104/24 brd 192.168.0.255 scope global dynamic wlp4s0       valid_lft 86396sec preferred_lft 86396sec    inet6 2a01:cb11:391:d100:e136:224f:92d0:2907/64 scope global noprefixroute dynamic        valid_lft 897sec preferred_lft 297sec    inet6 fe80::790d:8f97:be49:1e22/64 scope link        valid_lft forever preferred_lft forever````````net.ipv6.conf.all.disable_ipv6 = 0net.ipv6.conf.default.disable_ipv6 = 0net.ipv6.conf.docker0.disable_ipv6 = 1net.ipv6.conf.eth0.disable_ipv6 = 0net.ipv6.conf.lo.disable_ipv6 = 0net.ipv6.conf.wlp4s0.disable_ipv6 = 0````**Output of `docker version`:**```Client: Version:      17.04.0-ce API version:  1.28 Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 17:50:07 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-ce API version:  1.28 (minimum version 1.12) Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 17:50:07 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 12 Running: 1 Paused: 0 Stopped: 11Images: 3893Server Version: 17.04.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: containerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.0-2-amd64Operating System: Debian GNU/Linux 9 (stretch)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.4GiBName: laptopID: D6YZ:RQ4R:GATU:BDEN:2BMU:YHSC:BUUD:VEI7:S252:OZ2J:4GTM:BDLQDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Same problem on production with dualstack EC2 instances.
"
32916,0,4297,1,0,0,unshare,0,"title:On a single-node Swarm traffic ingress doesn't work, regression between v17.05.0-ce-rc1 and v17.05.0-ce-rc2 for CentOS. description:**Description**After I've updated from v17.05.0-ce-rc1 to v17.05.0-ce-rc2 my front-end reverse proxy became unavailable.**Steps to reproduce the issue:**1. install v17.05.0-ce-rc12. `docker stack up` my stack with a single 443 port published3. check application availability, look at iptables:```-P INPUT ACCEPT-P FORWARD DROP-P OUTPUT ACCEPT-N DOCKER-N DOCKER-INGRESS-N DOCKER-ISOLATION-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 2376 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -j DOCKER-INGRESS-A FORWARD -j DOCKER-ISOLATION-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT-A FORWARD -o docker0 -j DOCKER-A FORWARD -i docker0 ! -o docker0 -j ACCEPT-A FORWARD -i docker0 -o docker0 -j ACCEPT-A FORWARD -o docker_gwbridge -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT-A FORWARD -o docker_gwbridge -j DOCKER-A FORWARD -i docker_gwbridge ! -o docker_gwbridge -j ACCEPT-A FORWARD -j REJECT --reject-with icmp-host-prohibited-A FORWARD -i docker_gwbridge -o docker_gwbridge -j DROP-A DOCKER-INGRESS -p tcp -m tcp --dport 443 -j ACCEPT-A DOCKER-INGRESS -p tcp -m state --state RELATED,ESTABLISHED -m tcp --sport 443 -j ACCEPT-A DOCKER-INGRESS -j RETURN-A DOCKER-ISOLATION -i docker_gwbridge -o docker0 -j DROP-A DOCKER-ISOLATION -i docker0 -o docker_gwbridge -j DROP-A DOCKER-ISOLATION -j RETURN```4. (optional) tear down the stack5. upgrade to v17.05.0-ce-rc26. (optional) if the stack has been torn down, re-deploy7. look at iptables**Describe the results you received:**No ingress chain, therefore application is inaccessible```$ sudo iptables --list-rules-P INPUT ACCEPT-P FORWARD DROP-P OUTPUT ACCEPT-N DOCKER-N DOCKER-ISOLATION-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 2376 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -j DOCKER-ISOLATION-A FORWARD -o docker0 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT-A FORWARD -o docker0 -j DOCKER-A FORWARD -i docker0 ! -o docker0 -j ACCEPT-A FORWARD -i docker0 -o docker0 -j ACCEPT-A FORWARD -o docker_gwbridge -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT-A FORWARD -o docker_gwbridge -j DOCKER-A FORWARD -i docker_gwbridge ! -o docker_gwbridge -j ACCEPT-A FORWARD -j REJECT --reject-with icmp-host-prohibited-A FORWARD -i docker_gwbridge -o docker_gwbridge -j DROP-A DOCKER-ISOLATION -i docker_gwbridge -o docker0 -j DROP-A DOCKER-ISOLATION -i docker0 -o docker_gwbridge -j DROP-A DOCKER-ISOLATION -j RETURN```**Describe the results you expected:**iptables are the same as before upgradeMy application is accessible**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.05.0-ce-rc2 API version:  1.29 Go version:   go1.7.5 Git commit:   c57fdb2 Built:        Thu Apr 27 03:18:37 2017 OS/Arch:      linux/amd64Server: Version:      17.05.0-ce-rc2 API version:  1.29 (minimum version 1.12) Go version:   go1.7.5 Git commit:   c57fdb2 Built:        Thu Apr 27 03:18:37 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```$ docker infoContainers: 6 Running: 3 Paused: 0 Stopped: 3Images: 75Server Version: 17.05.0-ce-rc2Storage Driver: overlay Backing Filesystem: xfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: systemdPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: ybq9xmfvtuw7e935bav9c5v72 Is Manager: true ClusterID: tv5ojno8vnr3vx56g0wkyj0e7 Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 3 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 172.23.251.217 Manager Addresses:  172.23.251.217:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9048e5e50717ea4497b757314bad98ea3763c145runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.16.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 5.798GiBName: estelle-maersk.sm.sw.ruID: UFC4:F3BH:CRZS:RMZ4:S3WC:3PRC:WJDP:KZSK:PHMQ:24UR:EXZL:FEKLDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Hyper-V Gen.2 on Windows 10
"
32907,0,3368,0,0,0,pshahzeb,0,"title:Missing unmount request for a volume on docker stop after using docker cp. description:**Description**Docker doesn闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?send the unmount request to the managed plugin during docker stop if docker stop is issued after using docker cp on a container.**Steps to reproduce the issue:**0. Pre-reqs: VMWare ESX with a Docker host VM inside. (Ubuntu 14.04.4 LTS) and docker-volume-vsphere VIB installed.1. Install managed plugin See here https://github.com/vmware/docker-volume-vsphere#installation-instructions2. docker volume create -d vsphere --name volume13. docker run -it --volume-driver=vsphere -v volume1:/vol1 --name bb busybox4. (Inside container) touch /vol1/temp.txt(Separate terminal)5. docker cp bb:/vol1/temp.txt /tmp/6. docker stop bb**Describe the results you received:**When docker run is issued, a mount request is received on the managed plugin.When docker cp is issued, a mount and an unmount request is received on the managed plugin.When docker stop is issued, no unmount request is received on managed plugin.**Describe the results you expected:**I expect to receive an unmount request for the docker stop command above.(Note: if I skip docker cp (step 5) above, I see an unmount request on plugin side from docker on docker stop (step 6))**Logs**Results based on following logs of managed plugin since the plugin logs every mount and unmount request received.Initially.```2017-04-27 17:25:56.341223418 -0700 PDT [INFO] Plugin options - port=10192017-04-27 17:25:56.341233131 -0700 PDT [INFO] Getting volume data from unix:///var/run/docker.sock2017-04-27 17:25:56.527318226 -0700 PDT [INFO] Discovered 0 volumes in use.2017-04-27 17:25:56.527342319 -0700 PDT [INFO] Docker VMDK plugin started mock_esx=false version=""vSphere Volume Driver v0.4"" port=10192017-04-27 17:25:56.527587657 -0700 PDT [INFO] Going into ServeUnix - Listening on Unix socket address=""/run/docker/plugins/vsphere.sock""```After step 2 (docker volume create -d vsphere --name volume1)```2017-04-27 17:26:37.797641938 -0700 PDT [INFO] Attaching volume and creating filesystem fstype=ext4 name=volume12017-04-27 17:26:40.101610451 -0700 PDT [INFO] Volume and filesystem created name=volume1 fstype=ext4```After step 3 (docker run -it --volume-driver=vsphere -v volume1:/vol1 --name bb busybox)```2017-04-27 17:27:29.624606967 -0700 PDT [INFO] Mounting volume name=volume12017-04-27 17:29:54.486091123 -0700 PDT [INFO] Mounting volume name=volume1```No log after step 4After step 5 (docker cp bb:/vol1/temp.txt /tmp/)```2017-04-27 17:29:54.486213491 -0700 PDT [INFO] Already mounted, skipping mount. name=volume1 refcount=22017-04-27 17:29:54.509863275 -0700 PDT [INFO] Unmounting Volume name=volume12017-04-27 17:29:54.509895835 -0700 PDT [INFO] Still in use, skipping unmount request. name=volume1 refcount=1```No log after step 6(docker stop bb) i.e. no unmount request.docker log (Nothing interesting)```time=""2017-04-27T17:25:56.509411102-07:00"" level=info msg=""API listen on /var/run/docker.sock""time=""2017-04-27T17:25:56.509475898-07:00"" level=info msg=""API listen on [::]:2375""time=""2017-04-27T17:26:51.677994114-07:00"" level=error msg=""plugin not found""time=""2017-04-27T17:27:23.655694581-07:00"" level=error msg=""Handler for POST /v1.27/containers/create returned error: No such image: busybox:latest""time=""2017-04-27T17:29:10.212115613-07:00"" level=error msg=""plugin not found""time=""2017-04-27T17:30:24.952272196-07:00"" level=info msg=""Container a4340483f0aa0c5ae35cba73b83adf175842d55b4bd87861aa004fbba670b961 failed to exit within 10 seconds of signal 15 - using the force""```**Additional information you deem important (e.g. issue happens only occasionally):**This can be reproduced consistently.Seems like this should be reproducible with any third party volume managed plugin.**Output of `docker version`:**```Client: Version:      17.03.1-ce API version:  1.27 Go version:   go1.7.5 Git commit:   c6d412e Built:        Fri Mar 24 00:40:33 2017 OS/Arch:      linux/amd64Server: Version:      17.03.1-ce API version:  1.27 (minimum version 1.12) Go version:   go1.7.5 Git commit:   c6d412e Built:        Fri Mar 24 00:40:33 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 1 Running: 0 Paused: 0 Stopped: 1Images: 3Server Version: 17.03.1-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 9 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 4ab9917febca54791c5f071a9d1f404867857fccrunc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfeinit version: 949e6faSecurity Options: apparmorKernel Version: 4.2.0-27-genericOperating System: Ubuntu 14.04.4 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.86 GiBName: sc-rdops-vm02-dhcp-52-237ID: NINK:HV2F:IRM2:6JJU:XBVA:DW7J:CV5S:OARB:J4UL:O7S3:4LBA:7AVEDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**VMWare ESXi 6.5Ubuntu 14.04.4 LTS under ESXi//CC @pdhamdhere @MattAtTTU
"
32816,0,3029,0,0,0,jtprobst,0,"title:Docker build cache does not ignore uid/gid on ADD or COPY. description:The uid/gid of a file (on the build host's filesystem) seem to have an effect on the hash of a file when it is added through ADD or COPY. This seems superfluous since the ownership of the added file is reset to uid=gid=0 in the Docker image.This behaviour may lead to the Docker build cache being busted in continuous integration environments, if uid/gid are different across different build nodes.For a minimum working example, please consider the following example where an image is built twice, the second time with different ownership of a COPY'd file.Please note* The hashes of the added file are different as per `docker history`* The ownership is reset to uid=gid=0 inside the image, as stated in the [documentation for ADD](https://docs.docker.com/engine/reference/builder/#copy) (""All new files and directories are created with a UID and GID of 0."")```bash$ ls -lahtotal 8,0Kdrwxrwxr-x 1 jprobst jprobst   36 Apr 25 18:08 .drwxrwxrwx 1 jprobst jprobst 6,4K Apr 25 17:15 ..-rw-rw-r-- 1 jprobst jprobst   44 Apr 25 18:08 Dockerfile-rwxrwxrwx 1 jprobst jprobst    5 Apr 25 17:15 test.txt$ cat Dockerfile FROM ubuntu:16.04COPY test.txt /test.txt$ docker build -t demo .Sending build context to Docker daemon  3.072kBStep 1/2 : FROM ubuntu:16.04 ---> 104bec311bcdStep 2/2 : COPY test.txt /test.txt ---> ea497fe942a0Removing intermediate container 16753a7ab82bSuccessfully built ea497fe942a0$ docker history demoIMAGE               CREATED             CREATED BY                                      SIZE                COMMENTea497fe942a0        17 seconds ago      /bin/sh -c #(nop) COPY file:db60da90f31b3b...   5B                  104bec311bcd        4 months ago        /bin/sh -c #(nop)  CMD [""/bin/bash""]            0B                  <missing>           4 months ago        /bin/sh -c mkdir -p /run/systemd && echo '...   7B                  <missing>           4 months ago        /bin/sh -c sed -i 's/^#\s*\(deb.*universe\...   1.9kB               <missing>           4 months ago        /bin/sh -c rm -rf /var/lib/apt/lists/*          0B                  <missing>           4 months ago        /bin/sh -c set -xe   && echo '#!/bin/sh' >...   745B                <missing>           4 months ago        /bin/sh -c #(nop) ADD file:7529d28035b43a2...   129MB               $ sudo chown 1001:1001 test.txt$ ls -lahtotal 8,0Kdrwxrwxr-x 1 jprobst jprobst   36 Apr 25 18:08 .drwxrwxrwx 1 jprobst jprobst 6,4K Apr 25 17:15 ..-rw-rw-r-- 1 jprobst jprobst   44 Apr 25 18:08 Dockerfile-rwxrwxrwx 1    1001    1001    5 Apr 25 17:15 test.txt$ docker build -t demo .Sending build context to Docker daemon  3.072kBStep 1/2 : FROM ubuntu:16.04 ---> 104bec311bcdStep 2/2 : COPY test.txt /test.txt ---> 43cb126c18bbRemoving intermediate container 4e729efe09bbSuccessfully built 43cb126c18bb$ docker history demoIMAGE               CREATED             CREATED BY                                      SIZE                COMMENT43cb126c18bb        14 seconds ago      /bin/sh -c #(nop) COPY file:f9b82392428347...   5B                  104bec311bcd        4 months ago        /bin/sh -c #(nop)  CMD [""/bin/bash""]            0B                  <missing>           4 months ago        /bin/sh -c mkdir -p /run/systemd && echo '...   7B                  <missing>           4 months ago        /bin/sh -c sed -i 's/^#\s*\(deb.*universe\...   1.9kB               <missing>           4 months ago        /bin/sh -c rm -rf /var/lib/apt/lists/*          0B                  <missing>           4 months ago        /bin/sh -c set -xe   && echo '#!/bin/sh' >...   745B                <missing>           4 months ago        /bin/sh -c #(nop) ADD file:7529d28035b43a2...   129MB               $ docker run -t demo ls -lah /test.txt-rwxrwxrwx 1 root root 5 Apr 25 15:15 /test.txt```
"
32810,1,11817,29,0,0,simonferquel,0,"title:Windows containers: CreateContainer: failure in a Windows system call: A connection could not be established with the Virtual Machine hosting the Container. (0xc0370108). description:**Description**Intermittently, we have a windows container based docker run failing on the Docker for Windows test suite with the error in the title.**Steps to reproduce the issue:**1. here is the docker file:```FROM golang:1.7.4-nanoserverCMD [""go"", ""run"", ""server.go""]COPY server.go ./```2. Here is ""server.go""```package mainimport (	""fmt""	""net/http"")func handler(w http.ResponseWriter, r *http.Request) {	fmt.Fprintf(w, ""Hello"")}func main() {	http.HandleFunc(""/"", handler)	http.ListenAndServe("":8080"", nil)}```3. `docker build -t expose_port .`4. `docker run -d --name=expose_port -p 8080:8080 expose_port`**Describe the results you received:**On Docker RUN, command line shows:```C:\\Program Files\\Docker\\Docker\\Resources\\bin\\docker.exe: Error response from daemon: container d58e7fd5285a782ebdf8114e7f31b35d906e269339a95221d6ceb9b05cb98d56 encountered an error during CreateContainer: failure in a Windows system call: A connection could not be established with the Virtual Machine hosting the Container. (0xc0370108) extra info: {""SystemType"":""Container"",""Name"":""d58e7fd5285a782ebdf8114e7f31b35d906e269339a95221d6ceb9b05cb98d56"",""Owner"":""docker"",""IsDummy"":false,""IgnoreFlushesDuringBoot"":true,""LayerFolderPath"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\d58e7fd5285a782ebdf8114e7f31b35d906e269339a95221d6ceb9b05cb98d56"",""Layers"":[{""ID"":""e426025d-c7a6-5a83-943b-0821e278426e"",""Path"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\b3f5ae9ba39e3f86315dd89d6e22164b9abcc252b1a23b7f17da96e9f5de73d7""},{""ID"":""b924dd62-ed6e-56f3-a437-d6fed8bbec64"",""Path"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\03f0661094068d032e96326d817e56785e415fc0bc4d95980a51e038b13f6364""},{""ID"":""5fa8cb87-3a02-53d8-a422-d126eb44e177"",""Path"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\a74ed921ad882d26d4eee4bb18381c11a9e5c49a2bd6774311a272619a00eb17""},{""ID"":""3afa8685-8eba-5ed2-8e02-15c6982bc1b4"",""Path"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\d07e437dcc8a51f9441cce24026086fc9b3310b7bee8118b07b31cf0cf39c89f""},{""ID"":""48a54e3a-bb24-5512-8d91-7b2f8cfb705e"",""Path"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\1fcabb4b7fdc4a201709766ac7525e69bc939e000191dd6984eca228d6b8e9bc""},{""ID"":""38c92350-2911-5507-9273-25f6436893f0"",""Path"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\20a4e8ac2332610f65cdf3651d2cbc4ae2c3efc5dcdf7fe077cab7594b397d6f""},{""ID"":""44d146f2-4715-52fa-bb2c-d65fb622fbe5"",""Path"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\3b25e4c07bcfa0ee494695204166a01fbe9cd2045c57b76534e44e470be97ae0""},{""ID"":""8d4e8f6c-7256-596a-bc53-a3e5bdd7811c"",""Path"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\ee761393b4473fb3cebecd2df3575f3ade87405bbaf95d6d2b9da533ff0fe3f7""},{""ID"":""e7b94ddd-3ba5-5b78-ab1f-6906a97bc5bf"",""Path"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\6d062eeaf98f031dc9e574bb75794b793c5064ef8c299f1e4bd90bfe75bbaca1""},{""ID"":""6e2cef85-1e06-51f4-8b12-5f5b56da098a"",""Path"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\5f11c030a431b04f82de1632185a878525664a296f09b9f184e1227e20dc2665""},{""ID"":""3e7c605b-fea1-567d-956a-f06ac8e91074"",""Path"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\f89a99aa8a2348dc713396fd0dacf193e00cb545fac5eea12f95638d9d4b7f09""},{""ID"":""28d65942-8fa6-5d33-b866-cc80fef8b649"",""Path"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\5a3b9bb708374a3042f3be4956469b6347736a706d4d089cb18502d41a96003e""}],""HostName"":""d58e7fd5285a"",""MappedDirectories"":[],""SandboxPath"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter"",""HvPartition"":true,""EndpointList"":[""90c47b5b-9061-4b67-aff3-acec442504a9""],""HvRuntime"":{""ImagePath"":""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\f89a99aa8a2348dc713396fd0dacf193e00cb545fac5eea12f95638d9d4b7f09\\\\UtilityVM""},""Servicing"":false,""AllowUnqualifiedDNSQuery"":true}.```Here is an extract from the daemon logs```[03:28:38.924][WindowsDockerDaemon][Info   ] Starting C:\Program Files\Docker\Docker\Resources\dockerd.exe -H npipe:////./pipe/docker_engine_windows[03:28:38.925][WindowsDockerDaemon][Info   ] Started[03:28:38.976][WindowsDockerDaemon][Info   ] time=""2017-04-25T03:28:38.975348600-07:00"" level=warning msg=""failed to rename C:\\ProgramData\\Docker\\tmp for background deletion: %!s(<nil>). Deleting synchronously"" [03:28:38.977][WindowsDockerDaemon][Info   ] time=""2017-04-25T03:28:38.977349700-07:00"" level=info msg=""Windows default isolation mode: hyperv"" [03:28:38.978][WindowsDockerDaemon][Info   ] time=""2017-04-25T03:28:38.978347700-07:00"" level=info msg=""[graphdriver] using prior storage driver: windowsfilter"" [03:28:39.109][WindowsDockerDaemon][Info   ] time=""2017-04-25T03:28:39.109833200-07:00"" level=info msg=""Graph migration to content-addressability took 0.00 seconds"" [03:28:39.109][WindowsDockerDaemon][Info   ] time=""2017-04-25T03:28:39.109833200-07:00"" level=info msg=""Loading containers: start."" [03:28:39.110][WindowsDockerDaemon][Info   ] time=""2017-04-25T03:28:39.110832000-07:00"" level=info msg=""Restoring existing overlay networks from HNS into docker"" [03:28:39.524][WindowsDockerDaemon][Info   ] time=""2017-04-25T03:28:39.524834500-07:00"" level=info msg=""Loading containers: done."" [03:28:39.535][WindowsDockerDaemon][Info   ] time=""2017-04-25T03:28:39.535857000-07:00"" level=info msg=""Daemon has completed initialization"" [03:28:39.535][WindowsDockerDaemon][Info   ] time=""2017-04-25T03:28:39.535857000-07:00"" level=info msg=""Docker daemon"" commit=2878a85 graphdriver=windowsfilter version=17.05.0-ce-rc1 [03:28:39.544][WindowsDockerDaemon][Info   ] time=""2017-04-25T03:28:39.544855400-07:00"" level=info msg=""API listen on //./pipe/docker_engine_windows"" [03:39:08.244][WindowsDockerDaemon][Info   ] time=""2017-04-25T03:39:08.243879500-07:00"" level=error msg=""Create container failed with error: container d58e7fd5285a782ebdf8114e7f31b35d906e269339a95221d6ceb9b05cb98d56 encountered an error during CreateContainer: failure in a Windows system call: A connection could not be established with the Virtual Machine hosting the Container. (0xc0370108) extra info: {\""SystemType\"":\""Container\"",\""Name\"":\""d58e7fd5285a782ebdf8114e7f31b35d906e269339a95221d6ceb9b05cb98d56\"",\""Owner\"":\""docker\"",\""IsDummy\"":false,\""IgnoreFlushesDuringBoot\"":true,\""LayerFolderPath\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\d58e7fd5285a782ebdf8114e7f31b35d906e269339a95221d6ceb9b05cb98d56\"",\""Layers\"":[{\""ID\"":\""e426025d-c7a6-5a83-943b-0821e278426e\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\b3f5ae9ba39e3f86315dd89d6e22164b9abcc252b1a23b7f17da96e9f5de73d7\""},{\""ID\"":\""b924dd62-ed6e-56f3-a437-d6fed8bbec64\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\03f0661094068d032e96326d817e56785e415fc0bc4d95980a51e038b13f6364\""},{\""ID\"":\""5fa8cb87-3a02-53d8-a422-d126eb44e177\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\a74ed921ad882d26d4eee4bb18381c11a9e5c49a2bd6774311a272619a00eb17\""},{\""ID\"":\""3afa8685-8eba-5ed2-8e02-15c6982bc1b4\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\d07e437dcc8a51f9441cce24026086fc9b3310b7bee8118b07b31cf0cf39c89f\""},{\""ID\"":\""48a54e3a-bb24-5512-8d91-7b2f8cfb705e\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\1fcabb4b7fdc4a201709766ac7525e69bc939e000191dd6984eca228d6b8e9bc\""},{\""ID\"":\""38c92350-2911-5507-9273-25f6436893f0\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\20a4e8ac2332610f65cdf3651d2cbc4ae2c3efc5dcdf7fe077cab7594b397d6f\""},{\""ID\"":\""44d146f2-4715-52fa-bb2c-d65fb622fbe5\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\3b25e4c07bcfa0ee494695204166a01fbe9cd2045c57b76534e44e470be97ae0\""},{\""ID\"":\""8d4e8f6c-7256-596a-bc53-a3e5bdd7811c\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\ee761393b4473fb3cebecd2df3575f3ade87405bbaf95d6d2b9da533ff0fe3f7\""},{\""ID\"":\""e7b94ddd-3ba5-5b78-ab1f-6906a97bc5bf\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\6d062eeaf98f031dc9e574bb75794b793c5064ef8c299f1e4bd90bfe75bbaca1\""},{\""ID\"":\""6e2cef85-1e06-51f4-8b12-5f5b56da098a\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\5f11c030a431b04f82de1632185a878525664a296f09b9f184e1227e20dc2665\""},{\""ID\"":\""3e7c605b-fea1-567d-956a-f06ac8e91074\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\f89a99aa8a2348dc713396fd0dacf193e00cb545fac5eea12f95638d9d4b7f09\""},{\""ID\"":\""28d65942-8fa6-5d33-b866-cc80fef8b649\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\5a3b9bb708374a3042f3be4956469b6347736a706d4d089cb18502d41a96003e\""}],\""HostName\"":\""d58e7fd5285a\"",\""MappedDirectories\"":[],\""SandboxPath\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\"",\""HvPartition\"":true,\""EndpointList\"":[\""90c47b5b-9061-4b67-aff3-acec442504a9\""],\""HvRuntime\"":{\""ImagePath\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\f89a99aa8a2348dc713396fd0dacf193e00cb545fac5eea12f95638d9d4b7f09\\\\UtilityVM\""},\""Servicing\"":false,\""AllowUnqualifiedDNSQuery\"":true}"" [03:39:08.507][WindowsDockerDaemon][Info   ] time=""2017-04-25T03:39:08.502938000-07:00"" level=error msg=""Handler for POST /v1.29/containers/d58e7fd5285a782ebdf8114e7f31b35d906e269339a95221d6ceb9b05cb98d56/start returned error: container d58e7fd5285a782ebdf8114e7f31b35d906e269339a95221d6ceb9b05cb98d56 encountered an error during CreateContainer: failure in a Windows system call: A connection could not be established with the Virtual Machine hosting the Container. (0xc0370108) extra info: {\""SystemType\"":\""Container\"",\""Name\"":\""d58e7fd5285a782ebdf8114e7f31b35d906e269339a95221d6ceb9b05cb98d56\"",\""Owner\"":\""docker\"",\""IsDummy\"":false,\""IgnoreFlushesDuringBoot\"":true,\""LayerFolderPath\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\d58e7fd5285a782ebdf8114e7f31b35d906e269339a95221d6ceb9b05cb98d56\"",\""Layers\"":[{\""ID\"":\""e426025d-c7a6-5a83-943b-0821e278426e\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\b3f5ae9ba39e3f86315dd89d6e22164b9abcc252b1a23b7f17da96e9f5de73d7\""},{\""ID\"":\""b924dd62-ed6e-56f3-a437-d6fed8bbec64\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\03f0661094068d032e96326d817e56785e415fc0bc4d95980a51e038b13f6364\""},{\""ID\"":\""5fa8cb87-3a02-53d8-a422-d126eb44e177\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\a74ed921ad882d26d4eee4bb18381c11a9e5c49a2bd6774311a272619a00eb17\""},{\""ID\"":\""3afa8685-8eba-5ed2-8e02-15c6982bc1b4\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\d07e437dcc8a51f9441cce24026086fc9b3310b7bee8118b07b31cf0cf39c89f\""},{\""ID\"":\""48a54e3a-bb24-5512-8d91-7b2f8cfb705e\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\1fcabb4b7fdc4a201709766ac7525e69bc939e000191dd6984eca228d6b8e9bc\""},{\""ID\"":\""38c92350-2911-5507-9273-25f6436893f0\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\20a4e8ac2332610f65cdf3651d2cbc4ae2c3efc5dcdf7fe077cab7594b397d6f\""},{\""ID\"":\""44d146f2-4715-52fa-bb2c-d65fb622fbe5\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\3b25e4c07bcfa0ee494695204166a01fbe9cd2045c57b76534e44e470be97ae0\""},{\""ID\"":\""8d4e8f6c-7256-596a-bc53-a3e5bdd7811c\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\ee761393b4473fb3cebecd2df3575f3ade87405bbaf95d6d2b9da533ff0fe3f7\""},{\""ID\"":\""e7b94ddd-3ba5-5b78-ab1f-6906a97bc5bf\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\6d062eeaf98f031dc9e574bb75794b793c5064ef8c299f1e4bd90bfe75bbaca1\""},{\""ID\"":\""6e2cef85-1e06-51f4-8b12-5f5b56da098a\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\5f11c030a431b04f82de1632185a878525664a296f09b9f184e1227e20dc2665\""},{\""ID\"":\""3e7c605b-fea1-567d-956a-f06ac8e91074\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\f89a99aa8a2348dc713396fd0dacf193e00cb545fac5eea12f95638d9d4b7f09\""},{\""ID\"":\""28d65942-8fa6-5d33-b866-cc80fef8b649\"",\""Path\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\5a3b9bb708374a3042f3be4956469b6347736a706d4d089cb18502d41a96003e\""}],\""HostName\"":\""d58e7fd5285a\"",\""MappedDirectories\"":[],\""SandboxPath\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\"",\""HvPartition\"":true,\""EndpointList\"":[\""90c47b5b-9061-4b67-aff3-acec442504a9\""],\""HvRuntime\"":{\""ImagePath\"":\""C:\\\\ProgramData\\\\Docker\\\\windowsfilter\\\\f89a99aa8a2348dc713396fd0dacf193e00cb545fac5eea12f95638d9d4b7f09\\\\UtilityVM\""},\""Servicing\"":false,\""AllowUnqualifiedDNSQuery\"":true}"" ```**Describe the results you expected:**There is no reason why this container shouldn't start**Additional information you deem important (e.g. issue happens only occasionally):**The issue only happens occasionally (and it happens on other runs as well).Once the daemon is in this state, the following `docker runs` also fail.**Output of `docker version`:**Docker version is 17.05.0-rc1**Additional environment details (AWS, VirtualBox, physical, etc.):**Running on Docker for Windows
"
32808,1,5322,265,0,0,piontec,0,"title:docker fails to start with SIGSEGV. description:**Description**Docker daemon fails to start when restarted with `systemctl restart docker`**Steps to reproduce the issue:**1. Restart docker with systemctl2. Check syslog**Describe the results you received:**Systemd is restarting docker:```Apr 24 13:47:37 localhost systemd[1]: Stopping Docker Application Container Engine...Apr 24 13:47:53 localhost systemd[1]: Stopped Docker Application Container Engine.Apr 24 13:47:53 localhost systemd[1]: Closed Docker Socket for the API.Apr 24 13:47:53 localhost systemd[1]: Stopping Docker Socket for the API.Apr 24 13:47:53 localhost systemd[1]: Starting Docker Socket for the API.Apr 24 13:47:53 localhost systemd[1]: Listening on Docker Socket for the API.Apr 24 13:47:53 localhost systemd[1]: Starting Docker Application Container Engine...Apr 24 13:48:05 localhost systemd[1]: docker.service: Main process exited, code=exited, status=2/INVALIDARGUMENTApr 24 13:48:05 localhost systemd[1]: Failed to start Docker Application Container Engine.```But dockerd fails:```3657126 Apr 24 13:59:27 localhost dockerd[17816]: time=""2017-04-24T13:59:27.061012296Z"" level=warning msg=""libcontainerd: client is out of sync, restore was called on a fully synced container (386eb7812980        fe22ac7e2f32d3cfee52686ba5aef116b67ea2a1cd10e5a01b5f).""3657127 Apr 24 13:59:27 localhost dockerd[17816]: time=""2017-04-24T13:59:27.061623954Z"" level=debug msg=""libcontainerd: restore container 386eb7812980fe22ac7e2f32d3cfee52686ba5aef116b67ea2a1cd10e5a01b5f st        ate running""3657128 Apr 24 13:59:27 localhost dockerd[17816]: panic: runtime error: invalid memory address or nil pointer dereference3657129 Apr 24 13:59:27 localhost dockerd[17816]: [signal SIGSEGV: segmentation violation code=0x1 addr=0x40 pc=0x59add1]3657130 Apr 24 13:59:27 localhost dockerd[17816]: goroutine 6155 [running]:3657131 Apr 24 13:59:27 localhost dockerd[17816]: panic(0x16dc2a0, 0xc42000c080)3657132 Apr 24 13:59:27 localhost dockerd[17816]: #011/usr/local/go/src/runtime/panic.go:500 +0x1a13657133 Apr 24 13:59:27 localhost dockerd[17816]: github.com/docker/docker/daemon.(*Daemon).createSpec(0xc4203e2200, 0xc4214c7000, 0x0, 0x0, 0xc4203e2200)3657134 Apr 24 13:59:27 localhost dockerd[17816]: #011/usr/src/docker/.gopath/src/github.com/docker/docker/daemon/oci_linux.go:729 +0xe113657135 Apr 24 13:59:27 localhost dockerd[17816]: github.com/docker/docker/daemon.(*Daemon).containerStart(0xc4203e2200, 0xc4214c7000, 0x0, 0x0, 0x0, 0x0, 0xc42349b400, 0x0, 0x0)3657136 Apr 24 13:59:27 localhost dockerd[17816]: #011/usr/src/docker/.gopath/src/github.com/docker/docker/daemon/start.go:149 +0x2903657137 Apr 24 13:59:27 localhost dockerd[17816]: github.com/docker/docker/daemon.(*Daemon).StateChanged.func2(0xc42349ade0, 0xc4203e2200, 0xc4214c7000, 0xc421a3b104, 0x4, 0x100000000, 0x0, 0x0, 0x0, 0xc42        3496680)3657138 Apr 24 13:59:27 localhost dockerd[17816]: #011/usr/src/docker/.gopath/src/github.com/docker/docker/daemon/monitor.go:65 +0x2673657139 Apr 24 13:59:27 localhost dockerd[17816]: created by github.com/docker/docker/daemon.(*Daemon).StateChanged3657140 Apr 24 13:59:27 localhost dockerd[17816]: #011/usr/src/docker/.gopath/src/github.com/docker/docker/daemon/monitor.go:76 +0x6de3657141 Apr 24 13:59:27 localhost systemd[1]: docker.service: Main process exited, code=exited, status=2/INVALIDARGUMENT3657142 Apr 24 13:59:27 localhost systemd[1]: Failed to start Docker Application Container Engine.3657143 Apr 24 13:59:27 localhost systemd[1]: Dependency failed for daemon for configuring additional routing and iptables rules for additional IPs.3657144 Apr 24 13:59:27 localhost systemd[1]: docker_routing_rules.service: Job docker_routing_rules.service/start failed with result 'dependency'.3657145 Apr 24 13:59:27 localhost systemd[1]: docker.service: Unit entered failed state.3657146 Apr 24 13:59:27 localhost systemd[1]: docker.service: Failed with result 'exit-code'.```**Additional information you deem important (e.g. issue happens only occasionally):**It's not repeatable; eventually, some restart will be successful and docker will start**Output of `docker version`:**Please note: we confirmed this on 17.03.0 EE also```Client: Version:      17.03.1-ee-3 API version:  1.27 Go version:   go1.7.5 Git commit:   3fcee33 Built:        Thu Mar 30 20:06:11 2017 OS/Arch:      linux/amd64Server: Version:      17.03.1-ee-3 API version:  1.27 (minimum version 1.12) Go version:   go1.7.5 Git commit:   3fcee33 Built:        Thu Mar 30 20:06:11 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 393 Running: 316 Paused: 0 Stopped: 77Images: 1886Server Version: 17.03.1-ee-3Storage Driver: aufs Root Dir: /opt/io1/docker/aufs Backing Filesystem: extfs Dirs: 4506 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 4ab9917febca54791c5f071a9d1f404867857fccrunc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfeinit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-72-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 64Total Memory: 960.7 GiBName: ip-10-69-11-89ID: UGZS:UFD3:GB4C:W5MX:JU2L:K7PH:6ZWS:4GPM:27Q5:UNNN:X3DC:YDT7Docker Root Dir: /opt/io1/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 2962 Goroutines: 1968 System Time: 2017-04-25T10:12:51.915536168Z EventsListeners: 1Registry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: true```**Additional environment details (AWS, VirtualBox, physical, etc.):*** running on AWS x16.xlarge
"
32689,0,0,0,0,0,mfpatrick,0,"title:Distinguishing between names and ids?. description:When you rundocker network create net_1a new network is created and its id is returned: 88bc727969193ae1b2958cbb24f95796b79085917c33addccffea0068e7a5066Feeling mischievous, you can use this id as the name for another new network:docker network create 88bc727969193ae1b2958cbb24f95796b79085917c33addccffea0068e7a5066This then seems to create some ambiguity for the meaning of:docker network rm 88bc727969193ae1b2958cbb24f95796b79085917c33addccffea0068e7a5066I don't know if this is an issue for anybody at all, but I thought I'd share it anyway...docker versionClient: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:42:29 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:42:29 2017 OS/Arch:      linux/amd64 Experimental: falsedocker infoContainers: 1 Running: 1 Paused: 0 Stopped: 0Images: 9Server Version: 1.13.1Storage Driver: aufs Root Dir: /docker-workdir/aufs Backing Filesystem: extfs Dirs: 63 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: 0yzfgikq7n2e1rodqdyxs7mxp Is Manager: false Node Address: ... Manager Addresses:  ...:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: apparmorKernel Version: 3.19.0-80-genericOperating System: Ubuntu 14.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 991.5 MiBName: ...ID: Q7FR:AKBW:WOOI:P4QK:I6ZR:4GAP:TL5T:GBUR:PIFJ:GTFE:ZZKC:VIOWDocker Root Dir: /docker-workdirDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false
"
32667,0,12400,0,0,1,agunnerson-ibm,0,"title:runc: devices_unix.go: Race condition in getDevices(). description:In `devices_unix.go` from runc, `getDevices()` scans for files in `/dev` and then calls `os.Lstat()` on them. A race condition is introduced if anything in `/dev` is deleted between getting the list of files and accessing them.This has been fixed upstream with https://github.com/opencontainers/runc/commit/8f55948aa5c97472c4a8ef6664b10ed662ce1df5 but it appears that the change has not made it to docker yet.This can be easily reproduced by running a bunch of `--privileged` docker containers at once:```shfor i in {0..100}; do docker run --rm --privileged busybox echo ""test_${i}"" & done; wait```On one of our systems, this will result in the following. Note the lstat failures. The unmount failures are probably an unrelated issue.```sh[root@[REDACTED] andrew.gunnerson]# for i in {0..100}; do docker run --rm --privileged busybox echo ""test_${i}"" & done; wait[1] 21515[2] 21516[3] 21517[4] 21518[5] 21519[6] 21520[7] 21521[8] 21522[9] 21523[10] 21524[11] 21525[12] 21526[13] 21527[14] 21529[15] 21530[16] 21531[17] 21532[18] 21533[19] 21534[20] 21535[21] 21536[22] 21537[23] 21538[24] 21539[25] 21540[26] 21541[27] 21542[28] 21544[29] 21545[30] 21546[31] 21547[32] 21548[33] 21549[34] 21550[35] 21551[36] 21552[37] 21553[38] 21554[39] 21555[40] 21556[41] 21557[42] 21558[43] 21559[44] 21563[45] 21567[46] 21570[47] 21576[48] 21579[49] 21583[50] 21586[51] 21588[52] 21591[53] 21593[54] 21595[55] 21598[56] 21601[57] 21603[58] 21607[59] 21611[60] 21614[61] 21616[62] 21618[63] 21623[64] 21627[65] 21628[66] 21630[67] 21632[68] 21641[69] 21643[70] 21646[71] 21647[72] 21648[73] 21653[74] 21657[75] 21660[76] 21663[77] 21664[78] 21666[79] 21669[80] 21673[81] 21698[82] 21699[83] 21701[84] 21704[85] 21705[86] 21708[87] 21710[88] 21713[89] 21715[90] 21717[91] 21718[92] 21719[93] 21720[94] 21722[95] 21725[96] 21729[97] 21731[98] 21732[99] 21735[100] 21742[101] 21756test_15test_3/usr/bin/docker-current: Error response from daemon: linux runtime spec devices: lstat /dev/dm-25: no such file or directory./usr/bin/docker-current: Error response from daemon: linux runtime spec devices: lstat /dev/dm-22: no such file or directory.test_0test_33test_17test_5test_9test_36test_69test_6test_44test_60test_13test_71test_37test_79test_22test_27test_72test_31test_12test_38/usr/bin/docker-current: Error response from daemon: linux runtime spec devices: lstat /dev/dm-24: no such file or directory.test_96test_68test_75test_7test_41test_48test_46test_66test_73test_40test_30test_52test_55test_88test_39Error response from daemon: Unable to remove filesystem for 6893b25c24356e3d75db938b298f8e07e0847a931c66405dadf6e03804750133: remove /var/lib/docker/containers/6893b25c24356e3d75db938b298f8e07e0847a931c66405dadf6e03804750133/shm: device or resource busytest_23test_65test_62test_2/usr/bin/docker-current: Error response from daemon: linux runtime spec devices: lstat /dev/dm-22: no such file or directory.test_54test_4test_26test_58test_47test_77test_63test_16test_24test_19test_29test_74test_70test_34test_57test_45test_28test_11test_8test_10test_49test_95test_20test_32test_81test_64Error response from daemon: Unable to remove filesystem for 35a88372d83353293dcb6b31082a1742e60360898aecbe611473ed8544558d64: remove /var/lib/docker/containers/35a88372d83353293dcb6b31082a1742e60360898aecbe611473ed8544558d64/shm: device or resource busytest_90test_25test_93test_86test_80test_85test_43test_67test_76test_87test_14test_18test_92test_50test_91test_59test_89test_94test_82test_78test_56/usr/bin/docker-current: Error response from daemon: linux runtime spec devices: lstat /dev/dm-24: no such file or directory.test_61test_35test_53test_83test_98test_42[1]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[2]   Exit 127                docker run --rm --privileged busybox echo ""test_${i}""[4]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[16]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[40]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[52]   Exit 127                docker run --rm --privileged busybox echo ""test_${i}""[65]   Done                    docker run --rm --privileged busybox echo ""test_${i}""test_97Error response from daemon: Unable to remove filesystem for 3fff438f7b798f7350ccc673dd38af4dd5cc827debf6696bd297d9f47a89f61c: remove /var/lib/docker/containers/3fff438f7b798f7350ccc673dd38af4dd5cc827debf6696bd297d9f47a89f61c/shm: device or resource busytest_99[3]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[6]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[7]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[8]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[10]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[13]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[14]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[18]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[22]   Exit 127                docker run --rm --privileged busybox echo ""test_${i}""[23]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[24]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[28]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[31]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[32]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[34]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[37]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[38]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[39]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[41]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[42]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[45]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[47]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[49]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[53]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[56]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[61]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[63]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[66]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[67]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[69]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[70]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[72]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[73]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[74]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[76]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[80]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[85]   Exit 127                docker run --rm --privileged busybox echo ""test_${i}""[89]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[97]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[98]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[5]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[27]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[55]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[9]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[12]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[17]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[20]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[25]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[29]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[30]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[35]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[46]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[48]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[58]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[59]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[64]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[71]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[75]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[78]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[11]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[15]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[21]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[26]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[33]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[44]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[50]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[68]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[77]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[81]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[82]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[86]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[87]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[88]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[91]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[94]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[96]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[19]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[36]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[51]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[57]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[60]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[62]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[79]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[83]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[90]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[92]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[93]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[95]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[101]+  Exit 127                docker run --rm --privileged busybox echo ""test_${i}""[43]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[54]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[84]   Done                    docker run --rm --privileged busybox echo ""test_${i}""[99]-  Done                    docker run --rm --privileged busybox echo ""test_${i}""[100]+  Done                    docker run --rm --privileged busybox echo ""test_${i}""[root@[REDACTED] andrew.gunnerson]#```
"
32649,0,97,20,0,0,arun-gupta,0,"title:REST API Swagger representation cannot be loaded with SwaggerUI. description:Docker REST API 1.27 cannot be loaded with the SwaggerUI. It gives the error:```{""messages"": [""attribute definitions.RestartPolicy.default is not of type `string`""]}```The error can be seen at https://online.swagger.io/validator/debug?url=https://docs.docker.com/engine/api/v1.27/swagger.yaml.
"
32639,0,2879,297,0,0,euank,0,"title:docker run --net=host deletes ipv6 addresses from host interfaces. description:**Description**Running `docker run --net=host` with docker 17.04 results in my ipv6 addresses for all of my network interfaces being lost.**Steps to reproduce the issue:**```shellesk@multivac ~ $ ip a show wlp4s0  3: wlp4s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000    link/ether 10:02:b5:b2:b2:22 brd ff:ff:ff:ff:ff:ff    inet x.y.z.101/22 brd x.y.z.255 scope global dynamic wlp4s0       valid_lft 86328sec preferred_lft 86328sec    inet6 fe80::246a:a46d:b875:2b5a/64 scope link        valid_lft forever preferred_lft foreveresk@multivac ~ $ ip a show lo    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host        valid_lft forever preferred_lft forever$ docker run --net=host busyboxesk@multivac ~ $ ip a show wlp4s03: wlp4s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000    link/ether 10:02:b5:b2:b2:22 brd ff:ff:ff:ff:ff:ff    inet x.y.z.101/22 brd x.y.z.255 scope global dynamic wlp4s0       valid_lft 86192sec preferred_lft 86192secesk@multivac ~ $ ip a show lo1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever```**Describe the results you received:**`lo` and `wlp4s0` no longer have inet6 addresses**Describe the results you expected:**No impact on my existing interfaces**Output of `docker version`:**```$ docker versionClient: Version:      17.04.0-ce API version:  1.28 Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:06:13 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-ce API version:  1.28 (minimum version 1.12) Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:06:13 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```$ docker infoContainers: 27 Running: 0 Paused: 0 Stopped: 27Images: 71Server Version: 17.04.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: containerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: default selinuxKernel Version: 4.9.9-200.fc25.x86_64Operating System: Fedora 25 (Workstation Edition)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.678GiBName: multivac.euank.comID: 753V:GKN7:7TOV:KJUP:ELNG:Q45G:4HRT:TVWD:U2WL:6ZNQ:G4BT:YUQVDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: euankRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**This is running on a fedora25 machine with it installed normally from the distro repositories.
"
32613,0,1957,0,0,0,shin-,0,"title:Named volume incorrectly removed after engine upgrade. description:**Description**A named volume associated to a container before a Docker Engine upgrade will be removed by `docker rm -v <container>` after the upgrade.**Steps to reproduce the issue:**1. Downgrade to Docker Engine 1.12.6: `sudo apt install docker-engine=1.12.6-0~ubuntu-xenial`1. Create a named volume: `docker volume create --name foo`2. Create a container mounting the newly created volume: `docker run --name repro -v foo:/foomnt alpine true`3. Upgrade Docker Engine to the latest version: `sudo apt upgrade`3. Remove the container created earlier with the `--volumes` option: `docker rm -v repro`**Describe the results you received:**The named volume is removed alongside the container.**Describe the results you expected:**The named volume remains after the container is removed.**Additional information you deem important (e.g. issue happens only occasionally):**Originally reported here: https://github.com/docker/compose/issues/4607Note that the volume isn't removed if it was created with the same engine version.**Output of `docker version`:**```$ docker versionClient: Version:      17.04.0-ce API version:  1.28 Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:07:42 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-ce API version:  1.28 (minimum version 1.12) Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:07:42 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 4 Running: 0 Paused: 0 Stopped: 4Images: 109Server Version: 17.04.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 249 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: sg2ufch61oe8j2ndv2vwqtehp Is Manager: true ClusterID: xhbxxpaiwazbnrfy0ms860ia8 Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.100.237 Manager Addresses:  192.168.100.237:2377Runtimes: runcDefault Runtime: runcInit Binary: containerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-72-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.499GiBName: yunaID: YZQG:AKYJ:JQXJ:CEHT:62DP:PMWA:S43W:5X47:SSOE:UXGG:XHWS:555FDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```
"
32609,0,2184,2,0,0,febbraro,0,"title:Cannot disable/remove a plugin. . description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**I have installed the `rexray/ebs` plugin, and I was having difficultly getting it to work, so I was attempting to upgrade it from `rexray/ebs:latest` to `rexray/ebs:edge`. However, when I try to disable it I get the following error message:`Error response from daemon: plugin rexray/ebs:latest is in use`I do not have any volumes that were created with this plugin, so it seems that I should be able to disable/remove the plugin.**Steps to reproduce the issue:**1. docker plugin install rexray/ebs2. docker plugin disable rexray/ebs**Describe the results you received:**It gave me an error message: `Error response from daemon: plugin rexray/ebs:latest is in use`**Describe the results you expected:**I expected it to disable the plugin so that I could then remove it.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.04.0-ce API version:  1.28 Go version:   go1.7.5 Git commit:   4845c56 Built:        Wed Apr  5 18:55:10 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-ce API version:  1.28 (minimum version 1.12) Go version:   go1.7.5 Git commit:   4845c56 Built:        Wed Apr  5 18:55:10 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 1Server Version: 17.04.0-ceStorage Driver: overlay Backing Filesystem: xfs Supports d_type: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: pvt2k41nx4v3c98xa6ntm1h8v Is Manager: true ClusterID: udnrxhgowfyq8xycc685vjg1s Managers: 1 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.100.68 Manager Addresses:  192.168.100.68:2377Runtimes: runcDefault Runtime: runcInit Binary:containerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-327.28.2.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 7.389GiBName: manager01ID: O7BJ:7Z73:HAWX:TJKE:HTLC:FX7V:F5FN:6LVW:Y4NK:ET3P:46BX:CD7ODocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: overlay: the backing xfs filesystem is formatted without d_type support, which leads to incorrect behavior.         Reformat the filesystem with ftype=1 to enable d_type support.         Running without d_type support will not be supported in future releases.WARNING: bridge-nf-call-ip6tables is disabled```**Additional environment details (AWS, VirtualBox, physical, etc.):**I am running this on a CentOS 7 AWS EC2 t2.large instance.  I am also running this server as a Swarm mode manager in a 3 node Swarm mode cluster. 1 manager and 2 workers.
"
32588,0,1982,0,0,0,coreyfarrell,0,"title:bash completion for 'docker build' networks calls incorrect function.. description:**Description**Using bash completion to get network list for `docker build --network` displays an error instead of providing completion options.**Steps to reproduce the issue:**1. Type `docker build --network `2. Press tab to initiate completion.**Describe the results you received:**Error is displayed: `-bash: __docker_plugins: command not found`**Describe the results you expected:**List of networks.**Output of `docker version`:**Also occurred with 17.03.0-ce.```Client: Version:      17.04.0-ce API version:  1.28 Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:01:50 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-ce API version:  1.28 (minimum version 1.12) Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:01:50 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 3 Running: 3 Paused: 0 Stopped: 0Images: 14Server Version: 17.04.0-ceStorage Driver: devicemapper Pool Name: docker-253:0-67409928-pool Pool Blocksize: 65.54kB Base Device Size: 107.4GB Backing Filesystem: xfs Data file: /dev/docker_images/containers Metadata file: /dev/docker_images/metadata Data Space Used: 3.024GB Data Space Total: 107.4GB Data Space Available: 104.4GB Metadata Space Used: 5.042MB Metadata Space Total: 10.74GB Metadata Space Available: 10.73GB Thin Pool Minimum Free Space: 10.74GB Udev Sync Supported: true Deferred Removal Enabled: false Deferred Deletion Enabled: false Deferred Deleted Device Count: 0 Library Version: 1.02.135-RHEL7 (2016-11-16)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: containerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.10.2.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 7.778GiBName: docker.example.comID: I2IH:K7RF:TTTT:VXTR:X2E4:LMOZ:SAFK:32IR:RI3J:DKNM:L5FZ:OGN2Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical
"
32567,0,2610,0,0,0,gasparch,0,"title:Docker daemon crashes if fluentd daemon is gone and buffer is full. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->Docker daemon crashes if - container is configured to log to fluentd- fluentd server shuts down (network problem or planned shutdown)- buffer overflows<!--Briefly describe the problem you are having in a few paragraphs.-->1. Configure logstash with fluentd input on some host2. run ```shdocker run -d --log-driver=fluentd --log-opt fluentd-address=172.17.X.X:4000 --log-opt tag=""test"" --log-opt fluentd-buffer-limit=10KB --log-opt fluentd-max-retries=2 --name test1 --rm busybox /bin/sh -c 'yes ""crashme"" '```Yes, limits are on purpose low to expose Docker behavior.3. make sure that Logstash receives messages.4. stop Logstash5. on docker host `watch 'docker ps'` shows in matter of seconds that docker daemon is not available.**Describe the results you received:**Dockerd process crashed with segfault```....repeating linestime=""2017-04-12T17:01:47.079303891Z"" level=error msg=""Failed to log msg \""crashme\"" for logger fluentd: fluent#appendBuffer: Buffer full, limit 10240""time=""2017-04-12T17:01:47.079324142Z"" level=error msg=""Failed to log msg \""crashme\"" for logger fluentd: fluent#appendBuffer: Buffer full, limit 10240""panic: fluent#reconnect: failed to reconnect!goroutine 29272 [running]:panic(0x1630320, 0xc421062010)/usr/local/go/src/runtime/panic.go:500 +0x1a1github.com/docker/docker/vendor/github.com/fluent/fluent-logger-golang/fluent.(*Fluent).reconnect(0xc42096a790)/root/rpmbuild/BUILD/docker-ce/.gopath/src/github.com/docker/docker/vendor/github.com/fluent/fluent-logger-golang/fluent/fluent.go:276 +0xf8created by github.com/docker/docker/vendor/github.com/fluent/fluent-logger-golang/fluent.(*Fluent).send/root/rpmbuild/BUILD/docker-ce/.gopath/src/github.com/docker/docker/vendor/github.com/fluent/fluent-logger-golang/fluent/fluent.go:290 +0x136```**Describe the results you expected:**Container should terminate, but dockerd should stay alive. Otherwise it seems as very easy DoS to crash docker on any host you have access.**Additional information you deem important (e.g. issue happens only occasionally):**100% reproducible with settings above. **Output of `docker version`:**```Client: Version:      17.03.1-ce API version:  1.27 Go version:   go1.7.5 Git commit:   c6d412e Built:        Mon Mar 27 17:05:44 2017 OS/Arch:      linux/amd64Server: Version:      17.03.1-ce API version:  1.27 (minimum version 1.12) Go version:   go1.7.5 Git commit:   c6d412e Built:        Mon Mar 27 17:05:44 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 17 Running: 1 Paused: 0 Stopped: 16Images: 3Server Version: 17.03.1-ceStorage Driver: overlay Backing Filesystem: xfs Supports d_type: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 4ab9917febca54791c5f071a9d1f404867857fccrunc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfeinit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.6.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 14.69 GiBID: 5BXG:QZRZ:L2PI:QVJO:LTFG:JUPJ:ZABK:7LBA:D2G7:WR7K:EO65:SPSHDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**GCE n1-standard-4 instance
"
32556,0,0,300,0,0,fhauptmann,0,"title:docker servcie ps <service_name> lists all instances of services with names starting with service_name. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**On Docker 1.17.04 ""docker service ps <service_name>"" not only lists all instaces of the service named <service_name> but additionally lists all services with names starting with <service_name>. <!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. Create a docker swarm2. Login to a swarm manager3. $ docker service ps app_partner**Describe the results you received:**$ sudo docker service ps ""app_partner""ID                  NAME                    IMAGE                                                   NODE                                     DESIRED STATE       CURRENT STATE             ERROR               PORTShhip3olcnga3        app_partner-data.1      lop-ueb-docker-01:15000/partner-data:17.56.90b0b6d      dockerhost-06.mydomain   Running             Running 34 minutes agoo35af2w7gf2s        app_partner-prozess.1   lop-ueb-docker-01:15000/partner-prozess:17.25.48bb90b   dockerhost-07..mydomain   Running             Running 38 minutes agozesd22nicdc2        app_partner-data.1      lop-ueb-docker-01:15000/partner-data:17.55.f8f6f23      dockerhost-06..mydomain   Shutdown            Shutdown 34 minutes agozll16gs64ris        app_partner-suche.1     lop-ueb-docker-01:15000/partner-suche:17.42.a5d2592     dockerhost-07..mydomain   Running             Running 21 hours agoldorwz8fup88        app_partner-prozess.1   lop-ueb-docker-01:15000/partner-prozess:17.24.48bb90b   dockerhost-05..mydomain   Shutdown            Shutdown 38 minutes agowu0n4fbbch24        app_partner-data.1      lop-ueb-docker-01:15000/partner-data:17.54.f8f6f23      dockerhost-06..mydomain   Shutdown            Shutdown 39 minutes ago**Describe the results you expected:**$ docker --versionDocker version 1.13.1, build 092cba3$ sudo docker service ps app_partnerError: No such service: app_partner**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**Docker version 17.04.0-ce, build 4845c56**Output of `docker info`:**Containers: 22 Running: 13 Paused: 0 Stopped: 9Images: 23Server Version: 17.04.0-ceStorage Driver: overlay Backing Filesystem: xfs Supports d_type: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: buc0o3zmn249mi513g9hbpm27 Is Manager: true ClusterID: pkof2yjm986ej2f76liebg5vt Managers: 3 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: X.X.1.115 Manager Addresses:  X.X.1.115:2377  X.X.1.116:2377  X.X.1.117:2377Runtimes: runcDefault Runtime: runcInit Binary:containerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.6.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.51GiBName: dockerhost-05.mydomainID: E2U6:M6ET:CP6Q:GQMF:4YRH:A6YV:E6QK:POST:BA5L:KONL:XPPD:3JUBDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: registry-01:15000 127.0.0.0/8Live Restore Enabled: falseWARNING: overlay: the backing xfs filesystem is formatted without d_type support, which leads to incorrect behavior.         Reformat the filesystem with ftype=1 to enable d_type support.         Running without d_type support will not be supported in future releases.WARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled**Additional environment details (AWS, VirtualBox, physical, etc.):**Virtual Machine is running on OpenStack. 
"
32528,0,4144,2,0,0,dsheets,0,"title:daemon.json with default-ulimits rejected. description:**Description**Putting `{ ""default-ulimits"": {} }` in `daemon.json` results in `dockerd` failing to start and logging```unable to configure the Docker daemon with file /etc/docker/daemon.json: the following directives don't match any configuration option: default-ulimits```**Steps to reproduce the issue:**1. Edit `daemon.json` to contain `{ ""default-ulimits"": {} }`2. Start `dockerd`**Describe the results you received:**`dockerd` does not start and complains that `default-ulimits` is unknown.**Describe the results you expected:**`dockerd` starts.**Additional information you deem important (e.g. issue happens only occasionally):**This issue seems very strange to me as it appears to be tested in [daemon/config/config_unix_test.go](https://github.com/docker/docker/blob/f3a8886d8890d6797a568ab316baf9400ee2e1e1/daemon/config/config_unix_test.go#L23-L29). I see the same error in the logs when I use exactly the configuration in that test so I'm not certain what/if/how that test is passing.It looks like [daemon/config/config.go line 404](https://github.com/docker/docker/blob/f3a8886d8890d6797a568ab316baf9400ee2e1e1/daemon/config/config.go#L404) is the source of the error message and [lines 386-397](https://github.com/docker/docker/blob/f3a8886d8890d6797a568ab316baf9400ee2e1e1/daemon/config/config.go#L386-L397) are supposed to have handled the case where the config option (`default-ulimits`) and the command line argument (`--default-ulimit`) differ except `opts.UlimitOpt` does not appear to fulfill `opts.NamedOption` and does not appear to ever have. Even more strangely, this seems to have worked in the past and I can't find any obvious changes in the relevant files that would have broken this.I would also expect other issue reports regarding this and so I'm strongly considering the possibility that I've done something wrong. If I have done something wrong, I believe this is a usability problem and still constitutes a bug.There appears to be a history of problems with this configuration field: * #29385 * #22309 * #25566This issue was originally reported at docker/for-mac#1513.**Output of `docker version`:**```Client: Version:      17.04.0-ce API version:  1.28 Go version:   go1.7.5 Git commit:   4845c56 Built:        Wed Apr  5 06:06:36 2017 OS/Arch:      darwin/amd64Server: Version:      17.04.0-ce API version:  1.28 (minimum version 1.12) Go version:   go1.7.5 Git commit:   4845c56 Built:        Tue Apr  4 00:37:25 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 17.04.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary:containerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.19-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952GiBName: mobyID: LBRL:MJIS:5WS3:NVTP:MYHG:DD54:XVPJ:CQN6:TWVY:XL4Y:WPDX:PKADDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 16 Goroutines: 26 System Time: 2017-04-11T15:17:48.302951361Z EventsListeners: 1No Proxy: *.local, 169.254/16Username: dsheetsRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Also tried on 1.13.0, build 49bf474f9 on Debian Linux:```$ docker versionClient: Version:      1.13.0 API version:  1.25 Go version:   go1.7.3 Git commit:   49bf474f9 Built:        Tue Jan 17 09:52:33 2017 OS/Arch:      linux/amd64Server: Version:      1.13.0 API version:  1.25 (minimum version 1.12) Go version:   go1.7.3 Git commit:   49bf474f9 Built:        Tue Jan 17 09:52:33 2017 OS/Arch:      linux/amd64 Experimental: false$ docker infoContainers: 2 Running: 0 Paused: 0 Stopped: 2Images: 500Server Version: 1.13.0Storage Driver: devicemapper Pool Name: docker-8:2-8913512-pool Pool Blocksize: 65.54 kB Base Device Size: 10.74 GB Backing Filesystem: ext4 Data file: /dev/loop0 Metadata file: /dev/loop1 Data Space Used: 44.5 GB Data Space Total: 107.4 GB Data Space Available: 39.98 GB Metadata Space Used: 41.22 MB Metadata Space Total: 2.147 GB Metadata Space Available: 2.106 GB Thin Pool Minimum Free Space: 10.74 GB Udev Sync Supported: true Deferred Removal Enabled: false Deferred Deletion Enabled: false Deferred Deleted Device Count: 0 Data loop file: /var/lib/docker/devicemapper/devicemapper/data WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device. Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata Library Version: 1.02.127 (2016-06-11)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090erunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3einit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.3.0-1-amd64Operating System: Debian GNU/Linux stretch/sidOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.699 GiBName: debussyID: ECNR:42Z2:ZJ2R:LKMC:ZQDL:JQLC:YHMP:XO6Z:M53C:CC3J:DSGX:VGQ5Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: yallopRegistry: https://index.docker.io/v1/WARNING: No memory limit supportWARNING: No swap limit supportWARNING: No kernel memory limit supportWARNING: No oom kill disable supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```
"
32526,0,1566,0,0,0,keyidentity-simon,0,"title:17.03.1-ce on deb : 'docker build' fails when http_proxy build arg is not predefined in environment. description:`docker build --build-arg=http_proxy` fails, if `http_proxy` is not pre-defined in the environment.Same problem for:```https_proxyno_proxy```**Steps to reproduce the issue:**debian stretchdocker 17.03.1-ce```> cat Dockerfile FROM debian:stretch```Without `build-arg=http_proxy` it is fine`> docker build . > /dev/null`With `build-arg=http_proxy` and **no pre-define** of `http_proxy` it fails```> docker build --build-arg=http_proxy . > /dev/nullerror during connect: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.27/build?buildargs=%7B%22http_proxy%22%3Anull%7D&cachefrom=%5B%5D&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=Dockerfile&labels=%7B%7D&memory=0&memswap=0&networkmode=default&rm=1&shmsize=0&ulimits=null: read unix @->/var/run/docker.sock: read: connection reset by peer````build-arg` with pre-defined `http_proxy` is running well`> http_proxy=foo docker build --build-arg=http_proxy . > /dev/null`**Additional information you deem important (e.g. issue happens only occasionally):**Working fine with older docker version 1.12**Output of `docker version`:**`Docker version 17.03.1-ce, build c6d412e`**Output of `docker info`:**```Containers: 3 Running: 1 Paused: 0 Stopped: 2Images: 54Server Version: 17.03.1-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 4ab9917febca54791c5f071a9d1f404867857fccrunc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfeinit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.0-2-amd64Operating System: Debian GNU/Linux 9 (stretch)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.58 GiBName: nb03ID: J7F7:V5TY:VBPB:XQZE:VU32:YFRF:IJPI:IMDS:SJYP:ZJMF:6JJK:ZWR2Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```
"
32517,0,147,6,0,0,samuraisam,0,"title:Docker tag <sha256> no longer works in 17.04.0-ce. description:**Description**Pull request [21002](https://github.com/docker/docker/pull/21002) seems to have regressed in 17.04.0-ce**Steps to reproduce the issue:**Using docker 17.03.1 running `docker tag <sha256> <tagname>` works as expected and tags the repository.Using docker 17.04.0-ce running `docker tag <sha256> <tagname>` results in the following:```docker: Invalid repository name (97ed62d4dc30d1f53b903dac1e90c8fee4a77a30f0099b42f34f67cb5b17018c), cannot specify 64-byte hexadecimal strings.```Once I rolled back to 17.03.1 it worked as expected.**Docker version**Docker version is 17.04.0-ce on ubuntu-trusty
"
32452,0,1900,2,0,0,saikatguha,0,"title:secrets file not relative to compose file location. description:**Description**When configuring secrets in compose file v3, the file: path is not resolved relative to location of the compose file. The secrets file path is resolved relative to the current directory from where the command is executed. This is inconsistent with how other paths in compose file are resolved (e.g., volume paths or context paths).**Steps to reproduce the issue:**1. Create compose v3 file with `secrets.<name>.file = <secret file path>`2. Run `docker stack deploy --compose-file=<compose file path> <stack>` from a different directory than where the compose file is located3. Observe error `open <secret file path>: The system cannot find the path specified.`4. Run `docker stack deploy --compose-file=<compose file path> <stack>` from the same directory as compose file5. Observe no error.**Describe the results you received:**`open <secret file path>: The system cannot find the path specified.`when running `docker stack deploy` with a compose file in a different directory and the secret file located relative to the compose file.**Describe the results you expected:**`docker stack deploy` resolves secret file relative to compose file.**Output of `docker version`:**```Client: Version:      17.03.0-ce API version:  1.26 Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Feb 23 10:40:59 2017 OS/Arch:      windows/amd64Server: Version:      17.03.0-ce API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   3a232c8 Built:        Tue Feb 28 07:52:04 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 16 Running: 0 Paused: 0 Stopped: 16Images: 2552Server Version: 17.03.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 1877 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: p75loi3w18lwn81e5vls76da3 Is Manager: true ClusterID: ub5bn35up6w8n5wrpm21p2wky Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.65.2 Manager Addresses:  192.168.65.2:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 977c511eda0925a723debdc94d09459af49d082arunc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.12-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.934 GiBName: mobyID: BVXG:BRUM:3JDA:5JYQ:O2UQ:C5RW:NNVK:ROR5:B64Z:XZWN:CLHE:WVA2Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Docker for Windows, Hyper-V isolation, moby host
"
32446,0,132,143,0,0,aaronlehmann,0,"title:Daemon shutdown delayed by ""broadcasting node event"". description:When I shut down the daemon with `^C`, there is a 5 second pause, and then I get an error message ""timed out broadcasting node event"".```DEBU[0056] start clean shutdown of cluster resources...ERRO[0061] failed to send node leave: timed out broadcasting node event```This seems to be new on master in the last day or so. I think it's caused by #32283 cc @aboch
"
32433,0,2772,3,0,1,vgallissot,0,"title:NO more ipv6 on all interfaces on Fedora 25 package docker-engine-17.04.0.ce-1.fc25.x86_64. description:**Description**NO IPv6 address is available since docker-engine-17.04.0.ce-1.fc25.x86_64, not even on loop.**Steps to reproduce the issue:**1. On Fedora 25 x86_64: Update docker-engine to docker-engine-17.04.0.ce-1.fc25.x86_642. Docker run some image3. No IPv6 address is available regardless of the interface**Describe the results you received:**Example:```shellroot@mycont1:/# ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever13: eth0@if14: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default     link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.2/16 scope global eth0       valid_lft forever preferred_lft foreverroot@mycont1:/#```In that example, I used ubuntu:14.04 official docker image.**Describe the results you expected:**To have inet6 entries when showing interfaces.  Package downgrade gives my IPv6 addresses back: ``dnf downgrade docker-engine docker-engine-selinux``Example:```shelldocker run -t -i --rm --name ""mycont1"" -h ""mycont1""  ""ubuntu:14.04"" /bin/bashroot@mycont1:/# ip a1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host        valid_lft forever preferred_lft forever15: eth0@if16: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default     link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.2/16 scope global eth0       valid_lft forever preferred_lft forever    inet6 fe80::42:acff:fe11:2/64 scope link tentative        valid_lft forever preferred_lft forever```**Additional information you deem important (e.g. issue happens only occasionally):**Downgrading package to **17.03.1.ce-1.fc25** fixes the issue**Output of `docker version`:**```闂?docker versionClient: Version:      17.04.0-ce API version:  1.28 Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:06:13 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-ce API version:  1.28 (minimum version 1.12) Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:06:13 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```闂?docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 2Server Version: 17.04.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: containerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.10.8-200.fc25.x86_64Operating System: Fedora 25 (Workstation Edition)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.35GiBName: vincentg-lap2ID: 5JJQ:CP3G:POLH:NLLI:WSSP:IENF:QAAA:Q3CJ:QDRZ:6TEJ:3H6O:TL6VDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**nothing that matters 
"
32400,0,3378,200,0,0,thaJeztah,0,"title:""docker pull"" panics if TERMINFO contains an invalid value. description:This was first reported in https://github.com/docker/for-mac/issues/1515, but is not specific to docker for mac, so copying the information in this ticket### Expected behavior`docker pull` from private repository successfully pulls image### Actual behavior```bash[11:20] evant@localhost:~$ docker pull docker-registry.<..>.com:4443/sd_platform/platform-rhel6:5.0.375.0.37: Pulling from sd_platform/platform-rhel6panic: runtime error: invalid memory address or nil pointer dereference[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x449a4c0]goroutine 1 [running]:panic(0x461fa00, 0xc420014130)	/usr/local/go/src/runtime/panic.go:500 +0x1a1github.com/docker/docker/vendor/github.com/Nvveen/Gotty.(*TermInfo).GetAttribute(0x0, 0x46cd122, 0x3, 0x0, 0xc420440000, 0x10, 0x5064000)	/go/src/github.com/docker/docker/vendor/github.com/Nvveen/Gotty/gotty.go:94 +0x140github.com/docker/docker/vendor/github.com/Nvveen/Gotty.(*TermInfo).Parse(0x0, 0x46cd122, 0x3, 0xc420014a00, 0x1, 0x1, 0xc4201876d0, 0x4061055, 0xc4203d2000, 0xc420016280)	/go/src/github.com/docker/docker/vendor/github.com/Nvveen/Gotty/parser.go:42 +0x5agithub.com/docker/docker/pkg/jsonmessage.cursorUp(0x49c2460, 0xc4202f0c90, 0x49c29e0, 0x0, 0x1)	/go/src/github.com/docker/docker/pkg/jsonmessage/jsonmessage.go:144 +0xecgithub.com/docker/docker/pkg/jsonmessage.DisplayJSONMessagesStream(0x49c3560, 0xc420016740, 0x49c2460, 0xc4202f0c90, 0x1, 0xc420187901, 0x0, 0x4627520, 0x4630bc0)	/go/src/github.com/docker/docker/pkg/jsonmessage/jsonmessage.go:263 +0x3e8github.com/docker/docker/pkg/jsonmessage.DisplayJSONMessagesToStream(0x49c3560, 0xc420016740, 0x49c8f20, 0xc4202f0c90, 0x0, 0x0, 0xc4203da8e4)	/go/src/github.com/docker/docker/pkg/jsonmessage/jsonmessage.go:292 +0xd5github.com/docker/docker/cli/command/image.imagePullPrivileged(0x54080f8, 0xc420072178, 0xc420334e70, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...)	/go/src/github.com/docker/docker/cli/command/image/trust.go:316 +0x1cbgithub.com/docker/docker/cli/command/image.runPull(0xc420334e70, 0x7fff5fbff56c, 0x44, 0x0, 0x0, 0xc4203028a0)	/go/src/github.com/docker/docker/cli/command/image/pull.go:76 +0x2bbgithub.com/docker/docker/cli/command/image.NewPullCommand.func1(0xc4203a8d80, 0xc42036f6f0, 0x1, 0x1, 0x0, 0x0)	/go/src/github.com/docker/docker/cli/command/image/pull.go:32 +0x7cgithub.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).execute(0xc4203a8d80, 0xc4200760e0, 0x1, 0x1, 0xc4203a8d80, 0xc4200760e0)	/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:646 +0x26dgithub.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0xc42009b440, 0xc42009b8c0, 0xc42030f4b0, 0xc42007e488)	/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:742 +0x377github.com/docker/docker/vendor/github.com/spf13/cobra.(*Command).Execute(0xc42009b440, 0xc42009b440, 0x49c3920)	/go/src/github.com/docker/docker/vendor/github.com/spf13/cobra/command.go:695 +0x2bmain.main()	/go/src/github.com/docker/docker/cmd/docker/docker.go:168 +0xcb```### Information```Docker for Mac: version: 17.04.0-ce-rc2-mac6 (142462d3d)macOS: version 10.12.5 (build: 16F43c)``````logs: /tmp/0C29861F-A667-4600-8080-2FBAEA191D17/20170405-112044.tar.gz[OK]     db.git[OK]     vmnetd[OK]     dns[OK]     driver.amd64-linux[OK]     virtualization VT-X[OK]     app[OK]     moby[OK]     system[OK]     moby-syslog[OK]     db[OK]     env[OK]     virtualization kern.hv_support[OK]     slirp[OK]     osxfs[OK]     moby-console[OK]     logs[OK]     docker-cli[OK]     menubar[OK]     disk```
"
32398,0,2289,133,0,1,teohhanhui,0,"title:docker stack deploy does not recognize rw mount mode. description:**Description**#30597 introduced a regression when it comes to mount with `:rw` suffix. It should be valid according to https://docs.docker.com/engine/reference/run/#volume-shared-filesystems which says:> If neither 'rw' or 'ro' is specified then the volume is mounted inread-write mode.**Steps to reproduce the issue:**1. `docker stack deploy -c docker-stack.yml mystack`docker-stack.yml:```yamlversion: '3.0'services:  nginx:    image: nginx:1.11-alpine    volumes:      - nginx-configs:/etc/nginx/conf.d:rw      - ./vhost.d:/etc/nginx/vhost.d:ro      - nginx-contents:/usr/share/nginx/html:rw      - nginx-logs:/var/log/nginx:rwvolumes:  nginx-configs: {}  nginx-contents: {}  nginx-logs: {}```**Describe the results you received:**> 3 error(s) decoding:>> * invalid spec: nginx-configs:/etc/nginx/conf.d:rw: unknown option: rw> * invalid spec: nginx-contents:/usr/share/nginx/html:rw: unknown option: rw> * invalid spec: nginx-logs:/var/log/nginx:rw: unknown option: rw**Describe the results you expected:**> Creating network mystack_default> Creating service mystack_nginx**Additional information you deem important (e.g. issue happens only occasionally):**N/A**Output of `docker version`:**```Client: Version:      17.04.0-ce API version:  1.28 Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:07:42 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-ce API version:  1.28 (minimum version 1.12) Go version:   go1.7.5 Git commit:   4845c56 Built:        Mon Apr  3 18:07:42 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 22 Running: 8 Paused: 0 Stopped: 14Images: 245Server Version: 17.04.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 356 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: j0bscfxu5pwuhjs2uqa37tlze Is Manager: true ClusterID: y9d829wmrr8vg2pso3yaptb2i Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.1.114 Manager Addresses:  192.168.1.114:2377Runtimes: runcDefault Runtime: runcInit Binary: containerd version: 422e31ce907fd9c3833a38d7b8fdd023e5a76e73runc version: 9c2d8d184e5da67c95d601382adf14862e4f2228init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-71-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.711GiBName: YOGAID: M77W:GFMI:MAJO:7JRJ:4Z7V:3ZV2:MQDT:XKEB:LBIJ:6SIU:PKCU:2354Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: teohhanhuiRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical
"
32355,0,397,81,0,0,andyneff,0,"title:init-path does not seem to work.. description:While using `--init` works and execute tini 0.13.0. However, I cannot figure out how to use --init-path to change the init binary used.**Steps to reproduce the issue:**1. docker run -it --rm --init --init-path=/usr/local/bin/tini  --entrypoint=bash krallin/ubuntu-tini2. /proc/1/exe -h**Describe the results you received:**    exe (tini version 0.13.0 - git.949e6fa)**Describe the results you expected:**    tini (tini version 0.13.2 - git.79016ec)**Additional information you deem important (e.g. issue happens only occasionally):**I also tries pointing --init-path to a path on the host as suggested on krallin/tini#81, and that did not help either.**Output of `docker version`:**```Client: Version:      17.03.0-ce API version:  1.26 Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Feb 23 11:02:43 2017 OS/Arch:      linux/amd64Server: Version:      17.03.0-ce API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Feb 23 11:02:43 2017 OS/Arch:      linux/amd64 Experimental: false```
"
32325,0,2373,57,0,0,alexinthesky,0,"title:docker stack deploy ignores endpoint_mode. description:Hi, with a swarm on ```docker --versionDocker version 17.04.0-ce-rc1, build d2532c6```deploying this compose this way :docker stack deploy consul -c docker-compose.consul.yml _____________________________________```yamlversion: '3.2'services:    consul-bootstrap:      image: consul:0.7.5      command:      - consul      - agent      - -server      - -bootstrap-expect=3      - -data-dir      - /consul/data      - -client=0.0.0.0      deploy:       endpoint_mode: dnsrr```______________________________________endpoint seems to be ignored :```docker inspect consul_consul-bootstrap[    {        ""ID"": ""vqpxdivub21tt5t34o6z9bb5g"",        ""Version"": {            ""Index"": 15100        },        ""CreatedAt"": ""2017-04-03T16:52:34.16098497Z"",        ""UpdatedAt"": ""2017-04-03T16:52:34.169850555Z"",        ""Spec"": {            ""Name"": ""consul_consul-bootstrap"",            ""Labels"": {                ""com.docker.stack.namespace"": ""consul""            },            ""TaskTemplate"": {                ""ContainerSpec"": {                    ""Image"": ""consul:0.7.5@sha256:7fa3365242fca70d63e8e9737f4f1ac8687987d04bbdb7287bc80ea813e624ca"",                    ""Labels"": {                        ""com.docker.stack.namespace"": ""consul""                    },                    ""Args"": [                        ""consul"",                        ""agent"",                        ""-server"",                        ""-bootstrap-expect=3"",                        ""-data-dir"",                        ""/consul/data"",                        ""-client=0.0.0.0""                    ]                },                ""Resources"": {},                ""Placement"": {},                ""ForceUpdate"": 0            },            ""Mode"": {                ""Replicated"": {                    ""Replicas"": 1                }            },            ""Networks"": [                {                    ""Target"": ""v9ktszmecl76c3tqnr3gw9pbr"",                    ""Aliases"": [                        ""consul-bootstrap""                    ]                }            ],            ""EndpointSpec"": {                ""Mode"": ""vip""            }        },        ""Endpoint"": {            ""Spec"": {                ""Mode"": ""vip""            },            ""VirtualIPs"": [                {                    ""NetworkID"": ""v9ktszmecl76c3tqnr3gw9pbr"",                    ""Addr"": ""10.0.4.2/24""                }            ]        }    }]```<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1.2.3.**Describe the results you received:****Describe the results you expected:****Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```(paste your output here)```**Output of `docker info`:**```(paste your output here)```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
32314,0,0,200,0,0,thaJeztah,0,"title:Init Binary no longer set in output of docker info. description:I noticed that `Init Binary` is no longer set in the output of `docker info` in docker 17.04 (and master).This issue was introduced in https://github.com/docker/docker/pull/29673, which changes https://github.com/docker/docker/commit/db63f9370e26d725357c703cbaf9ab63cc7b6d0a#diff-d188edf2153ada0e6eee0a51db09b1fcL88 to https://github.com/docker/docker/commit/db63f9370e26d725357c703cbaf9ab63cc7b6d0a#diff-49f3d9765e66ddfa37dc814625477699R69, as a result, causing `v.InitBinary` to be empty (https://github.com/docker/docker/blob/d9c4261964fc4c93d2e34de650a33936ebbf7f9c/daemon/info_unix.go#L28)/cc @vdemeester 
"
32311,0,809,29,0,0,Fank,0,"title:Docs syntax issue. description:https://github.com/docker/docker/blob/17.03.x/docs/reference/commandline/service_create.md![image](https://cloud.githubusercontent.com/assets/1900106/24601239/6c42dcac-1858-11e7-8cfe-79ca04a46b90.png)OK with no issueshttps://docs.docker.com/engine/reference/commandline/service_create/#specify-service-constraints---constraint![image](https://cloud.githubusercontent.com/assets/1900106/24601250/79eaf074-1858-11e7-929f-b6a20e74b064.png)Table is messed upAnd `<tdnode.role</td>` is above the tableThis is the table in HTML:```html<table>  <tr>    <th>node attribute</th>    <th>matches</th>    <th>example</th>  </tr>  <tr>    <td><tt>node.id</tt></td>    <td>Node ID</td>    <td><tt>node.id == 2ivku8v2gvtg4</tt></td>  </tr>  <tr>    <td><tt>node.hostname</tt></td>    <td>Node hostname</td>    <td><tt>node.hostname != node-2</tt></td>  </tr>  <tr>    &lt;td<tt>node.role</tt>&lt;/td&gt;    <td><tt>node role: manager</tt></td>    <td><tt>node.role == manager</tt></td>  </tr>  <tr>    <td><tt>node.labels</tt></td>    <td>user defined node labels</td>    <td><tt>node.labels.security == high</tt></td>  </tr>  <tr>    <td><tt>engine.labels</tt></td>    <td>Docker Engine's labels</td>    <td><tt>engine.labels.operatingsystem == ubuntu 14.04</tt></td>  </tr></table>```
"
32297,0,72,23,0,0,z00sts,0,"title:Wrong containerd version in release notes for release v17.03.1-ce. description:Wrong containerd version in release notes for release v17.03.1-ce:```Update containerd to 595e75c212d19a81d2b808a518fe1afc1391dad5 #31662```(https://github.com/docker/docker/pull/31662/commits/74c52a7bab45f63defdbe4c33ec5c77416f2ecf7)But here version changed to 4ab9917febca54791c5f071a9d1f404867857fcc:https://github.com/docker/docker/commit/00132cc4426d7914822b98f952d32a45b015485e
"
32252,0,1871,287,0,0,yajo,0,"title:SELinux forbids writing to volumes in Fedora 25. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**If I create a volume and mount it, and have SELinux enabled, SELinux forbids the container write access to the volume<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**```闂?docker volume create testtest闂?docker container run --rm -it -v test:/test alpine touch /test/somefiletouch: /test/somefile: Permission denied闂?docker container run --rm -it -v test:/test:Z alpine touch /test/somefiletouch: /test/somefile: Permission denied闂?docker container run --rm -it -v test:/test:z alpine touch /test/somefiletouch: /test/somefile: Permission denied```**Describe the results you received:**Permission denied.**Describe the results you expected:**Permission granted.**Additional information you deem important (e.g. issue happens only occasionally):**- Workaround: `sudo setenforce 0` (but it is not really a workaround I like)- SELinux details here: https://bugzilla.redhat.com/show_bug.cgi?id=1437039#c0- Docker installed by [official packages](https://docs.docker.com/engine/installation/linux/fedora/).**Output of `docker version`:**```Client: Version:      17.03.1-ce API version:  1.27 Go version:   go1.7.5 Git commit:   c6d412e Built:        Mon Mar 27 17:14:43 2017 OS/Arch:      linux/amd64Server: Version:      17.03.1-ce API version:  1.27 (minimum version 1.12) Go version:   go1.7.5 Git commit:   c6d412e Built:        Mon Mar 27 17:14:43 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 45 Running: 0 Paused: 0 Stopped: 45Images: 726Server Version: 17.03.1-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: journaldCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 4ab9917febca54791c5f071a9d1f404867857fccrunc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfeinit version: 949e6faSecurity Options: seccomp  Profile: default selinuxKernel Version: 4.9.14-200.fc25.x86_64Operating System: Fedora 25 (Workstation Edition)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 6.761 GiBName: yajolap.yajodomainID: KUBN:F7JL:URX6:HO55:R3L2:SCUU:IWVY:EZ2O:F53G:WHTO:3G4D:R4YUDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Physical, Fedora 25.
"
32235,0,4590,300,0,0,yosifkit,0,"title:inspect --format Size/VirtualSize changes type. description:**Description**When using the format string on `docker inspect`, `.Size` and `.VirtualSize` are an int64, except if you use `.Id` somewhere, in which case they become a float64.   This is specific to images, since container inspect does not have `Size` or `VirtualSize`. **Steps to reproduce the issue:**1. `docker inspect -f '{{printf ""%d"" .Size}} {{.Id}}' alpine`2. while this works: `docker inspect -f '{{printf ""%d"" .Size}}' alpine`**Describe the results you received:**```console$ docker inspect -f '{{.VirtualSize}}' alpine3983636$ docker inspect -f '{{.VirtualSize}} {{.Id}}' alpine3.983636e+06 sha256:651aa95985aa4a17a38ffcf71f598ec461924ca96865facc2c5782ef2d2be07f$ docker inspect -f '{{printf ""%d"" .VirtualSize}}' alpine3983636$ docker inspect -f '{{printf ""%d"" .VirtualSize}} {{.Id}}' alpine%!d(float64=3.983636e+06) sha256:651aa95985aa4a17a38ffcf71f598ec461924ca96865facc2c5782ef2d2be07f```**Describe the results you expected:**```console$ docker inspect -f '{{.VirtualSize}}' alpine3983636$ docker inspect -f '{{.VirtualSize}} {{.Id}}' alpine3983636 sha256:651aa95985aa4a17a38ffcf71f598ec461924ca96865facc2c5782ef2d2be07f$ docker inspect -f '{{printf ""%d"" .VirtualSize}}' alpine3983636$ docker inspect -f '{{printf ""%d"" .VirtualSize}} {{.Id}}' alpine3983636 sha256:651aa95985aa4a17a38ffcf71f598ec461924ca96865facc2c5782ef2d2be07f```**Additional information you deem important (e.g. issue happens only occasionally):**Ran a test of all other keys when output with `.Size`. `.VirtualSize` behaves in the same way.```console$ for key in $(docker inspect -f '{{ range $k, $v := . }}{{ $k }}{{ "" "" }}{{ end }}' bash); do docker inspect -f '{{ printf ""Size: %d"" .Size }} '""$key: ""'{{ .'""$key""' }}' bash; doneSize: 12156318 Architecture: amd64Size: 12156318 Author: Size: 12156318 Comment: Size: 12156318 Config: {f78b191c4c87   false false false map[] false false false [PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin _BASH_GPG_KEY=7C0135FB088AAF6C66C650B9BB5869F064EA74AB _BASH_VERSION=4.4 _BASH_PATCH_LEVEL=0 _BASH_LATEST_PATCH=12] [bash] <nil> true sha256:d96e9ab22a9f45a482d1015781dfe702ef9a0497395506872f2d20981e6f53ac map[]  [docker-entrypoint.sh] false  [] map[]  <nil> []}Size: 12156318 Container: 81f48c4148367410a39fe784fa97ee1a7c23800f23da2c5fa17d8e53db2be560Size: 12156318 ContainerConfig: {f78b191c4c87   false false false map[] false false false [PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin _BASH_GPG_KEY=7C0135FB088AAF6C66C650B9BB5869F064EA74AB _BASH_VERSION=4.4 _BASH_PATCH_LEVEL=0 _BASH_LATEST_PATCH=12] [/bin/sh -c #(nop)  CMD [""bash""]] <nil> true sha256:d96e9ab22a9f45a482d1015781dfe702ef9a0497395506872f2d20981e6f53ac map[]  [docker-entrypoint.sh] false  [] map[]  <nil> []}Size: 12156318 Created: 2017-03-29T22:37:00.2132178ZSize: 12156318 DockerVersion: 1.13.1Size: 12156318 GraphDriver: {overlay map[RootDir:/mnt/spare/docker/overlay/1e17e7a5f76a4bc369a5b73a738d61559ff25f55726fee4d8b0192248da6b3be/root]}Size: %!d(float64=1.2156318e+07) Id: sha256:c60747d6e1cf2cd4e37d83bc015eb0d5d1be6f49b657c974bad9a6b42b6437b9Size: 12156318 Os: linuxSize: 12156318 Parent: sha256:d96e9ab22a9f45a482d1015781dfe702ef9a0497395506872f2d20981e6f53acSize: 12156318 RepoDigests: []Size: 12156318 RepoTags: [bash:4 bash:4.4 bash:4.4.12 bash:latest bashbrew/cache:d09e0f0d3ce02d3af7f8bd1148fe6f91f84a50016aa3243b484d799a4c1eb7d1]Size: 12156318 RootFS: {layers [sha256:9c833b2fdbc966e83b07fdee671b4112949cec9fc34ba84f4444e072de0604c7 sha256:2c03c42f290e3df0cf51b65aa06942024b2496c543d402068c63a0260b6c5ec8 sha256:12953c9fc8d81952ddc76dc592bca6b413d6075783856a94f9bc1e380d3ebbd1] }Size: 12156318 Size: 12156318Size: 12156318 VirtualSize: 12156318```**Output of `docker version`:**```console$ docker versionClient: Version:      17.03.1-ce API version:  1.27 Go version:   go1.8 Git commit:   c6d412e Built:        Thu Mar 30 12:57:47 2017 OS/Arch:      linux/amd64Server: Version:      17.03.1-ce API version:  1.27 (minimum version 1.12) Go version:   go1.8 Git commit:   c6d412e Built:        Thu Mar 30 12:57:47 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```console$ docker infoContainers: 4 Running: 4 Paused: 0 Stopped: 0Images: 9137Server Version: 17.03.1-ceStorage Driver: overlay Backing Filesystem: extfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: v0.2.5 (expected: 4ab9917febca54791c5f071a9d1f404867857fcc)runc version: c91b5be (expected: 54296cf40ad8143b62dbcaa1d90e520a2136ddfe)init version: N/A (expected: 949e6facb77383876aeff8a6944dde66b3089574)Security Options: seccomp  Profile: defaultKernel Version: 4.10.2-gentooOperating System: Gentoo/LinuxOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 30.87 GiBName: isengardID: UOCM:3F65:5FZC:6H5L:W3HY:34G4:A5XZ:SUOV:S2D4:XQTO:4KGA:6XSEDocker Root Dir: /mnt/spare/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Not that this should matter: physical box, Gentoo**Cute Animal:**![](http://wallpaper-gallery.net/images/cute-animal-desktop-wallpaper/cute-animal-desktop-wallpaper-27.jpg)
"
32136,0,1414,39,0,0,grexe,0,"title:docker daemon panic in startContainer.go when passing wrong hostConfig. description:When passing wrong parameters to `extraHosts` as part of the `HostConfig`, the error is propagated all the way down to the `startContainer` go code, and causes an `index out of range` error there.The daemon should better check arguments and report a suitable HTTP error response instead.I was using a Java [docker client library](https://github.com/spotify/docker-client/) (8.1.3-SNAPSHOT)and docker version 1.12.6, build 78d1802.The lib just sends out the REST call to the local docker daemon over HTTP in the end.**Steps to reproduce the issue:**1. call your local docker daemon with the usual REST URI for `createContainer` and a `HostConfig` that contains a newline or single argument instead of the expected ""host:alias"" format2. call `startContainer`3. you get a stack trace from the docker daemon indicating an `index out of range` error in the go code for `startContainer` (I guess it expects 2 arguments but only gets 1 and so the access fails)**Describe the results you received:**The container is created as normal and the call returns a container ID (it should already fail because of the wrong argument for hostConfig).Only when you try start this configured container, it crashes the daemon.**Describe the results you expected:**For a wrong configuration, I'd expect the `createContainer` method to check the arguments are valid, and already report an error if they are invalid, instead of returning an ID, i.e. *fail fast*.**Other info**I am using a private repo and the ZFS backend, but this should not matter, also could reproduce with standard containers from the global registry.**Output of `docker info`:**```Containers: 340 Running: 0 Paused: 0 Stopped: 340Images: 6146Server Version: 1.12.6Storage Driver: zfs Zpool: fpool Zpool Health: ONLINE Parent Dataset: fpool/docker Space Used By Parent: 85179502592 Space Available: 282574352384 Parent Quota: no Compression: lz4Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge null host overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcSecurity Options: apparmor seccompKernel Version: 4.8.0-42-genericOperating System: Ubuntu 16.10OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.29 GiBName: gregor-Aspire-VN7-592GID: MUSL:FDKF:NTZA:QIHD:SCGL:G2YZ:QZ7E:32DY:AV4B:WXPS:WQVF:BERDDocker Root Dir: /var/lib/dockerDebug Mode (client): false                                                                                                   Debug Mode (server): false                                                                                                   Registry: https://index.docker.io/v1/                                                                                        WARNING: No swap limit support                                                                                               Insecure Registries:                                                                                                          127.0.0.0/8```
"
32120,0,2229,96,0,0,DazWilkin,0,"title:docker container ls --format=""{{ json .Ports }}"" incorrectly encoding \u003e instead of "">"". description:Discovered format={{ json . }}https://docs.docker.com/engine/admin/formatting/#jsonThe port mappings are incorrectly [en|de]codedE.g.```""0.0.0.0:8080-\u003e8080/tcp""```Instead of```""0.0.0.0:8080->8080/tcp""```**Repro**```docker container ls --format=""{{ json .Ports }}""docker ps --format=""{{ json .Ports }}```**Describe the results you received:**String include unicode (`\u003e`) instead of ""`>`""```""0.0.0.0:9000-\u003e9000/tcp""""0.0.0.0:8080-\u003e8080/tcp""```**Describe the results you expected:**jq works as expected```docker container ls --format=""{{ json . }}"" | jq .Ports""0.0.0.0:9000->9000/tcp""""0.0.0.0:8080->8080/tcp""```**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.03.0-ce API version:  1.26 Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Feb 23 11:02:43 2017 OS/Arch:      linux/amd64Server: Version:      17.03.0-ce API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Feb 23 11:02:43 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```docker infoContainers: 4 Running: 2 Paused: 0 Stopped: 2Images: 16Server Version: 17.03.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 118 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: [REDACTED] Is Manager: true ClusterID: [REDACTED] Managers: 1 Nodes: 4 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.1.156 Manager Addresses:  192.168.1.156:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 977c511eda0925a723debdc94d09459af49d082arunc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-66-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.31 GiBName: [REDACTED]ID: [REDACTED]Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: [REDACTED]Registry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
32093,0,95,300,0,1,ylavoie,0,"title:ndots:0. description:Docker imposes ndots:0 in current resolv.confThis conflicts with search option and prevent containers from finding nodes in an intranet using short names.Removing the ndots:0 option fixes that, so there should be a way to override it. Providing a different ndots value currently results in:```cat /etc/resolv.confsearch mynetwork.netnameserver 127.0.0.11options ndots:15 ndots:0```
"
32038,1,1788,1,0,0,paddie,0,"title:docker logs -f <containerID> fails when container rotates log file. description:---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Using `docker logs -f <containerID>` to follow the output logs of a container seems to stop after a while, and sooner if the `--log-opt max-size` is set to a low value. What we've seen in live production systems, is that only the first log-file is properly followed, but the second it rotates, the `docker logs -f` command stops tracking the file. Maybe a fsnotify is not being triggered correctly?**Steps to reproduce the issue:**1. execute the following command to execute a docker container with a small max-size:    ```bash    docker run -d --log-driver=json-file --log-opt max-size=1k alpine /bin/ash -c 'while true; do echo ""hit CTRL+C to exit""; sleep 1; done'    ```2. Follow the container logs using the follow command:    ```    docker logs -f <containerID>    ```**Describe the results you received:**The log output stops after around 10-12 lines and never pick up again, even though the container keeps echoing.**Describe the results you expected:**The logs should either keep going or stop (and close the stream) after the json-file was rotated.**Additional information you deem important (e.g. issue happens only occasionally):**This has been observed on both Docker 1.12.6 in Amazon ECS and locally running the version described below using `docker version/info`.**Output of `docker version`:**```Client: Version:      17.03.0-ce API version:  1.26 Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Feb 23 10:40:59 2017 OS/Arch:      darwin/amd64Server: Version:      17.03.0-ce API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   3a232c8 Built:        Tue Feb 28 07:52:04 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 6 Running: 0 Paused: 0 Stopped: 6Images: 101Server Version: 17.03.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 977c511eda0925a723debdc94d09459af49d082arunc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.12-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.952 GiBName: mobyID: TP72:QUAN:KOBL:NK7N:LTOZ:6NRW:NQPN:GH7K:HZD6:QDDE:GSZJ:GSQUDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 17 Goroutines: 28 System Time: 2017-03-23T13:07:49.418835015Z EventsListeners: 1No Proxy: *.local, 169.254/16Username: trustpilotdockerhubRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**`Docker for Mac` and `AWS ECS`
"
31990,0,8122,48,0,0,nathanleclaire,0,"title:Builder causes daemon panic if --build-arg FOO env var is not set. description:**Description**```$ echo 'FROM alpine> ARG SPAM> ARG EGGS' | docker build --build-arg SPAM --build-arg EGGS -Sending build context to Docker daemon 2.048 kBStep 1/3 : FROM alpine ---> 88e169ea8f46Step 2/3 : ARG SPAM ---> Using cache ---> f7d6c77134d4$ echo $?0```O_O```$ docker-machine ssh default tail -n 50 /var/log/docker.logtime=""2017-03-22T00:41:30.937071601Z"" level=debug msg=""[BUILDER] Use cached version: [/bin/sh -c #(nop)  ARG SPAM]""time=""2017-03-22T00:41:33.164976156Z"" level=debug msg=""Calling GET /_ping""time=""2017-03-22T00:41:33.166988496Z"" level=debug msg=""Calling POST /v1.26/build?buildargs=%7B%22SPAM%22%3Anull%7D&cachefrom=%5B%5D&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=Dockerfile&labels=%7B%7D&memory=0&memswap=0&networkmode=default&rm=1&shmsize=0&ulimits=null""time=""2017-03-22T00:41:33.182757547Z"" level=debug msg=""[BUILDER] Use cached version: [/bin/sh -c #(nop)  ARG SPAM]""time=""2017-03-22T00:41:41.049953213Z"" level=debug msg=""Calling GET /_ping""time=""2017-03-22T00:41:41.051951690Z"" level=debug msg=""Calling POST /v1.26/build?buildargs=%7B%22SPAM%22%3Anull%7D&cachefrom=%5B%5D&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=Dockerfile&labels=%7B%7D&memory=0&memswap=0&networkmode=default&rm=1&shmsize=0&ulimits=null""time=""2017-03-22T00:41:41.068645527Z"" level=debug msg=""[BUILDER] Use cached version: [/bin/sh -c #(nop)  ARG SPAM]""time=""2017-03-22T00:41:56.421415458Z"" level=debug msg=""Calling GET /_ping""time=""2017-03-22T00:41:56.423540746Z"" level=debug msg=""Calling POST /v1.26/build?buildargs=%7B%22EGGS%22%3Anull%2C%22SPAM%22%3Anull%7D&cachefrom=%5B%5D&cgroupparent=&cpuperiod=0&cpuquota=0&cpusetcpus=&cpusetmems=&cpushares=0&dockerfile=Dockerfile&labels=%7B%7D&memory=0&memswap=0&networkmode=default&rm=1&shmsize=0&ulimits=null""time=""2017-03-22T00:41:56.439312418Z"" level=debug msg=""[BUILDER] Use cached version: [/bin/sh -c #(nop)  ARG SPAM]""2017-03-22 00:41:56.439748 I | http: panic serving 192.168.99.1:61221: runtime error: invalid memory address or nil pointer dereferencegoroutine 583 [running]:net/http.(*conn).serve.func1(0xc420d32c80)	/usr/local/go/src/net/http/server.go:1491 +0x12apanic(0x1777c40, 0xc420010090)	/usr/local/go/src/runtime/panic.go:458 +0x243github.com/docker/docker/builder/dockerfile.(*Builder).dispatch(0xc4214126c0, 0x2, 0x3, 0xc420955570, 0xc420a290b0, 0x1)	/go/src/github.com/docker/docker/builder/dockerfile/evaluator.go:161 +0x57fgithub.com/docker/docker/builder/dockerfile.(*Builder).build(0xc4214126c0, 0x2509c20, 0xc4202aeae0, 0x2509be0, 0xc4202aeb00, 0x2509120, 0xc4202aeac0, 0x0, 0x0, 0xc4214126c0, ...)	/go/src/github.com/docker/docker/builder/dockerfile/builder.go:266 +0x2b5github.com/docker/docker/builder/dockerfile.(*BuildManager).BuildFromContext(0xc4224911d0, 0x2522860, 0xc4220aa680, 0x25169a0, 0xc4220aa5c0, 0x0, 0x0, 0xc4213823c0, 0x2509120, 0xc4202aeac0, ...)	/go/src/github.com/docker/docker/builder/dockerfile/builder.go:117 +0x323github.com/docker/docker/api/server/router/build.(*buildRouter).postBuild(0xc42160c6f0, 0x2522860, 0xc4220aa680, 0x251f060, 0xc4213cf380, 0xc42137e4b0, 0xc4210cd140, 0x0, 0x0)	/go/src/github.com/docker/docker/api/server/router/build/build_routes.go:212 +0x87fgithub.com/docker/docker/api/server/router/build.(*buildRouter).(github.com/docker/docker/api/server/router/build.postBuild)-fm(0x2522860, 0xc4220aa680, 0x251f060, 0xc4213cf380, 0xc42137e4b0, 0xc4210cd140, 0xc421988a60, 0x1)	/go/src/github.com/docker/docker/api/server/router/build/build.go:27 +0x69github.com/docker/docker/api/server/router.cancellableHandler.func1(0x2522920, 0xc4210cd200, 0x251f060, 0xc4213cf380, 0xc42137e4b0, 0xc4210cd140, 0x0, 0x0)	/go/src/github.com/docker/docker/api/server/router/local.go:84 +0x104github.com/docker/docker/api/server/middleware.ExperimentalMiddleware.WrapHandler.func1(0x2522920, 0xc4210cd200, 0x251f060, 0xc4213cf380, 0xc42137e4b0, 0xc4210cd140, 0x1d, 0xe0ff5cb400000001)	/go/src/github.com/docker/docker/api/server/middleware/experimental.go:27 +0xd8github.com/docker/docker/api/server/middleware.VersionMiddleware.WrapHandler.func1(0x2522920, 0xc4210cd1a0, 0x251f060, 0xc4213cf380, 0xc42137e4b0, 0xc4210cd140, 0xc4229f3ad0, 0x8)	/go/src/github.com/docker/docker/api/server/middleware/version.go:47 +0x5cagithub.com/docker/docker/pkg/authorization.(*Middleware).WrapHandler.func1(0x2522920, 0xc4210cd1a0, 0x251f060, 0xc4213cf380, 0xc42137e4b0, 0xc4210cd140, 0x756ea17098b0a0, 0xc420a29988)	/go/src/github.com/docker/docker/pkg/authorization/middleware.go:43 +0x83fgithub.com/docker/docker/api/server/middleware.DebugRequestMiddleware.func1(0x2522920, 0xc4210cd1a0, 0x251f060, 0xc4213cf380, 0xc42137e4b0, 0xc4210cd140, 0xc400000000, 0xc421412000)	/go/src/github.com/docker/docker/api/server/middleware/debug.go:25 +0x9bfgithub.com/docker/docker/api/server.(*Server).makeHTTPHandler.func1(0x251f060, 0xc4213cf380, 0xc42137e4b0)	/go/src/github.com/docker/docker/api/server/server.go:139 +0x233net/http.HandlerFunc.ServeHTTP(0xc4222760c0, 0x251f060, 0xc4213cf380, 0xc42137e4b0)	/usr/local/go/src/net/http/server.go:1726 +0x44github.com/docker/docker/vendor/github.com/gorilla/mux.(*Router).ServeHTTP(0xc4221d3770, 0x251f060, 0xc4213cf380, 0xc42137e4b0)	/go/src/github.com/docker/docker/vendor/github.com/gorilla/mux/mux.go:103 +0x255github.com/docker/docker/api/server.(*routerSwapper).ServeHTTP(0xc421f92a90, 0x251f060, 0xc4213cf380, 0xc42137e4b0)	/go/src/github.com/docker/docker/api/server/router_swapper.go:29 +0x70net/http.serverHandler.ServeHTTP(0xc420056a00, 0x251f060, 0xc4213cf380, 0xc42137e4b0)	/usr/local/go/src/net/http/server.go:2202 +0x7dnet/http.(*conn).serve(0xc420d32c80, 0x2520ca0, 0xc4220aa500)	/usr/local/go/src/net/http/server.go:1579 +0x4b7created by net/http.(*Server).Serve	/usr/local/go/src/net/http/server.go:2293 +0x44d```:(If I set the value of those as environment variables it works fine though.**Output of `docker version`:**```$ docker versionClient: Version:      17.03.1-ce-rc1 API version:  1.26 Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Feb 23 10:40:59 2017 OS/Arch:      darwin/amd64Server: Version:      17.03.1-ce-rc1 API version:  1.27 (minimum version 1.12) Go version:   go1.7.5 Git commit:   3476dbf Built:        Fri Mar 17 00:27:41 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```$ docker infoContainers: 6 Running: 0 Paused: 0 Stopped: 6Images: 128Server Version: 17.03.1-ce-rc1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: vn5p5pcs5glevymwyvfvak64a Is Manager: true ClusterID: 0mxekj55chzgzv4gzbz8bdorp Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.99.100 Manager Addresses:  192.168.99.100:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 4ab9917febca54791c5f071a9d1f404867857fccrunc version: 54296cf40ad8143b62dbcaa1d90e520a2136ddfeinit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.4.54-boot2dockerOperating System: Boot2Docker 17.03.1-ce-rc1 (TCL 7.2); HEAD : dd6af02 - Fri Mar 17 22:17:14 UTC 2017OSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 1.955 GiBName: defaultID: U2B5:IGEE:LMFY:SWJW:JUPB:IUJS:YO7T:WEXF:PYPE:TZBF:MXYA:TJDNDocker Root Dir: /mnt/sda1/var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 31 Goroutines: 126 System Time: 2017-03-22T00:43:19.192419783Z EventsListeners: 0Username: nathanleclaireRegistry: https://index.docker.io/v1/Labels: provider=virtualboxExperimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```
"
31913,0,4539,101,0,0,StefanScherer,0,"title:Recreating Docker swarm leads to Err: listen tcp 0.0.0.0:7946: bind: address already in use. description:**Description**Recreating a Docker swarm with `docker swarm leave -f` and `docker swarm init` a couple of times leads to the following error in docker.log: `Err: listen tcp 0.0.0.0:7946: bind: address already in use` Joining workers to such a swarm manager then leads to `Mar 16 11:16:52 secondblue dockerd[758]: time=""2017-03-16T11:16:52.145876195Z"" level=warning msg=""memberlist: failed to receive: No installed keys could decrypt the message from=192.168.17.112:53924""`I came across this problem while writing a helper script to reset a (real hardwar) demo environment again and again. But it can be reproduced with Docker Machine.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. `docker-machine create -d virtualbox tst`2. `eval $(docker-machine env tst)`3. `docker swarm init --advertise-addr 192.168.99.100`4. `docker swarm leave -f`5. `docker swarm init --advertise-addr 192.168.99.100`6. `docker swarm leave -f`7. `docker swarm init --advertise-addr 192.168.99.100`8. `docker swarm leave -f`9. `docker-machine ssh tst`10. `cat /var/log/docker.log`In parallel looking on the ports listening in the machine, the port 7946 is still listening after leaving the swarm:```$ docker-machine ssh tstdocker@tst:~$ netstat -an | grep 7946tcp        0      0 :::7946                 :::*                    LISTEN      udp        0      0 :::7946                 :::*                                ```**Describe the results you received:**```time=""2017-03-17T07:37:17.975482519Z"" level=info msg=""Gossip cluster hostname tst-00b488f70cfd"" time=""2017-03-17T07:37:17.975500395Z"" level=debug msg=""Encryption key 1: 6fc7c"" time=""2017-03-17T07:37:17.975528348Z"" level=debug msg=""Encryption key 2: d51b0"" time=""2017-03-17T07:37:17.975533599Z"" level=debug msg=""Encryption key 3: 8681a"" time=""2017-03-17T07:37:17.975608225Z"" level=error msg=""Error in agentInit : failed to create memberlist: Failed to start TCP listener. Err: listen tcp 0.0.0.0:7946: bind: address already in use"" time=""2017-03-17T07:37:17.976687877Z"" level=debug msg=""Root CA updated successfully"" cluster.id=i1q2pbhbd31n02a39oo1ovuj6 method=""(*Server).updateCluster"" module=ca time=""2017-03-17T07:37:17.977759203Z"" level=debug msg=""Calling GET /v1.26/swarm"" time=""2017-03-17T07:37:17.978666940Z"" level=debug msg=""Calling GET /v1.26/nodes/jl5321ooxdhr5kths3f1ai904"" time=""2017-03-17T07:37:21.224266845Z"" level=error msg=""failed to send node leave: timed out broadcasting node event"" time=""2017-03-17T07:37:21.342478674Z"" level=debug msg=""checkEncryption(8jlu4ma, <nil>, 0, true)"" time=""2017-03-17T07:37:21.372807365Z"" level=debug msg=""Revoking external connectivity on endpoint gateway_ingress-sbox (8d8be82e3a664e223b320217070052bf21cfc08e9997f5cb1e96671a16d926b3)"" time=""2017-03-17T07:37:21.443056711Z"" level=debug msg=""Releasing addresses for endpoint gateway_ingress-sbox's interface on network docker_gwbridge"" time=""2017-03-17T07:37:21.443085904Z"" level=debug msg=""ReleaseAddress(LocalDefault/172.18.0.0/16, 172.18.0.2)"" time=""2017-03-17T07:37:21.472006338Z"" level=debug msg=""Releasing addresses for endpoint ingress-endpoint's interface on network ingress"" time=""2017-03-17T07:37:21.472074337Z"" level=debug msg=""ReleaseAddress(LocalDefault/10.255.0.0/16, 10.255.0.3)"" time=""2017-03-17T07:37:21.473235690Z"" level=debug msg=""releasing IPv4 pools from network ingress (8jlu4majgdvqiercuqqqhatgw)"" time=""2017-03-17T07:37:21.473255783Z"" level=debug msg=""ReleaseAddress(LocalDefault/10.255.0.0/16, 10.255.0.1)"" time=""2017-03-17T07:37:21.473269962Z"" level=debug msg=""ReleasePool(LocalDefault/10.255.0.0/16)"" ```**Describe the results you expected:**Should work multiple times.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      17.03.0-ce API version:  1.26 Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Feb 23 10:40:59 2017 OS/Arch:      darwin/amd64Server: Version:      17.03.0-ce API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   3a232c8 Built:        Tue Feb 28 07:52:04 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 17.03.0-ceStorage Driver: aufs Root Dir: /mnt/sda1/var/lib/docker/aufs Backing Filesystem: extfs Dirs: 0 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: jl5321ooxdhr5kths3f1ai904 Is Manager: true ClusterID: i1q2pbhbd31n02a39oo1ovuj6 Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.99.100 Manager Addresses:  192.168.99.100:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 977c511eda0925a723debdc94d09459af49d082arunc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.4.52-boot2dockerOperating System: Boot2Docker 17.03.0-ce (TCL 7.2); HEAD : f11a204 - Thu Mar  2 00:14:47 UTC 2017OSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 995.8 MiBName: tstID: DI4T:HKXV:ZQJE:UGL4:EWIC:LQE3:72NV:YSTO:T5DU:6JAC:H5R3:6JLFDocker Root Dir: /mnt/sda1/var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 25 Goroutines: 125 System Time: 2017-03-17T07:54:40.549954175Z EventsListeners: 0Username: stefanscherersealRegistry: https://index.docker.io/v1/Labels: provider=virtualboxExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**VirtualBox, Raspberry Pi
"
31897,0,0,143,0,0,aaronlehmann,0,"title:Client attempts to validate secret target using ""filepath"". description:https://github.com/docker/docker/blob/950658bbb63480de254a166bdeaef1fc8b8fe644/opts/secret.go#L56-L59I don't think this will work correctly on a Windows client talking to a Linux engine, or vice versa.cc @dnephin @ehazlett
"
31892,0,74,290,0,0,tonistiigi,0,"title:`ARG` should be scoped to `FROM`. description:Currently, when using multiple `FROM` statements in the `Dockerfile` all the previous commands are reset after a `FROM` statement. But `ARG` statement behaves like a global and leaks to the next `FROM`. Only the values passed by the user should be global, the `ARG` definitions should be local to the `FROM` statement.The leaking arg means that change in arguments in one block also invalidates all the commands in another block.```FROM busyboxARG foo=barRUN envFROM busyboxARG baz=barRUN env```Currently, last command will print both `foo` and `baz` while it should only show `baz`.When https://github.com/docker/docker/pull/31352 gets merged that means that `ARG` defined before first `FROM` should only be used for replacing a `FROM` value itself. If the same arg is needed in one of subblocks it just needs to be redefined. There is no change for user as they still need to only pass the value once.This may seem like an obscure thing nobody will encounter in practice atm but it will become much more relevant after https://github.com/docker/docker/issues/31067#issuecomment-287126021@dnephin 
"
31838,1,64,27,0,0,ohcrider,0,"title:Registry mirrors config loss when docker update. description:```Version 17.03.0-ce-mac2 (15654)Channel: stable1d7d97bbbd```![2017-03-15 13 40 55](https://cloud.githubusercontent.com/assets/3256161/23935137/1465819c-0985-11e7-9738-3ad77bf3343d.png)
"
31788,0,1842,0,0,0,dongluochen,0,"title:dind cannot start because group docker not found. description:docker/docker#30729 enforces a requirement for `docker` group to exist in `/etc/group`. While docker-in-docker images do not add this group. It results in `dind` failure. This fails classic Swarm tests https://github.com/docker/swarm/issues/2646. cc @dmcgowan @tonistiigi. **Describe the results you received:**`dind` containers exit after start. ```# CONTAINER ID                                                       IMAGE                            COMMAND                                                                                                                                                                                                                                                                                                                                                   CREATED             STATUS                              PORTS               NAMES# ee839608996df606dbd9a3f00f8abe7ed199ce8ac571d5064404503b96d866fb   dockerswarm/dind-master:latest   ""/dind sh -c '        rm -f /var/run/docker.pid ;         rm -f /var/run/docker/libcontainerd/docker-containerd.pid ;         rm -f /var/run/docker/libcontainerd/docker-containerd.sock ;         hostname node-1 ;         docker daemon -H 127.0.0.1:5562           -H=unix:///var/run/docker.sock           --storage-driver=aufs                '""   1 seconds ago       Exited (1) Less than a second ago                       node-1# 069875fee52b611b5d891cc5efc6e62fb15b9a5be26ac0303921dfd276763d5e   dockerswarm/dind-master:latest   ""/dind sh -c '        rm -f /var/run/docker.pid ;         rm -f /var/run/docker/libcontainerd/docker-containerd.pid ;         rm -f /var/run/docker/libcontainerd/docker-containerd.sock ;         hostname node-0 ;         docker daemon -H 127.0.0.1:5561           -H=unix:///var/run/docker.sock           --storage-driver=aufs                '""   2 seconds ago       Exited (1) Less than a second ago                       node-0```docker logs```# Command ""daemon"" is deprecated, and will be removed in Docker 1.16. Please run `dockerd` directly.# WARN[0000] [!] DON'T BIND ON ANY IP ADDRESS WITHOUT setting --tlsverify IF YOU DON'T KNOW WHAT YOU'RE DOING [!]# group docker not found```**Describe the results you expected:**Only use `docker` group if it has been created. 
"
31753,1,3638,0,0,0,bscheshirwork,0,"title:Ubuntu 16.04: some containers not restarting after reboot. description:From https://github.com/docker/compose/issues/4603Some container composition don't (re)start correctly after reboot.docker-compose.yml (1)```version: '2'services:  php:    image: bscheshir/php:7.1.2-fpm-4yii2-xdebug    restart: always    volumes:      - ../php-code:/var/www/html #php-code    depends_on:      - db    environment:      TZ: Europe/Moscow      XDEBUG_CONFIG: ""remote_host=192.168.0.83 remote_port=9001 var_display_max_data=1024 var_display_max_depth=5""      PHP_IDE_CONFIG: ""serverName=yii2""  nginx:    image: bscheshir/nginx:alpine    restart: always    ports:      - ""8081:80""      - ""8082:8080""      - ""8083:8088""    depends_on:      - php    volumes_from:      - php    volumes:      - ../nginx-conf:/etc/nginx/conf.d #nginx-conf      - ../nginx-logs:/var/log/nginx #nginx-logs    environment:      TZ: Europe/Moscow  mysql:    image: mysql:8.0.0    restart: always    expose:      - ""3306"" #for service mysql-proxy    ports:      - ""3307:3306"" #for external connection    volumes:      - ../mysql-data/db:/var/lib/mysql #mysql-data    environment:      TZ: Europe/Moscow      MYSQL_ROOT_PASSWORD: yii2      MYSQL_DATABASE: yii2      MYSQL_USER: yii2      MYSQL_PASSWORD: yii2  db: #mysql-proxy    image: bscheshir/mysql-proxy:0.8.5    expose:      - ""3306"" #for service php    ports:      - ""3308:3306"" #for external connection    restart: always    volumes:      - ../mysql-proxy/log.lua:/opt/log.lua      - ../mysql-proxy/mysql.log:/opt/mysql-proxy/mysql.log    environment:      TZ: Europe/Moscow      PROXY_DB_PORT: 3306      REMOTE_DB_HOST: mysql      REMOTE_DB_PORT: 3306      PROXY_LUA_SCRIPT: ""/opt/log.lua""    depends_on:      - mysql```In the `docker ps` list STATUS is ""Up 5 minutes""`docker inspect -f ""{{ .HostConfig.RestartPolicy }}"" <container>` return `always` for all containerBut service does not work correctly http access to web server 0.0.0.0:8081 0.0.0.0:8082 0.0.0.0:8083 (Connection was dropped), connect to db 3307 (Some strange: I can connect, but I can see the information schema only) (php not tested) Same situation with (2)```version: '2'services:  php:    image: bscheshir/php:7.1.2-fpm-4yii2-xdebug    restart: always    volumes:      - ./php-code:/var/www/html #php-code    depends_on:      - db    environment:      TZ: Europe/Moscow      XDEBUG_CONFIG: ""remote_enable=Off remote_autostart=Off""  nginx:    image: nginx:1.11.10-alpine    restart: always    ports:      - ""80:80""      - ""8080:8080""      - ""8088:8088""    depends_on:      - php    volumes_from:      - php    volumes:      - ./nginx-conf:/etc/nginx/conf.d #nginx-conf      - ./nginx-logs:/var/log/nginx #nginx-logs  db:    image: mysql:8.0.0    restart: always    volumes:      - ./mysql-data/db:/var/lib/mysql #mysql-data    environment:      TZ: Europe/Moscow      MYSQL_ROOT_PASSWORD: yii2      MYSQL_DATABASE: yii2      MYSQL_USER: yii2      MYSQL_PASSWORD: yii2```And other composition is running correctly at same time: `sameersbn/gitlab`The another composition for same config (env difference) may up correctly after reboothttps://github.com/bscheshirwork/docker-yii2-app-advanced-rbac/blob/master/docker-compose.yml (3)```version: '2'services:  php:    image: bscheshir/php:7.1.2-fpm-4yii2-xdebug    restart: always    volumes:      - ./php-code:/var/www/html #php-code    depends_on:      - db    environment:      TZ: Europe/Moscow      XDEBUG_CONFIG: ""remote_enable=Off remote_autostart=Off""  nginx:    image: nginx:1.11.10-alpine    restart: always    ports:      - ""80:80""      - ""8080:8080""    depends_on:      - php    volumes_from:      - php    volumes:      - ./nginx-conf:/etc/nginx/conf.d #nginx-conf      - ./nginx-logs:/var/log/nginx #nginx-logs  db:    image: mysql:8.0.0    restart: always    volumes:      - ./mysql-data/db:/var/lib/mysql #mysql-data    environment:      TZ: Europe/Moscow      MYSQL_ROOT_PASSWORD: yii2advanced      MYSQL_DATABASE: yii2advanced      MYSQL_USER: yii2advanced      MYSQL_PASSWORD: yii2advanced```And if I up then together ( (2) and (3) ) - all of it is fails after reboot  ```docker -vDocker version 17.03.0-ce, build 60ccb22docker-compose -vdocker-compose version 1.9.0, build 2585387```After run docker-compose restart manually ```/usr/local/bin/docker-compose -f /home/dev/projects/project/docker-compose.yml restart```services is run correctly  Any ideas?
"
31735,1,1617,279,0,0,cpuguy83,0,"title:Switch live-restore off breaks restart policy. description:**Description**When turning off live restore, the first time the daemon is restarted, restart policies do not seem to kick in.**Steps to reproduce the issue:**1. start docker with `dockerd --live-restore`2. start a container with a restart policy `docker run -d --name test --restart=always busybox top`3. `pkill dockerd`4. start docker with just `dockerd`5. Observe `test` container**Describe the results you received:**Container with restart policy is left in a stopped state on daemon restart**Describe the results you expected:**Container should be automatically started after daemon is brought back up**Additional information you deem important (e.g. issue happens only occasionally):**None**Output of `docker version`:**```Client: Version:      17.04.0-dev API version:  1.27 Go version:   go1.7.5 Git commit:   58562d7 Built:        Fri Mar 10 02:03:23 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-dev API version:  1.27 (minimum version 1.12) Go version:   go1.7.5 Git commit:   58562d7 Built:        Fri Mar 10 02:03:23 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 2 Running: 0 Paused: 0 Stopped: 2Images: 1Server Version: 17.04.0-devStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 5 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary:containerd version: 665e84e6c28653a9c29a6db601636a92d46896f3runc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70 (expected: 54296cf40ad8143b62dbcaa1d90e520a2136ddfe)init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.12-mobyOperating System: Debian GNU/Linux 8 (jessie) (containerized)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952GiBName: cf13527bdfaeID: T4MV:VSAK:73VI:SAB5:3UYK:HYA3:RBNW:FCDT:V4LA:GV5W:IUOD:MRRNDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 13 Goroutines: 22 System Time: 2017-03-10T03:58:22.172826056Z EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Running in dind in d4mac
"
31699,0,2830,279,0,0,cpuguy83,0,"title:Unkillable container after pause and kill -9 dockerd. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. docker run -d --name test busybox top2. docker pause test3. pkill -9 dockerd4. start dockerd**Describe the results you received:**In docker, container is marked as exited, but is still running (in paused state).This causes some really nasty behavior as well if you shutdown the daemon again and restart it.`Store.Cleanup()` fails with ebusy (because there's still a process running).Daemon takes longer to start trying to sync up state:```DEBU[0001] Loaded container 951cc0a5d14df315cff3ab06f26df179c12bb834c2860446a2da3283b957fc06DEBU[0001] Loaded container 95aee30e1454c724a181e69e3267e2458e46e483b05cbc3a332b7b2a5512d86aWARN[0001] libcontainerd: client is out of sync, restore was called on a fully synced container (951cc0a5d14df315cff3ab06f26df179c12bb834c2860446a2da3283b957fc06).ERRO[0013] state changed                                 container=951cc0a5d14df315cff3ab06f26df179c12bb834c2860446a2da3283b957fc06 state=exit```> **note**: the error log about ""state changed"" is something I put in for debugging> **note**: it's getting an event from containerd on the paused container that the container exited, but it did not.> **note**: the 12 second delay caused in this case.```$ docker-runc listID                                                                 PID         STATUS      BUNDLE                                                                                       CREATED951cc0a5d14df315cff3ab06f26df179c12bb834c2860446a2da3283b957fc06   23684       paused      /run/docker/libcontainerd/951cc0a5d14df315cff3ab06f26df179c12bb834c2860446a2da3283b957fc06   2017-03-09T17:10:53.812306125Z```Calling `docker-runc resume` on the paused container triggers an event from containerd:```DEBU[0168] libcontainerd: received containerd event: &types.Event{Type:""exit"", Id:""951cc0a5d14df315cff3ab06f26df179c12bb834c2860446a2da3283b957fc06"", Status:0x89, Pid:""init"", Timestamp:(*timestamp.Timestamp)(0xc42098b020)}WARN[0168] libcontainerd: unknown container 951cc0a5d14df315cff3ab06f26df179c12bb834c2860446a2da3283b957fc06```**Describe the results you expected:**State for a paused container should be correctly synced.**Additional information you deem important (e.g. issue happens only occasionally):**This is really an edge case, but also had some really weird issues when dropping from a live-restore enabled daemon to disabled with all this pause stuff as well, but it's proven difficult to reproduce.**Output of `docker version`:**```Client: Version:      17.04.0-dev API version:  1.27 Go version:   go1.7.5 Git commit:   58562d7 Built:        Thu Mar  9 17:05:50 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-dev API version:  1.27 (minimum version 1.12) Go version:   go1.7.5 Git commit:   58562d7 Built:        Thu Mar  9 17:05:50 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 2 Running: 0 Paused: 0 Stopped: 2Images: 1Server Version: 17.04.0-devStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 5 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary:containerd version: 665e84e6c28653a9c29a6db601636a92d46896f3runc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.12-mobyOperating System: Debian GNU/Linux 8 (jessie) (containerized)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952GiBName: cf13527bdfaeID: T4MV:VSAK:73VI:SAB5:3UYK:HYA3:RBNW:FCDT:V4LA:GV5W:IUOD:MRRNDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 17 Goroutines: 23 System Time: 2017-03-09T17:57:26.097121608Z EventsListeners: 0Registry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Tested in dind (on d4mac) trying to pinpoint an issue with #29554.
"
31697,0,1818,0,0,0,roy-codefresh,0,"title:Can't build images with labels that contains space inside of quotes. description:**Description**Can't build images with label that contains space ( ) between quotes(') in it's value.**Steps to reproduce the issue:**1. run command `docker build --label ""key='first second'""`**Describe the results you received:**I get the following error:```Error response from daemon: Syntax error - can't find = in ""second''"". Must be of the form: name=value```**Describe the results you expected:**I expect the build to run regularly and the resulted image to have a label with key named `key` and value `'first second'`.**Additional information you deem important (e.g. issue happens only occasionally):**This problem happen to me after upgrading to docker 17.03 from docker 1.12. Thisbug didn't occur to me on docker 1.12.**Output of `docker version`:**```Client: Version:      17.03.0-ce API version:  1.26 Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Mar  2 01:11:00 2017 OS/Arch:      darwin/amd64Server: Version:      17.03.0-ce API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   3a232c8 Built:        Tue Feb 28 07:52:04 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: $$ Running: $$ Paused: $$ Stopped: $$Images: $$Server Version: 17.03.0-ceStorage Driver: aufs Root Dir: /mnt/sda1/var/lib/docker/aufs Backing Filesystem: extfs Dirs: 299 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 977c511eda0925a723debdc94d09459af49d082arunc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.4.52-boot2dockerOperating System: Boot2Docker 17.03.0-ce (TCL 7.2); HEAD : f11a204 - Thu Mar  2 00:14:47 UTC 2017OSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 995.8 MiBName: codefreshID: WMNW:DC75:4663:BZTY:6B6I:SE2Z:M4SU:YGKB:H3TM:HW3H:N2N5:SQKLDocker Root Dir: /mnt/sda1/var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 181 Goroutines: 229 System Time: 2017-03-09T16:22:18.613208789Z EventsListeners: 2Username: roycodefreshRegistry: https://index.docker.io/v1/Labels: provider=virtualboxExperimental: falseInsecure Registries: $$$$$$$$$$$$$ $$$$$$$$$$$$$Live Restore Enabled: false```
"
31685,0,5045,2,0,0,adaiguoguo,0,"title:Docker ps hang by an incompletely exited container. description:**Output of `docker version`:**```[root@adct-eless-mesos-9 data]# docker versionClient: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:38:28 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:38:28 2017 OS/Arch:      linux/amd64 Experimental: false[root@adct-eless-mesos-9 data]# uname -r3.10.0-514.6.1.el7.x86_64```**Output of `docker info`:**```[root@adct-eless-mesos-9 data]# docker infoContainers: 7 Running: 2 Paused: 0 Stopped: 5Images: 15Server Version: 1.13.1Storage Driver: devicemapper Pool Name: docker-253:17-4456452-pool Pool Blocksize: 65.54 kB Base Device Size: 10.74 GB Backing Filesystem: xfs Data file: /dev/loop0 Metadata file: /dev/loop1 Data Space Used: 3.151 GB Data Space Total: 107.4 GB Data Space Available: 96.11 GB Metadata Space Used: 5.353 MB Metadata Space Total: 2.147 GB Metadata Space Available: 2.142 GB Thin Pool Minimum Free Space: 10.74 GB Udev Sync Supported: true Deferred Removal Enabled: false Deferred Deletion Enabled: false Deferred Deleted Device Count: 0 Data loop file: /data/docker/devicemapper/devicemapper/data WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device. Metadata loop file: /data/docker/devicemapper/devicemapper/metadata Library Version: 1.02.135-RHEL7 (2016-11-16)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.6.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 32Total Memory: 62.76 GiBName: adct-eless-mesos-9.vmID: IFPR:2AE3:EOYQ:KVIN:MABO:SCMJ:HF2P:2AYR:LGIU:6WT2:DRS4:LXH6Docker Root Dir: /data/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: docker-registry.tools.elenet.me:5000 127.0.0.0/8Live Restore Enabled: false```**What is the bug behavior?**```[root@adct-eless-mesos-9 ~]# docker ps```That action hang and container can't be stopped.**How to find the bug root cause?**1: Find the dockerd status```[root@adct-eless-mesos-9 data]# ps -ef|grep dockerdroot        1784       1  0 Feb21 ?        00:58:37 /usr/bin/dockerd --exec-opt native.cgroupdriver=cgroupfs --insecure-registry docker-registry.tools.elenet.me:5000 -g /data/docker -H tcp://127.0.0.1:4243 -H unix:///var/run/docker.sock --bip=10.99.5.129/28 --mtu=1450[root@adct-eless-mesos-9 data]# lsof -p 1784dockerd 1784 root   23u     unix 0xffff880aecb92c00       0t0   13743016 /var/run/docker.sockdockerd 1784 root   24u     unix 0xffff880bfe629c00       0t0   13775439 /var/run/docker.sockdockerd 1784 root   25u     unix 0xffff880f6d75f400       0t0   14510073 /var/run/docker.sockdockerd 1784 root   26u     unix 0xffff880f6d758400       0t0   14526831 /var/run/docker.sockdockerd 1784 root   27w      REG             253,17 283825669    4457362 /data/docker/containers/e8e8a9e36e6ce633077467c7c7954b1b0cfff3df177a936d4d9b47b7b5e3a676/e8e8a9e36e6ce633077467c7c7954b1b0cfff3df177a936d4d9b47b7b5e3a676-json.logdockerd 1784 root   28r      REG             253,17 283825669    4457362 /data/docker/containers/e8e8a9e36e6ce633077467c7c7954b1b0cfff3df177a936d4d9b47b7b5e3a676/e8e8a9e36e6ce633077467c7c7954b1b0cfff3df177a936d4d9b47b7b5e3a676-json.logdockerd 1784 root   29u     sock                0,7       0t0      17167 protocol: NETLINKdockerd 1784 root   30u     unix 0xffff880f6d75ec00       0t0   14531849 /var/run/docker.sockdockerd 1784 root   31u     unix 0xffff880ae8e18c00       0t0   14531856 /var/run/docker.sockdockerd 1784 root   32u     unix 0xffff880fef600400       0t0   14534909 /var/run/docker.sock```Now we get the container `e8e8a9e36e6ce633077467c7c7954b1b0cfff3df177a936d4d9b47b7b5e3a676` both read and write.2闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟鐑橆殢閺佸嫮鈧鍠栭悾鐪恊r inspect```[root@adct-eless-mesos-9 data]# docker inspect e8e8a9e36e6ce633077467c7c7954b1b0cfff3df177a936d4d9b47b7b5e3a676```Now docker inspect id hang.3闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟鐑橆殢閺佸嫰鏌熸潏鈺佸礋d Pid by docker container id```[root@adct-eless-mesos-9 data]# cat /data/docker/containers/e8e8a9e36e6ce633077467c7c7954b1b0cfff3df177a936d4d9b47b7b5e3a676/config.v2.json |python -m json.tool|grep Pid        ""Pid"": 7294,[root@adct-eless-mesos-9 data]# ps -ef|grep 7294root      661378  660472  0 16:04 pts/0    00:00:00 grep --color=auto 7294```The container process `7294` is disappeared.4闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟鐑橆殢閺佸嫰鏌熼鐔氱€爎e the container when to exit.```[root@adct-eless-mesos-9 data]# cat /run/docker/libcontainerd/containerd/events.log|grep e8e8a9e36e6ce633077467c7c7954b1b0cfff3df177a936d4d9b47b7b5e3a676{""id"":""e8e8a9e36e6ce633077467c7c7954b1b0cfff3df177a936d4d9b47b7b5e3a676"",""type"":""start-container"",""timestamp"":""2017-02-21T11:54:43.827455953+08:00""}{""id"":""e8e8a9e36e6ce633077467c7c7954b1b0cfff3df177a936d4d9b47b7b5e3a676"",""type"":""exit"",""timestamp"":""2017-03-08T19:54:27.877604017+08:00"",""pid"":""init"",""status"":137}""status"":137 128 + 9 = 137 (9 coming from SIGKILL)```**So I guess?**The container received a SIGKILL by Mesos.But for some reason, the exit operate was crashed.Then we docker ps,that operate will get info from container.But the container process is not found.
"
31663,0,1543,0,0,0,tswift242,0,"title:Error restoring container from checkpoint: ""No parent found for mountpoint"". description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Very sporadically, I get the following type of error when trying to restore a container from a checkpoint, which causes the restore to fail:""Error (criu/mount.c:360): mnt: No parent found for mountpoint 574 (@./var/lib/docker/checkpoints/test_cp/criu.work/restore-2017-03-08T15:12:42Z/.criu.cgyard.fnEP8f/systemd)""The full criu restore.log is attached.[restore.txt](https://github.com/docker/docker/files/829057/restore.txt)It seems to sporadically happen when I restore several containers from the same checkpoint at the same time. The issue reproduced 8/720 times when I ran the following script, which just starts and stops a bunch of simple Ubuntu containers over and over (renamed to satisfy github):[stress_cr_simple_start_stop.txt](https://github.com/docker/docker/files/829065/stress_cr_simple_start_stop.txt)I gave the script the following parameters: ```./stress_cr_simple_start_stop.sh 10 720```; this will go through 720 rounds of restoring 10 containers at a time from the same checkpoint.I wonder if this has anything to do with the way docker assigns the criu work dir for each restore. Docker creates a separate work directory for each restore; the directory names are differentiated with a datetimestamp with second precision. So, this means that if docker makes 2+ restore calls to criu within a second, the work dir for those restores could be the same. As an example, when I ran the script above for 720 runs with 10 concurrent restores at a time (7200 restores total), there were only 1087 different work directories created. The path that the criu error cites appears to be an ephemeral path that is created during the restore and which sits inside the work dir. If there are multiple concurrent restores happening for the same checkpoint, it therefore seems possible that they could be stepping on each others' toes if they are using the same work dir.**Steps to reproduce the issue:**1. ```./stress_cr_simple_start_stop.sh 10 720``` (can be a smaller number than 720, but should probably be at least 100)2. Observe restore failures during script execution, or grep for them afterward: ```grep -l ""Error"" /var/lib/docker/checkpoints/test_cp/criu.work/**/*```**Describe the results you received:**Restore fails with message like ""Error (criu/mount.c:360): mnt: No parent found for mountpoint 574 (@./var/lib/docker/checkpoints/test_cp/criu.work/restore-2017-03-08T15:12:42Z/.criu.cgyard.fnEP8f/systemd)""**Describe the results you expected:**Restores should always succeed, especially for a basic Ubuntu container.**Output of `docker version`:**```Client: Version:      17.03.0-ce API version:  1.26 Go version:   go1.7.5 Git commit:   3a232c8 Built:        Tue Feb 28 07:57:58 2017 OS/Arch:      linux/amd64Server: Version:      17.03.0-ce API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   3a232c8 Built:        Tue Feb 28 07:57:58 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 27Server Version: 17.03.0-ceStorage Driver: overlay Backing Filesystem: extfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 977c511eda0925a723debdc94d09459af49d082arunc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70init version: 949e6faSecurity Options: apparmorKernel Version: 4.10.1-041001-genericOperating System: Ubuntu 14.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 16Total Memory: 120.1 GiBName: ip-10-97-0-35ID: PBSJ:KR3H:XP7F:KQMN:CFJS:J75A:ZGUM:ZSC3:5DUR:MCZJ:5ACD:CXM7Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Using AWS and criu 2.11.
"
31627,1,4723,0,0,0,mojavezax,0,"title:Volume mount options keep reverting to earlier options when creating a service. description:**Description**I'm seeing some strange behavior while trying to mount an NFS volume whencreating a service. It appears that the `--mount` options keep reverting backto previously used options.Note that I'm only seeing this problem because I can't get the NFS mount to work at all.But that's another issue.**Steps to reproduce the issue:**1.  Create a service with a `--mount` option that references an NFS share.2.  List the service with `docker service ps --no-trunc`3.  Create another service with a `--mount` option referencing a _different server and share_4.  List this service in the same way.**Describe the results you received:**Running two tests with different NFS servers and shares, I got the same error message _with the same details_ each time:The first test goes like this:```$ docker service create --mount 'type=volume,source=sw,target=/mnt,volume-driver=local,volume-opt=type=nfs,volume-opt=device=10.30.216.38:/sw' --name fedora1 fedora /bin/bashl7r04fk3m38znmgk7brvoqzjd$ docker service ps --no-trunc fedora1ID                         NAME           IMAGE                                                                                  NODE                        DESIRED STATE  CURRENT STATE            ERROR                                                                                                                             PORTSy82mciumek6f5dlfausxdymnc  fedora1.1      fedora:latest@sha256:8d3f642aa4d3fa8f9dc52ab0e3bbbe8bc2494843dc6ebb26c4a6958db888e5a2  beryllium.example.com  Ready          Rejected 5 seconds ago   ""error while mounting volume with options: type='nfs' device=':/sw' o='addr=strontium.example.com': protocol not supported""leqzzempzukf8xjjlg9in44jt   \_ fedora1.1  fedora:latest@sha256:8d3f642aa4d3fa8f9dc52ab0e3bbbe8bc2494843dc6ebb26c4a6958db888e5a2  beryllium.example.com  Shutdown       Rejected 10 seconds ago  ""error while mounting volume with options: type='nfs' device=':/sw' o='addr=strontium.example.com': protocol not supported""$ docker service rm fedora1fedora1```The error message (which is another matter) shows the correct host name associated with the given address.Next, I try another test, _using a different NFS host and share_:```$ docker service create --mount 'type=volume,source=sw,target=/mnt,volume-driver=local,volume-opt=type=nfs,volume-opt=device=10.30.216.171:/shares/sw' --name fedora1 fedora /bin/bashxdj6rw1q8uaqarnwi4iqlpvai$ docker service ps --no-trunc fedora1ID                         NAME           IMAGE                                                                                  NODE                        DESIRED STATE  CURRENT STATE           ERROR                                                                                                                             PORTS2zj602q63m5dclofhx2q2mtua  fedora1.1      fedora:latest@sha256:8d3f642aa4d3fa8f9dc52ab0e3bbbe8bc2494843dc6ebb26c4a6958db888e5a2  beryllium.example.com  Ready          Rejected 4 seconds ago  ""error while mounting volume with options: type='nfs' device=':/sw' o='addr=strontium.example.com': protocol not supported""ddm6t162vdebyb0bsztrr6kx1   \_ fedora1.1  fedora:latest@sha256:8d3f642aa4d3fa8f9dc52ab0e3bbbe8bc2494843dc6ebb26c4a6958db888e5a2  beryllium.example.com  Shutdown       Rejected 4 seconds ago  ""error while mounting volume with options: type='nfs' device=':/sw' o='addr=strontium.example.com': protocol not supported""```Notice that the error message is exactly the same as the first! It still shows the host and share from the previous command.**Swarm environment**The manager is a VM and the workers are physical servers:```$ docker node lsID                           HOSTNAME               STATUS  AVAILABILITY  MANAGER STATUS0m73f50mpyhrrwmm60g7z0rr3    magnesium.example.com  Ready   Activej8iw5acnxhyowqh0heqawe8cz    beryllium.example.com  Ready   Activemtfevwhyxvgr1rphssv9ysi9p *  astatine.example.com   Ready   Drain         Leader```**Describe the results you expected:**The error messages should be different  ;-)**Additional information you deem important (e.g. issue happens only occasionally):**I restarted the docker engine, and also rebooted the machine. No change.**Output of `docker version`:**```$ docker versionClient: Version:      17.03.0-ce API version:  1.26 Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Feb 23 10:54:03 2017 OS/Arch:      linux/amd64Server: Version:      17.03.0-ce API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Feb 23 10:54:03 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 22Server Version: 17.03.0-ceStorage Driver: overlay Backing Filesystem: xfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: mtfevwhyxvgr1rphssv9ysi9p Is Manager: true ClusterID: rxne8yabccuskutu23dy40m9a Managers: 1 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 10.30.217.85 Manager Addresses:  10.30.217.85:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 977c511eda0925a723debdc94d09459af49d082arunc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.10.2.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 1.797 GiBName: astatine.example.comID: C3YM:WNQU:66FU:QC26:HNFQ:3BCR:EK5S:H7IX:7JIR:NCX3:2YUD:CPEVDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: silver.example.com:5005 127.0.0.0/8Live Restore Enabled: false```
"
31622,0,0,0,0,0,mlaventure,0,"title:Update containerd to handle invalid container state directories on restore. description:The following PR: https://github.com/docker/containerd/pull/410 need to be cherry-picked in the `containerd` branch used by 17.03.1 to allow it to successfully restore itself when a container state directory gets incomplete  
"
31614,0,9625,9,0,0,thiagoalves,0,"title:Container cannot be stopped, removed or exec'ed. description:**Description**Some containers cannot be stopped. When running `docker stop`, it doesn't output anything and hangs until Ctrl + C is pressed. The same behavior happens with `docker kill`, `docker rm -f` and `docker attach` (exits only with `kill -9` from another terminal). `docker inspect` and `docker logs` work normally.When running `docker exec <container_id> ls` I get:```rpc error: code = 13 desc = invalid header field value ""oci runtime error: exec failed: container_linux.go:247: starting container process caused \""process_linux.go:83: executing setns process caused \\\""exit status 16\\\""\""\n""```After this, `docker exec` gets 'hanged', i.e.: # of ExecIDs for the container increase by one. This can be checked by `docker inspect --format ""{{ len .ExecIDs }} {{ .Name }}"" <container_id>`**Steps to reproduce the issue:**This issue happens randomly (~ once per week) and I couldn't figure out a way to reproduce it yet.**Describe the results you received:**Container can't be stopped, kiiled or removed. Docker exec doesn't work.**Describe the results you expected:**Docker container can be stopped and removed (`rm`, `kill`). Commands can be executed inside of the container (`attach`, `exec`).**Additional information you deem important (e.g. issue happens only occasionally):*** This issue seems to be related to #29794 and #31007, although the former seems to report many different issues in a single ticket.* Container process seems to be in uninterruptible sleep state```   PID TTY      STAT   TIME COMMAND 20542 ?        Ds     0:00 [dumb-init] ```* It seems to be stuck on `zap_pid_ns_processes` kernel call:```# cat /proc/20542/stack[<ffffffff81120f1f>] zap_pid_ns_processes+0x13f/0x1a0[<ffffffff81084731>] do_exit+0xa81/0xb00[<ffffffff81084833>] do_group_exit+0x43/0xb0[<ffffffff810848b4>] SyS_exit_group+0x14/0x20[<ffffffff8183c5f2>] entry_SYSCALL_64_fastpath+0x16/0x71[<ffffffffffffffff>] 0xffffffffffffffff```* Parent process is in sleep state:```# ps 20525   PID TTY      STAT   TIME COMMAND 20525 ?        Sl     0:00 docker-containerd-shim 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a /var/run/docker/libcontainerd/2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86```* Output of `sudo docker-runc exec --cwd / -e PATH=/bin 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a ls````nsenter: failed to open /proc/20542/ns/ipc: No such file or directoryexec failed: container_linux.go:247: starting container process caused ""process_linux.go:83: executing setns process caused \""exit status 16\""""```* Output of `docker logs` (truncated, since the latest `samba-smbd` related error repeat once per minute)```Added user spark.Collect hostkey for masterCollect hostkey for localhostCollect hostkey for 0.0.0.0Starting namenodes on [master]master: Warning: Permanently added the ECDSA host key for IP address '10.1.15.3' to the list of known hosts.master: starting namenode, logging to /opt/hadoop/hadoop-2.7.3/logs/hadoop-hadoop-namenode-master.outlocalhost: starting datanode, logging to /opt/hadoop/hadoop-2.7.3/logs/hadoop-hadoop-datanode-master.outStarting secondary namenodes [0.0.0.0]0.0.0.0: starting secondarynamenode, logging to /opt/hadoop/hadoop-2.7.3/logs/hadoop-hadoop-secondarynamenode-master.outstarting org.apache.spark.deploy.master.Master, logging to /opt/spark/spark-2.0.1-bin-hadoop2.7/logs/spark-spark-org.apache.spark.deploy.master.Master-1-master.out2017-03-07 02:13:49,357 INFO supervisord started with pid 142017-03-07 02:13:50,360 INFO spawned: 'openssh-server' with pid 202017-03-07 02:13:50,362 INFO spawned: 'samba-smbd' with pid 212017-03-07 02:13:50,363 INFO spawned: 'samba-nmbd' with pid 222017-03-07 02:13:51,537 INFO success: openssh-server entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)2017-03-07 02:13:51,537 INFO success: samba-smbd entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)2017-03-07 02:13:51,537 INFO success: samba-nmbd entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)2017-03-07 02:14:01,628 INFO exited: samba-smbd (terminated by SIGTERM; not expected)2017-03-07 02:14:02,633 INFO spawned: 'samba-smbd' with pid 4252017-03-07 02:14:03,833 INFO success: samba-smbd entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)2017-03-07 02:15:01,518 INFO exited: samba-smbd (terminated by SIGTERM; not expected)```* Excerpt of `journalctl -u docker` that may be relevant to this issue (gzipped log has 240MB but I can send it upon request). ```Mar 07 12:26:10 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T12:26:10.238254768Z"" level=debug msg=""libcontainerd: received containerd event: &types.Event{Type:\""start-process\"", Id:\""2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a\"", Status:0x0, Pid:\""879fb34a699c2128485596549cc9d16f7d5f917f7a2b1a4ac23e7c77b10ef313\"", Timestamp:(*timestamp.Timestamp)(0xc82446fa70)}""Mar 07 12:26:10 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T12:26:10.238444580Z"" level=debug msg=""libcontainerd: event unhandled: type:\""start-process\"" id:\""2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a\"" pid:\""879fb34a699c2128485596549cc9d16f7d5f917f7a2b1a4ac23e7c77b10ef313\"" timestamp:<seconds:1488889570 nanos:237642549 > ""Mar 07 12:26:10 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T12:26:10.774784263Z"" level=debug msg=""containerd: process exited"" id=2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a pid=879fb34a699c2128485596549cc9d16f7d5f917f7a2b1a4ac23e7c77b10ef313 status=0 systemPid=21461Mar 07 12:26:10 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T12:26:10.775580140Z"" level=debug msg=""libcontainerd: received containerd event: &types.Event{Type:\""exit\"", Id:\""2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a\"", Status:0x0, Pid:\""879fb34a699c2128485596549cc9d16f7d5f917f7a2b1a4ac23e7c77b10ef313\"", Timestamp:(*timestamp.Timestamp)(0xc829510c00)}""Mar 07 12:26:40 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T12:26:40.776904366Z"" level=debug msg=""starting exec command 5b934d22287cc939f54f95769b1eb42494db450610e7b01ce6d4d9b607b7a86e in container 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""Mar 07 12:32:04 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T12:32:04.724028384Z"" level=debug msg=""Sending 15 to 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""Mar 07 12:34:37 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T12:34:37.899622463Z"" level=info msg=""Container 2b585a819f31 failed to exit within 10 seconds of kill - trying direct SIGKILL""Mar 07 13:06:09 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T13:06:09.211150018Z"" level=info msg=""Container 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a failed to exit within 10 seconds of signal 15 - using the force""Mar 07 13:06:09 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T13:06:09.211198698Z"" level=debug msg=""Sending 9 to 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""Mar 07 13:27:12 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T13:27:12.464715820Z"" level=info msg=""Container 2b585a819f31 failed to exit within 10 seconds of kill - trying direct SIGKILL""Mar 07 14:02:24 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T14:02:24.363250206Z"" level=info msg=""Container 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a failed to exit within 10 seconds of signal 15 - using the force""Mar 07 14:02:24 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T14:02:24.363341827Z"" level=debug msg=""Sending 9 to 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""Mar 07 15:08:06 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T15:08:06.571521919Z"" level=info msg=""Container 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a failed to exit within 10 seconds of signal 15 - using the force""Mar 07 15:08:06 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T15:08:06.571621959Z"" level=debug msg=""Sending 9 to 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""Mar 07 15:34:02 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T15:34:02.550021915Z"" level=debug msg=""starting exec command 110737c8b19da62e188434b363150427994185d79a95180f931acae1b71c6b51 in container 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""Mar 07 15:42:07 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T15:42:07.226136748Z"" level=info msg=""Container 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a failed to exit within 10 seconds of signal 15 - using the force""Mar 07 15:42:07 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T15:42:07.226229951Z"" level=debug msg=""Sending 9 to 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""Mar 07 16:08:17 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T16:08:17.523414592Z"" level=debug msg=""Sending 15 to 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""Mar 07 16:11:11 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T16:11:11.920430683Z"" level=debug msg=""Sending 9 to 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""Mar 07 16:12:49 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T16:12:49.010837942Z"" level=debug msg=""starting exec command e4764e23e9740e6212cc6fa2f1429d774b7ea807cfe43602277b505922c2a128 in container 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""Mar 07 16:19:17 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T16:19:17.805066095Z"" level=debug msg=""Sending 15 to 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""Mar 07 16:19:19 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T16:19:19.402231732Z"" level=debug msg=""Sending 15 to 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""Mar 07 16:19:20 ip-10-69-11-89 dockerd[89174]: time=""2017-03-07T16:19:20.855255324Z"" level=debug msg=""Sending 15 to 2b585a819f31b11a642bb66efd921f5b39fe5b7550b4e06702c0f10e86d4ca1a""```* Output of `sudo ls -l /var/run/runc`, `ps axjf`, `sudo docker-runc list`: https://gist.github.com/thiagoalves/fe8da3ecabe23990ed9b8b2198c4e69d**Output of `docker version`:**```Client: Version:      1.12.3-cs4 API version:  1.24 Go version:   go1.6.3 Git commit:   65c6c4c Built:        Fri Nov 11 16:23:03 2016 OS/Arch:      linux/amd64Server: Version:      1.12.3-cs4 API version:  1.24 Go version:   go1.6.3 Git commit:   65c6c4c Built:        Fri Nov 11 16:23:03 2016 OS/Arch:      linux/amd64```**Output of `docker info`:**```Containers: 240 Running: 221 Paused: 0 Stopped: 19Images: 749Server Version: 1.12.3-cs4Storage Driver: aufs Root Dir: /opt/io1/docker/aufs Backing Filesystem: extfs Dirs: 3740 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcSecurity Options: apparmor seccompKernel Version: 4.4.0-64-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 128Total Memory: 1.876 TiBName: ip-10-69-11-89ID: UGZS:UFD3:GB4C:W5MX:JU2L:K7PH:6ZWS:4GPM:27Q5:UNNN:X3DC:YDT7Docker Root Dir: /opt/io1/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 2362 Goroutines: 2607 System Time: 2017-03-07T16:26:05.191047529Z EventsListeners: 2Registry: https://index.docker.io/v1/WARNING: No swap limit supportInsecure Registries: 127.0.0.0/8```**Additional environment details (AWS, VirtualBox, physical, etc.):**Linux 16.04 on EC2 dedicated host (x1.32xlarge)
"
31610,0,2182,1,0,0,lsapan,0,"title:Docker creates ingress network folder in /var/lib/docker even when using -g. description:**Description**We are specifying a different docker root with `-g`, i.e. `-g /data/docker/`. It works, however docker is still recreating the `/var/lib/docker` folder and creates: `/var/lib/docker/network/files/ingress_sbox`.Inside that folder are three files:```root@xxx:/var/lib/docker/network/files/ingress_sbox# ls -ltotal 12-rw-r--r-- 1 root root 150 Mar  7 13:18 hosts-rw-r--r-- 1 root root  58 Mar  7 13:18 resolv.conf-rw-r--r-- 1 root root  71 Mar  7 13:18 resolv.conf.hash```**Steps to reproduce the issue:**1. Create a swarm2. Create a service**Describe the results you received:**Docker is creating the `/var/lib/docker` folder.**Describe the results you expected:**Docker shouldn't create the `/var/lib/docker` folder.**Output of `docker version`:**```Client: Version:      17.03.0-ce API version:  1.26 Go version:   go1.7.5 Git commit:   3a232c8 Built:        Tue Feb 28 08:01:32 2017 OS/Arch:      linux/amd64Server: Version:      17.03.0-ce API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   3a232c8 Built:        Tue Feb 28 08:01:32 2017 OS/Arch:      linux/amd64```**Output of `docker info`:**```Containers: 20 Running: 6 Paused: 0 Stopped: 14Images: 20Server Version: 17.03.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: 9xet8ik8dju4y8786a2b3aemd Is Manager: true ClusterID: c935qq94yavddxpuc6292zbxu Managers: 3 Nodes: 5 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 172.31.70.70 Manager Addresses:  172.31.70.70:2377  172.31.71.70:2377  172.31.72.70:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 977c511eda0925a723debdc94d09459af49d082arunc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-64-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 1.952 GiBName: ip-172-31-70-70ID: FMBW:VTZX:TIKD:2IDU:P23J:LAOZ:5PAX:ZUOT:WUIY:NTES:LX5W:VR76Docker Root Dir: /data/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Swarm is hosted in AWS, we are specifying a second EBS volume (which is encrypted) with `-g`.
"
31592,1,3424,16,0,0,zcola,0,"title:Swarm dns down. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Swarm dns down<!--Briefly describe the problem you are having in a few paragraphs.-->**Describe the results you received:**Into the kibana container wget http://kibana:5601, the container is no problemEnter the nginx_front_and_api container```/ # cat /etc/resolv.confnameserver 127.0.0.11options ndots:0/ # ping kibanaping: bad address 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤鐓庡娴滄潒bana'/ # ping bakerping: bad address 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劘閳ь剙鎳愰悮楣兟ㄩ惇鍗?``````[2017-03-07 09:42:12]  docker psCONTAINER ID        IMAGE                                                                                                                       COMMAND                  CREATED             STATUS              PORTS               NAMES39190836618b        dockerhub.vvv/elk/baker@sha256:0447902dbf0154a68e3d439b611671d414f87d6e7808953a69ae04d5d58a6a24                 ""/docker-entrypoin...""   3 days ago          Up 3 days                               baker.1.u6yyzv8tls8nu6a3rspvntoaz3751950ed3c0        dockerhub.vvv/elk/nginx_tribe@sha256:c8410f55200056879ac89128df87219b51533e0de1ae5d637ef6395ec0720844           ""nginx -g 'daemon ...""   8 days ago          Up 8 days           80/tcp, 443/tcp     nginx_tribe.2.9r60x74kzxjxxf4j0zv9d3ch4a52a8fc48119        dockerhub.vvv/elk/nginx_front_and_api@sha256:ceae0602d5ef537dd66983f329fb73123702c0c639f235facc5e0f5ff695c3cc   ""nginx -g 'daemon ...""   8 days ago          Up 8 days           80/tcp, 443/tcp     nginx_front_and_api.1.j7vwp5nh4onxlvwx1z27ko8cq58ae72eaec33        dockerhub.vvv/elk/alert:2017022404                                                                              ""/docker-entrypoin...""   8 days ago          Up 8 days           9001/tcp            alert.1.xoy9nxqavd3aeytpa68k36qco[2017-03-07 09:42:26]  /etc/init.d/docker  restart[ ok ] Stopping Docker: docker.[ ok ] Starting Docker: docker.```Restart docker01 back to normaldocker01 loghttps://gist.github.com/zcola/5addd510ad7ae0b3b095b4df0bbeb3c4**Additional information you deem important (e.g. issue happens only occasionally):**Upgrade 1.13 did not encounter this problem before, the previous version is 1.12.4May be associated with https://github.com/docker/docker/issues/31512, 闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟鎹愵嚙缁€鍌毲庨崶銊с€?be associated with https://github.com/docker/docker/issues/31562 闂?.13 Is it suitable for use in products? Feeling very unstable闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈鹃檮閸嬨倖銇? downgrade to 1.12.5  have a problem?**Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:36:34 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:36:34 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 2 Running: 0 Paused: 0 Stopped: 2Images: 14Server Version: 1.13.1Storage Driver: overlay Backing Filesystem: xfs Supports d_type: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: mqn5g91bmyjmukdse0v9l7k0v Is Manager: true ClusterID: 5tck16yngivrjwn360atgs4ky Managers: 3 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: x.s.72.13 Manager Addresses:  x.s.72.13:2377  x.s.72.14:2377  x.s.72.16:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faKernel Version: 4.7.0-0.bpo.1-amd64Operating System: Debian GNU/Linux 8 (jessie)OSType: linuxArchitecture: x86_64CPUs: 6Total Memory: 11.74 GiBName: elk-docker01-502.aaID: 45QU:5VNL:4WPT:7WVA:VSYL:AI6O:5PE2:BCWC:SX6W:NJLA:UPGO:CWWQDocker Root Dir: /home/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**kvm
"
31515,1,2747,0,0,0,yamnicz3k,0,"title:Docker ignores --log-opt (1.12.6). description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**For _json-file_ logging driver options are ignored.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. Install RHEL7.32. Configure docker to use _json-file_ logging driver3. Runs container with _--log-opt max-size=100k --log-opt max-file=2_**Describe the results you received:**```# ls -ltotal 1055824-rw-r----- 1 root root 1081127027 Mar  3 14:17 25c24257d4713a6f5fb21dc063d6bc62a15571f643b2ec10943b2352468b800f-json.log-rw-rw-rw- 1 root root       4570 Mar  3 12:46 config.v2.json-rw-rw-rw- 1 root root       1117 Mar  3 12:46 hostconfig.json-rw-r--r-- 1 root root         13 Mar  3 12:46 hostname-rw-r--r-- 1 root root        223 Mar  3 12:46 hosts-rw-r--r-- 1 root root         59 Mar  3 12:46 resolv.conf-rw-r--r-- 1 root root         71 Mar  3 12:46 resolv.conf.hashdrwxrwxrwt 2 root root         40 Mar  3 12:46 shm```**Describe the results you expected:**100k logfile size. :)**Output of `docker version`:**```Client: Version:      1.12.6 API version:  1.24 Go version:   go1.6.4 Git commit:   78d1802 Built:        Tue Jan 10 20:20:01 2017 OS/Arch:      linux/amd64Server: Version:      1.12.6 API version:  1.24 Go version:   go1.6.4 Git commit:   78d1802 Built:        Tue Jan 10 20:20:01 2017 OS/Arch:      linux/amd64```**Output of `docker info`:**```# docker infoContainers: 25 Running: 11 Paused: 0 Stopped: 14Images: 57Server Version: 1.12.6Storage Driver: devicemapper Pool Name: vg1-thinpool Pool Blocksize: 524.3 kB Base Device Size: 10.74 GB Backing Filesystem: xfs Data file:  Metadata file:  Data Space Used: 11.95 GB Data Space Total: 42.74 GB Data Space Available: 30.78 GB Metadata Space Used: 3.912 MB Metadata Space Total: 1.065 GB Metadata Space Available: 1.061 GB Thin Pool Minimum Free Space: 4.273 GB Udev Sync Supported: true Deferred Removal Enabled: true Deferred Deletion Enabled: true Deferred Deleted Device Count: 0 Library Version: 1.02.135-RHEL7 (2016-09-28)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: overlay null host bridgeSwarm: active NodeID: dad1q44mvuh8thifz6vxiv0nj Is Manager: true ClusterID: 1bv8swnokj5rc93jd4ipyr2aq Managers: 5 Nodes: 5 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 10.11.12.15Runtimes: runcDefault Runtime: runcSecurity Options: seccompKernel Version: 3.10.0-514.el7.x86_64Operating System: Red Hat Enterprise Linux Server 7.3 (Maipo)OSType: linuxArchitecture: x86_64CPUs: 16Total Memory: 31.42 GiBName: app-04.somedomain.comID: 2MNJ:IYA2:KAXC:O4Q2:P27G:YVJV:VZRF:SS2W:7IGB:2LBE:OYY6:O2LCDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 235 Goroutines: 19736 System Time: 2017-03-03T14:25:06.938459812+01:00 EventsListeners: 9Registry: https://index.docker.io/v1/Insecure Registries: 10.11.12.13:5000 10.11.12.13:5043 127.0.0.0/8```**Additional environment details (AWS, VirtualBox, physical, etc.):**VMware
"
31504,0,2402,300,0,0,tianon,0,"title:sh: `__docker_complete_detach-keys': not a valid identifier. description:**Description**Bash completion from master spits out a few warnings that then result in more warnings later:```console$ bash --versionGNU bash, version 4.3.48(1)-release (x86_64-pc-linux-gnu)Copyright (C) 2013 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>This is free software; you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.$ git log -1 --oneline0ab40a7 Merge pull request #31496 from vieux/update_deprecation$ source contrib/completion/bash/dockersh: `__docker_complete_detach-keys': not a valid identifiersh: `_docker_swarm_join-token': not a valid identifiersh: `_docker_swarm_unlock-key': not a valid identifier$ docker run <tab>$ docker run sh: __docker_complete_detach-keys: command not found```**Describe the results you received:**Warnings!**Describe the results you expected:**No warnings. :smile:**Output of `docker version`:**```console$ docker versionClient: Version:      17.04.0-dev API version:  1.27 Go version:   go1.7.5 Git commit:   0ab40a7-unsupported Built:        Thu Mar  2 16:36:14 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-dev API version:  1.27 (minimum version 1.12) Go version:   go1.7.5 Git commit:   0ab40a7-unsupported Built:        Thu Mar  2 16:36:14 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```console$ docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 5Server Version: 17.04.0-devStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: containerd version:  (expected: 665e84e6c28653a9c29a6db601636a92d46896f3)runc version: c91b5be (expected: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70)init version: N/A (expected: 949e6facb77383876aeff8a6944dde66b3089574)Security Options: seccomp  Profile: defaultKernel Version: 4.9.0-1-amd64Operating System: Gentoo/LinuxOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.45GiBName: viper-gentooID: L6I4:TCEW:OW73:FLZJ:NI65:RF7T:IX42:3DU3:LIYG:MTTV:RIGK:HDZ6Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled```cc @albers :+1: :heart:
"
31498,1,4004,7,0,0,CrimsonGlory,0,"title:Can't stop containers (rpc error: code = 14 desc = grpc: the connection is unavailable). description:**Description**Can't stop containers. ```docker-compose stopERROR: for backupdbsystem_db_1  Cannot stop container 869ccc14268f0c1db0b4fa5b0cfdcb5385ecfb3c86ef6c936c096e3625c348c8: Cannot kill container 869ccc14268f0c1db0b4fa5b0cfdcb5385ecfb3c86ef6c936c096e3625c348c8: rpc error: code = 14 desc = grpc: the connection is unavailable```**Steps to reproduce the issue:**1. System is under heavy load (right now: ""load average: 22.22, 22.30, 23.15"", but was about 35 when things started to go wrong)2. docker stop <any container>3. error**Additional information you deem important (e.g. issue happens only occasionally):**Complete docker.log file[docker.log file](http://www.mediafire.com/file/ru58oxpfr8w3nga/complete_logs.log)Relevant:```time=""2017-03-01T18:12:29.611724770-05:00"" level=error msg=""Handler for POST /v1.26/containers/backupdbsystem_db1/exec returned error: No such container: backupdbsystem_db1"" time=""2017-03-02T14:15:36.045669576-05:00"" level=error msg=""attach: stdout: write unix /var/run/docker.sock->@: write: broken pipe"" time=""2017-03-02T14:15:36.045723534-05:00"" level=error msg=""Error running exec in container: exec attach failed with error: write unix /var/run/docker.sock->@: write: broken pipe"" ESC[34mINFOESC[0m[0014] Firewalld running: false                     panic: close of nil channelgoroutine 206231 [running]:panic(0x8082e0, 0xc420664f50)        /usr/local/go/src/runtime/panic.go:500 +0x1a1github.com/docker/containerd/supervisor.(*Supervisor).execExit.func1(0xc4205cc960, 0xc420153110, 0x0)        /tmp/tmp.ezSaVZlwBZ/src/github.com/docker/containerd/supervisor/exit.go:90 +0x10ccreated by github.com/docker/containerd/supervisor.(*Supervisor).execExit        /tmp/tmp.ezSaVZlwBZ/src/github.com/docker/containerd/supervisor/exit.go:91 +0xeetime=""2017-03-02T14:25:02.716919328-05:00"" level=error msg=""libcontainerd: failed to receive event from containerd: rpc error: code = 13 desc = transport is closing"" time=""2017-03-02T14:25:12.171328514-05:00"" level=warning msg=""failed to retrieve containerd version: rpc error: code = 14 desc = grpc: the connection is unavailable"" ```docker-containerd-shim seems running```# ps aux | grep docker-containerd | grep 869cccroot      2548  0.0  0.0 413292   904 ?        Sl   Mar01   0:00 docker-containerd-shim 869ccc14268f0c1db0b4fa5b0cfdcb5385ecfb3c86ef6c936c096e3625c348c8 /var/run/docker/libcontainerd/869ccc14268f0c1db0b4fa5b0cfdcb5385ecfb3c86ef6c936c096e3625c348c8 docker-runc```But sending SIGUSR1 to process does not produce any output on docker.log```# kill -SIGUSR1 2548```**Output of `docker version`:**```# docker versionClient: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:42:29 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:42:29 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 33 Running: 12 Paused: 0 Stopped: 21Images: 229Server Version: 1.13.1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: xfs Dirs: 1058 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: ra5qlktmfa1am2u830g715tp4 Is Manager: true ClusterID: ol2zwaybi9d0mx2js74u3rkbf Managers: 1 Nodes: 2 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.20.46 Manager Addresses:  192.168.20.46:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: N/A (expected: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1)runc version: 9df8b306d01f59d3a8029be411de015b7304dd8f init version: 949e6faSecurity Options: apparmorKernel Version: 4.2.0-42-genericOperating System: Ubuntu 14.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 61.05 GiBName: codexServerID: I3P4:SLVS:BBBQ:SBVF:3XLC:CWAY:3RCM:EFNR:TJPK:RRU7:6WJO:C43JDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: crimsongloryRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**physical
"
31486,0,0,154,0,0,sturman,0,"title:Broken link for Docker for Windows x32 . description:**Description**There is broken link to download Docker for Windows x32 on 'Releases' page v.17.03.0-ce**Steps to reproduce the issue:**1. open Release page2. navigate to tag `v17.03.0-ce`3. try to download `Windows 32bits client zip`**Describe the results you received:**DNS error.Link is broken https://tegett.docker.com/builds/Windows/i386/docker-17.03.0-ce.zip**Describe the results you expected:**ZIP archive is downloadedLink should be https://get.docker.com/builds/Windows/i386/docker-17.03.0-ce.zip #
"
31455,0,2262,27,0,0,cen1,0,"title:Docker daemon crash - corrupted double-linked list. description:---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------**Description**Hard crash of dockerd**Steps to reproduce the issue:**Random crash, can't reproduce yet**Additional information you deem important (e.g. issue happens only occasionally):**Twice today out of nowhere after an hour of restart.**Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:38:28 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:38:28 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 35 Running: 0 Paused: 0 Stopped: 35Images: 52Server Version: 1.13.1Storage Driver: devicemapper Pool Name: docker-253:1-40524435-pool Pool Blocksize: 65.54 kB Base Device Size: 10.74 GB Backing Filesystem: xfs Data file: /dev/loop0 Metadata file: /dev/loop1 Data Space Used: 27.45 GB Data Space Total: 107.4 GB Data Space Available: 11.23 GB Metadata Space Used: 30.38 MB Metadata Space Total: 2.147 GB Metadata Space Available: 2.117 GB Thin Pool Minimum Free Space: 10.74 GB Udev Sync Supported: true Deferred Removal Enabled: false Deferred Deletion Enabled: false Deferred Deleted Device Count: 0 Data loop file: /var/lib/docker/devicemapper/devicemapper/data WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device. Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata Library Version: 1.02.135-RHEL7 (2016-11-16)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.6.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.7 GiBName: staging-internal-ccm.localdomainID: RNVN:UTPN:LR37:JCX6:MOEQ:V3DO:ABUV:INHB:KRIY:O4ZX:XUZP:EDLADocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**OVirt virtual machine, CentOS 7, install from docker repo[docker_dump.txt](https://github.com/docker/docker/files/811236/docker_dump.txt)
"
31447,0,2954,31,0,0,marccarre,0,"title:docker kill weaveproxy hangs indefinitely. description:**Description**`docker kill weaveproxy` hangs indefinitely.**Steps to reproduce the issue:**1. Get a machine with Ubuntu 16.04 LTS and Docker 1.13.1, e.g. running:        $ git clone https://github.com/weaveworks/weave.git        $ cd weave        $ git checkout docker-1.13.1        $ vagrant up        $ vagrant ssh2. Install Weave Net:        $ sudo -s        # curl -L git.io/weave -o /usr/local/bin/weave        # chmod a+x /usr/local/bin/weave        # weave version        weave script 1.9.1        [...]        weave proxy  1.9.1        [...]3. Start the Weave Net proxy:        # weave launch-proxy        [...]        87e922f524073f268e450669ca76771616a80bfe3d16831903f7729116583d1f4. Try to kill it. Docker hangs indefinitely.        # docker ps        CONTAINER ID        IMAGE                        COMMAND                  CREATED             STATUS              PORTS               NAMES        87e922f52407        weaveworks/weaveexec:1.9.1   ""/home/weave/weavepro""   3 seconds ago       Up 3 seconds                            weaveproxy        # docker kill weaveproxy    This last command never returns.**Describe the results you received:**Docker hangs indefinitely.    # docker ps    CONTAINER ID        IMAGE                        COMMAND                  CREATED             STATUS              PORTS               NAMES    87e922f52407        weaveworks/weaveexec:1.9.1   ""/home/weave/weavepro""   3 seconds ago       Up 3 seconds                            weaveproxy    # docker kill weaveproxyThis last command never returns.Following a `ctrl+c` and another `docker ps`, we can see that the uptime under `STATUS` has been reset:    ^C    # docker ps    CONTAINER ID        IMAGE                        COMMAND                  CREATED             STATUS              PORTS               NAMES    87e922f52407        weaveworks/weaveexec:1.9.1   ""/home/weave/weave...""   5 seconds ago       Up 1 second                             weaveproxyNote that this behaviour happens consistently.**Describe the results you expected:**`docker kill` should return and the `weaveproxy` container should disappear:    # docker ps    CONTAINER ID        IMAGE                        COMMAND                  CREATED             STATUS              PORTS               NAMES    9cc6b5c28912        weaveworks/weaveexec:1.9.1   ""/home/weave/weavepro""   3 seconds ago       Up 3 seconds                            weaveproxy    # docker kill weaveproxy    weaveproxy    # docker ps    CONTAINER ID        IMAGE                        COMMAND                  CREATED             STATUS              PORTS               NAMESIf you repeat the same steps against Docker 1.11.2, this is what you will observe.**Output of `docker version`:**```# docker versionClient: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```# docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 1.13.1Storage Driver: overlay Backing Filesystem: extfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-51-genericOperating System: Ubuntu 16.04.1 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 1.954 GiBName: vagrantID: 3IMF:IWUK:V6HP:O7ES:3H6M:UTOP:NCKX:XJ33:MLLP:XBVZ:KPDA:ULLXDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**VirtualBox / Vagrant.However, the same also happens under Google Cloud Platform.Machine type: n1-standard-1 (1 vCPU, 3.75 GB memory)CPU platform: Intel Sandy Bridge```# docker versionClient: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64 Experimental: false``````# docker infoContainers: 7 Running: 2 Paused: 0 Stopped: 5Images: 22Server Version: 1.13.1Storage Driver: overlay Backing Filesystem: extfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-64-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 3.613 GiBName: mct-0ID: KN3B:QQLS:ITVP:QP3T:4Z7L:RAR4:X46C:R5QQ:W64S:GLXC:TWZ5:UGMZDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: weave-ci-registry:5000 127.0.0.0/8Live Restore Enabled: false```
"
31446,0,1079,200,0,0,thaJeztah,0,"title:volume rm -f allows removing volume that is in use. description:As reported by @intesar in https://github.com/docker/docker/issues/31436#issuecomment-283206741, `docker volume rm -f` allows deleting volume that are in use. Steps to reproduce are below, but I suspect that the reference-counter is always updated if `-f` is used, even if removing the volume isn't actually successful.I was able to reproduce both on docker 1.13.1, and on current master (https://github.com/docker/docker/commit/7298941)**Reproduction steps:**Create a volume;```bash$ docker volume create my-volumemy-volume```Start a container using that volume and add some files to the volume```bash$ docker run -dit --name my-container -v my-volume:/volume busybox sh -c 'touch /volume/one /volume/two && exec /bin/sh'c76a270145efd47b4363554b67fadf74e6f4fa05daf045023a93e2366b38e65e```Try to remove the volume;```bash$ docker volume rm my-volumeError response from daemon: Unable to remove volume, volume still in use: remove my-volume: volume is in use - [c76a270145efd47b4363554b67fadf74e6f4fa05daf045023a93e2366b38e65e]```Try to remove the volume with `-f`;```bash$ docker volume rm -f my-volumemy-volume```This _looks_ to work, but doesn't actually remove the volume;```bash$ docker volume lsDRIVER              VOLUME NAMElocal               my-volume$ docker exec my-container sh -c 'ls -la /volume/'total 8drwxr-xr-x    2 root     root          4096 Mar  1 11:06 .drwxr-xr-x   19 root     root          4096 Mar  1 11:06 ..-rw-r--r--    1 root     root             0 Mar  1 11:06 one-rw-r--r--    1 root     root             0 Mar  1 11:06 two```However, running `docker volume rm` a _second_ time, the remove succeeds (no `-f` needed);```bash$ docker volume rm my-volumemy-volume```The volume is removed;```$ docker volume lsDRIVER              VOLUME NAME```And no longer attached to the container;```bash$ docker exec my-container sh -c 'ls -la /volume/'total 0```
"
31392,0,1221,0,0,0,retrospectacus,0,"title:Linking to a container by name which was renamed before fails.. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->If you have two linked containers, rename the target container and bring up a replacement with the old name, then delete and recreate the source container linking to the new target, no link is created.In my use case, the target container failed. I wanted to keep it around for investigation but also to get back up and running ASAP. So I renamed it and started a replacement, but then replacing my dependent containers, they would not link to the new target.**Steps to reproduce the issue:**For the example I used postgres and redis images. However I believe any image will work. In my environment A0 is my application and B0 is nginx.Create two named containers A0 & B0 with a link from B0 to A0. (hopefully the names ease understanding; unfortunately names must be >1 character)1. `docker run -d --name=A0 postgres`2. `docker run -d --name=B0 --link=A0 redis`You can see in `docker inspect B0` the link: `""/A0:/B0/A0""`Rename container A0.3. `docker stop A0`4. `docker rename A0 A1`You can inspect B0 again and the link there has been renamed: `""/A1:/B0/A0""`Start a replacement container A05. `docker run -d --name=A0 postgres`Delete and re-create B0 to point to the new A0.6. `docker rm -f B0`7. `docker run -d --name=B0 --link=A0 redis`Now inspect again B0 for links.**Describe the results you received:**```            ""Links"": null,```Also verified inside the container that the link is not present - ""host not found"" error, etc.**Describe the results you expected:**```            ""Links"": [                ""/A0:/B0/A0""            ],```**Additional information you deem important (e.g. issue happens only occasionally):**- This will occur if B0 existed and was linked to A0 *at any point before* the rename, and the replacement B0 is also named B0. I.e. you can run step 6 directly before step 3 and the bug will still occur.- It will not occur if the replacement B0 is given a different name.- Unable to reproduce on docker version 1.9.1 - link is created as expected.**Output of `docker version`:**```Docker version 1.13.0, build 49bf474```**Output of `docker info`:**```Containers: 2 Running: 2 Paused: 0 Stopped: 0Images: 4Server Version: 1.13.0Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090erunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3einit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-24-genericOperating System: Ubuntu 16.04 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.858 GiBName: ip-172-31-6-208ID: DFBJ:SEF4:QF2O:3RZM:GQ5L:TYEF:PQGB:XNLN:6DZA:R55T:FUCK:UZXZDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**AWS EC2 instance (not using ECS)
"
31383,1,2092,0,0,0,fencekicker,0,"title:docker exec fails: rpc error: code = 14 desc = grpc: the connection is unavailable. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**After running over the weekend under significant load, I found this VM in a state where I can't docker exec into any of the running docker containers. They all show up under 'docker ps', though 'ps axf' suggests at least one of the containers is dead. The error is always the same: ```$ docker exec -it <container1> bashrpc error: code = 14 desc = grpc: the connection is unavailable```I haven't tried this repeatedly to see if this is consistently reproducible. I would expect it not to be. <!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**Not sure at this point**Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:42:29 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:42:29 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 4 Running: 4 Paused: 0 Stopped: 0Images: 56Server Version: 1.13.1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 62 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: N/A (expected: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1)runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: apparmorKernel Version: 3.16.0-30-genericOperating System: Ubuntu 14.04.5 LTSOSType: linuxArchitecture: x86_64CPUs: 6Total Memory: 7.7 GiBName: vatip-test-vmID: 6NYT:5JFR:6YHH:IZ5N:D6IB:XIE5:C3AJ:M7HW:PLIL:KFUR:Y65M:QY7XDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```uname -a:```Linux vatip-test-vm 3.16.0-30-generic #40~14.04.1-Ubuntu SMP Thu Jan 15 17:43:14 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux```This is in a VM with Ubuntu 14.04 running over VMWare ESXi 5.5. The /var/log/upstart/docker.log has this to say:```time=""2017-02-27T10:53:05.219720554Z"" level=error msg=""Error running exec in container: rpc error: code = 14 desc = grpc: the connection is unavailable"" time=""2017-02-27T10:53:05.219869610Z"" level=error msg=""Handler for POST /v1.26/exec/0bf6f029fecc8f13c189caaa1c92440c90a6eacf559ab724ecffe63b3844ef0a/resize returned error: rpc error: code = 14 desc = grpc: the connection is unavailable"" ```
"
31378,0,5192,90,0,0,ghost,0,"title:Throw error instead of http panic when extra hosts are malformed. description:**Description**Server panic when extra hosts are malformed**Steps to reproduce the issue:**1. Create a container with the following config:```{       ""Hostname"": """",       ""Domainname"": """",       ""User"": """",       ""AttachStdin"": false,       ""AttachStdout"": true,       ""AttachStderr"": true,       ""Tty"": false,       ""OpenStdin"": false,       ""StdinOnce"": false,       ""Env"": [               ""FOO=bar"",               ""BAZ=quux""       ],       ""Cmd"": [               ""date""       ],       ""Entrypoint"": """",       ""Image"": ""alpine"",       ""Labels"": {               ""com.example.vendor"": ""Acme"",               ""com.example.license"": ""GPL"",               ""com.example.version"": ""1.0""       },       ""Volumes"": {         ""/volumes/data"": {}       },       ""WorkingDir"": """",       ""NetworkDisabled"": false,       ""MacAddress"": ""12:34:56:78:9a:bc"",       ""ExposedPorts"": {               ""22/tcp"": {}       },       ""StopSignal"": ""SIGTERM"",       ""HostConfig"": {         ""Binds"": [""/tmp:/tmp""],         ""PortBindings"": { ""22/tcp"": [{ ""HostPort"": ""11022"" }] },         ""PublishAllPorts"": false,         ""Privileged"": false,         ""ReadonlyRootfs"": false,         ""Dns"": [""8.8.8.8""],         ""DnsOptions"": [""""],         ""DnsSearch"": [""""],         ""ExtraHosts"": [""host,ip""],         ""NetworkMode"": ""bridge"",         ""Devices"": [],         ""Sysctls"": { ""net.ipv4.ip_forward"": ""1"" },         ""Ulimits"": [{}],         ""LogConfig"": { ""Type"": ""json-file"", ""Config"": {} },         ""SecurityOpt"": [],         ""StorageOpt"": {},         ""CgroupParent"": """",         ""VolumeDriver"": """",         ""ShmSize"": 67108864      },      ""NetworkingConfig"": {          ""EndpointsConfig"": {          }      }  }```Note invalid `""ExtraHosts"": [""host,ip""]`2. Start this container**Describe the results you received:**The following error is shown:`error during connect: Post http://%2Fvar%2Frun%2Fdocker.sock/v1.26/containers/d8c655aa31d3/start: EOF`**Describe the results you expected:**A user friendly message indicating the reason of such a failure**Additional information you deem important (e.g. issue happens only occasionally):**http panic instead of a proper error handling:```http: panic serving @: runtime error: index out of range                                                       goroutine 5720 [running]:                                                       net/http.(*conn).serve.func1(0xc421cbd380)                                                               /usr/lib/golang/src/net/http/server.go:1491 +0x12a                                                       panic(0x15dad40, 0xc420010090)                                                               /usr/lib/golang/src/runtime/panic.go:458 +0x243                                                       github.com/docker/docker/daemon.(*Daemon).buildSandboxOptions(0xc420093ba0, 0xc420494f00, 0x222d9c0, 0xc4219aef00, 0x222c0c0, 0xc421908840, 0x0)                                                               /builddir/build/BUILD/docker-047e51b797564227b0bf26f3aa448f563bea5c71/_build/src/github.com/docker/docker/daemon/container_operations.go:121 +0xded                                                       github.com/docker/docker/daemon.(*Daemon).connectToNetwork(0xc420093ba0, 0xc420494f00, 0xc420f70540, 0x2a, 0xc421d7ef00, 0x0, 0x0, 0x0)                                                               /builddir/build/BUILD/docker-047e51b797564227b0bf26f3aa448f563bea5c71/_build/src/github.com/docker/docker/daemon/container_operations.go:590 +0x79a                                                       github.com/docker/docker/daemon.(*Daemon).allocateNetwork(0xc420093ba0, 0xc420494f00, 0x58ce00, 0xc4221131e0)                                                               /builddir/build/BUILD/docker-047e51b797564227b0bf26f3aa448f563bea5c71/_build/src/github.com/docker/docker/daemon/container_operations.go:426 +0x27d                                                       github.com/docker/docker/daemon.(*Daemon).initializeNetworking(0xc420093ba0, 0xc420494f00, 0x0, 0x0)                                                               /builddir/build/BUILD/docker-047e51b797564227b0bf26f3aa448f563bea5c71/_build/src/github.com/docker/docker/daemon/container_operations.go:703 +0x2a5```**Output of `docker version`:**```Server Version: 1.12.5Storage Driver: devicemapper Pool Name: VolGroup01-docker--pool Pool Blocksize: 524.3 kB Base Device Size: 10.74 GB Backing Filesystem: xfs Data file: Metadata file: Data Space Used: 3.692 GB Data Space Total: 329.4 GB Data Space Available: 325.7 GB Metadata Space Used: 1.606 MB Metadata Space Total: 1.074 GB Metadata Space Available: 1.072 GB Thin Pool Minimum Free Space: 32.94 GB Udev Sync Supported: true Deferred Removal Enabled: true Deferred Deletion Enabled: false Deferred Deleted Device Count: 0 Library Version: 1.02.135-RHEL7 (2016-11-16)Logging Driver: journaldCgroup Driver: systemdPlugins: Volume: local Network: bridge null host overlay Authorization: rhel-push-pluginSwarm: inactiveRuntimes: docker-runc runcDefault Runtime: docker-runcSecurity Options: seccompKernel Version: 3.10.0-514.6.1.el7.x86_64Operating System: Red Hat Enterprise Linux Server 7.3 (Maipo)OSType: linuxArchitecture: x86_64Number of Docker Hooks: 2CPUs: 8Total Memory: 62.75 GiBName: denatb3dhcod02ID: D7GF:EZNF:2ZZA:64UO:JYY4:L2NL:4SLH:BLTX:ON2E:5V2S:NSDQ:LLZ5Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://registry.access.redhat.com/v1/Insecure Registries: 127.0.0.0/8Registries: registry.access.redhat.com (secure), docker.io (secure)```
"
31373,0,3496,31,0,0,LelandSindt,0,"title:Container stops after logs are piped to failing command. description:**Description**When `docker logs <container>` is piped to a command that fails the container hangs, and docker has to be restarted to recover. **Steps to reproduce the issue:**```$ docker run -d --name=failure alpine /bin/sh -c ""while true; do date; done""642305b0dc0d36553362b3d48fd6e06919d475e91545625ac4dc47a22d0f9e1f$ cat /var/lib/docker/containers/642305b0dc0d36553362b3d48fd6e06919d475e91545625ac4dc47a22d0f9e1f/642305b0dc0d36553362b3d48fd6e06919d475e91545625ac4dc47a22d0f9e1f-json.log | wc -l59247```--- wait ?30+ seconds?```$ docker logs failure --tail 10Mon Feb 27 03:27:10 UTC 2017Mon Feb 27 03:27:10 UTC 2017Mon Feb 27 03:27:10 UTC 2017Mon Feb 27 03:27:10 UTC 2017Mon Feb 27 03:27:10 UTC 2017Mon Feb 27 03:27:10 UTC 2017Mon Feb 27 03:27:10 UTC 2017Mon Feb 27 03:27:10 UTC 2017Mon Feb 27 03:27:10 UTC 2017$ docker logs failure |grep -10Usage: grep [OPTION]... PATTERN [FILE]...Try 'grep --help' for more information.$ docker logs failure --tail 10```....nothing.... ctrl+c```$ cat /var/lib/docker/containers/642305b0dc0d36553362b3d48fd6e06919d475e91545625ac4dc47a22d0f9e1f/642305b0dc0d36553362b3d48fd6e06919d475e91545625ac4dc47a22d0f9e1f-json.log | wc -l165360$ cat /var/lib/docker/containers/642305b0dc0d36553362b3d48fd6e06919d475e91545625ac4dc47a22d0f9e1f/642305b0dc0d36553362b3d48fd6e06919d475e91545625ac4dc47a22d0f9e1f-json.log | wc -l165360$ docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES642305b0dc0        alpine              ""/bin/sh -c 'while...""   52 seconds ago      Up 51 seconds                           failure$ docker stop failurefailure$ docker psCONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS               NAMES642305b0dc0        alpine              ""/bin/sh -c 'while...""   About a minute ago   Up About a minute                       failure$ systemctl restart docker$ docker ps --all |grep failure642305b0dc0        alpine                  ""/bin/sh -c 'while...""    2 minutes ago       Exited (137) 22 seconds ago                                    failure```**Describe the results you received:**When `docker logs <container>` is piped ""|"" to a command that fails... the container fails and the docker service must be restarted.**Describe the results you expected:**The command should fail, but the container should not be effected. **Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```docker versionClient: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```docker infoContainers: 19 Running: 1 Paused: 0 Stopped: 18Images: 39Server Version: 1.13.1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 96 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-64-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.678 GiBName: x1ID: YY5M:Q3IW:GK7S:C3F2:JGQN:UZ7F:BP2F:MC4T:5U7J:6QAT:VVQC:DCCFDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Ubuntu 16.04, Physical Host, 8GB Ram, 4CPU
"
31342,0,4212,298,0,0,titpetric,0,"title:Swarm in 1.13 stops listening on published port after turning off healthcheck. description:I'm having a problem where docker swarm would stop listening to published port after health checks would be turned off.**Steps to reproduce the issue:**Steps to reproduce from a clean 3 node swarm cluster (all managers):```root@swarm1:~# docker node lsID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS2jrjw0f0t6k2hbf2w0d41db2x *  swarm1    Ready   Active        Reachableaet822iruebj35gu4vlkn70bb    swarm3    Ready   Active        Leaderl4bdxu989ktteb61cte66dqbc    swarm2    Ready   Active        Reachable```I created a `party-swarm` network like this:```docker network create \  --driver overlay \  --subnet 10.0.0.0/20 \  --attachable \  party-swarm```I need a simple redis service for the example app:```docker service create --replicas 1 --network party-swarm --hostname redis --name redis -p 6379:6379 redis:3.2-alpine```And then I create the app like this:```docker service create -e PORT=80 \ --replicas 10 \ --network party-swarm \ --name gotwitter \ -p 80:80 titpetric/gotwitter```At this point the service is reachable on port 80 on all nodes.```docker service update --no-healthcheck [service]```**Describe the results you received:**At this point, dockerd doesn't listen on port 80 anymore.**Describe the results you expected:**I expected dockerd would listen on port 80.**Additional information you deem important (e.g. issue happens only occasionally):**I can restore listening on the published port by issuing `docker service update --health-cmd ""exit 0"" --health-interval 30s gotwitter`**Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba372 Built:        Wed Feb  8 06:44:30 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba372 Built:        Wed Feb  8 06:44:30 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 584 Running: 260 Paused: 0 Stopped: 324Images: 6Server Version: 1.13.1Storage Driver: devicemapper Pool Name: docker-8:1-5243831-pool Pool Blocksize: 65.54 kB Base Device Size: 10.74 GB Backing Filesystem: ext4 Data file: /dev/loop0 Metadata file: /dev/loop1 Data Space Used: 811.1 MB Data Space Total: 107.4 GB Data Space Available: 106.6 GB Metadata Space Used: 22.82 MB Metadata Space Total: 2.147 GB Metadata Space Available: 2.125 GB Thin Pool Minimum Free Space: 10.74 GB Udev Sync Supported: true Deferred Removal Enabled: false Deferred Deletion Enabled: false Deferred Deleted Device Count: 0 Data loop file: /var/lib/docker/devicemapper/devicemapper/data WARNING: Usage of loopback devices is strongly discouraged for production use. Use `--storage-opt dm.thinpooldev` to specify a custom block storage device. Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata Library Version: 1.02.137 (2016-11-30)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: 2jrjw0f0t6k2hbf2w0d41db2x Is Manager: true ClusterID: 2y5aa4qjf3e6akbclqx2rnx71 Managers: 3 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 10.55.8.161 Manager Addresses:  10.55.8.161:2377  10.55.8.162:2377  10.55.8.163:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.6.0-1-amd64Operating System: Debian GNU/Linux 9 (stretch)OSType: linuxArchitecture: x86_64CPUs: 6Total Memory: 7.793 GiBName: swarm1ID: 3ER2:7GXI:IZR5:O7M6:HKJT:I22T:LOWM:NVW2:CBGL:5WV3:3B2Y:2YW4Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No memory limit supportWARNING: No swap limit supportWARNING: No kernel memory limit supportWARNING: No oom kill disable supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**I'm running the swarm on 3 servers, VMs, each with 8GB ram, enough of disk space. I'm trying to scale the service to run 1000 containers and so far haven't been able to go beyond about 750 containers. In order to make it work, I also had to tune some sysctl options, most notably these:```sysctl -w net.ipv4.neigh.default.gc_thresh1=8096sysctl -w net.ipv4.neigh.default.gc_thresh2=8096sysctl -w net.ipv4.neigh.default.gc_thresh3=8096```This was done because dmesg had errors in the form: `neighbour: arp_cache: neighbor table overflow!`. This in turn would cause network connectivity issues to the docker hosts themselves. I suspect this has something to do with the number of docker containers I'm spawning, but the only limits I could discern were that there's some limit about open ports per system (1024), perhaps related with [this gh issue](https://github.com/docker/libnetwork/issues/1522).  That being said, the limits seem to be lower for some reason, and I haven't figured a way to pinpoint the core issue behind them. Even with the health-cmd work-around `docker service ls` is reporting drops in the number of running containers.```root@swarm1:~# docker service lsID            NAME       MODE        REPLICAS  IMAGEjgt62g2bsydm  gotwitter  replicated  738/1000  titpetric/gotwitter:latestsyhtbxnz8zhh  redis      replicated  1/1       redis:3.2-alpineroot@swarm1:~# docker service lsID            NAME       MODE        REPLICAS  IMAGEjgt62g2bsydm  gotwitter  replicated  651/1000  titpetric/gotwitter:latestsyhtbxnz8zhh  redis      replicated  1/1       redis:3.2-alpine```This may have something to do with the healthcheck timeout option (set by Dockerfile, 10s), but I haven't verified this yet.The source for the `gotwitter` image is [here](https://github.com/titpetric/books/blob/master/12fa-docker-golang/chapter7/Dockerfile)
"
31341,1,2739,8,0,0,thecrazymonkey,0,"title:setting healthcheck disable: true in compose file prevents the service name from being resolvable. description:**Description**I have very simple Dockerfile and docker-compose.yml files:_Dockerfile_```FROM centosHEALTHCHECK --interval=10s CMD exit 0ENTRYPOINT while true; do tail -f /dev/null;done```_docker-compose.yml_```version: '3.1'networks:  default:    driver: overlay    ipam:      driver: default      config:        - subnet: 192.168.24.0/24services:  health:    image: healthbug     deploy:      replicas: 1    networks:      - default     healthcheck:      disable: true```**Steps to reproduce the issue:**1. Build image from the Dockerfile above - ""docker build -t healthbug .""2. Run ""docker stack deploy -c docker-compose.yml test""3. ""docker ps"" should show the container as running without health status (expected)4. Try ""docker exec -ti <container_name> ping health""**Describe the results you received:**Ping returnsping: health: Name or service not known**Describe the results you expected:**Expecting to see output of ping command - e..g.:PING health (192.168.24.3) 56(84) bytes of data.64 bytes from e0bdd9aab838 (192.168.24.3): icmp_seq=1 ttl=64 time=0.030 ms**Additional information you deem important (e.g. issue happens only occasionally):**For the failed scenario ""docker inspect"" command shows State as:```""State"": {            ""Status"": ""running"",            ""Running"": true,            ""Paused"": false,            ""Restarting"": false,            ""OOMKilled"": false,            ""Dead"": false,            ""Pid"": 14956,            ""ExitCode"": 0,            ""Error"": """",            ""StartedAt"": ""2017-02-24T17:17:35.368304641Z"",            ""FinishedAt"": ""0001-01-01T00:00:00Z""        },```If I comment out (or replace with test: exit 0) the healthcheck section from the docker compose file everything runs as expected and the container is reported as healthy after 10s interval. Service name resolves correctly.**Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 7 Running: 0 Paused: 0 Stopped: 7Images: 588Server Version: 1.13.1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 499 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: s5ll7v7orfzxg37k2w22wlnl7 Is Manager: true ClusterID: qwg1m234fmqm4ria30gtig3jg Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 10.1.2.30 Manager Addresses:  10.1.2.30:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-62-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 7.673 GiBName: devboxID: GMRV:JAVH:HVHY:SSJE:OJGA:KAFD:Z5JI:Q767:FTXM:GXAH:4NXN:ETAMDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 10.0.0.0/16 172.26.0.0/16 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**This is on physical hw running either Ubuntu 16.04.2 or 14.04
"
31323,0,1464,22,0,0,jim-minter,0,"title:Race condition(s) in log API. description:**Description**API clients can hang on a ContainerLogs() call, for example when Follow is true and the container process is short lived.  AFAICS, the routines in daemon/logs.go do not hold the requisite lock or locks, e.g. at the point where they verify the container status and access its LogDriver.**Steps to reproduce the issue:**1. Add `time.Sleep(10 * time.Second) at https://github.com/docker/docker/blob/87e45626f433e5cecd576c0a6fcae09158d95a5e/daemon/logs.go#L512. Run the test code below.**Describe the results you received:**Client prints container output.With the server-side sleep, the client reliably hangs.  Without it, the hang happens occasionally under load.With or without the server-side sleep, after the client exits (after a SIGINT in the case of the hang), the daemon log contains ""Error closing logger: invalid argument"", which I think is indicative of a logic error.**Describe the results you expected:**Client prints container output.  No error in the daemon log.  No hang.**Additional information you deem important (e.g. issue happens only occasionally):**In some ways this is a similar issue to https://github.com/docker/docker/issues/29285 , although that was with the attach path.**Output of `docker version`:**```Client: Version:      17.04.0-dev API version:  1.27 Go version:   go1.7.5 Git commit:   87e4562 Built:        Fri Feb 24 10:46:59 2017 OS/Arch:      linux/amd64Server: Version:      17.04.0-dev API version:  1.27 (minimum version 1.12) Go version:   go1.7.5 Git commit:   87e4562 Built:        Fri Feb 24 10:46:59 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 1 Running: 0 Paused: 0 Stopped: 1Images: 1Server Version: 17.04.0-devStorage Driver: vfsLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: containerd version: 665e84e6c28653a9c29a6db601636a92d46896f3runc version: a01dafd48bc1c7cc12bdb01206f9fea7dd6feb70init version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.5-200.fc25.x86_64Operating System: Debian GNU/Linux 8 (jessie) (containerized)OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 7.796GiBName: de7edd3f4ba9ID: CGYO:SLJM:5MNC:WP5C:B4HW:ECPC:VBJE:COCN:GMAZ:77ZA:U6CM:UC7CDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabledExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Tested using latest docker master (running under `make shell`).
"
31307,0,2747,0,0,0,janie128,0,"title:Docker Remote API 1.26 - Service Logs cannot specify tail. description:**Description**Using the remote api to get service logs (`/v1.26/services/{id}/logs`), the query parameter `tail` appears to have no effect.**Steps to reproduce the issue:**1. `docker service create --name=logtest busybox /bin/sh -c ""while true; do echo 1234; sleep 5; done""`2. `curl --unix-socket /var/run/docker.sock -H ""Content-Type: application/json"" -X GET http:/v1.26/services/{serviceId}/logs?stdout=true&tail=2`**Describe the results you received:**More than two lines of logs.```闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} 1234闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} 1234闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} 1234闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} 1234闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} 1234```**Describe the results you expected:**Expected only the last two lines of logs.```闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} 1234闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} 1234```**Additional information you deem important (e.g. issue happens only occasionally):**Remote API to get container logs works as expected.`curl --unix-socket /var/run/docker.sock -H ""Content-Type: application/json"" -X GET http:/v1.26/containers/{containerId}/logs?stdout=true&tail=2`returns only two lines of logs.```12341234```**Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      darwin/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 36Server Version: 1.13.1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: {nodeId} Is Manager: true ClusterID: {clusterId} Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: {IP} Manager Addresses:  {IP}:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.8-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952 GiBName: mobyID: {ID}Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 113 Goroutines: 376 System Time: 2017-02-23T21:20:56.806721151Z EventsListeners: 2No Proxy: *.local, 169.254/16Username: {username}Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**N/A
"
31306,0,3255,0,0,0,janie128,0,"title:Docker Remote API 1.26 - Service Logs cannot specify stderr/stdout. description:**Description**Using the remote api to get service logs (`/v1.26/services/{id}/logs`), the query parameters `stderr` and `stdout` appear to have no effect. Both `stderr` and `stdout` are returned together.**Steps to reproduce the issue:**1. `docker service create --name=logtest busybox /bin/sh -c ""while true; do ls abc; echo 1234; sleep 5; done""`2. `curl --unix-socket /var/run/docker.sock -H ""Content-Type: application/json"" -X GET http:/v1.26/services/{serviceId}/logs?stdout=false&stderr=true`**Describe the results you received:**```闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} ls: abc: No such file or directory闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} 1234闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} ls: abc: No such file or directory闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} 1234闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} ls: abc: No such file or directory闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} 1234```**Describe the results you expected:**```闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} ls: abc: No such file or directory闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} ls: abc: No such file or directory闂傚倸鍊峰ù鍥р枖閺囥垹绐楅柟鎯у閻鈹戦娑氱懏.docker.swarm.node.id={nodeId},com.docker.swarm.service.id={serviceId},com.docker.swarm.task.id={taskId} ls: abc: No such file or directory```**Additional information you deem important (e.g. issue happens only occasionally):**Remote API to get container logs works as expected.`curl --unix-socket /var/run/docker.sock -H ""Content-Type: application/json"" -X GET http:/v1.26/containers/{containerId}/logs?stdout=false&stderr=true`returns```#ls: abc: No such file or directory#ls: abc: No such file or directory#ls: abc: No such file or directory```**Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      darwin/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 36Server Version: 1.13.1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: {nodeId} Is Manager: true ClusterID: {clusterId} Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: {IP} Manager Addresses:  {IP}:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.8-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952 GiBName: mobyID: {ID}Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 113 Goroutines: 376 System Time: 2017-02-23T21:00:02.58710375Z EventsListeners: 2No Proxy: *.local, 169.254/16Username: {username}Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**N/A
"
31297,0,1666,203,0,0,mmlb,0,"title:prune commands defaults don't work. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->Running `docker image prune` and `docker container prune` and just pressing enter at the prompt `... continue? [y/N]` does nothing. Presumably the default `N` should be selected and nothing happens. Instead it seems as if the cli is waiting for an actual character to by typed, without prompting again.**Steps to reproduce the issue:**1. run `docker image prune`2. press the enter key3. nothing happens**Describe the results you received:**docker prune command seemed to just hang.**Describe the results you expected:**I expected to either be prompted again (possibly with a message), or for the command to return as if I had typed `N` or any other character but `y`.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```闂?docker versionClient: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3727 Built:        Sun Feb 12 02:40:56 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3727 Built:        Sun Feb 12 02:40:56 2017 OS/Arch:      linux/amd64 Experimental: false  ```**Output of `docker info`:**```闂?docker infoContainers: 1 Running: 0 Paused: 0 Stopped: 1Images: 27Server Version: 1.13.1Storage Driver: zfs Zpool: error while getting pool information strconv.ParseUint: parsing """": invalid syntax Zpool Health: not available Parent Dataset: zroot/docker Space Used By Parent: 90112 Space Available: 150361333760 Parent Quota: no Compression: lz4Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: N/A (expected: 949e6facb77383876aeff8a6944dde66b3089574)Security Options: seccomp  Profile: defaultKernel Version: 4.9.8-1-ARCHOperating System: Arch LinuxOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.17 GiBName: mannyID: NUPW:OELY:QYZZ:OVHQ:QLUK:MY5Z:K5TE:FCCI:2JM5:LUQG:GDTM:XUQVDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false  ```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
31293,1,1248,17,0,0,sombralibre,0,"title:Requests to Swarm cluster get stucked.. description:Hi there,I'm not sure if it's the right place to post this, but I really need some help with the follows issues:I've create a swarm cluster as follow ```docker swarm init --advertise-addr 10.0.0.240 --listen-addr 10.0.0.240```Add a node by ```docker swarm join --token SWMTKN-1-44vris9xsytcrms6kg-3p2yktgdubc828u4gzc6rxdas --advertise-addr 10.0.0.241 --listen-addr 10.0.0.241  10.0.0.240:2377```I run ""docker node ls' and apparently everthing is ok, then I've created a compose file to be deployed with ""docker stack deploy"", with successful return, it created a stack with its own network and its services.```version: ""3""services: rabbitmq:  image: rabbitmq:3  networks:   - "" AlkaOverlay"" backend:  image: ""IMAGEB:TAGB""  networks:   - "" AlkaOverlay""  ports:   - ""1080:80""  environment:   - ""DJANGO_SETTINGS_MODULE=alka.settings_staging""  command: ""/srv/www/bin/gunicorn.sh""  deploy:   mode: ""replicated""   replicas: 2 celery:  image: ""IMAGEB:TAGB""  networks:   - "" AlkaOverlay""  environment:   - ""DJANGO_SETTINGS_MODULE=alka.settings_staging""  command: ""/srv/www/bin/celery.sh"" frontend:  image: ""IMAGEF:TAGF""  networks:   - "" AlkaOverlay""  ports:   - ""80:80""   - ""443:443""  deploy:   mode: ""replicated""   replicas: 2networks: AlkaOverlay:  driver: overlay  ipam:   driver: default   config:    - subnet: 10.0.253.0/24```The connections issues start to appears when try to use the web app throught tcp port 80, I've basically tried curl request like this:```for t in {1..10};do echo ""LOOP $t""; timeout 3s curl 10.0.0.240:1080 ;donefor t in {1..10};do echo ""LOOP $t""; timeout 3s curl 10.0.0.241:1080 ;done```and from inside of the ""frontend"" containers```for t in {1..10};do echo ""LOOP $t""; timeout 3s curl backend ;done```However always I run the tests, the response of the ""backends"" I get works like a ""round robin"", that means one request work fine, and the next get stucked waiting for response however the request reach the timeout and the petitions die; these timeout are translates to server errors (5XX) to the clients.On an intent to get the stack work fine, I've run every component (backend, frontend, rabbit, celery) on separated container and make its network connections through physical network interface of the hosts instances; well with this setup all work fine, but the pearks of scaling has been gone.I've checked the udp connections between hosts and these works fine, also have change the deploy mode from ""replicated"" to ""global"", but any of this setup to swarm has get the cluster to work fine.I would appreciate any help or advice with the issue. Thanks a lot.
"
31253,0,1468,43,0,0,pennywisdom,0,"title:windows: docker system prune not reclaiming expected space. description:**Description**I am running a CI process that builds images on a windows 2016 host Virtual Machine. A scheduled job runs every 4 hours to clear up space, but this does not seem to be reclaiming the space that docker is suggesting. The amount reclaimed has been decreasing.Currently I have a 60Gb virtual machine that is running server core and when I run ```docker system prune -fa``` i get the following outputTYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLEImages              0                   0                   0 B                 0 BContainers          0                   0                   0 B                 0 BLocal Volumes       0                   0                   0 B                 0 BHowever running a scan of C:\ProgramData\docker I can see that there are many Gb's of files here, especially under windows filter. With a scan in progress, where docker is reporting zero images I currently have:C:\ProgramData\docker -  20.5Gb - 188398 files - 66838 directoriesC:\ProgramData\docker\windowsfilter - 20.4Gb - 145451 files - 66752 directoriesIf i run ```docker images``` and ```docker ps -a``` these are both empty.There seems to be a gradual decline in the space that is reclaimed, like dangling images are not being detected and not picked up.One thing to note is that I am trying to delete all images to free up space; then on my next builds I am pulling in windowsservercore or nanoserver from the build of the images, i am not explicitly pulling windowsservercore or nanoserver. **Output of `docker version`:**```docker versionClient: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      windows/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.24) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      windows/amd64 Experimental: false```**Output of `docker info`:**```docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 1.13.1Storage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: l2bridge l2tunnel nat null overlay transparentSwarm: inactiveDefault Isolation: processKernel Version: 10.0 14393 (14393.693.amd64fre.rs1_release.161220-1747)Operating System: Windows Server 2016 StandardOSType: windowsArchitecture: x86_64CPUs: 4Total Memory: 3.997 GiBName: winch03ID: 6QNU:V7HZ:D7DG:RTJH:SIQ2:BKRE:WBDD:UHBB:RIVA:3RXB:PI4R:TAX2Docker Root Dir: C:\ProgramData\dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: -1 Goroutines: 22 System Time: 2017-02-22T12:04:10.5920341Z EventsListeners: 0Username: xxxxRegistry: https://index.docker.io/v1/Labels: hosttype=windows dc=ashford hostrole=devExperimental: falseInsecure Registries: 192.168.xxx.xx:5000 localhost:5000 127.0.0.0/8Live Restore Enabled: false```Running windows server 2016 on Hyper-V, fully patched with latest Windows Updates/**Expected Outcome**As I am deleting all images I would expect the amount of space reclaimed to be consistent and not reducing over time to a point where very little is reclaimed. It seems like there are dangling or orphaned images that are remaining that are not being detected.
"
31249,0,389,212,0,0,tlvenn,0,"title:Swarm mode with mode=host and port is already in use by service on another host.. description:Hi,I am using docker swarm mode (1.13) and I have 2 services A and B.Both services publish ports using exclusively `mode=host` and both services have placement constraint on a different server.Now the issue is that both services listen of port 443. Once the first service starts, the second is failing to start with the following error:`Error response from daemon: rpc error: code = 3 desc = port '443' is already in use by service 'A' (pjo2sx4wx3apaejqhgevpkvqs)`I am guessing there is a check somewhere that does not take into account that service A is using `mode=host` and so it's not mutually exclusive to run services on the same port anymore as far as the services are not running on the same host.docker version```Client: Version:      1.13.0 API version:  1.25 Go version:   go1.7.3 Git commit:   49bf474 Built:        Tue Jan 17 09:58:26 2017 OS/Arch:      linux/amd64Server: Version:      1.13.0 API version:  1.25 (minimum version 1.12) Go version:   go1.7.3 Git commit:   49bf474 Built:        Tue Jan 17 09:58:26 2017 OS/Arch:      linux/amd64 Experimental: false```
"
31228,0,3754,0,0,0,mostolog,0,"title:Stack deploy with default network is not working as expected. description:**Description**After reading https://github.com/docker/docker/issues/29982, according to https://docs.docker.com/compose/compose-file/#/networks and as https://docs.docker.com/compose/compose-file/#/external-1 states:> If set to true, specifies that this network has been created outside of Compose. docker-compose up will not attempt to create it, and will raise an error if it doesn闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?exist.However, seems stack networks are not working as expected.**Steps to reproduce the issue:**1.Create overlay attachable network mynet```$docker network create --attachable --driver overlay mynetkc9u8lgi1yugpudo5qk6o2g58$docker network inspect mynet[    {        ""Name"": ""mynet"",        ""Id"": ""kc9u8lgi1yugpudo5qk6o2g58"",        ""Created"": ""0001-01-01T00:00:00Z"",        ""Scope"": ""swarm"",        ""Driver"": ""overlay"",        ""EnableIPv6"": false,        ""IPAM"": {            ""Driver"": ""default"",            ""Options"": null,            ""Config"": []        },        ""Internal"": false,        ""Attachable"": true,        ""Containers"": null,        ""Options"": {            ""com.docker.network.driver.overlay.vxlanid_list"": ""4098""        },        ""Labels"": null    }]```2.Write stack.yml compose-file```version: ""3""networks:  default:    external:      name: ""mynet""services:  elasticsearch:    command: ""elasticsearch -E cluster.name=app -E node.name=app-elasticsearch -E discovery.zen.ping.unicast.hosts=elasticsearch""    image: ""elasticsearch:5.2.1""```3.Try to deploy the stack> docker stack deploy --compose-file stack.yml myapp**Describe the results you received:**docker stack deploy --compose-file stack.yaml myappCreating service myapp_elasticsearchError response from daemon: network myapp_default not found**Describe the results you expected:**Simple stack with service attached to default network ""mynet""**Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 7 Running: 6 Paused: 0 Stopped: 1Images: 42Server Version: 1.13.1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 116 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: ph56dmuj9xyp7v0mxngpi4wmg Is Manager: true ClusterID: jmdwt0h7bwcobihnfignepzwr Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 155.54.212.5 Manager Addresses:  155.54.212.5:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-21-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.4 GiBName: computerID: E4N3:47NS:3QGR:EWSK:L4ZR:RWXL:JJXE:U53F:4NIU:N6XK:6OVD:WY4CDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Similar issue**```$cat stack.ymlversion: ""3""networks:  default:    mynet:      external: trueservices:  elasticsearch:    command: ""elasticsearch -E cluster.name=app -E node.name=app-elasticsearch -E discovery.zen.ping.unicast.hosts=elasticsearch""    #hostname: ""{{.Service.Name}}-{{.Task.Slot}}""    image: ""elasticsearch:5.2.1""$docker stack deploy --compose-file stack.yml myappmynet Additional property mynet is not allowed``````$cat stack.ymlversion: ""3""networks:  default:    external:      name: mynetservices:  elasticsearch:    command: ""elasticsearch -E cluster.name=app -E node.name=app-elasticsearch -E discovery.zen.ping.unicast.hosts=elasticsearch""    image: ""elasticsearch:5.2.1""    networks:      - mynet$docker stack deploy --compose-file stack.yml myappservice ""elasticsearch"" references network ""mynet"", which is not declared```
"
31216,1,1808,5,0,0,rahilb,0,"title:Container name completion in exec command with flags. description:**Description**Zsh completion used to complete container names. This still works, however only if you try to complete when your command is exactly `docker exec`. i.e. `docker exec [TAB]` shows running containers and you may select one.`docker exec -it [TAB]` does not show running containers, and you're on your own. Once upon a time this worked, and it was very handy. **Steps to reproduce the issue:**1. Install shell completion2. Try to tab complete after passing options to exec i.e. `docker exec -it [TAB]`3. Container name/id options are not offered to you. **Describe the results you received:**``` rahil@Rahils-MacBook-Pro> docker exec -it [TAB]zsh: do you wish to see all 3743 possibilities (3746 lines)?```**Describe the results you expected:**``` rahil@Rahils-MacBook-Pro> docker exec -it [TAB]dynamodb_dyanmodev_1  2d43aa1d6a61  --       8 minutes, dynamodb_dyanmodev```**Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      darwin/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 2 Running: 1 Paused: 0 Stopped: 1Images: 46Server Version: 1.13.1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 20 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.8-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.952 GiBName: mobyID: RVCK:PUTJ:223U:OGPH:CQYL:X4RE:ECBM:LTJ6:ENMU:KSLV:ZNLI:427XDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 32 Goroutines: 49 System Time: 2017-02-21T12:14:40.742342925Z EventsListeners: 2No Proxy: *.local, 169.254/16Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**I tried this using the oh-my-zsh plugin to install completion and also with the [official instructions for zsh](https://docs.docker.com/compose/completion/#/zsh), both produce exactly the same results. 
"
31187,0,1591,7,0,0,tpoindessous,0,"title:""docker system prune"" doesn't handle ""enter"" key without a Y or N letter. description:**Description**<!--Briefly describe the problem you are having in a few paragraphs.-->The `docker system prune` doesn't handle the ""enter"" key, if I don't type a Y ou N letter first (or any letter).**Steps to reproduce the issue:**1. Launch `docker system prune`2. when ""Are you sure you want to continue? [y/N]"" line is displayed, type the ""enter"" key**Describe the results you received:**I see a newline and the docker command is still waiting for a key.**Describe the results you expected:**I want exiting from the command**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      darwin/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 13 Running: 12 Paused: 0 Stopped: 1Images: 70Server Version: 1.13.1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 73 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.8-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 3Total Memory: 3.855 GiBName: mobyID: Q2V4:ECV7:F3WV:PZFB:WCQ6:G44F:UY5T:SRAG:MYFD:W4IL:TU7X:NXYBDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 184 Goroutines: 174 System Time: 2017-02-20T15:01:35.772298515Z EventsListeners: 2No Proxy: *.local, 169.254/16Username: sk5thomasRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
31158,0,0,290,0,0,tonistiigi,0,"title:`system df` and `ps --size` block all other `ps` requests. description:While a size for a single container is being calculated for `docker system df` or `docker ps --size` the main container lock is blocked. This means that no other `docker ps` request returns until the size calculation has been finished. In the case of big images/containers and slow drivers(devicemapper) the wait time can be >30s.related #30225cc @mlaventure 
"
31146,0,3187,33,0,0,saamalik,0,"title:Inconsistent DNS lookup between compose-file stack and resource-file DAB stack. description:**Description**Inconsistent DNS lookup behavior between _docker stacks_ deployed using _compose-file_ and _resource bundles (DAB)_.When using a _compose-file_ both the service name and _stack_ concatenated service names are resolvable. For example:**docker-compose.yml**```yamlversion: ""3""networks:   test:services:  vm-a:    image: alpine:latest    command: sleep 10000    networks:      - test  vm-b:    image: alpine:latest    command: sleep 10000    networks:      - test```**Create stack using _compose-file_:**```$ docker stack deploy --compose-file docker-compose.yml test1Creating network test1_testCreating service test1_vm-aCreating service test1_vm-b```**Test DNS lookup:**```$ docker exec -it test1_vm-a.1.tte3vpsgaml3zgm5pmirnoy5p /bin/sh -l0e4fc9874a15:/# nslookup test1_vm-bName:      test1_vm-bAddress 1: 10.0.2.40e4fc9874a15:/# nslookup vm-bName:      vm-bAddress 1: 10.0.2.4```Note that both _test1\_vm-b_ and _vm-b_ lookups resolved correctly.Now let's compare this to using a DAB resource-file:**Create DAB:**```$ docker-compose bundleWARNING: Unsupported top level key 'networks' - ignoringWrote bundle to temp.dab```**Deploy stack using DAB:**```$ docker stack deploy --bundle-file test.dab test2Loading bundle from test.dabCreating network test2_testCreating service test2_vm-aCreating service test2_vm-b```**Test DNS Lookup:**```$ docker exec -it test2_vm-a.1.tglugdl6ed8nn6j2x70jh8af4 /bin/sh -lc5ec2ff8c04c:/# nslookup test2_vm-bName:      test2_vm-bAddress 1: 10.0.0.4c5ec2ff8c04c:/# nslookup vm-bnslookup: can't resolve 'vm-b': Name does not resolve```Why does _vm-b_ nslookup not resolve correctly when using _DAB_? Is this a bug or expected behavior? If expected, just curious why this behavior is different than using compose file? Also, is there any known workaround? Or is there a way to get the ""stack name"" passed into the containers? **`docker version`:**```$ docker versionClient: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      darwin/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      linux/amd64 Experimental: true```**`docker info`:**```$ docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 48Server Version: 1.13.1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 79 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: dtl8xp6tzq4hbia48gyvdn8d1 Is Manager: true ClusterID: 1rftvquar6yy7czh2bick7jft Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.65.2 Manager Addresses:  192.168.65.2:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.8-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 3.855 GiBName: mobyID: LTVQ:5GKD:HBLU:R3OX:WRA6:UWMH:TDE5:YRIM:3WBD:WEBC:DTB5:OTF4Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 47 Goroutines: 138 System Time: 2017-02-18T04:00:16.32167908Z EventsListeners: 1No Proxy: *.local, 169.254/16Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```Using *Docker for Mac*. 
"
31123,0,643,143,0,0,aaronlehmann,0,"title:API version confusion between 1.13.1 and 1.14. description:It appears some code was written with the assumption that API version 1.26 corresponds to Docker 1.14. When 1.13.1 was released, it took over that version number, and 1.14 is now supposed to be 1.27. We need to check the code and make sure 1.14-specific features and changes aren't gated on API version 1.26.Grepping, here are a few spots that may be affected:```api/server/router/container/container_routes.go:                // In case version is higher than 1.26, a binary frame will be sent.api/server/router/container/container_routes.go:                if versions.GreaterThanOrEqualTo(version, ""1.26"") {``````api/server/router/network/network_routes.go:            // Versions < 1.26 fetches all the containers attached to a networkapi/server/router/network/network_routes.go:            // run across all the networks. Starting API version 1.26, this detailedapi/server/router/network/network_routes.go:            if versions.LessThan(httputils.VersionFromContext(ctx), ""1.26"") {```cc @thaJeztah @vdemeester
"
31074,0,0,0,0,0,kixiro,0,"title:container not stop,  rpc error: code = 14 desc = grpc: the connection is unavailable, v1.13.1. description:<pre>~$ docker stop 54b3Error response from daemon: Cannot stop container 54b3: Cannot kill container 54b31cabf8548b5cac1ab09869e02a5e81d8a1d947db5529fb85a205002e2456: rpc error: code = 14 desc = grpc: the connection is unavailable</pre>Version and Info<pre>~$ docker versionClient: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64 Experimental: false~$ docker infoContainers: 5 Running: 3 Paused: 0 Stopped: 2Images: 15Server Version: 1.13.1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: N/A (expected: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1)runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-62-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 9Total Memory: 3.858 GiBName: node-dev2ID: TKQ6:XER5:NFV7:KVO3:4Q2X:PPQ3:BG24:2XUO:2YNM:7EKY:X7W4:DJSXDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false</pre>log messages:<pre>Feb 16 09:55:51 node-dev2 dockerd[1132]: time=""2017-02-16T09:55:51.955474211+03:00"" level=info msg=""Container failed to stop after sending signal 15 to the process, force killing""Feb 16 09:55:51 node-dev2 dockerd[1132]: time=""2017-02-16T09:55:51.955646461+03:00"" level=error msg=""Handler for POST /v1.26/containers/54b3/stop returned error: Cannot stop container 54b3: Cannot kill container 54b31cabf8548b5cac1ab09869e02a5e81d8a1d947db5529fb85a205002e2456: rpc error: code = 14 desc = grpc: the connection is unavailable""Feb 16 09:55:52 node-dev2 dockerd[1132]: time=""2017-02-16T09:55:52.021816927+03:00"" level=error msg=""Handler for POST /v1.24/containers/c6522f36942d5a7b0b05bd3ddafd0566a592cccc3dcab44662d0b11aeb997b69/start returned error: grpc: the connection is unavailable""</pre>additional erros in log:<pre>Feb 16 09:55:35 node-dev2 dockerd[1132]: time=""2017-02-16T09:55:35.255532487+03:00"" level=error msg=""stream copy error: reading from a closed fifo\ngithub.com/docker/docker/vendor/github.com/tonistiigi/fifo.(*fifo).Read\n\t/usr/src/docker/.gopath/src/github.com/docker/docker/vendor/github.com/tonistiigi/fifo/fifo.go:142\nbufio.(*Reader).fill\n\t/usr/local/go/src/bufio/bufio.go:97\nbufio.(*Reader).WriteTo\n\t/usr/local/go/src/bufio/bufio.go:472\nio.copyBuffer\n\t/usr/local/go/src/io/io.go:380\nio.Copy\n\t/usr/local/go/src/io/io.go:360\ngithub.com/docker/docker/pkg/pools.Copy\n\t/usr/src/docker/.gopath/src/github.com/docker/docker/pkg/pools/pools.go:60\ngithub.com/docker/docker/container/stream.(*Config).CopyToPipe.func1.1\n\t/usr/src/docker/.gopath/src/github.com/docker/docker/container/stream/streams.go:119\nruntime.goexit\n\t/usr/local/go/src/runtime/asm_amd64.s:2086""</pre>formatted trace:<pre>stream copy error: reading from a closed fifogithub.com/docker/docker/vendor/github.com/tonistiigi/fifo.(*fifo).Read	/usr/src/docker/.gopath/src/github.com/docker/docker/vendor/github.com/tonistiigi/fifo/fifo.go:142bufio.(*Reader).fill	/usr/local/go/src/bufio/bufio.go:97bufio.(*Reader).WriteTo	/usr/local/go/src/bufio/bufio.go:472io.copyBuffer	/usr/local/go/src/io/io.go:380io.Copy	/usr/local/go/src/io/io.go:360github.com/docker/docker/pkg/pools.Copy	/usr/src/docker/.gopath/src/github.com/docker/docker/pkg/pools/pools.go:60github.com/docker/docker/container/stream.(*Config).CopyToPipe.func1.1	/usr/src/docker/.gopath/src/github.com/docker/docker/container/stream/streams.go:119runtime.goexit	/usr/local/go/src/runtime/asm_amd64.s:2086</pre>System:<pre>~$ uname -aLinux node-dev2 4.4.0-62-generic #83-Ubuntu SMP Wed Jan 18 14:10:15 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</pre>packages<pre>~$ apt-cache policy docker-enginedocker-engine:  闂傚倷绀侀幖顐ょ矉鐎ｎ喖围閹肩补鎳ｈ閺岋綁鎮㈤崫銉х厐闂佹椿鍘奸崐鍨暦閹达箑绠ｉ柨鏃囨閻﹁泛顪冮妶鍛婵炲眰鍊涢埅鎼佹⒒娴ｅ搫甯堕柛妯荤墪闇夐柛銉墯閳锋捇鏌涢…鎴濇珮婵炲吋鐗犻弻鐔风暋閻楀牊鎷遍梺? 1.13.1-0~ubuntu-xenial  闂備浇宕甸崑鐐烘偄椤掑倻绀婂〒姘ｅ亾鐎规洘鍨块獮瀣晜閽樺妯佹俊鐐€曠换鎰偓姘煎墴瀵煡骞栨担鍦幍闂佸憡鍔樼亸娆愭櫠閺囥垺鐓曢柣鏂挎啞瀹曞矂鏌＄仦鑺ュ枠妞ゃ垺妫冨畷鍫曟嚋閺?   1.13.1-0~ubuntu-xenial  闂備浇顕х€涒晝绮欓幒鏃€宕查柛顐犲劚绾惧鏌熸潏鍓х暠婵☆偅蓱缁绘繃绻濋崒娑辨＆濠碘槅鍨伴澶愬蓟閻旂厧绀冮柤纰卞墮閳彃顪冮妶蹇曠暠闁绘牕銈稿?闂傚倷鑳堕崢褔宕㈤弽顓熷€块柨鏇炲亰缂嶆牗銇勯幇鈺佲偓鏍窗閹邦剦鐔嗛悹鍝勬惈閻︺劍淇婇幓鎺旂Ш闁哄瞼鍠栧畷姗€鎳犻鈧·鈧紓? *** 1.13.1-0~ubuntu-xenial 500        500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages        100 /var/lib/dpkg/status     1.13.0-0~ubuntu-xenial 500        500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages     1.12.6-0~ubuntu-xenial 500        500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages     1.12.5-0~ubuntu-xenial 500        500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages     1.12.4-0~ubuntu-xenial 500        500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages     1.12.3-0~xenial 500        500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages     1.12.2-0~xenial 500        500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages     1.12.1-0~xenial 500        500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages     1.12.0-0~xenial 500        500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages     1.11.2-0~xenial 500        500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages     1.11.1-0~xenial 500        500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages     1.11.0-0~xenial 500        500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages</pre>
"
31051,0,3962,0,0,0,feffi,0,"title:Docker build caching not working on specific base images. description:Recently I discovered a strange behaviour in docker build caching. Docker build is not caching at all on specific FROM base images.**Dockerfile No. 1 (not caching at all)**```FROM gbeutner/sles-11-sp4-x86_64RUN echo ""1""RUN echo ""2""RUN echo ""3""RUN echo ""4""```**Dockerfile No. 2 (caching working normally)**```FROM ubuntuRUN echo ""1""RUN echo ""2""RUN echo ""3""RUN echo ""4""```**Steps to reproduce the issue:**1. Create Dockerfile No. 12. ``docker build .`` (first run)3. ``docker build .`` (second run)Rinse and repeat with Dockerfile No. 2**FIRST run on Dockerfile No. 1**```Sending build context to Docker daemon 2.048 kBStep 1/5 : FROM gbeutner/sles-11-sp4-x86_64 ---> 670a2c051e58Step 2/5 : RUN echo ""1"" ---> Running in 80c33149a6301 ---> f5519bc7a04cRemoving intermediate container 80c33149a630Step 3/5 : RUN echo ""2"" ---> Running in 6510ff3f42fa2 ---> 9c3359a72b4cRemoving intermediate container 6510ff3f42faStep 4/5 : RUN echo ""3"" ---> Running in cd7cc309134b3 ---> bcd9f548062fRemoving intermediate container cd7cc309134bStep 5/5 : RUN echo ""4"" ---> Running in 4df8c10eed584 ---> bb28918474fcRemoving intermediate container 4df8c10eed58Successfully built bb28918474fc```**SECOND run on Dockerfile No. 1**```Sending build context to Docker daemon 2.048 kBStep 1/5 : FROM gbeutner/sles-11-sp4-x86_64 ---> 670a2c051e58Step 2/5 : RUN echo ""1"" ---> Running in 9e2a4f1b847e1 ---> ba7350e42ed2Removing intermediate container 9e2a4f1b847eStep 3/5 : RUN echo ""2"" ---> Running in e5a7abd2ab7d2 ---> 3f7fee97137bRemoving intermediate container e5a7abd2ab7dStep 4/5 : RUN echo ""3"" ---> Running in 9ecd0836c0c53 ---> b27b2384b6d8Removing intermediate container 9ecd0836c0c5Step 5/5 : RUN echo ""4"" ---> Running in e07b1aa2a3a64 ---> 7c1d43a94152Removing intermediate container e07b1aa2a3a6Successfully built 7c1d43a94152```**FIRST run on Dockerfile No. 2**```Sending build context to Docker daemon 2.048 kBStep 1/5 : FROM ubuntu ---> f49eec89601eStep 2/5 : RUN echo ""1"" ---> Running in 3a55aafda0121 ---> 868e0f3374e6Removing intermediate container 3a55aafda012Step 3/5 : RUN echo ""2"" ---> Running in fe7a1d8638432 ---> de52a61bbe25Removing intermediate container fe7a1d863843Step 4/5 : RUN echo ""3"" ---> Running in f5f82e311e873 ---> bd1ac7b862a1Removing intermediate container f5f82e311e87Step 5/5 : RUN echo ""4"" ---> Running in 6afc56ae390d4 ---> 4ccbdb51b8beRemoving intermediate container 6afc56ae390dSuccessfully built 4ccbdb51b8be```**SECOND run on Dockerfile No. 2**```Sending build context to Docker daemon 2.048 kBStep 1/5 : FROM ubuntu ---> f49eec89601eStep 2/5 : RUN echo ""1"" ---> Using cache ---> 868e0f3374e6Step 3/5 : RUN echo ""2"" ---> Using cache ---> de52a61bbe25Step 4/5 : RUN echo ""3"" ---> Using cache ---> bd1ac7b862a1Step 5/5 : RUN echo ""4"" ---> Using cache ---> 4ccbdb51b8beSuccessfully built 4ccbdb51b8be```**Describe the results you expected:**There should be caching happening on the SECOND run of ``docker build .`` on Dockerfile No. 1.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 1 Running: 0 Paused: 0 Stopped: 1Images: 56Server Version: 1.13.1Storage Driver: btrfs Build Version: Btrfs v4.4 Library Version: 101Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.8.0-30-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 3.858 GiBName: devID: IQ2D:TA3G:FV64:DHVS:ROO3:S6AA:I4JD:PVC3:N6HD:CJEK:IMT4:TJE3Docker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseHttp Proxy: http://...Https Proxy: http://...No Proxy: ...Registry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**The client VM is running inside VMWare Workstation 12.5 Pro.
"
31017,0,0,0,0,0,JackyChen255,0,"title:Docker image shares same layer can't be saved by two clients simultaneously. description:---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------**System and Docker version**[root@JackDocker ~]# docker versionClient: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:38:28 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:38:28 2017 OS/Arch:      linux/amd64 Experimental: false[root@JackDocker ~]# cat /etc/centos-releaseCentOS Linux release 7.2.1511 (Core)**Description**I commit the same container two times to get two new images. The container is created from centos image and don't change any data. Then from two clients, I try to use curl to simultaneously download these two images. But one download fails. The curl output reports ""HTTP/1.1 404 Not Found"". And in Docker server, it reports. ""DEBU[344839] Assembling tar data for 1de19895e0af89cc07c539056172c52b538a5640d985ed81f7f8e067fddbff4fERRO[344839] Handler for GET /v1.26/images/get returned error: open /var/lib/docker/devicemapper/mnt/1de19895e0af89cc07c539056172c52b538a5640d985ed81f7f8e067fddbff4f/rootfs/tmp/Ahello.txt: no such file or directory""**Steps to reproduce the issue:**1. Commit container twice[root@JackDocker ~]# docker ps -a76519999ff47        centos              ""/bin/bash""              3 weeks ago         Exited (137) 3 weeks ago                        tiny_shirley[root@JackDocker ~]# docker commit 76519999ff47sha256:992afced032709407e57e715ed91d679746741dac9b9ed2e2bf1245027286278[root@JackDocker ~]# docker commit 76519999ff47sha256:8f0fc18194beafdf36fef3c90d2d5b9e210d2bbfacea54c607dc2ecc5eaf3bb32. Use curl to download these two images simultaneously from two clients. But one download failed with 404 error.[root@AAA]# curl -XGET -vs 172.24.25.184:4243/v1.26/images/get?names=8f0fc18194be > /tmp/1.tar* About to connect() to 172.24.25.184 port 4243 (#0)*   Trying 172.24.25.184...* Connected to 172.24.25.184 (172.24.25.184) port 4243 (#0)> GET /v1.26/images/get?names=8f0fc18194be HTTP/1.1> User-Agent: curl/7.29.0> Host: 172.24.25.184:4243> Accept: */*>< HTTP/1.1 200 OK< Api-Version: 1.26< Content-Type: application/x-tar< Docker-Experimental: false< Server: Docker/1.13.1 (linux)< Date: Tue, 14 Feb 2017 20:36:02 GMT< Transfer-Encoding: chunked<{ [data not shown]* Connection #0 to host 172.24.25.184 left intact[root@BBB tmp]#  curl -XGET -sv 172.24.25.184:4243/v1.26/images/get?names=992afced0327 > /tmp/1.tar* About to connect() to 172.24.25.184 port 4243 (#0)*   Trying 172.24.25.184...* Connected to 172.24.25.184 (172.24.25.184) port 4243 (#0)> GET /v1.26/images/get?names=992afced0327 HTTP/1.1> User-Agent: curl/7.29.0> Host: 172.24.25.184:4243> Accept: */*>**< HTTP/1.1 404 Not Found**< Api-Version: 1.26< Content-Type: application/json< Docker-Experimental: false< Server: Docker/1.13.1 (linux)< Date: Tue, 14 Feb 2017 20:36:02 GMT< Content-Length: 166<{ [data not shown]* Connection #0 to host 172.24.25.184 left intact**Describe the results you received:**One image download failed. And when Docker engine runs in debug mode, it shows below error message.DEBU[344839] CreateV1ID {""container_config"":{""Hostname"":"""",""Domainname"":"""",""User"":"""",""AttachStdin"":false,""AttachStdout"":false,""AttachStderr"":false,""Tty"":false,""OpenStdin"":false,""StdinOnce"":false,""Env"":null,""Cmd"":null,""Image"":"""",""Volumes"":null,""WorkingDir"":"""",""Entrypoint"":null,""OnBuild"":null,""Labels"":null},""created"":""2017-02-14T20:33:55.824777925Z"",""layer_id"":""sha256:ff61b0c09e5485261ce79a87c11accda3b8afc51920837fc1a4924fbcc0a9748"",""parent"":""sha256:ddfde0ce914aebb87ee6a5c4ae346d5aa9a09adaa7bc89bec17f984ed1331c31""}DEBU[344839] CreateV1ID {""container_config"":{""Hostname"":"""",""Domainname"":"""",""User"":"""",""AttachStdin"":false,""AttachStdout"":false,""AttachStderr"":false,""Tty"":false,""OpenStdin"":false,""StdinOnce"":false,""Env"":null,""Cmd"":null,""Image"":"""",""Volumes"":null,""WorkingDir"":"""",""Entrypoint"":null,""OnBuild"":null,""Labels"":null},""created"":""2017-02-14T20:33:55.824777925Z"",""layer_id"":""sha256:84536107022ec06d756ab5bbf08e15f2b5fb3864ec6e281e8c2399ddfd7463e6"",""parent"":""sha256:5bbb1c3e2d1803c7109ace24cfaf659acbf89c121899fb5f5d32166852a15359""}DEBU[344839] CreateV1ID {""architecture"":""amd64"",""config"":{""Hostname"":"""",""Domainname"":"""",""User"":"""",""AttachStdin"":false,""AttachStdout"":false,""AttachStderr"":false,""ExposedPorts"":{""456/tcp"":{}},""Tty"":false,""OpenStdin"":false,""StdinOnce"":false,""Env"":null,""Cmd"":[""/bin/bash""],""Image"":"""",""Volumes"":null,""WorkingDir"":"""",""Entrypoint"":null,""OnBuild"":null,""Labels"":{""build-date"":""2016-03-31"",""license"":""GPLv2"",""name"":""CentOS Base Image"",""vendor"":""CentOS""},""StopSignal"":""SIGTERM""},""container"":""76519999ff478131eeb905ffd578603c5e742dbdf380a873e425fca121884e6c"",""container_config"":{""Hostname"":""76519999ff47"",""Domainname"":"""",""User"":"""",""AttachStdin"":true,""AttachStdout"":true,""AttachStderr"":true,""ExposedPorts"":{""456/tcp"":{}},""Tty"":true,""OpenStdin"":true,""StdinOnce"":true,""Env"":null,""Cmd"":[""/bin/bash""],""Image"":""centos"",""Volumes"":null,""WorkingDir"":"""",""Entrypoint"":null,""OnBuild"":null,""Labels"":{""build-date"":""2016-03-31"",""license"":""GPLv2"",""name"":""CentOS Base Image"",""vendor"":""CentOS""},""StopSignal"":""SIGTERM""},""created"":""2017-02-14T20:33:55.824777925Z"",""docker_version"":""1.13.1"",""layer_id"":""sha256:514a2a573af7c5adb3b8afacce69db110a820664f4830f43ee2f4107ecbcf0f3"",""os"":""linux"",""parent"":""sha256:ba66c805459e2e7e9ab1526cb38378e44d2fa8276e005730e1573c6d04d5a6bb""}DEBU[344839] Assembling tar data for 1de19895e0af89cc07c539056172c52b538a5640d985ed81f7f8e067fddbff4f**ERRO[344839] Handler for GET /v1.26/images/get returned error: open /var/lib/docker/devicemapper/mnt/1de19895e0af89cc07c539056172c52b538a5640d985ed81f7f8e067fddbff4f/rootfs/tmp/Ahello.txt: no such file or directory**DEBU[344839] Assembling tar data for 1de19895e0af89cc07c539056172c52b538a5640d985ed81f7f8e067fddbff4f
"
31015,0,2640,3,0,0,vikstrous,0,"title:network aliases don't work for containers with auto-generated names. description:**Description**Network aliases don't work on attachable overlay networks unless you specify a container name manually as well.Set up the network:```docker network create --attachable -d overlay testnet```Success case:```docker run --rm -it --net testnet --name somename --net-alias test alpine sh/ # ping testPING test (10.0.0.2): 56 data bytes64 bytes from 10.0.0.2: seq=0 ttl=64 time=0.031 ms```Fail case:```docker run --rm -it --net testnet --net-alias test alpine sh/ # ping testping: bad address 'test'```See also previous issue about network aliases not working #27370**Steps to reproduce the issue:**see above**Describe the results you received:**see above**Describe the results you expected:**see above**Additional information you deem important (e.g. issue happens only occasionally):**100% reproducible on docker 1.13.1 and master**Output of `docker version`:**```docker versionClient: Version:      1.14.0-dev API version:  1.26 Go version:   go1.7.4 Git commit:   bf6eb85 Built:        Tue Dec 27 22:23:51 2016 OS/Arch:      linux/amd64Server: Version:      1.14.0-dev API version:  1.26 (minimum version 1.12) Go version:   go1.7.4 Git commit:   bf6eb85 Built:        Tue Dec 27 22:23:51 2016 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```docker infoContainers: 40 Running: 38 Paused: 0 Stopped: 2Images: 1640Server Version: 1.14.0-devStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: im59t8fl8fza5tll52ojakhsh Is Manager: true ClusterID: 2kpjas1i8ysj5cftv3o9wz7yk Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months  External CAs:    cfssl: https://172.17.0.1:12381/api/v1/cfssl/sign Node Address: 172.17.0.1 Manager Addresses:  172.17.0.1:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090erunc version: 51371867a01c467f08af739783b8beafc154c4d7init version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.8.17Operating System: NixOS 17.03.git.6378f62 (Gorilla)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 15.53 GiBName: thisisfineID: 4XB6:RAOL:2UT7:W3TT:JBSR:ILHC:LREA:HUVU:5U7V:TI7E:WUT2:WQTSDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 388 Goroutines: 519 System Time: 2017-02-14T11:29:42.882901796-08:00 EventsListeners: 4Username: viktorstanchevRegistry: https://index.docker.io/v1/WARNING: No cpu cfs quota supportWARNING: No cpu cfs period supportExperimental: falseInsecure Registries: 172.17.0.1:3001 172.17.0.1:443 172.17.0.1:444 172.17.0.1:445 172.17.0.1 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**physical
"
30993,1,3809,54,0,0,chrishoage,0,"title:ZFS failed to register layer dataset does not exist. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Trying to pull some images (I'm still unsure why some work and other do not) result in the following error ```failed to register layer: exit status 2: ""/sbin/zfs zfs snapshot pond/docker/4522c1adffaf266062442dba2eb347084d774267a124d1bd7a04e6b3cb9634f0@371563767"" => cannot open 'pond/docker/4522c1adffaf266062442dba2eb347084d774267a124d1bd7a04e6b3cb9634f0': dataset does not existusage:	snapshot|snap [-r] [-o property=value] ... <filesystem|volume>@<snap> ...For the property list, run: zfs set|getFor the delegated permission list, run: zfs allow|unallow```Not all images have this problem```闂?docker image pull nginxUsing default tag: latestlatest: Pulling from library/nginx5040bd298390: Already exists333547110842: Pull complete4df1e44d2a7a: Pull completeDigest: sha256:f2d384a6ca8ada733df555be3edc427f2e5f285ebf468aae940843de8cf74645Status: Downloaded newer image for nginx:latest``````闂?docker image pull nginx:alpinealpine: Pulling from library/nginxb7f33cc0b48e: Already exists9a57e9207914: Pull complete79f62f9c7236: Pull complete50a2334db9bc: Pull completeDigest: sha256:d34e2176dab830485b0cb79340e1d5ebf7d530b34ad7bfe05d269ffed20a88f4Status: Downloaded newer image for nginx:alpine```But others do ```闂?docker image pull cantino/huginnUsing default tag: latestlatest: Pulling from cantino/huginnc60055a51d74: Already exists755da0cdb7d2: Already exists969d017f67e6: Already exists37c9a9113595: Already existsa3d9f8479786: Already existsd7d0c2c8ec3c: Extracting [==================================================>]    783 B/783 B3480f3638ec5: Download completedc00c829c370: Download complete52c5f6110241: Download complete65f3a34b31c0: Download complete4970b4c36b25: Download completedf6da8726ead: Download complete236e60444501: Download complete94fb09e7b96d: Download completeaac028a46934: Download completec78dd42f78d9: Download completefailed to register layer: exit status 2: ""/sbin/zfs zfs snapshot pond/docker/4522c1adffaf266062442dba2eb347084d774267a124d1bd7a04e6b3cb9634f0@371563767"" => cannot open 'pond/docker/4522c1adffaf266062442dba2eb347084d774267a124d1bd7a04e6b3cb9634f0': dataset does not existusage:	snapshot|snap [-r] [-o property=value] ... <filesystem|volume>@<snap> ...For the property list, run: zfs set|getFor the delegated permission list, run: zfs allow|unallow```**Steps to reproduce the issue:**1. Ensure you are using docker with the zfs driver2. Pull an image (`cantino/huginn`)3. Observe ZFS error**Describe the results you received:**A `dataset does not exist` error for trying to create a snapshot off a dataset that did not exist.**Describe the results you expected:**The dataset to be created correctly.**Additional information you deem important (e.g. issue happens only occasionally):**The two images I've had this happen on so far are `plexinc/pms-docker:plexpass`, `plexinc/pms-docker:public`, `cantino/huginn`. As the output above shows, `nginx` and friends do not have this issue.**Output of `docker version`:**```闂?docker versionClient: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```闂?docker infoContainers: 5 Running: 5 Paused: 0 Stopped: 0Images: 12Server Version: 1.13.1Storage Driver: zfs Zpool: pond Zpool Health: ONLINE Parent Dataset: pond/docker Space Used By Parent: 1008901120 Space Available: 501376187904 Parent Quota: no Compression: lz4Logging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-62-genericOperating System: Ubuntu 16.04.2 LTSOSType: linuxArchitecture: x86_64CPUs: 12Total Memory: 31.32 GiBName: cortexID: ZHTI:AFNB:DZ56:WQ2P:VSZL:5EWB:NLLR:4Q3M:4YWV:NV4C:J52R:UFKKDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Running on Ubuntu 16.04 with ZFS on Linux
"
30991,0,3655,300,0,0,mdlinville,1,"title:default secret mode in docker stack deploy. description:**Description**The default mode for secrets is supposed to be `0444` and this seems to be honored if you start a service with a secret by hand, as in the following example:```$ echo test | docker secret create my_secret -$ docker service create --name=my_redis --secret=my_secret redis:latest$ docker psCONTAINER ID        IMAGE                                                                           COMMAND                  CREATED             STATUS                  PORTS               NAMES05e643892f24        redis@sha256:afa4b429ef3ee08c8b198e50d684c5da0ffa43ae58631f61b08829bd6df3c500   ""docker-entrypoint...""   2 seconds ago       Up Less than a second   6379/tcp            my_redis.1.v17c59sp5xhvtmrcwb2i8k8w5$ docker exec 05e643892f24 ls -l /run/secrets/total 4-r--r--r-- 1 root root 5 Feb 14 00:09 my_secret```However, if I try to create the same service using a stack file:```version: ""3.1""services:  redis:    image: redis:latest    deploy:      replicas: 1    secrets:      - my_secretsecrets:  my_secret:    external: true```The secret is created with mode `000`:```$ docker stack deploy --compose-file docker-compose.yml my_redis$ docker service lsID            NAME            MODE        REPLICAS  IMAGEnx15ud8xas4k  my_redis_redis  replicated  1/1       redis:latest[misty@Spares-MacBook-Pro minimal_example]$ docker psCONTAINER ID        IMAGE                                                                           COMMAND                  CREATED             STATUS              PORTS               NAMESed741f855a4f        redis@sha256:afa4b429ef3ee08c8b198e50d684c5da0ffa43ae58631f61b08829bd6df3c500   ""docker-entrypoint...""   9 seconds ago       Up 7 seconds        6379/tcp            my_redis_redis.1.lx1w1zu7n5dvf3se3onthoo20$ docker exec ed741f855a4f ls -l /run/secrets/total 4---------- 1 root root 5 Feb 14 00:12 my_secret```**Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      darwin/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 08:47:51 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 40 Running: 1 Paused: 0 Stopped: 39Images: 355Server Version: 1.13.1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: g35wgnc8gq8vj00coqm5tfy7r Is Manager: true ClusterID: tovqmbzkj5mi9rmmcvmug8ecw Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.65.2 Manager Addresses:  192.168.65.2:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.8-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.952 GiBName: mobyID: I6B3:EFAL:TTOU:3LQG:QPHM:JRSX:I3D7:ULQJ:LZQ3:5O43:6G4U:TV4PDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 43 Goroutines: 143 System Time: 2017-02-14T00:14:09.082176811Z EventsListeners: 2No Proxy: *.local, 169.254/16Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```cc/ @nathanleclaire @shin- @thaJeztah 
"
30984,0,7895,1,0,0,ghollies,0,"title:containerd process continually restarting: process.json: no such file or directory. description:**Description**Shortly after startup, during a period of heavy system resource usage, I am seeing errors in from `journalctl` showing```Feb 12 19:22:19 example.com dockerd[883]: time=""2017-02-12T19:22:19.602401661-05:00"" level=info msg=""libcontainerd: new containerd process, pid: 22486""Feb 12 19:22:20 example.com dockerd[883]: time=""2017-02-12T19:22:20.109646713-05:00"" level=fatal msg=""open /var/run/docker/libcontainerd/containerd/a4169549305be1652784c635dd42cf0c84ba81be928cd430ab2608f0bf7fb862/1c53926e88b4be112f691600ed84a840c2d42032e2488f349bfe8d476a7ac42e/process.json: no such file or directory""```It then proceeds to keep spawning a new containerd, and then it dies immediately.The result is a system which can't properly interact with containers, no docker stop/exec, health checks always fail and return unhealthy. `docker exec -i -t container-name /bin/bashrpc error: code = 14 desc = grpc: the connection is unavailable`When inspecting the running processes we can see that the usual `docker-containerd` isn't running**Steps to reproduce the issue:**No easy reproduction1. Start up 3-4 containers on a system with health check defined (small light weight ones)2. Put the system under a heavy load  (max out CPU usage)3. Do this a lot of times, some machines will recover quickly. others will enter the failed state looking for `process.json`**Describe the results you received:**```Feb 12 19:22:17 example.com dockerd[883]: time=""2017-02-12T19:22:17.339757786-05:00"" level=error msg=""libcontainerd: failed to receive event from containerd: rpc error: code = 13 desc = transport is closing""Feb 12 19:22:17 example.com dockerd[883]: time=""2017-02-12T19:22:17.345519413-05:00"" level=warning msg=""Health check for container a4169549305be1652784c635dd42cf0c84ba81be928cd430ab2608f0bf7fb862 error: rpc error: code = 13 desc = transport is closing""Feb 12 19:22:17 example.com dockerd[883]: time=""2017-02-12T19:22:17.345855590-05:00"" level=warning msg=""Health check for container 6c973e40946c04543d6e444081bc7765e1c29e55c03168222c2ee4b0b3073756 error: rpc error: code = 13 desc = transport is closing""Feb 12 19:22:17 example.com dockerd[883]: time=""2017-02-12T19:22:17.346003309-05:00"" level=warning msg=""Health check for container 22310406af918a0af7e90c2e8234873237057ec84ccb636244b2b1c477416270 error: rpc error: code = 13 desc = transport is closing""Feb 12 19:22:18 example.com dockerd[883]: time=""2017-02-12T19:22:18.644524466-05:00"" level=info msg=""libcontainerd: new containerd process, pid: 22478""Feb 12 19:22:19 example.com dockerd[883]: time=""2017-02-12T19:22:19.602401661-05:00"" level=info msg=""libcontainerd: new containerd process, pid: 22486""Feb 12 19:22:20 example.com dockerd[883]: time=""2017-02-12T19:22:20.109646713-05:00"" level=fatal msg=""open /var/run/docker/libcontainerd/containerd/a4169549305be1652784c635dd42cf0c84ba81be928cd430ab2608f0bf7fb862/1c53926e88b4be112f691600ed84a840c2d42032e2488f349bfe8d476a7ac42e/process.json: no such file or directory""Feb 12 19:22:20 example.com dockerd[883]: time=""2017-02-12T19:22:20.909410988-05:00"" level=info msg=""libcontainerd: new containerd process, pid: 22494""Feb 12 19:22:20 example.com dockerd[883]: time=""2017-02-12T19:22:20.933222703-05:00"" level=fatal msg=""open /var/run/docker/libcontainerd/containerd/a4169549305be1652784c635dd42cf0c84ba81be928cd430ab2608f0bf7fb862/1c53926e88b4be112f691600ed84a840c2d42032e2488f349bfe8d476a7ac42e/process.json: no such file or directory""Feb 12 19:22:22 example.com dockerd[883]: time=""2017-02-12T19:22:22.409392219-05:00"" level=info msg=""libcontainerd: new containerd process, pid: 22500""Feb 12 19:22:22 example.com dockerd[883]: time=""2017-02-12T19:22:22.43553991-05:00"" level=fatal msg=""open /var/run/docker/libcontainerd/containerd/a4169549305be1652784c635dd42cf0c84ba81be928cd430ab2608f0bf7fb862/1c53926e88b4be112f691600ed84a840c2d42032e2488f349bfe8d476a7ac42e/process.json: no such file or directory""```and the last couple lines repeat forever, with the occasional failed health-check message**Describe the results you expected:**recovery looks like:```Feb 13 11:54:05 example.com dockerd[865]: time=""2017-02-13T11:52:40.063994820-05:00"" level=warning msg=""Health check for container 484ba5dd5c8aa113f86e0faf3abc3f4e2f9cbdfcf0800750023d979d2e96df46 error: rpc error: code = 13 desc = transport is closing""Feb 13 11:54:05 example.com dockerd[865]: time=""2017-02-13T11:52:43.081118258-05:00"" level=info msg=""libcontainerd: new containerd process, pid: 24964""...Feb 13 11:54:05 example.com dockerd[865]: time=""2017-02-13T11:53:40.063733001-05:00"" level=warning msg=""Health check for container 6b862ee77cb8f67ee248068041a9492f3b84b158a4b23b3c91fde26d658f9e22 error: rpc error: code = 4 desc = context deadline exceeded""Feb 13 11:54:05 example.com dockerd[865]: time=""2017-02-13T11:53:45.150569781-05:00"" level=warning msg=""Health check for container 484ba5dd5c8aa113f86e0faf3abc3f4e2f9cbdfcf0800750023d979d2e96df46 error: rpc error: code = 4 desc = context deadline exceeded""Feb 13 11:54:05 example.com dockerd[865]: 2017/02/13 11:53:48 grpc: Server.processUnaryRPC failed to write status stream error: code = 4 desc = ""context deadline exceeded""Feb 13 11:54:05 example.com dockerd[865]: 2017/02/13 11:53:48 grpc: Server.processUnaryRPC failed to write status: stream error: code = 4 desc = ""context deadline exceeded""Feb 13 11:54:05 example.com dockerd[865]: panic: close of nil channelFeb 13 11:54:05 example.com dockerd[865]: goroutine 155 [running]:Feb 13 11:54:05 example.com dockerd[865]: panic(0x8078a0, 0xc4203c3d50)Feb 13 11:54:05 example.com dockerd[865]: /usr/local/go/src/runtime/panic.go:500 +0x1a1Feb 13 11:54:05 example.com dockerd[865]: github.com/docker/containerd/supervisor.(*Supervisor).execExit.func1(0xc4203c70e0, 0xc42017ea90, 0x0)Feb 13 11:54:05 example.com dockerd[865]: /go/src/github.com/docker/containerd/supervisor/exit.go:90 +0x10cFeb 13 11:54:05 example.com dockerd[865]: created by github.com/docker/containerd/supervisor.(*Supervisor).execExitFeb 13 11:54:05 example.com dockerd[865]: /go/src/github.com/docker/containerd/supervisor/exit.go:91 +0xeeFeb 13 11:54:05 example.com dockerd[865]: time=""2017-02-13T11:54:01.384438045-05:00"" level=error msg=""libcontainerd: failed to receive event from containerd: rpc error: code = 13 desc = transport is closing""Feb 13 11:54:05 example.com dockerd[865]: time=""2017-02-13T11:54:01.907649292-05:00"" level=info msg=""libcontainerd: new containerd process, pid: 25197""Feb 13 11:54:50 example.com dockerd[865]: time=""2017-02-13T11:54:50.594564930-05:00"" level=error msg=""libcontainerd: failed to receive event from containerd: rpc error: code = 13 desc = transport is closing""Feb 13 11:54:51 example.com dockerd[865]: time=""2017-02-13T11:54:50.599276124-05:00"" level=info msg=""libcontainerd: new containerd process, pid: 25348""Feb 13 11:54:52 example.com dockerd[865]: time=""2017-02-13T11:54:50.605611385-05:00"" level=warning msg=""Health check for container 6b862ee77cb8f67ee248068041a9492f3b84b158a4b23b3c91fde26d658f9e22 error: rpc error: code = 13 desc = transport is closing""Feb 13 11:54:56 example.com dockerd[865]: time=""2017-02-13T11:54:50.679610404-05:00"" level=warning msg=""Health check for container 484ba5dd5c8aa113f86e0faf3abc3f4e2f9cbdfcf0800750023d979d2e96df46 error: rpc error: code = 14 desc = grpc: the connection is unavailable""Feb 13 11:54:56 example.com dockerd[865]: time=""2017-02-13T11:54:51.407090487-05:00"" level=info msg=""libcontainerd: new containerd process, pid: 25356""```**Additional information you deem important (e.g. issue happens only occasionally):**We were only able to reproduce this 1/10 tries or so**Output of `docker version`:**```Client: Version:      1.13.0 API version:  1.25 Go version:   go1.7.3 Git commit:   49bf474 Built:        Tue Jan 17 09:55:28 2017 OS/Arch:      linux/amd64Server: Version:      1.13.0 API version:  1.25 (minimum version 1.12) Go version:   go1.7.3 Git commit:   49bf474 Built:        Tue Jan 17 09:55:28 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 4 Running: 4 Paused: 0 Stopped: 0Images: 14Server Version: 1.13.0Storage Driver: overlay Backing Filesystem: xfs Supports d_type: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: N/A (expected: 03e5862ec0d8d3b3f750e19fca3ee367e13c090e)runc version: 2f7393a47307a16f8cee44a37b262e8b81021e3einit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.6.1.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 7.388 GiBName: example.comID: XQM5:RIEE:MFIW:YIFG:DAAC:ZYZC:RX2V:JZJI:3MXU:TF3P:V2D6:4TBLDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Running on AWS
"
30938,0,2722,0,0,0,anton-shirikov,0,"title:Creating service with publish mode=host and without published port crashes swarm manager. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**It seems like docker engine crashes when you are creating a service that exposes container port (using mode=host) on a random node portWhen providing both target and published port this problem does not occur and container is scheduled immediately.**Steps to reproduce the issue:**1. run ``` docker service create --name nginx --publish mode=host,target=80 nginx ```**Describe the results you received:**When running the command memory usage starts to go up until OS runs out of memory and OOM decides to kill docker engine process.After docker process restarts everything works fine, and the container is scheduled with a random port assigned to it (restarting docker before OOM kills it works fine as well).It does not show published port on service inspect:```admin@ip-172-31-1-47:~$ docker service inspect --pretty nginxID:             nxvndc2nniywikroeg7ebpt5pName:           nginxService Mode:   Replicated Replicas:      1Placement:UpdateConfig: Parallelism:   1 On failure:    pause Max failure ratio: 0ContainerSpec: Image:         nginx:latest@sha256:f2d384a6ca8ada733df555be3edc427f2e5f285ebf468aae940843de8cf74645Resources:Endpoint Mode:  vipPorts: PublishedPort 0  Protocol = tcp  TargetPort = 80 ```But does on service ps:```admin@ip-172-31-1-47:~$ docker service ps nginxID            NAME     IMAGE         NODE            DESIRED STATE  CURRENT STATE           ERROR  PORTSlwbw4suxil5k  nginx.1  nginx:latest  ip-172-31-1-82  Running        Running 10 minutes ago         *:32770->80/tcp```**Describe the results you expected:**Container is scheduled with a random port assigned to it on a worker node without crashing manager's docker engine.**Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:42:29 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:42:29 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 1.13.1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: j0r7jtwgi2tmwvioytu5ihc74 Is Manager: true ClusterID: xxmtdbgbjtn4590bxaqdz81c5 Managers: 1 Nodes: 3 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 172.31.1.47 Manager Addresses:  172.31.1.47:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: apparmorKernel Version: 4.2.0-040200-genericOperating System: Ubuntu 14.04.4 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 487.2 MiBName: ip-172-31-1-47ID: L4GS:BQCP:TDEH:OT4N:37XO:OV55:STBD:7W2N:G5OW:U6JC:IJAJ:ENHWDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**AWS t2.nano instances - 1 swarm manager with availability=drain and 2 worker nodes
"
30854,0,5958,2,0,0,joelchen,0,"title:Global mode target replicas keep increasing. description:**Description**Global mode target replicas keep increasing until a certain number, and current replicas is 0. Similar issue as http://stackoverflow.com/questions/41934123/docker-1-13-stack-deploy-with-global-service-malfunction-target-replicas-increa.**Steps to reproduce the issue:**1. Create 2 manager node swarm cluster.2. Edit docker-compose.yml on master node with service deploy set to global mode.3. `docker stack deploy -c docker-compose.yml stack`4. `docker service ls`5. `docker service ls` again after some time.6. `docker service ls` again after a few minutes.**Describe the results you received:**```$ docker service lsID            NAME                          MODE        REPLICAS  IMAGEy9vgl0f9b15c  project_caddy                     global      0/2       chrishawes/caddy:latest``````$ docker service lsy9vgl0f9b15c  project_caddy                     global      0/17      chrishawes/caddy:latest``````$ docker service lsID            NAME                          MODE        REPLICAS  IMAGEy9vgl0f9b15c  project_caddy                     global      0/29      chrishawes/caddy:latest```**Describe the results you expected:**```$ docker service lsID            NAME                          MODE        REPLICAS  IMAGEy9vgl0f9b15c  project_caddy                     global      2/2      chrishawes/caddy:latest```**Additional information you deem important (e.g. issue happens only occasionally):**If redis is used instead of caddy, target replica is correct (in this case swarm has 3 managers) but current replica is always 1:```$ docker service lsID            NAME                          MODE        REPLICAS  IMAGEvjqgk8qxoeai  project_redis                     global      1/3       redis:latest```Listing the containers in one of the manager nodes, there is a bunch of redis containers created but not running:```$ docker ps -aCONTAINER ID        IMAGE                                                                                                         COMMAND                  CREATED                  STATUS              PORTS                                                           NAMESc104fc03cc52        redis@sha256:afa4b429ef3ee08c8b198e50d684c5da0ffa43ae58631f61b08829bd6df3c500                                 ""docker-entrypoint...""   Less than a second ago   Created                                                                             project_redis.slk8qedylxazh54ymvfm3nko1.y3yohlpp9hkb9wmdix62wsv0827e5331d4dbe        redis@sha256:afa4b429ef3ee08c8b198e50d684c5da0ffa43ae58631f61b08829bd6df3c500                                 ""docker-entrypoint...""   6 seconds ago            Created                                                                             project_redis.slk8qedylxazh54ymvfm3nko1.r599un5n1kifrgpoy2t41z57x0c1ee32c1ab7        redis@sha256:afa4b429ef3ee08c8b198e50d684c5da0ffa43ae58631f61b08829bd6df3c500                                 ""docker-entrypoint...""   11 seconds ago           Created                                                                             project_redis.slk8qedylxazh54ymvfm3nko1.rz6x512dc4sbojrvwnyrltd2o4d1c85c2b582        redis@sha256:afa4b429ef3ee08c8b198e50d684c5da0ffa43ae58631f61b08829bd6df3c500                                 ""docker-entrypoint...""   16 seconds ago           Created                                                                             project_redis.slk8qedylxazh54ymvfm3nko1.o9r9dcqmolxso4bj4hdqbfvi7d14cf376d8e3        redis@sha256:afa4b429ef3ee08c8b198e50d684c5da0ffa43ae58631f61b08829bd6df3c500                                 ""docker-entrypoint...""   21 seconds ago           Created                                                                             project_redis.slk8qedylxazh54ymvfm3nko1.z5s62mfnx2v00ac6aiclq3vwz7c2697d3d1ea        redis@sha256:afa4b429ef3ee08c8b198e50d684c5da0ffa43ae58631f61b08829bd6df3c500                                 ""docker-entrypoint...""   27 seconds ago           Created                                                                             project_redis.slk8qedylxazh54ymvfm3nko1.h50xvf1fa26y65t094e3v0syl```In the manager node that has one redis container running, there is another redis created but not running:```$ docker ps -aCONTAINER ID        IMAGE                                                                                                         COMMAND                  CREATED             STATUS              PORTS                               NAMESredis@sha256:afa4b429ef3ee08c8b198e50d684c5da0ffa43ae58631f61b08829bd6df3c500                                 ""docker-entrypoint...""   6 minutes ago       Up 6 minutes        6379/tcp                            project_redis.n0iu4zdto5ezdiscnu36urnsq.wzn63rk17f7yhmf8ouwvlywzk6a93743b60ec        redis@sha256:afa4b429ef3ee08c8b198e50d684c5da0ffa43ae58631f61b08829bd6df3c500                                 ""docker-entrypoint...""   6 minutes ago       Created                                                 project_redis.n0iu4zdto5ezdiscnu36urnsq.tqzv5yech4b39k0n38xa2co3z```**Output of `docker version`:**```Client: Version:      1.13.1 API version:  1.26 Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64Server: Version:      1.13.1 API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   092cba3 Built:        Wed Feb  8 06:50:14 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 35 Running: 0 Paused: 0 Stopped: 35Images: 12Server Version: 1.13.1Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 121 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: gvqvt20ff1cpvq2tonlb7l92q Is Manager: true ClusterID: xd92cbileld0mieqx8qb8pf05 Managers: 2 Nodes: 2 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 172.31.16.112 Manager Addresses:  172.31.16.112:2377  172.31.7.169:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1runc version: 9df8b306d01f59d3a8029be411de015b7304dd8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-62-genericOperating System: Ubuntu 16.04.1 LTSOSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 1.952 GiBName: ip-172-31-16-112ID: SWAH:VWD3:HGAX:NKEB:MKVC:LK7B:BPQ2:S6X5:DA6J:QPXD:Y3AN:XAQVDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: khamoudRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Nodes are AWS t2.small instances.
"
30816,0,1737,298,0,0,runcom,0,"title:[REGRESSION] connection reset by peer when attaching stdin AND stderr at run. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**echo'ing something while attaching stdin AND stderr at docker run isn't working anymore. Works fine if you use just stdin or just stderr instead.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. `echo true | docker run -a stdin -a stderr --tty=false fedora bash`2. `echo true | docker run -a stdin -a stderr fedora bash`3.**Describe the results you received:**```sh$ echo true | docker run -a stdin -a stderr fedora bashread unix @->/var/run/docker.sock: read: connection reset by peer```**Describe the results you expected:**just exit == 0**Additional information you deem important (e.g. issue happens only occasionally):**if you revert this https://github.com/docker/docker/pull/30446 - everything works ok again.**Output of `docker version`:**```Client: Version:      1.14.0-dev API version:  1.26 Go version:   go1.7.5 Git commit:   41650df Built:        Wed Feb  8 09:46:12 2017 OS/Arch:      linux/amd64Server: Version:      1.14.0-dev API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   41650df Built:        Wed Feb  8 09:46:12 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 8 Running: 0 Paused: 0 Stopped: 8Images: 51Server Version: 1.14.0-devStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: journaldCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: cc oci runcDefault Runtime: ociInit Binary: docker-initcontainerd version: 78fb8f45890a601e0fd9051cf9f9f74923e950fdrunc version: 51371867a01c467f08af739783b8beafc154c4d7init version: 949e6faSecurity Options: seccomp  Profile: default selinuxKernel Version: 4.9.7-201.fc25.x86_64Operating System: Fedora 25 (Workstation Edition)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 11.44GiBName: runcom.usersys.redhat.comID: 62I5:E7N5:VHP3:HEWA:7I2L:JLUR:JQV7:SDPV:GYHS:LFYI:QBIH:KRRVDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 15 Goroutines: 24 System Time: 2017-02-08T10:00:49.513415092+01:00 EventsListeners: 0Username: runcomRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**everywhere
"
30803,1,2089,300,0,0,mdlinville,0,"title:""docker wait my_container"" returns 0 if my_container is non-interactive and still running. description:**Description**""docker wait my_container"" returns 0 while my_container is still running**Steps to reproduce the issue:**1.  Start a non-interactive container in the background:        ```bash    $ docker run -d --name=my_container ubuntu bash    ```2.  In another terminal, run `docker wait my_container`.**Describe the results you received:**The `docker wait` command returns 0 immediately, even though `my_container` is still running.**Describe the results you expected:**I expected `docker wait` to block like it would with an interactive container. You get this result if you start `my_container` with `-dit` flags.**Output of `docker version`:**```noneClient: Version:      1.13.1-rc1 API version:  1.25 Go version:   go1.7.4 Git commit:   2527cfc Built:        Sat Jan 28 00:43:00 2017 OS/Arch:      darwin/amd64Server: Version:      1.13.1-rc1 API version:  1.25 (minimum version 1.12) Go version:   go1.7.4 Git commit:   2527cfc Built:        Sat Jan 28 00:43:00 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```noneContainers: 23 Running: 1 Paused: 0 Stopped: 22Images: 248Server Version: 1.13.1-rc1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: g35wgnc8gq8vj00coqm5tfy7r Is Manager: true ClusterID: tovqmbzkj5mi9rmmcvmug8ecw Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.65.2 Manager Addresses:  192.168.65.2:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090erunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3einit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.6-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.952 GiBName: mobyID: Q6NJ:KJI4:MYVU:E3QH:TQN2:HNRH:7DSM:ESVO:L6EE:TRI7:HQIQ:ZXWGDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 39 Goroutines: 141 System Time: 2017-02-07T23:37:23.12485272Z EventsListeners: 2No Proxy: *.local, 169.254/16Registry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```cc @thaJeztah 
"
30782,0,1451,265,0,0,piontec,0,"title:'docker ps' and 'docker run' commands never finish, other like 'info' are working. description:**Description**Dockerd became unresponsive at 06:04:21 GMT (see logs). Commands like ""docker ps"" and ""docker run"" are never completed within reasonable time (1 min). ""docker info"" is working. Containers are running and weren't restarted.**Steps to reproduce the issue:**Unfortunately, I don't know the way to reproduce the problem.**Additional information you deem important (e.g. issue happens only occasionally):**This happened after about 2 weeks of running successfully with similar load.**Output of `docker version`:**```# docker versionClient: Version:      1.12.6-cs7 API version:  1.24 Go version:   go1.6.4 Git commit:   681cddc Built:        Tue Jan 24 18:01:10 2017 OS/Arch:      linux/amd64Server: Version:      1.12.6-cs7 API version:  1.24 Go version:   go1.6.4 Git commit:   681cddc Built:        Tue Jan 24 18:01:10 2017 OS/Arch:      linux/amd64```**Output of `docker info`:**```# docker infoContainers: 472 Running: 355 Paused: 0 Stopped: 117Images: 12929Server Version: 1.12.6-cs7Storage Driver: aufs Root Dir: /opt/io1/docker/aufs Backing Filesystem: extfs Dirs: 12143 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: null host overlay bridgeSwarm: inactiveRuntimes: runcDefault Runtime: runcSecurity Options: apparmor seccompKernel Version: 4.4.0-59-genericOperating System: Ubuntu 16.04.1 LTSOSType: linuxArchitecture: x86_64CPUs: 128Total Memory: 1.876 TiBName: ip-10-69-11-89ID: UGZS:UFD3:GB4C:W5MX:JU2L:K7PH:6ZWS:4GPM:27Q5:UNNN:X3DC:YDT7Docker Root Dir: /opt/io1/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 5526 Goroutines: 4451 System Time: 2017-02-07T07:56:27.892730562Z EventsListeners: 2Registry: https://index.docker.io/v1/WARNING: No swap limit supportInsecure Registries: 127.0.0.0/8```**Additional environment details (AWS, VirtualBox, physical, etc.):**- running on AWS, x1.32xlarge instance- restarting the daemon takes very long time```# time systemctl restart dockerreal    25m39.047suser    0m0.028ssys     0m0.012s```- after the restart, dockerd was behaving the same- please see attached syslog from this period (with debug) and thread dump requested when the commands were unresponsive[2017-02-07-docker.log.txt](https://github.com/docker/docker/files/757208/2017-02-07-docker.log.txt)[2017-02-07-dockerd_threaddump.log.txt](https://github.com/docker/docker/files/757207/2017-02-07-dockerd_threaddump.log.txt)
"
30779,0,1458,0,0,0,Hyzhou,0,"title:docker login with a wrong path.. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**docker@default-online:~$ docker login index.docker.io/namespaceUsername: hyzhouPassword:Login SucceededI provided the registry for user. Some people say they are already login but can not pull the they private image. In the end, we find the user login with a domain and path.If docker can refuse the login, when login url like this.**Describe the results you received:**Login Succeeded**Describe the results you expected:**Login Faild**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```docker@default-online:~$ docker versionClient: Version:      1.12.3 API version:  1.24 Go version:   go1.6.3 Git commit:   6b644ec Built:        Wed Oct 26 23:26:11 2016 OS/Arch:      linux/amd64Server: Version:      1.12.3 API version:  1.24 Go version:   go1.6.3 Git commit:   6b644ec Built:        Wed Oct 26 23:26:11 2016 OS/Arch:      linux/amd64```**Output of `docker info`:**```docker@default-online:~$ docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 4Server Version: 1.12.3Storage Driver: aufs Root Dir: /mnt/sda1/var/lib/docker/aufs Backing Filesystem: extfs Dirs: 16 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host overlay nullSwarm: inactiveRuntimes: runcDefault Runtime: runcSecurity Options: seccompKernel Version: 4.4.27-boot2dockerOperating System: Boot2Docker 1.12.3 (TCL 7.2); HEAD : 7fc7575 - Thu Oct 27 17:23:17 UTC 2016OSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 995.8 MiBName: default-onlineID: LXGY:ZWCS:I6JU:QJGI:6VDP:VYDW:W75W:WUO7:YYO5:TO2D:ZDHF:B4IEDocker Root Dir: /mnt/sda1/var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 13 Goroutines: 23 System Time: 2017-02-07T08:29:55.299882751Z EventsListeners: 0Username: hyzhouRegistry: https://index.docker.io/v1/Labels: provider=virtualboxInsecure Registries: 127.0.0.0/8```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
30775,0,2389,294,0,0,sudo-bmitch,0,"title:docker run --rm reports error attempting to remove container in version 1.13 with 1.24 API. description:**docker run --rm reports an error when attempting to remove container in version 1.13 with 1.24 API**This appears to be a side effect of [PR #20848](https://github.com/docker/docker/pull/20848). When using a newer client and server, but reverting the API to something before 1.25, I'm seeing an error from a failed attempt to remove a container. This is generating nuisance errors with the classic swarm as seen in [issue #2620](https://github.com/docker/swarm/issues/2620).**Steps to reproduce the issue:**```$ # normal result$ docker run -it --rm busybox echo hellohello$ # error when using an older api version$ DOCKER_API_VERSION=1.24 docker run -it --rm busybox echo hellohelloERRO[0002] error removing container: Error response from daemon: removal of container dc8b9e47ddfdea3c8d5c6abfd5b6fd4d703a5aa43fd5a712be3dcc8d730a163c is already in progress```**Describe the results you received:**The container is removed by the docker daemon and then the docker client attempts to also remove the container, resulting in the error message.**Describe the results you expected:**When using an API before 1.25, the docker server should not perform the auto remove, it should instead be performed by the client. I'm not sure if this change needs to be made as part of the client request or the daemon processing of the request.**Additional information you deem important (e.g. issue happens only occasionally):**I've reproduced this issue in multiple environments**Output of `docker version`:**```Client: Version:      1.13.0 API version:  1.25 Go version:   go1.7.3 Git commit:   49bf474 Built:        Tue Jan 17 09:44:08 2017 OS/Arch:      linux/amd64Server: Version:      1.13.0 API version:  1.25 (minimum version 1.12) Go version:   go1.7.3 Git commit:   49bf474 Built:        Tue Jan 17 09:44:08 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 4 Running: 3 Paused: 0 Stopped: 1Images: 233Server Version: 1.13.0Storage Driver: aufs Root Dir: /home/var-docker/aufs Backing Filesystem: extfs Dirs: 578 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: w4dwja2i927qhe4tbuuirwhkg Is Manager: true ClusterID: am788rn0mc5vdqtqna79g237a Managers: 1 Nodes: 1 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 192.168.234.174 Manager Addresses:  192.168.234.174:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090erunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3einit version: 949e6faKernel Version: 3.16.0-4-amd64Operating System: Debian GNU/Linux 8 (jessie)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 5.75 GiBName: bmitch-asusr556lID: LTRH:V6W7:3UHO:4AV2:OSYM:6G4R:WKJR:2BRK:MGCO:Z4KJ:UPTF:LTRUDocker Root Dir: /home/var-dockerDebug Mode (client): falseDebug Mode (server): falseUsername: bmitch3020Registry: https://index.docker.io/v1/WARNING: No kernel memory limit supportWARNING: No cpu cfs quota supportWARNING: No cpu cfs period supportLabels: foo=bar env=laptopExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Seen on physical and virtual machines, Debian and RHEL.
"
30758,0,2503,34,0,0,jonathan-kosgei,0,"title:Migrating docker-compose from 2 to 3,  Error response from daemon: rpc error: code = 3 desc = driver name: if driver is specified name is required. description:**Description**`docker stack deploy` doesn't work as expected on 1.13**Steps to reproduce the issue:**1. Run `docker stack deploy` with the following compose file```version: '3'volumes:  poc:services:  redis:    image: 172.31.25.208:5000/redis    logging:        driver: journald    volumes:      - poc:/redis    networks: [uncontainer]networks:  uncontainer:    driver: overlay    ipam:      config:        - subnet: 100.64.0.0/16```**Describe the results you received:**Running the above compose file gives```root@ip-172-31-25-208:~/docker-setup# docker stack deploy --compose-file=docker-compose.yml uncontainerCreating network uncontainer_uncontainerError response from daemon: rpc error: code = 3 desc = driver name: if driver is specified name is required```**Describe the results you expected:**Successful deploy of my app containers on my swarm cluster**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      1.13.0 API version:  1.25 Go version:   go1.7.3 Git commit:   49bf474 Built:        Tue Jan 17 09:58:26 2017 OS/Arch:      linux/amd64Server: Version:      1.13.0 API version:  1.25 (minimum version 1.12) Go version:   go1.7.3 Git commit:   49bf474 Built:        Tue Jan 17 09:58:26 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 31 Running: 15 Paused: 0 Stopped: 16Images: 116Server Version: 1.13.0Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: falseLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: active NodeID: cbtslk7duprzq29i530f4i8y5 Is Manager: true ClusterID: 0i22jyym0uiwvzkf3ehud7kub Managers: 1 Nodes: 2 Orchestration:  Task History Retention Limit: 10 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 172.31.25.208 Manager Addresses:  172.31.25.208:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090erunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3einit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-36-genericOperating System: Ubuntu 16.04.1 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 3.858 GiBName: ip-172-31-25-208ID: 5TRV:4MMS:OASJ:YC7Q:Y6K4:CO5M:PKMS:MQR3:PH6A:Y2U3:PBSJ:2OGWDocker Root Dir: /dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 172.31.25.208:5000 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**AWS
"
30711,0,2265,263,0,0,samoht,0,"title:panic in swarmkit  on 1.13.0 (maybe related to invalid bind mounts?). description:@ingshtrom reported an issue on https://github.com/docker/for-mac/issues/1255 that seems to be related to invalid bind mounts and swarkit:```Feb  3 12:58:30 moby root: time=""2017-02-03T12:58:30.117022997Z"" level=error msg=""failed to start taskManager"" error=""invalid bind mount source, source path not found: /olympia"" module=""node/agent""Feb  3 12:58:30 moby root: panic: runtime error: invalid memory address or nil pointer dereferenceFeb  3 12:58:30 moby root: [signal SIGSEGV: segmentation violation code=0x1 addr=0x8 pc=0xfc0854]Feb  3 12:58:30 moby root: goroutine 39774 [running]:Feb  3 12:58:30 moby root: panic(0x176af20, 0xc4200120a0)Feb  3 12:58:30 moby root: ^I/usr/local/go/src/runtime/panic.go:500 +0x1a1Feb  3 12:58:30 moby root: github.com/docker/docker/vendor/github.com/docker/swarmkit/agent.(*taskManager).Logs(0x0, 0x250f8e0, 0xc422b3eff0, 0x0, 0x0, 0x0, 0x1, 0x0, 0x0, 0x24fc4e0, ...)Feb  3 12:58:30 moby root: ^I/go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/agent/task.go:68 +0xa4Feb  3 12:58:30 moby root: created by github.com/docker/docker/vendor/github.com/docker/swarmkit/agent.(*worker).SubscribeFeb  3 12:58:30 moby root: ^I/go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/agent/worker.go:511 +0x54cFeb  3 12:58:30 moby root: panic: runtime error: invalid memory address or nil pointer dereferenceFeb  3 12:58:30 moby root: [signal SIGSEGV: segmentation violation code=0x1 addr=0x8 pc=0xfc0854]Feb  3 12:58:30 moby root: goroutine 39773 [running]:Feb  3 12:58:30 moby root: panic(0x176af20, 0xc4200120a0)Feb  3 12:58:30 moby root: ^I/usr/local/go/src/runtime/panic.go:500 +0x1a1Feb  3 12:58:30 moby root: github.com/docker/docker/vendor/github.com/docker/swarmkit/agent.(*taskManager).Logs(0x0, 0x250f8e0, 0xc421884720, 0x0, 0x0, 0x0, 0x1, 0x0, 0x0, 0x24fc4e0, ...)Feb  3 12:58:30 moby root: ^I/go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/agent/task.go:68 +0xa4Feb  3 12:58:30 moby root: created by github.com/docker/docker/vendor/github.com/docker/swarmkit/agent.(*worker).SubscribeFeb  3 12:58:30 moby root: ^I/go/src/github.com/docker/docker/vendor/github.com/docker/swarmkit/agent/worker.go:511 +0x54c```See https://github.com/docker/for-mac/issues/1255 for more details.```Client: Version:      1.13.0 API version:  1.25 Go version:   go1.7.3 Git commit:   49bf474 Built:        Wed Jan 18 16:20:26 2017 OS/Arch:      linux/amd64```
"
30688,0,2354,300,0,0,hutchic,0,"title:changing network services is not supported. description:moving from https://github.com/docker/compose/issues/4417docker-compose.yml```version: '3'services:  nginx1:    image: nginx    networks:      - consul      - frontends  nginx2:    image: nginx    networks:      - frontends      - backendsnetworks:  consul:  frontends:  backends:```run it on docker swarm twice in a row``` docker stack deploy --compose-file nginxCreating network mashape_consulCreating network mashape_backendsCreating network mashape_frontendsCreating service mashape_nginx1Creating service mashape_nginx2``````docker stack deploy --compose-file docker-compose.yml nginxUpdating service mashape_nginx1 (id: no2qi4r84aufbh6m1hzgwb3ge)Error response from daemon: rpc error: code = 2 desc = changing network in service is not supported```It only seems to happen when two services have two networks and one of those networks is shared between themThe docker swarm was setup using docker for awsdocker info```Containers: 4 Running: 4 Paused: 0 Stopped: 0Images: 22Server Version: 1.13.0Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: awslogsCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: active NodeID: qo6z5tlg5h00u839gj1cpsdpt Is Manager: true ClusterID: mmngj1f0qiwkjdfqfclq7f2tn Managers: 3 Nodes: 8 Orchestration:  Task History Retention Limit: 5 Raft:  Snapshot Interval: 10000  Number of Old Snapshots to Retain: 0  Heartbeat Tick: 1  Election Tick: 3 Dispatcher:  Heartbeat Period: 5 seconds CA Configuration:  Expiry Duration: 3 months Node Address: 172.31.17.99 Manager Addresses:  172.31.10.251:2377  172.31.17.99:2377  172.31.44.228:2377Runtimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090erunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3einit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.4-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 8Total Memory: 31.38 GiBName: ip-172-31-17-99.ec2.internalID: ZKRK:6FCI:DFG2:5AVP:DRD6:FHGY:NXQN:OPXC:RUGV:HPWY:5FAP:RTULDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 193 Goroutines: 343 System Time: 2017-02-02T17:52:03.524284036Z EventsListeners: 0Username: hutchicRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```
"
30676,0,76,0,0,0,Alessar,0,"title:Unexpected behavior at .dockerignore file. description:#### DescriptionBehavior by documentation and behavior of docker is not the same.https://docs.docker.com/engine/reference/builder/#/dockerignore-fileDocumentation says that /foo/bar and foo/bar at ```.dockerignore``` file are the same.#### Expected behaviorExpected that ```/node_modules``` and ```node_modules``` will be the same too.#### Actual behaviorIn case ```node_modules``` in ```.dockerignore``` file, looks like, all stuff in that directory are ignored correctly.In case ```/node_modules``` docker try to push node_modules into container and sometimes get error:WindowsError: [Error 3] The system cannot find the path specified: 'E:\\Project\\node_modules\\very-very-long-path\\filename'And additionally, looks like, docker cannot work with long names - possible it is issue too.
"
30659,0,9426,6,0,0,JamesJJ,0,"title:[1.13.0-rc7] panic: close of nil channel. description:**Description**`Jan 31 00:25:41 ip-10-12-76-243 dockerd[5328]: panic: close of nil channel`**Describe the results you received:**```[root@ip-10-12-76-243 centos]# journalctl -u docker.service-- Logs begin at Mon 2017-01-23 11:01:58 UTC, end at Thu 2017-02-02 01:53:02 UTC. --Jan 23 11:03:12 ip-10-12-76-243 systemd[1]: Starting Docker Application Container Engine...Jan 23 11:03:19 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:03:19.069893728Z"" level=info msg=""libcontainerd: new containerd process, pid: 5372""Jan 23 11:03:20 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:03:20.114209259Z"" level=info msg=""devmapper: Creating filesystem xfs on device docker-202:1-17039471-base""Jan 23 11:03:20 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:03:20.439029859Z"" level=info msg=""devmapper: Successfully created filesystem xfs on device docker-202:1-17039471Jan 23 11:03:20 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:03:20.552139118Z"" level=info msg=""Graph migration to content-addressability took 0.00 seconds""Jan 23 11:03:20 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:03:20.552942042Z"" level=info msg=""Loading containers: start.""Jan 23 11:03:22 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:03:22.228113573Z"" level=info msg=""Firewalld running: false""Jan 23 11:03:22 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:03:22.631498507Z"" level=info msg=""Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon Jan 23 11:03:22 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:03:22.696410494Z"" level=info msg=""Loading containers: done.""Jan 23 11:03:23 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:03:23.123110886Z"" level=info msg=""Daemon has completed initialization""Jan 23 11:03:23 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:03:23.123142981Z"" level=info msg=""Docker daemon"" commit=48a9e53 graphdriver=devicemapper version=1.13.0-rc7Jan 23 11:03:23 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:03:23.135151802Z"" level=info msg=""API listen on /var/run/docker.sock""Jan 23 11:03:23 ip-10-12-76-243 systemd[1]: Started Docker Application Container Engine.Jan 23 11:05:57 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:05:57.013656966Z"" level=error msg=""Handler for GET /v1.22/networks/cmsservice_default returned error: network cmJan 23 11:06:02 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:06:02Z"" level=info msg=""Firewalld running: false""Jan 23 11:06:04 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:06:04Z"" level=info msg=""Firewalld running: false""Jan 23 11:06:06 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:06:06Z"" level=info msg=""Firewalld running: false""Jan 23 11:06:06 ip-10-12-76-243 dockerd[5328]: time=""2017-01-23T11:06:06Z"" level=info msg=""Firewalld running: false""Jan 31 00:25:24 ip-10-12-76-243 dockerd[5328]: time=""2017-01-31T00:23:29.137459513Z"" level=warning msg=""Connect failed: dial udp 10.12.0.2:53: i/o timeout""Jan 31 00:25:24 ip-10-12-76-243 dockerd[5328]: time=""2017-01-31T00:25:23.508012062Z"" level=warning msg=""Connect failed: dial udp 10.12.0.2:53: i/o timeout""Jan 31 00:25:25 ip-10-12-76-243 dockerd[5328]: time=""2017-01-31T00:25:25.516158085Z"" level=error msg=""containerd: deleting container"" error=""exit status 1: \""container 0b31c9d92dcJan 31 00:25:26 ip-10-12-76-243 dockerd[5328]: time=""2017-01-31T00:25:26.586898742Z"" level=warning msg=""Health check for container bcdbc8abd8fdbc7044580344b863d652280f187d466bd453Jan 31 00:25:27 ip-10-12-76-243 dockerd[5328]: time=""2017-01-31T00:25:27Z"" level=info msg=""Firewalld running: false""Jan 31 00:25:41 ip-10-12-76-243 dockerd[5328]: time=""2017-01-31T00:25:41.443917791Z"" level=error msg=""libcontainerd: failed to receive event from containerd: rpc error: code = 13 Jan 31 00:25:41 ip-10-12-76-243 dockerd[5328]: time=""2017-01-31T00:25:41.504208325Z"" level=info msg=""libcontainerd: new containerd process, pid: 13868""Jan 31 00:25:41 ip-10-12-76-243 dockerd[5328]: panic: close of nil channelJan 31 00:25:41 ip-10-12-76-243 dockerd[5328]: goroutine 30 [running]:Jan 31 00:25:41 ip-10-12-76-243 dockerd[5328]: panic(0x8078a0, 0xc4202325c0)Jan 31 00:25:41 ip-10-12-76-243 dockerd[5328]: /usr/local/go/src/runtime/panic.go:500 +0x1a1Jan 31 00:25:41 ip-10-12-76-243 dockerd[5328]: github.com/docker/containerd/supervisor.(*Supervisor).execExit.func1(0xc420115d60, 0xc42010b520, 0x0)Jan 31 00:25:41 ip-10-12-76-243 dockerd[5328]: /go/src/github.com/docker/containerd/supervisor/exit.go:90 +0x10cJan 31 00:25:41 ip-10-12-76-243 dockerd[5328]: created by github.com/docker/containerd/supervisor.(*Supervisor).execExitJan 31 00:25:41 ip-10-12-76-243 dockerd[5328]: /go/src/github.com/docker/containerd/supervisor/exit.go:91 +0xeeJan 31 00:25:42 ip-10-12-76-243 dockerd[5328]: time=""2017-01-31T00:25:42.076459174Z"" level=info msg=""libcontainerd: new containerd process, pid: 13874""Jan 31 00:25:47 ip-10-12-76-243 dockerd[5328]: time=""2017-01-31T00:25:47.962587644Z"" level=error msg=""Handler for GET /containers/json returned error: write unix /var/run/docker.sJan 31 00:25:47 ip-10-12-76-243 dockerd[5328]: http: multiple response.WriteHeader callsJan 31 00:26:03 ip-10-12-76-243 dockerd[5328]: http: multiple response.WriteHeader callsJan 31 00:26:03 ip-10-12-76-243 dockerd[5328]: time=""2017-01-31T00:26:03.867046212Z"" level=error msg=""Handler for GET /containers/json returned error: write unix /var/run/docker.sJan 31 00:26:07 ip-10-12-76-243 dockerd[5328]: time=""2017-01-31T00:26:07.139583343Z"" level=warning msg=""Health check for container bcdbc8abd8fdbc7044580344b863d652280f187d466bd453Feb 01 04:41:05 ip-10-12-76-243 dockerd[5328]: time=""2017-02-01T04:41:05.140882775Z"" level=warning msg=""containerd: unable to save bcdbc8abd8fdbc7044580344b863d652280f187d466bd453Feb 01 14:54:01 ip-10-12-76-243 dockerd[5328]: time=""2017-02-01T14:54:01.716693438Z"" level=warning msg=""Connect failed: dial udp 10.12.0.2:53: i/o timeout""Feb 01 14:54:01 ip-10-12-76-243 dockerd[5328]: time=""2017-02-01T14:54:01.904030673Z"" level=error msg=""libcontainerd: failed to receive event from containerd: rpc error: code = 13 Feb 01 14:54:01 ip-10-12-76-243 dockerd[5328]: time=""2017-02-01T14:54:01.924336279Z"" level=info msg=""libcontainerd: new containerd process, pid: 16638""Feb 01 14:54:02 ip-10-12-76-243 dockerd[5328]: time=""2017-02-01T14:54:02.083205444Z"" level=info msg=""libcontainerd: new containerd process, pid: 16639""Feb 01 15:47:50 ip-10-12-76-243 dockerd[5328]: time=""2017-02-01T15:47:48.523888373Z"" level=info msg=""libcontainerd: new containerd process, pid: 1784""Feb 01 15:47:51 ip-10-12-76-243 dockerd[5328]: panic: close of nil channelFeb 01 15:47:51 ip-10-12-76-243 dockerd[5328]: goroutine 33 [running]:Feb 01 15:47:51 ip-10-12-76-243 dockerd[5328]: panic(0x8078a0, 0xc42020b720)Feb 01 15:47:51 ip-10-12-76-243 dockerd[5328]: /usr/local/go/src/runtime/panic.go:500 +0x1a1Feb 01 15:47:51 ip-10-12-76-243 dockerd[5328]: github.com/docker/containerd/supervisor.(*Supervisor).execExit.func1(0xc4202a4320, 0xc4200f9790, 0x0)Feb 01 15:47:51 ip-10-12-76-243 dockerd[5328]: /go/src/github.com/docker/containerd/supervisor/exit.go:90 +0x10cFeb 01 15:47:51 ip-10-12-76-243 dockerd[5328]: created by github.com/docker/containerd/supervisor.(*Supervisor).execExitFeb 01 15:47:51 ip-10-12-76-243 dockerd[5328]: /go/src/github.com/docker/containerd/supervisor/exit.go:91 +0xeeFeb 01 15:47:51 ip-10-12-76-243 dockerd[5328]: time=""2017-02-01T15:47:51.509274026Z"" level=error msg=""libcontainerd: failed to receive event from containerd: rpc error: code = 13 ```**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      1.13.0-rc7 API version:  1.25 Go version:   go1.7.3 Git commit:   48a9e53 Built:        Fri Jan 13 06:50:32 2017 OS/Arch:      linux/amd64Server: Version:      1.13.0-rc7 API version:  1.25 (minimum version 1.12) Go version:   go1.7.3 Git commit:   48a9e53 Built:        Fri Jan 13 06:50:32 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 4 Running: 4 Paused: 0 Stopped: 0Images: 4Server Version: 1.13.0-rc7Storage Driver: devicemapper Pool Name: docker_lvm_vg-docker_lvm Pool Blocksize: 524.3 kB Base Device Size: 8.59 GB Backing Filesystem: xfs Data file:  Metadata file:  Data Space Used: 2.705 GB Data Space Total: 49.92 GB Data Space Available: 47.22 GB Metadata Space Used: 852 kB Metadata Space Total: 1.615 GB Metadata Space Available: 1.614 GB Thin Pool Minimum Free Space: 3.494 GB Udev Sync Supported: true Deferred Removal Enabled: true Deferred Deletion Enabled: true Deferred Deleted Device Count: 0 Library Version: 1.02.135-RHEL7 (2016-09-28)Logging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: N/A (expected: 03e5862ec0d8d3b3f750e19fca3ee367e13c090e)runc version: 2f7393a47307a16f8cee44a37b262e8b81021e3einit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 3.10.0-514.2.2.el7.x86_64Operating System: CentOS Linux 7 (Core)OSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 1.795 GiBName: ip-10-12-76-243ID: SGKM:ARMQ:A4MR:HMLP:CSP7:QOKC:Q52E:6CJO:7DJQ:URHR:S6DC:2D6RDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):*** Centos 7, fully updated* AWS / EBS Disk* Docker from `https://yum.dockerproject.org/repo/testing/centos/7`
"
30641,1,0,263,0,0,samoht,0,"title:panic in 1.12.5. description:Reported by @cloutiertyler on Docker for Mac: https://github.com/docker/for-mac/issues/205#issuecomment-276240698I made a gist which isolate the panic stack trace: https://gist.github.com/samoht/ad87fb019d6e29580145c31bd4ec6488Please let me know if you need more information (or if you want this kind of issues to be formatted differently / reported in a different place). It happened using the stable channel of Docker for Mac on the 10th of January and was using 1.12.5
"
30609,0,1944,0,0,0,djones-skytap,0,"title:Docker CLI/API allows containers to be set to an invalid name. description:**Description**Docker CLI/API is allows containers to be set to an invalid name**Steps to reproduce the issue:**1. docker create --name invalidname- {any image}2. docker start invalidname-also1. docker run -itd --name validname {any image}2. docker rename validname invalidname2-3. docker stop invalidname2-4. docker start invalidname2-**Describe the results you received:**```Error response from daemon: invalid name: ""invalidname-"" includes invalid characters, resource name has to conform to ""^[\\w]+[\\w-. ]*[\\w]+$""Error: failed to start containers: invalidname-``````Error response from daemon: invalid name: ""invalidname2-"" includes invalid characters, resource name has to conform to ""^[\\w]+[\\w-. ]*[\\w]+$""Error: failed to start containers: invalidname2-```**Describe the results you expected:**creating and renaming a container should not allow invalid names. CLI states valid names are: [a-zA-Z0-9][a-zA-Z0-9_.-]Names do not appear to be allowed to end with period or dash, but these conditions are not caught.**Output of `docker version`:**```Client: Version:      1.13.1-rc1 API version:  1.25 Go version:   go1.7.4 Git commit:   2527cfc Built:        Sat Jan 28 00:43:00 2017 OS/Arch:      darwin/amd64Server: Version:      1.13.1-rc1 API version:  1.25 (minimum version 1.12) Go version:   go1.7.4 Git commit:   2527cfc Built:        Sat Jan 28 00:43:00 2017 OS/Arch:      linux/amd64 Experimental: true```**Output of `docker info`:**```Containers: 7 Running: 2 Paused: 0 Stopped: 5Images: 1Server Version: 1.13.1-rc1Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host ipvlan macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090erunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3einit version: 949e6faSecurity Options: seccomp  Profile: defaultKernel Version: 4.9.6-mobyOperating System: Alpine Linux v3.5OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952 GiBName: mobyID: K2GS:Q25F:CY3U:4MY3:O2D4:SF26:3UDA:EMSM:5QIC:FFB5:OH6G:SVDXDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 29 Goroutines: 36 System Time: 2017-01-31T22:32:08.992451828Z EventsListeners: 1Username: djonesRegistry: https://index.docker.io/v1/Experimental: trueInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Docker for Mac; Also able to repro on Ubuntu 16.04.
"
30593,1,1241,16,0,0,delcypher,0,"title:Docker container exit code has unexpected value when program aborts. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**When running a simple C program inside a container that calls the C standard library `abort()` function I expected the reported exit code of the container to be 134 (following bash's convention of making the exit code be `128` + 6 (SIGABRT) see http://tldp.org/LDP/abs/html/exitcodes.html ). Instead Docker reports that the container exits with exit code 139 (If bash's convention was being followed that exit code would imply SIGSEGV).I'm not sure if this is a bug or not because I don't know what Docker's convention is for handling the exit codes of processes that terminated due to a signal being sent.To be honest rather than relying on the exit code it would be more useful to me if the status of a docker container reported if the main process was killed and if so which signal killed it.<!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. Compile a simple C program to call abort```c#include <stdlib.h>int main() {  abort();}``````gcc -static abort.c -o abort```2. Run the binary inside a container```docker run --name=""foobar"" -ti -v `pwd`/abort:/tmp/abort ubuntu:14.04 /tmp/abort```3. Inspect the exit code```docker inspect -f '{{.State.ExitCode }}' foobar139```**Describe the results you received:**Reported exit code is `139`**Describe the results you expected:**I expected the exit code to be `134`.**Additional information you deem important (e.g. issue happens only occasionally):**If I run this the program like I get the exit code I expect```$ docker run --name=""foobar"" -ti -v `pwd`/abort:/tmp/abort ubuntu:14.04 /bin/bash -c '/tmp/abort; exit $?'/bin/bash: line 1:     6 Aborted                 (core dumped) /tmp/abort$ docker inspect -f '{{.State.ExitCode }}' foobar 134```**Output of `docker version`:**```docker --versionDocker version 1.12.6, build 78d18021ec```**Output of `docker info`:**```$ docker infoContainers: 2 Running: 0 Paused: 0 Stopped: 2Images: 102Server Version: 1.12.6Storage Driver: overlay Backing Filesystem: extfsLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: overlay host null bridgeSwarm: inactiveRuntimes: runcDefault Runtime: runcSecurity Options: seccompKernel Version: 4.8.13-1-ARCHOperating System: Arch LinuxOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.708 GiBName: dan-sputnikID: <redacted>Docker Root Dir: /home/dan/dockerDebug Mode (client): falseDebug Mode (server): falseUsername: delcypherRegistry: https://index.docker.io/v1/Insecure Registries: 127.0.0.0/8```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
30587,1,1204,8,0,0,efaruk,0,"title:Set-TimeZone Changing Host Machine TimeZone too. description:---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------**Description**When we use Set-TimeZone in windowscore based container its changing host machine timezone too.**Steps to reproduce the issue:**1. Create Dockerfile as following:```FROM microsoft/dotnet-framework:3.5COPY assets/ assets/ENTRYPOINT [ ""powershell"" ]```2. Build and run container with -it switch3. Run `Set-TimeZone -Id ""Pacific Standard Time""` (Different timezone from host machine)4. Check Container's and Host Machine time zones with `Get-TimeZone` powershell command**Describe the results you received:**Set-TimeZone affecting both container and host machine**Describe the results you expected:**Use Set-TimeZone to set only container timezone**Output of `docker version`:**```Client: Version:      1.12.2-cs2-ws-beta API version:  1.25 Go version:   go1.7.1 Git commit:   050b611 Built:        Tue Oct 11 02:35:40 2016 OS/Arch:      windows/amd64Server: Version:      1.12.2-cs2-ws-beta API version:  1.25 Go version:   go1.7.1 Git commit:   050b611 Built:        Tue Oct 11 02:35:40 2016 OS/Arch:      windows/amd64```**Output of `docker info`:**```Containers: 2 Running: 0 Paused: 0 Stopped: 2Images: 12Server Version: 1.12.2-cs2-ws-betaStorage Driver: windowsfilter Windows:Logging Driver: json-filePlugins: Volume: local Network: nat null overlaySwarm: inactiveDefault Isolation: processKernel Version: 10.0 14393 (14393.693.amd64fre.rs1_release.161220-1747)Operating System: Windows Server 2016 DatacenterOSType: windowsArchitecture: x86_64CPUs: 4Total Memory: 6 GiBName: winconID: TRSR:EBZG:57NQ:VGAH:NTIE:WA4T:ZLAK:7JCX:2LMU:HFHF:UVLV:AZRCDocker Root Dir: C:\ProgramData\dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Insecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details:**I'm running windows docker host machine inside of an Oracle VirtualBoxThanks, regards...
"
30586,0,1844,12,0,0,weirdgiraffe,0,"title:docker 1.13.0 creates empty docker folder in filesystem root. description:<!--If you are reporting a new issue, make sure that we do not have any duplicatesalready open. You can ensure this by searching the issue list for thisrepository. If there is a duplicate, please close your issue and add a commentto the existing issue instead.If you suspect your issue is a bug, please edit your issue description toinclude the BUG REPORT INFORMATION shown below. If you fail to provide thisinformation within 7 days, we cannot debug your issue and will close it. Wewill, however, reopen it if you later provide the information.For more information about reporting issues, seehttps://github.com/docker/docker/blob/master/CONTRIBUTING.md#reporting-other-issues---------------------------------------------------GENERAL SUPPORT INFORMATION---------------------------------------------------The GitHub issue tracker is for bug reports and feature requests.General support can be found at the following locations:- Docker Support Forums - https://forums.docker.com- IRC - irc.freenode.net #docker channel- Post a question on StackOverflow, using the Docker tag---------------------------------------------------BUG REPORT INFORMATION---------------------------------------------------Use the commands below to provide key information from your environment:You do NOT have to include this information if this is a FEATURE REQUEST-->**Description**Empty `/docker` folder will be created when docker starts a container. On readonly root filesystem it produces an error:```docker: Error response from daemon: linux init cgroups path: mkdir /docker: read-only file system```This behaviour was introduced in commit [7ed3d265a](https://github.com/docker/docker/commit/7ed3d265a4499ec03f10537fea0aac3ebaa0cec6#diff-ea22bb26655e758dc94c291dbaee0e76) and this side effect is not described in changelog, so it looks like some kind of buggy behaviour. <!--Briefly describe the problem you are having in a few paragraphs.-->**Steps to reproduce the issue:**1. under ubuntu 16.04 or debian jessie upgrade docker from 1.12.6 to 1.13.02. start any container, for example `docker run --rm alpine /bin/true`**Steps to reproduce the issue if `/docker` folder already exists:**1. remove `/docker` folder2. start any container, for example `docker run --rm alpine /bin/true`**Describe the results you received:**Empty `/docker` folder will be created**Describe the results you expected:**No additional folders should creaded in fylesystem root.**Additional information you deem important (e.g. issue happens only occasionally):****Output of `docker version`:**```Client: Version:      1.13.0 API version:  1.25 Go version:   go1.7.3 Git commit:   49bf474 Built:        Tue Jan 17 09:44:08 2017 OS/Arch:      linux/amd64Server: Version:      1.13.0 API version:  1.25 (minimum version 1.12) Go version:   go1.7.3 Git commit:   49bf474 Built:        Tue Jan 17 09:44:08 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 0 Running: 0 Paused: 0 Stopped: 0Images: 84Server Version: 1.13.0Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 62 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090erunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3einit version: 949e6faKernel Version: 3.16.0-4-amd64Operating System: Debian GNU/Linux 9 (stretch)OSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 993.7 MiBName: playgroundID: QEFF:ZELR:MFUQ:Q4M3:SYYS:CY6V:L6TJ:RHGQ:2NWF:ZJ4U:5JXS:INWXDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 15 Goroutines: 22 System Time: 2017-01-31T12:07:05.871298086+01:00 EventsListeners: 0Registry: https://index.docker.io/v1/WARNING: No memory limit supportWARNING: No swap limit supportWARNING: No kernel memory limit supportWARNING: No oom kill disable supportWARNING: No cpu cfs quota supportWARNING: No cpu cfs period supportExperimental: falseInsecure Registries: localregistry:5000 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**
"
30580,0,1647,14,0,0,resilva87,0,"title:docker top breaks when showing thread information after processes. description:**Description**Attempting to show threads after process in `top` command (`m` flag) returns `Error response from daemon: Unexpected pid '-': strconv.ParseInt: parsing ""-"": invalid syntax` **Steps to reproduce the issue:**1. Pull any image2. Run a new container3. Run `docker top <container-id> m`**Describe the results you received:**`Error response from daemon: Unexpected pid '-': strconv.ParseInt: parsing ""-"": invalid syntax` **Describe the results you expected:**ps information such as:```PID TTY      STAT   TIME COMMAND  173 ?        -      0:00 /bin/bash    - -        Ss     0:00 -  190 ?        -      0:00 ps m    - -        R+     0:00 -```**Additional information you deem important (e.g. issue happens only occasionally):**Combining `m` flag with any other causes the problem (such as `ps muax`)This error seems related to ps output parsing function implemented in https://github.com/docker/docker/blob/master/daemon/top_unix.go**Output of `docker version`:**```Client: Version:      1.13.0 API version:  1.25 Go version:   go1.7.3 Git commit:   49bf474 Built:        Tue Jan 17 09:58:26 2017 OS/Arch:      linux/amd64Server: Version:      1.13.0 API version:  1.25 (minimum version 1.12) Go version:   go1.7.3 Git commit:   49bf474 Built:        Tue Jan 17 09:58:26 2017 OS/Arch:      linux/amd64 Experimental: false```**Output of `docker info`:**```Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 4Server Version: 1.13.0Storage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 23 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins:  Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 03e5862ec0d8d3b3f750e19fca3ee367e13c090erunc version: 2f7393a47307a16f8cee44a37b262e8b81021e3einit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-59-genericOperating System: Ubuntu 16.04.1 LTSOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 7.659 GiBName: rsilva-noteID: G3OH:BUGW:Z6RR:6BVO:YSAV:QYEE:6VVL:FJQ4:Q7LW:OXIJ:LUHT:Q2VJDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No swap limit supportExperimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: false```**Additional environment details (AWS, VirtualBox, physical, etc.):**Ubuntu 16.10
"
30575,0,1899,185,0,0,lmakarov,0,"title:Unable to use docker ps --filter when a label value has a comma. description:**Description**An attempt to filter containers by label when the label value has a comma fails with```bad format of filter (expected name=value)```**Steps to reproduce the issue:**1. Create a container    ```    $ docker create --name test-label --label 'mylabel=value1,value2' busybox    ```2. Confirm the label was properly set    ```    $ docker inspect test-label | grep -a3 Labels            ""WorkingDir"": """",            ""Entrypoint"": null,            ""OnBuild"": null,            ""Labels"": {                ""mylabel"": ""value1,value2""            }        },    ```3. Try running docker ps and filter on the label    ```       $ docker ps -a --filter ""label=mylabel=value1,value2""    bad format of filter (expected name=value)    ```**Describe the results you received:**Getting an error from `docker ps````bad format of filter (expected name=value)```**Describe the results you expected:**See the respective container in the output list.**Additional information you deem important (e.g. issue happens only occasionally):**None**Output of `docker version`:**```Client: Version:      1.12.6 API version:  1.24 Go version:   go1.6.4 Git commit:   78d1802 Built:        Wed Jan 11 00:23:16 2017 OS/Arch:      darwin/amd64Server: Version:      1.12.6 API version:  1.24 Go version:   go1.6.4 Git commit:   78d1802 Built:        Wed Jan 11 00:23:16 2017 OS/Arch:      linux/amd64```**Output of `docker info`:**```Containers: 22 Running: 8 Paused: 0 Stopped: 14Images: 15Server Version: 1.12.6Storage Driver: aufs Root Dir: /mnt/sda1/var/lib/docker/aufs Backing Filesystem: extfs Dirs: 237 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge null host overlaySwarm: inactiveRuntimes: runcDefault Runtime: runcSecurity Options: seccompKernel Version: 4.4.41-boot2dockerOperating System: Boot2Docker 1.12.6 (TCL 7.2); HEAD : 5ab2289 - Wed Jan 11 03:20:40 UTC 2017OSType: linuxArchitecture: x86_64CPUs: 1Total Memory: 995.8 MiBName: docksalID: Y5RI:OJMO:CITK:FQFZ:OAFZ:5T2D:UGNS:Y6XI:6H4H:2EFX:ZJQN:XNWVDocker Root Dir: /mnt/sda1/var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 75 Goroutines: 73 System Time: 2017-01-30T22:45:39.580227457Z EventsListeners: 2Registry: https://index.docker.io/v1/Labels: provider=virtualboxInsecure Registries: 127.0.0.0/8```**Additional environment details (AWS, VirtualBox, physical, etc.):**Tested with boot2docker in VirtualBox as well as with Ubuntu 16.04.
"
