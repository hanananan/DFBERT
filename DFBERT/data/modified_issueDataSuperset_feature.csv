num,label,code_len,con_num,keyword_num,keyword_fix,username,permission,ds
23234,0,1478,20,0,0,santoshmallah,0,"title:DRILL_TO_DETAIL Feature is not working. description:I am using ```superset 2.0.1``` and want to use DRILL_TO_DETAIL feature  My superset_config.py file look like```JSONFEATURE_FLAGS = {    'CLIENT_CACHE': False,    'ENABLE_EXPLORE_JSON_CSRF_PROTECTION': False,    'PRESTO_EXPAND_DATA': True,    'ENABLE_TEMPLATE_PROCESSING': True,    'ALERTS_ATTACH_REPORTS':True,    'ALLOW_ADHOC_SUBQUERY':True,    'DASHBOARD_CROSS_FILTERS':True,    'DASHBOARD_RBAC':True,    'DISABLE_LEGACY_DATASOURCE_EDITOR':True,    'DRUID_JOINS':True,    ""ALERT_REPORTS"": True,    'EMBEDDABLE_CHARTS':True,    'EMBEDDED_SUPERSET':True,    'ENABLE_DND_WITH_CLICK_UX':True,    'ENABLE_EXPLORE_DRAG_AND_DROP':True,    'ENFORCE_DB_ENCRYPTION_UI':True,    'ESCAPE_MARKDOWN_HTML':True,    'LISTVIEWS_DEFAULT_CARD_VIEW':True,    'SCHEDULED_QUERIES':True,    'SQLLAB_BACKEND_PERSISTENCE':True,    'SQL_VALIDATORS_BY_ENGINE':True,    'THUMBNAILS':True,    'ROW_LEVEL_SECURITY': True,    'ALLOW_FULL_CSV_EXPORT': True,    'THUMBNAILS_SQLA_LISTENERS': True,    'DASHBOARD_FILTERS_EXPERIMENTAL': True,    'DASHBOARD_NATIVE_FILTERS': True,    'HORIZONTAL_FILTER_BAR': True,    'ENABLE_DRUID_DASHBOARDING':True,#    'ENABLE_FILTER_BOX_MIGRATION':True,    'ENABLE_EXPLORE_DRAG_AND_DROP':True,    'DYNAMIC_PLUGINS':True,    'DASHBOARD_NATIVE_FILTERS_SET':True,    'DASHBOARD_EDIT_CHART_IN_NEW_TAB':True,    'CROSS_REFERENCES':True,    **'DRILL_TO_DETAIL':True,**    'FEATURE_DRILL_TO_DETAIL':True,    'UX_BETA':True,    'VERSIONED_EXPORT':True}```I have added ```'DRILL_TO_DETAIL':True``` in my configuration file, but the Drill to Detail option is still unavailable in apache superset.![image](https://user-images.githubusercontent.com/51262721/221852007-c8966a30-0d0a-478b-9e0a-cb987ca8b548.png)- browser type and version: Chrome- superset version: `2.0.1`- python version: `3.8.0`- node.js version: `v16.14.2`- any feature flags active:   ```'DRILL_TO_DETAIL':True```I have check preset chart drill to detail option is available in that.![image](https://user-images.githubusercontent.com/51262721/221852280-93675f83-ee58-4f70-9eba-4964367f3a76.png)How can I enable this feature in apache superset.Thanks in advance.
"
23220,0,0,246,0,0,sfirke,0,"title:""Enable cross-filtering"" checkbox icon + command offered to unauthorized users. description:In Superset 2.1.0rc1.  On a public-facing dashboard, the public user can see this:![image](https://user-images.githubusercontent.com/7569808/221663558-f37bb92f-9ea6-4ce2-8d7a-443ecfcc91ca.png)When they uncheck the box, they see the flash of a modal popup message: ""Sorry there was an error saving this dashboard: UNAUTHORIZED"" before being bounced to the login screen.### Expected resultsThe user should not be offered this gear icon and the associated checkbox if they don't have privileges to manipulate it.### Actual resultsIt's visible to the user.
"
23206,0,0,17,0,0,vivekDebugs,0,"title:Documentation typo. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to https://superset.apache.org/docs/creating-charts-dashboards/creating-your-first-dashboard#creating-charts-in-explore-view2. Scroll down a bit to see the following typo -> _'just **be** clicking'_### Expected resultsIt should be _'just **by** clicking'_.### Actual resultsIt is _'just **be** clicking'_.#### Screenshots![image](https://user-images.githubusercontent.com/49686162/221491513-4137eee7-b2af-4423-a2f3-4ee7471a15c1.png)### Environment- browser type and version: Brave - Version 1.48.171  Chromium: 110.0.5481.177 (Official Build)  (64-bit)- superset version: -- python version: -- node.js version: -- any feature flags active: -### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context
"
23149,0,0,189,0,1,tooptoop4,0,"title:CVE-2023-23931 and CVE-2023-0286. description:https://github.com/apache/superset/blob/master/requirements/base.txt#L63 shows cryptography 39.0.0  Fixed Version is 39.0.1
"
23094,1,0,194,0,0,rohitpawar2811,0,"title:Unwanted User-Information leak in Filter-Bar (Owner/Created-User). description:Hi I have problem related to Filter-Box.I have an user whom I have allowed roles and some data-source permission , And In Current nature of superset in Filter-Box in field (Owner/Created-User) all users information is exposed![Screenshot from 2023-02-16 15-56-59](https://user-images.githubusercontent.com/72196393/219343370-3a9a5b09-5beb-439b-9e0b-482515b157cf.png)**Expected :** User can see only those user name whose Dastasources allowed to that user**Dependency :** - used superset-2.0.0-dev image**Questions**- Is this Resolved Already ? because I have seen that it is reported in some previous issue , but not solved by anyone- What is the things recommended to solve this problemThankyou in advance@rusackas @eschutho 
"
23090,1,0,21,0,0,88fingerslukee,0,"title:How to make LDAP packages install at build time. description:I'm trying to make python-ldap install at build time for the docker container. I can't figure out where to put the `apt-get `and `pip ` commands in the Dockerfile to get it to work.Can somebody please help? 
"
23070,1,0,3,1,0,anavasp,0,"title:Map chart color scheme in Edit screen does not match color scheme in regular views. description:I'm trying to build a dashboard with 4 map charts: 2 world maps and 2 country maps (more specifically, 2 Spain charts). The 2 world map charts are displayed as expected, but the other 2 country map charts are displayed with a seemingly random color scheme.When accessing the country map charts from the Charts menu, the charts are displayed properly and all settings can be changed as expected, including color scheme. However, one we go into the dashboard, the charts go ""rogue"" and if I try to edit them from the dashboard (by clicking on the 3 dots on the chart and clicking on ""Edit chart""), the Edit screen won't let me change the color scheme (I can't edit the color scheme of the world map charts like this either, but they're already working as expected).I've seen a similar bug (I think) to this one in [https://github.com/apache/superset/issues/20376](https://github.com/apache/superset/issues/20376) but I have not seen any hints as to how to solve my issue.#### How to reproduce the bug1. Create a Country map chart (only Spain has been tested) and choose a color scheme.2. Add the chart to a dashboard3. View country map chart on the dashboard.### Expected resultsThe country map chart should be displayed with the expected color scheme.### Actual resultsThe country map chart is displayed with a random color scheme.#### ScreenshotsDashboard screenshot. The 2 world map charts are displayed as expected but the country maps are not.![MicrosoftTeams-image (7)](https://user-images.githubusercontent.com/107985293/218510462-dee40865-22d3-475d-9aa0-d4b429ea914f.png)Editing the country map chart from the Charts menu. Note the ""Lineas Color Scheme"" setting, which is available for editing. The preview displays the chart as expected.![MicrosoftTeams-image (9)](https://user-images.githubusercontent.com/107985293/218511150-2dfab428-cb40-4c08-9d4f-2b138f51a823.png)The same chart, but the edit screen has been invoked from the chart menu in the dashboard. The last setting is greyed out.![MicrosoftTeams-image (10)](https://user-images.githubusercontent.com/107985293/218511306-6da8bd95-ff96-49e0-b6c7-c4f09b691df3.png)For comparison, here's one of the world map charts edit screen, once again accessed from the chart menu in the dashboard. The color scheme option is also greyed out, but this does not seem to affect the chart in the dashboard.![MicrosoftTeams-image (11)](https://user-images.githubusercontent.com/107985293/218511890-fc4a3989-a402-4551-80bd-37a5e131eb86.png)### Environment(please complete the following information):- browser type and version: tested on latest releases of Chrome and Edge on Windows 10 and MacOS.- superset version: `Superset 0.0.0-dev` (docker-compose, apache/superset:latest-dev)- python version: `3.8.13`- node.js version: - any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.
"
23058,1,0,65,0,0,mato1411,0,"title:Charts not exists error but access permissions are given. description:Users see ""Error: The chart does not exist"" error in Dashboard but access permissions to datasource are given.#### How to reproduce the bugWe have our own Superset 2.0.1 instance running on EKS. A database connection to an Aurora instance is given. Based on the dataset `aurora.dataset1` 10 charts have been created and added to a Dashboard. A dedicated role has been created that grants users the permission `datasource access on [aurora].[dataset1](id:xx)`.A user opens the Dashboard.### Expected resultsNo error is shown. The charts are displayed.### Actual resultsOnly 8/10 charts are shown properly. 2 charts show the following error: ""Error: The chart does not exist""#### Screenshots![error-superset](https://user-images.githubusercontent.com/86957357/218071756-b1d91f26-a6d2-457d-beba-a1cab6874215.png)### Environment- Installation on EKS using Helm chart 0.8.4- browser type and version: Across all browsers- superset version: 2.0.1- any feature flags active: No### Checklist- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context* The logs of all Superset pods not show any error.* In case a users with Admin role access the Dashboard, all charts are shown as expected.* In case a Admin users opens the chart and clicks on ""UPDATE CHART"", the chart is visible to the affected users for a couple of minutes. Afterwards, the error occurs again. Creating a copy of the affected chart not solves the problem.
"
23053,1,479,3,1,0,error691,0,"title:superset db upgrade failing on migration from 1.4.2 to 2.0.1. description:Hi,I'm trying to  upgrade superset from 1.4.2. After `superset db upgrade` I faced with migration error.```sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column ""user_id"" violates not-null constraintDETAIL:  Failing row contains (4405, null).[SQL: INSERT INTO sl_dataset_users (dataset_id, user_id) SELECT sl_datasets.id AS dataset_id, sqlatable_user.user_idFROM sqlatable_user JOIN tables ON tables.id = sqlatable_user.table_id JOIN sl_datasets ON sl_datasets.uuid = tables.uuid](Background on this error at: http://sqlalche.me/e/13/gkpj)```#### How to reproduce the bugUpgrade from 1.4.2 to 2.0.1`superset db upgrade`### Expected resultsSuccessful migration. ### Actual results`INFO  [alembic.runtime.migration] Running upgrade cecc6bf46990 -> ad07e4fdbaba, rm_time_range_endpoints_from_qc_3slices updated with no time_range_endpoints: 4264INFO  [alembic.runtime.migration] Running upgrade ad07e4fdbaba -> a9422eeaae74, new_dataset_models_take_2>> Copy 220 physical tables to sl_tables...>> Copy 4,621 SqlaTable to sl_datasets...   Copy dataset owners...Traceback (most recent call last):  File ""/ss_venv/lib64/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context    self.dialect.do_execute(  File ""/ss_venv/lib64/python3.8/site-packages/sqlalchemy/engine/default.py"", line 608, in do_execute    cursor.execute(statement, parameters)psycopg2.errors.NotNullViolation: null value in column ""user_id"" violates not-null constraintDETAIL:  Failing row contains (4405, null).The above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/ss_venv/bin/superset"", line 8, in <module>    sys.exit(superset())  File ""/ss_venv/lib64/python3.8/site-packages/click/core.py"", line 1130, in __call__    return self.main(*args, **kwargs)  File ""/ss_venv/lib64/python3.8/site-packages/flask/cli.py"", line 567, in main    return super().main(*args, **kwargs)  File ""/ss_venv/lib64/python3.8/site-packages/click/core.py"", line 1055, in main    rv = self.invoke(ctx)  File ""/ss_venv/lib64/python3.8/site-packages/click/core.py"", line 1657, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/ss_venv/lib64/python3.8/site-packages/click/core.py"", line 1657, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/ss_venv/lib64/python3.8/site-packages/click/core.py"", line 1404, in invoke    return ctx.invoke(self.callback, **ctx.params)  File ""/ss_venv/lib64/python3.8/site-packages/click/core.py"", line 760, in invoke    return __callback(*args, **kwargs)  File ""/ss_venv/lib64/python3.8/site-packages/click/decorators.py"", line 26, in new_func    return f(get_current_context(), *args, **kwargs)  File ""/ss_venv/lib64/python3.8/site-packages/flask/cli.py"", line 407, in decorator    return __ctx.invoke(f, *args, **kwargs)  File ""/ss_venv/lib64/python3.8/site-packages/click/core.py"", line 760, in invoke    return __callback(*args, **kwargs)  File ""/ss_venv/lib64/python3.8/site-packages/flask_migrate/cli.py"", line 150, in upgrade    _upgrade(directory, revision, sql, tag, x_arg)  File ""/ss_venv/lib64/python3.8/site-packages/flask_migrate/__init__.py"", line 111, in wrapped    f(*args, **kwargs)  File ""/ss_venv/lib64/python3.8/site-packages/flask_migrate/__init__.py"", line 200, in upgrade    command.upgrade(config, revision, sql=sql, tag=tag)  File ""/ss_venv/lib64/python3.8/site-packages/alembic/command.py"", line 378, in upgrade    script.run_env()  File ""/ss_venv/lib64/python3.8/site-packages/alembic/script/base.py"", line 569, in run_env    util.load_python_file(self.dir, ""env.py"")  File ""/ss_venv/lib64/python3.8/site-packages/alembic/util/pyfiles.py"", line 94, in load_python_file    module = load_module_py(module_id, path)  File ""/ss_venv/lib64/python3.8/site-packages/alembic/util/pyfiles.py"", line 110, in load_module_py    spec.loader.exec_module(module)  # type: ignore  File ""<frozen importlib._bootstrap_external>"", line 783, in exec_module  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed  File ""/ss_venv/lib64/python3.8/site-packages/superset/extensions/../migrations/env.py"", line 126, in <module>    run_migrations_online()  File ""/ss_venv/lib64/python3.8/site-packages/superset/extensions/../migrations/env.py"", line 118, in run_migrations_online    context.run_migrations()  File ""<string>"", line 8, in run_migrations  File ""/ss_venv/lib64/python3.8/site-packages/alembic/runtime/environment.py"", line 867, in run_migrations    self.get_context().run_migrations(**kw)  File ""/ss_venv/lib64/python3.8/site-packages/alembic/runtime/migration.py"", line 624, in run_migrations    step.migration_fn(**kw)  File ""/ss_venv/lib64/python3.8/site-packages/superset/migrations/versions/2022-04-01_14-38_a9422eeaae74_new_dataset_models_take_2.py"", line 876, in upgrade    copy_datasets(session)  File ""/ss_venv/lib64/python3.8/site-packages/superset/migrations/versions/2022-04-01_14-38_a9422eeaae74_new_dataset_models_take_2.py"", line 379, in copy_datasets    insert_from_select(  File ""/ss_venv/lib64/python3.8/site-packages/superset/migrations/versions/2022-04-01_14-38_a9422eeaae74_new_dataset_models_take_2.py"", line 102, in insert_from_select    return op.execute(query)  File ""<string>"", line 8, in execute  File ""<string>"", line 3, in execute  File ""/ss_venv/lib64/python3.8/site-packages/alembic/operations/ops.py"", line 2416, in execute    return operations.invoke(op)  File ""/ss_venv/lib64/python3.8/site-packages/alembic/operations/base.py"", line 401, in invoke    return fn(self, operation)  File ""/ss_venv/lib64/python3.8/site-packages/alembic/operations/toimpl.py"", line 207, in execute_sql    operations.migration_context.impl.execute(  File ""/ss_venv/lib64/python3.8/site-packages/alembic/ddl/impl.py"", line 202, in execute    self._exec(sql, execution_options)  File ""/ss_venv/lib64/python3.8/site-packages/alembic/ddl/impl.py"", line 193, in _exec    return conn.execute(  # type: ignore[call-overload]  File ""/ss_venv/lib64/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1011, in execute    return meth(self, multiparams, params)  File ""/ss_venv/lib64/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 298, in _execute_on_connection    return connection._execute_clauseelement(self, multiparams, params)  File ""/ss_venv/lib64/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1124, in _execute_clauseelement    ret = self._execute_context(  File ""/ss_venv/lib64/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1316, in _execute_context    self._handle_dbapi_exception(  File ""/ss_venv/lib64/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1510, in _handle_dbapi_exception    util.raise_(  File ""/ss_venv/lib64/python3.8/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/ss_venv/lib64/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context    self.dialect.do_execute(  File ""/ss_venv/lib64/python3.8/site-packages/sqlalchemy/engine/default.py"", line 608, in do_execute    cursor.execute(statement, parameters)sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column ""user_id"" violates not-null constraintDETAIL:  Failing row contains (4405, null).[SQL: INSERT INTO sl_dataset_users (dataset_id, user_id) SELECT sl_datasets.id AS dataset_id, sqlatable_user.user_idFROM sqlatable_user JOIN tables ON tables.id = sqlatable_user.table_id JOIN sl_datasets ON sl_datasets.uuid = tables.uuid](Background on this error at: http://sqlalche.me/e/13/gkpj)`### Environment- Docker env- Base image: `centos8`- superset version: `2.0.1`- python version: `3.8.8`- Postgres version: `11.1`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAfter the migration fail tables sl_dataset_users and sl_datasets are absent in DB. I'm not able to reproduce the select `SELECT sl_datasets.id AS dataset_id, sqlatable_user.user_idFROM sqlatable_user JOIN tables ON tables.id = sqlatable_user.table_id JOIN sl_datasets ON sl_datasets.uuid = tables.uuid`A clean installation runs without any problems.It seams like the issue https://github.com/apache/superset/issues/20824
"
23048,1,0,11,0,0,chiweng2009,0,"title:upgrade to , something error in sqllab. description:upgrade from apache/superset:c2c8efc3c431cc81bdc93d3595c5c582eb721090  to apache/superset:b94052e438944b34ef30681e976bf1842ba4e0a5, some error in sqllab. help~Traceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1517, in full_dispatch_request    rv = self.dispatch_request()  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1503, in dispatch_request    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)  File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/decorators.py"", line 175, in wraps    return f(self, *args, **kwargs)  File ""/home/admin/fire-insight-analysis-ding/superset/views/sql_lab/views.py"", line 219, in put    db.session.query(TabState).filter_by(id=tab_state_id).update(fields)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py"", line 3294, in update    result = self.session.execute(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 1696, in execute    result = conn._execute_20(statement, params or {}, execution_options)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1631, in _execute_20    return meth(self, args_10style, kwargs_10style, execution_options)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 325, in _execute_on_connection    return connection._execute_clauseelement(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1498, in _execute_clauseelement    ret = self._execute_context(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1862, in _execute_context    self._handle_dbapi_exception(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 2043, in _handle_dbapi_exception    util.raise_(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 207, in raise_    raise exception  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1819, in _execute_context    self.dialect.do_execute(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 732, in do_execute    cursor.execute(statement, parameters)  File ""/usr/local/lib/python3.8/site-packages/MySQLdb/cursors.py"", line 206, in execute    res = self._query(query)  File ""/usr/local/lib/python3.8/site-packages/MySQLdb/cursors.py"", line 319, in _query    db.query(q)  File ""/usr/local/lib/python3.8/site-packages/MySQLdb/connections.py"", line 254, in query    _mysql.connection.query(self, query)sqlalchemy.exc.IntegrityError: (MySQLdb._exceptions.IntegrityError) (1452, 'Cannot add or update a child row: a foreign key constraint fails (`fire-insight-ding`.`tab_state`, CONSTRAINT `tab_state_latest_query_id_fkey` FOREIGN KEY (`latest_query_id`) REFERENCES `query` (`client_id`) ON DELETE SET NULL)')[SQL: UPDATE tab_state SET changed_on=%s, latest_query_id=%s, changed_by_fk=%s WHERE tab_state.id = %s][parameters: (datetime.datetime(2023, 2, 9, 9, 27, 32, 260966), 'Mvni5_2n7', 1, 22)](Background on this error at: https://sqlalche.me/e/14/gkpj)![FE55E0FC-6F63-4CD1-97C5-C108F811B965](https://user-images.githubusercontent.com/6847398/217777448-1b6e2485-8721-4f8c-9397-b4b71fe74b91.png)
"
23043,1,0,4,0,0,ali-xflow,0,"title:Superset is adding unnecessary Group By clause in MapBox query. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Create a new chart.2. Choose a Dataset3. Save the dataset4. Choose mapbox in the chart options5. Click on view query### Expected resultsMapbox should show results with all values of longitude and latitude.### Actual resultsMapbox only show results with distinct, unique values of longitude and latitude, and it adds a group by clause in query.#### ScreenshotsThis is the result i am getting<img width=""655"" alt=""image"" src=""https://user-images.githubusercontent.com/114662678/217726756-5bf24a96-760d-45db-874d-9d2dc70b0b08.png"">Total rows should be 983:<img width=""482"" alt=""image"" src=""https://user-images.githubusercontent.com/114662678/217726841-99af3683-5492-4987-8e59-15ac3708d938.png"">### Environment(please complete the following information):- Edge- Using default docker-compose-non-dev.yml to set the environment### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextThe mapbox works perfectly in a development environment, but this issue exists only in production environment. Is there any way to modify query so it removes the group by clause so i get all the values 
"
23037,1,491,11,0,0,wrschneider,0,"title:webpack no longer starting in dev mode, after git pull. description:#### How to reproduce the bugHad it up and running, did a git pull to bring in latest changesnow run `docker-compose up`### Expected resultsWorks as usual### Actual resultssuperset_node container fails with webpack error```superset_node            | > superset@0.0.0-dev devsuperset_node            | > webpack --mode=development --color --watchsuperset_node            | superset_node            | [webpack-cli] Failed to load '/app/superset-frontend/webpack.config.js' configsuperset_node            | [webpack-cli] Error: Cannot find module './domToMarkup'superset_node            | Require stack:superset_node            | - /app/superset-frontend/node_modules/dom-converter/lib/domConverter.js```*non-dev did launch successfully.*### Environment- superset version: branch master, most recent commit: 7bb9b810ee7dc9292b375cab28d8a559d030f87c### ChecklistMake sure to follow these steps before submitting your issue - thank you!### Additional contextAdd any other context about the problem here.
"
23036,1,0,10,0,0,ironhacker,0,"title:Azure OAuth Redirect is http instead of https. description:Using OAuth2 for Azure, the redirect URI sent on sign in is ""http"" when it needs to be ""https"" and I cannot find a way to override it.  I did configure the redirect URI on Azure, but it MUST be ""https"".#### How to reproduce the bug1. Install Superset using Docker Compose2. Configure Nginx to proxy behind SSL.3. Configure Azure App and get Application ID, Tenant ID, and Secret.4. Configure OAUTH_PROVIDERS in superset_config_docker.py according to docs:  https://flask-appbuilder.readthedocs.io/en/latest/security.html#authentication-oauth5. Restart and attempt to sign in.### Expected resultsSuccessful Sign In### Actual resultsAzure Error:  AADSTS50011: The redirect URI 'http://[my-domain]/oauth-authorized/azure' specified in the request does not match the redirect URIs configured for the application.### Environment(please complete the following information):- Google Chrome Current:- superset version: git latest 2023-02-08 - Docker Compose### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextIn OAUTH_PROVIDERS, I tried defining redirect_uri, and redirect_url under the root, remote_app, and remote_app/client_kwargs to no avail.
"
23018,1,0,4,1,0,alekssakovsky,0,"title:repeat issue in calendar heatmap. description:https://github.com/apache/superset/issues/22408#issue-1494151128
"
23010,1,9768,7,1,1,gonzo-soc,0,"title:Failed generating csv HTTP Error 407: Authorization Required. description:A clear and concise description of what the bug is.**Failed generating csv HTTP Error 407: Authorization Required** - using firefox webdriver and Superset 2.0.0 release.#### How to reproduce the bug1. Go to 'Alerts and Reports'2. Create new scheduled reports on dashboard or chart (_Send as CSV_)3. See error log ### Expected resultsdashboard screenshot received by email w/o errors### Actual resultsReceived a log message: **Failed generating csv HTTP Error 407: Authorization Required**.#### Screenshots![image](https://user-images.githubusercontent.com/30850323/217115980-5ab33f8a-e608-45d6-bceb-2060ca066ec4.png)### Environment(please complete the following information):- browser type and version: `Chrome Version 109.0.5414.120 (Official Build) (64-bit)`- superset version: `superset version 2.0.0` / `superset-helm-chart-0.8.5`- python version: `Python 3.8.12`- node.js version: `N/A`- podman version: `4.0.2`- podman-compose version: `1.0.4`- host OS: `Rocky Linux release 8.6 (Green Obsidian)`- firefox webdriver: `GECKODRIVER_VERSION=v0.29.0`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ +] I have checked the superset logs for python stacktraces and included it here as text if there are any.```[2023-02-07 04:44:00,416: INFO/ForkPoolWorker-15] Report sent to emailA downstream exception occurred while generating a report: b2960655-20fe-4562-b25f-4021e3b419acTraceback (most recent call last):  File ""/app/superset/reports/commands/execute.py"", line 260, in _get_csv_data    csv_data = get_chart_csv_data(url, auth_cookies)  File ""/app/superset/utils/csv.py"", line 86, in get_chart_csv_data    response = opener.open(chart_url)  File ""/usr/local/lib/python3.8/urllib/request.py"", line 531, in open    response = meth(req, response)  File ""/usr/local/lib/python3.8/urllib/request.py"", line 640, in http_response    response = self.parent.error(  File ""/usr/local/lib/python3.8/urllib/request.py"", line 569, in error    return self._call_chain(*args)  File ""/usr/local/lib/python3.8/urllib/request.py"", line 502, in _call_chain    result = func(*args)  File ""/usr/local/lib/python3.8/urllib/request.py"", line 649, in http_error_default    raise HTTPError(req.full_url, code, msg, hdrs, fp)urllib.error.HTTPError: HTTP Error 407: Authorization RequiredThe above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/app/superset/tasks/scheduler.py"", line 79, in execute    AsyncExecuteReportScheduleCommand(  File ""/app/superset/reports/commands/execute.py"", line 659, in run    raise ex  File ""/app/superset/reports/commands/execute.py"", line 655, in run    ReportScheduleStateMachine(  File ""/app/superset/reports/commands/execute.py"", line 624, in run    state_cls(  File ""/app/superset/reports/commands/execute.py"", line 525, in next    raise first_ex  File ""/app/superset/reports/commands/execute.py"", line 503, in next    self.send()  File ""/app/superset/reports/commands/execute.py"", line 408, in send    notification_content = self._get_notification_content()  File ""/app/superset/reports/commands/execute.py"", line 341, in _get_notification_content    csv_data = self._get_csv_data()  File ""/app/superset/reports/commands/execute.py"", line 264, in _get_csv_data    raise ReportScheduleCsvFailedError(superset.reports.commands.exceptions.ReportScheduleCsvFailedError: Failed generating csv HTTP Error 407: Authorization Required```- [+] I have reproduced the issue with at least the latest released version of superset.- [+] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context1) **PNG-report** is being generated successfully (see the comment here: https://github.com/apache/superset/issues/22326 - on Dec 5, 2022)  2) Configuration _superset_config.py_```# Licensed to the Apache Software Foundation (ASF) under one# or more contributor license agreements.  See the NOTICE file# distributed with this work for additional information# regarding copyright ownership.  The ASF licenses this file# to you under the Apache License, Version 2.0 (the# ""License""); you may not use this file except in compliance# with the License.  You may obtain a copy of the License at##   http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing,# software distributed under the License is distributed on an# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY# KIND, either express or implied.  See the License for the# specific language governing permissions and limitations# under the License.## This file is included in the final Docker image and SHOULD be overridden when# deploying the image to prod. Settings configured here are intended for use in local# development environments. Also note that superset_config_docker.py is imported# as a final step as a means to override ""defaults"" configured here#import loggingimport osfrom datetime import timedeltafrom typing import Optionalfrom cachelib.file import FileSystemCachefrom celery.schedules import crontabfrom flask import sessionfrom flask import Flasklogger = logging.getLogger()def make_session_permanent():    '''    Enable maxAge for the cookie 'session'    '''    session.permanent = True# Set up max age of session to 24 hoursPERMANENT_SESSION_LIFETIME = timedelta(hours=24)def FLASK_APP_MUTATOR(app: Flask) -> None:    app.before_request_funcs.setdefault(None, []).append(make_session_permanent)def get_env_variable(var_name: str, default: Optional[str] = None) -> str:    """"""Get the environment variable or raise exception.""""""    try:        return os.environ[var_name]    except KeyError:        if default is not None:            return default        else:            error_msg = ""The environment variable {} was missing, abort..."".format(                var_name            )            raise EnvironmentError(error_msg)DATABASE_DIALECT = get_env_variable(""DATABASE_DIALECT"")DATABASE_USER = get_env_variable(""DATABASE_USER"")DATABASE_PASSWORD = get_env_variable(""DATABASE_PASSWORD"")DATABASE_HOST = get_env_variable(""DATABASE_HOST"")DATABASE_PORT = get_env_variable(""DATABASE_PORT"")DATABASE_DB = get_env_variable(""DATABASE_DB"")# The SQLAlchemy connection string.SQLALCHEMY_DATABASE_URI = ""%s://%s:%s@%s:%s/%s"" % (    DATABASE_DIALECT,    DATABASE_USER,    DATABASE_PASSWORD,    DATABASE_HOST,    DATABASE_PORT,    DATABASE_DB,)REDIS_HOST = get_env_variable(""REDIS_HOST"")REDIS_PORT = get_env_variable(""REDIS_PORT"")REDIS_CELERY_DB = get_env_variable(""REDIS_CELERY_DB"", ""0"")REDIS_RESULTS_DB = get_env_variable(""REDIS_RESULTS_DB"", ""1"")RESULTS_BACKEND = FileSystemCache(""/app/superset_home/sqllab"")CACHE_CONFIG = {    ""CACHE_TYPE"": ""redis"",    ""CACHE_DEFAULT_TIMEOUT"": 300,    ""CACHE_KEY_PREFIX"": ""superset_"",    ""CACHE_REDIS_HOST"": REDIS_HOST,    ""CACHE_REDIS_PORT"": REDIS_PORT,    ""CACHE_REDIS_DB"": REDIS_RESULTS_DB,}DATA_CACHE_CONFIG = CACHE_CONFIGclass CeleryConfig(object):    broker_url = f""redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_CELERY_DB}""    imports = (""superset.sql_lab"",)    result_backend = f""redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_RESULTS_DB}""    worker_prefetch_multiplier = 1    task_acks_late = False    worker_log_level = 'DEBUG'    beat_schedule = {        ""reports.scheduler"": {            ""task"": ""reports.scheduler"",            ""schedule"": crontab(minute=""*"", hour=""*""),        },        ""reports.prune_log"": {            ""task"": ""reports.prune_log"",            ""schedule"": crontab(minute=10, hour=0),        },    }class CustomCeleryConfig(object):    broker_url = f""redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_CELERY_DB}""    imports = (""superset.sql_lab"", ""superset.tasks"")    result_backend = f""redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_RESULTS_DB}""    # worker_prefetch_multiplier = 1    # task_acks_late = False    worker_prefetch_multiplier = 10    worker_log_level = 'DEBUG'    task_acks_late = True    task_annotations = {        'sql_lab.get_sql_results': {            'rate_limit': '100/s',        },        'email_reports.schedule_hourly': {            'rate_limit': '1/s',            'time_limit': 120,            'soft_time_limit': 150,            'ignore_result': True,        },    }    beat_schedule = {        ""reports.scheduler"": {            ""task"": ""reports.scheduler"",            ""schedule"": crontab(minute=""*"", hour=""*""),        },        ""reports.prune_log"": {            ""task"": ""reports.prune_log"",            ""schedule"": crontab(minute=10, hour=0),        },        'email_reports.schedule_hourly': {            'task': 'email_reports.schedule_hourly',            'schedule': crontab(minute=1, hour='*'),        },    }CELERY_CONFIG = CustomCeleryConfig# CELERY_CONFIG = CeleryConfigSQLLAB_CTAS_NO_LIMIT = True## Optionally import superset_config_docker.py (which will have been included on# the PYTHONPATH) in order to allow for local settings to be overridden#try:    import superset_config_docker    from superset_config_docker import *  # noqa    logger.info(        f""Loaded your Docker configuration at "" f""[{superset_config_docker.__file__}]""    )except ImportError:    logger.error(""ERROR: Failed to import superset_config_docker.py!!!!"")    logger.info(""Using default Docker config..."")```_superset_config_docker.py_```## Alert/Reports @link: https://superset.apache.org/docs/installation/alerts-reports/#ENABLE_SCHEDULED_EMAIL_REPORTS = TrueALERT_REPORTS_NOTIFICATION_DRY_RUN = FalseSMTP_HOST = ""smtp.somedomain"" # change to your hostSMTP_PORT = 25 # your port, e.g. 587SMTP_STARTTLS = FalseSMTP_SSL_SERVER_AUTH = False # If your using an SMTP server with a valid certificateSMTP_SSL = FalseSMTP_USER = """" # use the empty string """" if using an unauthenticated SMTP serverSMTP_PASSWORD = """" # use the empty string """" if using an unauthenticated SMTP serverSMTP_MAIL_FROM = ""admin@somedomain""EMAIL_REPORTS_SUBJECT_PREFIX = ""[SELLC Superset-test -- helm-chart 0.8.5]"" # optional - overwrites default value in config.py of ""[Report] ""# WebDriver configuration# If you use Firefox, you can stick with default values# If you use Chrome, then add the following WEBDRIVER_TYPE and WEBDRIVER_OPTION_ARGSWEBDRIVER_TYPE = ""firefox""# WEBDRIVER_OPTION_ARGS = [#     ""--force-device-scale-factor=2.0"",#     ""--high-dpi-support=2.0"",#     ""--headless"",#     ""--disable-gpu"",#     ""--disable-dev-shm-usage"",#     ""--no-sandbox"",#     ""--disable-setuid-sandbox"",#     ""--disable-extensions"",# ]FEATURE_FLAGS = {""ALERT_REPORTS"": True}ALERT_REPORTS_NOTIFICATION_DRY_RUN = False# The base URL for the email report hyperlinks.# This is for internal use, you can keep httpWEBDRIVER_BASEURL = ""http://superset:8088""SUPERSET_WEBSERVER_ADDRESS = ""superset""# This is the link sent to the recipient. Change to your domain, e.g. https://superset.mydomain.comWEBDRIVER_BASEURL_USER_FRIENDLY = ""http://superset.somedomain""SCREENSHOT_LOCATE_WAIT = 2000SCREENSHOT_LOAD_WAIT = 1600THUMBNAIL_SELENIUM_USER = ""admin"" ## Alert/Reports#```
"
23002,1,0,5,0,0,albertojarabo,0,"title:Time Series Graph with other non-main druid table column generates error. description:Im trying to create a Time Series V2 Graph on Superset based on a time column that is not the main that Druid works with. So I create a Dataset based on a Select with a CAST from a VARCHAR field to TIMESTAMP. The query works well, the Graph form seems to be working but when I try to update results, it appears an error.#### How to reproduce the bug1. Create a druid connection2. Create a druid dataset from a table3. Open SQLEditor4. Create a query that uses other field (varchar field with timestamp) and cast it to timestamp5. Run the query and check that works.6. Press on Create Chart when query has finished7. Check that no time field is set on Time Column, and the CASTed field is still a Varchar field.8. Try to cast inside the CustomSQL tab in Time Column and CAST it again.9. See error### Expected resultsSuperset should use the new Time Field for the ghrap.### Actual resultsNo time field is found despite having configured it. And If you try to force the cast inside the Time Column's CustomSQL it shows an error.#### Screenshots![image](https://user-images.githubusercontent.com/7034464/217032286-965649c1-d676-4119-8b38-2d4e75c1325b.png)![image](https://user-images.githubusercontent.com/7034464/217032655-5fe7275e-cd10-4574-ad88-6ddfa2d2dce8.png)![image](https://user-images.githubusercontent.com/7034464/217032742-391be4ad-0889-4f67-a631-1699fc546f1f.png)![image](https://user-images.githubusercontent.com/7034464/217032952-5f830955-4a53-4f4f-8b5b-b448537213b8.png)![image](https://user-images.githubusercontent.com/7034464/217033107-f0001b84-e00d-433d-8653-5e6504b8f679.png)###  Environment(please complete the following information):- browser type and version: Chrome 109.0.5414.120 (Build oficial) (64 bits)- superset version: `superset version`: 2.0.0- python version: `python --version` 3.8.12- druid version: 25.0.0
"
22976,1,0,3,0,0,hassan-turi,0,"title:Unable to get data of Present Month in Apache Superset. description:I am using Apache Superset for reporting purpose. I am want to draw a chart to show the graph for present Month. I used several ways but it is showing me the last day of the month. I used this method and other like start of this month It is showing me end of this month. Please show me the correct way to get the data of the current month.![image](https://user-images.githubusercontent.com/87395528/216524257-b86ee8af-e2c1-4427-b2df-52544b0d2ca4.png)
"
22965,1,0,6,0,0,architmmmec,0,"title:Want to export complete dashboard to Google sheet. description:Can someone explain the way to export complete dashboard to Google sheet
"
22946,0,0,176,0,0,alexclavel-ocient,0,"title:DB engine specs cannot change the CTE_ALIAS variable. description:As it stands, the CTE_ALIAS used in [superset/connectors/sqla/models.py ](https://github.com/apache/superset/blob/b410dbb5dd510f1ed1dce6b2d0e114dda263eedb/superset/connectors/sqla/models.py#L924)cannot be changed by the db engine spec. Instead, it pulls the value from the [base model](https://github.com/apache/superset/blob/b410dbb5dd510f1ed1dce6b2d0e114dda263eedb/superset/connectors/sqla/models.py#L99).This causes a problem for databases that cannot use the [default CTE_ALIAS](https://github.com/apache/superset/blob/b410dbb5dd510f1ed1dce6b2d0e114dda263eedb/superset/db_engine_specs/base.py#L89) of '__cte'. In particular, this alias starts with an underscore, which may not be supported#### How to reproduce the bugCreate Chart on a dataset containing a CTE### Expected resultsGenerate query like:`WITH cte as (SELECT * from schema.table),``    MY_CTE_ALIAS AS (SELECT *  from cte)``SELECT id AS ""id""``FROM MY_CTE_ALIAS``LIMIT 1000;`### Actual results`WITH cte as (SELECT * from schema.table),``    MY_CTE_ALIAS AS (SELECT *  from cte)``SELECT id AS ""id""``FROM __cte``LIMIT 1000;`### Checklist- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.
"
22922,0,0,7,0,0,sedanursayer,0,"title:superset runtime error. description:We want to run superset with waitress instead of gunicorn on windows like this : waitress-serve --host 127.0.0.1 superset:appour goal is to run Superset project directly from github project instead of installing it in virtualenv.but we are getting this error, any idea what to do? Error : raise RuntimeError(_app_ctx_err_msg)RuntimeError: Working outside of application context.
"
22918,0,0,10,0,0,zeynepkoyun,0,"title: can't find '_main_' module in 'superset'. description:Hello @eschutho  @craig-rueda  @hughhhh @michael-s-molina When I want to run the Superset project directly from the github project instead of installing it in virtualenv, I get the following error.Error Description: can't find '_main_' module in 'superset'
"
22911,1,0,21,0,0,88fingerslukee,0,"title:Postgres database successfully added but not showing in the list of connections. description:After adding a database, I cannot see it in the connections tab nor use it in a query or dataset.  #### How to reproduce the bugAdd a new database connection### Expected resultsdatabase connection shows up in list of connections### Actual resultsnothing shows up. No DBs are available to create a dataset from### Environmentrunning docker version. pulled latest available from the github master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x ] I have reproduced the issue with at least the latest released version of superset.- [ x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
22898,0,557,1,0,0,marshallbrekka,0,"title:Close/remove button is broken for metrics on chart page. description:The click handler for the button to remove a metric on the chart page is throwing an exception, breaking the ability to remove metrics from a chart.```Uncaught TypeError: Cannot read properties of undefined (reading 'stopPropagation')    at yt.onRemoveMetric (AdhocMetricOption.jsx:51:7)    at onClick (index.tsx:313:11)    at Object.l (react-dom.production.min.js:14:84)    at p (react-dom.production.min.js:14:238)    at react-dom.production.min.js:14:292    at b (react-dom.production.min.js:15:72)    at ot (react-dom.production.min.js:52:146)    at rt (react-dom.production.min.js:51:255)    at it (react-dom.production.min.js:52:334)    at ft (react-dom.production.min.js:56:10)```#### How to reproduce the bug1. Go to any chart editing page2. Click on the ""x"" on the left side of a metric that is already added to the chart4. Check the browsers dev tools/console for the exception### Expected resultsMetric should be removed from the list### Actual resultsThe metric remains on the chart#### Screenshots<img width=""327"" alt=""Screen Shot 2023-01-28 at 11 31 10 AM"" src=""https://user-images.githubusercontent.com/436140/215287501-348ee84c-a3d6-4988-b7d0-e696a9514e27.png""><img width=""752"" alt=""Screen Shot 2023-01-28 at 11 38 12 AM"" src=""https://user-images.githubusercontent.com/436140/215287516-5ff21bb5-e51a-45f7-a61c-dba23903c655.png"">### Environment(please complete the following information):- browser type and version: Chrome 108- superset version: [docker image sha256:ce10634ba3193607cebf8628c4441bffd8a5cee8791b1394e5c5b16046a77ebf](https://hub.docker.com/layers/apache/superset/latest/images/sha256-ce10634ba3193607cebf8628c4441bffd8a5cee8791b1394e5c5b16046a77)### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextThe [onRemoveMetric](https://github.com/apache/superset/blob/cddc361adc483ed605857a2eb39c5efffa089076/superset-frontend/src/explore/components/controls/MetricControl/AdhocMetricOption.jsx#L50-L53) handler expects to be passed the event objectI believe [this is the PR](https://github.com/apache/superset/pull/22707/files) that introduced the bug, as it changed how the `onRemove` handler is invoked, [no-longer passing the event object](https://github.com/apache/superset/blob/1fe4a71f5be10f182277b6008d212c7f40ced2e4/superset-frontend/src/explore/components/controls/OptionControls/index.tsx#L311-L314)
"
22883,1,0,8,0,0,RamiAly,0,"title:Markdown component doesn't exist in 2.0.0 version and above. description:A clear and concise description of what the bug is.After upgrading to 2.0.0, I cant create a markdown component as it's not shown as it was in 1.5.2 and prior #### How to reproduce the bugUpgrade to at least 2.0.01. Go to the dashboards tab  2. Click on create a new dashboard3. click on Layout Elements4. you will see multiple components but not markdown### Expected resultsto be able to create markdownwhat you expected to happen.### Actual resultswhat actually happens.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
22847,1,0,6,0,0,architmmmec,0,"title:Supporting nested column in Superset. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to '...'2. Click on '....'3. Scroll down to '....'4. See error### Expected resultswhat you expected to happen.### Actual resultswhat actually happens.#### Screenshots<img width=""866"" alt=""Screenshot 2023-01-25 at 9 39 19 AM"" src=""https://user-images.githubusercontent.com/37949198/214477911-1c4d24a8-14e1-4aeb-a181-9db724d3e349.png""><img width=""439"" alt=""Screenshot 2023-01-25 at 9 36 35 AM"" src=""https://user-images.githubusercontent.com/37949198/214477927-81ddd7af-5749-4cf1-97f6-c8e19d3e9ecf.png"">Screenshot from excel is what I wanted but I couldn't achieve similar thing in superset. Both the screenshots are attached.I have one column Nov, I want to create nesting of columns(subcolumn) for bau and event. 
"
22829,1,188,3,1,0,aortiz-WW,0,"title:Can't get UI to change again. description:### A clear and concise description of what the bug is.I'm trying to change the UI of superset. I want to add a banner at the top of the page and at the bottom. I have already done so by following these links:* https://superset.apache.org/docs/installation/installing-superset-using-docker-compose/* https://github.com/apache/superset/issues/22758#### How to reproduce the bugI first clone the repo. Then I go inside the `superset-frontend/src/views/components/` directory. Inside the Menu.tsx, I add to the Menuwrapper component my banner as such:```return <>           <div id='banner'  style={{backgrounColor: 'green', color: 'white', textAlign: 'center}}>Unclassified</div>           <Menu data={newMenuData} {...rest}/></>```Then I run the docker-compose pull and up explained in the first link above.### Expected resultsI expect to see changes in the banner after adding changes. It appeared once I made the changes and then if I want to make other changes, it doesn't appear### Actual resultsNothing changes after the initial change#### ScreenshotsIf applicable, add screenshots to help explain your problem.### EnvironmentUsing apache/superset on windows hosted VM running Ubuntu 22. Everything is ran using vs code. 
"
22820,1,1309,10,0,1,topratiksharma,0,"title:Dashboard not visible via embedded SDK.. description:I am working to embed the dashboard inside my angular application using superset SDK.After doing the whole integration the dashboard is not visible.Used this below article to integrate the dashboard.https://medium.com/@khushbu.adav/embedding-superset-dashboards-in-your-react-application-7f282e3dbd88Below is my config changes apart from the default file.```FEATURE_FLAGS = {""ALERT_REPORTS"": True,    ""EMBEDDED_SUPERSET"": True}ALERT_REPORTS_NOTIFICATION_DRY_RUN = TrueWEBDRIVER_BASEURL = ""http://superset:8088/"" (OR ""http://localhost:8088/""  tried both)# The base URL for the email report hyperlinks.WEBDRIVER_BASEURL_USER_FRIENDLY = WEBDRIVER_BASEURLSESSION_COOKIE_SAMESITE = NoneENABLE_PROXY_FIX = TruePUBLIC_ROLE_LIKE_GAMMA = TrueCORS_OPTIONS = {  'supports_credentials': True,  'allow_headers': ['*'],  'resources':['*'],  'origins': ['*']}GUEST_ROLE_NAME = ""Admin""GUEST_TOKEN_JWT_EXP_SECONDS: 300  # 5 minutes, or you could set it longer```I am using admin user as the default login and created custom as well as tried using the predefined dashboards.User list![image](https://user-images.githubusercontent.com/15375292/213927597-d87372b7-32cc-4783-bd2d-f17e4fe2459e.png)Dashboard settings![image](https://user-images.githubusercontent.com/15375292/213927642-951a5dc7-c747-46e1-8abf-a91ee9d41a3b.png)Chart Settings![image](https://user-images.githubusercontent.com/15375292/213927690-b4878b5f-15e0-48d8-bcd9-40cb636633ec.png)My UI code.``````#### How to reproduce the bug### Expected resultsShould see the dashboard on the application.### Actual resultsBlank screen with no errors.#### Screenshot![image](https://user-images.githubusercontent.com/15375292/213927835-5dce6c9b-9c2e-4f7a-a382-a82ee32bc76b.png)### Environment(please complete the following information):- browser type and version: NA- superset version: `superset version` - python version: `python --version` NA- node.js version: `node -v` : 16.15.0- any feature flags active: Yes  {""ALERT_REPORTS"": True,    ""EMBEDDED_SUPERSET"": True}### Frontend Code:```  public embed() {    // const token = await this.fetchGuestTokenFromBackend();    const element = document.getElementById('my-dashboard');    embedDashboard({      id: '5a99f740-1f70-46f5-8563-422ec22badcb', // given by the Superset embedding UI      supersetDomain: 'http://localhost:8088',      mountPoint: element, // any html element that can contain an iframe      fetchGuestToken: () => this.fetchGuestTokenFromBackend(),      dashboardUiConfig: {        // dashboard UI config: hideTitle, hideTab, hideChartControls, filters.visible, filters.expa0nded (optional)        hideTitle: true,        // filters: { expanded: true },      },    });  }```###API requests![image](https://user-images.githubusercontent.com/15375292/213930450-1ce5b35c-c477-4b57-846b-a1f34219b208.png)### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
22819,1,0,2,0,0,Andkov440,0,"title:500: Internal server error. description:Command for start superset:superset run -p 8088 --host 0.0.0.0The error appeare after login. #### Screenshots![Screenshot_4](https://user-images.githubusercontent.com/25137962/213914717-f7518387-13b9-491f-9a1e-c351ff8ace01.png)![Screenshot_5](https://user-images.githubusercontent.com/25137962/213914790-947e70b9-6a13-42e4-988d-399ab3fd9e3a.png)### Environment- browser type and version: Google Chrome 109- superset version: 2.0.1- python version: 3.8.10### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
22817,1,0,58,0,0,AyoubTahir,0,"title:Set Authorization header. description:const res = await request(app).delete(`/land`).set('Authorization', `Bearer ${token}`);Authorization header is missing
"
22778,1,0,77,0,0,nmella,0,"title:Bubble Chart Error 婵犵妲呴崑鎾跺緤娴犲鐤い鏍仜閻?""Object contains forbidden constructor property"". description:Hi there,I am new to Superset, so right now I am testing it. Right now I have the following error for the bubble chart:![image](https://user-images.githubusercontent.com/5648244/213223772-c545ea80-88ab-491a-836a-568dd9fe1211.png)The strange thing is that the chart works when building, but it fails when it is shown in the dashboard:![Peek 2023-01-18 13-02](https://user-images.githubusercontent.com/5648244/213226140-87e94ce5-3733-400b-867c-68ff2ab6c135.gif)The error ""Object contains forbidden constructor property"" only happens for the bubble chart when show in the dashboard. Any idea of what might be happening ?I have deploy the latest version of the Helm Chart. I search the container logs, and couldn't find anything related. Thanks ! This is an amazing project !### Environment- browser type and version: Chrome- superset version: Superset 0.0.0-dev- python version: 3.8.13
"
22755,1,3351,194,0,0,rohitpawar2811,0,"title:Alert is not working as expected and got unregistered-task error for alert. description:**I am Getting problem to schedule alert ,** ```The full contents of the message body was:superset_worker         | b'[[], {}, {""callbacks"": null, ""errbacks"": null, ""chain"": null, ""chord"": null}]' (77b)superset_worker         | Traceback (most recent call last):superset_worker         |   File ""/usr/local/lib/python3.8/site-packages/celery/worker/consumer/consumer.py"", line 581, in on_task_receivedsuperset_worker         |     strategy = strategies[type_]superset_worker         | KeyError: 'alerts.schedule_check'superset_worker_beat    | [2023-01-17 15:01:00,029: INFO/MainProcess] Scheduler: Sending due task reports.scheduler (reports.scheduler)superset_worker         | [2023-01-17 15:01:00,037: ERROR/MainProcess] Received unregistered task of type 'email_reports.schedule_hourly'.superset_worker         | The message has been ignored and discarded.``````The full contents of the message body was:superset_worker         | b'[[], {}, {""callbacks"": null, ""errbacks"": null, ""chain"": null, ""chord"": null}]' (77b)superset_worker         | Traceback (most recent call last):superset_worker         |   File ""/usr/local/lib/python3.8/site-packages/celery/worker/consumer/consumer.py"", line 581, in on_task_receivedsuperset_worker         |     strategy = strategies[type_]superset_worker         | KeyError: 'email_reports.schedule_hourly'superset_worker         | [2023-01-17 15:01:00,044: INFO/MainProcess] Task reports.scheduler[8ad8ef7f-f15b-42bb-bb93-8b5e3e5ab2ab] receivedsuperset_worker         | Scheduling alert rohit eta: 2023-01-17 15:01:00superset_worker         | [2023-01-17 15:01:00,080: INFO/ForkPoolWorker-3] Scheduling alert rohit eta: 2023-01-17 15:01:00superset_worker         | [2023-01-17 15:01:00,099: INFO/MainProcess] Task reports.execute[c7d43150-cbe4-4b6b-8bdd-8d8bfeac7741] receivedsuperset_worker         | [2023-01-17 15:01:00,099: INFO/ForkPoolWorker-3] Task reports.scheduler[8ad8ef7f-f15b-42bb-bb93-8b5e3e5ab2ab] succeeded in 0.054125094786286354s: None```I am Getting problem to schedule alert , **Problem:**Initially on first time It will be succesfully run and in response email sent , but after that in next schedule on trigger it run but not able to send email-notification but status would be success.**Expected** : Each time on sucessfull trigger it will send the email in response Myconfig```     class CeleryConfig(object):    BROKER_URL = f""redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_CELERY_DB}""    CELERY_IMPORTS = (""superset.sql_lab"",)    CELERY_RESULT_BACKEND = f""redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_RESULTS_DB}""    CELERYD_LOG_LEVEL = ""DEBUG""    # CELERYD_PREFETCH_MULTIPLIER = 1    # CELERY_ACKS_LATE = False    CELERYD_PREFETCH_MULTIPLIER = 10    CELERY_ACKS_LATE = True    CELERY_ANNOTATIONS = {        'sql_lab.get_sql_results': {            'rate_limit': '100/s',        },        'email_reports.send': {            'rate_limit': '1/s',            'time_limit': 1800,            'soft_time_limit': 1800,            'ignore_result': True,        },    },                                CELERYBEAT_SCHEDULE = {        ""email_reports.schedule_hourly"": {            ""task"": ""email_reports.schedule_hourly"",            ""schedule"": crontab(minute=1, hour=""*""),        },        ""reports.scheduler"": {            ""task"": ""reports.scheduler"",            ""schedule"": crontab(minute=""*"", hour=""*""),        },        ""reports.prune_log"": {            ""task"": ""reports.prune_log"",            ""schedule"": crontab(minute=10, hour=0),        },        ""alerts.schedule_check"": {            ""task"": ""alerts.schedule_check"",            ""schedule"": crontab(minute=""1"", hour=""*"")        },```
"
22743,0,2548,108,0,0,Germandrummer92,0,"title:cryptography >=39 is incompatible with superset. description:#### How to reproduce the bug```bash> python -m venv venv> pip install -e .> python -c ""from superset import *""> Traceback (most recent call last):  File ""<string>"", line 1, in <module>  File ""/Users/ddraper/dev/superset/superset/__init__.py"", line 21, in <module>    from superset.app import create_app  File ""/Users/ddraper/dev/superset/superset/app.py"", line 23, in <module>    from superset.initialization import SupersetAppInitializer  File ""/Users/ddraper/dev/superset/superset/initialization/__init__.py"", line 32, in <module>    from superset.extensions import (  File ""/Users/ddraper/dev/superset/superset/extensions/__init__.py"", line 32, in <module>    from superset.utils.async_query_manager import AsyncQueryManager  File ""/Users/ddraper/dev/superset/superset/utils/async_query_manager.py"", line 26, in <module>    from superset.utils.core import get_user_id  File ""/Users/ddraper/dev/superset/superset/utils/core.py"", line 79, in <module>    from cryptography.hazmat.backends.openssl.x509 import _CertificateModuleNotFoundError: No module named 'cryptography.hazmat.backends.openssl.x509'```### Expected resultsNo errors### Actual results```> Traceback (most recent call last):  File ""<string>"", line 1, in <module>  File ""/Users/ddraper/dev/superset/superset/__init__.py"", line 21, in <module>    from superset.app import create_app  File ""/Users/ddraper/dev/superset/superset/app.py"", line 23, in <module>    from superset.initialization import SupersetAppInitializer  File ""/Users/ddraper/dev/superset/superset/initialization/__init__.py"", line 32, in <module>    from superset.extensions import (  File ""/Users/ddraper/dev/superset/superset/extensions/__init__.py"", line 32, in <module>    from superset.utils.async_query_manager import AsyncQueryManager  File ""/Users/ddraper/dev/superset/superset/utils/async_query_manager.py"", line 26, in <module>    from superset.utils.core import get_user_id  File ""/Users/ddraper/dev/superset/superset/utils/core.py"", line 79, in <module>    from cryptography.hazmat.backends.openssl.x509 import _CertificateModuleNotFoundError: No module named 'cryptography.hazmat.backends.openssl.x509'```### Environment(please complete the following information):- python version: `python --version`婵犲痉鏉库偓娑綖婢跺簺浜圭紒鈧导瀛樷拻?python --versionPython 3.11.1```### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X ] I have reproduced the issue with at least the latest released version of superset.- [X ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context
"
22719,0,0,24,0,0,cdreier,0,"title:Error when booting the superset frontend. description:We are using the official docker images and since the relase a few days ago, the frontend is not able to start due to an javascript error.![image](https://user-images.githubusercontent.com/731608/212284634-f6ad4966-cd35-4250-a31f-f45cfdd0fa8e.png)i stepped through the code, and found, that this change could be the breaking changehttps://github.com/apache/superset/commit/08f45ef207fb159bf0de49dd0a90f423c77965a7#diff-67bc5f87bd184351ac940f107226c9f87c1aa4424fde45de421f7a21d907a71a`getBootstrapData()` does not return an object with a key `config`  - as seen in the diff, the correct path should be `getBootstrapData().common.conf` ?![Bildschirmfoto vom 2023-01-13 10-25-25](https://user-images.githubusercontent.com/731608/212285056-10f12ed7-5233-47d8-9c7a-71b689be1dd3.png)### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ x] I have reproduced the issue with at least the latest released version of superset.- [ x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
22715,0,2863,15,0,0,reidab,0,"title:Helm chart overrides default WTF_CSRF_EXEMPT_LIST with blank array. description:The default `config.py` includes a default value for `WTF_CSRF_EXEMPT_LIST` that excludes three endpoints from CSRF protection.https://github.com/apache/superset/blob/2ccdb72830ffb549c0112442ba0bc7e4219261d4/superset/config.py#L253-L257The `superset-config` helper in the Helm chart overrides this value to a blank array.https://github.com/apache/superset/blob/2ccdb72830ffb549c0112442ba0bc7e4219261d4/helm/superset/templates/_helpers.tpl#L89This causes newly-deployed Superset instances to throw CSRF errors on the `/superset/log` endpoint unless the Helm chart's config file is overridden to restore the default `WTF_CSRF_EXEMPT_LIST` entries.It seems like all of the `WTF_` related overrides from the Helm chart should be removed to allow the defaults to carry through.Or perhaps these three values should be excluded from CSRF protection in a more robust way than just by being config defaults? If Superset always needs them to be permitted in order for the endpoints to work, should users even be able to override that behavior?#### How to reproduce the bug1. Deploy a new instance of Superset using Helm2. Click around the UI a bit3. Notice requests to `/superset/log` in the console returning 302 redirect to login and presenting CSRF errors in the logs. ### Expected resultsThe default endpoints are excluded from CSRF protection### Actual resultsCSRF errors occur on these endpoints.```2023-01-13 05:29:14,936:INFO:flask_wtf.csrf:The CSRF token is missing.Refresh CSRF token errorTraceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask_wtf/csrf.py"", line 256, in protect    validate_csrf(self._get_csrf_token())  File ""/usr/local/lib/python3.8/site-packages/flask_wtf/csrf.py"", line 91, in validate_csrf    raise ValidationError('The CSRF token is missing.')wtforms.validators.ValidationError: The CSRF token is missing.During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1514, in full_dispatch_request    rv = self.preprocess_request()  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1857, in preprocess_request    rv = self.ensure_sync(before_func)()  File ""/usr/local/lib/python3.8/site-packages/flask_wtf/csrf.py"", line 224, in csrf_protect    self.protect()  File ""/usr/local/lib/python3.8/site-packages/flask_wtf/csrf.py"", line 259, in protect    self._error_response(e.args[0])  File ""/usr/local/lib/python3.8/site-packages/flask_wtf/csrf.py"", line 302, in _error_response    raise CSRFError(reason)flask_wtf.csrf.CSRFError: 400 Bad Request: The CSRF token is missing.2023-01-13 05:29:14,936:WARNING:superset.views.base:Refresh CSRF token errorTraceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask_wtf/csrf.py"", line 256, in protect    validate_csrf(self._get_csrf_token())  File ""/usr/local/lib/python3.8/site-packages/flask_wtf/csrf.py"", line 91, in validate_csrf    raise ValidationError('The CSRF token is missing.')wtforms.validators.ValidationError: The CSRF token is missing.During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1514, in full_dispatch_request    rv = self.preprocess_request()  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1857, in preprocess_request    rv = self.ensure_sync(before_func)()  File ""/usr/local/lib/python3.8/site-packages/flask_wtf/csrf.py"", line 224, in csrf_protect    self.protect()  File ""/usr/local/lib/python3.8/site-packages/flask_wtf/csrf.py"", line 259, in protect    self._error_response(e.args[0])  File ""/usr/local/lib/python3.8/site-packages/flask_wtf/csrf.py"", line 302, in _error_response    raise CSRFError(reason)flask_wtf.csrf.CSRFError: 400 Bad Request: The CSRF token is missing.10.17.0.1 - thedyrt [13/Jan/2023:05:29:14 +0000] ""POST /superset/log/?explode=events HTTP/1.1"" 302 220 ""https://superset.thedyrt.dev/superset/explore/table/2/"" ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36""```### Environment(please complete the following information):- browser type and version: Chrome 109- superset version: `2.0.1`- python version: `3.8.12`- node.js version: `16`- any feature flags active: n/a### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
22714,0,0,5,0,0,evolution232634,0,"title: /usr/bin/run-server.sh: not found. description:In k8s, superset is installed through helm, but ""/usr/bin/run-server.sh: not found"" error is reported![image](https://user-images.githubusercontent.com/46314984/212223664-4b3cb4d7-cec6-4b8e-a974-ac61883be327.png)
"
22700,1,0,7,0,0,dkrat7,0,"title:Login redirect problem for URLs with multiple parameters. description:Redirection after login is wrong for url's with multiple parameters#### How to reproduce the bug1. Non-authenticated user clicks superset link that requires login and includes multiple parameters, e.g.:http://127.0.0.1:8088/superset/dashboard/1/?standalone=1&native_filters=(NATIVE_FILTER-kx3sEYj0a:(__cache:(label:%27Motorcycles%27,value:!(%27Motorcycles%27)),filterState:(label:%27Motorcycles%27,value:!(%27Motorcycles%27)),extraFormData:(filters:!((col:product_line,op:IN,val:!(%27Motorcycles%27))))))2. In the next step user is redirected to the login page with the populated ""next"" parameter (url in ""next"" parameter is still correct), e.g.:http://127.0.0.1:8088/login/?next=http://superset:8088/superset/dashboard/1/?standalone=1&native_filters=(NATIVE_FILTER-kx3sEYj0a:(__cache:(label:%27Motorcycles%27,value:!(%27Motorcycles%27)),filterState:(label:%27Motorcycles%27,value:!(%27Motorcycles%27)),extraFormData:(filters:!((col:product_line,op:IN,val:!(%27Motorcycles%27))))))3. But after the login user is redirected to URL without second parameter, e.g.:http://127.0.0.1:8088/superset/dashboard/1/?standalone=1Second (in this case: native_filters) parameter is lost and user has to click the link again (now it works because user is already authenticated).(this issue might originate in the Flask-AppBuilder, which handles logins?)### Expected resultsUser should be redirected to the original URL after login.### Actual resultsUser is redirected to the URL location with only first parameter.### Environment- browser type and version: Firefox 108, Edge 108- superset version: 2.0.1### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
22673,1,0,2,0,0,snehlata08,0,"title:shortend url for chart keeps getting updated on refresh. description:A clear and concise description of what the bug is.When i open a char like this and click on the embed link ![image](https://user-images.githubusercontent.com/79985986/211731832-d289484f-bc5f-4972-9f27-3b516da500fb.png)I get this sort of url which is shortend url![image](https://user-images.githubusercontent.com/79985986/211732806-c0590731-f350-4c81-bb29-0babbfc36c6e.png)  Now when I refresh the page or make any changes in the chart this url gets updated. ![image](https://user-images.githubusercontent.com/79985986/211732934-ca41e5d9-45ad-4ff2-8a40-2909e44bc9fd.png)The problem is I want to embed this chart in my webpage. Since the url before and after are different I always see a chart which is before version and not the latest one. How can we address this problem with a static url so that i always see a latest chart only. 
"
22672,0,167,1,0,0,anthonyorona,0,"title:Links to slack are dead. description:Within the documentation, I have found 3 links to slack:Within ```https://superset.apache.org/community/https://github.com/apache/superset/blob/master/CODE_OF_CONDUCT.mdhttps://github.com/apache/superset/blob/master/README.md```It looks like these were last updated a few months ago: https://github.com/apache/superset/pull/22121 and the limit may have been exceeded.Can we get a new link to join the slack? I am new to superset and it looks like the best community forum. I would like to developer a superset plugin where I can embed a form and make an asynchronous request when a UI component is clicked. I do not need to go through superset's backend.
"
22641,1,2047,4,0,0,ivanshamaev,0,"title:Deployment custom viz plugin hello world in superset image 2.0.0 & 2.0.1. Unexpected error: TypeError: Go.default is not a constructor. description:Hi all!On new releases 2.0.0 and 2.0.1, I can't repeat the deployment of custom visualization into a superset image (as I used to do on 1.3.2 version). I get an **""Unexpected error: TypeError: Go.default is not a constructor""** error, while neither the dashboard nor the creation of charts work. Something is wrong in the image built locally by me. Without custom plugin all works. With plugin - it shows the error.**The sequence of my actions:**1. Created a new demo plugin using the new instructions [https://preset.io/blog/building-custom-viz-plugins-in-superset-v2/](https://preset.io/blog/building-custom-viz-plugins-in-superset-v2/) and [https://superset.apache.org/docs/contributing/creating-viz-plugins](https://superset.apache.org/docs/contributing/creating-viz-plugins).2. Checked through the dev server, everything works .3. Published demo hello world plugin in npmjs (public repository) - [https://www.npmjs.com/package/superset-plugin-chart-counters-new](https://www.npmjs.com/package/superset-plugin-chart-counters-new)4. Added lines to **package.json** & **MainPreset.js** files5. Launched the image build. Everything worked without errors6. Run docker-compose locally with the image that I built7. I go to the dashboard or create a chart - an error is shown.In version 1.3.2, I did exactly these steps for deploying plugins. But in the new version it doesn't work for some reason. My searches have not yielded results.-------**_superset/superset-frontend/package.json_**`""superset-plugin-chart-counters-new"": ""0.1.0"",`**_superset/superset-frontend/src/visualizations/presets/MainPreset.js_**```import SupersetPluginChartCountersNew from 'superset-plugin-chart-counters-new';new SupersetPluginChartCountersNew().configure({key: 'superset-plugin-chart-counters-new',}),```**_Building an image_**`sudo docker build -f Dockerfile --force-rm -t apache/temp-superset:2.0.12 .`**_run docker-compose:_**`sudo docker-compose -f docker-compose-non-dev.yml up`### Other errors from docker containers```List of error:Unexpected error: TypeError: Go.default is not a constructorUnhealthy container superset_worker:[2023-01-05 15:46:00,053: INFO/MainProcess] Task reports.scheduler[b0fccb65-8f9e-49f1-a89a-cf6c6929cb82] received[2023-01-05 15:46:00,073: INFO/ForkPoolWorker-1] Task reports.scheduler[b0fccb65-8f9e-49f1-a89a-cf6c6929cb82] succeeded in 0.018434799000260682s: NoneUnhealthy container superset_worker_beat:[2023-01-05 15:48:00,050: INFO/MainProcess] Scheduler: Sending due task reports.scheduler (reports.scheduler)Common log:superset_app          | [2023-01-05 15:39:04 +0000] [10] [ERROR] Error handling requestsuperset_app          | Traceback (most recent call last):superset_app          |   File ""/usr/local/lib/python3.8/site-packages/gunicorn/workers/gthread.py"", line 326, in handle_requestsuperset_app          |     resp.write_file(respiter)superset_app          |   File ""/usr/local/lib/python3.8/site-packages/gunicorn/http/wsgi.py"", line 385, in write_filesuperset_app          |     if not self.sendfile(respiter):superset_app          |   File ""/usr/local/lib/python3.8/site-packages/gunicorn/http/wsgi.py"", line 375, in sendfilesuperset_app          |     self.sock.sendfile(respiter.filelike, count=nbytes)superset_app          |   File ""/usr/local/lib/python3.8/socket.py"", line 482, in sendfilesuperset_app          |     return self._sendfile_use_sendfile(file, offset, count)superset_app          |   File ""/usr/local/lib/python3.8/socket.py"", line 346, in _sendfile_use_sendfilesuperset_app          |     self._check_sendfile_params(file, offset, count)superset_app          |   File ""/usr/local/lib/python3.8/socket.py"", line 460, in _check_sendfile_paramssuperset_app          |     raise ValueError(superset_app          | ValueError: count must be a positive integer (got 0)```
"
22639,1,0,0,0,0,khumis01,0,"title:Getting ""sub"" key value as 1 from security/login response token. description:Unable to parse response token received from api/v1/security/login request.Getting ""Unexpected type of JSON object member with key sub"" after parsing the token from JWT parser.
"
22622,1,0,7,0,0,Nixan04,0,"title:apache superset automatically using wsgi . description:how to run apache superset automatically using wsgi in venv??
"
22621,1,0,3,0,0,lbenothman,0,"title:Unable to connect to the databases. description:Hi team,I deployed superset using the helm chart and everything was working perfectly. Since the last docker version (Tag: master), Superset is not able to connect to the databases, I have linked it to a Redshift and to a Postgres Database. When I try to open a dashboard I have the following error:`(psycopg2.errors.UndefinedTable) relation ""ssh_tunnels"" does not existLINE 2: FROM ssh_tunnels              ^[SQL: SELECT ssh_tunnels.uuid AS ssh_tunnels_uuid, ssh_tunnels.created_on AS ssh_tunnels_created_on, ssh_tunnels.changed_on AS ssh_tunnels_changed_on, ssh_tunnels.extra_json AS ssh_tunnels_extra_json, ssh_tunnels.id AS ssh_tunnels_id, ssh_tunnels.database_id AS ssh_tunnels_database_id, ssh_tunnels.server_address AS ssh_tunnels_server_address, ssh_tunnels.server_port AS ssh_tunnels_server_port, ssh_tunnels.username AS ssh_tunnels_username, ssh_tunnels.password AS ssh_tunnels_password, ssh_tunnels.private_key AS ssh_tunnels_private_key, ssh_tunnels.private_key_password AS ssh_tunnels_private_key_password, ssh_tunnels.created_by_fk AS ssh_tunnels_created_by_fk, ssh_tunnels.changed_by_fk AS ssh_tunnels_changed_by_fk FROM ssh_tunnels WHERE ssh_tunnels.database_id = %(database_id_1)s][parameters: {'database_id_1': 5}](Background on this error at: https://sqlalche.me/e/14/f405)This may be triggered by:Issue 1002 - The database returned an unexpected error. `Same when I try to access the databases list#### How to reproduce the bug1. Go to any dashboard2. An error is displayed on every chart3. Click on see more4. See error#### Screenshots<img width=""1649"" alt=""image"" src=""https://user-images.githubusercontent.com/3247643/211000460-75f85346-df32-4980-abc0-57e85924c906.png""><img width=""593"" alt=""image"" src=""https://user-images.githubusercontent.com/3247643/211000501-82822dc2-6544-4cb9-b439-d9fb02bf8433.png""><img width=""488"" alt=""image"" src=""https://user-images.githubusercontent.com/3247643/211000574-b627d1ba-21ea-4575-9aab-b5e5f8c775fd.png"">### Environment(please complete the following information):- browser type and version: Chrome 108.0.5359.124- superset version: `superset version`: The last master tag### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X ] I have reproduced the issue with at least the latest released version of superset.- [X ] I have checked the issue tracker for the same issue and I haven't found one similar.
"
22619,1,1291,7,0,0,chick26,0,"title:Init superset fail with error 'No module named 'cryptography.hazmat.backends.openssl.x509''. description:A clear and concise description of what the bug is.### Process1. Using Ubuntu 22.04.5, MiniConda, Python3.82. install superset3. superset db upgrade### Actual results```shellTraceback (most recent call last):  File ""/home/chick/miniconda3/envs/py38/bin/superset"", line 5, in <module>    from superset.cli.main import superset  File ""/home/chick/miniconda3/envs/py38/lib/python3.8/site-packages/superset/__init__.py"", line 21, in <module>    from superset.app import create_app  File ""/home/chick/miniconda3/envs/py38/lib/python3.8/site-packages/superset/app.py"", line 23, in <module>    from superset.initialization import SupersetAppInitializer  File ""/home/chick/miniconda3/envs/py38/lib/python3.8/site-packages/superset/initialization/__init__.py"", line 33, in <module>    from superset.extensions import (  File ""/home/chick/miniconda3/envs/py38/lib/python3.8/site-packages/superset/extensions/__init__.py"", line 32, in <module>    from superset.utils.cache_manager import CacheManager  File ""/home/chick/miniconda3/envs/py38/lib/python3.8/site-packages/superset/utils/cache_manager.py"", line 24, in <module>    from superset.utils.core import DatasourceType  File ""/home/chick/miniconda3/envs/py38/lib/python3.8/site-packages/superset/utils/core.py"", line 76, in <module>    from cryptography.hazmat.backends.openssl.x509 import _CertificateModuleNotFoundError: No module named 'cryptography.hazmat.backends.openssl.x509'```### Environment- Ubuntu 22.04.5,- MiniConda, - Python3.8
"
22602,1,0,4,0,0,dragonball-wooboo,0,"title:I want to integrate superset with Prometheus.. description:I want to integrate superset with Prometheus.It has been confirmed that superset does not support Prometheus as a database So after installing trino in the middle, I'm trying to link Prometheus. At that time, trino has a problem in that part.Is there any way to solve this phenomenon?![image](https://user-images.githubusercontent.com/41145660/210735523-7db070aa-3f6f-405d-b595-8cb2fe47d77d.png)
"
22582,1,50,222,0,0,cwegener,0,"title:Python 3.10 support missed from 2.0 branch. description:Python 3.10 support is not included in the 2.0 branch. Was this a deliberate decision or was the relevant commit from master simply overlooked?#### How to reproduce the bug1. Install Python 3.102. `pip install apache-superset<=2.0.0`### Expected resultsApache Superset installation completes### Actual results```        ERROR: Failed building wheel for numpy```### Additional contextWhy was this commit left out from the 2.0 branch? 76d6a9af91a71401d158bc150518b3c9366030ac
"
22574,0,0,2,0,0,stephanclaus,0,"title:Filter for datetime value returns ""Cannot compile Column object until its 'name' is assigned."". description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Build a chart on a data set that contains a datetime column 2. Add this chart to a dashboard3. add a dashboard filter on the datetime column4. apply the filter5. See error### Expected resultsthe chart is filtered by the value### Actual resultsAn error is raised:Cannot compile Column object until its 'name' is assigned.This may be triggered by:Issue 1011 - Superset encountered an unexpected error. #### Screenshots<img width=""601"" alt=""Screenshot 2023-01-03 at 21 32 45"" src=""https://user-images.githubusercontent.com/75787042/210437349-3e65e68a-2841-4f5a-9721-1ec239c73430.png"">### Environment(please complete the following information):- Chrome Version 108.0.5359.124 (Official Build) (x86_64)- superset version: `2.0.0`- connecting to snowflake database### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextSuperset 2.0.0 and snowflake/sqlalchemy seems to have more problems with date time handling. The same approach is working fine if the filter column is a date field.
"
22564,1,0,0,0,0,Raj2598,0,"title:Error message: Excel file format cannot be determined, you must specify an engine manually, while uploading Excel file in superset. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to '...'2. Click on '....'3. Scroll down to '....'4. See error### Expected resultswhat you expected to happen.### Actual resultswhat actually happens.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
22514,1,670,17,0,0,ziadloo,0,"title:Missing ""Extra"" section and CSV upload checkbox for a SQLite database when running the project as a docker container. description:#### How to reproduce the bug1. Start a new container:```$ docker run -d -p 8080:8088 --name superset apache/superset$ docker exec -it superset superset fab create-admin \              --username admin \              --firstname Superset \              --lastname Admin \              --email admin@superset.com \              --password admin$ docker exec -it superset superset db upgrade$ docker exec -it superset superset init```2. Enable adding a new database of SQLite type by adding `PREVENT_UNSAFE_DB_CONNECTIONS = False` to the `/app/superset/config.py` file:```$ docker exec -it superset /bin/bash$ printf ""\nPREVENT_UNSAFE_DB_CONNECTIONS = False\n"" >>  /app/superset/config.py$ exit```3. Restart the container (for good measure, I'm not sure if it is needed):```$ docker restart superset```4. Go to `http://localhost:8080/databaseview/list/` (after login of course)5. Click on the `+ DATABASE` button (top-right corner)6. Click on the `SQLite` box in the opened dialog7. As for the `SQLALCHEMY URI` field, enter `sqlite:////tmp/test.db`8. Click on the `CONNECT` button9. Once you are back to the database list, hover the mouse pointer over the `Actions` column of the newly created database and click on the `Edit` icon10. This will open the `Edit database` dialog for the database, now navigate to the `ADVANCED` tab of the dialog11. Supposedly, there should be an `Extra` accordion with a checkbox letting me enable ""CSV uploads"" for the database. But there's no such section/checkbox### Expected resultsA way to enable CSV uploads for a SQLite database### Actual resultsMissing checkbox for enabling CSV uploads (such a checkbox cannot be found anywhere)#### ScreenshotsThe ""Edit database"" dialog when the project is run using docker:![image](https://user-images.githubusercontent.com/3235521/209203241-d92ef19a-1347-4f7f-ae51-9e237e7b9c27.png)### Environment- browser type and version: Google Chrome Version 108.0.5359.124 (Official Build) (64-bit)- superset version: `$ superset version`: `0.0.0-dev` !!! As mentioned before, I'm running the project using docker.- python version: `Python 3.8.13`- node.js version: `node -v`: `bash: node: command not found` !!! For some reason, the docker does not come with node but it works which makes me wonder why node is mentioned here?- `$ superset --version`:```Loaded your LOCAL configuration at [/app/pythonpath/superset_config.py]Python 3.8.13Flask 2.0.3Werkzeug 2.0.3```### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [闂?] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ 闂傚倸鍊烽懗鍓佹崲濠靛鍊块柨鏇氶檷娴?I have reproduced the issue with at least the latest released version of superset.- [ 闂?] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextThe documentation on how to enable CSV uploads is not showing the same UI as docker's latest. I'm not sure if the documentation is too old or the docker's latest.This is what the documentation shows:https://superset.apache.org/docs/creating-charts-dashboards/exploring-data/#enabling-data-upload-functionality![image](https://user-images.githubusercontent.com/3235521/209205923-e2b71c1c-b70b-45be-aa7a-df46c94bab58.png)But what I see in my docker's latest UI, it's not a tab but an accordion (see the screenshot provided above).
"
22500,1,0,0,0,0,Ashvi213,0,"title:pxoxy issue while running npm run dev-server. description:I was trying to add a custom pluggin with the help of tutorial mentioned in [Building Custom Viz Plugins in Superset v2 (Updated for Monorepo) | Preset](https://preset.io/blog/building-custom-viz-plugins-in-superset-v2/). But at last when I run 'npm run dev-server'. I get the below error (Attaching screenshot for reference)..Please help me to resolve..Do i need to run anyother commands instead of 'npm run dev-server' ? (edited)![MicrosoftTeams-image (4)](https://user-images.githubusercontent.com/115608385/208939603-d4edbc23-cc73-4e09-80cf-4194cb2230cb.png)
"
22495,1,1971,18,0,0,ASchmidtGit,0,"title:Adding DataSet failing (NotImplementedError). description:I want to add a dataset but get an exception#### How to reproduce the bug1. Go to Dataset2. + Dataset3. chose source and view4. click add### Expected resultsThe Dataset should be added### Actual results```Traceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/api/__init__.py"", line 85, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/views/base_api.py"", line 112, in wraps    raise ex  File ""/app/superset/views/base_api.py"", line 109, in wraps    duration, response = time_function(f, self, *args, **kwargs)  File ""/app/superset/utils/core.py"", line 1468, in time_function    response = func(*args, **kwargs)  File ""/app/superset/utils/log.py"", line 245, in wrapper    value = f(*args, **kwargs)  File ""/app/superset/views/base_api.py"", line 82, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/datasets/api.py"", line 257, in post    new_model = CreateDatasetCommand(g.user, item).run()  File ""/app/superset/datasets/commands/create.py"", line 51, in run    dataset.fetch_metadata(commit=False)  File ""/app/superset/connectors/sqla/models.py"", line 1752, in fetch_metadata    new_columns = self.external_metadata()  File ""/app/superset/connectors/sqla/models.py"", line 735, in external_metadata    return get_physical_table_metadata(  File ""/app/superset/connectors/sqla/utils.py"", line 61, in get_physical_table_metadata    database.has_table_by_name(table_name=table_name, schema=_schema_name)  File ""/app/superset/models/core.py"", line 760, in has_table_by_name    return engine.has_table(table_name, schema)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 2331, in has_table    connection = engine.connect()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 2212, in run_callable  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1653, in run_callable    )  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/interfaces.py"", line 479, in has_table    published so that third-party dialects may provide anNotImplementedError```### Environment- browser type: Chrome 108- superset version: 1.5.0- python version: 3.8.12- sqlalchemy: 1.4.45- clickhouse-sqlalchemy: 0.2.3
"
22470,1,0,36,0,0,jurbanhost,0,"title:Charts in tabs don't display until you unfold out of scope filters. description:#### How to reproduce the bug1. Create dashboard with that structure:  Three charts in three tabs, with three dashboard filters, each filter for own tab.  Scope of filter 1 is for tab 1, scope of filter 2 is for tab 2 and scope of filter 3 is for tab 3.  Save this dashboard by name ""bug_report_20221220""    or (bestway)    upload dashboard from file: [dashboard_export_20221220T112259.zip](https://drive.google.com/file/d/1lNKv9E-vifb-uwY438gcK-xHzPNF6Bs-/view?usp=sharing)  Attention! used dataset ""birth_names"" from Examples2. Go to ""Dashboards"" menu item of Superset.3. Click to dashboard by name ""bug_report_20221220""4. You will see that charts in tabs don't display until you unfold out of scope filters.Attention! You may need to open the dashboard ""bug_report_20221220"" twice to reproduce unexpected behavior.### Expected results闂備浇顕х换鎰崲閹版澘绠叉い锝呮ts in tabs will display without you unfold out of scope filters.### Actual results闂備浇顕х换鎰崲閹版澘绠叉い锝呮ts in tabs don't display until you unfold out of scope filters.#### Video of unexpected behavior.[superset filters with charts in tabs bug.wmv](https://drive.google.com/file/d/1xQRkUq1Nxe-Ra8lCTqg7cSBemgTBtCVi/view?usp=sharing)### EnvironmentApache Superset in docker from https://hub.docker.com/r/apache/superset latest version on 2022-12-20.
"
22469,1,0,143,0,0,polmonso,0,"title:UX for saving JSON metadata is misleading. description:We were setting the expanded slice setting via the json metadata of the Dashboard properties which is saved on the modal menu automatically, but if you then save the Dashboard it gets overwritten.#### How to reproduce the bug1. Go to Edit mode of the Dashboard2. Click on the Three dots -> Dashboard Properties -> Advanced3. Change the expanded_slices dictionary4. Save Modal dialog5. **Save Dashboard** instead 6. Reopen the Advanced dashboard properties, the setting is not savedThe way to keep the changes is Discarding the changes, which is counterintuitive.### Expected resultsSave Dashboard should not override the modal dialog saved changes### Actual resultsSave Dashboard overrides the modal dialog saved changes### Environment- browser type and version: Firefox 108.0- superset version: `Version: 1.3.2`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
22468,1,0,0,0,0,sesong11,0,"title:Can't create multi databases have same database name. description:I have multiple PostgreSQL databases with the same database name, when I create the first database is working fine. But when I create a new Database show error Database Creation ErrorA database with the same name already exists.Version: 1.5.2
"
22429,1,0,28,0,0,yashu183,0,"title:docker build failed. description:I cloned the official github repo and I want to build the docker file. So I executed `docker build .`It was failing on `npm run build` in `superset-node` container#### How to reproduce the bug1. clone the officila github repo2. cd superset3. Run `docker build .`### Expected resultsI should see the image that I built ### Actual results<img width=""946"" alt=""Screenshot_20221214_030522"" src=""https://user-images.githubusercontent.com/70622860/207841864-99b86a45-ab33-4e97-9ebc-1bfc694ca500.png"">
"
22428,1,0,28,0,1,yashu183,0,"title:superset-frontend build. description:I cloned the github repo and running `npm run build` in `superset-frontend` directoryThere were so many linting issues and `eslint --fix` or `npm run lint` cant fix them#### How to reproduce the bug1. clone the official giuthub repo2. cd superset-frontend3.Run `npm i` and `npm run build`4. See error### Expected resultsI expect to build the frontend successfully
"
22410,0,0,3,0,0,zufolo441,0,"title:Handlebars doesn't work anymore. description:Hi all, I'm using a lot the new handlebars from 2.0Now, I downloaded latest git, and it doesn't work anymore.I' obtain empty text with CSS content, or html tags.Please see attachments.![Screenshot_20221213_145216](https://user-images.githubusercontent.com/45826835/207347117-d5ee4a11-03d9-4a1a-b772-1d814ac279f2.png)![Screenshot_20221213_145150](https://user-images.githubusercontent.com/45826835/207347131-ea82ea28-c0ef-440f-97e2-9126ba07b8c0.png)
"
22402,0,0,0,0,0,molschimke2,0,"title:Handlebars Chart: ReferenceError: exports is not defined. description:An error is shown whenever a handlebars chart should be configured.#### How to reproduce the bug1. Create a new dashboard and dataset2. add handlebars chart3. Configure the handlebars chart with some metrics4. Hit preview### Expected resultsthe handlebars chart should present the rendered script### Actual resultserror message is shown:""Unexpected errorAn error occurred while rendering the visualization: ReferenceError: exports is not defined""#### Screenshots![2022-12-13_01-19-20](https://user-images.githubusercontent.com/81193827/207194469-6d82495f-98b5-484c-82d3-ec4466a67fe3.png)### Environment(please complete the following information):- browser type and version: Chrome- superset version: latest- python version: not sure- node.js version: not sure- any feature flags active: not sure### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
22393,0,0,5,0,1,opqpop,0,"title:Superset Table UI unusable with infinite scrollbar flashing. description:https://user-images.githubusercontent.com/5566843/207159358-9e2fba12-0cda-405a-9e56-4801387c0748.movSee video where both vertical and horizontal scroll for the table is flashing initially, but is sometimes fixed when we click ""Aggregate"" and then switch back to ""Raw Records"". Doesn't always fix it however#### How to reproduce the bugGo to any Superset Table UI and select a column, then scrollbar starts flashing### Expected resultsNo flashing### Actual resultsSee video### Environment(please complete the following information):- browser type and version: Chrome Version 107.0.5304.110 (Official Build) (arm64)- python version: `python --version`: Python 3.10.8- any feature flags active: none### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.
"
22392,1,12624,0,1,1,erick-enriquez-dd,0,"title:ReportScheduleUnexpectedError when taking screenshots to configure alerts. description:A clear and concise description of what the bug is.Hi everyone, i'm trying to configure superset alerts and reporting (deployed on k8s) but i'm running into a bug when my alert tries to screenshot my chart. I'm running into ReportScheduleUnexpectedError message.#### How to reproduce the bugEnable an Alert in Alerts & Reports  to send a slack message with a screenshot of an existing Chart and view my logs in my worker node as the alert is scheduled.  The following are my superset helm values:```superset:      # -- Install additional packages and do any other bootstrap configuration in this script      # including chrome webdriver for alerting      bootstrapScript: >        #!/bin/bash        apt-get update -y &&\         apt-get install -y --no-install-recommends nano &&\         rm -rf /var/lib/apt/lists/*        pip install psycopg2==2.8.5 redis==3.2.1 pinotdb==0.3.12 sqlalchemy-trino==0.4.1 \          snowflake-sqlalchemy==1.2.4 Authlib==0.15.5        apt-get update && \          wget -q https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb && \          apt-get install -y --no-install-recommends ./google-chrome-stable_current_amd64.deb && \          rm -f google-chrome-stable_current_amd64.deb        export CHROMEDRIVER_VERSION=$(curl --silent https://chromedriver.storage.googleapis.com/LATEST_RELEASE) && \          wget -q https://chromedriver.storage.googleapis.com/${CHROMEDRIVER_VERSION}/chromedriver_linux64.zip && \          unzip chromedriver_linux64.zip -d /usr/bin && \          chmod 755 /usr/bin/chromedriver && \          rm -f chromedriver_linux64.zip        pip install --no-cache gevent psycopg2 redis            if [ ! -f ~/bootstrap ]; then echo ""Running Superset with uid {{        .Values.runAsUser }}"" > ~/bootstrap; fi          # -- A dictionary of overrides to append at the end of superset_config.py - the name does not matter      configOverrides:        feature_flags: |          FEATURE_FLAGS = {              ""ALERT_REPORTS"": True          }          SLACK_API_TOKEN = os.getenv(""SLACK_API_TOKEN"",None)            selenium: |          THUMBNAIL_SELENIUM_USER=""admin""          SCREENSHOT_LOCATE_WAIT = 100          SCREENSHOT_LOAD_WAIT = 600            celery_conf: |          from celery.schedules import crontab              class CeleryConfig(object):            broker_url = f""redis://{env('REDIS_HOST')}:{env('REDIS_PORT')}/0""            imports = ('superset.sql_lab', ""superset.tasks"", ""superset.tasks.thumbnails"", )            result_backend = f""redis://{env('REDIS_HOST')}:{env('REDIS_PORT')}/0""            task_annotations = {                'sql_lab.get_sql_results': {                    'rate_limit': '100/s',                },            }            beat_schedule = {                'reports.scheduler': {                    'task': 'reports.scheduler',                    'schedule': crontab(minute='*', hour='*'),                },                'reports.prune_log': {                    'task': 'reports.prune_log',                    'schedule': crontab(minute=0, hour=0),                },                'cache-warmup-hourly': {                    'task': 'cache-warmup',                    'schedule': crontab(minute='*/30', hour='*'),                    'kwargs': {                        'strategy_name': 'top_n_dashboards',                        'top_n': 10,                        'since': '7 days ago',                    },                }            }          CELERY_CONFIG = CeleryConfig        reports: |          WEBDRIVER_BASEURL=""http://superset:8088/""          WEBDRIVER_BASEURL_USER_FRIENDLY=""https://superset.doordash.team/""          WEBDRIVER_TYPE= ""chrome""          WEBDRIVER_OPTION_ARGS = [              ""--force-device-scale-factor=2.0"",              ""--high-dpi-support=2.0"",              ""--headless"",              ""--disable-gpu"",              ""--disable-dev-shm-usage"",              # This is required because our process runs as root (in order to install pip packages)              ""--no-sandbox"",              ""--disable-setuid-sandbox"",              ""--disable-extensions"",          ]        enable_oauth: |          import os          import logging          from flask_appbuilder.security.manager import AUTH_DB, AUTH_OAUTH          from superset.security import SupersetSecurityManager          # This will make sure the redirect_uri is properly computed, even with SSL offloading          ENABLE_PROXY_FIX = True          OKTA_BASE_URL = os.getenv(""OKTA_BASE_URL"")          if OKTA_BASE_URL is not None:              AUTH_TYPE = AUTH_OAUTH              AUTH_USER_REGISTRATION = True              AUTH_USER_REGISTRATION_ROLE = ""Gamma""              OKTA_KEY = os.getenv(""OKTA_KEY"")              OKTA_SECRET = os.getenv(""OKTA_SECRET"")              OAUTH_PROVIDERS = [                  {                      ""name"": ""okta"",                      ""token_key"": ""access_token"",                      ""icon"": ""fa-circle-o"",                      ""remote_app"": {                          ""client_id"": OKTA_KEY,                          ""client_secret"": OKTA_SECRET,                          ""api_base_url"": OKTA_BASE_URL,                          ""client_kwargs"": {""scope"": ""openid email profile groups""},                          ""access_token_url"": OKTA_BASE_URL + ""token"",                          ""authorize_url"": OKTA_BASE_URL + ""authorize"",                      },                  }              ]              DEFAULT_ROLES = [""Gamma"", ""sql_lab"", ""Dataset Creator"", ""DoorDash Default""]              logger = logging.getLogger(""okta_login"")              class CustomSsoSecurityManager(SupersetSecurityManager):                  def oauth_user_info(self, provider, response=None):                      if provider == ""okta"":                          res = self.appbuilder.sm.oauth_remotes[provider].get(""userinfo"")                          if res.status_code != 200:                              logger.error(""Failed to obtain user info: %s"", res.json())                              return                          userinfo = res.json()                          logger.debug(""User info: %s"", userinfo)                          username, _ = userinfo[""email""].split(""@"")                          return {                              ""username"": username,                              ""name"": userinfo[""name""],                              ""email"": userinfo[""email""],                              ""first_name"": userinfo[""given_name""],                              ""last_name"": userinfo[""family_name""],                          }                  def auth_user_oauth(self, userinfo):                      user = super(CustomSsoSecurityManager, self).auth_user_oauth(userinfo)                      logger.debug(""User roles: %s"", user.roles)                      default_roles = [self.find_role(r) for r in DEFAULT_ROLES]                      # This function is called on every login, so we can't just concatenate                      # default_roles to the end of user.roles. If the user's first role is not                      # Admin or Alpha, potentially extend their roles so that they have                      # DEFAULT_ROLES                      if len(user.roles) == 0 or not user.roles[0].name in ('Admin', 'Alpha'):                          user.roles.extend(r for r in default_roles if r not in user.roles)                      logger.debug(""Update user roles to: %s"", user.roles)                      self.update_user(user)                      return user              CUSTOM_SECURITY_MANAGER = CustomSsoSecurityManager      # Vault injected secrets DB_HOST and DB_PASS in envFromSecrets: ['superset-custom-env'] would override those      # default values from the default envFromSecret: 'superset-env'      # See the envFromSecrets in deployment.yaml, deployment-worker.yaml, init-job.yaml      # https://github.com/apache/superset/blob/master/helm/superset/templates/deployment.yaml      envFromSecrets: ['superset-custom-env']          image:        repository: apache/superset        tag: 1.3.1        pullPolicy: IfNotPresent          # Set to false if bringing your own PostgreSQL.      postgresql:        enabled: false          # The limits below will apply to all Superset components. To set individual resource limitations refer pod specific values can be specified below.      # The pod specific values will overwrite anything that is set here.      resources:        requests:          cpu: 6          memory: 24Gi        limits:          cpu: 6          memory: 24Gi          supersetNode:        connections:          db_host: 'data-platform-superset-cluster.cluster-cz3quezzzfhu.us-west-2.rds.amazonaws.com'        env:          OKTA_BASE_URL: https://doordash.okta.com/oauth2/v1/          OKTA_KEY: vault:secret_v2/data/superset/OKTA_KEY#OKTA_KEY          OKTA_SECRET: vault:secret_v2/data/superset/OKTA_SECRET#OKTA_SECRET          SLACK_API_TOKEN: vault:secret_v2/data/superset/SLACK_API_TOKEN#SLACK_API_TOKEN        podAnnotations:          ""vault.security.banzaicloud.io/vault-addr"": ""https://vault.doordash-int.com""          ""vault.security.banzaicloud.io/vault-path"": ""kubernetes-data00-prod""          ""vault.security.banzaicloud.io/vault-role"": ""superset""          ""vault.security.banzaicloud.io/vault-skip-verify"": ""true""      # Superset beat configuration (to trigger scheduled jobs like reports)      # This pod will trigger scheduled tasks configured in the alerts and reports UI      supersetCeleryBeat:        # -- This is only required if you intend to use alerts and reports        enabled: true      # Superset Celery worker configuration      supersetWorker:        command:          - ""/bin/sh""          - ""-c""          - "". /app/pythonpath/superset_bootstrap.sh; celery --app=superset.tasks.celery_app:app worker"" ```### Expected resultsA successful screenshot and message in slack### Actual resultsI get the following error:```superset Scheduling alert Test2 eta: 2022-12-10 00:40:00                                                                                    闂?superset [2022-12-10 00:40:00,367: INFO/ForkPoolWorker-31] Scheduling alert Test2 eta: 2022-12-10 00:40:00                                             闂?superset Query for Test2 took 170.06 ms                                                                                                 闂?superset [2022-12-10 00:40:00,751: INFO/ForkPoolWorker-31] Query for Test2 took 170.06 ms                                                              闂?superset Screenshotting chart at http://superset:8088/superset/slice/93/?standalone=true                                                                  闂?superset [2022-12-10 00:40:00,764: INFO/ForkPoolWorker-31] Screenshotting chart at http://superset:8088/superset/slice/93/?standalone=true                                         闂?superset Init selenium driver      闂?superset [2022-12-10 00:40:00,767: INFO/ForkPoolWorker-31] Init selenium driversuperset Taking a PNG screenshot or url http://superset:8088/superset/slice/93/?standalone=true&standalone=3                                                                   闂?superset [2022-12-10 00:40:11,678: INFO/ForkPoolWorker-31] Taking a PNG screenshot or url http://superset:8088/superset/slice/93/?standalone=true&standalone=3           闂?superset (Background on this error at: http://sqlalche.me/e/13/2j85)                                                                             闂?superset                                                                                                     闂?superset During handling of the above exception, another exception occurred:                                                                         闂?superset                                                                                                                 闂?superset Traceback (most recent call last):                                                                                              闂?superset  File ""/app/superset/tasks/scheduler.py"", line 71, in execute                                                                                  闂?superset   task_id, report_schedule_id, scheduled_dttm_,                                                                                         闂?superset  File ""/app/superset/reports/commands/execute.py"", line 584, in run                                                                          闂?superset   raise ReportScheduleUnexpectedError(str(ex))                                                                                    闂?superset superset.reports.commands.exceptions.ReportScheduleUnexpectedError: (psycopg2.errors.IdleInTransactionSessionTimeout) terminating connection due to idle-in-transaction timeout                      闂?superset SSL connection has been closed unexpectedly```### EnvironmentDeployed on Kubernetes via helm charts.- browser type and version: chrome 108- superset version: 1.3.1- python version: 3.7.0- node.js version: not installed- any feature flags active:FEATURE_FLAGS = {""ALERT_REPORTS"": True闂?}THUMBNAIL_SELENIUM_USER=""admin""SCREENSHOT_LOCATE_WAIT = 100SCREENSHOT_LOAD_WAIT = 600### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [x ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextI was able to get the screenshots to work fine in staging with the same configuration on the same browser, but not in production. I've verified that the superset user 'admin' has admin permissions and that the chart i'm trying to access exists and that admin is on the list of users allowed to access the chart. The only thing I haven't yet tried is upgrading superset to the latest version.Seems related to [this](https://github.com/apache/superset/issues/17933) unresolved issue
"
22385,0,0,0,0,1,prasadpatunkar,0,"title:Edit dataset button is disabled after superset upgrade to 2.0. description:I upgraded superset from 1.4.0 to firstly 1.5.0 and then 2.0.0When I upgraded to 2.0.0, as a Admin, option to Edit Dataset is disabled (greyed out) when I am on Edit Chart Page.But when I go to Datasets and try to Edit, I am able to Edit the datasets.Is there a feature flag or permission to fix this issue ?
"
22380,1,0,0,0,0,galemoine,0,"title:Error when displaying a Mapbox map in superset. description:When I try to display any Mapbox based chart (MapBox, deck.gl Scatterplot, deck.gl 3D Hexagon etc...) I get a javascript error from mapbox-gl.jsMy points are well displayed but not the map background.MAPBOX_API_KEY is however well valued in the configuration file.#### How to reproduce the bug1. clone the master repository2. add the MAPBOX_API_KEY in the configuration file under /superset/docker/pythonpath_dev/superset_config_docker.py3. add the MAPBOX_API_KEY to .env-non-dev file4. launch docker-compose -f docker-compose-non-dev.yml up -d5. on the deck.gl Demo dashboard the elements are present but the background map is not displayed### Expected resultsThe MapBox chart is well diplayed with a background map### Actual resultsThe elements are well displayed but not the map background.Some javascript errors are present in the console on mapbox-gl.js, it's all the same : Error: t.split is not a function#### Screenshots![image](https://user-images.githubusercontent.com/3499177/206741757-50351e59-2590-4998-a0e2-3021abae3cdb.png)### Environment- browser type and version: Tested with firefox and opera- superset version: 2.0 (master)- python version: 3.8.10- node.js version: v16.13.1- any feature flags active: EMBEDDED_SUPERSET### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextI work on a company network but I also did the test on my personal pc on my own network and I have exactly the same behavior.I also tried to install superset via pip instead of Docker but I still get the same error
"
22375,1,0,0,0,0,nagarajmmu,0,"title:ERROR:flask_appbuilder.security.sqla.manager:DB Creation and initialization failed: (psycopg2.OperationalError) could not translate host name ""db"" to address: Name or service not known. description:Hi TeamI have installed a superset latest version using Docker in Linux (Centos) machine.When I tried to run superset by below docker command, it worked fine, and I am able to login to superset--docker-compose -f docker-compose-non-dev.yml upBut when I tried to run the below docker command, it gave me ERROR: flask_appbuilder.security.sqla.manager:DB Creation and initialization failed: (psycopg2.OperationalError) could not translate host name ""db"" to address: Name or service not known--docker-compose -f docker-compose.yml up#### How to reproduce the bug1. download the superset from git URL: https://github.com/apache/superset.git2. run commandto run superset: docker-compose -f docker-compose.yml up3. in log, I am able to see error: DB Creation and initialization failed: (psycopg2.OperationalError) could not translate host name ""db"" to address: Name or service not known4. also this keep repeating in log.### Expected resultsSuperset should up and running and user should be able to login.#### Screenshots![image](https://user-images.githubusercontent.com/61146310/206593159-729c7ae6-41d6-4e81-9fec-b60bf95e1b0b.png)### Environmentsuperset version: 0.0.0-dev (Latest)python version: 3.8Please let me know, how to resolve this issue.ThanksNagaraj M M
"
22348,0,0,33,0,0,askldjd,0,"title:How to import Snowflake Database with the Encrypted Extra field. description:#### How to reproduce the bugIn the [tutorial](https://superset.apache.org/docs/databases/snowflake/), users may use the `SECURE EXTRA` field to supply a Key Pair as authentication. However, it is not clear how this can be done when the datasources are [configured through YAML](https://superset.apache.org/docs/miscellaneous/importing-exporting-datasources/).I was able to configure the database manually through the UI. However, when I tried to export the same database, the keypair field does not exist. Looking over the codebase, the import seems to suggest that it should be a field called [encrypted_extra](https://github.com/apache/superset/blob/e98943e5805fd23c4b3018bee342873f19ee6546/superset/db_engine_specs/snowflake.py#L299). I tried to supply the `encrypted_extra` field in the datasource yaml, but the field didn't seem to make it (as indicated by the logs). Any guidance would be greatly appreciated.Make sure to follow these steps before submitting your issue - thank you!- [ *] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [* ] I have reproduced the issue with at least the latest released version of superset.- [ *] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
22331,1,0,0,0,0,nagarajmmu,0,"title:Cross filter is not showing up in Superset UI, after enabled in config.py. description:Hi TeamI have installed a superset latest version using Docker in Linux (Centos) machine.While going through the below video, I came to know that CROSS filter option is available in superset., please find the link for reference.[Introducing Advanced Drill-Down Functionality In Apache Superset Using Apache Echarts](https://www.youtube.com/watch?v=7YnpKLZ1PRM)I have observed ""DASHBOARD_CROSS_FILTERS"" is available in superset config.py, I have enabled it, but CROSS FILTER is not showing in chart UI.Please let me know, how can I get CROSS FILTER in superset. I have been waiting for CROSS FILTER and DRILL DOWN feature from last one year.#### How to reproduce the bug1. Got to Charts Menu, 2. Click on New Chart3. Choose a Dataset4. Select ECharts5. Select Pie Chart.6. Click on Create New Chart### Expected resultsIn Pie Chart, under ""DATA"" tab, ""ENABLE DASHBOARD CROSS FILTETS"" checkbox option should be available below the ""FILTERS"", but I am not able to see ""ENABLE DASHBOARD CROSS FILTETS"" checkbox.### Actual resultsIn Pie Chart, under ""DATA"" tab, ""ENABLE DASHBOARD CROSS FILTETS"" checkbox option is not available.#### Screenshots![image](https://user-images.githubusercontent.com/61146310/205734519-66db97f5-99b3-4658-9d74-46c8e34a64e0.png)### Environment- browser type and version: Chrome - v108.0.5359.71- superset version: `0.0.0-dev (Latest)`- python version: `3.8`- any feature flags active: Yes below flags are enabled              ""DASHBOARD_NATIVE_FILTERS"": True,               ""DASHBOARD_CROSS_FILTERS"": TruePlease let me know, how can I get CROSS FILTER, DRILL DOWN features in superset, I am fine to add plugins if available. ThanksNagaraj M M
"
22299,1,0,10,0,0,yunchanggou,0,"title:[Bar chart] Error saying dataset no longer exists after updating chart. description:there is an error when I attemp to create a Bar Chart, it point ' Missing dataset,The dataset associated with this chart no longer exists'#### How to reproduce the bug1. select a Bar chart2. set the DIMENSIONS and METRICS3. clict to 'UPDATE CHART'4. See error### Expected resultsoutput the Bar Chart  i want ### Actual resultspoint the error:#### ScreenshotsMissing dataset,The dataset associated with this chart no longer exists![闂傚倸鍊烽悞锕傚箖閸洖纾块弶鍫涘妽濞呯娀鏌ら幁鎺戝姕婵炲懐濞€閺?https://user-images.githubusercontent.com/85088515/205006847-951ef57c-a12c-4c41-9277-d27ae504027d.png)### Environment(please complete the following information):- browser type and version:google  89.0.4389.90 闂?2 闂?- superset version: `2.0`- python version: `python --3.8`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- I have checked the superset logs for python stacktraces and included it here as text if there are any.-  I have reproduced the issue with at least the latest released version of superset.-  I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context2022-12-01 16:49:25,493:INFO:werkzeug:63.221.140.231 - - [01/Dec/2022 16:49:25] ""POST /superset/log/?explode=events HTTP/1.1"" 200 -2022-12-01 16:49:37,145:INFO:werkzeug:63.221.140.231 - - [01/Dec/2022 16:49:37] ""POST /superset/log/?explode=events HTTP/1.1"" 200 -SupersetSecurityExceptionTraceback (most recent call last):  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/views/utils.py"", line 486, in check_datasource_perms    datasource_id, datasource_type = get_datasource_info(  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/views/utils.py"", line 273, in get_datasource_info    raise SupersetException(superset.exceptions.SupersetException: The dataset associated with this chart no longer existsThe above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/views/base.py"", line 207, in wraps    return f(self, *args, **kwargs)  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/utils/log.py"", line 245, in wrapper    value = f(*args, **kwargs)  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/utils/cache.py"", line 226, in wrapper    response = f(*args, **kwargs)  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/views/utils.py"", line 443, in wrapper    check_perms(*args, **kwargs)  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/views/utils.py"", line 490, in check_datasource_perms    raise SupersetSecurityException(superset.exceptions.SupersetSecurityException: The dataset associated with this chart no longer exists2022-12-01 16:49:41,515:WARNING:superset.views.base:SupersetSecurityExceptionTraceback (most recent call last):  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/views/utils.py"", line 486, in check_datasource_perms    datasource_id, datasource_type = get_datasource_info(  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/views/utils.py"", line 273, in get_datasource_info    raise SupersetException(superset.exceptions.SupersetException: The dataset associated with this chart no longer existsThe above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/views/base.py"", line 207, in wraps    return f(self, *args, **kwargs)  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/utils/log.py"", line 245, in wrapper    value = f(*args, **kwargs)  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/utils/cache.py"", line 226, in wrapper    response = f(*args, **kwargs)  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/views/utils.py"", line 443, in wrapper    check_perms(*args, **kwargs)  File ""/home/zte/workspace/superset/venv/lib/python3.8/site-packages/superset/views/utils.py"", line 490, in check_datasource_perms    raise SupersetSecurityException(superset.exceptions.SupersetSecurityException: The dataset associated with this chart no longer exists2022-12-01 16:49:41,517:INFO:werkzeug:63.221.140.231 - - [01/Dec/2022 16:49:41] ""GET /superset/explore_json/ HTTP/1.1"" 403 -
"
22291,1,0,0,0,0,CraigChaffee,0,"title:Copy To Clipboard loses falsy values. description:A clear and concise description of what the bug is.SQL Lab copy results loses all falsy values. #### How to reproduce the bug1. Go to 'SQL Lab'2. Query ""select 0 as a, 1 as b, false as c;""3. Click COPY TO CLIPBOARD### Expected results""0\t1\tfalse""what you expected to happen.Falsy values should not be filtered.### Actual results""\t1\t""what actually happens.Filtering #### ScreenshotsIf applicable, add screenshots to help explain your problem.<img width=""439"" alt=""Screenshot 2022-11-30 at 10 15 44 PM"" src=""https://user-images.githubusercontent.com/13027874/204979597-108aa417-574e-4ba5-a7e6-ecca02d7f6be.png"">### Environment(please complete the following information):- browser type and version:Chrome- superset version: `superset version` 1.5.2 and replicated in the latest release.- python version: `python --version` 3 something### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ x ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ x ] I have reproduced the issue with at least the latest released version of superset.- [ x ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
22290,1,4002,78,0,0,josechudev,0,"title:Fail to login via LDAP: werkzeug.exceptions.NotFound: 404 Not Found: The requested URL was not found on the server. description:#### How to reproduce the bug1. pull the v0.7.7 of the helm chart2. apply the next ldap configs:```bootstrapScript: |  #!/bin/bash  rm -rf /var/lib/apt/lists/* && \  apt-get update -y && apt-get install -y python3-dev libldap2-dev libsasl2-dev ldap-utils tox lcov valgrind  pip install python-ldap==3.4.3 \  pip install \    psycopg2-binary==2.9.1 \    redis==3.5.3 && \  if [ ! -f ~/bootstrap ]; then echo ""Running Superset with uid {{ .Values.runAsUser }}"" > ~/bootstrap; ficonfigOverrides:  enable_ldap: |        from flask_appbuilder.security.manager import AUTH_LDAP      SESSION_COOKIE_SAMESITE = 'None'      AUTH_TYPE = AUTH_LDAP      AUTH_USER_REGISTRATION = False      AUTH_LDAP_USE_TLS = False      AUTH_LDAP_SERVER = ""ldap://host:port""      AUTH_LDAP_BIND_USER = ""CN=bind user,OU=Devops,DC=xx,DC=xx,DC=xx,DC=xx,DC=io""      AUTH_LDAP_BIND_PASSWORD = ""pass""      AUTH_LDAP_UID_FIELD = ""sAMAccountName""      AUTH_LDAP_SEARCH_FILTER = ""(sAMAccountName=%s)""      AUTH_LDAP_SEARCH = ""OU=Devops,DC=xx,DC=az,DC=platform,DC=xx,DC=io""      AUTH_LDAP_FIRSTNAME_FIELD = ""givenName""      AUTH_LDAP_LASTNAME_FIELD = ""sn""      AUTH_LDAP_EMAIL_FIELD = ""mail""      AUTH_ROLES_SYNC_AT_LOGIN = True            AUTH_LDAP_GROUP_FIELD = ""memberOf""      AUTH_ROLES_MAPPING = {          ""CN=devops_admins,OU=devops,DC=xx,DC=xx,DC=xx,DC=xx,DC=io"": [""Admin""],          ""*"": [""Viewer""]       }      ```### Expected resultsSuccessful login### Actual results```[01/Dec/2022:00:29:20 +0000] ""POST /login/ HTTP/1.1"" 302 220 ""https://host/login/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:107.0) Gecko/20100101 Firefox/107.0""[01/Dec/2022:00:29:20 +0000] ""GET /login/ HTTP/1.1"" 200 25343 ""-"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:107.0) Gecko/20100101 Firefox/107.0""[01/Dec/2022:00:29:22 +0000] ""GET /static/assets/theme.18064043eb90700c676a.entry.css.map HTTP/1.1"" 304 0 ""-"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:107.0) Gecko/20100101 Firefox/107.0""HTTPExceptionTraceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1516, in full_dispatch_request    rv = self.dispatch_request()  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1502, in dispatch_request    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)  File ""/usr/local/lib/python3.8/site-packages/flask/scaffold.py"", line 332, in send_static_file    return send_from_directory(  File ""/usr/local/lib/python3.8/site-packages/flask/helpers.py"", line 700, in send_from_directory    return werkzeug.utils.send_from_directory(  # type: ignore  File ""/usr/local/lib/python3.8/site-packages/werkzeug/utils.py"", line 847, in send_from_directory    raise NotFound()werkzeug.exceptions.NotFound: 404 Not Found: The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.2022-12-01 00:29:22,369:WARNING:superset.views.base:HTTPExceptionTraceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1516, in full_dispatch_request    rv = self.dispatch_request()  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1502, in dispatch_request    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)  File ""/usr/local/lib/python3.8/site-packages/flask/scaffold.py"", line 332, in send_static_file    return send_from_directory(  File ""/usr/local/lib/python3.8/site-packages/flask/helpers.py"", line 700, in send_from_directory    return werkzeug.utils.send_from_directory(  # type: ignore  File ""/usr/local/lib/python3.8/site-packages/werkzeug/utils.py"", line 847, in send_from_directory    raise NotFound()werkzeug.exceptions.NotFound: 404 Not Found: The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.[01/Dec/2022:00:29:22 +0000] ""GET /static/appbuilder/css/bootstrap.min.css.map HTTP/1.1"" 404 0 ""-"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:107.0) Gecko/20100101 Firefox/107.0""```### Environment(please complete the following information):- browser type and version: Mozilla Firefox107.0 (64-bit)- superset helm v0.7.7### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context- Add any other context about the problem here.- We are currently running superset on a Rancher cluster- We have already configured Grafana with the same LDAP values and it has worked- I have installed python-ldap already- I have tried reinstalling gunicornThanks
"
22281,1,0,4,0,0,alekssakovsky,0,"title:When are opened superset iframe (as embedDashboard) and superset ui in different tabs, one of them is off.. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to 'one of page with embedDashboard'2. Go to '.../superset/welcome/'4. See error![image](https://user-images.githubusercontent.com/39739131/204879123-13ce387f-89ff-4dee-a7fa-20582a2b9ff4.png)### Expected resultsboth work
"
22268,1,0,4,0,0,nailuox,0,"title:Error attempting to connect to clickhouse. description:#### How to reproduce the bugtest connect can success![204700433-1a969835-0620-4608-aac4-91df8fe875b3](https://user-images.githubusercontent.com/49058926/204701390-bc0088be-80ac-487c-9940-1f4f6b626023.png)An error is reported when saving. The refreshed page has actually been saved successfully and an error is reported when editing data![204700626-660579d9-9b72-4020-9c13-0ee37b993b8d](https://user-images.githubusercontent.com/49058926/204701382-270b0663-e68a-48d6-8a01-2912309ba11c.png)![image](https://user-images.githubusercontent.com/49058926/204701529-83540b84-8ccf-4bc5-a078-cc61563b5603.png)### Expected resultswhat you expected to happen.### Actual resultswhat actually happens.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: `master branch latest`- python version: `3.8.1`- node.js version: `16.18.0`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
22261,0,0,4,0,0,cbuffevant,0,"title:Templates are not being rendered in dataset metrics. description:Templates used in dataset metrics are not being rendered at all when used in charts.#### How to reproduce the bugI was able to replicate the issue running Superset locally followint this instructions https://superset.apache.org/docs/installation/installing-superset-using-docker-compose.1. Go to Datasets2. Open `flights` dataset3. Create a new metric with this information > name: my_metric> label: My Metric> SQL: sum(case when '{{ time_grain}}' = 'P1W' then 1 when '{{ time_grain}}' = 'P1D' then -1 else 0 end)4. Save the dataset5. Go to create a new Chart (for example, Time Series bar chart, v2)6. Select `flights` dataset7. Drop `My Metric` into the Metric section of the chart8. Update the chart.9. Create a new adhoc metric with the same SQL code than the dataset metric.10. Update the chart.### Expected resultsBoth metrics should display the same information.### Actual resultsThe dataset metrics is set to 0 while the ad hoc metric has the right values.If you go to check the actual query, you will see that the template `{{ time_grain }}` is not rendered in the dataset metric case.#### Screenshots![image](https://user-images.githubusercontent.com/8312839/204580212-cccf3dff-e6df-485f-8159-f8d6ff8ed160.png)![image](https://user-images.githubusercontent.com/8312839/204580362-cae1af84-6e99-4cd8-8cd7-c925f34f1771.png)![image](https://user-images.githubusercontent.com/8312839/204580412-a17d9391-755f-46df-b598-0d5018407fd4.png)![image](https://user-images.githubusercontent.com/8312839/204580553-4e03ec20-d23d-4b63-a36f-f725a5d69746.png)![image](https://user-images.githubusercontent.com/8312839/204580620-39da2985-db13-4d82-930f-8999cf4724b3.png)### Environment- browser type and version: Chrome 107.0.5304.110 (Official Build) (x86_64)- superset version: I just clone the repo and use non-dev docker-compose script.- python version: `3.10.6`- node.js version: `12.0`- any feature flags active: `ENABLE_TEMPLATE_PROCESSING`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any. (No stack trace produced).- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextI uploaded a video to the Superset Slack channel with the steps to replicated it.https://apache-superset.slack.com/files/U02U4GLFWJC/F04CWRUQ1RR/superset_-_29_november_2022.mp4
"
22259,1,0,0,0,0,anas1509,0,"title:error getting credentials - err: exit status 1, out: `Cannot autolaunch D-Bus without X11 $DISPLAY`. description:A clear and concise description of what the bug is.I'm facing the below issue just after I try to run the container with docker compose, here is a screenshot of it![Screenshot 2022-11-29 123628](https://user-images.githubusercontent.com/67197816/204493102-75ece4f3-edb9-4bee-9ad1-dc565af2aadc.png)Appreciate your support and thanks a lot.
"
22258,1,4095,15,0,1,adimyth,0,"title:403 Forbidden error when trying to embed a dashboard & view it using a guest user token. description:I am trying to embed a superset dashboard into a simple front-end application. However, when the embedded dashboard always throws `403: Forbidden`. I am pretty sure I have set the correct permissions and everything. I even tried accessing it using `admin` user, still it fails.## How to reproduce the bugThe source for the application can be found here - https://github.com/adimyth/superset_embedded### `superset` applicationAdded the following configuration in `superset_config.py````pythonFEATURE_FLAGS = {""ALERT_REPORTS"": True, ""EMBEDDED_SUPERSET"": True}SESSION_COOKIE_SAMESITE = NoneENABLE_PROXY_FIX = TruePUBLIC_ROLE_LIKE_GAMMA = TrueCORS_OPTIONS = {    'supports_credentials': True,    'allow_headers': ['*'],    'resources': ['*'],    'origins': ['http://localhost:8088', 'http://localhost:8000']}```This gave me the following dashboard it to embed into my application![Screenshot 2022-11-29 at 2 28 54 PM](https://user-images.githubusercontent.com/26377913/204484479-755a7e0b-8cf8-45b2-8b41-1038ea9dd631.png)### `frontend` application```html<head>    <script src=""https://unpkg.com/@preset-sdk/embedded""></script>    <style>        iframe {            height: 100%;            width: 100%;            border: none;        }    </style></head><body>    <p id=""dashboard-container""> </p>    <script>        // 1. Request guest_token from our backend, which runs at localhost:8000 by default             async function fetchGuestTokenFromBackend() {                let response = await fetch('http://127.0.0.1:8000/guest-token');                let data = await response.json()                return data        }        // 2. Uses Preset Embedded SDK to embed the dashboard as iFrame        const myDashboard = presetSdk.embedDashboard({          id: ""{{ DASHBOARD_ID }}"",          supersetDomain: ""{{ SUPERSET_DOMAIN }}"",          mountPoint: document.getElementById(""dashboard-container""),          fetchGuestToken: () => fetchGuestTokenFromBackend(),          dashboardUiConfig: { hideTitle: true, hideChartControls: true}        });    </script></body>```The frontend simply calls the `/guest-token` from backend and passes it to the `presetSdk.embedDashboard`### `backend` applicationThe `/guest-token` endpoint simply calls 2 methods from the helper (superset.py) file```python@app.get(""/guest-token"")async def analytics_view(request: Request):    access_token = superset.authenticate()    guest_token = superset.get_guest_token_for_dashboard(        dashboard_id=DASHBOARD_ID, access_token=access_token    )    return guest_token```The helper has 2 methods - `authenticate()` which authenticates the superset-admin user & `get_guest_token_for_dashboard` which is used to generate access token for the guest user```pythonimport jsonimport osimport requestsfrom dotenv import load_dotenvload_dotenv()URL_AUTH = os.getenv(""URL_AUTH"")URL_GUEST_TOKEN = os.getenv(""URL_GUEST_TOKEN"")USERNAME = os.getenv(""USERNAME"")FIRST_NAMER = os.getenv(""FIRST_NAMER"")LAST_NAME = os.getenv(""LAST_NAME"")def authenticate(    username=""admin"",    password=""admin"",):    response = requests.post(        ""http://localhost:8088/api/v1/security/login"",        headers={            ""Content-Type"": ""application/json"",            ""Accept"": ""application/json"",            ""Access-Control-Allow-Origin"": ""http://localhost:8000"",        },        data=json.dumps(            {                ""username"": username,                ""password"": password,                ""provider"": ""db""            }        ),    )    return response.json()[""access_token""]def get_guest_token_for_dashboard(    dashboard_id,    access_token,    username=USERNAME,    first_name=FIRST_NAMER,    last_name=LAST_NAME,):    response = requests.post(        URL_GUEST_TOKEN,        data=json.dumps(            {                ""user"": {                    ""username"": username,                    ""first_name"": first_name,                    ""last_name"": last_name,                },                ""resources"": [                    {                        ""type"": ""dashboard"",                        ""id"": dashboard_id,                    }                ],                ""rls"": [],            }        ),        headers={            ""Authorization"": ""Bearer "" + access_token,            ""Accept"": ""application/json"",            ""Content-Type"": ""application/json"",        },    )    return response.json()[""token""]```Finally we pass environment variables. Note that the `DASHBOARD_ID` matches from the screenshot above. Also note that I am passing superset-admin creds to the embedded dashboard```URL_AUTH=http://localhost:8088/api/v1/security/loginURL_GUEST_TOKEN=http://localhost:8088/api/v1/security/guest_token/USERNAME=adminFIRST_NAMER=SupsersetLAST_NAME=AdminDASHBOARD_ID=b0a944b2-4ab5-47b7-a31d-c3eca4c36397SUPERSET_DOMAIN=http://localhost:8088/```## ErrorWhen loading the frontend application which has the embedded dashboard, it returns -```{""errors"": [{""message"": ""403 Forbidden: You don't have the permission to access the requested resource. It is either read-protected or not readable by the server."", ""error_type"": ""GENERIC_BACKEND_ERROR"", ""level"": ""error"", ""extra"": {""issue_codes"": [{""code"": 1011, ""message"": ""Issue 1011 - Superset encountered an unexpected error.""}]}}]}```## Expected resultsI was expecting to see the actual dashboard in the frontend application## Actual results![Screenshot 2022-11-29 at 2 37 17 PM](https://user-images.githubusercontent.com/26377913/204486368-d21af1ac-7b20-4d5e-9981-958f41d43ea5.png)What's surprising is that after decoding the guest token, we can clearly see that the user is superset admin & has access to the dashboard 婵犵妲呴崑鎾跺緤娴犲鐤柕濠忓椤?![Screenshot 2022-11-29 at 2 39 15 PM](https://user-images.githubusercontent.com/26377913/204486870-af11d0a1-d0af-4d6e-979f-a3a7d98ada2c.png)### Environment(please complete the following information):- browser type and version: Chrome- superset version: Built from the latest code as of 29th Nov- python version: 3.9- node.js version: NA- any feature flags active: `{""ALERT_REPORTS"": True, ""EMBEDDED_SUPERSET"": True}`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
22241,1,423,71,0,0,ruijielou,0,"title:addAlpha is not to be rgb(x,x,x). description:```typescriptexport function addAlpha(color: string, opacity: number): string {  // opacity value should be between 0 and 1.  if (opacity > 1 || opacity < 0) {    throw new Error(`The opacity should between 0 and 1, but got: ${opacity}`);  }  // the alpha value is between 00 - FF  const alpha = `0${Math.round(opacity * 255)    .toString(16)    .toUpperCase()}`.slice(-2);  return `${color}${alpha}`;}```This method does not take rgb color conversion into account, which will lead to incorrect results, such as' rgb (209124178) 98 ';
"
22237,0,2627,17,0,0,programmeddeath1,0,"title:Unable to Edit Clickhouse Database Settings in Superset. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to Databases and go to Actions for existing Clickhouse Database2. Click on the edit icon under actions.3. It fails with ""An error ocurred while fetching the databases"" as shown in screenshot.4. See error popup at the bottom and nothing shows up in the edit database window.### Expected resultsIt should show the edit database options to change the IP or port etc.### Actual resultsIt shows a blank edit database screen![ClickhouseSupersetError](https://user-images.githubusercontent.com/44861370/204212506-d2e98de2-204a-4011-910f-ca4fe25abbaa.png)#### ScreenshotsIf applicable, add screenshots to help explain your problem.### EnvironmentSuperset docker setup (please complete the following information):- browser type and version:- superset version: `latest-dev`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [闂傚倸鍊烽悞锕傚礈濮樿泛鍌ㄥù鐘差儐閸?I have checked the superset logs for python stacktraces and included it here as text if there are any.```_delta_humanized&sortOrder=desc"" ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36""superset_app            | Object of type immutabledict is not JSON serializablesuperset_app            | Traceback (most recent call last):superset_app            |   File ""/app/superset/views/base.py"", line 210, in wrapssuperset_app            |     return f(self, *args, **kwargs)superset_app            |   File ""/app/superset/views/base_api.py"", line 409, in get_headlesssuperset_app            |     duration, response = time_function(super().get_headless, pk, **kwargs)superset_app            |   File ""/app/superset/utils/core.py"", line 1555, in time_functionsuperset_app            |     response = func(*args, **kwargs)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/api/__init__.py"", line 1398, in get_headlesssuperset_app            |     return self.response(200, **_response)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/api/__init__.py"", line 704, in responsesuperset_app            |     _ret_json = jsonify(kwargs)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask/json/__init__.py"", line 361, in jsonifysuperset_app            |     f""{dumps(data, indent=indent, separators=separators)}\n"",superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask/json/__init__.py"", line 139, in dumpssuperset_app            |     rv = _json.dumps(obj, **kwargs)superset_app            |   File ""/usr/local/lib/python3.8/json/__init__.py"", line 234, in dumpssuperset_app            |     return cls(superset_app            |   File ""/usr/local/lib/python3.8/json/encoder.py"", line 199, in encodesuperset_app            |     chunks = self.iterencode(o, _one_shot=True)superset_app            |   File ""/usr/local/lib/python3.8/json/encoder.py"", line 257, in iterencodesuperset_app            |     return _iterencode(o, 0)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask/json/__init__.py"", line 57, in defaultsuperset_app            |     return super().default(o)superset_app            |   File ""/usr/local/lib/python3.8/json/encoder.py"", line 179, in defaultsuperset_app            |     raise TypeError(f'Object of type {o.__class__.__name__} 'superset_app            | TypeError: Object of type immutabledict is not JSON serializablesuperset_app            | 2022-11-28 07:03:55,630:ERROR:superset.views.base:Object of type immutabledict is not JSON serializable```- [闂傚倸鍊烽悞锕傚礈濮樿泛鍌ㄥù鐘差儐閸?I have reproduced the issue with at least the latest released version of superset.- [闂傚倸鍊烽悞锕傚礈濮樿泛鍌ㄥù鐘差儐閸?I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
22235,0,0,189,0,0,tooptoop4,0,"title:CVEs on 2.0.1 docker image. description:i pulled docker image for 2.0.1rc4findings:upgrade Pillow to 9.3.0 to resolve CVE-2022-30595, CVE-2022-45198, CVE-2022-45199upgrade Flask-Caching to 1.11.0 to resolve CVE-2021-33026upgrade Werkzeug to 2.1.1 to resolve CVE-2022-29361upgrade aiohttp to 3.8.3 to resolve CVE-2022-33124curl is also affected by CVE-2022-42916 , can it be removed from the image?
"
22215,1,0,0,0,0,AnanthaGopi0,0,"title:Microsoft SQL server as metadata is not suppoted . description:but I am getting errors doing the ""Superset DB upgrade"".sqlalchemy.exc.ProgrammingError: (pymssql._pymssql.ProgrammingError) (208, b""Invalid object name 'alembic_version'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n"")[SQL: UPDATE alembic_version SET version_num='b4456560d4f3' WHERE alembic_version.version_num = 'bb51420eaf83']is there any alternate solution for that to configure the mssql server as metadata to the superset.![image](https://user-images.githubusercontent.com/115773598/203705559-683b8ebc-8f5f-45b3-a935-fc5945fe5bbc.png)- browser type and version:- superset version: 1.3.0- python version: 3.8.8- node.js version: - any feature flags active: THUMBNAILS, ALERT_REPORTS, VERSIONED_EXPORT### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ok ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ok ] I have reproduced the issue with at least the latest released version of superset.- [[ok](url) ] I have checked the issue tracker for the same issue and I haven't found one similar.Add any other context about the problem here.
"
22203,0,516,14,0,0,xingyuli,0,"title:Dataset list: schema not allowed to filter. description:On the `Datasets` page, I cannot search by utilizing the SCHEMA filter.#### How to reproduce the bug1. Go to 'Data -> Datasets'2. Choose from the 'SCHEMA' drop down list.3. See error### Expected resultsShould be work.### Actual resultsIt just says 'HTTP 400 bad requests' ...#### Screenshots![image](https://user-images.githubusercontent.com/3337431/203502261-fbc57462-8497-4065-8189-0387e3cab7fd.png)Superset log:```[23/Nov/2022:16:34:12 +0800] ""GET /api/v1/dataset/?q=(filters:!((col:schema,opr:eq,value:information_schema)),order_column:changed_on_delta_humanized,order_direction:desc,page:0,page_size:25) HTTP/1.1"" 400 58 ""http://superset.k8s-dev/tablemodelview/list/?filters=(schema:(label:information_schema,value:information_schema))&pageIndex=0&sortColumn=changed_on_delta_humanized&sortOrder=desc"" ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36""```### Environment(please complete the following information):- superset version: `2.0.0`
"
22189,0,0,28,0,0,mayurnewase,1,"title:[reports] GET chart/<pk>/data api doesn't respect force parameter. description:A clear and concise description of what the bug is.Api to get data of a saved chart used by reports to send csv data doesn't respect force parameter resulting in reports having stale data.#### How to reproduce the bug1. setup caching for data and report2. create table chart, so it caches the data3. change the data in the datasource without busrting cache of the chart4. create report with csv and enable `Ignore cache when generating screenshot`5. see the report having stale data.### Expected resultsAs `Ignore cache when generating screenshot` is enabled, report should have fresh data from datasource.Or this option is only for reports with screenshot as its name suggests?### Actual resultsReport has stale data.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: 1.5.1 and 2.0- python version: `python --version`- node.js version: `node -v`- any feature flags active: ALERT_REPORTS### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
22166,1,0,5,0,0,rabindragogoi,0,"title:Cannot upgrade from superset 1.3.0 to 1.5.3 :- db upgrade failure. description:Upgrading superset version from 1.3.0 to 1.5.2. It is throwing error as : ==============================================MySQLdb._exceptions.OperationalError: (1054, ""Unknown column 'dbs.allow_csv_upload' in 'field list'"")and sqlalchemy.exc.OperationalError: (MySQLdb._exceptions.OperationalError) (1054, ""Unknown column 'dbs.allow_csv_upload' in 'field list'"")[SQL: SELECT dbs.uuid AS dbs_uuid, dbs.created_on AS dbs_created_on, dbs.changed_on AS dbs_changed_on, dbs.id AS dbs_id, dbs.verbose_name AS dbs_verbose_name, dbs.database_name AS dbs_database_name, dbs.sqlalchemy_uri AS dbs_sqlalchemy_uri, dbs.password AS dbs_password, dbs.cache_timeout AS dbs_cache_timeout, dbs.select_as_create_table_as AS dbs_select_as_create_table_as, dbs.expose_in_sqllab AS dbs_expose_in_sqllab, dbs.configuration_method AS dbs_configuration_method, dbs.allow_run_async AS dbs_allow_run_async, dbs.allow_csv_upload AS dbs_allow_csv_upload, dbs.allow_ctas AS dbs_allow_ctas, dbs.allow_cvas AS dbs_allow_cvas, dbs.allow_dml AS dbs_allow_dml, dbs.force_ctas_schema AS dbs_force_ctas_schema, dbs.allow_multi_schema_metadata_fetch AS dbs_allow_multi_schema_metadata_fetch, dbs.extra AS dbs_extra, dbs.encrypted_extra AS dbs_encrypted_extra, dbs.impersonate_user AS dbs_impersonate_user, dbs.server_cert AS dbs_server_cert, dbs.created_by_fk AS dbs_created_by_fk, dbs.changed_by_fk AS dbs_changed_by_fkFROM dbsWHERE dbs.id = %s][parameters: (1,)](Background on this error at: http://sqlalche.me/e/13/e3q8)====================================### Expected resultsSuperset upgrade should happen.### Actual resultsSuperset upgrade failing as it is not able to fetch the metadata from mysql.- browser type and version: chrome- superset version: `superset version` = version 1.5.2- python version: `python --version` = 3.8Checklist:- [ yes ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ yes  ] I have reproduced the issue with at least the latest released version of superset.- [yes  ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextPlease need urgent help in superset upgradation from version 1.3.0 to 1.5.2
"
22141,0,0,0,0,0,wrb2,0,"title:Documentation lists old Trino driver. description:Even though new Trino driver should be `trino-python-client` as per https://github.com/apache/superset/pull/19957,  the documentation section [Installing Database Drivers](https://superset.apache.org/docs/databases/installing-database-drivers) still lists deprecated `sqlalchemy-trino`.File link: https://github.com/apache/superset/blob/master/docs/docs/databases/installing-database-drivers.mdxInstead of `pip install sqlalchemy-trino` it should say `pip install trino`. The connect string stays the same.
"
22139,1,575,194,0,0,rohitpawar2811,0,"title:Ldap Auth setup can't debug what is the problem. description:A clear and concise description of what the bug is.**My configurations**```from flask_appbuilder.security.manager import AUTH_LDAPAUTH_TYPE = AUTH_LDAP AUTH_ROLE_ADMIN = 'admin'AUTH_USER_REGISTRATION = True AUTH_LDAP_SERVER = ""ldap://localhost:389""# AUTH_LDAP_SEARCH=""ou=people,dc=superset,dc=com""AUTH_LDAP_SEARCH= ""cn=admin,dc=ramhlocal,dc=com""# AUTH_LDAP_APPEND_DOMAIN = ""XXX.com""AUTH_LDAP_UID_FIELD=""cn""AUTH_LDAP_FIRSTNAME_FIELD= ""Rohit""AUTH_LDAP_LASTTNAME_FIELD= ""sn""AUTH_LDAP_USE_TLS = FalseAUTH_LDAP_BIND_USER= ""ou=people,dc=superset,dc=com""AUTH_LDAP_ALLOW_SELF_SIGNED= TrueAUTH_LDAP_APPEND_DOMAIN= False```**Expected results**It will make me log onto superset by using ldap user.**Actual results**I can't log to superset by normal password as well the ldap one password. And I can be able to debug because no error came related to ldap.**Environment**- superset version: `superset-2.0.0-dev`**I already did**I install the python-ldap package in my container.Just I want a way to get **logs** of what i am making wrong , yet i can't get any msg related to ldap in all container logs .Any way
"
22117,1,0,0,0,0,kalyan4uonly,0,"title:Create a default custom role in superset. description:Hi,I am new to superset, how we can create a default custom role like gamma, alpha etc.. with specific permissions programmatically? Could anyone explain me in detail.Thanks
"
22105,0,0,27,0,0,sker65,0,"title:Helm Chart does not work if you enable celery beat with extraConfigs. description:If you deploy to k8s with the official helm chart and do enable celery beat pod for scheduled email reports the pod spec does not include extraConfigs if you configured any.This leads to a crash loop as the celery beat pod refuses to start, if the flask app is somehow dependent on this extra config.While is is included in the worker pods, it is not in the celery beat pod (kind of inconsistent as is basically the same flask app that needs to load).#### How to reproduce the bug1. create an extra config that includes a file (in my example it is the client_secret.json, that the customSecurityManager want to load at startup time).2. Add a celery config like described in the example here: https://superset.apache.org/docs/installation/alerts-reports/3. Activate the celery beat like describe in doc over here: https://superset.apache.org/docs/installation/alerts-reports/ 4. Try to apply the helm chart5. The celery start command will crash as soon as it tries to load the appsee also https://github.com/apache/superset/blob/master/helm/superset/templates/deployment-beat.yaml (extraConfigs section missing in template)vs https://github.com/apache/superset/blob/master/helm/superset/templates/deployment-worker.yaml#L109 (extraConfigs included if set)### Expected resultscelery beat pod should start as normal superset or superset-workers do### Actual resultscelery beat pod goes into crash loop / refuses to start### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stack traces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.
"
22099,1,3465,194,0,0,rohitpawar2811,0,"title:chromedriver' executable needs to be in PATH. description:**Facing problem in report sending through mail**```[2022-11-11 11:53:00,175: ERROR/ForkPoolWorker-8] A downstream exception occurred while generating a report: 352d7d4c-54aa-45ac-8fbe-010079f2036bsuperset_worker          | Traceback (most recent call last):superset_worker          |   File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/common/service.py"", line 72, in startsuperset_worker          |     self.process = subprocess.Popen(cmd, env=self.env,superset_worker          |   File ""/usr/local/lib/python3.8/subprocess.py"", line 858, in __init__superset_worker          |     self._execute_child(args, executable, preexec_fn, close_fds,superset_worker          |   File ""/usr/local/lib/python3.8/subprocess.py"", line 1704, in _execute_childsuperset_worker          |     raise child_exception_type(errno_num, err_msg, err_filename)superset_worker          | FileNotFoundError: [Errno 2] No such file or directory: 'chromedriver'superset_worker          | superset_worker          | During handling of the above exception, another exception occurred:superset_worker          | superset_worker          | Traceback (most recent call last):superset_worker          |   File ""/app/superset/reports/commands/execute.py"", line 217, in _get_screenshotssuperset_worker          |     image = screenshot.get_screenshot(user=user)superset_worker          |   File ""/app/superset/utils/screenshots.py"", line 76, in get_screenshotsuperset_worker          |     self.screenshot = driver.get_screenshot(self.url, self.element, user)superset_worker          |   File ""/app/superset/utils/webdriver.py"", line 111, in get_screenshotsuperset_worker          |     driver = self.auth(user)superset_worker          |   File ""/app/superset/utils/webdriver.py"", line 89, in authsuperset_worker          |     driver = self.create()superset_worker          |   File ""/app/superset/utils/webdriver.py"", line 86, in createsuperset_worker          |     return driver_class(**kwargs)superset_worker          |   File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/chrome/webdriver.py"", line 73, in __init__superset_worker          |     self.service.start()superset_worker          |   File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/common/service.py"", line 81, in startsuperset_worker          |     raise WebDriverException(superset_worker          | selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home```selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home```**What i Did**I just run an docker-compose file and added these configurationsFEATURE_FLAGS = {    ""DYNAMIC_PLUGINS"": True,    ""ENABLE_TEMPLATE_PROCESSING"": True,    ""VERSIONED_EXPORT"": True,    ""ALERT_REPORTS"": True}SCREENSHOT_LOCATE_WAIT = 1000SCREENSHOT_LOAD_WAIT = 1600 # Email configuration#THUMBNAIL_SELENIUM_USER = 'admin@mydomain.com'ENABLE_SCHEDULED_EMAIL_REPORTS = TrueSMTP_HOST = ""smtp.gmail.com""SMTP_USER = ""@gmail.com""SMTP_PASSWORD = ""XXXX""SMTP_PORT = ""465""SMTP_SSL = FalseSMTP_STARTTLS = FalseSMTP_MAIL_FROM = ""xxxx@gmail.com""# WebDriver configurationWEBDRIVER_TYPE = ""chrome""WEBDRIVER_OPTION_ARGS = [    ""--force-device-scale-factor=2.0"",    ""--high-dpi-support=2.0"",    ""--headless"",    ""--disable-gpu"",    ""--disable-dev-shm-usage"",    ""--no-sandbox"",    ""--disable-setuid-sandbox"",    ""--disable-extensions"",]```Should i have to download the chrome-Driver in container , i think not so **how can i give path to executable driver of crome** selenium.common.exceptions.WebDriverException: **Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home**```
"
22087,1,0,194,0,0,rohitpawar2811,0,"title:werkzeug.exceptions.NotFound and get_screenshot() error. description: werkzeug.exceptions.NotFound:404 Not Found: The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.I have simple compose the docker-compose -f docker-compose.yml up -dAnd i getting this And 2nd one is get_screenshot() this method is giving error when i apply email-alert to my report then i got this``superset_worker          | [2022-11-10 05:35:01,172: ERROR/ForkPoolWorker-7] A downstream exception occurred while generating a report: e11bc1a7-635d-4ac1-9004-6deeec9fdd96[2022-11-10 05:36:01,197: ERROR/ForkPoolWorker-7] A downstream exception occurred while generating a report: 4b1d334b-9b57-4513-88d8-c2b1e56b6b72superset_worker          | Traceback (most recent call last):superset_worker          |   File ""/app/superset/reports/commands/execute.py"", line 217, in _get_screenshotssuperset_worker          |     image = screenshot.get_screenshot(user=user)superset_worker          |   File ""/app/superset/utils/screenshots.py"", line 76, in get_screenshotsuperset_worker          |     self.screenshot = driver.get_screenshot(self.url, self.element, user)superset_worker          |   File ""/app/superset/utils/webdriver.py"", line 111, in get_screenshotsuperset_worker          |     driver = self.auth(user)superset_worker          |   File ""/app/superset/utils/webdriver.py"", line 89, in authsuperset_worker          |     driver = self.create()superset_worker          |   File ""/app/superset/utils/webdriver.py"", line 86, in createsuperset_worker          |     return driver_class(**kwargs)superset_worker          |   File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/firefox/webdriver.py"", line 170, in __init__superset_worker          |     RemoteWebDriver.__init__(superset_worker          |   File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py"", line 157, in __init__superset_worker          |     self.start_session(capabilities, browser_profile)superset_worker          |   File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py"", line 252, in start_sessionsuperset_worker          |     response = self.execute(Command.NEW_SESSION, parameters)superset_worker          |   File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py"", line 321, in executesuperset_worker          |     self.error_handler.check_response(response)superset_worker          |   File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py"", line 242, in check_responsesuperset_worker          |     raise exception_class(message, screen, stacktrace)superset_worker          | selenium.common.exceptions.InvalidArgumentException: Message: Argument --marionette can't be set via capabilitiessuperset_worker          | superset_worker          | superset_worker          | The above exception was the direct cause of the following exception:superset_worker          | superset_worker          | Traceback (most recent call last):superset_worker          |   File ""/app/superset/tasks/scheduler.py"", line 85, in executesuperset_worker          |     AsyncExecuteReportScheduleCommand(superset_worker          |   File ""/app/superset/reports/commands/execute.py"", line 681, in runsuperset_worker          |     raise exsuperset_worker          |   File ""/app/superset/reports/commands/execute.py"", line 677, in runsuperset_worker          |     ReportScheduleStateMachine(superset_worker          |   File ""/app/superset/reports/commands/execute.py"", line 639, in runsuperset_worker          |     state_cls(superset_worker          |   File ""/app/superset/reports/commands/execute.py"", line 540, in nextsuperset_worker          |     raise first_exsuperset_worker          |   File ""/app/superset/reports/commands/execute.py"", line 518, in nextsuperset_worker          |     self.send()superset_worker          |   File ""/app/superset/reports/commands/execute.py"", line 415, in sendsuperset_worker          |     notification_content = self._get_notification_content()superset_worker          |   File ""/app/superset/reports/commands/execute.py"", line 335, in _get_notification_contentsuperset_worker          |     screenshot_data = self._get_screenshots()superset_worker          |   File ""/app/superset/reports/commands/execute.py"", line 222, in _get_screenshotssuperset_worker          |     raise ReportScheduleScreenshotFailedError(superset_worker          | superset.reports.comm``uperset.reports.commands.exceptions.ReportScheduleScreenshotFailedError: Failed taking a screenshot Message: Argument --marionette can't be set via capabilities **Reproduce_Bug**simple compose the docker-compose -f docker-compose.yml up -d
"
22062,0,0,48,0,0,hushaoqing,0,"title:[bug]: Always jump to the first Tab when using search button. description:Always jump to the first Tab when using search button#### How to reproduce the bugwatch the video below### Expected resultskeep the current Tab### Actual resultsAlways jump to the first Tab#### Screenshots[If applicable, add screenshots to help explain your problem.](https://user-images.githubusercontent.com/10289162/200560516-273de480-c4b2-42f1-bdbe-5eb154b1277b.mov)### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
22025,1,0,28,0,0,yashu183,0,"title:Excel sheet upload throwing 500 error. description:I am uploading an excel sheet but superset is throwing 500 Internal Server ErrorIt uploads files to this directory `UPLOAD_FOLDER = BASE_DIR + ""/app/static/uploads/""``BASE_DIR ` is the superset directory in `site-packages` but I cant find `app` directory in `superset` directoryOn dev server its shown File not found error
"
22005,1,3881,7,0,0,e-geist,0,"title:Embedding Dashboards denied when cross origin. description:Hi,we tried embedding a dashboard with the Superset Embed SDK and ran into CORS problems when trying to load the iframe cross origin.Embedding the dashboard with a local port-forward to the remote Superset works fine, as they have the same origin then (localhost).### How to reproduce the bug1. Host superset somewhere other than localhost.2. Go to superset and allow embedding any dashboard for any url.3. Build page using Superset Embed SDK and embed aforementioned Dashboard + appropriate code for login + guest token fetching (see below for minimal example).4. Load built page locally (other origin than Superset)### Expected resultsDashboard is visibly embedded in page without errors.### Actual results**HTTP request of embed sdk is answered with HTTP code 200, but prohibits embedding the content.**HTTP Header Response:```HTTP/2 200 OKaccess-control-allow-origin: *content-encoding: brcontent-security-policy: frame-ancestors http://* https://*content-type: text/html; charset=utf-8date: Wed, 02 Nov 2022 11:30:04 GMTpermissions-policy: interest-cohort=()referrer-policy: strict-origin-when-cross-originserver: gunicornset-cookie: session=eyJjc3JmX3Rva2VuIjoiYzNiYTBhODVhZWFiMThmMWI0OGIwZDU4Y2FiMTVhNmIyM2I3OTA4ZSIsImxvY2FsZSI6ImVuIn0.Y2JUvA.5Fk-ksgyXTH6QVATgPGXrpAXT5M; Secure; HttpOnly; Path=/; SameSite=Laxstrict-transport-security: max-age=31536000; includeSubDomains; preloadvary: Accept-Encoding, Cookiex-content-type-options: nosniffx-frame-options: DENYx-xss-protection: 1; mode=blockcontent-length: 24285```HTTP Header Request:```GET /embedded/454cd010-3fcf-46f7-8ede-ae4ee7cfaca7?uiConfig=9 HTTP/2Host: <remote page>User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8Accept-Language: de,en-US;q=0.7,en;q=0.3Accept-Encoding: gzip, deflate, brConnection: keep-aliveReferer: http://localhost:3000/Upgrade-Insecure-Requests: 1Sec-Fetch-Dest: iframeSec-Fetch-Mode: navigateSec-Fetch-Site: cross-siteTE: trailers```### Environment- browser type and version: Firefox 91.0, Microsoft Edge 107.0.1418.26- superset environment: Kubernetes in Azure- Superset version: 2.0.0 (container from dockerhub with tag 2.0.0 + clickhouse-driver) with most up2date official helm-chart (0.7.6 at the time)- Superset Embed UI SDK: https://www.npmjs.com/package/@superset-ui/embedded-sdk/v/0.1.0-alpha.7 - used via [unpkg](https://unpkg.com/@superset-ui/embedded-sdk)- relevant config options from helm-chart values.yaml:```# flask_confWTF_CSRF_ENABLED = FalseSESSION_COOKIE_SAMESITE = None  ENABLE_CORS = True  CORS_OPTIONS = {    ""send_wildcard"": True,    ""allow_headers"": [""*""],    ""resources"":[""*""],    ""origins"": [""*""]  }# talisman_configTALISMAN_ENABLED = TrueTALISMAN_CONFIG = {  ""content_security_policy"": ""frame-ancestors http://* https://*"",  ""force_https"": False,  ""force_https_permanent"": False,  ""frame_options"": ""ALLOWFROM"",  ""frame_options_allow_from"": ""*""}GUEST_ROLE_NAME = 'Guest_role_name_with_enough_permissions'GUEST_TOKEN_JWT_SECRET = ""test_secret""GUEST_TOKEN_JWT_ALGO = ""HS256""GUEST_TOKEN_HEADER_NAME = ""X-GuestToken""GUEST_TOKEN_JWT_EXP_SECONDS = 3600FEATURE_FLAGS = {  ""EMBEDDED_SUPERSET"": True,  ""DASHBOARD_RBAC"": True}```### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context#### Previously worked successfullyFor a very short amount of time (1.5d) embedding worked flawlessly. We thought it might have sth to do with the Superset version - but neither 2.0.0 nor latest (top of master) worked.#### CORS optionsWe tried different combinations of CORS and Talisman options, but neither of them worked.It seems that no matter what options are chosen, **x-frame-options is always ""DENY""**Overwriting HTTP_HEADERS with HTTP_HEADERS = {} or any other values doesn't have an effect either.#### Python logsLogin and guest token retrieval are logged as successful in logs. When retrieving embedded dashboard, a warning is shown:```2022-11-02 11:30:04,259:WARNING:root:Class 'werkzeug.local.LocalProxy' is not mapped10.244.6.170 - - [02/Nov/2022:11:30:04 +0000] ""GET /embedded/454cd010-3fcf-46f7-8ede-ae4ee7cfaca7?uiConfig=9 HTTP/1.1"" 200 24285 ""http://localhost:3000/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:91.0) Gecko/20100101 Firefox/91.0""```#### Minimal embedding codeEmbedding was also tried in other environments (Website with PHP backend) and doesn't work either.**The security login and retrieval of the guest token in the backend for frontend work flawless - the problem occurs only after the embed sdk uses the guest token.**Frontend (embedded in otherwise empty HTML document) - supersetEmbeddedSdk is imported in head via unpkg:```var fetchGuestTokenFromBackend = async function () {                response = await fetch(""http://localhost:3000/fetchGuestToken"", { method: 'POST' })                responseText = await response.text()                return responseText            };            supersetEmbeddedSdk.embedDashboard({                id: ""454cd010-3fcf-46f7-8ede-ae4ee7cfaca7"", // given by the Superset embedding UI                supersetDomain: <superset_domain>,                mountPoint: document.getElementById(""my-superset-container""), // any html element that can contain an iframe                fetchGuestToken: fetchGuestTokenFromBackend,                dashboardUiConfig: { hideTitle: true, hideChartControls: true }            });```Backend for frontend (Node with express js and got for requests):```app.post('/fetchGuestToken', async (req, res) => {  const responseLogin = await got.post('<superset_domain>/api/v1/security/login', {    json: {      username: <guest_token_user>,      password: <guest_token_user>,      provider: 'db'    }  }).json()  const responseGuestToken = await got.post(""<superset_domain>/api/v1/security/guest_token/"", {    json: {      ""user"": { ""username"": ""someuser"", ""first_name"": ""MyApp User"", ""last_name"": ""MyApp User"" },       ""resources"": [{ ""type"": ""dashboard"", ""id"": ""454cd010-3fcf-46f7-8ede-ae4ee7cfaca7"" }],       ""rls"": [{ ""clause"": ""sth = 'sth'"" }]    },    headers: {      ""Authorization"": `Bearer ${responseLogin.access_token}`    }  }).json();  res.send(responseGuestToken.token)});```We are not sure whether this is a problem on the embedding SDK side or Superset itself. If any information is missing or we can try some other options please let us know, as we need to rely on this feature in the near future.Thank you very much!
"
21987,0,0,3,0,0,tharunkc-93,0,"title:Embed dashboard on v2.0 generates the following error and throws a 500 internal server error. description:Error log below for reference`'LoginManager' object has no attribute 'reload_user'Traceback (most recent call last):  File ""/root/superset/lib/python3.8/site-packages/flask/app.py"", line 1523, in full_dispatch_request    rv = self.dispatch_request()  File ""/root/superset/lib/python3.8/site-packages/flask/app.py"", line 1509, in dispatch_request    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)  File ""/root/superset/lib/python3.8/site-packages/superset/utils/log.py"", line 243, in wrapper    value = f(*args, add_extra_log_payload=log, **kwargs)  File ""/root/superset/lib/python3.8/site-packages/superset/embedded/view.py"", line 60, in embedded    login_manager.reload_user(AnonymousUserMixin())AttributeError: 'LoginManager' object has no attribute 'reload_user'2022-11-01 11:35:46,896:ERROR:superset.views.base:'LoginManager' object has no attribute 'reload_user'Traceback (most recent call last):  File ""/root/superset/lib/python3.8/site-packages/flask/app.py"", line 1523, in full_dispatch_request    rv = self.dispatch_request()  File ""/root/superset/lib/python3.8/site-packages/flask/app.py"", line 1509, in dispatch_request    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)  File ""/root/superset/lib/python3.8/site-packages/superset/utils/log.py"", line 243, in wrapper    value = f(*args, add_extra_log_payload=log, **kwargs)  File ""/root/superset/lib/python3.8/site-packages/superset/embedded/view.py"", line 60, in embedded    login_manager.reload_user(AnonymousUserMixin())AttributeError: 'LoginManager' object has no attribute 'reload_user'`![WhatsApp Image 2022-11-01 at 12 10 26 AM](https://user-images.githubusercontent.com/104201903/199183269-47630e8d-1e21-4b05-9dbc-e25025e18d2e.jpeg)
"
21983,1,1547,50,0,1,yanickrochon,0,"title:ImportError: cannot import name 'safe_str_cmp' from 'werkzeug.security' after upgrade. description:After performing `pip install apache-superset --upgrade`, the command terminated successfully and `pipdeptree` shows all dependencies met correctly.However trying to start superset I get```Traceback (most recent call last):  File ""/path/to/bin/superset"", line 5, in <module>    from superset.cli.main import superset  File ""/path/to/lib/python3.8/site-packages/superset/__init__.py"", line 21, in <module>    from superset.app import create_app  File ""/path/to/lib/python3.8/site-packages/superset/app.py"", line 23, in <module>    from superset.initialization import SupersetAppInitializer  File ""/path/to/lib/python3.8/site-packages/superset/initialization/__init__.py"", line 26, in <module>    from flask_appbuilder import expose, IndexView  File ""/path/to/lib/python3.8/site-packages/flask_appbuilder/__init__.py"", line 5, in <module>    from .api import ModelRestApi  # noqa: F401  File ""/path/to/lib/python3.8/site-packages/flask_appbuilder/api/__init__.py"", line 24, in <module>    from ..baseviews import AbstractViewApi  File ""/path/to/lib/python3.8/site-packages/flask_appbuilder/baseviews.py"", line 22, in <module>    from .forms import GeneralModelConverter  File ""/path/to/lib/python3.8/site-packages/flask_appbuilder/forms.py"", line 3, in <module>    from flask_wtf import FlaskForm  File ""/path/to/lib/python3.8/site-packages/flask_wtf/__init__.py"", line 3, in <module>    from .csrf import CSRFProtect, CsrfProtect  File ""/path/to/lib/python3.8/site-packages/flask_wtf/csrf.py"", line 10, in <module>    from werkzeug.security import safe_str_cmpImportError: cannot import name 'safe_str_cmp' from 'werkzeug.security' (/path/to/lib/python3.8/site-packages/werkzeug/security.py)```#### How to reproduce the bug1. Upgrade to Superset 2.0.02. Start superset4. See error### Expected resultsNo error.### Actual resultsCannot import name `safe_str_cmp` from `werkzeug.security` because of deprecation of [`pbkdf2_hex`, `pbkdf2_bin`, and `safe_str_cmp`](https://blog.appseed.us/how-to-fix-cannot-import-safe_str_cmp-from-werkzeug/)### Environment(please complete the following information):- superset version: `2.0.0`- python version: `3.8.2`- node.js version: n/a- any feature flags active: n/a### Checklist- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.The issue also happens when running `superset db upgrade`.
"
21977,1,5053,0,0,0,gpineda-dev,0,"title:API : create new slice from existing dataset -- 'Dataset' object has no attribute 'perm'. description:Hello, here I am .. my first issue on GitHub I hope to fulfill correctly the requirements, otherwise, feel free to mention it to help improving myself.After spending time replicating over hours the creation of charts, I wanted to automate the process. Through the exposed **API** I am now able to create a database, a new dataset however I meet some errors while trying to **generate a chart linked to an existing database**.Indeed as described in the swagger documentation, it should be possible to specify the existing dataset id with its type to instantiate a new chart linked to it by setting `datasource_type` to `dataset` however this led to a `Fatal Error` code.Then I followed the error stack to target precisely this error :- [superset.models.slice](https://github.com/apache/superset/blob/bf001931c8c7e58a211e411fa74ca4991c6aa2a8/superset/models/slice.py#L354) requires a `.perm` / `schema_perm` - property on fetched [`src_class`](https://github.com/apache/superset/blob/bf001931c8c7e58a211e411fa74ca4991c6aa2a8/superset/models/slice.py#L127) - `src_class` is coming from [`superset.datasource.dao.DatasourceDAO.sources`](https://github.com/apache/superset/blob/bf001931c8c7e58a211e411fa74ca4991c6aa2a8/superset/datasource/dao.py#L38) and corresponding type should be `Type[""BaseDatasource""]`-  [`superset.dataset.models.Dataset`](https://github.com/apache/superset/blob/bf001931c8c7e58a211e411fa74ca4991c6aa2a8/superset/datasets/models.py#L73) is not a child class of `BaseDatasource` .. as a result, `.perm` is not an available property.as mentioned the `Dataset` model [`shouldn't be used yet`](https://github.com/apache/superset/blob/bf001931c8c7e58a211e411fa74ca4991c6aa2a8/superset/datasets/models.py#L20).In my case, I need a virtual dataset since tables name is not unique within multiple databases.#### How to reproduce the bug> I use https://pypi.org/project/superset-api-client/ as client but I tried the same with native python lib + curl.Please find below a complete example including the use of the client (this may help others to understand this REST interface).```pythonimport osfrom supersetapiclient.databases import Databasefrom requests import Response# Prepare the clientos.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'client = SupersetClient(    host='http://localhost:8080',    password = 'admin',    username = 'admin',)# Setup the dbn_database = {    'database_name': 'issue-github',    'sqlalchemy_uri': 'mysql+mysqldb://myuser:mypassword@192.168.2.1:3362/mediator-db',    'expose_in_sqllab': True,    'allow_ctas': True,    'allow_cvas': True,    'allow_dml' : True}rep: Response = client.post(client.databases.base_url, json = n_database )# Setup a dataset + sync columnsdb = client.databases.find_one(database_name=n_database['database_name'])n_dataset = {    'table_name': 'mediator_log',    'schema': 'mediator-db',    'database': db.id,    # the following commented lines are not yet supported by the api ... unfortunately     # 'kind': 'virtual',    # 'sql': 'SELECT * FROM `mediator-db`.mediator_log',}rep: Response = client.post(client.datasets.base_url, json= n_dataset)dset = client.datasets.find_one(table_name = n_dataset['table_name'])dset.table_name = 'issue-github'dset.kind = 'virtual'dset.sql   = 'SELECT * FROM mediator_log'dset.save()client.put(client.datasets.base_url + f'/{k.id}/refresh')# Try to create a new chart linked to the previously generated datasetn_chart = {    'datasource_id': dset.id,    'datasource_type': 'dataset',    'slice_name': 'chartX',    # 'params': json.dumps({    #     'groupby': ['fwd_port', 'uses_internet_proxy'],     #     'metric': 'count'    # }),    'description': 'ici vient ma description',    'viz_type': 'pie'}k: Response = client.post(client.charts.base_url, json = n_chart) print(k.json()) # ERROR returned```### Expected resultsAs described in the swagger documentation : > ![grafik](https://user-images.githubusercontent.com/36532817/198905310-ad1914f5-c491-49cc-b889-b8f0ac7af10d.png)### Actual results> {'message': 'Fatal error'}**Superset logs :**```log2022-10-30 21:53:48,001:ERROR:root:'Dataset' object has no attribute 'perm'Traceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/api/__init__.py"", line 86, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/views/base_api.py"", line 114, in wraps    raise ex  File ""/app/superset/views/base_api.py"", line 111, in wraps    duration, response = time_function(f, self, *args, **kwargs)  File ""/app/superset/utils/core.py"", line 1574, in time_function    response = func(*args, **kwargs)  File ""/app/superset/utils/log.py"", line 244, in wrapper    value = f(*args, **kwargs)  File ""/app/superset/views/base_api.py"", line 84, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/charts/api.py"", line 304, in post    new_model = CreateChartCommand(item).run()  File ""/app/superset/charts/commands/create.py"", line 48, in run    chart = ChartDAO.create(self._properties)  File ""/app/superset/dao/base.py"", line 131, in create    db.session.commit()  File ""<string>"", line 2, in commit  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 1435, in commit    self._transaction.commit(_to_root=self.future)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 829, in commit    self._prepare_impl()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 808, in _prepare_impl    self.session.flush()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 3367, in flush    self._flush(objects)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 3507, in _flush    transaction.rollback(_capture_exception=True)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py"", line 70, in __exit__    compat.raise_(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 207, in raise_    raise exception  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 3467, in _flush    flush_context.execute()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py"", line 456, in execute    rec.execute(self)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py"", line 630, in execute    util.preloaded.orm_persistence.save_obj(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py"", line 212, in save_obj    for (  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py"", line 385, in _organize_states_for_save    mapper.dispatch.before_insert(mapper, connection, state)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/event/attr.py"", line 343, in __call__    fn(*args, **kw)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/events.py"", line 743, in wrap    fn(*arg, **kw)  File ""/app/superset/models/slice.py"", line 354, in set_related_perm    target.perm = ds.permAttributeError: 'Dataset' object has no attribute 'perm'172.17.0.1 - - [30/Oct/2022:21:53:48 +0000] ""POST /api/v1/chart/ HTTP/1.1"" 500 26 ""http://localhost:8080/api/v1"" ""python-requests/2.28.1""```#### Screenshots### Environment- browser type and version:  `python-requests/2.28.1`- superset version: `Superset 0.0.0-dev`- python version: `3.8.13`- node.js version: `??`- any feature flags active:     - SUPERSET_WEBSERVER_TIMEOUT=600     - FAB_API_SWAGGER_UI=1     - ROW_LIMIT=150000### ChecklistMake sure to follow these steps before submitting your issue - thank you!- - [x]  I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextRunning in docker, image `apache/superset@sha256:5fab9c506b7e0e92a94d77568959ac37f898756914cdda36723719cb5758af60` pulled from dockerhub
"
21972,0,264,17,1,0,gebhardtr,0,"title:error when creating superset-websocket container. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Run `docker-compose up`### Expected resultsAll containers are created without error### Actual results```npm WARN EBADENGINE Unsupported engine {npm WARN EBADENGINE   package: 'superset-websocket@0.0.1',npm WARN EBADENGINE   required: { node: '^16.9.1', npm: '^7.5.4' },npm WARN EBADENGINE   current: { node: 'v16.18.0', npm: '8.19.2' }npm WARN EBADENGINE }```what actually happens.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version: N/A- superset version: commit `efefb66c2de15b66af0c18a2e70910e29ce9447c`- python version: 3.9.15- node.js version: 16.18.0- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.https://github.com/apache/superset/issues/18615 appears to be related, but it's larger in scope than this issue.### Additional contextAdd any other context about the problem here.
"
21910,1,0,15,0,0,lwandrebeck,0,"title:PostgreSQL 15.0 - There was an error loading the schemas and the tables. description:Rocky Linux 9, Superset 2.0.0 (virtual env install).Superset databaseview/list page does not show anymore available databases (without displaying any error), and thus data upload is not possible anymore. Existing dataset is still usable. Used to work fine with PostgreSQL 14 (pg_upgrade was used to get from 14 to 15, so previous rights when it comes to schemas were kept).superset tables are in public schema, superset data tables are in superset_data schema.#### How to reproduce the bug1. Go to data (top menu)2. Click on databases3. databaseview/list page is displayed4. database list is empty### Expected resultsPage should list available databases.### Actual resultsPage shows no available database.#### Screenshots![image](https://user-images.githubusercontent.com/2599010/197227496-4ef977ea-0457-463e-b040-8340e034f063.png)![image](https://user-images.githubusercontent.com/2599010/197227796-41f5d21c-c529-4980-bd2f-e160804fdd92.png)### Environment(please complete the following information):- browser type and version: Firefox 106.0.1- superset version: Superset 2.0.0- python version: Python 3.9.10- node.js version: not installed- any feature flags active: --certfile=/home/XXX/YYY.crt --keyfile=/home/XXX/YYY.key -b ip:port -w 10 -k gevent --worker-connections 1000 --timeout 120 --limit-request-line 0 --limit-request-field_size 0 --pid /run/superset/superset.pid ""superset.app:create_app()### Checklist- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextsuperset init has been run, no change.No error on postgresql, celery, redis sides either.I already have upgraded a couple other things from PG14 to PG15 without problem (nextcloud, mediawiki闂? so I suspect there闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?something fishy on superset side.Thanks for your support !
"
21829,1,945,11,0,1,baguskna,0,"title:export to .CSV in embedding superset not working. description:Hi, I have successfully embedded the dashboard and we want feature export to .CSV , but it is not working it said```Blocked opening 'URL' in a new window because the request was made in a sandboxed frame whose 'allow-popups' permission is not set.Blocked form submission to 'URL' because the form's frame is sandboxed and the 'allow-forms' permission is not set.```I was able to override the iframe with this way    ```    const embed = await embedDashboard({      id: dashboardId,      supersetDomain: URL,      mountPoint: document.querySelector(""#superset-id""),      fetchGuestToken: () => guestToken,      dashboardUiConfig: {        hideTitle: true,        hideChartControls: false,        hideTab: true,      },    });    const size = await embed.getScrollSize();    if (size.width !== 0) {      const iframe = document.querySelector(""iframe"") as HTMLIFrameElement;      iframe.setAttribute(        ""sandbox"",        ""allow-same-origin allow-scripts allow-presentation allow-downloads allow-forms allow-popups allow-popups-to-escape-sandbox""      );    }    ```still it returns the same error as I mentioned above, by any chance is there a way we can fix this?
"
21784,1,41,97,0,0,artemonsh,0,"title:localized words within template literal (`${t('word')}`) don't go into messages.pot. description:It seems that all variables that are delimited by a dollar sign like this: ```{`${t('Start (Longitude, Latitude)')}: `}``` are not being transferred to the messages.pot and messages.po files, hence no translation could be made.#### How to reproduce the bug1. Go to any file that contains template literals that contain dollar sign, e.g. [superset/superset-frontend/plugins/legacy-preset-chart-deckgl/src/layers/Arc/Arc.jsx](https://github.com/apache/superset/blob/8f74e46d45ca94f5656f7b881f1096c16657c829/superset-frontend/plugins/legacy-preset-chart-deckgl/src/layers/Arc/Arc.jsx#L40) or [superset/superset-frontend/plugins/plugin-chart-pivot-table/src/react-pivottable/TableRenderers.jsx](https://github.com/apache/superset/blob/8f74e46d45ca94f5656f7b881f1096c16657c829/superset-frontend/plugins/plugin-chart-echarts/src/Pie/controlPanel.tsx#L127)2. Open [messages.pot](https://github.com/apache/superset/blob/master/superset/translations/messages.pot) and find out that these words/phrases are absent.### Expected resultsI expect to see all words/phrases wrapped in `t()` function inside messages.pot.### Actual resultsWords that are located inside [template literals](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals) do not go into messages.pot file.### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
21783,1,378,97,0,0,artemonsh,0,"title:No translation for ControlPanel because of react-pivottable lack of flexibility. description:When trying to use AGGREGATION FUNCTIONS like _Sum_ or _Sample Variance_ for chart Pivot Table v2 (or v1), one cannot translate them simply in .po and .json files, because an error occures.![image](https://user-images.githubusercontent.com/53895552/195346573-e07f24ca-5e93-4cae-898b-b70b59d705fc.png)#### How to reproduce the bug0. Add translation for one of the aggregation functions and change the locale1. Go to 'Charts'2. Click on 'Pivot Chart v2'3. Scroll down to 'Options'4. Choose any translated option![image](https://user-images.githubusercontent.com/53895552/195347448-fd70aad2-1e79-46c3-a0c9-487e473f1d2f.png)### Expected resultsI want to have an opportunity to translate the name of the aggregation functions.### Actual resultsSimple translation causes an error.### Environment(please complete the following information):- browser type and version: chrome- superset version: `2.0.0`- python version: `python 3.8`- node.js version: `node 16`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### SuggestionsI suggest to change variable aggregatorsFactory in the file superset-frontend/plugins/plugin-chart-pivot-table/src/PivotTableChart.tsxThe function looks like this:```const aggregatorsFactory = (formatter: NumberFormatter) => ({  'List Unique Values': aggregatorTemplates.listUnique(', ', formatter),  Sum: aggregatorTemplates.sum(formatter)}```while it should look like this:```const aggregatorsFactory = (formatter: NumberFormatter) => ({  t('List Unique Values'): aggregatorTemplates.listUnique(', ', formatter),  t('Sum'): aggregatorTemplates.sum(formatter)}```I know that it is impossible to use function result as the key for the object, but due to the lack of knowledge I cannot suggest a good way to replace keys of this object.Another suggestion is to change `formatSelectOptions()` function to accept both value and label, now it accepts only one value (both for value and label)
"
21777,1,0,2,0,0,gcoder5,0,"title:about add database for clickhouse. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to Main Page2. Click on Connect database3. select Clickhouse4. if my clickhouse password incloude '@' or '+',i will test connect failure.### Expected resultswhen my password incloude  '@' or '+', i can test connect successful and add database successful.### Actual results test connect failure.#### ScreenshotsIf applicable, add screenshots to help explain your problem.![image](https://user-images.githubusercontent.com/55041518/195230668-8e6f4ab1-b3ac-4d86-a945-ed792fe17ed5.png)### Environment(please complete the following information):- browser type and version:chrome 105.0.5195.125- docker images version:apache/superset     latest### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ 闂傚倸鍊烽悞锕傚礈濮樿泛鍌ㄥù鐘差儐閸?I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ 闂傚倸鍊烽悞锕傚礈濮樿泛鍌ㄥù鐘差儐閸?I have reproduced the issue with at least the latest released version of superset.- [ 闂傚倸鍊烽悞锕傚礈濮樿泛鍌ㄥù鐘差儐閸?I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context
"
21756,1,0,0,0,0,mtv2102,0,"title:Is there Api to fetch chart data (with filter applied) from dashboard?. description:I have tried using api such as 'api/v1/chart/data?format=json' to fetch chart data in json format. But when I try to fetch the chart data with filter applied on dashboard, I couldn't  find any api so far.I have checked with the following url..http://localhost:8088/swagger/v1 . It has listed the set of supported api's.Among that i have found something like,  `api/v1/dashboard/14(dashboard_id)/charts `But I couldn't find any api to get the filtered chart data ...Filter Applied<img width=""194"" alt=""image"" src=""https://user-images.githubusercontent.com/112002949/194867660-ee15d1ef-0809-4a47-8393-8f0f9475b337.png"">Chart Data with applied filter in dashboard<img width=""380"" alt=""image"" src=""https://user-images.githubusercontent.com/112002949/194867743-b52db6a7-81ea-475e-b73f-93591bdfeb87.png"">I have spent my entire day on trying this, but couldn't find.Any help / guidance would be appreciated.
"
21755,1,148,23,0,0,HeathLee,0,"title:x-aixs alias name same as original field name. description:When using [Apache Doris](https://doris.apache.org/) (compatible with MySQL protocol) as database and enabled GENERIC_CHART_AXES feature, the sql generated by superset can not be executed correctly.#### How to reproduce the bug1. Enable `GENERIC_CHART_AXES` feature2. Explore doris dataset as below![image](https://user-images.githubusercontent.com/7382922/194853777-a6b1b9e0-3d97-42ea-901e-8d78ff705576.png)### Expected resultsgenerated sql should have different alias name in `select` clause like```sqlSELECT DATE(c_at) AS c_at_aliased,       COUNT(*) AS countFROM doris_db.table_xxxGROUP BY DATE(c_at)ORDER BY count DESCLIMIT 10000;```or user can custome alias x-aixs name### Environment- superset version: `master at d1a6f0ebc4e2dd092580ad49da7c724c577e6ece`- any feature flags active:`GENERIC_CHART_AXES: true`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
21745,1,6734,41,0,0,EMCP,0,"title:Supersets Trino integration not able to list table schemas. description:I can successfully connect using both the `hive` and `ubuntu` user in the connection string.. however when I go to create a dataset.. no tables or schemas are being listed.. with either userI can confirm the tables exist, I can query it in the SQL Lab.. I just cannot proceed from there.#### How to reproduce the bugAdd a Trino DB with a catalog in the connection stringOnce connected try to add a dataset with a known existing table### Expected resultsit should allow me to make a dataset so I can create charts### Actual resultsits blank and you cannot proceed#### Screenshots![image](https://user-images.githubusercontent.com/3691722/194712937-bb996b78-bd99-4fc9-a1f8-29231e55103e.png)### Environment```Superset 2.0.0TRINO 399HIVE + S3 + Parquetpypi trino==0.315.0 (I cannot connect with latest 0.317.0 )```### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ X] I have reproduced the issue with at least the latest released version of superset.- [ X] I have checked the issue tracker for the same issue and I haven't found one similar.StackTrace when clicking in the screenshotted area````The above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/home/ubuntu/.local/lib/python3.8/site-packages/superset/models/core.py"", line 606, in get_all_view_names_in_schema    views = self.db_engine_spec.get_view_names(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/superset/db_engine_specs/trino.py"", line 103, in get_view_names    return BaseEngineSpec.get_view_names(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/superset/db_engine_specs/base.py"", line 1007, in get_view_names    views = inspector.get_view_names(schema)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/reflection.py"", line 325, in get_view_names    return self.dialect.get_view_names(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/trino/sqlalchemy/dialect.py"", line 214, in get_view_names    res = connection.execute(sql.text(query), schema=schema)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 2235, in execute    return connection.execute(statement, *multiparams, **params)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1011, in execute    return meth(self, multiparams, params)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 298, in _execute_on_connection    return connection._execute_clauseelement(self, multiparams, params)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1124, in _execute_clauseelement    ret = self._execute_context(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1316, in _execute_context    self._handle_dbapi_exception(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1510, in _handle_dbapi_exception    util.raise_(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context    self.dialect.do_execute(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/trino/sqlalchemy/dialect.py"", line 333, in do_execute    cursor.execute(statement, parameters)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/trino/dbapi.py"", line 460, in execute    added_prepare_header = self._prepare_statement(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/trino/dbapi.py"", line 339, in _prepare_statement    raise trino.exceptions.FailedToObtainAddedPrepareHeadersqlalchemy.exc.DBAPIError: (trino.exceptions.FailedToObtainAddedPrepareHeader) [SQL: SELECT ""table_name""FROM ""information_schema"".""views""WHERE ""table_schema"" = ?][parameters: ('stonks',)](Background on this error at: http://sqlalche.me/e/13/dbapi)2022-10-08 16:48:57,519:WARNING:superset.models.core:Get all view names failedTraceback (most recent call last):  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context    self.dialect.do_execute(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/trino/sqlalchemy/dialect.py"", line 333, in do_execute    cursor.execute(statement, parameters)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/trino/dbapi.py"", line 460, in execute    added_prepare_header = self._prepare_statement(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/trino/dbapi.py"", line 339, in _prepare_statement    raise trino.exceptions.FailedToObtainAddedPrepareHeadertrino.exceptions.FailedToObtainAddedPrepareHeaderThe above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/home/ubuntu/.local/lib/python3.8/site-packages/superset/models/core.py"", line 606, in get_all_view_names_in_schema    views = self.db_engine_spec.get_view_names(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/superset/db_engine_specs/trino.py"", line 103, in get_view_names    return BaseEngineSpec.get_view_names(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/superset/db_engine_specs/base.py"", line 1007, in get_view_names    views = inspector.get_view_names(schema)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/reflection.py"", line 325, in get_view_names    return self.dialect.get_view_names(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/trino/sqlalchemy/dialect.py"", line 214, in get_view_names    res = connection.execute(sql.text(query), schema=schema)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 2235, in execute    return connection.execute(statement, *multiparams, **params)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1011, in execute    return meth(self, multiparams, params)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 298, in _execute_on_connection    return connection._execute_clauseelement(self, multiparams, params)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1124, in _execute_clauseelement    ret = self._execute_context(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1316, in _execute_context    self._handle_dbapi_exception(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1510, in _handle_dbapi_exception    util.raise_(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/home/ubuntu/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context    self.dialect.do_execute(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/trino/sqlalchemy/dialect.py"", line 333, in do_execute    cursor.execute(statement, parameters)  File ""/home/ubuntu/.local/lib/python3.8/site-packages/trino/dbapi.py"", line 460, in execute    added_prepare_header = self._prepare_statement(  File ""/home/ubuntu/.local/lib/python3.8/site-packages/trino/dbapi.py"", line 339, in _prepare_statement    raise trino.exceptions.FailedToObtainAddedPrepareHeadersqlalchemy.exc.DBAPIError: (trino.exceptions.FailedToObtainAddedPrepareHeader) [SQL: SELECT ""table_name""FROM ""information_schema"".""views""WHERE ""table_schema"" = ?][parameters: ('stonks',)](Background on this error at: http://sqlalche.me/e/13/dbapi)```
"
21732,1,0,38,0,0,dfoley84,0,"title:superset db upgrade. description:I'm trying to publish apache/superset to ECS, when trying to do  a superset db upgrade I'm faced with the following issues,#### How to reproduce the bug1. Go to '...'2. Click on '....'3. Scroll down to '....'4. See error### Expected resultsDB to be successfully configured. ### Actual results`<html><body><!--StartFragment-->Skipping local overrides--闂?| 2022-10-07T11:11:31.174+01:00 | ######################################################################闂?| 2022-10-07T11:11:31.174+01:00 | Init Step 1/4 [Starting] -- Applying DB migrations闂?| 2022-10-07T11:11:31.174+01:00 | ######################################################################闂?| 2022-10-07T11:11:36.334+01:00 | Traceback (most recent call last):闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 568, in _build_master闂?| 2022-10-07T11:11:36.334+01:00 | ws.require(__requires__)闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 886, in require闂?| 2022-10-07T11:11:36.334+01:00 | needed = self.resolve(parse_requirements(requirements))闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 777, in resolve闂?| 2022-10-07T11:11:36.334+01:00 | raise VersionConflict(dist, req).with_context(dependent_req)闂?| 2022-10-07T11:11:36.334+01:00 | pkg_resources.ContextualVersionConflict: (typing-extensions 4.3.0 (/usr/local/lib/python3.8/site-packages), Requirement.parse('typing-extensions<4,>=3.10'), {'apache-superset'})闂?| 2022-10-07T11:11:36.334+01:00 | During handling of the above exception, another exception occurred:闂?| 2022-10-07T11:11:36.334+01:00 | Traceback (most recent call last):闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/bin/superset"", line 33, in <module>闂?| 2022-10-07T11:11:36.334+01:00 | sys.exit(load_entry_point('apache-superset', 'console_scripts', 'superset')())闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/bin/superset"", line 25, in importlib_load_entry_point闂?| 2022-10-07T11:11:36.334+01:00 | return next(matches).load()闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/lib/python3.8/importlib/metadata.py"", line 77, in load闂?| 2022-10-07T11:11:36.334+01:00 | module = import_module(match.group('module'))闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/lib/python3.8/importlib/__init__.py"", line 127, in import_module闂?| 2022-10-07T11:11:36.334+01:00 | return _bootstrap._gcd_import(name[level:], package, level)闂?| 2022-10-07T11:11:36.334+01:00 | File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_import闂?| 2022-10-07T11:11:36.334+01:00 | File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load闂?| 2022-10-07T11:11:36.334+01:00 | File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked闂?| 2022-10-07T11:11:36.334+01:00 | File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked闂?| 2022-10-07T11:11:36.334+01:00 | File ""<frozen importlib._bootstrap_external>"", line 843, in exec_module闂?| 2022-10-07T11:11:36.334+01:00 | File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed闂?| 2022-10-07T11:11:36.334+01:00 | File ""/app/superset/cli/main.py"", line 28, in <module>闂?| 2022-10-07T11:11:36.334+01:00 | from superset.cli.lib import normalize_token闂?| 2022-10-07T11:11:36.334+01:00 | File ""/app/superset/cli/lib.py"", line 20, in <module>闂?| 2022-10-07T11:11:36.334+01:00 | from superset import config闂?| 2022-10-07T11:11:36.334+01:00 | File ""/app/superset/config.py"", line 46, in <module>闂?| 2022-10-07T11:11:36.334+01:00 | import pkg_resources闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 3243, in <module>闂?| 2022-10-07T11:11:36.334+01:00 | def _initialize_master_working_set():闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 3226, in _call_aside闂?| 2022-10-07T11:11:36.334+01:00 | f(*args, **kwargs)闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 3255, in _initialize_master_working_set闂?| 2022-10-07T11:11:36.334+01:00 | working_set = WorkingSet._build_master()闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 570, in _build_master闂?| 2022-10-07T11:11:36.334+01:00 | return cls._build_from_requirements(__requires__)闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 583, in _build_from_requirements闂?| 2022-10-07T11:11:36.334+01:00 | dists = ws.resolve(reqs, Environment())闂?| 2022-10-07T11:11:36.334+01:00 | File ""/usr/local/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 772, in resolve闂?| 2022-10-07T11:11:36.334+01:00 | raise DistributionNotFound(req, requirers)闂?| 2022-10-07T11:11:36.334+01:00 | pkg_resources.DistributionNotFound: The 'typing-extensions<4,>=3.10' distribution was not found and is required by apache-superset<!--EndFragment--></body></html>`
"
21731,0,0,0,0,0,mattitoo,0,"title:2.0.1RC1: Clicking on ""Time Range"" in the Weekly Threads chart of the Slack Demo Dashboard results in a type error. description:A (hopefully) clear and concise description of what the bug is.#### How to reproduce the bug1. Go to 'Slack Demo Dashboard'2. Click on 'Edit chart' for 'Weekly Threads'3. Click on 'Time Range' button4. See error (Unexpected error: TypeError: Cannot read properties of undefined (reading 'locale'))### Expected resultsI can change the time range### Actual results'Unexpected error'#### Screenshots<img width=""1668"" alt=""Bildschirmfoto 2022-10-07 um 10 15 00"" src=""https://user-images.githubusercontent.com/104143980/194507165-7f46a06e-008b-4be4-b57c-aaebee52d6e6.png"">### Environment(please complete the following information):- browser type and version: Chrome Version 106.0.5249.103 (Offizieller Build) (x86_64)- superset version: 2.0.1RC1 docker version- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
21715,1,1055,0,0,0,brian-bh,0,"title:with recursive CTE works on SQL Lab, but not on making chart with it. description:A clear and concise description of what the bug is.#### How to reproduce the bugI am using databases on Amazon Redshift (and PostgreSQL just in case).For the purpose of ordering data to date, I was using with recursive CTE in many queries.The problem is: recursive CTE works well in SQL Lab, but not in making Charts.### Expected resultsMaking chart also works well with recursive CTE.### Actual resultsChart query gives me an error: ""Error: Recursive CTE in subquery are not supported.""#### Screenshots(This is a partial query from my company, so I am masking some not important values and schema name)![with_recursive_sql_lab](https://user-images.githubusercontent.com/46946734/194273543-b8978225-fea6-4910-b891-6b6b7a1ec168.PNG)![with_recursive_on_chart](https://user-images.githubusercontent.com/46946734/194273123-3e8bc871-6898-409a-bc93-8086230238b4.PNG)### Environment- browser type and version: Chromium based browsers, spotted on Google Chrome- superset version: `superset version`: 2.0.0- on docker non-dev composed settings;### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [V] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [V] I have reproduced the issue with at least the latest released version of superset.- [V] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context## Python Log```Query SELECT ym AS ymFROM  (with recursive x(ym) as     (select to_char(min(date(ri.(MASKED)_date)), 'yyyy-mm') as ym      from (MASKED) ri      where ri.user_id in ((MASKED))      union all select to_char(dateadd(month, 1, to_date(ym, 'yyyy-mm')), 'yyyy-mm')      from x      where to_date(ym, 'yyyy-mm') < to_date(dateadd(month, 0, current_date), 'yyyy-mm') ) select x.ym   from x) AS virtual_tableLIMIT 1000 on schema pfproduct failedTraceback (most recent call last):  File ""/app/superset/connectors/sqla/models.py"", line 1924, in query    df = self.database.get_df(sql, self.schema, mutator=assign_column_label)  File ""/app/superset/models/core.py"", line 458, in get_df    self.db_engine_spec.execute(cursor, sqls[-1])  File ""/app/superset/db_engine_specs/base.py"", line 1329, in execute    raise cls.get_dbapi_mapped_exception(ex)  File ""/app/superset/db_engine_specs/base.py"", line 1327, in execute    cursor.execute(query)psycopg2.errors.FeatureNotSupported: Recursive CTE in subquery are not supported.```
"
21701,0,198,6,0,0,AndVK,0,"title:Plural forms are not compiled from .tsx files to messages.pot for translation. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. There is a file(example): ```/superset-frontend/src/components/ErrorMessage/DatabaseErrorMessage.tsx```![image](https://user-images.githubusercontent.com/89656461/194044143-fb2111a8-3b82-4510-bfa0-89c4167a2063.png)2. Run the following command```pybabel extract -F superset/translations/babel.cfg -o superset/translations/messages.pot -k _ -k __ -k t -k tn -k tct .```### Expected resultsmessage.pot file contains the following lines![photo_2022-10-05_14-04-32](https://user-images.githubusercontent.com/89656461/194046633-f5caaeb3-54aa-4e7c-a0c3-9f891e033832.jpg)### Actual resultsmessage.pot file is missing the following lines![photo_2022-10-05_14-04-35](https://user-images.githubusercontent.com/89656461/194047047-d6baca66-ac93-4674-a2a0-47744a4bf2dc.jpg)### Environment- browser type and version: Google Chrome 98.0.4758.102- superset version: v2.0.0rc2- python version: Python 3.10.0- node.js version: v16.15.1### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextPlure forms from .py files are exported correctly
"
21699,1,0,1,0,1,stevetracvc,0,"title:[Chart Explore] Weird scroll bar jumping issue when Search Box is active. description:Video explains it way better. Disabling the search box fixes it. This only occurs in the explore view.#### How to reproduce the bug1. Edit a table2. Click on Search Box to add the search box3. Watch the fireworks### Expected resultsIt to not go crazy### Actual resultsIt goes crazy. You can see the CSS class keeps toggling between two options.#### Screenshotshttps://user-images.githubusercontent.com/70416691/193972638-ce489936-b579-48d4-9014-5590b9b72af2.mp4### Environment(please complete the following information):- browser type and version: Chrome 102.0.5005.61 on Ubuntu- superset version: checked out fresh, tag 2.0.0, docker### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context
"
21694,0,0,3,1,0,sholtoarmstrong-iot,0,"title:Line Chart annotations dont load on Time-Series Line Charts. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to a Time-Series Line Chart. (In the screenshots the ""Top 10 California Names Timeseries"" was converted from a **Line Chart** to a **Time-Series Line Chart**2. Create an annotation layer![Create annotation layer](https://user-images.githubusercontent.com/65215432/193779663-8f37a002-0539-4647-92d3-eaf32aed7574.png)3. Configure, apply and save the annotation layer to point to any Line Chart. In the example ""Num Births Trend"" was used as it is easy to see.![Configured annotation Layer](https://user-images.githubusercontent.com/65215432/193780431-0197d124-5740-43a2-b3d7-9522831d0a0d.png)4. Save the chart as a new chart and let the page reload.![Save Step](https://user-images.githubusercontent.com/65215432/193784124-5a4d5405-83a8-419f-809f-7c5eb0fc2d09.png)6. The annotation layer is now listed under annotation layers but is not rendered in the plot.![Saved Chart](https://user-images.githubusercontent.com/65215432/193780691-d123870e-33e0-4548-a0d8-aa9bdcf0c683.png)### Expected resultsI expected that the configured annotation layer would still be persisted after the reload and also show up in dashboards.### Actual resultsThe annotation layer remains configured but does not show up in the chart in both the chart editor nor the dashboard.### Environment(please complete the following information):- browser type and version:    - Brave Version 1.42.88  Chromium: 104.0.5112.81 (Official Build)  (64-bit)   - Firefox 105.0.1 (64-bit)   - Chrome Version 105.0.5195.125 (Official Build) (64-bit)- superset version: Superset 2.0.0 (067495d954ee0015d35c1437245feb66984e4c49)- python version:    - Python 3.8.13- node.js version:    - v18.7.0   - v16.17.0- any feature flags active: None### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ x ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ x ] I have reproduced the issue with at least the latest released version of superset.- [ x ] I have checked the issue tracker for the same issue and I haven't found one similar. (Most similar found https://github.com/apache/superset/issues/20441, however there are no errors in the logs frontend or backend with this issue)### Additional contextTested both locally and in cluster with docker image. Same error persists. Does not happen when annotating a line chart with a line chart but annotating a time-series line chart with a line chart seems to cause issues.
"
21689,0,0,8,0,0,zhaorui2022,0,"title:[Chart] Can't use custom SQL in chart since 2.0.0 upgrade. description:We have an issue reported from our user where chart fails when adding a column using custom SQL. The case we have seen is a column with type BIGINT. The user was trying to do some simple calculation like `column_name/6000`, however, it throws an error both on the UI and in the backend server where it says `Expected text or file-like object, got <class 'dict'>`. This should not be chart type specific and we have reproduced this error with both histogram and data table.This functionality was working as expected before upgrading to 2.0.0, so it is likely to be a regression. And I can reproduce this error in the latest master branch as of 10/03/2022 3:30PM.#### How to reproduce the bug1. Go to chart, create a new chart2. When adding a new column, select custom SQL, and put any valid SQL statement3. Click on save, and update chart4. See error### Expected resultsChart updated with custom SQL.### Actual resultsFails due to `Expected text or file-like object, got <class 'dict'>`#### Screenshots![Google Chrome - Superset - 2022-10-03 at 3 48 29 PM](https://user-images.githubusercontent.com/105950525/193699807-f249323d-68ee-4972-952f-6b1c86a0a3a6.gif)### Environment(please complete the following information):- browser type and version: not browser specific- superset version: 2.0.0, can be reproduced with latest commit on master branch as of 10/03/2022 3:30PM PST- python version: 3.8- node.js version: N/A- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
21678,0,449,55,0,0,hermanzdosilovic,0,"title:ClickHouse Error: year 54725 is out of range. description:Whatever query I run in SQL Lab I get the following error:```ClickHouse Erroryear 54725 is out of rangeThis may be triggered by:Issue 1002 - The database returned an unexpected error.```#### How to reproduce the bug1. Go to SQL -> SQL Lab2. Choose any `clickhouse` database3. Write **any** query, for example: `select version()`, `select 1`, `select now()`, or `select 'hello, world'`4. See error### Expected resultsA query should run successfully.### Actual resultsI get the following error:```ClickHouse Erroryear 54725 is out of rangeThis may be triggered by:Issue 1002 - The database returned an unexpected error.```#### Screenshots![image](https://user-images.githubusercontent.com/7927278/193559652-ffb8e96d-ffed-451e-ba31-f6b954e6f51b.png)![image](https://user-images.githubusercontent.com/7927278/193559859-ea204310-cec4-4398-80e3-c3cfafed6000.png)![image](https://user-images.githubusercontent.com/7927278/193560571-798d44c3-b3b5-4259-8d12-36f229168d7e.png)![image](https://user-images.githubusercontent.com/7927278/193560617-e0fd1313-5170-41c3-bca2-f809eeb6316e.png)### Environment- browser type and version: `Version 1.44.105 Chromium: 106.0.5249.91 (Official Build) (x86_64)`- superset version: `apache/superset:31895f412eba60e274c7158a39cf0a8455ffd671` (Docker image)- python version: `3.8.13`- node.js version: N/A since I am using official Docker image- any feature flags active:    ```    FEATURE_FLAGS = {        ""ALERT_REPORTS"": True,        ""DASHBOARD_RBAC"": True,        ""ENABLE_TEMPLATE_PROCESSING"": True,        ""SCHEDULED_QUERIES"": True    }    ```### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any. [Logs are available here](https://github.com/apache/superset/files/9696884/log.txt).- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context1. ClickHouse version: `21.12.2.17`2. Using `clickhouse-sqlalchemy==0.2.2`
"
21665,0,0,8,0,0,zhaorui2022,0,"title:""Create View As"" functionality is broken after SQLLAB_BACKEND_PERSISTENCE is set to True. description:After we upgrade superset to 2.0.0, we got user reports saying ""Create View As"" is broken and it shows an error message saying ""No stored results found, you need to re-run your query"", and if rerunning, it will complain the view already exists. After disabling SQLLAB_BACKEND_PERSISTENCE, it solves the issue. But SQLLAB_BACKEND_PERSISTENCE is set to True by default in 2.0.0.#### How to reproduce the bug1. Go to SQL Lab's SQL editor2. Select a database where it allows ""Create View As""3. Write any query4. Click on ""Create View As"" button in the dropdown list next to ""Run"" button. And fill in the information as expected.5. See the error on the UI.### Expected resultsThe UI should show it has successfully created the view with a link to explore the view immediately.### Actual resultsShows an error. #### Screenshots<img width=""527"" alt=""Screen Shot 2022-09-30 at 11 13 55 AM"" src=""https://user-images.githubusercontent.com/105950525/193331778-73925f89-a131-4a68-8d54-f8d052c7d045.png"">### Environment(please complete the following information):- browser type and version: N/A, not browser specific- superset version: 2.0.0- python version: 3.8- node.js version: not specific to node.js version- any feature flags active: has the error when SQLLAB_BACKEND_PERSISTENCE is set to true### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
21657,0,0,1,0,0,zertyuiop,0,"title:Charts with non-English names cannot be imported.. description:The chart cannot be imported if there are non-English characters in the name.#### How to reproduce the bug1. Create a chart with Russian (or perhaps any non-English) title2. Export it3. Delete it4. Import it (Import successful message)### Expected resultsThe chart should appear in the list of charts### Actual resultsThe chart does not appear in the list. When trying to re-import, there is no overwriting suggestion, the chart is imported successfully, but it still does not appear in the list.### Environment(please complete the following information):- browser type and version: Microsoft Edge 105.0.1343.53- superset version: `2.0.0`, `0dda5fe`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextIn the exported zip file, the chart files are named _55x.yml, where x is a number in order from 1 (at least in my case). Replacing the ""_"" character with any letter allows you to import charts.
"
21653,0,0,8,0,0,zhaorui2022,0,"title:Alert/Report screenshots showing ""Unexpected error"" even though it shows no error on server side. description:We have some user reporting the screenshots they received for their superset alerts or reports show ""Unexpected error. See more"" where the see more is supposed to be a link we can click on. Since we can't click on the ""See More"" in the screenshot, we are trying to figure out the root cause by ruling out causes. After some investigation, we think it might be caused by timeouts because:1. The user we use to capture screenshots have admin role attached, so it should not be a permission issue2. There was no issue on the backend database or query engine3. Not all charts on those dashboard screenshots show this error, and it's a different set of charts showing the error every time users receive screenshot emails4. If the user click on the ""Explorer in Superset"" in the email, the dashboards load immediately and we think it's because the data is cached.However, while looking at the log on the server side, there was no error at all. And the only thing it goes the theory that this is caused by timeout is that the exception is supposed to be caught here https://github.com/apache/superset/blob/master/superset/reports/commands/execute.py#L229#### How to reproduce the bugIt's a bit tricky to reproduce, but we have been seeing this happening consistently with charts that takes a long time to load. It happens even more with the reports scheduled to run weekly. ### Expected resultsEither show the correct content in the screenshots or throw an error on the server side.### Actual resultsNo error on the server side but shows an unexpected error in the screenshot.#### Screenshots![Screen Shot 2022-09-29 at 11 52 34 AM](https://user-images.githubusercontent.com/105950525/193118193-fab1bf5c-f2f6-4481-9d3f-cf8f2bfbf6b8.png)### Environment(please complete the following information):- browser type and version: We are using latest version of firefox to capture screenshots on the server side- superset version: 2.0.0, but it has been happening for quite a while- python version: 3.8- node.js version: N/A- any feature flags active: Alert and Reports are enabled### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
21639,0,0,2,0,0,stephanclaus,0,"title:Dataset filter by schema is not working. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Login to superset as an admin2. go to Data/Datasets3. Enter a value in the schema input4. see error message below### Expected resultsThe datasets are filtered by schema### Actual resultssee error message below#### Screenshots![schema_filter](https://user-images.githubusercontent.com/75787042/192954416-8dca53e2-c37e-465e-9148-7ce9ef18ef1d.png)If applicable, add screenshots to help explain your problem.![error_message](https://user-images.githubusercontent.com/75787042/192954230-3d3da506-bff3-4ac9-9ae5-190160dd1c5f.png)### Environment(please complete the following information):- browser type and version: Chrome Version 105.0.5195.102 (Official Build) (x86_64)- superset version: `2.0.0`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context- Databases connected are Snowflake and PostGres- all other filters work as expected
"
21635,0,0,28,0,0,mayurnewase,0,"title:Chart cache timeout is ignored. description:Chart cache timeout is ignored, I only tested with dataset cache timeout set but looking at the code I think it will be ignored irrespetive of dataset cache timeout config.#### How to reproduce the bug1. start redis locally, and setup redis cache in config for data2. create any chart on 1 dataset3. set dataset cache timeout to 120 seconds4. set chart cache timeout to 5 seconds (from properties modal).5. open chart, and click on update chart6. use redis cli, to check the expiry set on the cache key using `ttl {cache_key}` -> it will be 120 seconds.7. after a minute backend still gives cached data, and we see `cached a minute ago` tag on top right corner.### Expected resultsChart cache timout should override dataset timeout setting, and return actual data from database after 5 seconds.### Actual resultsChart cache timout setting is ignored, and dataset cache timeout is used for checking existing cached data..#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version: chrome- superset version: latest master (last commit sha: `71bf2673071d5db6688fbaefd4457aeeae3464bb`)- python version: `python --version`: 3.9- node.js version: `node -v`: 16- any feature flags active: No### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
21606,1,0,124,0,0,Always-prog,0,"title:Permissions for Filters and FilterSets don't works.. description:Permissions for Filters and FilterSets don't works as well.#### How to reproduce the bug1. Enable DASHBOARD_RBAC in Feature flags.2. Go to Users list3. Create a new user, and assign to him the Gamma role4. Check that _can edit FilterSets_, _can list FilterSets_ and other permissions for Superset is added.5. Go to any dashboard, edit properties, and add Gamma role to Roles list.4. Login as that new user5. Go to dashboard and see problem, user can't see/add/delete Filters or FilterSets.### Expected resultsUser can change Filters and FiltersSet if him have a permissions for this in himself role.### Actual resultsUser can't see Filters and FiltersSet, because him isn't owner of dashboard.#### ScreenshotsHere's Gamma role permissions. It contains permissions to Filters.![image](https://user-images.githubusercontent.com/66589759/192612036-6494643e-d9e0-433c-bf4b-2e2bafa2dd5e.png)Here's screenshot of what user with permissions for adding/deleting Filters see. It can't delete or change anything.![image](https://user-images.githubusercontent.com/66589759/192612545-fcd89312-31ce-4e80-9859-6261048e1775.png)### Environment(please complete the following information):- Docker-non-dev.- any feature flags active: DASHBOARD_RBAC### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
21600,1,69,9,0,0,zhugw,0,"title:display databases more than role real has. description:superset version 1.4.1SQLALCHEMY URI```mysql+mysqlconnector://superset:XXXXXXXXXX@192.168.0.8/smart_auth```has specified the database: `smart_auth`and then create a role with only this permission<img width=""670"" alt=""image"" src=""https://user-images.githubusercontent.com/4953871/192511327-8795d954-fa5c-4b49-84ec-966ab5cc56e5.png"">but when user assigned this role login, it could see many databases  <img width=""407"" alt=""image"" src=""https://user-images.githubusercontent.com/4953871/192511708-66b4b9d6-dff9-474f-a8ba-44b01cdf86e3.png"">not only could see these additional databases, but also could query data from tables of these databaseshow to let it only see `smart_auth` database only?
"
21563,1,0,8,0,0,zhaorui2022,0,"title:[2.0.0] Sqllab regression: Create View As workflow broken. description:After upgrading Superset to 2.0.0, when using Create View As functionality, the UI shows an error saying ""No stored results found, you need to re-run your query"" while it should return a success message.#### How to reproduce the bug1. With `SQLLAB_BACKEND_PERSISTENCE` set as False. Go to Sqllab, write any `SELECT` query 2. Click on the arrow next to Run, and select `Create View AS`3. Give any name to the view, and then click on `CREATE`4. See error as shown in the screenshot### Expected resultsShow an error message, and users should be able to start explore the newly created view immediately### Actual resultsShows an error on the UI.#### ScreenshotsIf applicable, add screenshots to help explain your problem.![Screen Shot 2022-09-22 at 9 27 54 PM](https://user-images.githubusercontent.com/105950525/191892222-65a8ec5f-1a54-4d7c-b634-7e2de65c6e7c.png)### Environment(please complete the following information):- browser type and version: N/A, not browser specific- superset version: 2.0.0- python version: 3.9- node.js version: N/A- any feature flags active: `SQLLAB_BACKEND_PERSISTENCE = False`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context
"
21559,0,0,8,0,1,zhaorui2022,0,"title:""Set up email report"" only if the user's first role has ""menu_access on Manage"" permission. description:If a user is not Admin, but is granted ""menu_access on Manage"" permission through other roles, the user won't be able to see ""Set up email report"" button in the drop down menu on Dashboards or charts unless the first role has ""menu_access on Manage"" permission. This is because on line 123 of this file https://github.com/apache/superset/blob/master/superset-frontend/src/components/ReportModal/HeaderReportDropdown/index.tsx#L118-L123 , it only checks the first role.#### How to reproduce the bug1. Find a user whose first role doesn't have ""menu_access on Manager"" permission but is granted through other roles2. Click on either a dashboard or a chart3. Click on the three dots button4. ""Set up email report"" button doesn't show up### Expected resultsIf a user has been granted the correct permission, the user should be able to see the ""Set up email report"" button### Actual results the ""Set up email report"" button doesn't show up#### ScreenshotsN/A### Environment(please complete the following information):- browser type and version: tried on all browsers- superset version: superset 2.0.0- python version: 3.8- node.js version: N/A- any feature flags active: ALERT_REPORT is enabled### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextWill send a PR later to fix the issue
"
21556,0,0,9,0,0,frassinier,0,"title:Cannot display embedded dashboard if blocking cookies . description:Using the default behavior of Firefox or [Brave](https://brave.com/fr/), which blocks all cookies for security reasons, the iframe will not render at all.#### How to reproduce the bug1. Go to any website which has an embedded dashboard2. Wait for the dashboard to load3. See a generic unexpected error### Expected resultsI expect to see the iframe renders without cookies.### Actual resultsDepending on the web browser, you can either read:- `Unexpected error: SupersetApiError: The operation is insecure.`- `Unexpected error: SupersetApiError: An attempt was made to break through the security policy of the user agent.`#### Screenshots<img width=""1675"" alt=""image"" src=""https://user-images.githubusercontent.com/18534166/191831879-c79a9b13-6c44-45ae-b2c9-388be5971e7b.png""><img width=""1680"" alt=""image"" src=""https://user-images.githubusercontent.com/18534166/191831928-ad48f4c9-afcc-4086-88fb-7b1314da2afb.png"">### Environment(please complete the following information):- browser type and version: Firefox 105 or Brave 1.43.93### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
21554,1,1633,246,0,0,sfirke,0,"title:Database connectivity problem: {""cache_timeout"":[""Not a valid integer.""]}. description:I don't have this fully figured out but opening to establish a record for others.#### How to reproduce the bugGo to Databases -> Edit database -> Performance.  Leave the first two cache timeouts blank (chart, schema) and put 3600 for the last one.  Click Finish.### Expected resultsValues save.### Actual resultsError on screen: ![image](https://user-images.githubusercontent.com/7569808/191824454-890ba934-5921-4ca8-bf02-dc86a110036c.png)Accompanied by a PUT request resulting in 400 in the logs.### WorkaroundPut values of 300, 300 (in one instance Superset changed this to 299??) and 14400 for the cache timeout values.  Those are accepted.### Environment-Superset 2.0.0, docker-compose deployed-MSSQL database### Additional contextI was troubleshooting a problem where my table list wouldn't refresh, despite being able to query a new table in SQL Lab.  First the table list didn't refresh, then I changed a timeout setting and afterward would get this error when it tried to list tables:```2022-09-22 18:19:59,211:ERROR:superset.views.base:value is not an integer or out of rangeTraceback (most recent call last):  File ""/app/superset/views/base.py"", line 185, in wraps    return f(self, *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/decorators.py"", line 175, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/utils/log.py"", line 245, in wrapper    value = f(*args, **kwargs)  File ""/app/superset/views/core.py"", line 1122, in tables    for datasource_name in database.get_all_table_names_in_schema(  File ""/app/superset/utils/cache.py"", line 146, in wrapped_f    cache.set(cache_key, obj, timeout=kwargs.get(""cache_timeout""))  File ""/usr/local/lib/python3.8/site-packages/flask_caching/__init__.py"", line 267, in set    return self.cache.set(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask_caching/backends/rediscache.py"", line 163, in set    result = self._write_client.setex(  File ""/usr/local/lib/python3.8/site-packages/redis/client.py"", line 1822, in setex    return self.execute_command('SETEX', name, time, value)  File ""/usr/local/lib/python3.8/site-packages/redis/client.py"", line 901, in execute_command    return self.parse_response(conn, command_name, **options)  File ""/usr/local/lib/python3.8/site-packages/redis/client.py"", line 915, in parse_response    response = connection.read_response()  File ""/usr/local/lib/python3.8/site-packages/redis/connection.py"", line 756, in read_response    raise responseredis.exceptions.ResponseError: value is not an integer or out of range```
"
21550,1,0,0,0,0,7imon7ays,0,"title:Compressed files exported via API can't be unzipped. description:#### How to reproduce the bug1. Hit the API endpoints `/api/v1/assets/export` or `/api/v1/dashboards/export`2. Write the response body to a .zip file3. Try to decompress the file4. On Mac OS, get ""undefined error: 0"". With Python's zipfile get ""bad magic number"" error"".### Expected resultsWe expect a zipped file that follows the PK format since the payload's string contains special characters and starts with `PK\x03\x04`.### Actual resultsI am unable to decompress the payload's string. Maybe I'm misunderstanding how to consume the endpoint. The docs for `/api/v1/assets/export` read ""Returns a ZIP file with all the Superset assets (databases, datasets, charts, dashboards, saved queries) as YAML files.""### Environment- browser type and version: N/A- superset version: 2.0.0.- python version: `Python 3.9.7`- node.js version: `v16.9.1`- any feature flags active: None### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextNone
"
21534,1,4393,99,0,0,fmusayev,0,"title:Async Queries sometimes stuck in PENDING (Fails to pass task to worker). description:When using async queries in SQL Lab, after couple of executions the same query stucks in PENDING state.I have checked the logs of Superset Node and Worker and it seems that superset node fails pass data/task to worker, but without any errors or signs.Superset Node logs:```...Triggering query_id: 742022-09-20 23:51:12,129:INFO:superset.sqllab.command:Triggering query_id: 74Query 74: Running query on a Celery worker2022-09-20 23:51:12,381:INFO:superset.sqllab.sql_json_executer:Query 74: Running query on a Celery workerTriggering query_id: 752022-09-20 23:55:40,069:INFO:superset.sqllab.command:Triggering query_id: 75Query 75: Running query on a Celery worker2022-09-20 23:55:40,084:INFO:superset.sqllab.sql_json_executer:Query 75: Running query on a Celery workerUnable to load SQLAlchemy dialect <class 'pyhive.sqlalchemy_hive.HiveDialect'>: module 'pyhive.sqlalchemy_hive' has no attribute 'HiveHTTPDialect'2022-09-20 23:56:55,495:WARNING:superset.db_engine_specs:Unable to load SQLAlchemy dialect <class 'pyhive.sqlalchemy_hive.HiveDialect'>: module 'pyhive.sqlalchemy_hive' has no attribute 'HiveHTTPDialect'Unable to load SQLAlchemy dialect <class 'pyhive.sqlalchemy_hive.HiveDialect'>: module 'pyhive.sqlalchemy_hive' has no attribute 'HiveHTTPSDialect'2022-09-20 23:56:55,495:WARNING:superset.db_engine_specs:Unable to load SQLAlchemy dialect <class 'pyhive.sqlalchemy_hive.HiveDialect'>: module 'pyhive.sqlalchemy_hive' has no attribute 'HiveHTTPSDialect'Unable to load SQLAlchemy dialect <class 'pyhive.sqlalchemy_presto.PrestoDialect'>: No module named 'sqlalchemy_trino'2022-09-20 23:56:56,326:WARNING:superset.db_engine_specs:Unable to load SQLAlchemy dialect <class 'pyhive.sqlalchemy_presto.PrestoDialect'>: No module named 'sqlalchemy_trino'192.168.113.223 - - [20/Sep/2022:23:56:56 +0000] ""GET /superset/sqllab/ HTTP/1.1"" 200 27759 ""https://bi-910848238944.iomete.com/superset/welcome/"" ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Safari/605.1.15""/app/superset/views/core.py:2351: FutureWarning: 'pyarrow.deserialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.  return self.results_exec(key)Triggering query_id: 762022-09-20 23:57:10,277:INFO:superset.sqllab.command:Triggering query_id: 76Query 76: Running query on a Celery worker2022-09-20 23:57:10,293:INFO:superset.sqllab.sql_json_executer:Query 76: Running query on a Celery workerTriggering query_id: 772022-09-20 23:57:14,854:INFO:superset.sqllab.command:Triggering query_id: 77Query 77: Running query on a Celery worker2022-09-20 23:57:14,869:INFO:superset.sqllab.sql_json_executer:Query 77: Running query on a Celery worker...```WORKER Logs:```...User information: uid=0 euid=0 gid=0 egid=0  warnings.warn(RuntimeWarning(ROOT_DISCOURAGED.format(Query 75: Executing 1 statement(s)[2022-09-20 23:55:40,233: INFO/ForkPoolWorker-1] Query 75: Executing 1 statement(s)Query 75: Set query to 'running'[2022-09-20 23:55:40,234: INFO/ForkPoolWorker-1] Query 75: Set query to 'running'Query 75: Running statement 1 out of 1[2022-09-20 23:55:40,452: INFO/ForkPoolWorker-1] Query 75: Running statement 1 out of 1[2022-09-20 23:57:01,469: WARNING/ForkPoolWorker-1] /app/superset/sql_lab.py:328: FutureWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.  pa.default_serialization_context()[2022-09-20 23:57:01,469: WARNING/ForkPoolWorker-1] /app/superset/sql_lab.py:161: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.  return execute_sql_statements(Query 75: Storing results in results backend, key: 848dbe03-0e9c-462a-a59d-a0bd3c44fbfb[2022-09-20 23:57:01,470: INFO/ForkPoolWorker-1] Query 75: Storing results in results backend, key: 848dbe03-0e9c-462a-a59d-a0bd3c44fbfbQuery 77: Executing 1 statement(s)[2022-09-20 23:57:14,909: INFO/ForkPoolWorker-1] Query 77: Executing 1 statement(s)Query 77: Set query to 'running'[2022-09-20 23:57:14,909: INFO/ForkPoolWorker-1] Query 77: Set query to 'running'Query 77: Running statement 1 out of 1[2022-09-20 23:57:15,105: INFO/ForkPoolWorker-1] Query 77: Running statement 1 out of 1Query 77: Storing results in results backend, key: 25229e25-7d5f-455e-8447-e0ec47b622a6[2022-09-20 23:57:15,979: INFO/ForkPoolWorker-1] Query 77: Storing results in results backend, key: 25229e25-7d5f-455e-8447-e0ec47b622a6```As you can see from logs, Query 74/76 logs does not exists in worker, only in superset master node
"
21531,0,0,2,0,0,andrey-zayats,0,"title:[chart power query] An error message occurs when user saves a chart using chart power query. description:#### How to reproduce the bug- Go to SQL lab- Run a query- Hit the ""Create chart"" button- Hit the ""Save"" button, and save the chart- See the error### Expected resultsAll controls remain filled in, no errors appear after saving a chart using chart power query### Actual resultsUser sees an unexpected error after saving a chart using chart power query, see the video belowhttps://user-images.githubusercontent.com/90777564/191276272-e2cff763-0fc2-4585-b99a-d77053a73a00.mp4#### Screenshots### Environmentlatest master- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
21517,1,0,31,0,0,arunk-tx,0,"title:connection issue. description:created some alerts/reports, and initally was working fine, now even on refreshing dashboard , query is failing getting: log  File ""/usr/local/lib/python3.8/site-packages/psycopg2/__init__.py"", line 122, in connect                                                                                                       conn = _connect(dsn, connection_factory=connection_factory, **kwasync)                                                                                                                   sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) FATAL:  sorry, too many clients already    
"
21513,0,0,48,0,0,LiuBodong,0,"title:bug: chart-plugin-echarts does not show Orientation description correctly. description:When enable `Show legend` in pie chart, The description of Orientation is shown the same as `Legend type`#### How to reproduce the bug1. Create a pie chart2. Go to `CUSTOMIZE`3. Click Orientation's description4. See error### Expected resultsShow correct description### Actual resultsOrientation show `Legend type` description#### Why this happendsSomeone may copy and paste code but forgot to correct the description ![闂傚倸鍊烽悞锕傚箖閸洖纾块弶鍫涘妽濞呯娀鏌ら幁鎺戝姕婵炲懐濞€閺?https://user-images.githubusercontent.com/23203149/190991205-73fb7ef8-ea60-46cf-b867-0627b3ff1e80.png)#### Screenshots![闂傚倸鍊烽悞锕傚箖閸洖纾块弶鍫涘妽濞呯娀鏌ら幁鎺戝姕婵炲懐濞€閺?https://user-images.githubusercontent.com/23203149/190990012-64b23fa2-2891-46d7-ae85-8b635cf00c52.png)### Environment- browser type and version: firefox- superset version: `2.0.0`- python version: `3.8.13`- node.js version: `v16.17.0`- any feature flags active: no### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextno any other context about the problem
"
21494,0,0,31,0,0,enzo-dechaene,0,"title:Branding favicon is not used on all page. description:Hello,I had replaced the FAVICONS parameter in the config.py file.`FAVICONS = [{""href"": ""/static/assets/images/my-favicon.png""}]`It seems to work on all pages except :- login page- 404, 500 error pages- Security pages (list users, list roles, row level security, action log)![image](https://user-images.githubusercontent.com/107003976/190647441-c378c807-c808-4fb1-ac1e-f9e5b7d792ed.png)It seems that the path to the superset favicon is still used in the project, it should use the FAVICONS parameter.![image](https://user-images.githubusercontent.com/107003976/190647560-dce9efc4-e7c7-4c19-8afa-ee0c0533dd5c.png)
"
21477,1,1407,0,0,0,hungpv29,0,"title:Lost top app-menu bar in public-welcome, login, list users, list roles... pages. description:Lost top app-menu bar in public-welcome, login, list users, list roles... pages![image](https://user-images.githubusercontent.com/64894530/190306627-44db7e5c-838d-429a-8eb1-e11272b93549.png)Error message```vendors.bcc40b00aee47a3bf22c.entry.js:2 TypeError: Cannot read properties of null (reading 'store')    at vendors.bcc40b00aee47a3bf22c.entry.js:2:2301504    at O (6052.4524fb0b983b459dad6c.entry.js:628:101)    at Gi (vendors.bcc40b00aee47a3bf22c.entry.js:2:2224002)    at bl (vendors.bcc40b00aee47a3bf22c.entry.js:2:2269964)    at hu (vendors.bcc40b00aee47a3bf22c.entry.js:2:2262740)    at du (vendors.bcc40b00aee47a3bf22c.entry.js:2:2262665)    at ru (vendors.bcc40b00aee47a3bf22c.entry.js:2:2259695)    at Ql (vendors.bcc40b00aee47a3bf22c.entry.js:2:2256463)    at Vu (vendors.bcc40b00aee47a3bf22c.entry.js:2:2277678)    at vendors.bcc40b00aee47a3bf22c.entry.js:2:2278887    vendors.bcc40b00aee47a3bf22c.entry.js:2 Uncaught TypeError: Cannot read properties of null (reading 'store')    at vendors.bcc40b00aee47a3bf22c.entry.js:2:2301504    at O (6052.4524fb0b983b459dad6c.entry.js:628:101)    at Gi (vendors.bcc40b00aee47a3bf22c.entry.js:2:2224002)    at bl (vendors.bcc40b00aee47a3bf22c.entry.js:2:2269964)    at hu (vendors.bcc40b00aee47a3bf22c.entry.js:2:2262740)    at du (vendors.bcc40b00aee47a3bf22c.entry.js:2:2262665)    at ru (vendors.bcc40b00aee47a3bf22c.entry.js:2:2259695)    at Ql (vendors.bcc40b00aee47a3bf22c.entry.js:2:2256463)    at Vu (vendors.bcc40b00aee47a3bf22c.entry.js:2:2277678)    at vendors.bcc40b00aee47a3bf22c.entry.js:2:2278887```#### How to reproduce the bugLost top app-menu bar when access following paths:- /superset/welcome/ (public welcome page)- /login/ (login page)- /superset/sqllab/- Any pages accessed from `Settings` (like /users/list/, /roles/list/ ...)![image](https://user-images.githubusercontent.com/64894530/190305925-5abaccb4-f5d3-4791-bba3-69ed0ad6e05d.png)### Environment- browser type and version: Chorme (Version 105.0.5195.102) | Safari- superset version: `1.5.1`- python version: `3.8.12`- node.js version: `16.9.1`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
21476,0,0,5,0,0,TrendTech,0,"title:always return with this error. [""There was an error loading the tables""]. description:![image](https://user-images.githubusercontent.com/48197920/190302852-e6ce7aa1-6134-49f4-90b5-15b6a47b2afc.png)![image](https://user-images.githubusercontent.com/48197920/190303353-ddf09ae8-6a71-4afa-beff-3a48efc7d000.png)1. i follow the install instruction2. i add a mysql database.3. when i try to visit the tables. it bring this error. i try old version. still the same4. what i miss in my install process?
"
21467,0,0,10,0,0,bonamim,0,"title:The feature flags list is not up to date. description:Supposedly we should find the `DRILL_TO_DETAIL` flag available in this list:https://github.com/apache/superset/blob/2.0.0/RESOURCES/FEATURE_FLAGS.md#### How to reproduce the bug1. Go to: https://github.com/apache/superset/blob/2.0.0/RESOURCES/FEATURE_FLAGS.md### Expected resultsThe `DRILL_TO_DETAIL` flag should be in one of these classifications:- In Development- In Testing- Stable- Deprecated Flags### Actual resultsI can't find the flag.### Environment- superset version: superset version 2.0.0### Additional contextI would like to know if this feature flag can be used in production environment.
"
21408,1,0,0,0,0,pradhangn,0,"title:CSV export doesn't include timeshifted data. description:#### How to reproduce the bugBuild any line chart with any time-shift comparison. Export a CSV.### Expected resultsAll data shown on chart must be exported.### Actual resultsThe timeshifted data (like say 1 week ago) is not exported into the CSV#### Screenshots![new-chart-2022-09-09T07-39-59 334Z](https://user-images.githubusercontent.com/40589807/189298347-77a6874b-0638-4784-85d7-e2ab6c8f743e.jpg)### Environment- browser type and version: Chrome- superset version: 2.0.0### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [N] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [Y ] I have reproduced the issue with at least the latest released version of superset.- [Y] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextThis hinders the user experience a lot because if they like a chart and want to take out the data, they now have to modify the chart before exporting a CSV.
"
21382,0,0,1,0,0,alexander-e-andrews,0,"title:Embedded-SDK getGuestTokenRefreshTiming missing buffer.from. description:A clear and concise description of what the bug is.Followed along with example deployment. Successfully passing in the first token.   Afterwards it attempts to do getGuestTokenRefreshTiming and fails as Buffer.from is not found#### How to reproduce the bug1. Follow along with example2. Navigate to the webpage### Expected resultsFunction runs without issue### Actual results`guestTokenRefresh.js:41 Uncaught (in promise) ReferenceError: Buffer is not defined.      at getGuestTokenRefreshTiming (guestTokenRefresh.js:41:1)       at _callee3$ (index.js:137:1)       at tryCatch (runtime.js:63:1)       at Generator.invoke [as _invoke] (runtime.js:293:1)       at Generator.next (runtime.js:118:1)       at asyncGeneratorStep (asyncToGenerator.js:3:1)        at _next (asyncToGenerator.js:25:1)`    ### Environment- browser type and version: chrome 105.0.5195.102- superset version: 2.0.0- node.js version: v16.17.0### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdding a buffer replacement to guestTokenRefresh.js like npmjs.com/package/buffer removes the error
"
21368,0,0,4,0,0,C-monC,0,"title: Caching menu items between users - Stealing permissions from the last signed in user. description:Hi,This is probably not a bug with superset but I would appreciate help identifying the issue.When a user logs in they have a small change of getting a frontend that belongs to someone else.i.e. Clicking profile in the top right menu actually takes you to someone else's profile.The api always has the correct user (""/api/me/"") - there is no data leakage. It just presents broken UI's to users.The other user's username is also shared with the other user - a big concern.This issue lasts about a minute. Refreshing the page many times delivers the right page after a while.The setup:Superset is running inside an iframe - The purpose of this is because users in the ""parent system"" have many distinct users in superset.Nginx is the reverse proxy and Cloudflare is enabled.I have Security manger class that checks cookies and logs the user in automatically. This worked without issues until about 2 weeks ago.I have disabled caching completely in Cloudflare and Nginx for the subdomain superset is hosted on with the same results. I can verify in the browser all the requests do not hit caches outside superset.Are there other caching mechanisms in superset itself?
"
21353,0,0,28,0,0,mayurnewase,0,"title:Dashboard filter default value is cleared when 2 dashboards (one cloned from another) opened in succession having filters on same column name of same type. description:Happens in both master and 1.5.1#### How to reproduce the bug1. open 1 dashboard add 1 native filter of type value on any column and set any default value and save it2. save that dashboard by overwriting itself.3. save it again creating a new copy4. change the default value for that filter to something else5. save this dashboard by overwriting itself.6. now go to dashboard list7. open original dashboard8. it won't apply default value of its filter### Expected resultsBoth dashboard should correctly apply default values of filters### Actual resultsThe dashboard which is opened second time doesn't apply default value for native filters.#### Screenshotshttps://user-images.githubusercontent.com/12967587/188796575-98552db6-bf37-4e21-9a0d-0f296e79a8d0.mp4### Environment(please complete the following information):- browser type and version:  100.0.4896.127 (Official Build) (64-bit)- superset version: 1.5.1 and master- python version: python 3.8- node.js version: 16.13.1- any feature flags active: bunch of them, but related here are ""DASHBOARD_RBAC""### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextFrom quick debugging this is happening in this useEffect hook https://github.com/apache/superset/blob/master/superset-frontend/src/dashboard/components/nativeFilters/FilterBar/index.tsx#L285causes:   1. When dashboard is navigated away and opened again, it persists previous filters   2. Native filter ids are same as 2nd dash is created from 1st one.
"
21345,1,84,2,0,0,Vicinius,0,"title:Virtual Dataset becoming Physical after a while. description:Whenever I create a Virtual Dataset from ""Explore"" button, after running a query on SQL Lab > SQL Editor, I start to work on charts on top of it, and at some point, my virtual Dataset becomes Physical, and for some reason this breaks all my previous work. The flow I've been doing is creating a table chart, then a bar chart (I have created a metric on this bar chart, a COUNT(DISTINCT X)... and then it breaks everything when I try to run or save my bar chart. And I get the error after running it: ```Unexpected errorError: (1142, ""SELECT command denied to user '' for table ''"")```#### How to reproduce the bug1. Go to SQL Lab into SQL Editor2. Query something from a schema/table3. Save it as a **Virtual** Dataset using the ""Explore"" Button on SQL Editor4. On top of it, create a table chart 5. Then, create a bar chart and some metrics on it6. It should turn the dataset into physical### Expected resultsDo not turn my dataset into physical### Actual resultsIt does turn it into a physical one#### Screenshots![image](https://user-images.githubusercontent.com/59844324/188724087-9b44d5fb-ad02-4a3c-9671-ff821d3a18cf.png)After becoming Physical### Environment- browser type and version: Chrome 105.0.5195.102- superset version: Sadly I don't know for sure, because I don't have acess to the actual server running my superset at the moment- python version: Same as above- node.js version: Same as above- any feature flags active: none### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextFirst time opening a bug here. Couldn't check logs of reproduce with the latest version because I really can't acess it.
"
21341,0,0,17,0,0,goto-loop,0,"title:Table chart: Conditional formatting assigns color to N/A values. description:When using the Table chart, it is possible to define conditional color formatting. Currently, the formatting is applied also to N/A values if a left-open interval with positive target value is used.#### How to reproduce the bug1. Create a new Table chart from the new_members_daily example dataset2. Set chart to RAW RECORDS and under COLUMNS add new_members, then hit CREATE CHART3. Under CUSTOMIZE tab, CONDITIONAL FORMATTING, add new formatter with arbitrary color for values < 14. Click APPLY and see the first row with N/A value be marked as red### Expected resultsN/A values should be excluded from conditional formatting, i.e. they should have no color because their value is undefined.### Actual resultsN/A values get color formatted.#### Screenshots![Screenshot_20220906_121559](https://user-images.githubusercontent.com/102797966/188610166-3fe0dbe2-9d63-4222-b29f-da3616214990.png)### Environment- browser type and version: Firefox 104.0.1- superset version: 2.0.0### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextA possible workaround is to split up the left-open interval, e.g. instead of one conditional formatter for x < 1 you use three formatters with the ranges 0 < x < 1, x = 0 and x < 0. It seems that N/A gets treated as zero value, but it does not satisfy a comparison with the actual number 0.
"
21340,1,0,0,0,0,MrTrakez,0,"title:APACHE SUPERSET CHANGE FILTER VALUE ORDER. description:The order of these values in the Age filter is not quite right. I want the value ""6 - 13"" to be below ""0 - 5"". Is there any way to set that in Apache Superset?![image](https://user-images.githubusercontent.com/111070577/188601299-57161576-cd0b-45f2-b8dd-d10be1bcffde.png)
"
21336,1,432,22,0,0,mikri2017,0,"title:Import error 'Row' from 'sqlalchemy.engine' when build docker image. description:When starting superset with creating docker image on the latest commit, see error:`ImportError: cannot import name 'Row' from 'sqlalchemy.engine'`full error text:```superset_app            |   File ""/app/superset/utils/encrypt.py"", line 23, in <module>superset_app            |     from sqlalchemy.engine import Connection, Dialect, Rowsuperset_app            | ImportError: cannot import name 'Row' from 'sqlalchemy.engine' (/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/__init__.py)superset_app            | [2022-09-06 05:04:27 +0000] [268] [INFO] Worker exiting (pid: 268)```After some tests with this import string, i saw, that Row successefully importing on sqlalchemy 1.4.40, but not on 1.3.24
"
21281,0,0,19,0,0,yousoph,1,"title:Error when duplicating virtual dataset. description:Getting an error when trying to duplicate a virtual dataset (feature in this PR: https://github.com/apache/superset/pull/20309)#### How to reproduce the bug1. Visit the Datasets page2. On the Actions column of a Virtual dataset, click the duplicate icon 3. Enter a dataset name and click ""Duplicate"" ### Expected resultsVirtual dataset gets copied and created successfully### Actual resultsAn error message appears and the dataset doesn't get created #### Screenshots<img width=""874"" alt=""Superset 2022-08-31 15-10-11"" src=""https://user-images.githubusercontent.com/10627051/187795512-ef471d5a-ee67-4064-a0dd-706b15bf1c87.png"">### Environment(please complete the following information):- browser type and version:- superset version: `master`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
21271,0,0,183,0,1,EugeneTorap,0,"title:Dataset creating issues in SQL Lab. description:I found 2 interesting bugs when we want to create a dataset in SQL Lab:1. When we create a dataset and provide some name and then want to do it again with the same name. In second dataset creation we got `Untitled Query 7 08/31/2022 17:58:02` name but input has `qwe1` name2. [FIXED] When we reload page and create a duplicate name of dataset for example name=`qwe1` then modal window is disappeared and don't handle error from server.### Expected resultsWe handle server error response and show ""Dataset [qwe1] already exists"" on UI side to user.### Actual resultsServer error response is not handled.#### Screenshotshttps://user-images.githubusercontent.com/29536522/187712014-c11971cb-1634-4287-a540-163eba57b83a.movhttps://user-images.githubusercontent.com/29536522/187713956-c98bf383-b42f-49b4-b82e-5684272f4a7a.mov### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.@michael-s-molina @kgabryje @villebro @lyndsiWilliams 
"
21242,1,5857,2,0,0,fgomezotero,0,"title:superset init command fails at version 2.0.0. description:When I run `#superset init` command at the console of Superset UI container it fails#### How to reproduce the bug1. Go to Superset UI container console 2. Run `#superset db upgrade` - *finish successfully*3. Then when I run `#superset init`and get an error### Expected resultsThe command completes without errors### Actual resultsI got an SQL error.#### Screenshots``` bash$ superset initLoaded your LOCAL configuration at [/app/pythonpath/superset_config.py]2022-08-29 15:04:50,882:INFO:superset.utils.logging_configurator:logging was configured successfully2022-08-29 15:04:50,887:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>2022-08-29 15:04:55,390:INFO:superset.security.manager:Syncing role definition2022-08-29 15:04:55,403:INFO:superset.security.manager:Syncing Admin perms2022-08-29 15:04:55,605:INFO:superset.security.manager:Syncing Alpha perms2022-08-29 15:04:55,807:INFO:superset.security.manager:Syncing Gamma perms2022-08-29 15:04:56,018:INFO:superset.security.manager:Syncing granter perms2022-08-29 15:04:56,214:INFO:superset.security.manager:Syncing sql_lab perms2022-08-29 15:04:56,422:INFO:superset.security.manager:Copy/Merge True to PublicTraceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context    self.dialect.do_execute(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 608, in do_execute    cursor.execute(statement, parameters)psycopg2.errors.UndefinedFunction: operator does not exist: character varying = booleanLINE 3: WHERE ab_role.name = true                           ^HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.The above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/usr/local/bin/superset"", line 33, in <module>    sys.exit(load_entry_point('apache-superset', 'console_scripts', 'superset')())  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1128, in __call__    return self.main(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 601, in main    return super().main(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1053, in main    rv = self.invoke(ctx)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1659, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1395, in invoke    return ctx.invoke(self.callback, **ctx.params)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 754, in invoke    return __callback(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/decorators.py"", line 26, in new_func    return f(get_current_context(), *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 445, in decorator    return __ctx.invoke(f, *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 754, in invoke    return __callback(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/decorators.py"", line 26, in new_func    return f(get_current_context(), *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 445, in decorator    return __ctx.invoke(f, *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 754, in invoke    return __callback(*args, **kwargs)  File ""/app/superset/cli/main.py"", line 62, in init    security_manager.sync_role_definitions()  File ""/app/superset/security/manager.py"", line 725, in sync_role_definitions    self.copy_role(  File ""/app/superset/security/manager.py"", line 782, in copy_role    role_from_permissions = list(self.find_role(role_from_name).permissions)  File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/sqla/manager.py"", line 308, in find_role    self.get_session.query(self.role_model).filter_by(name=name).one_or_none()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py"", line 3459, in one_or_none    ret = list(self)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py"", line 3535, in __iter__    return self._execute_and_instances(context)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py"", line 3560, in _execute_and_instances    result = conn.execute(querycontext.statement, self._params)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1011, in execute    return meth(self, multiparams, params)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 298, in _execute_on_connection    return connection._execute_clauseelement(self, multiparams, params)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1124, in _execute_clauseelement    ret = self._execute_context(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1316, in _execute_context    self._handle_dbapi_exception(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1510, in _handle_dbapi_exception    util.raise_(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context    self.dialect.do_execute(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 608, in do_execute    cursor.execute(statement, parameters)sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedFunction) operator does not exist: character varying = booleanLINE 3: WHERE ab_role.name = true                           ^HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.[SQL: SELECT ab_role.id AS ab_role_id, ab_role.name AS ab_role_name FROM ab_role WHERE ab_role.name = true](Background on this error at: http://sqlalche.me/e/13/f405)```### Environment- deployed on the Openshift 3.11 platform, using dockerhub's *apache/superset:2.0.0* as a base image- superset version: **2.0.0**- python version: Python 3.8.12- Postgresql version: 12- any feature flags active:	- ""DASHBOARD_CACHE"": True,    - ""GLOBAL_ASYNC_QUERIES"": True,    - ""DASHBOARD_CROSS_FILTERS"": True,    - ""DASHBOARD_NATIVE_FILTERS_SET"": True,    - ""ALERT_REPORTS"": True,    - ""ENABLE_EXPLORE_DRAG_AND_DROP"": True,    - ""ENABLE_DND_WITH_CLICK_UX"": True,
"
21230,1,0,0,0,1,mtv2102,0,"title:Superset not get loaded properly in local environment. description:I just cloned the code from git and tried running with the following command but it shows the url in the attached way,docker-compose up![Screenshot 2022-08-25 at 2 28 08 PM](https://user-images.githubusercontent.com/112002949/187149346-4ec1eef8-22bb-4875-bec9-e6465cd036bb.png)But when I tried with the following commands in prod env. It is working ,docker-compose -f docker-compose-non-dev.yml pulldocker-compose -f docker-compose-non-dev.yml upAt the same time with the docker-compose.yml file, when I tried comment the following highlighted line ,it works.But I am sure that will not be the right fix.![Screenshot 2022-08-29 at 3 19 26 PM](https://user-images.githubusercontent.com/112002949/187150031-08903028-8ab4-4f80-bff6-d3743ac7d271.png)I tried by increasing docker size from 6 to 8GB..Does it require an additional storage? Any help would be appreciated....
"
21210,0,0,0,0,0,forestlzj,0,"title:duckdb  - unable to list the table schema. description:A clear and concise description of what the bug is.After setting duckb connection to a local file,  in ""SQL Editor"",  it can show list of duckdb connecton and schema correctly, when select a duckdb schema, it can't show the table names in the ""See Table schema"" drop down box.  In superset oupt log, it shows error:**Engine no attribute 'exec_driver_sql'**### Environment(please complete the following information):- browser type and version: chrome 104.0.5112.102- superset version: 2.0- python version: 3.9.13- duckdb version: 0.4.0- duckdb-engine version: 0.6.2- any feature flags active:### ChecklistAdd any other context about the problem here.OS: Redhat 7.9
"
21206,1,0,80,0,0,matianhe3,0,"title:password contains '@' , can not connect database. . description:docker-compose-non-dev ![image](https://user-images.githubusercontent.com/24929062/186877529-b7eaf484-7683-4886-b11b-8d201752e3f8.png)![image](https://user-images.githubusercontent.com/24929062/186877892-883767d5-1edd-46fd-a52c-a16b95620348.png)i tried mysql, postgresql, mssql.i change password , remove '@' , it connected.only SQLAlchemy URI failed. UI connector successed.![image](https://user-images.githubusercontent.com/24929062/186878412-3d51f9b5-1a20-4252-a181-88a7be2639fe.png)
"
21197,0,1574,29,0,0,korjavin,0,"title:superset-init-db pod failed on upgrade. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Upgrade helm chart to current one2. Get superset:latest (which is only god knows what) as image3. init-db failed with the message:```>> Copy 56 metrics to sl_columns...   Link metric columns to datasets...>> Run postprocessing on 700 columns<string>:3: SAWarning: TypeDecorator UUIDType() will not produce a cache key because the ``cache_ok`` attribute is not set to True.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Set this attribute to True if this type object's state is safe to use in a cache key, or False to disable this warning. (Background on this error at: https://sqlalche.me/e/14/cprf)/app/superset/migrations/versions/2022-04-01_14-38_a9422eeaae74_new_dataset_models_take_2.py:732: SAWarning: TypeDecorator UUIDType() will not produce a cache key because the ``cache_ok`` attribute is not set to True.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Set this attribute to True if this type object's state is safe to use in a cache key, or False to disable this warning. (Background on this error at: https://sqlalche.me/e/14/cprf)  count = session.query(func.count()).select_from(query).scalar()Traceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1819, in _execute_context    self.dialect.do_execute(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 732, in do_execute    cursor.execute(statement, parameters)psycopg2.errors.DuplicateAlias: table name ""sl_columns"" specified more than once```
"
21188,1,0,0,0,0,harsha23339,0,"title:Superset consuming more time. description:we have a select query which is retrieving 100K rows in about 12 sec's in SSMS.When we run the same query in superset it is almost taking 50 Sec's.If multiple users are running, it is timing out after 15mins for few usersAny suggestions on how to reduce the timings on superset, as for even one user superset is almost consuming 4 times the time consumed by SSMS.Happy to provide any details such as config, query etc.![image](https://user-images.githubusercontent.com/105300318/186528321-3ed1c058-5fd2-4a26-a4d0-7287194be27d.jpeg)
"
21183,0,0,7,0,0,rdubois,0,"title:Unable to define the 'SameSite' for Global Async Query async-token cookie. description:For the session cookie, the Superset configuration allows to override the default behaviour and configure the SameSite option through the `SESSION_COOKIE_SAMESITE` variable.That option is not available for the Global Async Token JWT cookie. The default value `None` is then considered.### Environment(please complete the following information):- superset version: 1.5.1 / 2.0.0### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
21177,1,0,0,0,0,lihanlilyy,0,"title:Ability to Restrict Access to Different Charts under the Same Datasource. description:Hi, just wondering if it is possible to restrict access to charts created using the same datasource to different user groups through row level access. For example, I used a datasource named ""DS"" to create charts ""Chart A"" and ""Chart B"". There are 2 user groups ""User A"" and ""User B"". Is it possible to restrict the settings such that:- only User A can view Chart A, and- only User B can view Chart B?Thank you.
"
21164,1,1328,10,0,1,bonamim,0,"title:The menu bar is accessible through the login screen using OAuth (Google). description:After changing the **Apache Superset** to use the **OAuth (Google)** setting. The **menu bar** started to appear on the login screen 闂傚倸鍊风粈渚€鎮块崶褉鏋栭柡鍥╁枎閸ㄦ棃鎮楅棃娑欐喐缂?#### How to reproduce the bug1. We tried to use the steps described [**here**](https://superset.apache.org/docs/installation/running-on-kubernetes/#setting-up-oauth);2. The config inside the Pod:```  config_oauth: |    CSRF_ENABLED = True    # This will make sure the redirect_uri is properly computed, even with SSL offloading    ENABLE_PROXY_FIX = True    from flask_appbuilder.security.manager import AUTH_OAUTH    AUTH_TYPE = AUTH_OAUTH    OAUTH_PROVIDERS = [        {            ""name"": ""google"",            ""icon"": ""fa-google"",            ""token_key"": ""access_token"",            ""remote_app"": {                ""client_id"": os.getenv(""GOOGLE_KEY""),                ""client_secret"": os.getenv(""GOOGLE_SECRET""),                ""api_base_url"": ""https://www.googleapis.com/oauth2/v2/"",                ""client_kwargs"": {""scope"": ""email profile""},                ""request_token_url"": None,                ""access_token_url"": ""https://accounts.google.com/o/oauth2/token"",                ""authorize_url"": ""https://accounts.google.com/o/oauth2/auth"",                ""authorize_params"": {""hd"": os.getenv(""AUTH_DOMAIN"", """")}            },        }    ]    # Map Authlib roles to superset roles    AUTH_ROLE_ADMIN = 'Admin'    AUTH_ROLE_PUBLIC = 'Gamma'    # Will allow user self registration, allowing to create Flask users from Authorized User    AUTH_USER_REGISTRATION = True    # The default user self registration role    AUTH_USER_REGISTRATION_ROLE = ""Gamma""```### Expected results 闂?Login screen **without** available menu bar:![image](https://user-images.githubusercontent.com/36086878/186178495-15b9de19-c377-47dc-88f3-4eabf8b5984a.png)You **cannot** access the dashboard list even if you are not logged in:![image](https://user-images.githubusercontent.com/36086878/186179200-f027fbd2-6149-448d-b7e2-195ddef7ad4e.png)### Actual results 闂?Login screen **with** available menu bar:![image](https://user-images.githubusercontent.com/36086878/186178308-06bc4706-1266-49d6-8a1b-9f3a0b22214d.png)You **can** access the dashboard list even if you are not logged in:![image](https://user-images.githubusercontent.com/36086878/186178767-43548d7f-ebe3-4859-b035-b105d6a619ec.png)### Environment- browser type and version: Chrome (Version 104.0.5112.101)- superset version: `superset version` 2.0.0- any feature flags active:  - ENABLE_TEMPLATE_PROCESSING### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context- Helm Chart
"
21145,1,0,0,0,0,DwijadasDey,0,"title:Failed to load API definition. description:Hi I am getting ""Failed to load API definition"" error in the browser when trying to access API endpoint `http://SERVER_IP:8088/swagger/v1`Swagger UI is enabled in config.py [`FAB_API_SWAGGER_UI = True`]![Screenshot from 2022-08-22 13-36-56](https://user-images.githubusercontent.com/12824049/185871432-31cf8864-3f1a-4dba-858c-64a0b9d3bc18.png)In the browse console, I can see the following two errors:`GET http://SERVER_IP:8088/api/v1/_openapi 404 (Not Found)`and`DevTools failed to load source map: Could not load content for http://SERVER_IP:8088/static/appbuilder/css/bootstrap.min.css.map: HTTP error: status code 404, net::ERR_HTTP_RESPONSE_CODE_FAILURE`In the superset console:`WARNING:superset.views.base:404 Not Found: The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.`Shall i have to enable any more feature flags to get it working or need to customise superset using flask app builder ?If i need to extend superset using FAB for swagger REST API then where can i found the documentation ?**Environment:**Python 3.8.1 Superset 1.4.2
"
21106,1,0,0,0,0,labros-zotos,0,"title:Cannot delete database. description:On a fresh installation, I create a new BigQuery database. I can connect to the database just fine.However, if I try to delete it, I get the following error:`Traceback (most recent call last): File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1802, in _execute_context self.dialect.do_execute( File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 719, in do_execute cursor.execute(statement, parameters) psycopg2.errors.UndefinedColumn: column report_schedule.extra_json does not exist`I have run `superset db upgrade` and `superset db init`.The problem seems to be that the columns of `report_schedule` table are not what the source code is expecting.#### How to reproduce the bug1. Install the latest version Apache Superset using the Docker image2. Login with an admin user.3. Create a BigQuery database following superset instructions4. Delete the database you created on step 3### Expected resultsThe database I created to be deleted.### Actual resultsError: _There was an issue deleting Google BigQuery: Fatal error_Error on logs: Traceback (most recent call last): File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1802, in _execute_context self.dialect.do_execute( File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 719, in do_execute cursor.execute(statement, parameters) psycopg2.errors.UndefinedColumn: column report_schedule.extra_json does not exist#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version: Chrome latest- superset version: `2.0.0`- python version: `3.8`- node.js version: `-`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextDocker container is running on Cloud Run. The database used is PostgreSQL 14
"
21080,1,131,49,0,0,mdeshmu,0,"title:cannot connect to redshift from superset ui when using iam authentication. description:I am trying to connect to redshift via redshift_connector using passwordless IAM Authentication.It works fine when i directly login to ecs container where superset is hosted and create/execute the cursor but When i try to create a database connection from super ui then I am getting ConnectionRefusedError.#### How to reproduce the bug1. Go to 'Databases'2. Choose 'Amazon Redshift'3. Set SQLALCHEMY URI to `redshift+redshift_connector:///<databasename>`4. Go to ADVANCED --> Other --> ENGINE PARAMETERS and add following:```{  ""connect_args"":  {  ""iam"":""True"",  ""cluster_identifier"":""<clusteridentifier>"",  ""db_user"":""<databaseuser>""  }}```6. Click on ""Test Connection""7. See error### Expected resultsShould be able to connect and query to Redshift from Superset UI### Actual resultsERROR: (redshift_connector.error.InterfaceError) ('communication error', ConnectionRefusedError(111, 'Connection refused'))(Background on this error at: http://sqlalche.me/e/13/rvf5)#### Screenshots![redshift_connector](https://user-images.githubusercontent.com/57723564/184537036-2b9df15a-850e-45b8-a3f6-18df383b8f37.png)### Environment- browser type and version: Google Chrome Version 103.0.5060.134 (Official Build) (64-bit)- superset version: 1.5.1- python version: 3.8.12- node.js version: NA- any feature flags active: NA### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextI can telnet over 5439 to the redshift from ecs container as well as my local system.
"
21078,1,4350,11,0,0,vigodeltoro,0,"title:Issue to implement Clickhouse DB driver in docker container. description:Hi folks, maybe there is somebody out there, who can help me.. it would be very appreciated..I tried to add the dlickhouse-driver and  clickhouse-sqlalchemy to my superset instance running in docker.As described ( https://superset.apache.org/docs/databases/docker-add-drivers/ ) I added the docker/requirements-local.txt file with the following content:```clickhouse-driver==0.2.0clickhouse-sqlalchemy==0.1.6```And then I run docker-compose build --force-rmIf start superset after that ( dev or non-dev, doesn't matter ) I got that error every time Superset tries to connect to a DB. ``` superset_app            | [2022-08-13 00:30:13 +0000] [14] [INFO] Booting worker with pid: 14superset_worker         | Usage: celery [OPTIONS] COMMAND [ARGS]...superset_worker         | Try 'celery --help' for help.superset_worker         |superset_worker         | Error: Invalid value for '-A' / '--app':superset_worker         | Unable to load celery application.superset_worker         | While trying to load the module superset.tasks.celery_app:app the following error occurred:superset_worker         | Traceback (most recent call last):superset_worker         |   File ""/usr/local/lib/python3.8/site-packages/celery/bin/celery.py"", line 53, in convertsuperset_worker         |     return find_app(value)superset_worker         |   File ""/usr/local/lib/python3.8/site-packages/celery/app/utils.py"", line 384, in find_appsuperset_worker         |     sym = symbol_by_name(app, imp=imp)superset_worker         |   File ""/usr/local/lib/python3.8/site-packages/kombu/utils/imports.py"", line 56, in symbol_by_namesuperset_worker         |     module = imp(module_name, package=package, **kwargs)superset_worker         |   File ""/usr/local/lib/python3.8/site-packages/celery/utils/imports.py"", line 100, in import_from_cwdsuperset_worker         |     return imp(module, package=package)superset_worker         |   File ""/usr/local/lib/python3.8/importlib/__init__.py"", line 127, in import_modulesuperset_worker         |     return _bootstrap._gcd_import(name[level:], package, level)superset_worker         |   File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_importsuperset_worker         |   File ""<frozen importlib._bootstrap>"", line 991, in _find_and_loadsuperset_worker         |   File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load_unlockedsuperset_worker         |   File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removedsuperset_worker         |   File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_importsuperset_worker         |   File ""<frozen importlib._bootstrap>"", line 991, in _find_and_loadsuperset_worker         |   File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load_unlockedsuperset_worker         |   File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removedsuperset_worker         |   File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_importsuperset_worker         |   File ""<frozen importlib._bootstrap>"", line 991, in _find_and_loadsuperset_worker         |   File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlockedsuperset_worker         |   File ""<frozen importlib._bootstrap>"", line 671, in _load_unlockedsuperset_worker         |   File ""<frozen importlib._bootstrap_external>"", line 843, in exec_modulesuperset_worker         |   File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removedsuperset_worker         |   File ""/app/superset/__init__.py"", line 21, in <module>superset_worker         |     from superset.app import create_appsuperset_worker         |   File ""/app/superset/app.py"", line 23, in <module>superset_worker         |     from superset.initialization import SupersetAppInitializersuperset_worker         |   File ""/app/superset/initialization/__init__.py"", line 32, in <module>superset_worker         |     from superset.extensions import (superset_worker         |   File ""/app/superset/extensions/__init__.py"", line 33, in <module>superset_worker         |     from superset.utils.encrypt import EncryptedFieldFactorysuperset_worker         |   File ""/app/superset/utils/encrypt.py"", line 23, in <module>superset_worker         |     from sqlalchemy.engine import Connection, Dialect, Rowsuperset_worker         | ImportError: cannot import name 'Row' from 'sqlalchemy.engine' (/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/__init__.py)```I tried it by adding a layer in a Dockerfile as well:```FROM apache/superset:latest# Switching to root to install the required packagesUSER root# Example: installing the Clickhouse driver to connect to the metadata databaseRUN apt-get -y update && apt-get -y upgradeRUN pip3 install clickhouse-driver==0.2.0 && pip3 install clickhouse-sqlalchemy==0.1.6# Switching back to using the `superset` userUSER superset```Same behavior with Image apache/superset:2.0.0.If I clone the Superset repo and run docker-compose up.. everything works.. but I need the Clickhouse connector.. Tested in Docker and Kubernetes with helm.. same result.. In Kubernetes the Superset Pod is running but the initcontainer are in error state with that error.Does anybody has an idea  ? best regards and many thanks..
"
21077,1,0,0,0,0,MrTrakez,0,"title:Color of the lines does not change in JAVASCRIPT DATA INTERCEPTOR . description:Hello all,I have a table with two columns. One column contains the hexcode for the color and the other one contains the geojson. I added the database in superset and wanted to change the color using javascript. Since I need multiple lines with different colors, I don't know what to do. Do you guys have a solution?![Help](https://user-images.githubusercontent.com/111070577/184448321-dc2ee3ba-3fef-4fb9-bd77-677b57bb5886.png)
"
21063,0,0,292,0,1,rusackas,1,"title:Total on Table Chart gets cut off on the Dashboard if the Chart is re-sized. description:The total count from an aggregated Table Chart gets cut off on the Dashboard, after re-sizing it.#### How to reproduce the bug1. Access Superset.2. Create a **Table Chart** using the **Vehicle Sales** Dataset.3. Set `product_line` on the **Dimensions**.4. Set `SUM(price_each)` on the **Metrics**.5. Enable **SHOW TOTALS**.6. Click on **Create Chart**.7. Access the **CUSTOMIZE** tab.8. Change the `SUM(price_each)` D3 format to **Original value**.9. Save the Chart and add it to a **new** Dashboard.10. Edit the Dashboard, and decrease the Chart height so that a vertical scroll bar appears.11. Increase the height so that all rows are visible.12. Save your changes### Expected resultsThe **Total** number should display as expected.### Actual resultsThe **Total** number is cut off(will paste screenshot/video here - Github is being problematic here at the moment)### Known WorkaroundsManually re-sizing the Chart so that the number is properly displayed _might_ fix the issue. Reports are mixed.### Environment(please complete the following information):- browser type and version: Chrome (on PC)- superset version: latest master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
21061,1,0,0,0,0,MrTrakez,0,"title:ENABLE_JAVASCRIPT_CONTROLS is true in config.py/superset_config.py but does not work. description:I have set ""ENABLE_JAVASCRIPT_CONTROLS"" to true in config.py file and even added ENABLE_JAVASCRIPT_CONTROLS: True in superset_config.py and then restarted Superset Apache. However, it still shows that I can't use javascript and is still grayed out.![image](https://user-images.githubusercontent.com/111070577/184160894-0c256ba8-2d37-4516-9423-df7bc8a90b7c.png)
"
21041,0,0,45,0,1,vin01,0,"title:Connection and host liveness checks use only ipv4. description:Hi,currently hostname validation (https://github.com/apache/superset/blob/master/superset/utils/network.py#L42) and port check (https://github.com/apache/superset/blob/master/superset/utils/network.py#L25) use only ipv4 addresses (because of `gethostbyname` and `AF_INET` respectively)This results in ipv6 only hostnames being marked as invalid and ports show up as closed.Both of these can be. fixed by using `getaddrinfo`.- https://docs.python.org/3/library/socket.html#socket.gethostbyname- https://docs.python.org/3/library/socket.html#socket.getaddrinfoI am creating this single issue to track both these bugs as they are related. Hopefully that is alright with the [guidelines](https://github.com/apache/superset/blob/master/CONTRIBUTING.md#pull-request-guidelines) ;)Please review related patches.Thanks!
"
20963,1,0,0,1,0,pashkash,0,"title:Got 504: Gateway time-out after a minute even with --timeout 600  gunicorn's param.. description:Hey.I changed the gunicorn parametters via env variables, but still getting 504 error during the Chart creation or SQL lab.#### How to reproduce the bug1. Setup Trino ORM with Hive connector. Change `GUNICORN_KEEPALIVE` param to 600 in `.env-non-dev` and `superset_config.py`.2. Run the Superset with `docker-compose -f docker-compose-non-dev.yml up`3. Enter the docker container and check that params are passed with `ps` `...  /usr/local/bin/python /usr/bin/gunicorn --bind 0.0.0.0:8088 ... --timeout 600`5. Go to ""Create new chart"" in the web UI. Fill query params. Run the query.6. Get ""504: Gateway time-out"" after a minute of waiting.### Expected resultsA chart should be shown with data from connectors even if my query was processing for 1m+.### Actual resultsI got the 504 response after a minute.#### Screenshots![image](https://user-images.githubusercontent.com/5039134/182683101-b5ac1ca0-575f-4186-8159-32025e0f929e.png)### Environment- browser type and version: Safary, Chrome;- superset version: the latest superset-image### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar. found [this](https://github.com/apache/superset/issues/5993) but closed and not helpful.### Additional contextIf a query is finished in less than a minute - i can see my chart.
"
20961,0,1465,246,0,0,sfirke,0,"title:BUG: Dashboard filters ""stick"" to second part of Mixed Chart. description:My mixed chart (with stacked bars and a five year rolling total line) on a dashboard starts off correct, but after some filtering on the dashboard, the filter conditions persist only with the rolling total line (Query B).Here's the current state of the dashboard - see no filters applied and I've removed the filter related to bicycles:![image](https://user-images.githubusercontent.com/7569808/182675518-f792c269-0196-4f1a-b3fe-bdd32a76d5d7.png)Note that the Five Year Rolling Average line is way at the bottom, that's the problem due to the incorrectly-persisted filtering.Then I click View Query and can see that the correct filtering is applied to the stacked bars (Query A) but a lot of previous filtering is also applying to the rolling line, Query B:**Query A SQL**```SELECT TOP 10000 DATEADD(YEAR, DATEDIFF(YEAR, 0, [CrashDate]), 0) AS [CrashDate],           [GretInjSev] AS [GretInjSev],           COUNT(*) AS countFROM dbo.[RoadsoftCrashes]WHERE [GretInjSev] IN (1,                       2,                       3,                       4,                       5)  AND [NFC] IN (N'3',                 N' 4',                  N' 5',                   N'6',                    N'7')GROUP BY DATEADD(YEAR, DATEDIFF(YEAR, 0, [CrashDate]), 0),         [GretInjSev]ORDER BY count DESC;```**Query B SQL** - Lots of extra filtering incl. a repeated filter and the bicycle filter which I've since deleted:```SELECT TOP 10000 DATEADD(YEAR, DATEDIFF(YEAR, 0, [CrashDate]), 0) AS [CrashDate],           COUNT(*) AS countFROM dbo.[RoadsoftCrashes]WHERE [GretInjSev] IN (1,                       2,                       3,                       4,                       5)  AND [NFC] IN (N'3',                 N'4',                  N'5',                   N'6',                    N'7')  AND [GretInjSev] IN (1,                       2,                       3,                       4,                       5)  AND [GretInjSev] IN (1,                       2,                       3,                       4,                       5)  AND [Bicycle] IN (1)  AND [GretInjSev] IN (1,                       2,                       3,                       4,                       5)GROUP BY DATEADD(YEAR, DATEDIFF(YEAR, 0, [CrashDate]), 0)ORDER BY count DESC;```That's confirmed when I click Edit Chart and see two different sets of filters applied:![image](https://user-images.githubusercontent.com/7569808/182677412-dd2876d7-2812-4274-bd08-ac4ad6ae5af2.png)vs.![image](https://user-images.githubusercontent.com/7569808/182677474-3db38768-db14-48f9-a95a-57cb21dd523c.png)### Environment(please complete the following information):- Firefox- superset version: 2.0.0- any feature flags active: `ALERT_REPORTS, ENABLE_SCHEDULED_EMAIL_REPORTS, DASHBOARD_RBAC, GENERIC_CHART_AXES, EMAIL_NOTIFICATIONS`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
20960,0,5978,8,0,1,justineyster,0,"title:Connection to Trino using SSL certificate no longer working. description:My team is using Trino behind a company firewall and connecting to it using Superset. When we first set this up, we had some issues getting Superset to trust the SSL certificate used to access Trino through the firewall, and we fixed these issues by taking the following two steps:1) Moved the certificate to `/etc/pki/ca-trust/source/anchors/cert.pem` and ran `update-ca-trust` during our Docker image build.2) Added the following to the `secure_extra` section of our database connection settings in the Superset UI:```{ ""connect_args"": {""verify"": ""/etc/pki/ca-trust/source/anchors/cert.pem""}}```These steps fixed the issue for several months, but now we're once again seeing the following error:```Error: HTTPSConnectionPool(host='trino.host.name', port=443): Max retries exceeded with url: /v1/statement (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)')))```The certificate gets pulled every time we deploy the image, so it is definitely still valid. A former team member used the following command from inside a Superset worker pod to test the certificate:```curl https://trino.host.name/v1/info```This should throw an error message if there is a problem with the SSL certificate, however, the output is:```{""nodeVersion"":{""version"":""390""},""environment"":""production"",""coordinator"":true,""starting"":false,""uptime"":""22.65h""}```I am wondering if anything has changed on the Superset side that is interfering with our ability to make this connection. Note that we recently upgraded from Superset version 1.4.1 to 1.5.1, if that helps. We haven't upgraded to 2.0.0 yet due to breaking changes. Any hints or debugging tips would be helpful, as I am quite stuck with debugging this on my own.#### How to reproduce the bug1. Connect to Trino from Superset using an SSL certificate as described above.### Expected resultsConnection is successful.### Actual resultsSSL error.#### ScreenshotsN/A### Environment- browser type and version: Chrome- superset version: `1.5.1`- python version: `3.9.7`- node.js version: `14.18.2`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextPython stack trace:```Traceback (most recent call last):  File ""/opt/app-root/lib64/python3.9/site-packages/superset/connectors/sqla/models.py"", line 1725, in query    df = self.database.get_df(sql, self.schema, mutator=assign_column_label)  File ""/opt/app-root/lib64/python3.9/site-packages/superset/models/core.py"", line 439, in get_df    with closing(engine.raw_connection()) as conn:  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/engine/base.py"", line 2369, in raw_connection    return self._wrap_pool_connect(  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/engine/base.py"", line 2336, in _wrap_pool_connect    return fn()  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/pool/base.py"", line 304, in unique_connection    return _ConnectionFairy._checkout(self)  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/pool/base.py"", line 778, in _checkout    fairy = _ConnectionRecord.checkout(pool)  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/pool/base.py"", line 495, in checkout    rec = pool._do_get()  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/pool/impl.py"", line 241, in _do_get    return self._create_connection()  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/pool/base.py"", line 309, in _create_connection    return _ConnectionRecord(self)  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/pool/base.py"", line 440, in __init__    self.__connect(first_connect_check=True)  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/pool/base.py"", line 664, in __connect    pool.dispatch.first_connect.for_modify(  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/event/attr.py"", line 314, in exec_once_unless_exception    self._exec_once_impl(True, *args, **kw)  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/event/attr.py"", line 285, in _exec_once_impl    self(*args, **kw)  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/event/attr.py"", line 322, in __call__    fn(*args, **kw)  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/util/langhelpers.py"", line 1406, in go    return once_fn(*arg, **kw)  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/engine/strategies.py"", line 199, in first_connect    dialect.initialize(c)  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/engine/default.py"", line 311, in initialize    self.server_version_info = self._get_server_version_info(  File ""/opt/app-root/lib64/python3.9/site-packages/trino/sqlalchemy/dialect.py"", line 319, in _get_server_version_info    res = connection.execute(sql.text(query))  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/engine/base.py"", line 1011, in execute    return meth(self, multiparams, params)  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/sql/elements.py"", line 298, in _execute_on_connection    return connection._execute_clauseelement(self, multiparams, params)  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/engine/base.py"", line 1124, in _execute_clauseelement    ret = self._execute_context(  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/engine/base.py"", line 1316, in _execute_context    self._handle_dbapi_exception(  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/engine/base.py"", line 1514, in _handle_dbapi_exception    util.raise_(exc_info[1], with_traceback=exc_info[2])  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/opt/app-root/lib64/python3.9/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context    self.dialect.do_execute(  File ""/opt/app-root/lib64/python3.9/site-packages/trino/sqlalchemy/dialect.py"", line 333, in do_execute    cursor.execute(statement, parameters)  File ""/opt/app-root/lib64/python3.9/site-packages/trino/dbapi.py"", line 484, in execute    result = self._query.execute()  File ""/opt/app-root/lib64/python3.9/site-packages/trino/client.py"", line 770, in execute    response = self._request.post(self._sql, additional_http_headers)  File ""/opt/app-root/lib64/python3.9/site-packages/trino/client.py"", line 468, in post    http_response = self._post(  File ""/opt/app-root/lib64/python3.9/site-packages/trino/client.py"", line 854, in decorated    raise error  File ""/opt/app-root/lib64/python3.9/site-packages/trino/client.py"", line 841, in decorated    result = func(*args, **kwargs)  File ""/opt/app-root/lib64/python3.9/site-packages/requests/sessions.py"", line 635, in post    return self.request(""POST"", url, data=data, json=json, **kwargs)  File ""/opt/app-root/lib64/python3.9/site-packages/requests/sessions.py"", line 587, in request    resp = self.send(prep, **send_kwargs)  File ""/opt/app-root/lib64/python3.9/site-packages/requests/sessions.py"", line 701, in send    r = adapter.send(request, **kwargs)  File ""/opt/app-root/lib64/python3.9/site-packages/requests/adapters.py"", line 563, in send    raise SSLError(e, request=request)requests.exceptions.SSLError: HTTPSConnectionPool(host='trino.host.name', port=443): Max retries exceeded with url: /v1/statement (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)')))```
"
20951,0,0,28,0,0,mayurnewase,0,"title:Connect database from top right corner button doesn't work in 1.5.1. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to homepage2. Hover on + sign on top right corner -> hover on data -> click ""Connect database""It works in master, happening because Antd tab component in this version is calling onclick handler with key of the parent element instead of the actual element being clicked so onclick handler doesn't recognise the key and ignores the event.### Expected resultsShould open Add database modal### Actual resultsNothing happens#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
20950,0,0,1,0,0,haimingOu,0,"title:Stop button for queries doesn't work in SQL Lab when using SQL Lab with impala engine. description:A clear and concise description of what the bug is.I am currently having a problem: Stop button for queries doesn't work in SQL Lab when I use SQL Lab with impala engine.#### How to reproduce the bug1.Run any query in SQL Lab with impala-thriftserver as backend processing engine.2.Press STOP button on the UI.3.Check the query engine, the query will still be running. You will still get the results on front end when the query finishes.### Expected resultsThe query should be killed on the query processing engine.### Actual resultsQuery keeps running on the processing engine. You will still get the results on the front end when the query finishes.#### Screenshots![11](https://user-images.githubusercontent.com/50991240/182510393-62d39d07-8ac9-4b6e-980d-256dfa20be3a.png)### Environmentbrowser type and version: Chrome/Firefoxsuperset version: latestpython version: 3.8### ChecklistMake sure to follow these steps before submitting your issue - thank you! [闂傚倸鍊烽悞锕傚礈濮樿泛鍌ㄥù鐘差儐閸?I have checked the superset logs for python stacktraces and included it here as text if there are any. [闂傚倸鍊烽悞锕傚礈濮樿泛鍌ㄥù鐘差儐閸?I have reproduced the issue with at least the latest released version of superset. [闂傚倸鍊烽悞锕傚礈濮樿泛鍌ㄥù鐘差儐閸?I have checked the issue tracker for the same issue and I haven't found one similar.
"
20918,1,0,0,0,1,mranjank,0,"title:Installation Issue. description:OSNAME=""Amazon Linux""VERSION=""2""ID=""amzn""ID_LIKE=""centos rhel fedora""VERSION_ID=""2""PRETTY_NAME=""Amazon Linux 2""I am trying to install Superset on an EC2 Linux instance but can't seem to get past of superset db upgrade stage as there seems to be some conflict. Here is what I have donesudo yum updatesudo yum install gcc gcc-c++ libffi-devel python3-devel python3-pip python3-wheel openssl-devel cyrus-sasl-devel openldap-develpip3 install --upgrade pippip install virtualenvpython3 -m venv venv. venv/bin/activatepip install apache-supersetI see two errors hereERROR: flask-appbuilder 3.4.5 has requirement Flask-WTF<0.15.0,>=0.14.2, but you'll have flask-wtf 1.0.1 which is incompatible.ERROR: flask-caching 2.0.0 has requirement cachelib>=0.9.0, but you'll have cachelib 0.4.1 which is incompatible.I resolved both with pip install Flask-WTF==0.14.3pip install cachelib==0.9.0but when I run superset db upgradeI am gettingTraceback (most recent call last):  File ""/home/ec2-user/venv/lib64/python3.7/site-packages/pkg_resources/__init__.py"", line 584, in _build_master    ws.require(__requires__)  File ""/home/ec2-user/venv/lib64/python3.7/site-packages/pkg_resources/__init__.py"", line 901, in require    needed = self.resolve(parse_requirements(requirements))  File ""/home/ec2-user/venv/lib64/python3.7/site-packages/pkg_resources/__init__.py"", line 792, in resolve    raise VersionConflict(dist, req).with_context(dependent_req)pkg_resources.ContextualVersionConflict: (cachelib 0.9.0 (/home/ec2-user/venv/lib/python3.7/site-packages), Requirement.parse('cachelib<0.5,>=0.4.1'), {'apache-superset'})During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/home/ec2-user/venv/bin/superset"", line 6, in <module>    from pkg_resources import load_entry_point  File ""/home/ec2-user/venv/lib64/python3.7/site-packages/pkg_resources/__init__.py"", line 3261, in <module>    @_call_aside  File ""/home/ec2-user/venv/lib64/python3.7/site-packages/pkg_resources/__init__.py"", line 3245, in _call_aside    f(*args, **kwargs)  File ""/home/ec2-user/venv/lib64/python3.7/site-packages/pkg_resources/__init__.py"", line 3274, in _initialize_master_working_set    working_set = WorkingSet._build_master()  File ""/home/ec2-user/venv/lib64/python3.7/site-packages/pkg_resources/__init__.py"", line 586, in _build_master    return cls._build_from_requirements(__requires__)  File ""/home/ec2-user/venv/lib64/python3.7/site-packages/pkg_resources/__init__.py"", line 599, in _build_from_requirements    dists = ws.resolve(reqs, Environment())  File ""/home/ec2-user/venv/lib64/python3.7/site-packages/pkg_resources/__init__.py"", line 787, in resolve    raise DistributionNotFound(req, requirers)pkg_resources.DistributionNotFound: The 'cachelib<0.5,>=0.4.1' distribution was not found and is required by apache-supersetif I try to downgrade to 0.4.1 than flask complains and I still get this error in ""superset db upgrade""Either documentation at https://superset.apache.org/docs/installation/installing-superset-from-scratch is wrong or build pls help fix this
"
20873,0,0,183,0,0,EugeneTorap,0,"title:Validate request fields in sql_json API. description:We use postman/insomnia http client to call/test all superset API.And we found that `/superset/sql_json/` API don't have validation for required fields. For example if we don't provide `sql` field in JSON body of request we get such error: `""message"": ""Failed to execute query '164' - 'None': 'NoneType' object has no attribute 'strip'""` and then Query History record is created with `sql` column is `null` (db table - `query`)#### How to reproduce the bug1. Call `login` API to auth2. Call `/superset/sql_json/` API without `sql` field3. See response error4. See error for `/api/v1/query/` API### Expected resultsWe have to validate required fields for `/superset/sql_json/` API .### Actual resultsThere's no validation for `/superset/sql_json/` API .Columns sql has null value in db table - `query`.`/api/v1/query/` API is broken with error message is `""error"": ""'NoneType' object has no attribute 'strip'""`#### Screenshots![image](https://user-images.githubusercontent.com/29536522/181068957-91e9ce3a-0c2c-4bbf-8a95-2a93ff5a8bf4.png)![image](https://user-images.githubusercontent.com/29536522/181069075-f15a44b9-40c9-46c7-bac7-654ec1d64dd7.png)![image](https://user-images.githubusercontent.com/29536522/181069158-dec7b7ee-307c-4a81-b70d-14afb2e4239d.png)### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.@michael-s-molina @kgabryje @codyml @zhaoyongjie @diegomedina248 @jinghua-qa @geido @AAfghahi @srinify 
"
20843,0,23777,12,0,1,nigzak,0,"title:Send emails does not work -official documentation wrong? CHROME=>version incompatible ChromeDriver/Chrome FIREFOX=> 'geckodriver' executable needs to be in PATH. description:Sending emails does not work - does not mind if firefox or chrome is used#### How to reproduce the bugcreate custom dockerfile with adding firefox or chrome (same issue if you only add one of them) and confighaving redis active and reachable from dockerstart dockerinit image, load example and add a job for sending a report every minute```superset fab create-admin --username admin --firstname Superset --lastname Admin --email admin@superset.com --password adminsuperset db upgradesuperset load_examplessuperset init```start celery```celery --app=superset.tasks.celery_app:app worker --pool=prefork -O fair -c 4```HINT: featureflag alert_reports is active![image](https://user-images.githubusercontent.com/102737855/180746793-aee43f26-f912-4bc4-a0d7-a93aaaa42248.png)### Expected resultsemail is sent### Actual resultserror is shown in logfile, no email is sentOfficial Documentation: https://superset.apache.org/docs/installation/alerts-reports/HINT CHROME: the chromedriver version is using V88 (LATEST_RELEASE_88) and the chrome stable is using currently 103 => I already changed this and updated ""LATEST_RELEASE_88"" to ""LATEST_RELEASE""![image](https://user-images.githubusercontent.com/102737855/180747630-1e718be0-19c2-4b0d-a2dd-be1782786979.png)=> if I use it without ""_88"" the error with version incompatibility is not there anymore and it works#### firefoxdockerfile```FROM apache/superset:2.0.0USER superset:supersetCOPY custom_sso_security_manager.py /app/pythonpath/custom_sso_security_manager.pyCOPY superset_config.py /app/pythonpath/superset_config.pyUSER root:rootRUN chown superset:superset /app/pythonpath/custom_sso_security_manager.pyRUN chown superset:superset /app/pythonpath/superset_config.pyRUN chmod +x /app/pythonpath/custom_sso_security_manager.pyRUN chmod +x /app/pythonpath/superset_config.pyRUN apt-get update && \    apt-get install --no-install-recommends -y firefox-esrENV GECKODRIVER_VERSION=0.29.0RUN wget -q https://github.com/mozilla/geckodriver/releases/download/v${GECKODRIVER_VERSION}/geckodriver-v${GECKODRIVER_VERSION}-linux64.tar.gz && \    tar -x geckodriver -zf geckodriver-v${GECKODRIVER_VERSION}-linux64.tar.gz -O > /usr/bin/geckodriver && \    chmod 777 /usr/bin/geckodriver && \    rm geckodriver-v${GECKODRIVER_VERSION}-linux64.tar.gzRUN pip install --no-cache authlib gevent psycopg2 redisUSER superset:superset```error```logging was configured successfully2022-07-25 09:25:43,392:INFO:superset.utils.logging_configurator:logging was configured successfully2022-07-25 09:25:43,399:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'> -------------- celery@7db8236e4201 v5.2.2 (dawn-chorus)--- ***** ------- ******* ---- Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.2.5 2022-07-25 09:25:45- *** --- * ---- ** ---------- [config]- ** ---------- .> app:         __main__:0x7ff39e8a2040- ** ---------- .> transport:   redis://redis:6379/5- ** ---------- .> results:     redis://redis:6379/5- *** --- * --- .> concurrency: 4 (prefork)-- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)--- ***** ----- -------------- [queues]                .> celery           exchange=celery(direct) key=celerySQLite Database support for metadata databases will be removed             in a future version of Superset.[2022-07-25 09:25:47,477: WARNING/ForkPoolWorker-4] SQLite Database support for metadata databases will be removed             in a future version of Superset.Init selenium driver[2022-07-25 09:25:47,565: INFO/ForkPoolWorker-4] Init selenium driverA downstream exception occurred while generating a report: f7372ee4-3c4d-4b6a-8b78-930926d4ba4fTraceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/common/service.py"", line 72, in start    self.process = subprocess.Popen(cmd, env=self.env,  File ""/usr/local/lib/python3.8/subprocess.py"", line 858, in __init__    self._execute_child(args, executable, preexec_fn, close_fds,  File ""/usr/local/lib/python3.8/subprocess.py"", line 1704, in _execute_child    raise child_exception_type(errno_num, err_msg, err_filename)FileNotFoundError: [Errno 2] No such file or directory: 'geckodriver'During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/reports/commands/execute.py"", line 234, in _get_screenshots    image = screenshot.get_screenshot(user=user)  File ""/app/superset/utils/screenshots.py"", line 74, in get_screenshot    self.screenshot = driver.get_screenshot(self.url, self.element, user)  File ""/app/superset/utils/webdriver.py"", line 109, in get_screenshot    driver = self.auth(user)  File ""/app/superset/utils/webdriver.py"", line 87, in auth    driver = self.create()  File ""/app/superset/utils/webdriver.py"", line 84, in create    return driver_class(**kwargs)  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/firefox/webdriver.py"", line 164, in __init__    self.service.start()  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/common/service.py"", line 81, in start    raise WebDriverException(selenium.common.exceptions.WebDriverException: Message: 'geckodriver' executable needs to be in PATH.The above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/app/superset/tasks/scheduler.py"", line 79, in execute    AsyncExecuteReportScheduleCommand(  File ""/app/superset/reports/commands/execute.py"", line 659, in run    raise ex  File ""/app/superset/reports/commands/execute.py"", line 655, in run    ReportScheduleStateMachine(  File ""/app/superset/reports/commands/execute.py"", line 624, in run    state_cls(  File ""/app/superset/reports/commands/execute.py"", line 525, in next    raise first_ex  File ""/app/superset/reports/commands/execute.py"", line 503, in next    self.send()  File ""/app/superset/reports/commands/execute.py"", line 408, in send    notification_content = self._get_notification_content()  File ""/app/superset/reports/commands/execute.py"", line 334, in _get_notification_content    screenshot_data = self._get_screenshots()  File ""/app/superset/reports/commands/execute.py"", line 239, in _get_screenshots    raise ReportScheduleScreenshotFailedError(superset.reports.commands.exceptions.ReportScheduleScreenshotFailedError: Failed taking a screenshot Message: 'geckodriver' executable needs to be in PATH.[2022-07-25 09:25:47,881: ERROR/ForkPoolWorker-4] A downstream exception occurred while generating a report: f7372ee4-3c4d-4b6a-8b78-930926d4ba4fTraceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/common/service.py"", line 72, in start    self.process = subprocess.Popen(cmd, env=self.env,  File ""/usr/local/lib/python3.8/subprocess.py"", line 858, in __init__    self._execute_child(args, executable, preexec_fn, close_fds,  File ""/usr/local/lib/python3.8/subprocess.py"", line 1704, in _execute_child    raise child_exception_type(errno_num, err_msg, err_filename)FileNotFoundError: [Errno 2] No such file or directory: 'geckodriver'During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/reports/commands/execute.py"", line 234, in _get_screenshots    image = screenshot.get_screenshot(user=user)  File ""/app/superset/utils/screenshots.py"", line 74, in get_screenshot    self.screenshot = driver.get_screenshot(self.url, self.element, user)  File ""/app/superset/utils/webdriver.py"", line 109, in get_screenshot    driver = self.auth(user)  File ""/app/superset/utils/webdriver.py"", line 87, in auth    driver = self.create()  File ""/app/superset/utils/webdriver.py"", line 84, in create    return driver_class(**kwargs)  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/firefox/webdriver.py"", line 164, in __init__    self.service.start()  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/common/service.py"", line 81, in start    raise WebDriverException(selenium.common.exceptions.WebDriverException: Message: 'geckodriver' executable needs to be in PATH.The above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/app/superset/tasks/scheduler.py"", line 79, in execute    AsyncExecuteReportScheduleCommand(  File ""/app/superset/reports/commands/execute.py"", line 659, in run    raise ex  File ""/app/superset/reports/commands/execute.py"", line 655, in run    ReportScheduleStateMachine(  File ""/app/superset/reports/commands/execute.py"", line 624, in run    state_cls(  File ""/app/superset/reports/commands/execute.py"", line 525, in next    raise first_ex  File ""/app/superset/reports/commands/execute.py"", line 503, in next    self.send()  File ""/app/superset/reports/commands/execute.py"", line 408, in send    notification_content = self._get_notification_content()  File ""/app/superset/reports/commands/execute.py"", line 334, in _get_notification_content    screenshot_data = self._get_screenshots()  File ""/app/superset/reports/commands/execute.py"", line 239, in _get_screenshots    raise ReportScheduleScreenshotFailedError(superset.reports.commands.exceptions.ReportScheduleScreenshotFailedError: Failed taking a screenshot Message: 'geckodriver' executable needs to be in PATH.```#### chrome LATEST_RELEASE_88 (from docu page, unchanged)dockerfile```FROM apache/superset:2.0.0USER superset:supersetCOPY custom_sso_security_manager.py /app/pythonpath/custom_sso_security_manager.pyCOPY superset_config.py /app/pythonpath/superset_config.pyUSER root:rootRUN chown superset:superset /app/pythonpath/custom_sso_security_manager.pyRUN chown superset:superset /app/pythonpath/superset_config.pyRUN chmod +x /app/pythonpath/custom_sso_security_manager.pyRUN chmod +x /app/pythonpath/superset_config.pyRUN apt-get update && \    wget -q https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb && \    apt-get install -y --no-install-recommends ./google-chrome-stable_current_amd64.deb && \    rm -f google-chrome-stable_current_amd64.debRUN export CHROMEDRIVER_VERSION=$(curl --silent https://chromedriver.storage.googleapis.com/LATEST_RELEASE_88) && \    wget -q https://chromedriver.storage.googleapis.com/${CHROMEDRIVER_VERSION}/chromedriver_linux64.zip && \    unzip chromedriver_linux64.zip -d /usr/bin && \    chmod 755 /usr/bin/chromedriver && \    rm -f chromedriver_linux64.zipRUN pip install --no-cache authlib gevent psycopg2 redisUSER superset:superset```error```Init selenium driver[2022-07-25 09:54:00,174: INFO/ForkPoolWorker-4] Init selenium driverA downstream exception occurred while generating a report: 1d59d5b2-f620-480b-9a89-a6a15ef9917bTraceback (most recent call last):  File ""/app/superset/reports/commands/execute.py"", line 234, in _get_screenshots    image = screenshot.get_screenshot(user=user)  File ""/app/superset/utils/screenshots.py"", line 74, in get_screenshot    self.screenshot = driver.get_screenshot(self.url, self.element, user)  File ""/app/superset/utils/webdriver.py"", line 109, in get_screenshot    driver = self.auth(user)  File ""/app/superset/utils/webdriver.py"", line 87, in auth    driver = self.create()  File ""/app/superset/utils/webdriver.py"", line 84, in create    return driver_class(**kwargs)  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/chrome/webdriver.py"", line 76, in __init__    RemoteWebDriver.__init__(  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py"", line 157, in __init__    self.start_session(capabilities, browser_profile)  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py"", line 252, in start_session    response = self.execute(Command.NEW_SESSION, parameters)  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py"", line 321, in execute    self.error_handler.check_response(response)  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py"", line 242, in check_response    raise exception_class(message, screen, stacktrace)selenium.common.exceptions.SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version 88Current browser version is 103.0.5060.134 with binary path /usr/bin/google-chromeThe above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/app/superset/tasks/scheduler.py"", line 79, in execute    AsyncExecuteReportScheduleCommand(  File ""/app/superset/reports/commands/execute.py"", line 659, in run    raise ex  File ""/app/superset/reports/commands/execute.py"", line 655, in run    ReportScheduleStateMachine(  File ""/app/superset/reports/commands/execute.py"", line 624, in run    state_cls(  File ""/app/superset/reports/commands/execute.py"", line 525, in next    raise first_ex  File ""/app/superset/reports/commands/execute.py"", line 503, in next    self.send()  File ""/app/superset/reports/commands/execute.py"", line 408, in send    notification_content = self._get_notification_content()  File ""/app/superset/reports/commands/execute.py"", line 334, in _get_notification_content    screenshot_data = self._get_screenshots()  File ""/app/superset/reports/commands/execute.py"", line 239, in _get_screenshots    raise ReportScheduleScreenshotFailedError(superset.reports.commands.exceptions.ReportScheduleScreenshotFailedError: Failed taking a screenshot Message: session not created: This version of ChromeDriver only supports Chrome version 88Current browser version is 103.0.5060.134 with binary path /usr/bin/google-chrome[2022-07-25 09:54:01,631: ERROR/ForkPoolWorker-4] A downstream exception occurred while generating a report: 1d59d5b2-f620-480b-9a89-a6a15ef9917bTraceback (most recent call last):  File ""/app/superset/reports/commands/execute.py"", line 234, in _get_screenshots    image = screenshot.get_screenshot(user=user)  File ""/app/superset/utils/screenshots.py"", line 74, in get_screenshot    self.screenshot = driver.get_screenshot(self.url, self.element, user)  File ""/app/superset/utils/webdriver.py"", line 109, in get_screenshot    driver = self.auth(user)  File ""/app/superset/utils/webdriver.py"", line 87, in auth    driver = self.create()  File ""/app/superset/utils/webdriver.py"", line 84, in create    return driver_class(**kwargs)  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/chrome/webdriver.py"", line 76, in __init__    RemoteWebDriver.__init__(  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py"", line 157, in __init__    self.start_session(capabilities, browser_profile)  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py"", line 252, in start_session    response = self.execute(Command.NEW_SESSION, parameters)  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py"", line 321, in execute    self.error_handler.check_response(response)  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py"", line 242, in check_response    raise exception_class(message, screen, stacktrace)selenium.common.exceptions.SessionNotCreatedException: Message: session not created: This version of ChromeDriver only supports Chrome version 88Current browser version is 103.0.5060.134 with binary path /usr/bin/google-chromeThe above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/app/superset/tasks/scheduler.py"", line 79, in execute    AsyncExecuteReportScheduleCommand(  File ""/app/superset/reports/commands/execute.py"", line 659, in run    raise ex  File ""/app/superset/reports/commands/execute.py"", line 655, in run    ReportScheduleStateMachine(  File ""/app/superset/reports/commands/execute.py"", line 624, in run    state_cls(  File ""/app/superset/reports/commands/execute.py"", line 525, in next    raise first_ex  File ""/app/superset/reports/commands/execute.py"", line 503, in next    self.send()  File ""/app/superset/reports/commands/execute.py"", line 408, in send    notification_content = self._get_notification_content()  File ""/app/superset/reports/commands/execute.py"", line 334, in _get_notification_content    screenshot_data = self._get_screenshots()  File ""/app/superset/reports/commands/execute.py"", line 239, in _get_screenshots    raise ReportScheduleScreenshotFailedError(superset.reports.commands.exceptions.ReportScheduleScreenshotFailedError: Failed taking a screenshot Message: session not created: This version of ChromeDriver only supports Chrome version 88Current browser version is 103.0.5060.134 with binary path /usr/bin/google-chrome```### Environment(please complete the following information):- browser type and version: Chrome latest- superset version: 2.0.0- any feature flags active:   ""ALERT_REPORTS"": True### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context#### superset_config firefox```from flask_appbuilder.security.manager import AUTH_OID,AUTH_REMOTE_USER,AUTH_DB, AUTH_LDAP, AUTH_OAUTHfrom celery.schedules import crontabimport osfrom custom_sso_security_manager import CustomSsoSecurityManagerCUSTOM_SECURITY_MANAGER = CustomSsoSecurityManagerbasedir = os.path.abspath(os.path.dirname(__file__))SUPERSET_WORKERS = 1# AUTHENTIFICATION STUFF ---------------------------------------------------------------------------OIDCCID=""REMOVED""OIDCCS=""REMOVED""CSRF_ENABLED = TrueAUTH_TYPE = AUTH_OAUTHAUTH_USER_REGISTRATION = TrueAUTH_ROLES_MAPPING = {    ""REMOVED"": [""Admin""]}AUTH_ROLES_SYNC_AT_LOGIN = TruePERMANENT_SESSION_LIFETIME = 600OAUTH_PROVIDERS = [    {       REMOVED    }]ENABLE_PROXY_FIX = TruePREFERRED_URL_SCHEME = 'https'# Console Log SettingsDATA_DIR = os.path.join(os.path.expanduser('~'), '.superset')if not os.path.exists(DATA_DIR):    os.makedirs(DATA_DIR) LOG_FORMAT = '%(asctime)s:%(levelname)s:%(name)s:%(message)s'LOG_LEVEL = 'DEBUG' # ---------------------------------------------------# Enable Time Rotate Log Handler# ---------------------------------------------------# LOG_LEVEL = DEBUG, INFO, WARNING, ERROR, CRITICAL ENABLE_TIME_ROTATE = FalseTIME_ROTATE_LOG_LEVEL = 'DEBUG'FILENAME = os.path.join(DATA_DIR, 'superset.log')ROLLOVER = 'midnight'INTERVAL = 1BACKUP_COUNT = 30## REDIS/CELERY/ALERTS ------------------------------------from celery.schedules import crontabFEATURE_FLAGS = {    ""ALERT_REPORTS"": True}REDIS_HOST = ""redis""REDIS_PORT = ""6379""CACHE_CONFIG = {    'CACHE_TYPE': 'RedisCache',    'CACHE_DEFAULT_TIMEOUT': 86400,    'CACHE_KEY_PREFIX': 'superset_',    'CACHE_REDIS_HOST': 'redis',    'CACHE_REDIS_PORT': 6379,    'CACHE_REDIS_DB': 1,    'CACHE_REDIS_URL': 'redis://redis:6379/1'}FILTER_STATE_CACHE_CONFIG = {    'CACHE_TYPE': 'RedisCache',    'CACHE_DEFAULT_TIMEOUT': 86400,    'CACHE_KEY_PREFIX': 'superset_filter_',    'CACHE_REDIS_URL': 'redis://redis:6379/2'}EXPLORE_FORM_DATA_CACHE_CONFIG = {    'CACHE_TYPE': 'RedisCache',    'CACHE_DEFAULT_TIMEOUT': 86400,    'CACHE_KEY_PREFIX': 'superset_filter_',    'CACHE_REDIS_URL': 'redis://redis:6379/3'}class CeleryConfig:    broker_url = 'redis://redis:6379/5'    imports = ('superset.sql_lab', ""superset.tasks"", ""superset.tasks.thumbnails"", )    result_backend = 'redis://redis:6379/5'    worker_prefetch_multiplier = 10    worker_log_level  = 'DEBUG'    task_acks_late = True    task_annotations = {        'sql_lab.get_sql_results': {            'rate_limit': '100/s',        },        'email_reports.send': {            'rate_limit': '1/s',            'time_limit': 120,            'soft_time_limit': 150,            'ignore_result': True,        },    }    beat_schedule = {        'reports.scheduler': {            'task': 'reports.scheduler',            'schedule': crontab(minute='*', hour='*'),        },    }CELERY_CONFIG = CeleryConfigSCREENSHOT_LOCATE_WAIT = 100SCREENSHOT_LOAD_WAIT = 600# Email configurationSMTP_HOST = ""REMOVED""SMTP_STARTTLS = TrueSMTP_SSL = TrueSMTP_USER = ""REMOVED""SMTP_PORT = 25SMTP_PASSWORD = ""REMOVED""SMTP_MAIL_FROM = ""REMOVED""## https://superset.apache.org/docs/installation/alerts-reports/ webdriver cfg# This is for internal use, you can keep httpWEBDRIVER_BASEURL=""http://superset:8088""# This is the link sent to the recipient, change to your domain eg. https://superset.mydomain.comWEBDRIVER_BASEURL_USER_FRIENDLY=""https://superset.localhost/""```#### superset_config chrome```from flask_appbuilder.security.manager import AUTH_OID,AUTH_REMOTE_USER,AUTH_DB, AUTH_LDAP, AUTH_OAUTHfrom celery.schedules import crontabimport osfrom custom_sso_security_manager import CustomSsoSecurityManagerCUSTOM_SECURITY_MANAGER = CustomSsoSecurityManagerbasedir = os.path.abspath(os.path.dirname(__file__))SUPERSET_WORKERS = 1# AUTHENTIFICATION STUFF ---------------------------------------------------------------------------OIDCCID=""REMOVED""OIDCCS=""REMOVED""CSRF_ENABLED = TrueAUTH_TYPE = AUTH_OAUTHAUTH_USER_REGISTRATION = TrueAUTH_ROLES_MAPPING = {    ""REMOVED"": [""Admin""]}AUTH_ROLES_SYNC_AT_LOGIN = TruePERMANENT_SESSION_LIFETIME = 600OAUTH_PROVIDERS = [    {       REMOVED    }]ENABLE_PROXY_FIX = TruePREFERRED_URL_SCHEME = 'https'# Console Log SettingsDATA_DIR = os.path.join(os.path.expanduser('~'), '.superset')if not os.path.exists(DATA_DIR):    os.makedirs(DATA_DIR) LOG_FORMAT = '%(asctime)s:%(levelname)s:%(name)s:%(message)s'LOG_LEVEL = 'DEBUG' # ---------------------------------------------------# Enable Time Rotate Log Handler# ---------------------------------------------------# LOG_LEVEL = DEBUG, INFO, WARNING, ERROR, CRITICAL ENABLE_TIME_ROTATE = FalseTIME_ROTATE_LOG_LEVEL = 'DEBUG'FILENAME = os.path.join(DATA_DIR, 'superset.log')ROLLOVER = 'midnight'INTERVAL = 1BACKUP_COUNT = 30## REDIS/CELERY/ALERTS ------------------------------------from celery.schedules import crontabFEATURE_FLAGS = {    ""ALERT_REPORTS"": True}REDIS_HOST = ""redis""REDIS_PORT = ""6379""CACHE_CONFIG = {    'CACHE_TYPE': 'RedisCache',    'CACHE_DEFAULT_TIMEOUT': 86400,    'CACHE_KEY_PREFIX': 'superset_',    'CACHE_REDIS_HOST': 'redis',    'CACHE_REDIS_PORT': 6379,    'CACHE_REDIS_DB': 1,    'CACHE_REDIS_URL': 'redis://redis:6379/1'}FILTER_STATE_CACHE_CONFIG = {    'CACHE_TYPE': 'RedisCache',    'CACHE_DEFAULT_TIMEOUT': 86400,    'CACHE_KEY_PREFIX': 'superset_filter_',    'CACHE_REDIS_URL': 'redis://redis:6379/2'}EXPLORE_FORM_DATA_CACHE_CONFIG = {    'CACHE_TYPE': 'RedisCache',    'CACHE_DEFAULT_TIMEOUT': 86400,    'CACHE_KEY_PREFIX': 'superset_filter_',    'CACHE_REDIS_URL': 'redis://redis:6379/3'}class CeleryConfig:    broker_url = 'redis://redis:6379/5'    imports = ('superset.sql_lab', ""superset.tasks"", ""superset.tasks.thumbnails"", )    result_backend = 'redis://redis:6379/5'    worker_prefetch_multiplier = 10    worker_log_level  = 'DEBUG'    task_acks_late = True    task_annotations = {        'sql_lab.get_sql_results': {            'rate_limit': '100/s',        },        'email_reports.send': {            'rate_limit': '1/s',            'time_limit': 120,            'soft_time_limit': 150,            'ignore_result': True,        },    }    beat_schedule = {        'reports.scheduler': {            'task': 'reports.scheduler',            'schedule': crontab(minute='*', hour='*'),        },    }CELERY_CONFIG = CeleryConfigSCREENSHOT_LOCATE_WAIT = 100SCREENSHOT_LOAD_WAIT = 600# Email configurationSMTP_HOST = ""REMOVED""SMTP_STARTTLS = TrueSMTP_SSL = TrueSMTP_USER = ""REMOVED""SMTP_PORT = 25SMTP_PASSWORD = ""REMOVED""SMTP_MAIL_FROM = ""REMOVED""## https://superset.apache.org/docs/installation/alerts-reports/ webdriver cfg# WebDriver configuration# If you use Firefox, you can stick with default values# If you use Chrome, then add the following WEBDRIVER_TYPE and WEBDRIVER_OPTION_ARGSWEBDRIVER_TYPE = ""chrome""WEBDRIVER_OPTION_ARGS = [    ""--force-device-scale-factor=2.0"",    ""--high-dpi-support=2.0"",    ""--headless"",    ""--disable-gpu"",    ""--disable-dev-shm-usage"",    ""--no-sandbox"",    ""--disable-setuid-sandbox"",    ""--disable-extensions"",]# This is for internal use, you can keep httpWEBDRIVER_BASEURL=""http://superset:8088""# This is the link sent to the recipient, change to your domain eg. https://superset.mydomain.comWEBDRIVER_BASEURL_USER_FRIENDLY=""https://superset.localhost/""```
"
20839,1,0,10,0,0,elestranobaron,0,"title:Can't add new database. description:Hi, i'm using last version of superset on dockerwhen i'm at step three of adding a mysql database (didn't try any other but i expect the same result) i click on ""finish"" and it does nothingExcept i get this error message :![Capture2](https://user-images.githubusercontent.com/12266455/180671711-9faf7d0a-8d16-430e-84a0-bceb16c1c8cd.png)
"
20838,1,549,20,0,0,kenho811,0,"title:Superset 2.0.0 - PostgreSQL error - SQL Lab - 'dict' object has no attribute 'set'. description:**Description**I upgraded Superset from 1.4.1 to 2.0.0.I use postgresql as my backend database.When I am in SQL Lab and run some SQLs against a test Postgres Database, I got `dict object has no attribute set`![dict_has_no_attribute_set](https://user-images.githubusercontent.com/57944769/180607953-1872721b-58ba-4dc5-b925-f899e6a3f117.png)![dict_has_no_attribute_set_2](https://user-images.githubusercontent.com/57944769/180607956-3b3a2f20-b72a-47a9-9824-8caee6503c13.png)The above two screenshots show that1. The version of superset is 2.0.02. Whether I run a simple DML (SELECT) or DLL (CREATE), the result is just the same error.However, interestingly, I don't have problem rendering charts (which supposedly fetch the transformed data in the test database and render it graphically)![superset_chart_no_problem](https://user-images.githubusercontent.com/57944769/180608060-314a3186-db30-4387-93d4-ecbff8619022.png)The chart above is one of the examples in Superset#### How to reproduce the bug1. Use Postgresql as Database2. Go to 'SQL Lab'3. Run some SQL (e.g. select * from table)4. Click on 'run'5. See the error **dict object has no attribute set**### Expected resultsNo such error. Superset 1.4.1 does not have this error### Actual resultshas error### Environment(please complete the following information):- browser type and version: Crhome- superset version: 2.0.0- python version: 3.9.13My requirements are```        'apache-superset==2.0.0',        # Breaking changes in markupsafe https://github.com/pallets/markupsafe/issues/284        'markupsafe==2.0.1',        # Solve No PIL installation error        'pillow==9.0.1',        # Error werkzeug.security.safe_str_cmp        'Werkzeug==2.0.0',        'jinja2==3.0.3',        # Bug. See: https://stackoverflow.com/questions/69124218/apache-superset-query-error-on-datetime-with-timezone-column        'psycopg2-binary==2.8.5',        # For using gunicorn        'gevent'```### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
20828,0,0,24,0,0,cdreier,0,"title:volumeMounts for extraConfigs are missing in the deployment-worker.yaml. description:Hi,we try to run superset on kubernetes with your helm charts and a custom security manager. we use the extraConfigs to mount some config files needed by flask_oidc (client_secret.json) - in the superset node, everything is fine, but the worker node crashes as the worker also initializes the flask_oidc context and does not mount the extraConfigsworking deployment for the superset nodehttps://github.com/apache/superset/blob/master/helm/superset/templates/deployment.yaml#L111missing extraConfigs in the worker node :cry: https://github.com/apache/superset/blob/master/helm/superset/templates/deployment-worker.yaml#L104### Expected resultsthe worker node mounts all the extraConfigs under the extraVolumeMounts like the main node### Actual resultsthe worker node crashes, as the extraConfigs were not mounted 
"
20825,0,0,9,0,0,syedgufran95,0,"title:Not able to take URL_PARAM in explore chart. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to 'http://localhost:8088/superset/sqllab/?name=can_read'2. Write query on default dataset on sqllab 'select * from ab_permission where name = '{{ url_param('name') }}''3. Click on explore after running the query (it should return one row)4. click on explore.5. now write &name=can_read in the URL.### Expected resultsURL parameters should persist in the URL and should be read by charts### Actual resultsURL parameters disappear#### ScreenshotsURL params working in SQL lab![Screenshot from 2022-07-22 16-41-26](https://user-images.githubusercontent.com/43085010/180427546-97a70f40-6571-4b6e-a283-ccc7ef02957a.png)URL param disappears from url![ezgif com-gif-maker(4)](https://user-images.githubusercontent.com/43085010/180427449-375f9d8a-55d7-4589-a193-769594379162.gif)### Environment(please complete the following information):- browser type and version: persists on all browser (chrome ,Mozilla,brave)- superset version: `[2.0.0](https://github.com/apache/superset/releases/tag/2.0.0)`### Additional contextI am using jinja templating and I am using URL parms to get the data. I have change feature flag as well still it is not working.
"
20824,1,9533,1,0,0,EinEtw4s,0,"title:superset db upgrade failing when upgrading from 1.5.1 to 2.0.0. description:I am running the pip version of superset. After I upgraded using the standard `pip install apache-superset --upgrade` I ran `superset db upgrade`, which in turn failed.#### How to reproduce the bugUpgrade from 1.5.1 to 2.0.0Although this might be a problem only I am experiencing, I did not test to see whether it is reproducible on other systems.### Expected results`superset db upgrade` to complete without errors.### Actual resultsThe following error message:```logging was configured successfully2022-07-22 10:58:33,964:INFO:superset.utils.logging_configurator:logging was configured successfully2022-07-22 10:58:33,970:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deployments2022-07-22 10:58:33,971:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentsFalling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deployments2022-07-22 10:58:33,973:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentsWARNI [alembic.env] SQLite Database support for metadata databases will         be removed in a future version of Superset.INFO  [alembic.runtime.migration] Context impl SQLiteImpl.INFO  [alembic.runtime.migration] Will assume transactional DDL.INFO  [alembic.runtime.migration] Running upgrade ad07e4fdbaba -> a9422eeaae74, new_dataset_models_take_2Loaded your LOCAL configuration at [/home/finn/Documents/superset/superset_config.py]>> Copy 16 physical tables to sl_tables...>> Copy 16 SqlaTable to sl_datasets...   Copy dataset owners...Traceback (most recent call last):  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context    self.dialect.do_execute(  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 608, in do_execute    cursor.execute(statement, parameters)sqlite3.IntegrityError: UNIQUE constraint failed: sl_dataset_users.dataset_id, sl_dataset_users.user_idThe above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/home/finn/Documents/superset/venv/bin/superset"", line 8, in <module>    sys.exit(superset())  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/click/core.py"", line 1130, in __call__    return self.main(*args, **kwargs)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/flask/cli.py"", line 567, in main    return super().main(*args, **kwargs)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/click/core.py"", line 1055, in main    rv = self.invoke(ctx)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/click/core.py"", line 1657, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/click/core.py"", line 1657, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/click/core.py"", line 1404, in invoke    return ctx.invoke(self.callback, **ctx.params)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/click/core.py"", line 760, in invoke    return __callback(*args, **kwargs)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/click/decorators.py"", line 26, in new_func    return f(get_current_context(), *args, **kwargs)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/flask/cli.py"", line 407, in decorator    return __ctx.invoke(f, *args, **kwargs)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/click/core.py"", line 760, in invoke    return __callback(*args, **kwargs)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/flask_migrate/cli.py"", line 149, in upgrade    _upgrade(directory, revision, sql, tag, x_arg)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/flask_migrate/__init__.py"", line 98, in wrapped    f(*args, **kwargs)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/flask_migrate/__init__.py"", line 185, in upgrade    command.upgrade(config, revision, sql=sql, tag=tag)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/alembic/command.py"", line 322, in upgrade    script.run_env()  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/alembic/script/base.py"", line 569, in run_env    util.load_python_file(self.dir, ""env.py"")  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/alembic/util/pyfiles.py"", line 94, in load_python_file    module = load_module_py(module_id, path)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/alembic/util/pyfiles.py"", line 110, in load_module_py    spec.loader.exec_module(module)  # type: ignore  File ""<frozen importlib._bootstrap_external>"", line 848, in exec_module  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/superset/extensions/../migrations/env.py"", line 126, in <module>    run_migrations_online()  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/superset/extensions/../migrations/env.py"", line 118, in run_migrations_online    context.run_migrations()  File ""<string>"", line 8, in run_migrations  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/alembic/runtime/environment.py"", line 853, in run_migrations    self.get_context().run_migrations(**kw)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/alembic/runtime/migration.py"", line 623, in run_migrations    step.migration_fn(**kw)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/superset/migrations/versions/2022-04-01_14-38_a9422eeaae74_new_dataset_models_take_2.py"", line 876, in upgrade    copy_datasets(session)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/superset/migrations/versions/2022-04-01_14-38_a9422eeaae74_new_dataset_models_take_2.py"", line 379, in copy_datasets    insert_from_select(  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/superset/migrations/versions/2022-04-01_14-38_a9422eeaae74_new_dataset_models_take_2.py"", line 102, in insert_from_select    return op.execute(query)  File ""<string>"", line 8, in execute  File ""<string>"", line 3, in execute  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/alembic/operations/ops.py"", line 2414, in execute    return operations.invoke(op)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/alembic/operations/base.py"", line 394, in invoke    return fn(self, operation)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/alembic/operations/toimpl.py"", line 207, in execute_sql    operations.migration_context.impl.execute(  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/alembic/ddl/impl.py"", line 202, in execute    self._exec(sql, execution_options)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/alembic/ddl/impl.py"", line 195, in _exec    return conn.execute(construct, multiparams)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1011, in execute    return meth(self, multiparams, params)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 298, in _execute_on_connection    return connection._execute_clauseelement(self, multiparams, params)  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1124, in _execute_clauseelement    ret = self._execute_context(  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1316, in _execute_context    self._handle_dbapi_exception(  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1510, in _handle_dbapi_exception    util.raise_(  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context    self.dialect.do_execute(  File ""/home/finn/Documents/superset/venv/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 608, in do_execute    cursor.execute(statement, parameters)sqlalchemy.exc.IntegrityError: (sqlite3.IntegrityError) UNIQUE constraint failed: sl_dataset_users.dataset_id, sl_dataset_users.user_id[SQL: INSERT INTO sl_dataset_users (dataset_id, user_id) SELECT sl_datasets.id AS dataset_id, sqlatable_user.user_id FROM sqlatable_user JOIN tables ON tables.id = sqlatable_user.table_id JOIN sl_datasets ON sl_datasets.uuid = tables.uuid](Background on this error at: http://sqlalche.me/e/13/gkpj)```### Environment(please complete the following information):- OS: `Ubuntu 20.04.4 LTS x86_64`- Kernel: `5.4.0`- superset version: `2.0.0`- python version: `3.8.10`- node.js version: `v16.16.0`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextThe two tables `sl_dataset_users` and `sl_datasets` appear to be empty when queried through `sqlite3` whilst `sqlatable_user` is filled with entries.
"
20817,1,131,0,0,0,sanjayssk,0,"title:Embedded dashboard, how to handle token timeout issue. description:I successfully embedded a dashboard using embedDashboard with a guest token. But when I wait for the time out (5 mins) when the guest token is supposed to expire, doing any filter Apply interactions on the dashboard starts giving errors on permissions, same as if guest token is invalid. Shouldn't there be an event from embedDashboard on such errors so that I can then see if a refresh token solves the problem and prompt the user to refresh?#### How to reproduce the bugEmbed any dashboard using embedDashboard. Wait for 5 minutes and then do some interaction. ### Expected resultsThe dashboard interactions should keep working once embedded### Actual resultsError like the following appears on any interaction on a popup.```This endpoint requires the datasource app1_demo.tbl_1_locationwise, database or            `all_datasource_access` permission```### Environment- Chrome Version 103.0.5060.134 (Official Build) (64-bit)- superset version: don't know as it says latest and the UI menu shows 0.0.dev. Docker image was used in April 2022.- python version: 3.9.5- node.js version: 12.16.1- any feature flags active: ""EMBEDDED_SUPERSET"": True,
"
20797,0,0,89,0,0,nytai,1,"title:Dashboard does not load when a filter is configured ""Select first filter value by default"" option  . description:A clear and concise description of what the bug is.It seems when ""Select first filter value by default"" is configured for a filter and the dashboard has tabs the dashboard stays in a loading state and filters remain out of scope. Clicking the filters that are out of scope triggers the fetch for the first value and the dashboard can render. #### How to reproduce the bug- Import the attached dashboard export (you might have to edit the database to use your examples db instead of the SQLLite one I used). - load the imported ""video game sales"" dashboard. - You should see the bug that looks like the attached screenshot- click on the ""filters out of scope"" and the dashboard should load correctly. Refreshing the dashboard (as long as the url contains the `native_filters_key` query param, also results in the dashboard loading correctly.### Expected resultsThe dashboard loads correctly when opened from the dashboard list/ home page or a link (that does not contain the `native_filters_key` query param. ### Actual resultsThe dashboard stays in a loading state until ""filters out of scope"" is clicked or the dashboard is refreshed#### Screenshots<img width=""2557"" alt=""Screen Shot 2022-07-20 at 1 52 56 PM"" src=""https://user-images.githubusercontent.com/10255196/180080011-b2702b25-a6da-4a8a-a6b5-91781a62a9cc.png"">### Environment version `1.5.1`### Additional contextDashboard export:[dashboard_export_20220720T134744.zip](https://github.com/apache/superset/files/9154399/dashboard_export_20220720T134744.zip)
"
20790,0,10050,2,0,0,snt1017,0,"title:superset db upgrade is returning: psycopg2.errors.DuplicateAlias: table name ""sl_columns"" specified more than once. description:I've been using superset in docker environment, last version I used I from 6 months ago (docker image from https://hub.docker.com/r/apache/superset does not have the version number), when I update the version since the model data changed I have to run code `superset db upgrade` but it returns error. I'm using as superset database PostgreSQL 12, the error appears when a9422eeaae74 (new_dataset_models_take_2) migration is running.```bashINFO  [alembic.runtime.migration] Running upgrade ad07e4fdbaba -> a9422eeaae74, new_dataset_models_take_2>> Copy 17 physical tables to sl_tables...<string>:3: SAWarning: TypeDecorator UUIDType() will not produce a cache key because the ``cache_ok`` attribute is not set to True.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Set this attribute to True if this type object's state is safe to use in a cache key, or False to disable this warning. (Background on this error at: https://sqlalche.me/e/14/cprf)>> Copy 57 SqlaTable to sl_datasets...   Copy dataset owners...   Link physical datasets with tables...>> Copy 3,885 table columns to sl_columns...   Link all columns to sl_datasets...>> Copy 61 metrics to sl_columns...   Link metric columns to datasets...>> Run postprocessing on 3,946 columns/app/superset/migrations/versions/2022-04-01_14-38_a9422eeaae74_new_dataset_models_take_2.py:732: SAWarning: TypeDecorator UUIDType() will not produce a cache key because the ``cache_ok`` attribute is not set to True.  This can have significant performance implications including some performance degradations in comparison to prior SQLAlchemy versions.  Set this attribute to True if this type object's state is safe to use in a cache key, or False to disable this warning. (Background on this error at: https://sqlalche.me/e/14/cprf)  count = session.query(func.count()).select_from(query).scalar()Traceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1819, in _execute_context    self.dialect.do_execute(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 732, in do_execute    cursor.execute(statement, parameters)psycopg2.errors.DuplicateAlias: table name ""sl_columns"" specified more than onceThe above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/usr/local/bin/superset"", line 33, in <module>    sys.exit(load_entry_point('apache-superset', 'console_scripts', 'superset')())  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1128, in __call__    return self.main(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 601, in main    return super().main(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1053, in main    rv = self.invoke(ctx)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1659, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1659, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1395, in invoke    return ctx.invoke(self.callback, **ctx.params)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 754, in invoke    return __callback(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/decorators.py"", line 26, in new_func    return f(get_current_context(), *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 445, in decorator    return __ctx.invoke(f, *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 754, in invoke    return __callback(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask_migrate/cli.py"", line 149, in upgrade    _upgrade(directory, revision, sql, tag, x_arg)  File ""/usr/local/lib/python3.8/site-packages/flask_migrate/__init__.py"", line 98, in wrapped    f(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask_migrate/__init__.py"", line 185, in upgrade    command.upgrade(config, revision, sql=sql, tag=tag)  File ""/usr/local/lib/python3.8/site-packages/alembic/command.py"", line 294, in upgrade    script.run_env()  File ""/usr/local/lib/python3.8/site-packages/alembic/script/base.py"", line 490, in run_env    util.load_python_file(self.dir, ""env.py"")  File ""/usr/local/lib/python3.8/site-packages/alembic/util/pyfiles.py"", line 97, in load_python_file    module = load_module_py(module_id, path)  File ""/usr/local/lib/python3.8/site-packages/alembic/util/compat.py"", line 184, in load_module_py    spec.loader.exec_module(module)  File ""<frozen importlib._bootstrap_external>"", line 843, in exec_module  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed  File ""/app/superset/extensions/../migrations/env.py"", line 126, in <module>    run_migrations_online()  File ""/app/superset/extensions/../migrations/env.py"", line 118, in run_migrations_online    context.run_migrations()  File ""<string>"", line 8, in run_migrations  File ""/usr/local/lib/python3.8/site-packages/alembic/runtime/environment.py"", line 813, in run_migrations    self.get_context().run_migrations(**kw)  File ""/usr/local/lib/python3.8/site-packages/alembic/runtime/migration.py"", line 561, in run_migrations    step.migration_fn(**kw)  File ""/app/superset/migrations/versions/2022-04-01_14-38_a9422eeaae74_new_dataset_models_take_2.py"", line 881, in upgrade    postprocess_columns(session)  File ""/app/superset/migrations/versions/2022-04-01_14-38_a9422eeaae74_new_dataset_models_take_2.py"", line 732, in postprocess_columns    count = session.query(func.count()).select_from(query).scalar()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py"", line 2888, in scalar    ret = self.one()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py"", line 2865, in one    return self._iter().one()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py"", line 2903, in _iter    result = self.session.execute(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 1696, in execute    result = conn._execute_20(statement, params or {}, execution_options)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1631, in _execute_20    return meth(self, args_10style, kwargs_10style, execution_options)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 325, in _execute_on_connection    return connection._execute_clauseelement(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1498, in _execute_clauseelement    ret = self._execute_context(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1862, in _execute_context    self._handle_dbapi_exception(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 2043, in _handle_dbapi_exception    util.raise_(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 207, in raise_    raise exception  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1819, in _execute_context    self.dialect.do_execute(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 732, in do_execute    cursor.execute(statement, parameters)sqlalchemy.exc.ProgrammingError: (psycopg2.errors.DuplicateAlias) table name ""sl_columns"" specified more than once[SQL: SELECT count(*) AS count_1 FROM (SELECT sl_columns.id AS column_id, table_columns.column_name AS column_name, sl_columns.changed_by_fk AS changed_by_fk, sl_columns.changed_on AS changed_on, sl_columns.created_on AS created_on, sl_columns.description AS description, sql_metrics.d3format AS d3format, sl_datasets.external_url AS external_url, sl_columns.extra_json AS extra_json, sl_columns.is_dimensional AS is_dimensional, sl_columns.is_filterable AS is_filterable, sl_datasets.is_managed_externally AS is_managed_externally, sl_columns.is_physical AS is_physical, sql_metrics.metric_type AS metric_type, table_columns.python_date_format AS python_date_format, dbs.sqlalchemy_uri AS sqlalchemy_uri, sl_dataset_tables.table_id AS table_id, coalesce(table_columns.verbose_name, sql_metrics.verbose_name) AS verbose_name, sl_columns.warning_text AS warning_text FROM sl_columns, (SELECT sl_columns.uuid AS uuid, sl_columns.created_on AS created_on, sl_columns.changed_on AS changed_on, sl_columns.id AS id, sl_columns.table_id AS table_id, sl_columns.is_aggregation AS is_aggregation, sl_columns.is_additive AS is_additive, sl_columns.is_dimensional AS is_dimensional, sl_columns.is_filterable AS is_filterable, sl_columns.is_increase_desired AS is_increase_desired, sl_columns.is_managed_externally AS is_managed_externally, sl_columns.is_partition AS is_partition, sl_columns.is_physical AS is_physical, sl_columns.is_temporal AS is_temporal, sl_columns.is_spatial AS is_spatial, sl_columns.name AS name, sl_columns.type AS type, sl_columns.unit AS unit, sl_columns.expression AS expression, sl_columns.description AS description, sl_columns.warning_text AS warning_text, sl_columns.external_url AS external_url, sl_columns.extra_json AS extra_json, sl_columns.created_by_fk AS created_by_fk, sl_columns.changed_by_fk AS changed_by_fk FROM sl_columns  LIMIT %(param_1)s OFFSET %(param_2)s) AS sl_columns JOIN sl_dataset_columns ON sl_dataset_columns.column_id = sl_columns.id JOIN sl_datasets ON sl_datasets.id = sl_dataset_columns.dataset_id LEFT OUTER JOIN sl_dataset_tables ON sl_datasets.is_physical AND sl_dataset_tables.dataset_id = sl_datasets.id JOIN dbs ON dbs.id = sl_datasets.database_id LEFT OUTER JOIN table_columns ON table_columns.uuid = sl_columns.uuid LEFT OUTER JOIN sql_metrics ON sql_metrics.uuid = sl_columns.uuid WHERE sl_columns.is_physical OR table_columns.verbose_name IS NOT NULL OR table_columns.verbose_name IS NOT NULL OR sql_metrics.verbose_name IS NOT NULL OR sql_metrics.d3format IS NOT NULL OR sql_metrics.metric_type IS NOT NULL) AS anon_1][parameters: {'param_1': 100000, 'param_2': 0}](Background on this error at: https://sqlalche.me/e/14/f405)```#### How to reproduce the bug1. Run `superset db upgrade` before a9422eeaae74 migration using PostgreSQL 12 as superset database.### Expected resultsMigration must be applied### Actual resultsError### Environment### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextThe error looks like a missing alias on database query when a join is performed to a subquery.
"
20762,1,0,0,0,0,pribettacap,0,"title:Superset Helm chart failing. description:Installing helm chart from chart source was giving the following error yesterday:gunicorn: error: argument --max-requests: expected one argumentToday, its throwing the following error:Error: file '/root/.cache/helm/repository/superset' does not appear to be a gzipped archive; got 'text/html; charset=utf-8'#### How to reproduce the bugInstall superset helm chart ( i am installing via terraform)### Expected resultsExpected it to install normally.### Actual resultsDoesnt install#### Screenshots### Environment(please complete the following information):- superset version: latest
"
20748,0,0,0,0,0,jacobcroope,0,"title:Dashboard shows endless loading. description:Upon initially loading a dashboard filters load and populate while the dashboard spins it's logo endlessly. A manual refresh causes a normal loading behavior. #### How to reproduce the bugSee screenshot. 1. Go to any dashboard 2. Wait for it to load3. Hit refresh on your browser to get it to load correctly after waiting. ### Expected resultsDashboard fully loads. ### Actual resultsDashboard only loads after refresh. #### Screenshotshttps://user-images.githubusercontent.com/1770898/179555764-5a31249f-144a-479a-bdf4-b4dbb4f74938.mp4### Environment- Windows 10,11 and Firefox, Chrome, Safari, and Edge. - Superset Version 1.3, 1.5, 2.0 - docker-compose install currently version 2.0 but tried on all of the recent versions. - python 3.8.10- [x ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.This has been an annoying issue that prevents us from rolling this out to customers. 
"
20744,1,53810,6,0,0,LyZane,0,"title:docker-compose up failed. description:#### How to reproduce the bug```bashgit clone https://github.com/apache/superset.gitcd supersetdocker-compose -f docker-compose-non-dev.yml pulldocker-compose -f docker-compose-non-dev.yml up```### Expected resultsvisit: http://localhost:8088/ and http://localhost:8080/<img width=""694"" alt=""image"" src=""https://user-images.githubusercontent.com/1787721/179537491-eec1cbba-65c2-47c8-b0dd-74c6c7b79d5d.png"">### Environment- browser type and version: Chrome 103.0.5060.114- superset version: `2.0 (Tue Jun 28 08:53:02 2022 -0400)`### Additional context```log$ docker-compose -f docker-compose-non-dev.yml upStarting superset_cache ... doneStarting superset_db    ... doneStarting superset_init        ... doneStarting superset_app         ... doneStarting superset_worker      ... doneStarting superset_worker_beat ... doneAttaching to superset_db, superset_cache, superset_worker_beat, superset_worker, superset_app, superset_initsuperset_app            | Skipping local overridessuperset_app            | Starting web app...superset_cache          | 1:C 18 Jul 2022 14:33:50.007 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oosuperset_cache          | 1:C 18 Jul 2022 14:33:50.008 # Redis version=7.0.3, bits=64, commit=00000000, modified=0, pid=1, just startedsuperset_cache          | 1:C 18 Jul 2022 14:33:50.008 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.confsuperset_cache          | 1:M 18 Jul 2022 14:33:50.008 * monotonic clock: POSIX clock_gettimesuperset_cache          | 1:M 18 Jul 2022 14:33:50.009 * Running mode=standalone, port=6379.superset_cache          | 1:M 18 Jul 2022 14:33:50.009 # Server initializedsuperset_cache          | 1:M 18 Jul 2022 14:33:50.010 * Loading RDB produced by version 7.0.3superset_cache          | 1:M 18 Jul 2022 14:33:50.011 * RDB age 10 secondssuperset_cache          | 1:M 18 Jul 2022 14:33:50.011 * RDB memory usage when created 1.19 Mbsuperset_cache          | 1:M 18 Jul 2022 14:33:50.011 * Done loading RDB, keys loaded: 11, keys expired: 0.superset_cache          | 1:M 18 Jul 2022 14:33:50.011 * DB loaded from disk: 0.000 secondsdb_1                    |db_1                    | PostgreSQL Database directory appears to contain a database; Skipping initializationdb_1                    |superset_cache          | 1:M 18 Jul 2022 14:33:50.011 * Ready to accept connectionsdb_1                    | 2022-07-18 14:33:50.078 UTC [1] LOG:  listening on IPv4 address ""0.0.0.0"", port 5432db_1                    | 2022-07-18 14:33:50.078 UTC [1] LOG:  listening on IPv6 address ""::"", port 5432superset_worker         | Skipping local overridessuperset_worker         | Starting Celery worker...db_1                    | 2022-07-18 14:33:50.086 UTC [1] LOG:  listening on Unix socket ""/var/run/postgresql/.s.PGSQL.5432""db_1                    | 2022-07-18 14:33:50.101 UTC [25] LOG:  database system was shut down at 2022-07-18 14:33:40 UTCsuperset_worker_beat    | Skipping local overridessuperset_worker_beat    | Starting Celery beat...db_1                    | 2022-07-18 14:33:50.189 UTC [1] LOG:  database system is ready to accept connectionssuperset_init           | Skipping local overridessuperset_init           |superset_init           | ######################################################################superset_init           |superset_init           |superset_init           | Init Step 1/4 [Starting] -- Applying DB migrationssuperset_init           |superset_init           |superset_init           | ######################################################################superset_init           |superset_app            | usage: gunicorn [OPTIONS] [APP_MODULE]superset_app            | gunicorn: error: argument --max-requests: expected one argumentsuperset_app            | Skipping local overridessuperset_app            | Starting web app...superset_app            | usage: gunicorn [OPTIONS] [APP_MODULE]superset_app            | gunicorn: error: argument --max-requests: expected one argumentsuperset_app exited with code 2superset_app            | Skipping local overridessuperset_app            | Starting web app...superset_app            | usage: gunicorn [OPTIONS] [APP_MODULE]superset_app            | gunicorn: error: argument --max-requests: expected one argumentsuperset_app exited with code 2superset_app            | Skipping local overridessuperset_app            | Starting web app...superset_app            | usage: gunicorn [OPTIONS] [APP_MODULE]superset_app            | gunicorn: error: argument --max-requests: expected one argumentsuperset_app exited with code 2superset_app            | Skipping local overridessuperset_app            | Starting web app...superset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    |                                     WARNINGsuperset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    | A Default SECRET_KEY was detected, please use superset_config.py to override it.superset_worker_beat    | Use a strong complex alphanumeric string and use a tool to help you generatesuperset_worker_beat    | a sufficiently random sequence, ex: openssl rand -base64 42superset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    | logging was configured successfullysuperset_worker_beat    | 2022-07-18 14:34:05,223:INFO:superset.utils.logging_configurator:logging was configured successfullysuperset_worker_beat    | 2022-07-18 14:34:05,238:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>superset_worker         | --------------------------------------------------------------------------------superset_worker         |                                     WARNINGsuperset_worker         | --------------------------------------------------------------------------------superset_worker         | A Default SECRET_KEY was detected, please use superset_config.py to override it.superset_worker         | Use a strong complex alphanumeric string and use a tool to help you generatesuperset_worker         | a sufficiently random sequence, ex: openssl rand -base64 42superset_worker         | --------------------------------------------------------------------------------superset_worker         | --------------------------------------------------------------------------------superset_worker         | logging was configured successfullysuperset_worker         | 2022-07-18 14:34:05,261:INFO:superset.utils.logging_configurator:logging was configured successfullysuperset_worker_beat    | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker_beat    | 2022-07-18 14:34:05,264:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker         | 2022-07-18 14:34:05,274:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>superset_worker_beat    | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker_beat    | 2022-07-18 14:34:05,282:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker         | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker         | 2022-07-18 14:34:05,289:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker         | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker         | 2022-07-18 14:34:05,306:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_app            | usage: gunicorn [OPTIONS] [APP_MODULE]superset_app            | gunicorn: error: argument --max-requests: expected one argumentsuperset_app exited with code 2superset_app            | Skipping local overridessuperset_app            | Starting web app...superset_app            | usage: gunicorn [OPTIONS] [APP_MODULE]superset_app            | gunicorn: error: argument --max-requests: expected one argumentsuperset_app exited with code 2superset_init           | --------------------------------------------------------------------------------superset_init           |                                     WARNINGsuperset_init           | --------------------------------------------------------------------------------superset_init           | A Default SECRET_KEY was detected, please use superset_config.py to override it.superset_init           | Use a strong complex alphanumeric string and use a tool to help you generatesuperset_init           | a sufficiently random sequence, ex: openssl rand -base64 42superset_init           | --------------------------------------------------------------------------------superset_init           | --------------------------------------------------------------------------------superset_init           | logging was configured successfullysuperset_init           | 2022-07-18 14:34:09,697:INFO:superset.utils.logging_configurator:logging was configured successfullysuperset_init           | 2022-07-18 14:34:09,730:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>superset_init           | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_init           | 2022-07-18 14:34:09,746:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_init           | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_init           | 2022-07-18 14:34:09,764:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_app            | Skipping local overridessuperset_app            | Starting web app...superset_app            | usage: gunicorn [OPTIONS] [APP_MODULE]superset_app            | gunicorn: error: argument --max-requests: expected one argumentsuperset_app exited with code 2superset_worker_beat    | ERROR: Pidfile (/tmp/celerybeat.pid) already exists.superset_worker_beat    | Seems we're already running? (pid: 8)superset_worker_beat    | Loaded your LOCAL configuration at [/app/docker/pythonpath_dev/superset_config.py]superset_worker_beat    | celery beat v5.2.2 (dawn-chorus) is starting.superset_worker         | Loaded your LOCAL configuration at [/app/docker/pythonpath_dev/superset_config.py]superset_worker         |superset_worker         |  -------------- celery@c4a746c651f6 v5.2.2 (dawn-chorus)superset_worker         | --- ***** -----superset_worker         | -- ******* ---- Linux-5.10.104-linuxkit-x86_64-with-glibc2.2.5 2022-07-18 14:34:16superset_worker         | - *** --- * ---superset_worker         | - ** ---------- [config]superset_worker         | - ** ---------- .> app:         __main__:0x4025c7e430superset_worker         | - ** ---------- .> transport:   redis://redis:6379/0superset_worker         | - ** ---------- .> results:     redis://redis:6379/1superset_worker         | - *** --- * --- .> concurrency: 4 (prefork)superset_worker         | -- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)superset_worker         | --- ***** -----superset_worker         |  -------------- [queues]superset_worker         |                 .> celery           exchange=celery(direct) key=celerysuperset_worker         |superset_worker         |superset_worker         | [tasks]superset_worker         |   . cache-warmupsuperset_worker         |   . cache_chart_thumbnailsuperset_worker         |   . cache_dashboard_thumbnailsuperset_worker         |   . load_chart_data_into_cachesuperset_worker         |   . load_explore_json_into_cachesuperset_worker         |   . reports.executesuperset_worker         |   . reports.prune_logsuperset_worker         |   . reports.schedulersuperset_worker         |   . sql_lab.get_sql_resultssuperset_worker         |superset_worker         | /usr/local/lib/python3.8/site-packages/celery/platforms.py:840: SecurityWarning: You're running the worker with superuser privileges: this issuperset_worker         | absolutely not recommended!superset_worker         |superset_worker         | Please specify a different user using the --uid option.superset_worker         |superset_worker         | User information: uid=0 euid=0 gid=0 egid=0superset_worker         |superset_worker         |   warnings.warn(SecurityWarning(ROOT_DISCOURAGED.format(superset_worker         | [2022-07-18 14:34:16,396: WARNING/MainProcess] /usr/local/lib/python3.8/site-packages/celery/app/utils.py:204: CDeprecationWarning:superset_worker         |     The 'CELERY_IMPORTS' setting is deprecated and scheduled for removal insuperset_worker         |     version 6.0.0. Use the imports insteadsuperset_worker         |superset_worker         |   deprecated.warn(description=f'The {setting!r} setting',superset_worker         |superset_worker         | [2022-07-18 14:34:16,398: WARNING/MainProcess] /usr/local/lib/python3.8/site-packages/celery/app/utils.py:204: CDeprecationWarning:superset_worker         |     The 'BROKER_URL' setting is deprecated and scheduled for removal insuperset_worker         |     version 6.0.0. Use the broker_url insteadsuperset_worker         |superset_worker         |   deprecated.warn(description=f'The {setting!r} setting',superset_worker         |superset_worker         | [2022-07-18 14:34:16,398: WARNING/MainProcess] /usr/local/lib/python3.8/site-packages/celery/app/utils.py:204: CDeprecationWarning:superset_worker         |     The 'CELERYBEAT_SCHEDULE' setting is deprecated and scheduled for removal insuperset_worker         |     version 6.0.0. Use the beat_schedule insteadsuperset_worker         |superset_worker         |   deprecated.warn(description=f'The {setting!r} setting',superset_worker         |superset_worker         | [2022-07-18 14:34:16,399: WARNING/MainProcess] /usr/local/lib/python3.8/site-packages/celery/app/utils.py:204: CDeprecationWarning:superset_worker         |     The 'CELERY_RESULT_BACKEND' setting is deprecated and scheduled for removal insuperset_worker         |     version 6.0.0. Use the result_backend insteadsuperset_worker         |superset_worker         |   deprecated.warn(description=f'The {setting!r} setting',superset_worker         |superset_worker         | [2022-07-18 14:34:16,399: WARNING/MainProcess] /usr/local/lib/python3.8/site-packages/celery/app/utils.py:204: CDeprecationWarning:superset_worker         |     The 'CELERY_ACKS_LATE' setting is deprecated and scheduled for removal insuperset_worker         |     version 6.0.0. Use the task_acks_late insteadsuperset_worker         |superset_worker         |   deprecated.warn(description=f'The {setting!r} setting',superset_worker         |superset_worker         | [2022-07-18 14:34:16,400: WARNING/MainProcess] /usr/local/lib/python3.8/site-packages/celery/app/utils.py:204: CDeprecationWarning:superset_worker         |     The 'CELERYD_PREFETCH_MULTIPLIER' setting is deprecated and scheduled for removal insuperset_worker         |     version 6.0.0. Use the worker_prefetch_multiplier insteadsuperset_worker         |superset_worker         |   deprecated.warn(description=f'The {setting!r} setting',superset_worker         |superset_worker         | [2022-07-18 14:34:16,400: WARNING/MainProcess] Please run `celery upgrade settings path/to/settings.py` to avoid these warnings and to allow a smoother upgrade to Celery 6.0.superset_worker_beat    | Skipping local overridessuperset_worker_beat    | Starting Celery beat...superset_worker         | [2022-07-18 14:34:17,489: INFO/MainProcess] Connected to redis://redis:6379/0superset_worker         | [2022-07-18 14:34:17,499: INFO/MainProcess] mingle: searching for neighborssuperset_worker         | [2022-07-18 14:34:18,545: INFO/MainProcess] mingle: all alonesuperset_worker         | [2022-07-18 14:34:18,624: INFO/MainProcess] celery@c4a746c651f6 ready.superset_init           | INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.superset_init           | INFO  [alembic.runtime.migration] Will assume transactional DDL.superset_app            | Skipping local overridessuperset_app            | Starting web app...superset_init           | Loaded your LOCAL configuration at [/app/docker/pythonpath_dev/superset_config.py]superset_init           |superset_init           | ######################################################################superset_init           |superset_init           |superset_init           | Init Step 1/4 [Complete] -- Applying DB migrationssuperset_init           |superset_init           |superset_init           | ######################################################################superset_init           |superset_init           |superset_init           | ######################################################################superset_init           |superset_init           |superset_init           | Init Step 2/4 [Starting] -- Setting up admin user ( admin / admin )superset_init           |superset_init           |superset_init           | ######################################################################superset_init           |superset_app            | usage: gunicorn [OPTIONS] [APP_MODULE]superset_app            | gunicorn: error: argument --max-requests: expected one argumentsuperset_app exited with code 2superset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    |                                     WARNINGsuperset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    | A Default SECRET_KEY was detected, please use superset_config.py to override it.superset_worker_beat    | Use a strong complex alphanumeric string and use a tool to help you generatesuperset_worker_beat    | a sufficiently random sequence, ex: openssl rand -base64 42superset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    | logging was configured successfullysuperset_worker_beat    | 2022-07-18 14:34:26,721:INFO:superset.utils.logging_configurator:logging was configured successfullysuperset_worker_beat    | 2022-07-18 14:34:26,732:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>superset_worker_beat    | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker_beat    | 2022-07-18 14:34:26,747:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker_beat    | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker_beat    | 2022-07-18 14:34:26,764:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker_beat    | Loaded your LOCAL configuration at [/app/docker/pythonpath_dev/superset_config.py]superset_worker_beat    | celery beat v5.2.2 (dawn-chorus) is starting.superset_worker_beat    | ERROR: Pidfile (/tmp/celerybeat.pid) already exists.superset_worker_beat    | Seems we're already running? (pid: 8)superset_init           | --------------------------------------------------------------------------------superset_init           |                                     WARNINGsuperset_init           | --------------------------------------------------------------------------------superset_init           | A Default SECRET_KEY was detected, please use superset_config.py to override it.superset_init           | Use a strong complex alphanumeric string and use a tool to help you generatesuperset_init           | a sufficiently random sequence, ex: openssl rand -base64 42superset_init           | --------------------------------------------------------------------------------superset_init           | --------------------------------------------------------------------------------superset_init           | logging was configured successfullysuperset_init           | 2022-07-18 14:34:35,164:INFO:superset.utils.logging_configurator:logging was configured successfullysuperset_init           | 2022-07-18 14:34:35,194:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>superset_init           | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_init           | 2022-07-18 14:34:35,208:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_init           | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_init           | 2022-07-18 14:34:35,223:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker_beat exited with code 73superset_worker_beat    | Skipping local overridessuperset_worker_beat    | Starting Celery beat...superset_app            | Skipping local overridessuperset_app            | Starting web app...superset_app            | usage: gunicorn [OPTIONS] [APP_MODULE]superset_app            | gunicorn: error: argument --max-requests: expected one argumentsuperset_app exited with code 2superset_init           | Loaded your LOCAL configuration at [/app/docker/pythonpath_dev/superset_config.py]superset_init           | Recognized Database Authentications.superset_init           | Error! User already exists adminsuperset_init           |superset_init           | ######################################################################superset_init           |superset_init           |superset_init           | Init Step 2/4 [Complete] -- Setting up admin usersuperset_init           |superset_init           |superset_init           | ######################################################################superset_init           |superset_init           |superset_init           | ######################################################################superset_init           |superset_init           |superset_init           | Init Step 3/4 [Starting] -- Setting up roles and permssuperset_init           |superset_init           |superset_init           | ######################################################################superset_init           |superset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    |                                     WARNINGsuperset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    | A Default SECRET_KEY was detected, please use superset_config.py to override it.superset_worker_beat    | Use a strong complex alphanumeric string and use a tool to help you generatesuperset_worker_beat    | a sufficiently random sequence, ex: openssl rand -base64 42superset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    | logging was configured successfullysuperset_worker_beat    | 2022-07-18 14:34:45,750:INFO:superset.utils.logging_configurator:logging was configured successfullysuperset_worker_beat    | 2022-07-18 14:34:45,761:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>superset_worker_beat    | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker_beat    | 2022-07-18 14:34:45,773:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker_beat    | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker_beat    | 2022-07-18 14:34:45,796:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker_beat    | Loaded your LOCAL configuration at [/app/docker/pythonpath_dev/superset_config.py]superset_worker_beat    | celery beat v5.2.2 (dawn-chorus) is starting.superset_worker_beat    | ERROR: Pidfile (/tmp/celerybeat.pid) already exists.superset_worker_beat    | Seems we're already running? (pid: 8)superset_worker_beat exited with code 73superset_worker_beat    | Skipping local overridessuperset_worker_beat    | Starting Celery beat...superset_init           | --------------------------------------------------------------------------------superset_init           |                                     WARNINGsuperset_init           | --------------------------------------------------------------------------------superset_init           | A Default SECRET_KEY was detected, please use superset_config.py to override it.superset_init           | Use a strong complex alphanumeric string and use a tool to help you generatesuperset_init           | a sufficiently random sequence, ex: openssl rand -base64 42superset_init           | --------------------------------------------------------------------------------superset_init           | --------------------------------------------------------------------------------superset_init           | logging was configured successfullysuperset_init           | 2022-07-18 14:34:56,616:INFO:superset.utils.logging_configurator:logging was configured successfullysuperset_init           | 2022-07-18 14:34:56,639:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>superset_init           | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_init           | 2022-07-18 14:34:56,652:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_init           | Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_init           | 2022-07-18 14:34:56,666:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentssuperset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    |                                     WARNINGsuperset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    | A Default SECRET_KEY was detected, please use superset_config.py to override it.superset_worker_beat    | Use a strong complex alphanumeric string and use a tool to help you generatesuperset_worker_beat    | a sufficiently random sequence, ex: openssl rand -base64 42superset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    | --------------------------------------------------------------------------------superset_worker_beat    | logging was configured successfullysuperset_worker_beat    | 2022-07-18 14:35:03,295:INFO:superset.utils.logging_configurator:logging was configured successfullysuperset_worker_beat    | 2022-07-18 14:35:03,305:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>superset_worker_beat    "
20576,1,0,0,0,0,kamalkeshavani-aiinside,0,"title:[SQL Lab] Saved Queries do not include parameters. description:If a query with parameters is saved, the parameters are not stored with the query. So when executing a saved query, query fails without the necessary parameters.#### How to reproduce the bug1. Create a query with parameters2. Run and save the query3. Go to Saved Queries, and run in SQL Lab### Expected resultsSaved Query should have the parameters.### Actual resultsSaved Query does not have parameters.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment- browser type and version:- superset version: `master`Dockerhub image- any feature flags active: ENABLE_TEMPLATE_PROCESSING### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextIn 'saved_query' table of metadata, there is column 'extra_json' which can/should be used to store the parameters.
"
20464,1,0,20,0,0,pankajsoni22,0,"title:[Greemplum database connector is not working] - Not able to connect with Greenplum(Postgresql) database. description:Giving import error while trying to connect to greenplum database#### How to reproduce the bug1. Add database and select 'Other' from list2. Add greenplum sqlalchemy uri: greenplum:///?User=<user>&;Password=<password>&Database=<db_name>&Server=<host_name/ip>&Port=<port_name>3. Click on test connection4. Error shows:ERROR: cannot import name 'coercions' from 'sqlalchemy.sql' (/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/__init__.py)### Expected resultsNaturally I've added driver ""sqlalchemy_greenplum"" and wanted to connect greenplum database. It should list in the list of added database list.### Actual resultsIt throws 'sqlalchemy' import error#### Screenshots![image](https://user-images.githubusercontent.com/39917736/175021085-841facc4-1383-4cd1-bfa4-b1b1e87a90ca.png)### Environment(please complete the following information):- browser type and version: Chrome Version 102.0.5005.115 (Official Build) (64-bit)- superset version: `latest`- python version: `3.8`- node.js version: `16`- any feature flags active: no### ChecklistI've install drive ""sqlalchemy_greenplum"".For further reference sqlalchemy allowed in superset is 1.3.24 which gives the above error but I tried with sqlalchemy==1.4.+ and this is working. 
"
20450,1,1565,7,0,0,dheardal,0,"title:Postgres timestamp with timezone causes error. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Setup a postgres table with a timestamp with time zone (timstamptz) column2. Query that column using sql editor or consume that column in a chart3. See error### Expected resultsBe able to see the column### Actual results```superset_1        | Traceback (most recent call last):superset_1        |   File ""/app/superset/views/base.py"", line 211, in wrapssuperset_1        |     return f(self, *args, **kwargs)superset_1        |   File ""/app/superset/utils/log.py"", line 245, in wrappersuperset_1        |     value = f(*args, **kwargs)superset_1        |   File ""/app/superset/views/core.py"", line 2574, in sql_jsonsuperset_1        |     command_result: CommandResult = command.run()superset_1        |   File ""/app/superset/sqllab/command.py"", line 104, in runsuperset_1        |     raise exsuperset_1        |   File ""/app/superset/sqllab/command.py"", line 96, in runsuperset_1        |     status = self._run_sql_json_exec_from_scratch()superset_1        |   File ""/app/superset/sqllab/command.py"", line 138, in _run_sql_json_exec_from_scratchsuperset_1        |     raise exsuperset_1        |   File ""/app/superset/sqllab/command.py"", line 133, in _run_sql_json_exec_from_scratchsuperset_1        |     return self._sql_json_executor.execute(superset_1        |   File ""/app/superset/sqllab/sql_json_executer.py"", line 111, in executesuperset_1        |     raise SupersetErrorsException(superset_1        | superset.exceptions.SupersetErrorsException: [SupersetError(message=""'+00'"", error_type=<SupersetErrorType.GENERIC_DB_ENGINE_ERROR: 'GENERIC_DB_ENGINE_ERROR'>, level=<ErrorLevel.ERROR: 'error'>, extra={'engine_name': 'PostgreSQL', 'issue_codes': [{'code': 1002, 'message': 'Issue 1002 - The database returned an unexpected error.'}]})]```#### Screenshots<img width=""1004"" alt=""Screenshot 2022-06-21 at 11 28 46"" src=""https://user-images.githubusercontent.com/56386166/174778852-49154faa-bc43-4478-a6b4-136a2c44ca7e.png"">### Environment(please complete the following information):- browser type and version: Chrome 102- superset version: 1.5.1- python version:  3.8- node.js version: none- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextThis was not an issue in the 1.4.2.May be similar to #19995
"
20436,0,305,0,0,0,LuPan2015,0,"title:Cursor falls behind in SQL Lab. description:When typing in SQL Lab, the cursor slowly falls behind the characters.# Expected resultsTyping to be normal# Actual results ```SELECT    database,    table,    partition,    sum(rows) AS rows,    count() AS part_countFROM system.partsWHERE (active = 1) AND (table ='game_match_log') AND (database ='gem') and partition =  ''GROUP BY    database,    table,    partitionORDER BY part_count DESC;limit 30;```https://user-images.githubusercontent.com/10804128/174222924-b61f595e-59cb-467d-b00e-662196fd242f.mp4
"
20428,0,17498,4,0,0,Thelin90,0,"title:Presto-Trino Does Not Work Superset Version 1.5.1 - Solution Found. description:I am currently deploying the latest version of superset in my local k8s (helm). I have added trino package, but also tried sqlalchemy-trino . And I can see it gets installed, all fine.Superset boots up and all look fine.I have a presto - trino deployment running in local k8s (coordinator + hive metastore). For the presto-trino deployment I am running, I am not using any user/password, since I just want to verify the functionality.When I connect to trino, the database connection is OK! Works fine no worries.I can then extract metadata information around catalog and schema. But when I try to display data, I get this weird error logs from superset:```bashTraceback (most recent call last):  File ""/app/superset/sql_lab.py"", line 275, in execute_sql_statement    db_engine_spec.handle_cursor(cursor, query, session)  File ""/app/superset/db_engine_specs/presto.py"", line 970, in handle_cursor    polled = cursor.poll()AttributeError: 'Cursor' object has no attribute 'poll'```#### How to reproduce the bug1. Run a `presto-trino` cluster with version  >= `385 `. Then install `superset` via docs: https://superset.apache.org/docs/installation/running-on-kubernetes/2. Use official `superset helm` with `image tag`, and modify to install `sqlalchemy-trino`, I have used following `values.yaml`: ```yaml## Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements.  See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the ""License""); you may not use this file except in compliance with# the License.  You may obtain a copy of the License at##    http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an ""AS IS"" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.## Default values for superset.# This is a YAML-formatted file.# Declare variables to be passed into your templates.replicaCount: 1# User ID directive. This user must have enough permissions to run the bootstrap script# Runn containers as root is not recommended in production. Change this to another UID - e.g. 1000 to be more securerunAsUser: 0# Create custom service account for Superset. If create: true and name is not provided, superset.fullname will be used.# serviceAccountName: supersetserviceAccount:  create: false# Install additional packages and do any other bootstrap configuration in this script# For production clusters it's recommended to build own image with this step done in CIbootstrapScript: |  #!/bin/bash  rm -rf /var/lib/apt/lists/* && \  pip install \    psycopg2-binary==2.9.1 \    --upgrade trino \    --upgrade pyhive \    redis==3.5.3 && \  if [ ! -f ~/bootstrap ]; then echo ""Running Superset with uid {{ .Values.runAsUser }}"" > ~/bootstrap; fi## The name of the secret which we will use to generate a superset_config.py file## Note: this secret must have the key superset_config.py in it and can include other files as well##configFromSecret: '{{ template ""superset.fullname"" . }}-config'## The name of the secret which we will use to populate env vars in deployed pods## This can be useful for secret keys, etc.##envFromSecret: '{{ template ""superset.fullname"" . }}-env'## This can be a list of template stringsenvFromSecrets: []## Extra environment variables that will be passed into pods##extraEnv: {}  # Extend timeout to allow long running queries.  # GUNICORN_TIMEOUT: 300  # OAUTH_HOME_DOMAIN: ..  # # If a whitelist is not set, any address that can use your OAuth2 endpoint will be able to login.  # #   this includes any random Gmail address if your OAuth2 Web App is set to External.  # OAUTH_WHITELIST_REGEX: ...## Extra environment variables in RAW format that will be passed into pods##extraEnvRaw: []  # Load DB password from other secret (e.g. for zalando operator)  # - name: DB_PASS  #   valueFrom:  #     secretKeyRef:  #       name: superset.superset-postgres.credentials.postgresql.acid.zalan.do  #       key: password## Extra environment variables to pass as secrets##extraSecretEnv: {}  # MAPBOX_API_KEY: ...  # # Google API Keys: https://console.cloud.google.com/apis/credentials  # GOOGLE_KEY: ...  # GOOGLE_SECRET: ...extraConfigs: {}  # import_datasources.yaml: |  #     databases:  #     - allow_file_upload: true  #       allow_ctas: true  #       allow_cvas: true  #       database_name: example-db  #       extra: ""{\r\n    \""metadata_params\"": {},\r\n    \""engine_params\"": {},\r\n    \""\  #         metadata_cache_timeout\"": {},\r\n    \""schemas_allowed_for_file_upload\"": []\r\n\  #         }""  #       sqlalchemy_uri: example://example-db.local  #       tables: []extraSecrets: {}extraVolumes: [] # - name: customConfig #   configMap: #     name: '{{ template ""superset.fullname"" . }}-custom-config' # - name: additionalSecret #   secret: #     secretName: my-secret #     defaultMode: 0600extraVolumeMounts: [] # - name: customConfig #   mountPath: /mnt/config #   readOnly: true # - name: additionalSecret: #   mountPath: /mnt/secret# A dictionary of overrides to append at the end of superset_config.py - the name does not matter# WARNING: the order is not guaranteedconfigOverrides: {}  #  extend_timeout: |  #    # Extend timeout to allow long running queries.  #    SUPERSET_WEBSERVER_TIMEOUT = ...  # enable_oauth: |  #   from flask_appbuilder.security.manager import (AUTH_DB, AUTH_OAUTH)  #   AUTH_TYPE = AUTH_OAUTH  #   OAUTH_PROVIDERS = [  #       {  #           ""name"": ""google"",  #           ""whitelist"": [ os.getenv(""OAUTH_WHITELIST_REGEX"", """") ],  #           ""icon"": ""fa-google"",  #           ""token_key"": ""access_token"",  #           ""remote_app"": {  #               ""client_id"": os.environ.get(""GOOGLE_KEY""),  #               ""client_secret"": os.environ.get(""GOOGLE_SECRET""),  #               ""api_base_url"": ""https://www.googleapis.com/oauth2/v2/"",  #               ""client_kwargs"": {""scope"": ""email profile""},  #               ""request_token_url"": None,  #               ""access_token_url"": ""https://accounts.google.com/o/oauth2/token"",  #               ""authorize_url"": ""https://accounts.google.com/o/oauth2/auth"",  #               ""authorize_params"": {""hd"": os.getenv(""OAUTH_HOME_DOMAIN"", """")}  #           }  #       }  #   ]  #   # Map Authlib roles to superset roles  #   AUTH_ROLE_ADMIN = 'Admin'  #   AUTH_ROLE_PUBLIC = 'Public'  #   # Will allow user self registration, allowing to create Flask users from Authorized User  #   AUTH_USER_REGISTRATION = True  #   # The default user self registration role  #   AUTH_USER_REGISTRATION_ROLE = ""Admin""  # secret: |  #   # Generate your own secret key for encryption. Use openssl rand -base64 42 to generate a good key  #   SECRET_KEY = 'YOUR_OWN_RANDOM_GENERATED_SECRET_KEY'# Same as above but the values are filesconfigOverridesFiles: {}  # extend_timeout: extend_timeout.py  # enable_oauth: enable_oauth.pyconfigMountPath: ""/app/pythonpath""extraConfigMountPath: ""/app/configs""image:  repository: apache/superset  tag: latest  pullPolicy: IfNotPresentimagePullSecrets: []initImage:  repository: busybox  tag: latest  pullPolicy: IfNotPresentservice:  type: ClusterIP  port: 8088  annotations: {}    # cloud.google.com/load-balancer-type: ""Internal""  loadBalancerIP: nullingress:  enabled: false  # ingressClassName: nginx  annotations: {}    # kubernetes.io/tls-acme: ""true""    ## Extend timeout to allow long running queries.    # nginx.ingress.kubernetes.io/proxy-connect-timeout: ""300""    # nginx.ingress.kubernetes.io/proxy-read-timeout: ""300""    # nginx.ingress.kubernetes.io/proxy-send-timeout: ""300""  path: /  pathType: ImplementationSpecific  hosts:    - chart-example.local  tls: []  #  - secretName: chart-example-tls  #    hosts:  #      - chart-example.localresources: {}  # We usually recommend not to specify default resources and to leave this as a conscious  # choice for the user. This also increases chances charts run on environments with little  # resources, such as Minikube. If you do want to specify resources, uncomment the following  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.  # The limits below will apply to all Superset components. To set individual resource limitations refer to the pod specific values below.  # The pod specific values will overwrite anything that is set here.  # limits:  #   cpu: 100m  #   memory: 128Mi  # requests:  #   cpu: 100m  #   memory: 128Mi#### Custom hostAliases for all superset pods## https://kubernetes.io/docs/tasks/network/customize-hosts-file-for-pods/hostAliases: []# - hostnames:#   - nodns.my.lan#   ip: 18.27.36.45#### Superset node configurationsupersetNode:  command:    - ""/bin/sh""    - ""-c""    - "". {{ .Values.configMountPath }}/superset_bootstrap.sh; /usr/bin/run-server.sh""  connections:    # Change in case of bringing your own redis and then also set redis.enabled:false    redis_host: '{{ template ""superset.fullname"" . }}-redis-headless'    # redis_password: superset    redis_port: ""6379""    # You need to change below configuration incase bringing own PostgresSQL instance and also set postgresql.enabled:false    db_host: '{{ template ""superset.fullname"" . }}-postgresql'    db_port: ""5432""    db_user: superset    db_pass: superset    db_name: superset  env: {}  forceReload: false # If true, forces deployment to reload on each upgrade  initContainers:    - name: wait-for-postgres      image: ""{{ .Values.initImage.repository }}:{{ .Values.initImage.tag }}""      imagePullPolicy: ""{{ .Values.initImage.pullPolicy }}""      envFrom:        - secretRef:            name: '{{ tpl .Values.envFromSecret . }}'      command: [ ""/bin/sh"", ""-c"", ""until nc -zv $DB_HOST $DB_PORT -w1; do echo 'waiting for db'; sleep 1; done"" ]  ## Annotations to be added to supersetNode deployment  deploymentAnnotations: {}  ## Annotations to be added to supersetNode pods  podAnnotations: {}  ## Labels to be added to supersetNode pods  podLabels: {}  # Resource settings for the supersetNode pods - these settings overwrite might existing values from the global resources object defined above.  resources: {}    # limits:    #  cpu: 100m    #  memory: 128Mi    # requests:    #  cpu: 100m    #  memory: 128Mi#### Superset worker configurationsupersetWorker:  command:    - ""/bin/sh""    - ""-c""    - "". {{ .Values.configMountPath }}/superset_bootstrap.sh; celery --app=superset.tasks.celery_app:app worker""  forceReload: false # If true, forces deployment to reload on each upgrade  initContainers:    - name: wait-for-postgres      image: ""{{ .Values.initImage.repository }}:{{ .Values.initImage.tag }}""      imagePullPolicy: ""{{ .Values.initImage.pullPolicy }}""      envFrom:        - secretRef:            name: '{{ tpl .Values.envFromSecret . }}'      command: [ ""/bin/sh"", ""-c"", ""until nc -zv $DB_HOST $DB_PORT -w1; do echo 'waiting for db'; sleep 1; done"" ]  ## Annotations to be added to supersetWorker deployment  deploymentAnnotations: {}  ## Annotations to be added to supersetWorker pods  podAnnotations: {}  ## Labels to be added to supersetWorker pods  podLabels: {}  # Resource settings for the supersetWorker pods - these settings overwrite might existing values from the global resources object defined above.  resources: {}    # limits:    #  cpu: 100m    #  memory: 128Mi    # requests:    #  cpu: 100m    #  memory: 128Mi#### Superset beat configuration (to trigger scheduled jobs like reports)supersetCeleryBeat:  # This is only required if you intend to use alerts and reports  enabled: false  command:    - ""/bin/sh""    - ""-c""    - "". {{ .Values.configMountPath }}/superset_bootstrap.sh; celery --app=superset.tasks.celery_app:app beat --pidfile /tmp/celerybeat.pid --schedule /tmp/celerybeat-schedule""  forceReload: false # If true, forces deployment to reload on each upgrade  initContainers:    - name: wait-for-postgres      image: ""{{ .Values.initImage.repository }}:{{ .Values.initImage.tag }}""      imagePullPolicy: ""{{ .Values.initImage.pullPolicy }}""      envFrom:        - secretRef:            name: '{{ tpl .Values.envFromSecret . }}'      command: [ ""/bin/sh"", ""-c"", ""until nc -zv $DB_HOST $DB_PORT -w1; do echo 'waiting for db'; sleep 1; done"" ]  ## Annotations to be added to supersetCeleryBeat deployment  deploymentAnnotations: {}  ## Annotations to be added to supersetCeleryBeat pods  podAnnotations: {}  ## Labels to be added to supersetCeleryBeat pods  podLabels: {}  # Resource settings for the CeleryBeat pods - these settings overwrite might existing values from the global resources object defined above.  resources: {}    # limits:    #  cpu: 100m    #  memory: 128Mi    # requests:    #  cpu: 100m    #  memory: 128Mi#### Init job configurationinit:  # Configure resources  # Warning: fab command consumes a lot of ram and can  # cause the process to be killed due to OOM if it exceeds limit  # Make sure you are giving a strong password for the admin user creation( else make sure you are changing after setup)  # Also change the admin email to your own custom email.  resources: {}    # limits:    #   cpu:    #   memory:    # requests:    #   cpu:    #   memory:  command:    - ""/bin/sh""    - ""-c""    - "". {{ .Values.configMountPath }}/superset_bootstrap.sh; . {{ .Values.configMountPath }}/superset_init.sh""  enabled: true  loadExamples: false  createAdmin: true  adminUser:    username: admin    firstname: Superset    lastname: Admin    email: admin@superset.com    password: admin  initContainers:    - name: wait-for-postgres      image: ""{{ .Values.initImage.repository }}:{{ .Values.initImage.tag }}""      imagePullPolicy: ""{{ .Values.initImage.pullPolicy }}""      envFrom:        - secretRef:            name: '{{ tpl .Values.envFromSecret . }}'      command: [ ""/bin/sh"", ""-c"", ""until nc -zv $DB_HOST $DB_PORT -w1; do echo 'waiting for db'; sleep 1; done"" ]  initscript: |-    #!/bin/sh    set -eu    echo ""Upgrading DB schema...""    superset db upgrade    echo ""Initializing roles...""    superset init    {{ if .Values.init.createAdmin }}    echo ""Creating admin user...""    superset fab create-admin \                    --username {{ .Values.init.adminUser.username }} \                    --firstname {{ .Values.init.adminUser.firstname }} \                    --lastname {{ .Values.init.adminUser.lastname }} \                    --email {{ .Values.init.adminUser.email }} \                    --password {{ .Values.init.adminUser.password }} \                    || true    {{- end }}    {{ if .Values.init.loadExamples }}    echo ""Loading examples...""    superset load_examples    {{- end }}    if [ -f ""{{ .Values.extraConfigMountPath }}/import_datasources.yaml"" ]; then      echo ""Importing database connections.... ""      superset import_datasources -p {{ .Values.extraConfigMountPath }}/import_datasources.yaml    fi  ## Annotations to be added to init job pods  podAnnotations: {}#### Configuration values for the postgresql dependency.## ref: https://github.com/kubernetes/charts/blob/master/stable/postgresql/README.mdpostgresql:  ##  ## Use the PostgreSQL chart dependency.  ## Set to false if bringing your own PostgreSQL.  enabled: true  ## Authentication parameters  auth:    ## The name of an existing secret that contains the postgres password.    existingSecret:    ## PostgreSQL name for a custom user to create    username: superset    ## PostgreSQL password for the custom user to create. Ignored if `auth.existingSecret` with key `password` is provided    password: superset    ## PostgreSQL name for a custom database to create    database: superset  ## PostgreSQL Primary parameters  primary:    ##    ## Persistent Volume Storage configuration.    ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes    persistence:      ##      ## Enable PostgreSQL persistence using Persistent Volume Claims.      enabled: true      ##      ## Persistant class      # storageClass: classname      ##      ## Access modes:      accessModes:        - ReadWriteOnce    ## PostgreSQL port    service:      ports:        postgresql: ""5432""## Configuration values for the Redis dependency.## ref: https://github.com/bitnami/charts/blob/master/bitnami/redis## More documentation can be found here: https://artifacthub.io/packages/helm/bitnami/redisredis:  ##  ## Use the redis chart dependency.  ##  ## If you are bringing your own redis, you can set the host in supersetNode.connections.redis_host  ##  ## Set to false if bringing your own redis.  enabled: true  ##  ## Set architecture to standalone/replication  architecture: standalone  ##  ## Auth configuration:  ##  auth:    ## Enable password authentication    enabled: false    ## The name of an existing secret that contains the redis password.    existingSecret: """"    ## Name of the key containing the secret.    existingSecretKey: """"    ## Redis password    password: superset  ##  ## Master configuration  ##  master:    ##    ## Image configuration    # image:      ##      ## docker registry secret names (list)      # pullSecrets: nil    ##    ## Configure persistance    persistence:      ##      ## Use a PVC to persist data.      enabled: false      ##      ## Persistant class      # storageClass: classname      ##      ## Access mode:      accessModes:      - ReadWriteOncenodeSelector: {}tolerations: []affinity: {}```### Expected resultsBeing able to query `delta.io` table via `presto-trino` deployment.### Actual resultsNo output.### Root Cause To ProblemThere was a chance to the codebase via this commit:https://github.com/apache/superset/commit/b08e21efd906d13994414b39bfa7f6e98466d4cb### SolutionAfter downgrading to `1.5.0`, querying works, so the change from:`BaseEngineSpec` -> `PrestoEngineSpec` is causing the issue.#### ScreenshotsWhen troubles:<img width=""526"" alt=""image (3)"" src=""https://user-images.githubusercontent.com/19892351/174393160-e07de6f9-20d8-4991-8fa8-de568e1c1225.png""><img width=""941"" alt=""image (2)"" src=""https://user-images.githubusercontent.com/19892351/174393166-893c0145-74f9-4d04-b16a-04baffcc0242.png""><img width=""1413"" alt=""image (1)"" src=""https://user-images.githubusercontent.com/19892351/174393170-a148a914-71e6-4038-ad4a-b52a50612760.png"">When downgrading to `1.5.0`<img width=""949"" alt=""image"" src=""https://user-images.githubusercontent.com/19892351/174393758-bde585b6-f49d-4c1e-8724-dd399ec8101c.png"">### Environment- browser type and version:- superset version: `1.5.1`- python version: `Python 3.8.12`
"
20421,1,0,3,0,0,shafad1,0,"title:Cannot convert superset http to https. description:i have done the configuration in config.py SUPERSET_WEBSERVER_PROTOCOL = ""https""SUPERSET_WEBSERVER_ADDRESS = ""0.0.0.0""SUPERSET_WEBSERVER_PORT = 443after done this configuration still superset is able to run with http only.. can anyone suggest the exact steps to solve this , 
"
20418,0,0,8,0,0,zhaorui2022,0,"title:Transient query execution errors sent to alert owners as alert failure notifications. description:When executing alert queries, if there is any transient errors, the error will be sent to users as alert failures. However, this could be avoided by adding retries.#### How to reproduce the bugThis bug can only be reproduced when there is any transient error when executing queries.### Expected resultsIf the alert itself is working, users shouldn't receive a notification saying the alert fails. ### Actual resultsWhen there is a transient error, users will receive a notification with the transient error message.And also, the error message isn't helpful for alert owners to debug as it is usually internal errors.#### ScreenshotsN/A### Environment(please complete the following information):- browser type and version: This is caused by backend and it applies to all browser types and versions.- superset version: `superset version`: latest- python version: `python --version`: any python version- node.js version: `node -v` N/A- any feature flags active: None### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
20391,0,0,0,0,0,huypn1106,0,"title:Pivot v2 doesn't apply color weight for values of Conditional formatting metrics. description:## DescriptionI recently upgraded superset to newest version and I'm unable to create Conditional formatting for Pivot table v2 as before. When I select color, it apply the same color weight for all values of metric.Settings of older version still here but when I change to another color, the color weight the same for all values. I think it cause by the change of color value from rgb(0,255,0) to color hex code.Working settings from old version display on new version:![image](https://user-images.githubusercontent.com/32066762/173777448-abf8d962-88aa-4294-bb4d-ba2d65093127.png)## ScreenshotCurrent Version:![image](https://user-images.githubusercontent.com/32066762/173775214-fab481a3-72b4-4261-b611-32a2eebf9a2f.png)Expected as Older version:![image](https://user-images.githubusercontent.com/32066762/173774657-88c5e06e-6776-40ed-9fe8-8e5601d0ae86.png)
"
20388,1,0,4,0,0,kkfnui,0,"title:Dataset edit UI can't show all `SQL expression` content. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to 'Dataset'2. Click on 'edit' any dataset 3. Change tab to metrics4. Add any longer  sql expression  like   `count(distinct if(event='hello', user_id, null))`### Expected resultsA clear UI,### Actual resultswhat actually happens.#### Screenshots<img width=""836"" alt=""iShot_2022-06-15_11 50 03"" src=""https://user-images.githubusercontent.com/1238381/173734070-8e7597c6-7e53-44d2-b177-87add0f3a836.png"">If applicable, add screenshots to help explain your problem.## Any MoreCan we redesign  this UI?
"
20386,0,259,276,0,0,eschutho,1,"title:Toolbar is missing on some pages. description:Toolbar is missing on SqlLab and Explore, and maybe a few other places. The error I'm seeing is: ```LocationProvider.js?e373:13 Uncaught Error: useQueryParams must be used within a QueryParamProvider    at useLocationContext (LocationProvider.js?e373:13:1)    at useQueryParams (useQueryParams.js?5bf2:71:1)    at RightMenu (MenuRight.tsx?488f:99:1)```#### How to reproduce the bug1. Go to SqlLab or Explore2. See error (no toolbar)### Expected resultsToolbar should be present### Actual resultsNo toolbar#### Screenshots![_DEV__Games_per_Genre](https://user-images.githubusercontent.com/5186919/173706874-df35ccf3-85c4-4439-9a36-e5723c6555d2.png)![_DEV__Superset](https://user-images.githubusercontent.com/5186919/173706893-1f16efe5-2779-46e6-9cd0-e24a80063661.png)### Environment- browser type and version: Chrome- superset version: `superset version` Master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
20378,1,0,0,0,0,ValentinC-BR,0,"title:[TimeSeriesBarChart V2] Wrong row limit displayed. description:The number of rows displayed at the top of a timeseries bar chart v2 is wrong.When you reach the row limit (e.g. 1000), some data is missing in the chart, BUT the number of rows (at the top) is wrong.This a big issue, as this leads to wrong interpretations of the results.#### How to reproduce the bug1. Create a timeseries bar chart v22. Group By a dimension3. Set the limit to a small number (< total rows expected)4. Run and watch the number of rows5. Do the same with the previous timeseries chart6. Look at the number of rows : the limit is reached### Expected resultsThere should be a clear message indicating the the row limit was reached### Actual resultsAccording to the UI, the row limit is not reached#### Screenshots##### TimeSeries Bar Chart v2 (missing bars, ""592 rows"")![image](https://user-images.githubusercontent.com/79460908/173566828-92de2a5e-3b8f-450f-ab65-8390b87c6ba8.png)##### TimeSeries Bar Chart (legacy)![image](https://user-images.githubusercontent.com/79460908/173566895-3c39221f-013e-4d2c-981d-93de73d2720e.png)### Environment(please complete the following information):- browser type and version: Google Chrome Version 94.0.4606.71 (Oficial build) (x86_64)- superset version: 1.5.0 (same issue in previous versions)- python version: 3.7.9- node.js version: doesn't apply, I run on Kubernetes, using gunicorn as server- source : AWS Athena- any feature flags active: /### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
20376,1,0,0,0,1,mlmaverick,0,"title:Unable to use gradients as colors for worldmap. description:We recently upgraded the Superset version to 1.5.0 and I'm unable to deselect the `Categorical Color Scheme` for a heat map on the world map. From the what I understood, the colors schemes for a dashboard are now fixed to the dashboard but what do we do when we need to show gradients on the plot. #### How to reproduce the bug1. Create a dashboard with multiple charts and one of them is with country data on world map.2. Create a chart with world map with gradient color scheme.### Expected results![image](https://user-images.githubusercontent.com/105640903/173549335-c0abd98a-6cc7-4fef-8b39-1b0a634e524f.png)### Actual results![image](https://user-images.githubusercontent.com/105640903/173547661-a3497a5f-e86b-431d-a172-bb0502c1bb99.png)### Environment(please complete the following information):- browser type and version:  Chrome Version 102.0.5005.115- superset version: `1.5.0`- python version: `3.8.12`Any help with this regards would be helpful. Thanks!
"
20343,1,1959,4,0,0,kkfnui,0,"title:For Time range filter  custom type , If start  is Now, and End is Specific Time Will  cause error . description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to 'And Chart'2. Click on 'Time'3. Config custom  start is Now, and End is Specific Time -- as  next hour4. wait for more than an hour,5. Dashboard will raise server error, And We can't edit chart from dashboarderror stack```File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/api/_init_闂傚倸鍊烽懗鍫曞磻閵娾晛纾挎繛宸簻閻ゅ墽绱?"
20335,1,0,6,0,0,apecortes,0,"title:Metric calculation error ""Part of a Whole"". description:On Superset 1.5.0.#### How to reproduce the bugGiving the following dataset:![image](https://user-images.githubusercontent.com/91876082/172872466-d147603b-d896-4673-aeae-3dce4820c5d3.png)Having created the metric Users: COUNT(DISTINCT userId). We see that there are 4 DISTINCT userId. But the calculation at the level of the parent is a sum of the children, and it is not correct.There is no difference between COUNT and COUNT DISTINCT.### Expected resultsThe expected result is that at the level of the parent there will be 4 and not 5.### Actual resultsThe end result is that COUNT(userId) and COUNT(DISTINCT userId) give the same result.#### Screenshots**COUNT**![image](https://user-images.githubusercontent.com/91876082/172873875-220e0fdc-7c76-4e9b-bab9-a2a878cb31fe.png)**COUNT DISTINCT**![image](https://user-images.githubusercontent.com/91876082/172873729-086a4b35-8d06-41e6-82a2-283cfcc0bb48.png)### Additional contextAdd any other context about the problem here.
"
20334,1,0,12,0,0,oleg-savko,0,"title:Annotation Formula not displayed with Generic Chart Axes enabled. description:Annotation Layer:  Formula not displayed , if  feature flag:`""GENERIC_CHART_AXES"": True`Tested Superset version: 1.5.1Tested Database: ClickhouseIf disable `""GENERIC_CHART_AXES"": False` than annotation start to displayed correctExpected: Annotation Layer:  Formula displayed correct
"
20329,1,0,0,0,0,Asturias-sam,0,"title:Getting Error while running Queries on SQL LAB for MSSQL. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Enable MSSQL DataSource.2. Run Query on SQL LAB 3.  Create Charts### Expected resultsShould able to run querywhat you expected to happen.Should able to run query via SQL Lab### Actual resultsFor Point 2 : Run Query on SQL LAB I am getting this error : '_AppCtxGlobals' object has no attribute 'user'For Point 3: If we create charts directly via Charts tab it's working fine#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version:  1.1.0- python version: `python --version` 3.7.9- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
20288,1,0,1,0,0,HazemBittar,0,"title:Dashboard import asking for password database failed . description:Make sure these boxes are checked before submitting your issue - thank you! - [x]    I have reproduced the issue with at least the latest released version of superset - [x]   I have checked the superset logs for python stacktraces and included it here as text if any - [x]   I have checked the issue tracker for the same issue and I haven't found one similarSuperset versionsuperset==1.4.1Expected resultsImport dashboard from on instance to anotherActual resultsFails on import after ask me for database password and i added the password with no success! i connect the database and the test connection good! i used sql server as datasource ""mssql+pymssql://sa:XXXXXXXXXX@hostname/database""Steps to reproduceThis is the error:An error occurred while importing database: Error importing databaseTraceback (most recent call last): 2022-06-07 11:32:40,626:INFO:superset.dashboards.commands.importers.dispatcher:Command failed validationsuperset_1                | Error importing dashboardsuperset_1                | 2022-06-07 11:32:40,627:WARNING:superset.views.base:Error importing dashboardsuperset_1                | Command failed validationsuperset_1                | 2022-06-07 11:33:09,308:INFO:superset.dashboards.commands.importers.dispatcher:Command failed validationsuperset_1                | Error importing dashboardsuperset_1                | 2022-06-07 11:33:09,308:WARNING:superset.views.base:Error importing dashboardsuperset_1                | /usr/local/lib/python3.8/site-packages/flask_caching/__init__.py:201: UserWarning: Flask-Caching: CACHE_TYPE is set to null, caching is effectively disabled.superset_1                |   warnings.warn(superset_1                | Unable to load dialect <class 'sqlalchemy.dialects.mssql.adodbapi.MSDialect_adodbapi'>: type object 'MSDialect_adodbapi' has no attribute 'dbapi'superset_1                | 2022-06-07 11:33:29,972:WARNING:superset.db_engine_specs:Unable to load dialect <class 'sqlalchemy.dialects.mssql.adodbapi.MSDialect_adodbapi'>: type object 'MSDialect_adodbapi' has no attribute 'dbapi'superset_1                | 2022-06-07 11:33:30,260:DEBUG:snowflake.connector.ssl_wrap_socket:Injecting ssl_wrap_socket_with_ocspsuperset_1                | /usr/local/lib/python3.8/site-packages/snowflake/connector/options.py:94: UserWarning: You have an incompatible version of 'pyarrow' installed (4.0.1), please install a version that adheres to: 'pyarrow<6.1.0,>=6.0.0; extra == ""pandas""'superset_1                |   warn_incompatible_dep(superset_1                | 2022-06-07 11:33:30,263:DEBUG:snowflake.connector.auth:cache directory: /root/.cache/snowflakesuperset_1                | Unable to load dialect <class 'sqlalchemy.dialects.mssql.adodbapi.MSDialect_adodbapi'>: type object 'MSDialect_adodbapi' has no attribute 'dbapi'superset_1                | 2022-06-07 11:34:46,360:WARNING:superset.db_engine_specs:Unable to load dialect <class 'sqlalchemy.dialects.mssql.adodbapi.MSDialect_adodbapi'>: type object 'MSDialect_adodbapi' has no attribute 'dbapi'superset_1                | 2022-06-07 11:34:46,827:DEBUG:snowflake.connector.ssl_wrap_socket:Injecting ssl_wrap_socket_with_ocspsuperset_1                | /usr/local/lib/python3.8/site-packages/snowflake/connector/options.py:94: UserWarning: You have an incompatible version of 'pyarrow' installed (4.0.1), please install a version that adheres to: 'pyarrow<6.1.0,>=6.0.0; extra == ""pandas""'superset_1                |   warn_incompatible_dep(superset_1                | 2022-06-07 11:34:46,833:DEBUG:snowflake.connector.auth:cache directory: /root/.cache/snowflakesuperset_1                | Command failed validationsuperset_1                | 2022-06-07 11:35:36,352:INFO:superset.dashboards.commands.importers.dispatcher:Command failed validationsuperset_1                | Error importing dashboardsuperset_1                | 2022-06-07 11:35:36,352:WARNING:superset.views.base:Error importing dashboardsuperset_1                | Command failed validationsuperset_1                | 2022-06-07 11:35:50,702:INFO:superset.dashboards.commands.importers.dispatcher:Command failed validationsuperset_1                | Error importing dashboardsuperset_1                | 2022-06-07 11:35:50,703:WARNING:superset.views.base:Error importing dashboardi tried using commend line give me error 濠碘槅鍋撶徊浠嬪疮椤栫偛鐤柕蹇婃缁辨棃鏌涢幇鈺佸婵?# superset import-dashboards --path /home/superset/dashboard_export_20220607T122056.zipLoaded your LOCAL configuration at [/etc/superset/superset_config.py]logging was configured successfully2022-06-07 12:36:06,938:INFO:superset.utils.logging_configurator:logging was configured successfully2022-06-07 12:36:06,946:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>/usr/local/lib/python3.8/site-packages/flask_caching/__init__.py:201: UserWarning: Flask-Caching: CACHE_TYPE is set to null, caching is effectively disabled.  warnings.warn(Command failed validation2022-06-07 12:36:08,614:INFO:superset.dashboards.commands.importers.dispatcher:Command failed validationThere was an error when importing the dashboards(s), please check the exception traceback in the logTraceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/superset/cli.py"", line 360, in import_dashboards    ImportDashboardsCommand(contents, overwrite=True).run()  File ""/usr/local/lib/python3.8/site-packages/superset/dashboards/commands/importers/dispatcher.py"", line 64, in run    raise exc  File ""/usr/local/lib/python3.8/site-packages/superset/dashboards/commands/importers/dispatcher.py"", line 57, in run    command.run()  File ""/usr/local/lib/python3.8/site-packages/superset/commands/importers/v1/__init__.py"", line 63, in run    self.validate()  File ""/usr/local/lib/python3.8/site-packages/superset/commands/importers/v1/__init__.py"", line 146, in validate    raise exceptionsuperset.commands.exceptions.CommandInvalidError: Error importing dashboard2022-06-07 12:36:08,614:ERROR:superset.cli:There was an error when importing the dashboards(s), please check the exception traceback in the logTraceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/superset/cli.py"", line 360, in import_dashboards    ImportDashboardsCommand(contents, overwrite=True).run()  File ""/usr/local/lib/python3.8/site-packages/superset/dashboards/commands/importers/dispatcher.py"", line 64, in run    raise exc  File ""/usr/local/lib/python3.8/site-packages/superset/dashboards/commands/importers/dispatcher.py"", line 57, in run    command.run()  File ""/usr/local/lib/python3.8/site-packages/superset/commands/importers/v1/__init__.py"", line 63, in run    self.validate()  File ""/usr/local/lib/python3.8/site-packages/superset/commands/importers/v1/__init__.py"", line 146, in validate    raise exceptionsuperset.commands.exceptions.CommandInvalidError: Error importing dashboard
"
20286,0,0,0,1,0,erikclark,0,"title:In Superset, SQL LAB - >SQL EDITOR when running queries, final row is not visible. description:A clear and concise description of what the bug is.#### How to reproduce the bugWhen running query in SQL LAB - SQL Editor, when scrolling through the results, the final record is not visible. This appears to the same issue as previously reported. But issue is still occurring.  If I sort DESC, I can see the final row on top. If I sort ASC, I cannot see the final record.--Historical tickets that look similar.https://github.com/apache/superset/issues/11966https://github.com/apache/superset/issues/9869 ### Expected resultsI should see the last record in the set### Actual resultsI cannot see the final record#### ScreenshotsIn this screen shot I can see the record because it is on the top:![image](https://user-images.githubusercontent.com/107008937/172266442-b4461b7d-df32-4756-aadb-88c41cbd3d7f.png)However, when I sort Ascending, I cannot see this record even though I scrolled to the bottom of the page:![image](https://user-images.githubusercontent.com/107008937/172266597-aaadbd62-1d8d-42fe-9d58-5e3e88cda939.png)### Environment- browser type and version: same behavior in Microsoft Edge 102.0.1245.33 (Official build) (64-bit) andGoogle Chrome Version 102.0.5005.63 (Official Build) (64-bit)- superset version: 1.4.1
"
20262,0,0,8,0,0,zhaorui2022,0,"title:Referencing local variable response before initialiazing in get_chart_csv_data error handling . description:In [this line](https://github.com/apache/superset/blob/4f77824e550bc70d2f6365221b9078004d49b78c/superset/utils/csv.py#L83), it is trying to access `response` before it is initialized if `auth_cookies` is false. Will send a PR after creating this issue.#### How to reproduce the bug1. Run with an unauthorized user name to create an alert. When the alerts fails and tries to send a notification, it fails with error message `Failed generating csv local variable 'response' referenced before assignment`.### Expected resultsIf running with unauthorized user name, it should just fails to retrieve data.### Actual resultsIt fails with error message `Failed generating csv local variable 'response' referenced before assignment`#### ScreenshotsN/A### Environment(please complete the following information):- browser type and version: It is a backend error and is happening to all browsers - superset version: `superset version` latest- python version: `python --version` 3.9- node.js version: `node -v` N/A- any feature flags active: N/A### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
20217,1,0,0,0,0,saberhosseini,0,"title:Add visualization as python script & R script Like Powerbi . description:Adding Python script or R Script as Visual is very necessary.Is there a solution?
"
20208,0,0,3,0,0,humbledude,0,"title:database access on [DATABASE] does not allow read data sources. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. set permission on Role : `database access on [DATABASE]`2. login user with the role3. add a dataset in [DATABASE]### Expected resultsaccess to the dataset### Actual resultsthe dataset is not available (not showing)### Environmentusing helm chart (0.5.10), docker image (apache/superset:1.5.0)(please complete the following information):- browser type and version: chrome  101.0.4951.64- superset version: 1.5.0- python version: 3.8.12- node.js version:- any feature flags active: ldap enabled, ### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contexthttps://superset.apache.org/docs/security/#permissionsdocuments says `Granting access to a database allows for the user to access all data sources within that database`and when I grant `schema access on [DATABASE.SCHEMA]` then it works well on the schema only
"
20199,1,0,0,0,0,phrozenzero,0,"title:ModuleNotFoundError: No module named 'werkzeug.wrappers.etag' on superset db upgrade [Fedora]. description:I followed the README.md and ran the following commands after initiating the venv.> pip3 install apache-superset> superset db upgrade.superset db upgrade fails with the following error:> /superset/superset/utils/cache.py"", line 28, in <module>    from werkzeug.wrappers.etag import ETagResponseMixinModuleNotFoundError: No module named 'werkzeug.wrappers.etag'
"
20198,1,0,0,0,0,G0m3e,0,"title:With GENERIC_CHART_AXES enabled, SORT BY doesn't seem to work. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Dataset SQL as below`SELECT 'Total' AS `TYPE`, 111 AS `T_NUM`UNION ALLSELECT 'Average of Go-live', 10UNION ALLSELECT 'Average of Project', 200`2. Make a new Bar Chart v2 and select TYPE  as X-AXIS, 3. ""SORT BY"" with custom sql below`FIELD(TYPE, 'Total', 'Average of Project', 'Average of Go-live')`4. See error### Expected resultsx-axis shows in order of  'Total', 'Average of Project', 'Average of Go-live'### Actual resultsx-axis always shows in order of  'Average of Go-live', 'Average of Project', 'Total' no matter SORT BY is enabled or notPS: the same SORT BY sql works with ""Bar Chart""#### Screenshots![image](https://user-images.githubusercontent.com/19158762/170416177-a1e3b94f-e57c-4bdd-b323-d34d5353ac41.png)### Environment(please complete the following information):- browser type and version: Edge  101.0.1210.53- superset version: 1.5.0- python version: 3.8.9- node.js version: v16.13.2- any feature flags active: GENERIC_CHART_AXES### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
20168,1,0,2,0,0,azadsagar,0,"title:AttributeError: 'Select' object has no attribute '_simple_int_clause'. description:Trying to use dataset via Athena Database. Using the latest docker image. I am getting below error and 500 on UI page.#### How to reproduce the bug1. Go to Datasets2. Click on +Datasets3. Select athena as database and select appropriate schema and table.4. Click on newly created dataset. you should see error.### Expected resultsShould be able to create chart from newaly added dataset (athena)### Actual results500 Internal server error.`'Select' object has no attribute '_simple_int_clause'Traceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1516, in full_dispatch_request    rv = self.dispatch_request()  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1502, in dispatch_request    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)  File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/decorators.py"", line 133, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/utils/log.py"", line 245, in wrapper    value = f(*args, **kwargs)  File ""/app/superset/views/core.py"", line 888, in explore    datasource_data = datasource.data if datasource else dummy_datasource_data  File ""/app/superset/connectors/sqla/models.py"", line 871, in data    data_ = super().data  File ""/app/superset/connectors/base/models.py"", line 293, in data    ""select_star"": self.select_star,  File ""/app/superset/connectors/sqla/models.py"", line 860, in select_star    return self.database.select_star(  File ""/app/superset/models/core.py"", line 485, in select_star    return self.db_engine_spec.select_star(  File ""/app/superset/db_engine_specs/base.py"", line 1129, in select_star    sql = database.compile_sqla_query(qry)  File ""/app/superset/models/core.py"", line 465, in compile_sqla_query    sql = str(qry.compile(engine, compile_kwargs={""literal_binds"": True}))  File ""<string>"", line 1, in <lambda>  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 481, in compile    return self._compiler(dialect, bind=bind, **kw)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 487, in _compiler    return dialect.statement_compiler(dialect, self, **kw)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 592, in __init__    Compiled.__init__(self, dialect, statement, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 322, in __init__    self.string = self.process(self.statement, **compile_kwargs)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 352, in process    return obj._compiler_dispatch(self, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/visitors.py"", line 96, in _compiler_dispatch    return meth(self, **kw)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 2201, in visit_select    text = self._compose_select_body(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 2320, in _compose_select_body    text += self.limit_clause(select, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/pyathena/sqlalchemy_athena.py"", line 90, in limit_clause    if limit_clause is not None and select._simple_int_clause(limit_clause):AttributeError: 'Select' object has no attribute '_simple_int_clause'2022-05-24 06:46:36,378:ERROR:superset.views.base:'Select' object has no attribute '_simple_int_clause'Traceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1516, in full_dispatch_request    rv = self.dispatch_request()  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1502, in dispatch_request    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)  File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/decorators.py"", line 133, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/utils/log.py"", line 245, in wrapper    value = f(*args, **kwargs)  File ""/app/superset/views/core.py"", line 888, in explore    datasource_data = datasource.data if datasource else dummy_datasource_data  File ""/app/superset/connectors/sqla/models.py"", line 871, in data    data_ = super().data  File ""/app/superset/connectors/base/models.py"", line 293, in data    ""select_star"": self.select_star,  File ""/app/superset/connectors/sqla/models.py"", line 860, in select_star    return self.database.select_star(  File ""/app/superset/models/core.py"", line 485, in select_star    return self.db_engine_spec.select_star(  File ""/app/superset/db_engine_specs/base.py"", line 1129, in select_star    sql = database.compile_sqla_query(qry)  File ""/app/superset/models/core.py"", line 465, in compile_sqla_query    sql = str(qry.compile(engine, compile_kwargs={""literal_binds"": True}))  File ""<string>"", line 1, in <lambda>  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 481, in compile    return self._compiler(dialect, bind=bind, **kw)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 487, in _compiler    return dialect.statement_compiler(dialect, self, **kw)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 592, in __init__    Compiled.__init__(self, dialect, statement, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 322, in __init__    self.string = self.process(self.statement, **compile_kwargs)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 352, in process    return obj._compiler_dispatch(self, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/visitors.py"", line 96, in _compiler_dispatch    return meth(self, **kw)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 2201, in visit_select    text = self._compose_select_body(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 2320, in _compose_select_body    text += self.limit_clause(select, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/pyathena/sqlalchemy_athena.py"", line 90, in limit_clause    if limit_clause is not None and select._simple_int_clause(limit_clause):AttributeError: 'Select' object has no attribute '_simple_int_clause'`#### Screenshots![2022-05-24 12-27-51](https://user-images.githubusercontent.com/8531843/169968430-9a78d1e1-496f-421a-bddc-884e000a6d44.png)### Environment- browser type and version: Chrome- superset version: `superset version` : Docker Image digest : 1d0a0c2923e5- python version: `python --version`  : Python 3.8.12- node.js version: `node -v` : NA- any feature flags active: NA### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextBrowser Endpoint : superset/explore/table/154/Let me know if additional information is required from metadata db.Code Snipet from SQLAlchemy:<code>    def limit_clause(self, select, **kw):        text = []        offset_clause = select._offset_clause        if offset_clause is not None and select._simple_int_clause(offset_clause):            text.append(                f"" OFFSET {self.process(offset_clause.render_literal_execute(), **kw)}""            )        limit_clause = select._limit_clause        if limit_clause is not None and select._simple_int_clause(limit_clause):            text.append(                f"" LIMIT {self.process(limit_clause.render_literal_execute(), **kw)}""            )        return ""\n"".join(text)</code>
"
20155,0,2700,5,0,0,ensky,0,"title:Big Number with Trendline coudn't work with PostgreSQL's date field. description:Big Number with Trendline coudn't work with PostgreSQL's date field.#### How to reproduce the bug1. Create a table with a column which type is ""date"" in postgresql2. Add that database and table as dataset to Superset3. Try to create a Big Number with Trendline chart with that dataset4. It shows ```Unexpected errorError: '+08'```which +08 is the timezone about your pgsql settings### Expected resultsThe chart should be draw successfully### Actual results```Unexpected errorError: '+08'```#### Screenshots![image](https://user-images.githubusercontent.com/797580/169739356-3dd586ee-d942-4169-b6b6-8baf8262d39e.png)#### Additional Error Log```Traceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1950, in full_dispatch_request    rv = self.dispatch_request()  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1936, in dispatch_request    return self.view_functions[rule.endpoint](**req.view_args)  File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/decorators.py"", line 190, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/utils/log.py"", line 245, in wrapper    value = f(*args, **kwargs)  File ""/app/superset/views/core.py"", line 2351, in results    return self.results_exec(key)  File ""/app/superset/views/core.py"", line 2419, in results_exec    obj = _deserialize_results_payload(  File ""/app/superset/views/utils.py"", line 625, in _deserialize_results_payload    df = result_set.SupersetResultSet.convert_table_to_df(pa_table)  File ""/app/superset/result_set.py"", line 177, in convert_table_to_df    return table.to_pandas(integer_object_nulls=True)  File ""pyarrow/array.pxi"", line 757, in pyarrow.lib._PandasConvertible.to_pandas  File ""pyarrow/table.pxi"", line 1748, in pyarrow.lib.Table._to_pandas  File ""/usr/local/lib/python3.8/site-packages/pyarrow/pandas_compat.py"", line 789, in table_to_blockmanager    blocks = _table_to_blocks(options, table, categories, ext_columns_dtypes)  File ""/usr/local/lib/python3.8/site-packages/pyarrow/pandas_compat.py"", line 1130, in _table_to_blocks    return [_reconstruct_block(item, columns, extension_columns)  File ""/usr/local/lib/python3.8/site-packages/pyarrow/pandas_compat.py"", line 1130, in <listcomp>    return [_reconstruct_block(item, columns, extension_columns)  File ""/usr/local/lib/python3.8/site-packages/pyarrow/pandas_compat.py"", line 733, in _reconstruct_block    dtype = make_datetimetz(item['timezone'])  File ""/usr/local/lib/python3.8/site-packages/pyarrow/pandas_compat.py"", line 758, in make_datetimetz    tz = pa.lib.string_to_tzinfo(tz)  File ""pyarrow/types.pxi"", line 1927, in pyarrow.lib.string_to_tzinfo  File ""pyarrow/error.pxi"", line 143, in pyarrow.lib.pyarrow_internal_check_status  File ""/usr/local/lib/python3.8/site-packages/pytz/__init__.py"", line 188, in timezone    raise UnknownTimeZoneError(zone)pytz.exceptions.UnknownTimeZoneError: '+08'2022-05-23 03:27:32,051:ERROR:superset.views.base:'+08'```### Environment- browser type and version: any browser- superset version: 1.5.0- python version: 3.8.12- any feature flags active:  - VERSIONED_EXPORT  - ENABLE_TEMPLATE_PROCESSING### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context- This issue doesn't exists in Superset-v1.4.0The SQL in the chart is```sqlSELECT DATE_TRUNC('day', publish_date) AS __timestamp,       count(*) AS countFROM  (SELECT publish_date   FROM software.package_file) AS virtual_tableGROUP BY DATE_TRUNC('day', publish_date)LIMIT 50000;```The error part seems to be the DATE_TRUNC function, it returns something like ""2022-05-23 12:00:00+08"". Which format seems to be errorly processed by pyarrow project.Accourding to pyarrow project, the timezone format seems to be like +08:00 format, maybe it's the root cuase? https://github.com/apache/arrow/blob/apache-arrow-5.0.0/python/pyarrow/types.pxi#L1915
"
20150,0,67,1,0,0,lfkpoa,0,"title:Sunburst is not using linear color scheme when secondary metric is provided. description:The sunburst chart allows to provide the primary metric and a secondary metric.On Customize it is possible to choose a color scheme and a linear color scheme.The hint on linear color scheme is ""When a secondary metric is provided, a linear color scale is used."".However, the linear color scheme is never used, even if I provide the second metric.It is not possible to unselect or clear the color scheme.Sunburst.js (line 492) tests the condition to set colorByCategory to false when the secondary metric is provided and is diferente than the primary metric.However, it also checks if the colorScheme was not provided:```if (metrics[0] !== metrics[1] && metrics[1] && !colorScheme ) {```But colorScheme is always present since there is no way to clear it.I tried commenting the !colorScheme test and the chart seemed to work properly.It used the linear color scheme correctly when I provided the secondary metric and used de color scheme by category otherwise.### Expected resultsI expected that the linear color scheme would be used instead of the color scheme based on categories.### Actual resultsIt keeps using the color scheme based on categories even when the secondary metric is used.I'm running docker-compose up based on main branch.### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context
"
20137,0,0,13,0,0,niravpeak,0,"title:redshift_connector Driver throws error while running SELECT 1 (or any query). description:A clear and concise description of what the bug is.We were using driver `redshift+psycopg2` , that worked well so far. As part of enhanced security we moved from that driver to `redshift+redshift_connector` driver. Although it does successful connect & dropdown of tables. it is unable to display correct dataset & getting mentioned error below:#### How to reproduce the bug1. install redshift_connector bootstrapScript: |  #!/bin/bash  rm -rf /var/lib/apt/lists/* && \  pip install \    psycopg2-binary==2.9.1 \    redis==3.5.3 \    sqlalchemy-redshift==0.8.9 \    redshift-connector==2.0.907 && \  if [ ! -f ~/bootstrap ]; then echo ""Running Superset with uid {{ .Values.runAsUser }}"" > ~/bootstrap; fi2. Go to 'databases' => Add database using username / password or IAM based. test connect3. Go to sql editor page4. select database & relevant schema.5. On editor type ""SELECT 1""6. See below error:First element of field tuple is neither a tuple nor str### Expected resultsOutput with data 1what you expected to happen.### Actual resultswhat actually happens.On pod we are getting below error trace: raceback (most recent call last):  File ""/app/superset/views/base.py"", line 207, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/utils/log.py"", line 245, in wrapper    value = f(*args, **kwargs)  File ""/app/superset/views/core.py"", line 2393, in sql_json    command_result: CommandResult = command.run()  File ""/app/superset/sqllab/command.py"", line 104, in run    raise ex  File ""/app/superset/sqllab/command.py"", line 96, in run    status = self._run_sql_json_exec_from_scratch()  File ""/app/superset/sqllab/command.py"", line 138, in _run_sql_json_exec_from_scratch    raise ex  File ""/app/superset/sqllab/command.py"", line 133, in _run_sql_json_exec_from_scratch    return self._sql_json_executor.execute(  File ""/app/superset/sqllab/sql_json_executer.py"", line 111, in execute    raise SupersetErrorsException(superset.exceptions.SupersetErrorsException: [SupersetError(message='First element of field tuple is neither a tuple nor str', error_type=<SupersetErrorType.GENERIC_DB_ENGINE_ERROR: 'GENERIC_DB_ENGINE_ERROR'>, level=<ErrorLevel.ERROR: 'error'>, extra={'engine_name': 'Amazon Redshift', 'issue_codes': [{'code': 1002, 'message': 'Issue 1002 - The database returned an unexpected error.'}]})]#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version: chrome:- superset version: `superset version`: Superset 0.0.0dev- python version: `python --version`: Python 3.8.12- node.js version: `node -v`: - any feature flags active: [ installed with helm chart ]helm install superset . --values=values.yaml -n superset-experiment### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.Few more details about debug trace from redshift_connector can be seen as below:2022-05-17 05:50:12,363:DEBUG:redshift_connector:===================================2022-05-17 05:50:12,363:DEBUG:redshift_connector.cursor:Cursor.paramstyle=named2022-05-17 05:50:12,363:DEBUG:redshift_connector.core:===================================2022-05-17 05:50:12,363:DEBUG:redshift_connector.core:Establishing a connection2022-05-17 05:50:12,363:DEBUG:redshift_connector.core:{'user': 'IAM:uksegmentexplorer', 'database': 'dev', 'application_name': 'sqlalchemy-redshift', 'replication': None, 'client_protocol_version': '2', 'driver_version': 'Redshift Python Driver 2.0.907', 'os_version': 'Linux-5.4.181-99.354.amzn2.x86_64-x86_64-with-glibc2.2.5'}2022-05-17 05:50:12,363:DEBUG:redshift_connector.core:===================================2022-05-17 05:50:12,369:DEBUG:redshift_connector.cursor:Cursor.paramstyle=format2022-05-17 05:50:12,369:DEBUG:redshift_connector.core:Sending start-up message2022-05-17 05:50:12,551:DEBUG:redshift_connector.core:Server indicated EXTENDED_RESULT_METADATA transfer protocol will be used rather than protocol requested by client: BINARY2022-05-17 05:50:12,551:DEBUG:redshift_connector.cursor:Cursor.paramstyle=format2022-05-17 05:50:12,559:DEBUG:redshift_connector.core:field count=1
"
20133,1,0,0,1,0,mickm,0,"title:Slack invite link expired. description:The Slack invite link has expired#### How to reproduce the bug1. Go to https://github.com/apache/superset OR https://superset.apache.org OR https://superset.apache.org/community2. Click on any of the ""Slack"" links3. Get error ""This link is no longer active.""### Expected resultsjoin the Superset Slack channel### Actual results""This link is no longer active. To join this workspace, you'll need to ask the person who originally invited you for a new link.""#### Screenshotsn/a### Environmentn/a### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextSimilar to: https://github.com/apache/superset/issues/19396 https://github.com/apache/superset/issues/17677 https://github.com/apache/superset/issues/8613
"
20105,0,1248,299,0,1,Nicoretti,0,"title:Add dataset does not work for Exasol backend when using pydobc based sqlalchemy dialect. description:Add dataset does not work for Exasol DB when using pydobc based sqlalchemy dialect. (see also https://github.com/exasol/sqlalchemy-exasol/issues/136)#### How to reproduce the bug0. Setup Exasol DB and add it as data source1. Go to 'Datasets'2. Click on '+ DATASET'3. Select the Exasol DB as database4. Select a schema containing views and tables5. Try to select a Table/Schema6. No Tables/Schemas are shown### Expected resultsTable(s) and view(s) of the specified schema are shown.### Actual resultsNo table(s) nor view(s) of the specified schema are shown.#### Screenshots**Expected result:**![image](https://user-images.githubusercontent.com/600911/168984838-bfdafc40-94bf-4b50-957f-d8a5ba327ae0.png)**Actual result**![image](https://user-images.githubusercontent.com/600911/168985019-2aec77b8-6f6a-49f7-97dd-060b8e794c56.png)### Log```2022-05-18 09:49:43,443:INFO:werkzeug: * Running on http://127.0.0.1:8000/ (Press CTRL+C to quit)2022-05-18 09:49:46,313:INFO:werkzeug:127.0.0.1 - - [18/May/2022 09:49:46] ""GET /api/v1/me/ HTTP/1.1"" 200 -2022-05-18 09:49:48,206:INFO:werkzeug:127.0.0.1 - - [18/May/2022 09:49:48] ""GET /api/v1/database/?q=(filters:!((col:database_name,opr:ct,value:%27%27)),order_columns:database_name,order_direction:asc,page:0,page_size:100) HTTP/1.1"" 200 -2022-05-18 09:49:49,715:INFO:werkzeug:127.0.0.1 - - [18/May/2022 09:49:49] ""GET /api/v1/database/?q=(filters:!((col:database_name,opr:ct,value:%27%27)),order_columns:database_name,order_direction:asc,page:0,page_size:100) HTTP/1.1"" 200 -2022-05-18 09:49:49,805:INFO:werkzeug:127.0.0.1 - - [18/May/2022 09:49:49] ""GET /api/v1/database/1/schemas/?q=(force:!f) HTTP/1.1"" 200 -Attempt to use a closed connection.2022-05-18 09:49:52,059:WARNING:superset.models.core:Attempt to use a closed connection.Attempt to use a closed connection.2022-05-18 09:49:52,112:WARNING:superset.models.core:Attempt to use a closed connection.2022-05-18 09:49:52,125:INFO:werkzeug:127.0.0.1 - - [18/May/2022 09:49:52] ""GET /superset/tables/1/test_get_metadata_functions_schema/undefined/false/ HTTP/1.1"" 200 -```### Environment- browser type and version: `Firefox 100.0`- superset version: `superset version` = `1.5.0`- python version: `python --version` = `3.9.7`- node.js version: `node -v` == `-`- any feature flags active: `exasol`### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextThis issue was discovered within the context of another issue (#16541). The reporter of that issue mentions that only the version`sqlalchemy-exasol 2.0.10` is working properly together with `superset`.We already have investigated this issue and can confirm that the cause of this issue is a bug in the exasol sqlalchemy dialect. For further details on the bug in the exasol dialect see also [sqlalchemy-exasol#issue-136](https://github.com/exasol/sqlalchemy-exasol/issues/136).A fix for the `sqlalchemy-exasol` issue is on the way, see [this PR](https://github.com/exasol/sqlalchemy-exasol/pull/137).Once the PR is merged and a new version of [sqlalchemy-exasol](https://pypi.org/project/sqlalchemy-exasol/) have been released, adjusting the version constrains of `sqlalchemy-exasol` within `superset` will fix this bug.
"
20101,1,224,4,1,0,M3gar00,0,"title:Default Login not working AWS ECS. description:I have used terraform to deploy Superset to ECS. In order to test baseline performance and connectivity, I left the username and password as the default: admin/admin.The Dockerfile I'm using looks like:```FROM apache/superset# Switching to root to install the required packagesUSER root# install trino so the Superset doesn't complain about it not being thereRUN pip install trinoUSER supersetENV SUPERSET_ENV dev```#### How to reproduce the bug1. Go to `superset.myDomain.com`2. enter `admin` for username3. enter `admin` for password### Expected resultsAbility to login### Actual results`Invalid login. Please try again.`### Environment- browser type and version: Chrome 101.0.4951.64- superset version: superset docker image:latest, digest: a8b3631068a6### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ X] I have reproduced the issue with at least the latest released version of superset.- [ X]  I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextI have looked at similar issues that are addressed in non AWS ECS environments and have tried solutions presented in issue [10547](https://github.com/apache/superset/issues/10547) and issue [10149](https://github.com/apache/superset/issues/10149). The solutions presented there have not born fruit in this environment.
"
20100,1,6792,29,0,0,EBoisseauSierra,0,"title:Error when trying to use a custom viz plugin as per blog post. description:I have created a HelloWorld custom viz plugin as per https://preset.io/blog/building-custom-viz-plugins-in-superset-v2/Yet Superset becomes unstable after I load it.#### How to reproduce the bug1. Follow the [blog post](https://preset.io/blog/building-custom-viz-plugins-in-superset-v2/) instructions up to the `npm run dev-server` code block.2. Run Superset in dev mode (cf. below),3. Open the browser and try to:  * Create a chart,  * List already existing charts.### Expected resultsIt works as in the blogpost.### Actual resultsI get a different kind of error in each case.#### Screenshots**Issue 1**: Adding new chart![Screenshot from 2022-05-17 16-10-55](https://user-images.githubusercontent.com/37387755/168845785-ed76c8d7-a765-4eca-97c4-dd92793ad50d.png)**Issue 2**: Listing charts![Screenshot from 2022-05-17 16-14-06](https://user-images.githubusercontent.com/37387755/168846317-2fd8c953-6395-46f8-953b-f546d63f544a.png)### Environment- browser type and version: Firefox DevEd 101.0b7- superset version: tested on `1.5.0` and `e69f6292c`- python version: `3.8.13`- node.js version: `16.14.2`- any feature flags active: n/a### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextI'm accessing Superset running:* `cd /tmp/superset-hello-world && npm run dev`* `cd superset && FLASK_ENV=development superset run -p 8088 --with-threads --reload --debugger `* `cd superset/superset-frontend && npm run dev-server`----```$ npm run dev-server> superset@1.5.0 dev-server> cross-env NODE_ENV=development BABEL_ENV=development node --max_old_space_size=4096 ./node_modules/webpack-dev-server/bin/webpack-dev-server.js --mode=development[Superset Plugin] Use symlink source for @superset-ui/chart-controls @ ./packages/superset-ui-chart-controls[Superset Plugin] Use symlink source for @superset-ui/core @ ./packages/superset-ui-core[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-calendar @ ./plugins/legacy-plugin-chart-calendar[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-chord @ ./plugins/legacy-plugin-chart-chord[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-country-map @ ./plugins/legacy-plugin-chart-country-map[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-event-flow @ ./plugins/legacy-plugin-chart-event-flow[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-heatmap @ ./plugins/legacy-plugin-chart-heatmap[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-histogram @ ./plugins/legacy-plugin-chart-histogram[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-horizon @ ./plugins/legacy-plugin-chart-horizon[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-map-box @ ./plugins/legacy-plugin-chart-map-box[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-paired-t-test @ ./plugins/legacy-plugin-chart-paired-t-test[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-parallel-coordinates @ ./plugins/legacy-plugin-chart-parallel-coordinates[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-partition @ ./plugins/legacy-plugin-chart-partition[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-pivot-table @ ./plugins/legacy-plugin-chart-pivot-table[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-rose @ ./plugins/legacy-plugin-chart-rose[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-sankey @ ./plugins/legacy-plugin-chart-sankey[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-sankey-loop @ ./plugins/legacy-plugin-chart-sankey-loop[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-sunburst @ ./plugins/legacy-plugin-chart-sunburst[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-treemap @ ./plugins/legacy-plugin-chart-treemap[Superset Plugin] Use symlink source for @superset-ui/legacy-plugin-chart-world-map @ ./plugins/legacy-plugin-chart-world-map[Superset Plugin] Use symlink source for @superset-ui/legacy-preset-chart-deckgl @ ./plugins/legacy-preset-chart-deckgl[Superset Plugin] Use symlink source for @superset-ui/legacy-preset-chart-nvd3 @ ./plugins/legacy-preset-chart-nvd3[Superset Plugin] Use symlink source for @superset-ui/plugin-chart-echarts @ ./plugins/plugin-chart-echarts[Superset Plugin] Use symlink source for @superset-ui/plugin-chart-handlebars @ ./plugins/plugin-chart-handlebars[Superset Plugin] Use symlink source for @superset-ui/plugin-chart-pivot-table @ ./plugins/plugin-chart-pivot-table[Superset Plugin] Use symlink source for @superset-ui/plugin-chart-table @ ./plugins/plugin-chart-table[Superset Plugin] Use symlink source for @superset-ui/plugin-chart-word-cloud @ ./plugins/plugin-chart-word-cloud[Superset Plugin] Use symlink source for @superset-ui/preset-chart-xy @ ./plugins/preset-chart-xy[Superset Plugin] Use symlink source for @superset-ui/switchboard @ ./packages/superset-ui-switchboard1% setup initialize[HPM] Proxy created: /  -> http://localhost:8088<i> [webpack-dev-server] Project is running at:<i> [webpack-dev-server] Loopback: http://localhost:9000/<i> [webpack-dev-server] On Your Network (IPv4): http://192.168.1.66:9000/<i> [webpack-dev-server] On Your Network (IPv6): http://[fe80::f23e:9459:7104:e585]:9000/<i> [webpack-dev-server] Content not from webpack is served from '/home/ebosi/documents/superset/static/assets' directory<i> [webpack-dev-server] 404s will fallback to '/index.html'794 assets10964 modulesWARNING in ./node_modules/@data-ui/shared/esm/enhancer/WithTooltip.js 3:60-78export 'withTooltipPropTypes' (imported as 'vxTooltipPropTypes') was not found in '@vx/tooltip/build/tooltips/TooltipWithBounds' (possible exports: __esModule, default)WARNING in ./src/dashboard/components/Header/index.jsx 60:8-35export 'UserWithPermissionsAndRoles' (imported as 'UserWithPermissionsAndRoles') was not found in 'src/types/bootstrapTypes' (possible exports: isUser, isUserWithPermissionsAndRoles)WARNING in ./src/visualizations/presets/MainPreset.js 168:10-39export 'SupersetPluginChartHelloWorld' (imported as 'SupersetPluginChartHelloWorld') was not found in 'superset-hello-world' (possible exports: SupersetHelloWorld)WARNING in ./src/components/Checkbox/index.tsx 19:0-74export 'CheckboxProps' (reexported as 'CheckboxProps') was not found in 'src/components/Checkbox/Checkbox' (possible exports: default)WARNING in ./src/components/Popover/index.tsx 20:0-48export 'PopoverProps' (reexported as 'PopoverProps') was not found in 'antd/lib/popover' (possible exports: __esModule, default)WARNING in ./src/components/Popover/index.tsx 21:0-52export 'TooltipPlacement' (reexported as 'TooltipPlacement') was not found in 'antd/lib/tooltip' (possible exports: __esModule, default)WARNING in ./src/utils/textUtils.ts 23:13-46Module not found: Error: Can't resolve '../../../superset_text' in '/home/ebosi/documents/superset/superset-frontend/src/utils'webpack 5.52.1 compiled with 7 warnings in 61633 ms[HPM] Proxy created: /  -> http://localhost:8088```----Error when trying to access `./chart/list`:> Unexpected error: TypeError: superset_hello_world__WEBPACK_IMPORTED_MODULE_54__.SupersetPluginChartHelloWorld is not a constructor```    in Unknown (at App.tsx:61)    in ErrorBoundary (at App.tsx:60)    in Suspense (at App.tsx:59)    in Route (at App.tsx:58)    in Switch (at App.tsx:57)    in LocationProvider (created by Context.Consumer)    in Route (created by QueryParamProvider)    in QueryParamProvider (at RootContextProviders.tsx:38)    in DynamicPluginProvider (at RootContextProviders.tsx:37)    in EmbeddedUiConfigProvider (at RootContextProviders.tsx:36)    in FlashProvider (at RootContextProviders.tsx:35)    in Unknown (at RootContextProviders.tsx:34)    in Provider (at RootContextProviders.tsx:33)    in ThemeProvider (at RootContextProviders.tsx:32)    in RootContextProviders (at App.tsx:54)    in Router (created by BrowserRouter)    in BrowserRouter (at App.tsx:52)    in App (created by HotExportedApp)    in AppContainer (created by HotExportedApp)    in HotExportedApp (at views/index.tsx:22)    ```
"
20074,0,0,0,0,0,cloainbuffer,0,"title:[GENERIC_CHART_AXES]  When timestamp values with dataset labels, timestamp format is not working  #bug. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Make Dataset and add label on timestamp column2. Set X-AXIS to labeled timestamp column### Expected resultsX-AXIS show formatted data by D3 format rule ### Actual resultsWhen dataset columns add label, generic chart x axis cannot adjust timestamp format#### Screenshots![superset_bug_report](https://user-images.githubusercontent.com/82880157/168534358-b0db166f-36c7-4d7b-af4a-8dcd8b824cf1.gif)### Environment""GLOBAL_ASYNC_QUERIES"": False,""ENABLE_TEMPLATE_PROCESSING"": True,""ENABLE_TEMPLATE_REMOVE_FILTERS"": True,""DASHBOARD_NATIVE_FILTERS"": True,""DASHBOARD_NATIVE_FILTERS_SET"": True,""ENABLE_EXPLORE_DRAG_AND_DROP"": True,""ENABLE_DND_WITH_CLICK_UX"": True,""OMNIBAR"": True,""GENERIC_CHART_AXES"": True,""DASHBOARD_CACHE"": True,### Checklist- [x]  I have checked the superset logs for python stacktraces and included it here as text if there are any. - [x] I have checked the issue tracker for the same issue and I haven't found one similar. ### Additional contextHere is output query`SELECT DATE_TRUNC('day', date) AS date,       sum(sales_dollar_amount) AS ""SUM(sales_dollar_amount)""FROM schm.""ek_store_sales_BASE_S""GROUP BY DATE_TRUNC('day', date)ORDER BY ""SUM(sales_dollar_amount)"" DESCLIMIT 10000;`It seems like generic chart cannot read label on dataset 
"
20072,1,0,0,0,0,kamalkeshavani-aiinside,0,"title:2 options inside top right '+' button not working. description:Two new options added under 'Data' in the top right '+' button do not work.<img width=""571"" alt=""image"" src=""https://user-images.githubusercontent.com/74634977/168519163-3ee1a8c9-cc49-4c69-9519-7439d2762339.png"">#### How to reproduce the bug1. Scroll over to '+' sign in the top-right corner to open the popup2. Scroll to 'Data' option to open another popup3. Click on any of first 2 options### Expected resultsThe UI should move to Add Database/Google Sheet screen.### Actual resultsNothing happens.#### ScreenshotsYou can see in the gif, that there are no links associated with the 2 buttons.![1 5_issue](https://user-images.githubusercontent.com/74634977/168519491-02ee12c8-674f-48a7-a3c1-f2142700c41a.gif)### Environment- browser type and version: Chrome v101- superset version: 1.5.0- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextNo error logs are seen in container.
"
20062,0,0,61,0,0,aehanno,0,"title:Impossible to have translation for DatePicker. description:Adding code to activate translation in DatePicker component
"
20060,0,0,61,0,1,aehanno,0,"title:Missing French Translation. description:Issues to add french translation missingStep : - [x]  The additional French translations- [ ] Fixing the untranslated strings- [ ] using gettext instead of lazy_gettext- [ ] translate variable- [ ] translate changed_on_delta_humanized
"
20054,1,0,0,0,0,Narendra678,0,"title:Disable Export permission from role in list of dashboards. description:Hi Team,I need to disable export option in superset, May i know which role(permissions) i have to remove.![image](https://user-images.githubusercontent.com/88739186/168248149-93be6c11-05cf-40d0-b4e7-e2f498a4efba.png)Regards,Naren
"
20047,0,0,26,0,0,stephenLYZ,1,"title:[native-filter] The bottom of the left sidebar looks weird in the safari.. description:## Screenshot<img width=""393"" alt=""image"" src=""https://user-images.githubusercontent.com/11830681/168119573-a4524f1d-f96f-470f-91a9-355af7137bfe.png"">
"
20037,1,0,9,0,0,srinisubramanian,0,"title:Export/Import does not import certification details and  Chart changes. description:Exporting a dashboard and importing it into another instance/landscape of Superset (where the dashboard was previously imported and created) prompts to overwrite and on confirmation imports.  The dashboard changes (title etc) are imported but the certification data entered for a dashboard is not imported.  Also any chart changes are not imported.#### How to reproduce the bug1.  Create a dashboard and add a chart.  Export and Import it to another instance where the dashboard does not exist.  Import is successful but the Dashboard Certification and Certified By details are not imported.2. Now make some change in the Dashboard like changing title and also changes in the include chart in the original instance like changing title or making changes to the chart itself.  Export the dashboard and import it to the second system.  The dashboard changes are imported but the Chart changes are NOT imported.3. For testing I exported only the chart and imported the chart and it works.  Looks like the overwrite of dashboard works but overwrite of chart is missing.### Expected resultsChart changes are also imported### Actual resultsChart changes are NOT imported#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version: Chrome latest- superset version: 1.5.0- python version: 3.8.12- node.js version: N/A- any feature flags active: DASHBOARD_RBAC, VERSIONED_EXPORT, ENABLE_TEMPLATE_PROCESSING and DASHBOARD_CROSS_FILTERS### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
20023,1,0,6,0,0,hijack-621,0,"title:execute  docker-compose -f docker-compose-non-dev.yml pull  get error  like  this. description:![image](https://user-images.githubusercontent.com/82790351/167793834-1c33f5ed-a1ca-4efc-8711-0ab8d2f4096b.png)
"
19994,0,437,10,0,0,iercan,0,"title:Can not create permalink on safari browser. description:We've just upgraded superset to 1.5.0. Our users using Safari browser reported that they are not able to create permalink on dashboard or in explore chart. I've also tested it on Safari and confirmed it is not working although it works on Chrome. When we click ""Copy permalink to clipboard "" we see below error. <img width=""496"" alt=""Screen Shot 2022-05-09 at 17 26 15"" src=""https://user-images.githubusercontent.com/3406152/167431725-7b9d7fc9-ed60-4ada-8b89-4f786e336f89.png"">In my investigation I realized backend creates permalink successfully but somehow frontend throw this error. #### How to reproduce the bug1. Open a dashboard with safari2. Click on 'Copy permalink to clipboard'3. See error### Expected resultsPermalink should be copied to clipboard### Actual resultsUI throws error although backend return success### Environment- browser type and version: Safari 14.1.2, Chrome 101- superset version: 1.5.0 installed with apache/superset docker image- any feature flags active:```    ""SQLLAB_BACKEND_PERSISTENCE"": True,    ""THUMBNAILS"": True,    ""THUMBNAILS_SQLA_LISTENERS"": True,    ""LISTVIEWS_DEFAULT_CARD_VIEW"": False,    ""ALERT_REPORTS"": True,    ""DASHBOARD_NATIVE_FILTERS"": True,    ""DASHBOARD_CROSS_FILTERS"": False,    ""DRUID_JOINS"": True,    ""DASHBOARD_NATIVE_FILTERS_SET"": True,    ""DASHBOARD_RBAC"": True,    ""ENABLE_EXPLORE_DRAG_AND_DROP"": True,    ""ENABLE_DND_WITH_CLICK_UX"": True,```
"
19990,1,0,78,0,0,RavazziniAndrea,0,"title:Can't open Explore from chart (v1.5.0). description:When in a dashboard, clicking on ""view chart in Explore"" on any chart, result in ""An error occurred while opening Explore"".The only way to enter in Explore is from the chart list (that keeps working as usual).#### Screenshot![exploreError](https://user-images.githubusercontent.com/74816007/167392027-f0a18ee9-135d-437b-b99e-7daf44485b6a.png)### Environment- browser type and version: Firefox 91.9.0esr (64-bit) & Chromium 101.0.4951.54 - superset version: 1.5.0- python version: 3.8.10- node.js version: 10.19.0Thanks
"
19986,0,449,38,0,0,dat-linux,0,"title:Fails to install on Python 3.10 because of Numpy dependency. description:#### How to reproduce the bug`python3.10 -m pip install apache-superset`### Expected resultsCorrect install### Actual resultserrors:see screenshots#### Screenshots![VirtualBox_DAT LInux_07_05_2022_14_31_38](https://user-images.githubusercontent.com/99078210/167254576-c63b32d4-2cbf-4a44-a648-f61cf95cc791.png)![VirtualBox_DAT LInux_07_05_2022_14_31_52](https://user-images.githubusercontent.com/99078210/167254578-47035105-91cc-4ede-869c-944ed5af0169.png)### EnvironmentUbuntu 22.04 with Python 3.10### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [y ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [y ] I have reproduced the issue with at least the latest released version of superset.- [ y] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextNot sure why **numpy 1.19.4** is being targeted, when the main config file stipulates **numpy=1.21.?** There must be a conflicting internal dependency via another package during the build stage.It's potentially **pyarrow==5.0.0** causing the problem, as when try to **pip install pyarrow=5.0.0** standalone the same problem arises.This is conmfirmed by the project.toml for pyarrow=5.0.0:```[build-system]requires = [    ""cython >= 0.29"",    ""numpy==1.16.6; python_version<'3.9'"",    ""numpy==1.19.4; python_version>='3.9'"",    ""setuptools"",    ""setuptools_scm"",    ""wheel""]```### RecommendationIf possible, Superset's **pyarrow** dependency should be upgraded to 6.0.0:```[build-system]requires = [    ""cython >= 0.29"",    ""numpy==1.16.6; python_version<'3.9'"",    ""numpy==1.19.4; python_version=='3.9'"",    ""numpy==1.21.3; python_version>'3.9'"",    ""setuptools"",    ""setuptools_scm"",    ""wheel""] ```
"
19985,1,0,0,0,0,wengieeee,0,"title:/api/v1/explore/form_data?tab_id=7 response 403 FORBIDDEN. description:PS : we update our superset from v1.4.1 to v1.5.0闂傚倷鐒︾€笛呯矙閹达附鍋ら柡澶嬪強ecially the database  `superset db upgrade`API  /api/v1/explore/form_data?tab_id=X always error闂傚倷鐒︾€笛呯矙閹达富鏁嗛柣鐘垫珴re are no specific errors reported in the log, and debug can't get in api code 闂?superset.explore.form_data.api.ExploreFormDataRestApi.post##### enter chart config page1. Go to  chart config page2. api  /api/v1/explore/form_data?tab_id=7  [METHOD POST] responses  403 FORBIDDEN![image](https://user-images.githubusercontent.com/16257260/167247140-3d53cb38-ee85-4f3f-8417-6354d4bf6ecb.png)![image](https://user-images.githubusercontent.com/16257260/167246530-4f47dc81-db31-431f-a594-02f7182e13f1.png)#### click run 3. Click on 'run' 4. api /api/v1/explore/form_data?tab_id=7  [METHOD PUT] responses 405 METHOD NOT ALLOWED![image](https://user-images.githubusercontent.com/16257260/167247173-4fc0dde0-edaf-4def-9298-ab9c20740491.png)![image](https://user-images.githubusercontent.com/16257260/167246565-504336f8-f190-4780-b491-722b2846493c.png)### we drop old mysql database and use `superset db upgrade` rebuild database , The problem won't happen### Environment- browser type and version: chrom- superset version: `superset version` : 1.4.1 updated to 1.5.0- python version: `python --version` : 3.9- DB : mysql
"
19974,0,399,32,0,0,rumbin,0,"title:[GENERIC_CHART_AXES] Custom SQL for x-axis is broken. description:Having GENERIC_CHART_AXES enabled, the x-Axis control works as expected when using existing columns (""simple"") and calculated columns (""saved""). However, when using ""custom sql"" Superset claims that 0 rows were returned, which is not true.#### How to reproduce the bug1. Enable the GENERIC_CHART_AXES feature flag2. Create a new chart of type Scatter Plot3. Choose any metric to be shown on the y-axis4. Define some custom SQL for the x-axis; this could be as simple as an existing column name written in parentheses or with added whitespace or so5. Run the query6. Realize that no data is shown in the chart7. Go to the hamburger menu and select _Run in SQLLab_8. Notice that in SQLLab there actually _are_ rows returned from this query### Expected resultsThe scatter plot shows all returned rows/records.### Actual resultsThe scatter plot is empty, claiming that no rows were returned by the query.#### Screenshots![xy_custom_sql](https://user-images.githubusercontent.com/1220356/167103065-fc71f91b-de6a-46fc-9f95-37eee58b8775.gif)### Environment(please complete the following information):- browser type and version: Chrome 100.0.4896.127 (Official Build) (64-bit)- superset version: 1.5 official docker image- feature flags:```""THUMBNAILS"": True,""THUMBNAILS_SQLA_LISTENERS"": True,""SQLLAB_BACKEND_PERSISTENCE"": True,""ENABLE_TEMPLATE_PROCESSING"": True,""DASHBOARD_CROSS_FILTERS"": True,""ALERT_REPORTS"": True,""ALERTS_ATTACH_REPORTS"": True,""DASHBOARD_NATIVE_FILTERS"": True,""GENERIC_CHART_AXES"": True,""ENABLE_EXPLORE_DRAG_AND_DROP"": True,""ENABLE_DND_WITH_CLICK_UX"": True,""DASHBOARD_NATIVE_FILTERS_SET"": True```### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19969,0,0,0,0,0,thinhnd2104,0,"title:Timestamp literal Athena. description:![image](https://user-images.githubusercontent.com/90733094/167061986-fce91b54-1f20-4ca4-8c29-1c46f05d407e.png)Make sure to follow these steps before submitting your issue - thank you!- [ x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ x] I have reproduced the issue with at least the latest released version of superset.- [x ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19947,1,0,0,0,0,poste0,0,"title:A lot of error messages on welcome page. description:There are a lot of error messages shown on the welcome page if a user doesn't have permissions to read Dashboards, Charts, Saved Queries or Recent activity. This happens In case of redirect from a forbidden page as well. This doesn't look well when a user sees an error messages stack at the time.#### How to reproduce the bug1. Create a role without permissions to read Dashboards, Charts, Saved Queries, Recent Activity2. Set this role only to a user3. Login as this user4. There are a lot of error messages on welcome page### Expected resultsDon't show a stack of messages to the user as it doesn't look well### Actual resultsThere are a lot of messages#### Screenshots![image](https://user-images.githubusercontent.com/26258521/166662882-66737bc6-6d7c-4716-af31-e08a1dd8ab0c.png)### Environment(please complete the following information):- browser type and version: Chrome 100.0.4896.127 and Microsoft Edge 101.0.1210.32- superset version: The latest version built from sources on master branch- python version: 3.8.10- node.js version: 16.9.1- any feature flags active: Checked on default superset from master branch
"
19915,1,818,27,0,0,xmnlab,0,"title:Not possible to register you at the moment, try again later: Can't flush None value found in collection User.roles. description:The user activation after the user registration is not working.#### How to reproduce the bug1. Go to 'Login'2. Click on 'Register'3. Create a new user4. from the email, activate it### Expected resultsthe user registration### Actual resultsit results in an error: ""Not possible to register you at the moment, try again later""from the console I have this:```epigraphhub_1     | 2022-05-01 23:33:34,133:INFO:werkzeug:181.188.176.197 - - [01/May/2022 23:33:34] ""POST /register/form HTTP/1.1"" 302 -epigraphhub_1     | 2022-05-01 23:33:34,413:INFO:werkzeug:181.188.176.197 - - [01/May/2022 23:33:34] ""GET / HTTP/1.1"" 302 -epigraphhub_1     | 2022-05-01 23:33:34,921:WARNING:root:Class 'werkzeug.local.LocalProxy' is not mappedepigraphhub_1     | 2022-05-01 23:33:34,943:INFO:werkzeug:181.188.176.197 - - [01/May/2022 23:33:34] ""GET /superset/welcome/ HTTP/1.1"" 200 -epigraphhub_1     | 2022-05-01 23:33:45,944:INFO:werkzeug:127.0.0.1 - - [01/May/2022 23:33:45] ""GET /health HTTP/1.1"" 200 -epigraphhub_1     | 2022-05-01 23:33:59,857:ERROR:flask_appbuilder.security.sqla.manager:Error adding new user to database. Can't flush None value found in collection User.roles```#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: `1.4.1`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.  - 1.5 is not available yet on conda-forge (but it needs first sqloxide and hashids on conda-forge, I am working on that)- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19907,1,0,2,0,1,missyoyo,0,"title:Can not down database driver followed ""Installing Superset Locally Using Docker Compose"" guide. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. I just git clone -b 1.4.2 superset.git and run it use default ""docker-compose-non-dev.yml""2. I add ""elasticsearch-dbapi"" to ./docker/requirements-local.txt and start it ""docker-compose-non-dev.yml up""3. and can no dowload database driversWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f8ce6d87160>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/elasticsearch-dbapi/5. actually,superset_worker_beat can not access internet,such as apt-update failed. curl my router web page failed. When i use ""docker exec -u root -it superset_worker_beat /bin/bash"" and try manual.apt update0% [Connecting to debian.map.fastlydns.net (151.101.74.132)] [Connecting to debian.map.fastlydns.net (151.101.74.132)]7. But I think my docker network works good. I have run a ubuntu container and connect to same netwok ""superset_default"".docker network inspect superset_default""Containers"": {            ""184b5d69e21a70e08c497662557d180e427d8bf9037f88d50d12f4ceb2c0827c"": {                ""Name"": ""superset_worker_beat"",                ""EndpointID"": ""3e255b369c2f441e129e915a6c93eddba0cb524c3173024f64c8dbcc3f460ea3"",                ""MacAddress"": ""02:42:c0:a8:40:07"",                ""IPv4Address"": ""192.168.64.7/20"",                ""IPv6Address"": """"            },        ""e7e49a3f097457083384b10eaf8b78cff2478a69c9f8d5ed53fbd0c553a7614d"": {                ""Name"": ""ubuntu"",                ""EndpointID"": ""2cfcccb90b8b82f6174b084a4e7df8e827f53b95e9434fa85fe5c1ad4456c0dc"",                ""MacAddress"": ""02:42:c0:a8:40:08"",                ""IPv4Address"": ""192.168.64.8/20"",                ""IPv6Address"": """"            }...""com.docker.compose.version"": ""1.29.2""...This ubuntu can access internet normally.So, may I know how to fix superset_worker_beat internet access or how I can install database driver offline, please.
"
19900,1,0,0,0,0,happy-hui1,0,"title:docker-compose up: Cannot start services superset_init闂傚倷鐒︾€笛呯矙閹达附鍎婇柛褜婀痳set_worker_beat闂傚倷绶氬褍螞濡ゅ懎纾归柛顐ｆ礀閻掑灚銇勯幒鍡椾壕闂佺锕ら悥濂稿春閳?""#### How to reproduce the bugRemoving superset_appRemoving superset_initRemoving superset_workerRemoving superset_worker_beatsuperset_cache is up-to-datesuperset_db is up-to-dateStarting superset_websocket ... Recreating 4e80981fc5ad_superset_app ... Starting superset_node               ... Starting superset_websocket                  ... doneRecreating a10d3d77804a_superset_worker ... Starting superset_node                       ... doneRecreating bc04ec33c40f_superset_init        ... errorERROR: for 6c79d9ae2119_superset_tests_worker  Cannot start service superset-tests-worker: OCI runtime create failed: container_linux.go:367: starting container process caused: exec: """"/app/docker/docker-bootstrap.sh"""": permission denied: unknownRecreating cc76d3717563_superset_worker_beat ... errorocess caused: exec: """"/app/docker/docker-init.sh"""": permission denied: unknownRecreating 4e80981fc5ad_superset_app         ... errorERROR: for cc76d3717563_superset_worker_beat  Cannot start service superset-worker-beat: OCI runtime create failed: container_linux.go:367: starting container process caused: exec: """"/app/docker/docker-bootstrap.sh"""": permission denied: unknownERROR: for a10d3d77804a_superset_worker  Cannot start service superset-worker: OCI runtime create failed: container_linux.go:367: starting container process caused: exec: """"/app/docker/docker-bootstrap.sh"""": permission denied: unknownERROR: for 4e80981fc5ad_superset_app  Cannot start service superset: OCI runtime create failed: container_linux.go:367: starting container process caused: exec: """"/app/docker/docker-bootstrap.sh"""": permission denied: unknownERROR: for superset-tests-worker  Cannot start service superset-tests-worker: OCI runtime create failed: container_linux.go:367: starting container process caused: exec: """"/app/docker/docker-bootstrap.sh"""": permission denied: unknownERROR: for superset-init  Cannot start service superset-init: OCI runtime create failed: container_linux.go:367: starting container process caused: exec: """"/app/docker/docker-init.sh"""": permission denied: unknownERROR: for superset-worker-beat  Cannot start service superset-worker-beat: OCI runtime create failed: container_linux.go:367: starting container process caused: exec: """"/app/docker/docker-bootstrap.sh"""": permission denied: unknownERROR: for superset-worker  Cannot start service superset-worker: OCI runtime create failed: container_linux.go:367: starting container process caused: exec: """"/app/docker/docker-bootstrap.sh"""": permission denied: unknownERROR: for superset  Cannot start service superset: OCI runtime create failed: container_linux.go:367: starting container process caused: exec: """"/app/docker/docker-bootstrap.sh"""": permission denied: unknownERROR: Encountered errors while bringing up the project.### Expected resultsAll containers to be succesfully deployed by Docker-Compose.### Actual resultsSuperset containers failed to be deployed because of error """"/app/docker/docker-bootstrap.sh"""": permission denied: unknown### How to reproduce the bugcd incubator-superset-masterdocker-compose up. description:"
19856,0,804,5,0,0,anied,0,"title:Import from `'antd'` is not allowed but the recommended alternative does not exist. description:I am developing a superset plugin locally, with a local dev setup propped up following the [instructions in `CONTRIBUTING.md`](https://github.com/apache/superset/blob/master/CONTRIBUTING.md).  In my `.tsx` file I am attempting to import several components from [`antd`](https://github.com/ant-design/ant-design) like so:```typescriptimport { Menu, Dropdown } from 'antd';```However, this generates the following lint warning:> `'antd' import is restricted from being used. Please import Ant components from the index of common/components`This appears to be defined in [superset frontend's `.eslintrc.js` file](https://github.com/apache/superset/blob/master/superset-frontend/.eslintrc.js#L243):```javascript'no-restricted-imports': [  'warn',  {    paths: [      {        name: 'antd',        message:          'Please import Ant components from the index of common/components',      },      {        name: '@superset-ui/core',        importNames: ['supersetTheme'],        message:          'Please use the theme directly from the ThemeProvider rather than importing supersetTheme.',      },    ],  },],```However, no such `common/components` directory seems to exist anywhere in the superset codebase.  Trying several permutations to get this import at some version of this path all fail.  **What is the correct, expected way in which to import `antd` components into a plugin file?**#### How to reproduce the bug1. Follow the steps in [`CONTRIBUTING.md`](https://github.com/apache/superset/blob/master/CONTRIBUTING.md) to set up a local dev environment (for what it is worth, my setup is a little different in that I have my plugin in a separate directory and then `npm link`ed in2. Try to import Ant Design components using    ```typescript    import { Menu, Dropdown } from 'antd';    ```### Expected resultsThe components are imported without any issues.### Actual resultsA lint warning is given: `'antd' import is restricted from being used. Please import Ant components from the index of common/components`.  The files _do_, however, appear to be imported and available.  Attempting permutations such as + ```typescript    import { Menu, Dropdown } from 'common/components';    ```+ ```typescript    import { Menu, Dropdown } from '@superset-ui/common/components';    ```+ ```typescript    import { Menu, Dropdown } from '@superset-ui/core/lib/components';    ```...all fail for various reasons.### Environment(please complete the following information):- browser type and version: **Not Applicable**- superset version: **Superset 1.4.1**- python version: **Python 3.9.10**- node.js version: **8.3.1**- any feature flags active: **none** (that I am aware of)### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.    **Not applicable**- [ ] I have reproduced the issue with at least the latest released version of superset.    **Not sure-- I find the various version tags a bit hard to parse**- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextn/aThanks!
"
19838,0,0,87,0,1,cccs-Dustin,0,"title:The Column Resize Selection Area Is Too Narrow On The Markdown Dashboard Widget . description:Within the edit mode of a dashboard, hovering over the far right edge of the Markdown widget only shows the 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墰缁犳梹鎱ㄦ繝鍕亰e闂?cursor, not the 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墰缁犳梹銇勯鍡楃ize闂?cursor. This is inconsistent with the other types of charts, as for the rest of them, the ""resize"" cursor appears when one hovers over the far right edge. The screenshot below is what you see when you try to adjust the width of a Markdown widget (you see the ""move"" cursor and not the ""resize"" cursor).![Very Small Column Resize Selection Area](https://user-images.githubusercontent.com/96579982/165142373-b9d26117-5ff7-4c17-9d82-cae5fde49536.PNG)#### How to reproduce the bug1. Go to a dashboard which contains a Markdown widget, or add a Markdown widget to a new or existing dashboard.2. Select the ""Edit dashboard"" button (pencil icon in the top right of the page).3. Try to adjust the width of the markdown widget.4. You will notice that it is not easy to get the ""resize"" cursor to appear.### Expected resultsWhen you go to adjust the width of the Markdown widget, the ""resize"" cursor should appear and thus allow you to make the widget larger or smaller.### Actual resultsWhen you try to find the area that gives you the ""resize"" cursor, it does not seem to exist, or it is so small that it takes a while to get your cursor lined up with it.#### ScreenshotsPlease see the main summary for a screenshot### Environment(please complete the following information):- browser type and version: Google Chrome (Version 100.0.4896.127)- superset version: Master- python version: Python 3.8.10- node.js version: v16.9.1- any feature flags active: N/A### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAlso, since discovering this bug, I have created a fix for it on my local fork. I will create a corresponding PR that fixes this bug (and link it to this issue).- https://github.com/apache/superset/pull/19839
"
19832,0,0,12,0,0,jefimm,0,"title:helm chart values for postgres are not used. description:The bitnami helm chart for postgres uses different values than specified in the supersethttps://github.com/bitnami/charts/blob/master/bitnami/postgresql/values.yaml#L121-L127but superset is usinghttps://github.com/apache/superset/blob/master/helm/superset/values.yaml#L387-L394
"
19799,1,0,0,0,1,JohnRson,0,"title:Apache Superset  1.5.0 login error. description:I have been using Apache Superset 1.4.2 and wanted to upgrade to 1.5.0 as it supports non-timeseries-x-axis.https://github.com/apache/superset/tree/master/RELEASING/release-notes-1-5I tried to install it from github via python on windows 10 into an unique environment:conda activate %env%call conda install gitpip install --upgrade setuptools pip  --user pythonpip install X:\python_geohash-0.8.5-cp39-cp39-win_amd64.whlpip install markupsafe==2.0.1pip install sqlalchemy-trinopip install git+https://github.com/apache/superset.git@1.5.0rc3pip show apache-supersetSET FLASK_APP=supersetsuperset db upgradeflask fab create-adminsuperset load_examplessuperset initsuperset run -p 8088 --with-threads --reload --debuggerI already installed some aditional libraries (geohash, markupsafe, sqlalchemy-trino), otherwise it wouldn't finish.So far, there is no console error but when I open http://127.0.0.1:8088/superset/welcome/ it just shows an empty white screen ![Bild1](https://user-images.githubusercontent.com/104075422/164315281-b8e1b388-ad87-4b1c-95f0-7c7caba35d47.png)Does anyone know how to fix this issue?
"
19771,0,0,57,0,0,MattMills,0,"title:Gallery in Readme 404s. description:When I click the first large image that says ""gallery"" in the readme, I get sent to a 404 link (https://superset.apache.org/gallery not found)#### How to reproduce the bug1. Open apache superset github2. Click on 'gallery'3. ...4. See error### Expected resultsI expected a gallery### Actual resultsI get a disappointing 404 error.#### ScreenshotsN/A### EnvironmentN/A### ChecklistMake sure to follow these steps before submitting your issue - thank you!N/A### Additional contextN/A
"
19746,0,0,183,0,0,EugeneTorap,0,"title:SQL Lab UI Error: Objects are not valid as a React child. description:There are such errors in browser console.> Uncaught Error: Objects are not valid as a React child (found: object with keys {data, query}). If you meant to render a collection of children, use an array instead.> The above error occurred in the <defaultRenderer> component:#### How to reproduce the bug1. Go to SQL Lab2. Click on 'RUN'3. Click on 'Query history'4. See error### Expected resultsNo error### Actual resultsThere's error#### Screenshots![image](https://user-images.githubusercontent.com/29536522/163711301-a22163fe-676b-4b1d-89a8-73effeb0a02e.png)https://user-images.githubusercontent.com/29536522/164038206-370664ac-96b6-4329-a76e-8c2fcb0e2b06.mov### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19742,1,0,0,0,0,milad000cu,0,"title:database list in the dataset creation form is empty . description:A clear and concise description of what the bug is.I installed Superset and connected the PostGres database to it, but the database list in the dataset creation form is empty and there is no databasehttps://pasteboard.co/gT0ocv1NjGDI.jpg#### How to reproduce the bug1. Go to '...'2. Click on '....'3. Scroll down to '....'4. See error### Expected resultswhat you expected to happen.### Actual resultswhat actually happens.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19738,1,28928,292,1,1,Hongbo-Miao,0,"title:[Helm] sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation ""ab_permission_view_role"" does not exist. description:#### How to reproduce the bugI am trying to deploy to Kubernetes by Helm based on https://superset.apache.org/docs/installation/running-on-kubernetesby running```shhelm repo add superset https://apache.github.io/supersethelm upgrade --install --values values.yaml superset superset/superset```The values.yaml file I am using is https://github.com/apache/superset/blob/master/helm/superset/values.yamlI didn't change any value.### Expected resultsI expect it deploy successfully.### Actual resultsI got error ```shsqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation ""ab_permission_view_role"" does not existLINE 2: FROM ab_role LEFT OUTER JOIN (ab_permission_view_role AS ab_...                                      ^[SQL: SELECT ab_role.id AS ab_role_id, ab_role.name AS ab_role_name, ab_permission_view_1.id AS ab_permission_view_1_id, ab_permission_view_1.permission_id AS ab_permission_view_1_permission_id, ab_permission_view_1.view_menu_id AS ab_permission_view_1_view_menu_id FROM ab_role LEFT OUTER JOIN (ab_permission_view_role AS ab_permission_view_role_1 JOIN ab_permission_view AS ab_permission_view_1 ON ab_permission_view_1.id = ab_permission_view_role_1.permission_view_id) ON ab_role.id = ab_permission_view_role_1.role_id](Background on this error at: http://sqlalche.me/e/13/f405)```  Full log for `superset-init-db--1-xxx` (click to expand)    ```shellRequirement already satisfied: psycopg2-binary==2.9.1 in /usr/local/lib/python3.8/site-packages (2.9.1)Requirement already satisfied: redis==3.5.3 in /usr/local/lib/python3.8/site-packages (3.5.3)WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venvWARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.Upgrading DB schema...logging was configured successfully2022-04-16 03:29:27,934:INFO:superset.utils.logging_configurator:logging was configured successfully2022-04-16 03:29:27,940:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deployments2022-04-16 03:29:27,945:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `FILTER_STATE_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentsFalling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deployments2022-04-16 03:29:27,954:WARNING:superset.utils.cache_manager:Falling back to the built-in cache, that stores data in the metadata database, for the following cache: `EXPLORE_FORM_DATA_CACHE_CONFIG`. It is recommended to use `RedisCache`, `MemcachedCache` or another dedicated caching backend for production deploymentsINFO  [alembic.runtime.migration] Context impl PostgresqlImpl.INFO  [alembic.runtime.migration] Will assume transactional DDL.INFO  [alembic.runtime.migration] Running upgrade  -> 4e6a06bad7a8, InitINFO  [alembic.runtime.migration] Running upgrade 4e6a06bad7a8 -> 5a7bad26f2a7, empty messageINFO  [alembic.runtime.migration] Running upgrade 5a7bad26f2a7 -> 1e2841a4128, empty messageINFO  [alembic.runtime.migration] Running upgrade 1e2841a4128 -> 2929af7925ed, TZ offsets in data sourcesINFO  [alembic.runtime.migration] Running upgrade 2929af7925ed -> 289ce07647b, Add encrypted password fieldINFO  [alembic.runtime.migration] Running upgrade 289ce07647b -> 1a48a5411020, adding slug to dashINFO  [alembic.runtime.migration] Running upgrade 1a48a5411020 -> 315b3f4da9b0, adding log modelINFO  [alembic.runtime.migration] Running upgrade 315b3f4da9b0 -> 55179c7f25c7, sqla_descrINFO  [alembic.runtime.migration] Running upgrade 55179c7f25c7 -> 12d55656cbca, is_featuredINFO  [alembic.runtime.migration] Running upgrade 12d55656cbca -> 2591d77e9831, user_idINFO  [alembic.runtime.migration] Running upgrade 2591d77e9831 -> 8e80a26a31db, empty messageINFO  [alembic.runtime.migration] Running upgrade 8e80a26a31db -> 7dbf98566af7, empty messageINFO  [alembic.runtime.migration] Running upgrade 7dbf98566af7 -> 43df8de3a5f4, empty messageINFO  [alembic.runtime.migration] Running upgrade 43df8de3a5f4 -> d827694c7555, css templatesINFO  [alembic.runtime.migration] Running upgrade d827694c7555 -> 430039611635, log moreINFO  [alembic.runtime.migration] Running upgrade 430039611635 -> 18e88e1cc004, making audit nullableINFO  [alembic.runtime.migration] Running upgrade 18e88e1cc004 -> 836c0bf75904, cache_timeoutsINFO  [alembic.runtime.migration] Running upgrade 18e88e1cc004 -> a2d606a761d9, adding favstar modelINFO  [alembic.runtime.migration] Running upgrade a2d606a761d9, 836c0bf75904 -> d2424a248d63, empty messageINFO  [alembic.runtime.migration] Running upgrade d2424a248d63 -> 763d4b211ec9, fixing audit fkINFO  [alembic.runtime.migration] Running upgrade d2424a248d63 -> 1d2ddd543133, log dtINFO  [alembic.runtime.migration] Running upgrade 1d2ddd543133, 763d4b211ec9 -> fee7b758c130, empty messageINFO  [alembic.runtime.migration] Running upgrade fee7b758c130 -> 867bf4f117f9, Adding extra field to Database modelINFO  [alembic.runtime.migration] Running upgrade 867bf4f117f9 -> bb51420eaf83, add schema to table modelINFO  [alembic.runtime.migration] Running upgrade bb51420eaf83 -> b4456560d4f3, change_table_unique_constraintINFO  [alembic.runtime.migration] Running upgrade b4456560d4f3 -> 4fa88fe24e94, owners_many_to_manyINFO  [alembic.runtime.migration] Running upgrade 4fa88fe24e94 -> c3a8f8611885, Materializing permissionINFO  [alembic.runtime.migration] Running upgrade c3a8f8611885 -> f0fbf6129e13, Adding verbose_name to tablecolumnINFO  [alembic.runtime.migration] Running upgrade f0fbf6129e13 -> 956a063c52b3, adjusting key lengthINFO  [alembic.runtime.migration] Running upgrade 956a063c52b3 -> 1226819ee0e3, Fix wrong constraint on table columnsINFO  [alembic.runtime.migration] Running upgrade 1226819ee0e3 -> d8bc074f7aad, Add new field 'is_restricted' to SqlMetric and DruidMetricINFO  [alembic.runtime.migration] Running upgrade d8bc074f7aad -> 27ae655e4247, Make creator ownersINFO  [alembic.runtime.migration] Running upgrade 27ae655e4247 -> 960c69cb1f5b, add dttm_format related fields in table_columnsINFO  [alembic.runtime.migration] Running upgrade 960c69cb1f5b -> f162a1dea4c4, d3format_by_metricINFO  [alembic.runtime.migration] Running upgrade f162a1dea4c4 -> ad82a75afd82, Update models to support storing the queries.INFO  [alembic.runtime.migration] Running upgrade ad82a75afd82 -> 3c3ffe173e4f, add_sql_string_to_tableINFO  [alembic.runtime.migration] Running upgrade 3c3ffe173e4f -> 41f6a59a61f2, database options for sql labINFO  [alembic.runtime.migration] Running upgrade 41f6a59a61f2 -> 4500485bde7d, allow_run_sync_asyncINFO  [alembic.runtime.migration] Running upgrade 4500485bde7d -> 65903709c321, allow_dmlINFO  [alembic.runtime.migration] Running upgrade 41f6a59a61f2 -> 33d996bcc382, update slice modelINFO  [alembic.runtime.migration] Running upgrade 33d996bcc382, 65903709c321 -> b347b202819b, empty messageINFO  [alembic.runtime.migration] Running upgrade b347b202819b -> 5e4a03ef0bf0, Add access_request table to manage requests to access datastores.INFO  [alembic.runtime.migration] Running upgrade 5e4a03ef0bf0 -> eca4694defa7, sqllab_setting_defaultsINFO  [alembic.runtime.migration] Running upgrade eca4694defa7 -> ab3d66c4246e, add_cache_timeout_to_druid_clusterINFO  [alembic.runtime.migration] Running upgrade eca4694defa7 -> 3b626e2a6783, Sync DB with the models.py.INFO  [alembic.runtime.migration] Running upgrade 3b626e2a6783, ab3d66c4246e -> ef8843b41dac, empty messageINFO  [alembic.runtime.migration] Running upgrade ef8843b41dac -> b46fa1b0b39e, Add json_metadata to the tables table.INFO  [alembic.runtime.migration] Running upgrade b46fa1b0b39e -> 7e3ddad2a00b, results_key to queryINFO  [alembic.runtime.migration] Running upgrade 7e3ddad2a00b -> ad4d656d92bc, Add avg() to default metricsINFO  [alembic.runtime.migration] Running upgrade ad4d656d92bc -> c611f2b591b8, dim_specINFO  [alembic.runtime.migration] Running upgrade c611f2b591b8 -> e46f2d27a08e, materialize permsINFO  [alembic.runtime.migration] Running upgrade e46f2d27a08e -> f1f2d4af5b90, Enable Filter SelectINFO  [alembic.runtime.migration] Running upgrade e46f2d27a08e -> 525c854f0005, log_this_plusINFO  [alembic.runtime.migration] Running upgrade 525c854f0005, f1f2d4af5b90 -> 6414e83d82b7, empty messageINFO  [alembic.runtime.migration] Running upgrade 6414e83d82b7 -> 1296d28ec131, Adds params to the datasource (druid) tableINFO  [alembic.runtime.migration] Running upgrade 1296d28ec131 -> f18570e03440, Add index on the result key to the query table.INFO  [alembic.runtime.migration] Running upgrade f18570e03440 -> bcf3126872fc, Add keyvalue tableINFO  [alembic.runtime.migration] Running upgrade f18570e03440 -> db0c65b146bd, update_slice_model_jsonINFO  [alembic.runtime.migration] Running upgrade db0c65b146bd -> a99f2f7c195a, rewriting url from shortner with new formatINFO  [alembic.runtime.migration] Running upgrade a99f2f7c195a, bcf3126872fc -> d6db5a5cdb5d, empty messageINFO  [alembic.runtime.migration] Running upgrade d6db5a5cdb5d -> b318dfe5fb6c, adding verbose_name to druid columnINFO  [alembic.runtime.migration] Running upgrade d6db5a5cdb5d -> 732f1c06bcbf, add fetch values predicateINFO  [alembic.runtime.migration] Running upgrade 732f1c06bcbf, b318dfe5fb6c -> ea033256294a, empty messageINFO  [alembic.runtime.migration] Running upgrade b318dfe5fb6c -> db527d8c4c78, Add verbose name to DruidCluster and DatabaseINFO  [alembic.runtime.migration] Running upgrade db527d8c4c78, ea033256294a -> 979c03af3341, empty messageINFO  [alembic.runtime.migration] Running upgrade 979c03af3341 -> a6c18f869a4e, query.start_running_timeINFO  [alembic.runtime.migration] Running upgrade a6c18f869a4e -> 2fcdcb35e487, saved_queriesINFO  [alembic.runtime.migration] Running upgrade 2fcdcb35e487 -> a65458420354, add_result_backend_time_loggingINFO  [alembic.runtime.migration] Running upgrade a65458420354 -> ca69c70ec99b, tracking_urlINFO  [alembic.runtime.migration] Running upgrade ca69c70ec99b -> a9c47e2c1547, add impersonate_user to dbsINFO  [alembic.runtime.migration] Running upgrade ca69c70ec99b -> ddd6ebdd853b, annotationsINFO  [alembic.runtime.migration] Running upgrade a9c47e2c1547, ddd6ebdd853b -> d39b1e37131d, empty messageINFO  [alembic.runtime.migration] Running upgrade ca69c70ec99b -> 19a814813610, Adding metric warning_textINFO  [alembic.runtime.migration] Running upgrade 19a814813610, a9c47e2c1547 -> 472d2f73dfd4, empty messageINFO  [alembic.runtime.migration] Running upgrade 472d2f73dfd4, d39b1e37131d -> f959a6652acd, empty messageINFO  [alembic.runtime.migration] Running upgrade f959a6652acd -> 4736ec66ce19, empty messageINFO  [alembic.runtime.migration] Running upgrade 4736ec66ce19 -> 67a6ac9b727b, update_spatial_paramsINFO  [alembic.runtime.migration] Running upgrade 67a6ac9b727b -> 21e88bc06c02, migrate_old_annotation_layersINFO  [alembic.runtime.migration] Running upgrade 21e88bc06c02 -> e866bd2d4976, smaller_gridINFO  [alembic.runtime.migration] Running upgrade e866bd2d4976 -> e68c4473c581, allow_multi_schema_metadata_fetchINFO  [alembic.runtime.migration] Running upgrade e68c4473c581 -> f231d82b9b26, empty messageINFO  [alembic.runtime.migration] Running upgrade f231d82b9b26 -> bf706ae5eb46, cal_heatmap_metric_to_metricsINFO  [alembic.runtime.migration] Running upgrade f231d82b9b26 -> 30bb17c0dc76, empty messageINFO  [alembic.runtime.migration] Running upgrade 30bb17c0dc76, bf706ae5eb46 -> c9495751e314, empty messageINFO  [alembic.runtime.migration] Running upgrade f231d82b9b26 -> 130915240929, is_sqllab_viewINFO  [alembic.runtime.migration] Running upgrade 130915240929, c9495751e314 -> 5ccf602336a0, empty messageINFO  [alembic.runtime.migration] Running upgrade 5ccf602336a0 -> e502db2af7be, add template_params to tablesINFO  [alembic.runtime.migration] Running upgrade e502db2af7be -> c5756bec8b47, Time grain SQLAINFO  [alembic.runtime.migration] Running upgrade c5756bec8b47 -> afb7730f6a9c, remove empty filtersINFO  [alembic.runtime.migration] Running upgrade afb7730f6a9c -> 80a67c5192fa, single pie chart metricINFO  [alembic.runtime.migration] Running upgrade 80a67c5192fa -> bddc498dd179, adhoc filtersINFO  [alembic.runtime.migration] Running upgrade bddc498dd179 -> 4451805bbaa1, remove double percentsINFO  [alembic.runtime.migration] Running upgrade bddc498dd179 -> 3dda56f1c4c6, Migrate num_period_compare and period_ratio_typeINFO  [alembic.runtime.migration] Running upgrade 3dda56f1c4c6 -> 1d9e835a84f9, empty messageINFO  [alembic.runtime.migration] Running upgrade 4451805bbaa1, 1d9e835a84f9 -> e3970889f38e, empty messageINFO  [alembic.runtime.migration] Running upgrade 4451805bbaa1, 1d9e835a84f9 -> 705732c70154, empty messageINFO  [alembic.runtime.migration] Running upgrade 4451805bbaa1, 1d9e835a84f9 -> fc480c87706c, empty messageINFO  [alembic.runtime.migration] Running upgrade fc480c87706c -> bebcf3fed1fe, Migrate dashboard position_json data from V1 to V2INFO  [alembic.runtime.migration] Running upgrade bebcf3fed1fe, 705732c70154 -> ec1f88a35cc6, empty messageINFO  [alembic.runtime.migration] Running upgrade 705732c70154, e3970889f38e -> 46ba6aaaac97, empty messageINFO  [alembic.runtime.migration] Running upgrade 46ba6aaaac97, ec1f88a35cc6 -> c18bd4186f15, empty messageINFO  [alembic.runtime.migration] Running upgrade c18bd4186f15 -> 7fcdcde0761c, Reduce position_json size by remove extra space and component id prefixINFO  [alembic.runtime.migration] Running upgrade 7fcdcde0761c -> 0c5070e96b57, add user attributes tableINFO  [alembic.runtime.migration] Running upgrade 0c5070e96b57 -> 1a1d627ebd8e, position_jsonINFO  [alembic.runtime.migration] Running upgrade 1a1d627ebd8e -> 55e910a74826, add_metadata_column_to_annotation_model.pyINFO  [alembic.runtime.migration] Running upgrade 55e910a74826 -> 4ce8df208545, empty messageINFO  [alembic.runtime.migration] Running upgrade 4ce8df208545 -> 46f444d8b9b7, remove_coordinator_from_druid_cluster_model.pyINFO  [alembic.runtime.migration] Running upgrade 46f444d8b9b7 -> a61b40f9f57f, remove allow_run_syncINFO  [alembic.runtime.migration] Running upgrade a61b40f9f57f -> 6c7537a6004a, models for email reportsINFO  [alembic.runtime.migration] Running upgrade 6c7537a6004a -> 3e1b21cd94a4, change_owner_to_m2m_relation_on_datasources.pyINFO  [alembic.runtime.migration] Running upgrade 6c7537a6004a -> cefabc8f7d38, Increase size of name column in ab_view_menuINFO  [alembic.runtime.migration] Running upgrade 55e910a74826 -> 0b1f1ab473c0, Add extra column to QueryINFO  [alembic.runtime.migration] Running upgrade 0b1f1ab473c0, cefabc8f7d38, 3e1b21cd94a4 -> de021a1ca60d, empty messageINFO  [alembic.runtime.migration] Running upgrade de021a1ca60d -> fb13d49b72f9, better_filtersINFO  [alembic.runtime.migration] Running upgrade fb13d49b72f9 -> a33a03f16c4a, Add extra column to SavedQueryINFO  [alembic.runtime.migration] Running upgrade 4451805bbaa1, 1d9e835a84f9 -> c829ff0b37d0, empty messageINFO  [alembic.runtime.migration] Running upgrade c829ff0b37d0 -> 7467e77870e4, remove_aggsINFO  [alembic.runtime.migration] Running upgrade 7467e77870e4, de021a1ca60d -> fbd55e0f83eb, empty messageINFO  [alembic.runtime.migration] Running upgrade fbd55e0f83eb, fb13d49b72f9 -> 8b70aa3d0f87, empty messageINFO  [alembic.runtime.migration] Running upgrade 8b70aa3d0f87, a33a03f16c4a -> 18dc26817ad2, empty messageINFO  [alembic.runtime.migration] Running upgrade 18dc26817ad2 -> c617da68de7d, form nullableINFO  [alembic.runtime.migration] Running upgrade c617da68de7d -> c82ee8a39623, Add implicit tagsINFO  [alembic.runtime.migration] Running upgrade 18dc26817ad2 -> e553e78e90c5, add_druid_auth_py.pyINFO  [alembic.runtime.migration] Running upgrade e553e78e90c5, c82ee8a39623 -> 45e7da7cfeba, empty messageINFO  [alembic.runtime.migration] Running upgrade 45e7da7cfeba -> 80aa3f04bc82, Add Parent ids in dashboard layout metadataINFO  [alembic.runtime.migration] Running upgrade 80aa3f04bc82 -> d94d33dbe938, form stripINFO  [alembic.runtime.migration] Running upgrade d94d33dbe938 -> 937d04c16b64, update datasourcesINFO  [alembic.runtime.migration] Running upgrade 937d04c16b64 -> 7f2635b51f5d, update base columnsINFO  [alembic.runtime.migration] Running upgrade 7f2635b51f5d -> e9df189e5c7e, update base metricsINFO  [alembic.runtime.migration] Running upgrade e9df189e5c7e -> afc69274c25a, update the sql, select_sql, and executed_sql columns in the   query table in mysql dbs to be long text columnsINFO  [alembic.runtime.migration] Running upgrade afc69274c25a -> d7c1a0d6f2da, Remove limit used from query modelINFO  [alembic.runtime.migration] Running upgrade d7c1a0d6f2da -> ab8c66efdd01, resampleINFO  [alembic.runtime.migration] Running upgrade ab8c66efdd01 -> b4a38aa87893, deprecate database expressionINFO  [alembic.runtime.migration] Running upgrade b4a38aa87893 -> d6ffdf31bdd4, Add published column to dashboardsINFO  [alembic.runtime.migration] Running upgrade d6ffdf31bdd4 -> 190188938582, Remove duplicated entries in dashboard_slices table and add unique constraintINFO  [alembic.runtime.migration] Running upgrade 190188938582 -> def97f26fdfb, Add index to tagged_objectINFO  [alembic.runtime.migration] Running upgrade def97f26fdfb -> 11c737c17cc6, deprecate_restricted_metricsINFO  [alembic.runtime.migration] Running upgrade 11c737c17cc6 -> 258b5280a45e, form strip leading and trailing whitespaceINFO  [alembic.runtime.migration] Running upgrade 258b5280a45e -> 1495eb914ad3, time rangeINFO  [alembic.runtime.migration] Running upgrade 1495eb914ad3 -> b6fa807eac07, make_names_non_nullableINFO  [alembic.runtime.migration] Running upgrade b6fa807eac07 -> cca2f5d568c8, add encrypted_extra to dbsINFO  [alembic.runtime.migration] Running upgrade cca2f5d568c8 -> c2acd2cf3df2, alter type of dbs encrypted_extraINFO  [alembic.runtime.migration] Running upgrade c2acd2cf3df2 -> 78ee127d0d1d, reconvert legacy filters into adhocINFO  [alembic.runtime.migration] Running upgrade 78ee127d0d1d -> db4b49eb0782, Add tables for SQL Lab stateINFO  [alembic.runtime.migration] Running upgrade db4b49eb0782 -> 5afa9079866a, serialize_schema_permissions.pyINFO  [alembic.runtime.migration] Running upgrade 5afa9079866a -> 89115a40e8ea, Change table schema description to long textINFO  [alembic.runtime.migration] Running upgrade 89115a40e8ea -> 817e1c9b09d0, add_not_null_to_dbs_sqlalchemy_urlINFO  [alembic.runtime.migration] Running upgrade 817e1c9b09d0 -> e96dbf2cfef0, datasource_cluster_fkINFO  [alembic.runtime.migration] Running upgrade e96dbf2cfef0 -> 3325d4caccc8, empty messageINFO  [alembic.runtime.migration] Running upgrade 3325d4caccc8 -> 0a6f12f60c73, add_role_level_securityINFO  [alembic.runtime.migration] Running upgrade 0a6f12f60c73 -> 72428d1ea401, Add tmp_schema_name to the query object.INFO  [alembic.runtime.migration] Running upgrade 72428d1ea401 -> b5998378c225, add certificate to dbsINFO  [alembic.runtime.migration] Running upgrade b5998378c225 -> f9a30386bd74, cleanup_time_grainularityINFO  [alembic.runtime.migration] Running upgrade f9a30386bd74 -> 620241d1153f, update time_grain_sqlaINFO  [alembic.runtime.migration] Running upgrade 620241d1153f -> 743a117f0d98, Add slack to the scheduleINFO  [alembic.runtime.migration] Running upgrade 743a117f0d98 -> e557699a813e, add_tables_relation_to_row_level_securityINFO  [alembic.runtime.migration] Running upgrade e557699a813e -> ea396d202291, Add ctas_method to the Query objectINFO  [alembic.runtime.migration] Running upgrade ea396d202291 -> a72cb0ebeb22, deprecate dbs.perm columnINFO  [alembic.runtime.migration] Running upgrade a72cb0ebeb22 -> 2f1d15e8a6af, add_alertsINFO  [alembic.runtime.migration] Running upgrade 2f1d15e8a6af -> f2672aa8350a, add_slack_to_alertsINFO  [alembic.runtime.migration] Running upgrade f2672aa8350a -> f120347acb39, Add extra column to tables and metricsINFO  [alembic.runtime.migration] Running upgrade f2672aa8350a -> 978245563a02, Migrate iframe in dashboard to markdown componentINFO  [alembic.runtime.migration] Running upgrade 978245563a02, f120347acb39 -> f80a3b88324b, empty messageINFO  [alembic.runtime.migration] Running upgrade f80a3b88324b -> 2e5a0ee25ed4, refractor_alertingINFO  [alembic.runtime.migration] Running upgrade f80a3b88324b -> 175ea3592453, Add cache to datasource lookup table.INFO  [alembic.runtime.migration] Running upgrade 175ea3592453, 2e5a0ee25ed4 -> ae19b4ee3692, empty messageINFO  [alembic.runtime.migration] Running upgrade ae19b4ee3692 -> e5ef6828ac4e, add rls filter type and grouping keyINFO  [alembic.runtime.migration] Running upgrade e5ef6828ac4e -> 3fbbc6e8d654, fix data access permissions for virtual datasetsINFO  [alembic.runtime.migration] Running upgrade 3fbbc6e8d654 -> 18532d70ab98, Delete table_name unique constraint in mysqlINFO  [alembic.runtime.migration] Running upgrade 18532d70ab98 -> b56500de1855, add_uuid_column_to_import_mixinINFO  [alembic.runtime.migration] Running upgrade b56500de1855 -> af30ca79208f, Collapse alerting models into a single oneINFO  [alembic.runtime.migration] Running upgrade af30ca79208f -> 585b0b1a7b18, add exec info to saved queriesINFO  [alembic.runtime.migration] Running upgrade 585b0b1a7b18 -> 96e99fb176a0, add_import_mixing_to_saved_queryINFO  [alembic.runtime.migration] Running upgrade 96e99fb176a0 -> 49b5a32daba5, add report schedulesINFO  [alembic.runtime.migration] Running upgrade 49b5a32daba5 -> a8173232b786, Add path to logsINFO  [alembic.runtime.migration] Running upgrade a8173232b786 -> e38177dbf641, security converge saved queriesLoaded your LOCAL configuration at [/app/pythonpath/superset_config.py]Cleaning up slice uuid from dashboard position json..Cleaning up slice uuid from dashboard position json.. Done.      Traceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context    self.dialect.do_execute(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 608, in do_execute    cursor.execute(statement, parameters)psycopg2.errors.UndefinedTable: relation ""ab_permission_view_role"" does not existLINE 2: FROM ab_role LEFT OUTER JOIN (ab_permission_view_role AS ab_...                                      ^The above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/usr/local/bin/superset"", line 33, in <module>    sys.exit(load_entry_point('apache-superset', 'console_scripts', 'superset')())  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1128, in __call__    return self.main(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 601, in main    return super().main(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1053, in main    rv = self.invoke(ctx)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1659, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1659, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1395, in invoke    return ctx.invoke(self.callback, **ctx.params)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 754, in invoke    return __callback(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/decorators.py"", line 26, in new_func    return f(get_current_context(), *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 445, in decorator    return __ctx.invoke(f, *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 754, in invoke    return __callback(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask_migrate/cli.py"", line 149, in upgrade    _upgrade(directory, revision, sql, tag, x_arg)  File ""/usr/local/lib/python3.8/site-packages/flask_migrate/__init__.py"", line 98, in wrapped    f(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask_migrate/__init__.py"", line 185, in upgrade    command.upgrade(config, revision, sql=sql, tag=tag)  File ""/usr/local/lib/python3.8/site-packages/alembic/command.py"", line 294, in upgrade    script.run_env()  File ""/usr/local/lib/python3.8/site-packages/alembic/script/base.py"", line 490, in run_env    util.load_python_file(self.dir, ""env.py"")  File ""/usr/local/lib/python3.8/site-packages/alembic/util/pyfiles.py"", line 97, in load_python_file    module = load_module_py(module_id, path)  File ""/usr/local/lib/python3.8/site-packages/alembic/util/compat.py"", line 184, in load_module_py    spec.loader.exec_module(module)  File ""<frozen importlib._bootstrap_external>"", line 843, in exec_module  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed  File ""/app/superset/extensions/../migrations/env.py"", line 126, in <module>    run_migrations_online()  File ""/app/superset/extensions/../migrations/env.py"", line 118, in run_migrations_online    context.run_migrations()  File ""<string>"", line 8, in run_migrations  File ""/usr/local/lib/python3.8/site-packages/alembic/runtime/environment.py"", line 813, in run_migrations    self.get_context().run_migrations(**kw)  File ""/usr/local/lib/python3.8/site-packages/alembic/runtime/migration.py"", line 561, in run_migrations    step.migration_fn(**kw)  File ""/app/superset/migrations/versions/e38177dbf641_security_converge_saved_queries.py"", line 100, in upgrade    migrate_roles(session, PVM_MAP)  File ""/app/superset/migrations/shared/security_converge.py"", line 237, in migrate_roles    roles = session.query(Role).options(Load(Role).joinedload(Role.permissions)).all()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py"", line 3373, in all    return list(self)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py"", line 3535, in __iter__    return self._execute_and_instances(context)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py"", line 3560, in _execute_and_instances    result = conn.execute(querycontext.statement, self._params)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1011, in execute    return meth(self, multiparams, params)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 298, in _execute_on_connection    return connection._execute_clauseelement(self, multiparams, params)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1124, in _execute_clauseelement    ret = self._execute_context(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1316, in _execute_context    self._handle_dbapi_exception(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1510, in _handle_dbapi_exception    util.raise_(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context    self.dialect.do_execute(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 608, in do_execute    cursor.execute(statement, parameters)sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) relation ""ab_permission_view_role"" does not existLINE 2: FROM ab_role LEFT OUTER JOIN (ab_permission_view_role AS ab_...                                      ^[SQL: SELECT ab_role.id AS ab_role_id, ab_role.name AS ab_role_name, ab_permission_view_1.id AS ab_permission_view_1_id, ab_permission_view_1.permission_id AS ab_permission_view_1_permission_id, ab_permission_view_1.view_menu_id AS ab_permission_view_1_view_menu_id FROM ab_role LEFT OUTER JOIN (ab_permission_view_role AS ab_permission_view_role_1 JOIN ab_permission_view AS ab_permission_view_1 ON ab_permission_view_1.id = ab_permission_view_role_1.permission_view_id) ON ab_role.id = ab_permission_view_role_1.role_id](Background on this error at: http://sqlalche.me/e/13/f405)  ```</details>### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextFound a related error when deploying by Helm without clear fix solution inside:- https://github.com/apache/superset/issues/15262Also, found people who are using docker-compose met similar issues:- https://github.com/apache/superset/issues/16247- https://github.com/apache/superset/issues/17822
"
19720,1,1334,0,0,1,kleijnweb,0,"title:Helm chart: somehow imagePullSecret gets a `registry-` prefix, release fails. description:Hi, I am trying to deploy the superset Helm chart with a customized image. There's no option to specify `imagePullSecrets` for the chart. Using k8s on DigitalOcean. I linked the repository, and tested it using a basic deploy, and it ""just works"". That is to say, the pods get the correct value for `imagePullSecret`, and pulling works. However, when trying to install the Helm chart, the used `imagePullSecret` mysteriously gets a `registry-` prefix (there's already a `-registry` suffix, so it becomes `registry-xxx-registry` when it should just be `xxx-registry`). The values on the default service account are correct.To illustrate, default service accounts for both namespaces:```$ kubectl get sa default -n test -o yamlapiVersion: v1imagePullSecrets:- name: xxx-registrykind: ServiceAccountmetadata:  creationTimestamp: ""2022-04-14T14:26:41Z""  name: default  namespace: test  resourceVersion: ""13125""  uid: xxx-xxxsecrets:- name: default-token-9ggrm$ kubectl get sa default -n superset -o yamlapiVersion: v1imagePullSecrets:- name: xxx-registrykind: ServiceAccountmetadata:  creationTimestamp: ""2022-04-14T14:19:47Z""  name: default  namespace: superset  resourceVersion: ""12079""  uid: xxx-xxxsecrets:- name: default-token-wkdhv```LGTM, but after trying to install the helm chart (which fails because of registry auth), I can see that the wrong secret is set on the pods:```$ kubectl get -n superset pods -o json | jq '.items[] | {name: .spec.containers[0].name, sa: .spec.serviceAccount, secret: .spec.imagePullSecrets}'{  ""name"": ""superset"",  ""sa"": ""default"",  ""secret"": [    {      ""name"": ""registry-xxx-registry""    }  ]}{  ""name"": ""xxx-superset-postgresql"",  ""sa"": ""default"",  ""secret"": [    {      ""name"": ""xxx-registry""    }  ]}{  ""name"": ""redis"",  ""sa"": ""xxx-superset-redis"",  ""secret"": null}{  ""name"": ""superset"",  ""sa"": ""default"",  ""secret"": [    {      ""name"": ""registry-xxx-registry""    }  ]}{  ""name"": ""superset-init-db"",  ""sa"": ""default"",  ""secret"": [    {      ""name"": ""registry-xxx-registry""    }  ]}```In the test namespace the secret name is just correct. Extra interesting is that postgres DOES have the correct secret name, and that uses a Helm dependency. So it seems like there's an issue in the superset Helm chart that is causing this, but there's no `imagePullSecrets` values being set anywhere in the templates. And as you can see above, they are using the default service account.I have already tried destroying and recreating the whole cluster, but the problem recurs.I have tried version 0.5.10 (latest) of the Helm chart and version 0.3.5, both result in the same issue. * https://github.com/apache/superset/tree/dafc841e223c0f01092a2e116888a3304142e1b8/helm/superset* https://github.com/apache/superset/tree/1.3/helm/superset
"
19684,1,0,0,0,0,SakshiTharkude,0,"title:Feature Request: Modify CSV export for Tables and Pivot Tables to more closely resembled rendered data in these charts. description:ChartsCreating charts selecting a particular visualization type , building queriesFor eg: It the selected visualization type is PIVOT TABLE And i want to export the pivot table chart to a CSV fileIt gets exported but not appropriateIt should to exported in the same format as for eg in the pivoted format onlyIf suppose I create a pivot table of 3 matrix the csv file should  give the same output
"
19682,1,0,43,0,0,Max-Jesch,0,"title:Blank Page + Error when trying to add chart. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. run superset locally on WSL2 using docker following: https://hub.docker.com/r/apache/superset2. connect to local MySQL instance 3. Navigate to ""Charts"" -> click ""+ CHART""### Expected resultsopening of a GUI that guides me through creating a chart### Actual resultsA blank page and two errors in the console vendors.f9c3fd7027468531bc17.entry.js:2 TypeError: Cannot convert undefined or null to object    at Function.keys (<anonymous>)    at r (3389.e322f34f3c49e199e320.entry.js:166:8112)    at R (6052.cd8224a03af27b29c66e.entry.js:669:580)    at Ko (vendors.f9c3fd7027468531bc17.entry.js:2:2260208)    at bl (vendors.f9c3fd7027468531bc17.entry.js:2:2306170)    at hu (vendors.f9c3fd7027468531bc17.entry.js:2:2298946)    at du (vendors.f9c3fd7027468531bc17.entry.js:2:2298871)    at ru (vendors.f9c3fd7027468531bc17.entry.js:2:2295901)    at Ql (vendors.f9c3fd7027468531bc17.entry.js:2:2292669)    at Vu (vendors.f9c3fd7027468531bc17.entry.js:2:2313884)vendors.f9c3fd7027468531bc17.entry.js:2 Uncaught TypeError: Cannot convert undefined or null to object    at Function.keys (<anonymous>)    at r (3389.e322f34f3c49e199e320.entry.js:166:8112)    at R (6052.cd8224a03af27b29c66e.entry.js:669:580)    at Ko (vendors.f9c3fd7027468531bc17.entry.js:2:2260208)    at bl (vendors.f9c3fd7027468531bc17.entry.js:2:2306170)    at hu (vendors.f9c3fd7027468531bc17.entry.js:2:2298946)    at du (vendors.f9c3fd7027468531bc17.entry.js:2:2298871)    at ru (vendors.f9c3fd7027468531bc17.entry.js:2:2295901)    at Ql (vendors.f9c3fd7027468531bc17.entry.js:2:2292669)    at Vu (vendors.f9c3fd7027468531bc17.entry.js:2:2313884)#### Screenshots![image](https://user-images.githubusercontent.com/23448917/163105952-5ea4063f-6bad-4a44-aecf-7902c6ebbf35.png)### Environment- browser type and version: latest Chrome- superset version: `superset version` latest- python version: `python --version` doesnt matter, runs in docker container- node.js version: `node -v` doesnt matter, runs in docker container- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19669,0,0,19,0,0,paulinjo,0,"title:Helm chart not adding service account name to celery beat pods. description:The `serviceAccountName` cannot be applied to the celery beat pods when deploying using the Helm chart.#### How to reproduce the bug1. Set the `serviceAccountName` and `supersetCeleryBeat.enabled:true` in the `values.yml` file for helm deployment2. Deploy using helm### Expected results`serviceAccountName` spec is applied to the `celerybeat` pod.### Actual results`serviceAccountName` spec applied to all pods except for `celerybeat`.### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19658,0,0,2,0,0,sujiplr,0,"title:DB Engine error 1.5.0rc2 . description:Getting DB Engine error on the while running the SQL.2022-04-12 11:54:44,750:DEBUG:superset.stats_logger:[stats_logger] (incr) DatabaseRestApi.function_names.success2022-04-12 11:54:44,750:DEBUG:superset.stats_logger:[stats_logger] (timing) DatabaseRestApi.function_names.time | 17.298333999860915 2022-04-12 11:54:44,751:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:54:44] ""GET /api/v1/database/2/function_names/ HTTP/1.1"" 200 -2022-04-12 11:54:44,752:DEBUG:superset.models.core:Database.get_sqla_engine(). Masked URL: mssql+pymssql://Zebpay_developer:XXXXXXXXXX@z8tbkx0ebz.database.windows.net:1433/zebpayTestnet-db2022-04-12 11:54:44,762:DEBUG:superset.stats_logger:[stats_logger] (incr) DatabaseRestApi.get_list.success2022-04-12 11:54:44,762:DEBUG:superset.stats_logger:[stats_logger] (timing) DatabaseRestApi.get_list.time | 22.575500001039472 2022-04-12 11:54:44,764:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:54:44] ""GET /api/v1/database/?q=(filters:!((col:database_name,opr:ct,value:%27%27),(col:expose_in_sqllab,opr:eq,value:!t)),order_columns:database_name,order_direction:asc,page:0,page_size:100) HTTP/1.1"" 200 -2022-04-12 11:54:48,600:DEBUG:superset.stats_logger:[stats_logger] (incr) DatabaseRestApi.schemas.success2022-04-12 11:54:48,600:DEBUG:superset.stats_logger:[stats_logger] (timing) DatabaseRestApi.schemas.time | 3859.7955830009596 2022-04-12 11:54:48,601:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:54:48] ""GET /api/v1/database/2/schemas/?q=(force:!f) HTTP/1.1"" 200 -2022-04-12 11:55:19,563:ERROR:superset.views.core:Failed to execute query 'with currency AS (select 'INR' as curUNION select 'USD' as cur)select * from currency': The query record was not created as expected  Please contact an administrator for further assistance or try again.2022-04-12 11:55:19,566:DEBUG:superset.stats_logger:[stats_logger] (incr) sql_json2022-04-12 11:55:19,569:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:19] ""POST /superset/sql_json/ HTTP/1.1"" 500 -2022-04-12 11:55:31,312:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:31] ""GET /api/v1/me/ HTTP/1.1"" 200 -2022-04-12 11:55:31,321:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:31] ""GET /api/v1/me/ HTTP/1.1"" 200 -2022-04-12 11:55:35,548:DEBUG:superset.models.core:Database.get_sqla_engine(). Masked URL: postgresql+psycopg2://xxxxxxxx2022-04-12 11:55:35,571:DEBUG:superset.stats_logger:[stats_logger] (incr) DatabaseRestApi.function_names.success2022-04-12 11:55:35,571:DEBUG:superset.stats_logger:[stats_logger] (timing) DatabaseRestApi.function_names.time | 33.699666000757134 2022-04-12 11:55:35,571:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:35] ""GET /api/v1/database/3/function_names/ HTTP/1.1"" 200 -2022-04-12 11:55:35,574:DEBUG:superset.stats_logger:[stats_logger] (incr) DatabaseRestApi.get_list.success2022-04-12 11:55:35,574:DEBUG:superset.stats_logger:[stats_logger] (timing) DatabaseRestApi.get_list.time | 33.9531249992433 2022-04-12 11:55:35,576:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:35] ""GET /api/v1/database/?q=(filters:!((col:database_name,opr:ct,value:%27%27),(col:expose_in_sqllab,opr:eq,value:!t)),order_columns:database_name,order_direction:asc,page:0,page_size:100) HTTP/1.1"" 200 -2022-04-12 11:55:36,821:DEBUG:superset.stats_logger:[stats_logger] (incr) DatabaseRestApi.schemas.success2022-04-12 11:55:36,821:DEBUG:superset.stats_logger:[stats_logger] (timing) DatabaseRestApi.schemas.time | 1286.3558750013908 2022-04-12 11:55:36,822:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:36] ""GET /api/v1/database/3/schemas/?q=(force:!f) HTTP/1.1"" 200 -2022-04-12 11:55:41,656:DEBUG:superset.stats_logger:[stats_logger] (incr) validate_sql_json2022-04-12 11:55:41,663:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:41] ""POST /superset/validate_sql_json/ HTTP/1.1"" 200 -2022-04-12 11:55:43,148:DEBUG:superset.stats_logger:[stats_logger] (incr) validate_sql_json2022-04-12 11:55:43,152:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:43] ""POST /superset/validate_sql_json/ HTTP/1.1"" 200 -2022-04-12 11:55:43,503:DEBUG:superset.stats_logger:[stats_logger] (incr) extra_table_metadata2022-04-12 11:55:43,503:DEBUG:superset.stats_logger:[stats_logger] (incr) DatabaseRestApi.table_metadata.init2022-04-12 11:55:43,504:DEBUG:superset.models.core:Database.get_sqla_engine(). Masked URL: postgresql+psycopg2://xxxxx2022-04-12 11:55:43,506:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:43] ""GET /superset/extra_table_metadata/3/ab_role/%255Bobject%2520Object%255D/ HTTP/1.1"" 200 -2022-04-12 11:55:44,117:DEBUG:superset.stats_logger:[stats_logger] (incr) validate_sql_json2022-04-12 11:55:44,121:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:44] ""POST /superset/validate_sql_json/ HTTP/1.1"" 200 -2022-04-12 11:55:44,644:DEBUG:superset.stats_logger:[stats_logger] (incr) DatabaseRestApi.table_metadata.error2022-04-12 11:55:44,650:DEBUG:superset.stats_logger:[stats_logger] (incr) DatabaseRestApi.table_metadata.error2022-04-12 11:55:44,650:DEBUG:superset.stats_logger:[stats_logger] (timing) DatabaseRestApi.table_metadata.time | 1146.9648750007764 2022-04-12 11:55:44,651:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:44] ""GET /api/v1/database/3/table/ab_role/%255Bobject%2520Object%255D/ HTTP/1.1"" 422 -2022-04-12 11:55:44,774:INFO:superset.sqllab.command:Triggering query_id: 72022-04-12 11:55:44,777:DEBUG:superset.sql_parse:Parsing with sqlparse statement: None2022-04-12 11:55:44,786:ERROR:superset.views.core:Failed to execute query '7' - 'None': 'NoneType' object has no attribute 'strip'2022-04-12 11:55:44,787:DEBUG:superset.stats_logger:[stats_logger] (incr) sql_json2022-04-12 11:55:44,789:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:44] ""POST /superset/sql_json/ HTTP/1.1"" 500 -2022-04-12 11:55:45,631:ERROR:superset.views.core:Failed to execute query 'select * from ab_role ': The query record was not created as expected  Please contact an administrator for further assistance or try again.2022-04-12 11:55:45,633:DEBUG:superset.stats_logger:[stats_logger] (incr) sql_json2022-04-12 11:55:45,635:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:45] ""POST /superset/sql_json/ HTTP/1.1"" 500 -2022-04-12 11:55:49,167:ERROR:superset.views.core:Failed to execute query 'select * from ab_role ': The query record was not created as expected  Please contact an administrator for further assistance or try again.2022-04-12 11:55:49,169:DEBUG:superset.stats_logger:[stats_logger] (incr) sql_json2022-04-12 11:55:49,171:INFO:werkzeug:127.0.0.1 - - [12/Apr/2022 11:55:49] ""POST /superset/sql_json/ HTTP/1.1"" 500 -#### Screenshots<img width=""1439"" alt=""image"" src=""https://user-images.githubusercontent.com/31705464/162895010-d0d10310-e8c0-44c7-a987-6b55cb4b9d47.png"">### Environment- superset version: `1.5.0rc2`### How to reproduce this error- Create new database connection- Query any table/view from the database by only selecting the database from the SQLLab- Don't select schema and see table schema. - In the above situation you will get the DB Engine error mentioned in the screenshot.
"
19655,0,0,11,0,0,lxf-lxf,0,"title:Filter column: database_name not allowed to filter. description:<img width=""770"" alt=""image"" src=""https://user-images.githubusercontent.com/61101384/162849762-d0e5ba07-74b3-43d0-8574-96a17f32e1bf.png""><img width=""553"" alt=""image"" src=""https://user-images.githubusercontent.com/61101384/162849798-86d04125-72be-4bc5-a20d-07d7215a3bb9.png""><img width=""1936"" alt=""image"" src=""https://user-images.githubusercontent.com/61101384/162850874-380faa92-816f-46dc-b632-6388d7fc2269.png"">
"
19654,0,0,222,0,0,cwegener,0,"title:Regression - Echarts Bar and Line chart label values changed unexpectectly when using Group By. description:After #19116, the label values for Echarts Bar and Line chart (possibly more, but those are the only ones I noticed) have changed on charts that use a Group By field.#### How to reproduce the bug1. Install Superset from commit 375c03e082. Load example dataset3. Create a new Echarts bar chart (i.e. Time-Series Bar Chart v2) using any example dataset (e.g. `cleaned_sales_data`)4. Pick a metric for the new chart (e.g. `SUM(sales)`)5. Pick a ""Group By"" field for the new chart (e.g. `status`)6. Observe the chart labels. This is the easiest when showing the Legend.### Expected resultsThe chart label values will be the values from the ""Group By"" field### Actual resultsThe chart label values are a concatenation (""flattened"") the metric key (i.e. `SUM(sales)` in my example) + "", "" + the value from the ""Group By"" field#### ScreenshotsBehaviour at `git checkout 375c03e08`:![image](https://user-images.githubusercontent.com/2950544/162840466-984c4e16-a85a-44b0-9173-c1297f5653a7.png)Behaviour at `git checkout 375c03e08~`:![image](https://user-images.githubusercontent.com/2950544/162840549-81b7da3c-8f0c-43e9-ae25-da41ffd230d8.png)### Environment(please complete the following information):- browser type and version: Firefox 99- superset version: `git checkout 375c03e08`- python version: Python 3.10.4- node.js version: Node v16.9.1- any feature flags active: Default### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextNVD3 charts do not appear to exhibit this regression.
"
19640,1,0,0,0,0,AswarS,0,"title:how to use the api? Could someone help me plz!. description:i want to use the api to get and create a database, dataset and chart, but i don't understand the parameter provided by the offical document.((http://127.0.0.1:5000/swagger/v1))for example, i want to get the charts information, but what does the columns means and what value should it take?The following are the parameters required by the api {  ""columns"": [    ""string""  ],  ""filters"": [    {      ""col"": ""string"",      ""opr"": ""string"",      ""value"": 0    }  ],  ""keys"": [    ""list_columns""  ],  ""order_column"": ""string"",  ""order_direction"": ""asc"",  ""page"": 0,  ""page_size"": 0}
"
19609,0,0,0,0,0,xiamicpp,0,"title:got an error when save query as a virtual dataset. description:A clear and concise description of what the bug is.`2022-04-08 08:00:45,691:ERROR:superset.views.base:Can't generate DDL for NullType(); did you forget to specify a type on this Column?Traceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1516, in full_dispatch_request    rv = self.dispatch_request()  File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1502, in dispatch_request    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)  File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/decorators.py"", line 133, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/utils/log.py"", line 245, in wrapper    value = f(*args, **kwargs)  File ""/app/superset/views/core.py"", line 2121, in sqllab_viz    db.session.commit()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/scoping.py"", line 163, in do    return getattr(self.registry(), name)(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 1046, in commit    self.transaction.commit()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 504, in commit    self._prepare_impl()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 483, in _prepare_impl    self.session.flush()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 2540, in flush    self._flush(objects)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 2682, in _flush    transaction.rollback(_capture_exception=True)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py"", line 68, in __exit__    compat.raise_(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py"", line 2642, in _flush    flush_context.execute()  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py"", line 422, in execute    rec.execute(self)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py"", line 586, in execute    persistence.save_obj(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py"", line 248, in save_obj    _finalize_insert_update_commands(  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py"", line 1432, in _finalize_insert_update_commands    mapper.dispatch.after_insert(mapper, connection, state)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/event/attr.py"", line 322, in __call__    fn(*args, **kw)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/events.py"", line 731, in wrap    fn(*arg, **kw)  File ""/app/superset/connectors/sqla/models.py"", line 2021, in after_insert    SqlaTable.write_shadow_dataset(target, database, session)  File ""/app/superset/connectors/sqla/models.py"", line 2375, in write_shadow_dataset    tables = load_or_create_tables(  File ""/app/superset/connectors/sqla/utils.py"", line 229, in load_or_create_tables    columns = [  File ""/app/superset/connectors/sqla/utils.py"", line 232, in <listcomp>    type=str(column[""type""]),  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/type_api.py"", line 623, in __str__    return str(self.compile())  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/type_api.py"", line 606, in compile    return dialect.type_compiler.process(self)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 402, in process    return type_._compiler_dispatch(self, **kw)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/visitors.py"", line 96, in _compiler_dispatch    return meth(self, **kw)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 3478, in visit_null    raise exc.CompileError(sqlalchemy.exc.CompileError: Can't generate DDL for NullType(); did you forget to specify a type on this Column?`
"
19604,1,0,0,0,0,kevinwen2k,0,"title:Filter space is cut off if user is not an admin or the owner of the dashboard when no filter is specified. description:We programed to collapse the filter by default so that user will have more space to view those graphs. We're using Superset 1.3.2.Steps to reproduce:1. Dashboard creator:2. Create a dashboard without filterResults:1. The filter space on the left side shows up on behalf of the owner or admin user2. The filter space on the left side is missing on behalf of a user just viewerExpected: The filter space should remain for all of users![non_admin_user_viewing_dashboard_without_filter](https://user-images.githubusercontent.com/4207782/162322390-d3b9df51-67ef-4b8d-acda-809ac2f0![owner_and_admin_user_viewing_dashboard_without_filter](https://user-images.githubusercontent.com/4207782/162322451-010d0afa-8a81-4ecb-8adb-441cd52fa0a7.png)1f69.png)
"
19592,0,0,39,0,1,cccs-RyanS,0,"title:Adhoc filter popover simple tab on explore view does not render subject multi select if no suggestions are present. description:In the explore view for a dataset there are a set of conditions which causes the the subject select to not render in the adhoc filter pop over control (AdhocFilterEditPopoverSimpleTabContent) . These condition are met when a column is selected and an operator belonging to the MULTI_OPERATORS list has also been selected and no suggestions have been populated. I believe this to be caused by this line [here](https://github.com/apache/superset/blob/6d5771af346e1ae821b1ac0598751508265481a6/superset-frontend/src/explore/components/controls/FilterControl/AdhocFilterEditPopoverSimpleTabContent/index.tsx#L411) this seems to cause the behaviour that if you have a MULTI_OPERATOR and no suggestions the select will not render. The intention seems to be to delay rendering until suggestions are loaded, however there are cases where the suggestions will never load in some of our datasets. If this is not intended behaviour I would also be more than happy to take a look and attempt a fix.  #### How to reproduce the bugThe bug is data source dependent but here are some steps to create a simple fake dataset that this bug will appear in 1. SQL Lab and input a query such as `select 1 as col1, 2 as col2, 3 as col3`2. Save this query as a virtual dataset by clicking the explore button3. Open the dataset in the explore view 4. click on filters to open the popover5. select any col (col1, col2, col3) and select the IN operator6. The multislect for the subject will not renderOR 1. Disable suggestions on a dataset 2. repeat steps 3-6### Expected resultsThe multi select would render even if there are no suggestions loaded. ### Actual resultsThe subject multi select does not render.#### Screenshots![Capture2](https://user-images.githubusercontent.com/71385290/162224640-d50ae2a3-1e8f-414e-878e-714adf5c8412.PNG)### Environment- browser: Firefox- superset version: superset master branch and 1.5.0rc1- python version: python 3.8.10- node.js version: v16.13.0### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have not reproduced the issue with at least the latest released version of superset.  however I have reproduced it for 1.5.0rc1- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19588,1,798,104,0,0,riazarbi,0,"title:Helm upgrade from 0.5.8 to 0.5.9 fails. description:When upgrading my helm release fro v 0.5.8 to 0.5.9 I get the following error - ```Error: UPGRADE FAILED: cannot patch ""superset-redis-master"" with kind StatefulSet: StatefulSet.apps ""superset-redis-master"" is invalid: spec: Forbidden: updates to statefulset spec for fields other than 'replicas', 'template', and 'updateStrategy' are forbidden```#### How to reproduce the bug1. Deploy a helm chart with a v 0.5.8 release2. Upgrade the release to v 0.5.9### Expected resultsThe upgrade to complete successfully.### Actual resultsI get the above error### Environment- browser type and version: Not relevant- superset version: `1.4.0`- python version: Not relevant- node.js version: Not relevant- any feature flags active: Not relevant### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset. **Not possible**- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextI've tried to add `--reuse-values` to the helm upgrade command, and I get a different error```ubuntu-admin@k3s-server-32:~/deployments$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml helm upgrade --install superset superset/superset --values superset2-values.yaml --version=0.5.9 --namespace=superset2 --create-namespace --reuse-valuescoalesce.go:163: warning: skipped value for extraEnv: Not a table.Error: UPGRADE FAILED: error validating """": error validating data: ValidationError(StatefulSet.spec.template.spec.containers[0].command): invalid type for io.k8s.api.core.v1.Container.command: got ""string"", expected ""array""```
"
19580,0,0,1,0,1,zeesumwang,0,"title:text cursor algin did not fix the text in sqlLab.. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to 'sqlLab'2. typing some sql3. See errorhttps://user-images.githubusercontent.com/38022455/162117952-af433203-915b-43ae-bdc5-fd621756347e.mp4### Expected resultscursor algin fix right### Actual resultswhat actually happens.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environmentwindow10(please complete the following information):- browser type and version: chorme 99.0.4844.84- superset version: `superset version` 1.5.0rc1### this related PR fixed this bug, but the same bug come up now..https://github.com/apache/superset/pull/15820
"
19568,0,0,5,0,0,shalnice,0,"title:Could not save sync column from source - Error OLD_API_CHECK_DATASET_OWNERSHIP. description:Hello, I tried to add new column to my dataset in superset (launch with docker-compose) using sync column from data source (postgresql). but when I click ""Sync colum from source"" the new column appears on the list, but when I clicked save, an error message appear :  Error **OLD_API_CHECK_DATASET_OWNERSHIP**I tried the following things in the config.py file  and relaunch superset : -  changing OLD_API_CHECK_DATASET_OWNERSHIP = True to False- remove the entire line OLD_API_CHECK_DATASET_OWNERSHIPBut I still get the same error message. Do you have any idea how to debug this ?![image](https://user-images.githubusercontent.com/98736099/162003717-711bfa8d-c6dc-4316-b1b5-a338466b03fb.png)- browser type and version: Chrome Version 100.0.4896.75 (Build officiel) (64 bits)- superset version: 1.4.2- python version: 3.9.12- node.js version:  do not know where to check 
"
19564,0,578,29,0,0,EBoisseauSierra,0,"title:`{{ from_dttm }}` and `{{ to_dttm }}` Jinja special variables are not rendered in Custom SQL metrics. description:When using [Jinja special variables](https://superset.apache.org/docs/installation/sql-templating/) in Custom SQL metrics (Explore Panel), `{{ from_dttm }}` and `{{ to_dttm }}` are not rendered 闂?unlike, say, `{{ current_user_id() }}`.#### How to reproduce the bugTurn Jinja templating feature flag on:```pythonFEATURE_FLAGS ={    ""ENABLE_TEMPLATE_PROCESSING"": True,}```1. Go to your_dataset/BigNumber/Explore Panel2. Click on Metric/Custom SQL3. Use following definition:  a. `MIN({{ current_user_id() }})`  b. `MIN('{{ from_dttm }}')`### Expected resultsBoth definitions to return a number.### Actual results* `MIN({{ current_user_id() }})` returns a result:![Screenshot from 2022-04-06 14-31-25_shadow](https://user-images.githubusercontent.com/37387755/161986495-c5ad557d-7e69-4da6-8f8c-b720f821c10d.png)by executing the following query```sqlSELECT MIN(3) AS ""MIN({{ current_user_id() }})""FROM my.dbWHERE timestamp >= TO_TIMESTAMP('2022-03-01 00:00:00.000000', 'YYYY-MM-DD HH24:MI:SS.US')  AND timestamp < TO_TIMESTAMP('2022-04-01 00:00:00.000000', 'YYYY-MM-DD HH24:MI:SS.US');  ```* But `MIN('{{ from_dttm }}')` returns 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墰绾剧偓鎱?Data闂?(even with a Time Range filter set).![Screenshot from 2022-04-06 14-31-04_shadow](https://user-images.githubusercontent.com/37387755/161986525-9cdac00c-08c1-4983-833e-59cd3b28a675.png)executing this query:```sqlSELECT MIN('{{ from_dttm }}') AS ""MIN('{{ from_dttm }}')""FROM my.dbWHERE timestamp >= TO_TIMESTAMP('2022-03-01 00:00:00.000000', 'YYYY-MM-DD HH24:MI:SS.US')  AND timestamp < TO_TIMESTAMP('2022-04-01 00:00:00.000000', 'YYYY-MM-DD HH24:MI:SS.US');```### Environment(please complete the following information):- superset version: `1.4.1` (and also on https://c96e35bc.us2a.app.preset.io/ on 2022-04-06)- python version: `3.7.3`- any feature flags active:  - ENABLE_TEMPLATE_PROCESSING### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context* Database engine: PostgreSQL* The only valid syntax for `{{ from_dttm }}` is using single quotes (i.e. `sum('{{ from_dttm }}')`). Indeed, both `{{ from_dttm }}` (no quotes) or `""{{ from_dttm }}""` (double quotes) yield an error.
"
19547,1,0,2,0,0,sujiplr,0,"title:Error while accessing SQL Editor - 1.5.0rc1. description:SQL Editor is not loading and showing only a blank screen. Below goes the stack trace. #### How to reproduce the bugClick on the SQL Editor and check. This is not coming always. #### Screenshots<img width=""1325"" alt=""image"" src=""https://user-images.githubusercontent.com/31705464/161924010-5a7cd247-fcb0-4cfa-bd77-ff9abe4e2cb3.png"">If applicable, add screenshots to help explain your problem.Unable to load dialect <class 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤鐓庡娴滅磦lalchemy.dialects.mssql.adodbapi.MSDialect_adodbapi闂?: type object 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劚鍥撮梺娲诲枛濠€鎶渁lect_adodbapi闂?has no attribute 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劘閳ь剙鎳愮槐鐐靛緤濮掞箠闂?022-04-06 07:43:36,481:warning:superset.db_engine_specs:Unable to load dialect <class 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤鐓庡娴滅磦lalchemy.dialects.mssql.adodbapi.MSDialect_adodbapi闂?: type object 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劚鍥撮梺娲诲枛濠€鎶渁lect_adodbapi闂?has no attribute 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劘閳ь剙鎳愮槐鐐靛緤濮掞箠闂?0.0.2.215 - - [06/Apr/2022:07:43:36 +0000] 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墰閻滃鎮楀☉妯妓?/superset/sqllab/ HTTP/1.1闂?200 27957 ### EnvironmentK8 deployment. - superset version: 1.5.0rc1`
"
19546,0,0,2,0,0,sujiplr,0,"title:Error while saving Virtual data set using explore 1.5.0rc1. description:A clear and concise description of what the bug is.#### How to reproduce the bugRun query in SQLEditor and after getting the result try explore and save the data set then it will throw error.### stack trace Traceback (most recent call last):File 闂?usr/local/lib/python3.8/site-packages/flask/app.py闂? line 1950, in full_dispatch_requestrv = self.dispatch_request()File 闂?usr/local/lib/python3.8/site-packages/flask/app.py闂? line 1936, in dispatch_requestreturn self.view_functions[rule.endpoint](**req.view_args)File 闂?usr/local/lib/python3.8/site-packages/flask_appbuilder/security/decorators.py闂? line 148, in wrapsreturn f(self, *args, **kwargs)File 闂?app/superset/utils/log.py闂? line 245, in wrappervalue = f(*args, **kwargs)File 闂?app/superset/views/core.py闂? line 2227, in sqllab_vizdb.session.commit()File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/scoping.py闂? line 163, in doreturn getattr(self.registry(), name)(*args, **kwargs)File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py闂? line 1046, in commitself.transaction.commit()File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py闂? line 504, in commitself._prepare_impl()File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py闂? line 483, in _prepare_implself.session.flush()File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py闂? line 2540, in flushself._flush(objects)File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py闂? line 2682, in _flushtransaction.rollback(_capture_exception=True)File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py闂? line 68, in __exit__compat.raise_(File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py闂? line 182, in raise_raise exceptionFile 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py闂? line 2642, in _flushflush_context.execute()File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py闂? line 422, in executerec.execute(self)File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py闂? line 586, in executepersistence.save_obj(File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py闂? line 248, in save_obj_finalize_insert_update_commands(File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py闂? line 1432, in _finalize_insert_update_commandsmapper.dispatch.after_insert(mapper, connection, state)File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/event/attr.py闂? line 322, in __call__fn(*args, **kw)File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/events.py闂? line 731, in wrapfn(*arg, **kw)File 闂?app/superset/connectors/sqla/models.py闂? line 2031, in after_insertSqlaTable.write_shadow_dataset(target, database, session)File 闂?app/superset/connectors/sqla/models.py闂? line 2385, in write_shadow_datasettables = load_or_create_tables(File 闂?app/superset/connectors/sqla/utils.py闂? line 221, in load_or_create_tablescolumns = [File 闂?app/superset/connectors/sqla/utils.py闂? line 226, in <listcomp>is_temporal=column[闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柟缁樺坊濡插牓鏌ｅ☉妯哄帶e闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墯椤?python_type.__name__.upper()File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/sql/type_api.py闂? line 410, in python_typeraise NotImplementedError()NotImplementedError2022-04-05 13:00:26,310:ERROR:superset.views.base:Traceback (most recent call last):File 闂?usr/local/lib/python3.8/site-packages/flask/app.py闂? line 1950, in full_dispatch_requestrv = self.dispatch_request()File 闂?usr/local/lib/python3.8/site-packages/flask/app.py闂? line 1936, in dispatch_requestreturn self.view_functions[rule.endpoint](**req.view_args)File 闂?usr/local/lib/python3.8/site-packages/flask_appbuilder/security/decorators.py闂? line 148, in wrapsreturn f(self, *args, **kwargs)File 闂?app/superset/utils/log.py闂? line 245, in wrappervalue = f(*args, **kwargs)File 闂?app/superset/views/core.py闂? line 2227, in sqllab_vizdb.session.commit()File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/scoping.py闂? line 163, in doreturn getattr(self.registry(), name)(*args, **kwargs)File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py闂? line 1046, in commitself.transaction.commit()File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py闂? line 504, in commitself._prepare_impl()File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py闂? line 483, in _prepare_implself.session.flush()File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py闂? line 2540, in flushself._flush(objects)File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py闂? line 2682, in _flushtransaction.rollback(_capture_exception=True)File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py闂? line 68, in __exit__compat.raise_(File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py闂? line 182, in raise_raise exceptionFile 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py闂? line 2642, in _flushflush_context.execute()File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py闂? line 422, in executerec.execute(self)File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/unitofwork.py闂? line 586, in executepersistence.save_obj(File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py闂? line 248, in save_obj_finalize_insert_update_commands(File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/persistence.py闂? line 1432, in _finalize_insert_update_commandsmapper.dispatch.after_insert(mapper, connection, state)File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/event/attr.py闂? line 322, in __call__fn(*args, **kw)File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/orm/events.py闂? line 731, in wrapfn(*arg, **kw)File 闂?app/superset/connectors/sqla/models.py闂? line 2031, in after_insertSqlaTable.write_shadow_dataset(target, database, session)File 闂?app/superset/connectors/sqla/models.py闂? line 2385, in write_shadow_datasettables = load_or_create_tables(File 闂?app/superset/connectors/sqla/utils.py闂? line 221, in load_or_create_tablescolumns = [File 闂?app/superset/connectors/sqla/utils.py闂? line 226, in <listcomp>is_temporal=column[闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柟缁樺坊濡插牓鏌ｅ☉妯哄帶e闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墯椤?python_type.__name__.upper()File 闂?usr/local/lib/python3.8/site-packages/sqlalchemy/sql/type_api.py闂? line 410, in python_typeraise NotImplementedError()NotImplementedError
"
19531,1,0,0,1,0,Artem-fb,0,"title:Export Dashboard button cannot be hidden. description:As The problem still exists(v1.4.1) and I can't reopen my previous tikket (https://github.com/apache/superset/issues/15855), I create this oneThere is no permission in roles which can hide button ""EXPORT"" DashboardExpected resultsshould be permission for ""export"" dashboard buttonActual resultsthere is no permission for ""export"" dashboard buttonnow permission ""can read on dashboard"" makes it possible to export Dashboard to jsonScreenshotshttp://prntscr.com/1en2xm0http://prntscr.com/1en4qbxHow to reproduce the bugGo to list roles create new role, add to this role only two permissions: ""menu access on Dasboard""and ""can read on Dashboard""Create new user which has only this roleCreate some Dashboard and give access for this userLogout and Login as this new userYou can export dashboard to json and see sql queries for this dashboardinstall 0.37.1 version, no export button will exist in dashboard menuinstall 1.4.1 version this button will appear in dashboard menuEnvironmentsuperset version: 1.4.1python version: 3.8
"
19525,0,0,0,0,0,pedrohdemedeiros,0,"title:Cannot autheticate on API. Get the tokens (JWT and csrf) but all responses are ""401"". description:I cannot use the API succefully for any request (except to get the secutiry tokens), always getting "" Response 401"" for any request. #### How to reproduce the bugOn the docker container where the superset is running:```>>>import requestssession = requests.session()jwt_token = session.post(    url='http://localhost:8088/api/v1/security/login',    json={    ""username"": ""admin"",    ""password"": ""admin"",    ""refresh"": False,    ""provider"": ""db""    }).json()[""access_token""]csrf_token = session.get(    url='http://localhost:8088/api/v1/security/csrf_token/',    headers={        'Authorization': f'Bearer {jwt_token}',    }).json()[""result""]headers = {    'accept': 'application/json',    'Authorization': f'Bearer {jwt_token}',    'X-CSRFToken': csrf_token,}#trying to use the ""current user"" request as a testresponse = requests.get('http://localhost:8088/api/v1/me', headers=headers)session.close()````> >>response### Expected results{  ""result"": {    ""email"": ""admin@superset.com"",    ""first_name"": ""Superset"",    ""id"": 1,    ""is_active"": true,    ""is_anonymous"": false,    ""last_name"": ""Admin"",    ""username"": ""admin""  }}### Actual results```>>> response<Response [401]>```#### Screenshots### Environment(please complete the following information):- superset version: v1.0.0- python version: Python 3.8.12### Checklist- [ x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x ] I have reproduced the issue with at least the latest released version of superset.- [ x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19510,1,3661,12,0,1,nigzak,0,"title:OAuth Login: user details are not synchronized, only the entitlements are synced on login. description:I have enabled the OIDC loginI have enabled the userinfo endpointI have activated the synchronized for the entitlements (AUTH_ROLES_SYNC_AT_LOGIN = True)#### How to reproduce the bug1. Login as Admin2. Navigate to some user and overwrite full name or email and SAVE3. let the user login with his account via OIDC4. the overwritten details are still persist and not updated### Expected resultsSimilar to the entitlements the user details should be updated from OIDC (if available)HINT: could be an expected result - but in this case probably an additional feature flag could be added? (like AUTH_USER_SYNC_AT_LOGIN) ### Actual resultsUser details (except entitlements) are not udpated### Environment- browser type: CHROME- superset version: 1.4.1 Docker Image with AuthLib 0.x### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset. => with 1.4.1 (latest stable)- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### superset_config.py```from flask_appbuilder.security.manager import AUTH_OID,AUTH_REMOTE_USER,AUTH_DB, AUTH_LDAP, AUTH_OAUTHimport osfrom custom_sso_security_manager import CustomSsoSecurityManagerCUSTOM_SECURITY_MANAGER = CustomSsoSecurityManagerbasedir = os.path.abspath(os.path.dirname(__file__))SUPERSET_WORKERS = 4# CRYPTION STUFF -----------------------------------------------------------------------------------SECRET_KEY = os.getenv('SUPERSET_SECRET_KEY')# DATABASE STUFF -----------------------------------------------------------------------------------PSQLHOST=os.getenv('PSQL_HOST')PSQLPORT=os.getenv('PSQL_PORT')PSQLUSER=os.getenv('PSQL_USER')PSQLPASS=os.getenv('PSQL_PASS')PSQLDB=os.getenv('PSQL_DB')PSQLSSLMODE = os.getenv('PSQL_SSL_MODE')PSQLSSLROOTCA = os.getenv('PSQL_SSL_ROOTCA')print (' USING DB FOR SQLALCHEMY ')print ('HOST: ' + str(PSQLHOST))print ('PORT: ' + str(PSQLPORT))print ('SSL_MODE: ' + PSQLSSLMODE)print ('SSL_CA: ' + PSQLSSLROOTCA)if PSQLSSLMODE != None and PSQLSSLMODE != """" and PSQLSSLROOTCA != None and PSQLSSLROOTCA != """":	print('PSQL: SSL MODE USED MODE=' + PSQLSSLMODE + ' CA=' + PSQLSSLROOTCA)	SQLALCHEMY_DATABASE_URI = 'postgresql+psycopg2://' + PSQLUSER + ':' + PSQLPASS + '@' + PSQLHOST + ':' + str(PSQLPORT) + '/' + PSQLDB + '?sslmode=' + PSQLSSLMODE + '&sslrootcert=' + PSQLSSLROOTCA  # PSQL must be parsed to STR, otherwise concatenation fails (INT vs STR)else:	print('PSQL: NO SSL MODE USED')	SQLALCHEMY_DATABASE_URI = 'postgresql+psycopg2://' + PSQLUSER + ':' + PSQLPASS + '@' + PSQLHOST + ':' + str(PSQLPORT) + '/' + PSQLDB # AUTHENTIFICATION STUFF ---------------------------------------------------------------------------OIDCCID=os.getenv('OIDC_CLIENT_ID')OIDCCS=os.getenv('OIDC_CLIENT_SECRET')CSRF_ENABLED = TrueAUTH_TYPE = AUTH_OAUTHAUTH_USER_REGISTRATION = FalseAUTH_ROLES_MAPPING = {    ""X.Y"": [""test""],    ""x.z"": [""Admin""]}AUTH_ROLES_SYNC_AT_LOGIN = TruePERMANENT_SESSION_LIFETIME = 600OAUTH_PROVIDERS = [    {        'name': 'XX',        'icon': 'XX',        'token_key': 'access_token',        'remote_app': {            'client_id': OIDCCID,            'client_secret': OIDCCS,            'api_base_url': 'https://sso.xx.com/as/',            'client_kwargs':{              'scope': 'openid email profile authorization_group entitlement_group scoped_entitlement offline_access'            },            'request_token_url': None,            'access_token_url': 'https://sso.xx.com/as/token.oauth2',			'refresh_token_url' : 'https://sso.xx.com/as/token.oauth2',            'authorize_url': 'https://sso.xx.com/as/authorization.oauth2',			'code_challenge_method':'S256',        }    }]ENABLE_PROXY_FIX = TruePREFERRED_URL_SCHEME = 'https'```### custom_sso_security_manager.py```from superset.security import SupersetSecurityManagerimport loggingclass CustomSsoSecurityManager(SupersetSecurityManager):	def oauth_user_info(self, provider, response=None):		access_token = response[""access_token""]		headers = {'Authorization': 'Bearer %s' % (access_token)}		me = self.appbuilder.sm.oauth_remotes[provider].get(""https://sso.xx.com/idp/userinfo.openid"", headers=headers)		data = me.json()		logging.debug(""User info from xx: %s"", data)      		logging.debug(""Entitlements: %s"", data.get(""entitlement_group"", []))		return {            ""username"": data.get(""sub"", """"),            ""first_name"": data.get(""given_name"", """"),            ""last_name"": data.get(""family_name"", """"),            ""email"": data.get(""email"", """"),            ""role_keys"": data.get(""entitlement_group"", []),		}```
"
19508,1,0,0,0,0,ValentinC-BR,0,"title:[Timeseries Bar Chart] The bar colors are not coherent with other charts in a dashboard. description:The Timeseries bar chart colors are not harmonized with other charts (since 1.4 ?)This might look like a mere cosmetic issue (actually, it is) but it is very annoying in a dashboard.#### How to reproduce the bug1. Add a timeseries bar chart to a dashboard2. Add another chart to your dashboard, with the same legend (GROUP BY field in most charts)3. Check colors### Expected resultsThe bars have the same colors the bar chart or line chart series### Actual resultsThe colors are different#### Screenshots![image](https://user-images.githubusercontent.com/79460908/161521939-023842ce-ac01-402c-a76f-aa677bf33535.png)### Environment- Browser type and version: Google Chrome Version 99.0.4844.51 (Oficial build) (x86_64)- Superset version: 1.4.1- Python version: 3.8.12- Node.js version: doesn闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?apply, I run on Kubernetes, using gunicorn as server- Source : AWS Athena- Any feature flags active: ALERT_REPORTS, ENABLE_TEMPLATE_PROCESSING, DASHBOARD_NATIVE_FILTERSChecklist[X] (not relevant) I have checked the superset logs for python stacktraces and included it here as text if there are any.[X] I have reproduced the issue with at least the latest released version of superset.[X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19504,1,563,32,0,0,rumbin,0,"title:Select time grain ""Original Value"" is not working on first attempt. description:The first attempt to choose ""Original Value"" as time grain results in ""Day"" being selected.This is very confusing for both beginners for power users who might not even check teh result of their actions.#### How to reproduce the bug1. Go to Explore with any time-series chart. Make sure  that the set time grain is not ""Day"". Maybe set it to ""Week"" and then refresh the page.2. Click on Time Grain3. Select ""Original Value""4. See how the Time Grain is set to ""Day"" instead5. repeat step 36. See how now the time grain is set as desired### Expected resultsSelecting ""Original Value"" works on the first attempt.### Actual resultsIt takes 2 attempts after loading/reloading the page.It seems that ""Original Value"" is only set correctly, if ""Day"" was set before.#### Screenshots![time_grain_original_value](https://user-images.githubusercontent.com/1220356/161505615-2b32a634-ad20-4d16-9af9-7bbe299f8cbd.gif)### EnvironmentWe use the official Docker images of 1.4.1 and 1.4.2, respectively.- affected browsers:     - Chrome 99.0.4844.84, 64 bit    - Edge 99.0.1150.36, 64 bit    - 98.0.2, 64 bit- superset version: 1.4.1; 1.4.2- python version: python --version- node.js version: ??- any feature flags active: ```python    FEATURE_FLAGS = {      # stable:      ""THUMBNAILS"": True,      ""THUMBNAILS_SQLA_LISTENERS"": True,      ""SQLLAB_BACKEND_PERSISTENCE"": True,      ""ENABLE_TEMPLATE_PROCESSING"": True,      ""DASHBOARD_CROSS_FILTERS"": True,      # experimental:      ""ALERT_REPORTS"": True,      ""ALERTS_ATTACH_REPORTS"": True,      ""DASHBOARD_NATIVE_FILTERS"": True,      # unclassified:      ""ENABLE_EXPLORE_DRAG_AND_DROP"": True,      ""ENABLE_DND_WITH_CLICK_UX"": True,      # development:      ""DASHBOARD_NATIVE_FILTERS_SET"": True    }```### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19502,1,0,9,0,0,srinisubramanian,0,"title:Export/Import Dashboard does not import chart changes. description:When changes are made to a dashboard and chart(s) and exported and imported the chart changes are not imported.  Only dashboard changes seem to be imported.#### How to reproduce the bugCreate a dashboard, add a few charts and export (VERSIONED_EXPORT= True).  Import it into another instance for the first time and all changes are imported.Make some changes to the dashboard AND to the charts.  Export and Import.  The changes to the dashboard are imported but not the changes to the charts.  Some of the changes that were not imported were:1.  Pie chart for e.g. Emit Cross Filter2. Big Number with trend line - Time filter, changes to filterA simple test is to for e.g. add/change the filter for the chart.  After exporting, unzip the file and verify the Chart YAML.  The new filter is present.  Now import, the filter change is not present in the target.### Expected resultsChart modifications are also imported### Actual resultsOnly dashboard changes seem to be imported#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version: Chrome- superset version: 1.4.1- python version: `python --version`- node.js version: `node -v`- any feature flags active:- VERSIONED_EXPORT- DASHBOARD_RBAC- DASHBOARD_CROSS_FILTER### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19499,1,0,5,0,0,moathOSA,0,"title:table column dimenssions. description:i have an issue in table column dimensions , i can't specify the column width and height to view only small data and view all data only on click !!also table columns not supporting JSON format like in SqlLab![table_column_dimensions_issue](https://user-images.githubusercontent.com/60176683/161419862-32487ebd-e897-4d7e-9169-06e65b3d06ed.jpg)superset version 1.4.1### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19496,1,169,0,0,0,nightbear1009,0,"title:migration plan "" New dataset models "" can't execute properly. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. add new dataset using virtual query with bigquery2. the sql is  as below```SELECT  project_id,  user_email,  creation_time,  total_bytes_billed,  queryFROM `region-us`.INFORMATION_SCHEMA.JOBS_BY_PROJECTWHERE job_type = ""QUERY""```3. go to console call `superset db upgrade`### Expected resultssuccess### Actual resultsTraceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/pybigquery/sqlalchemy_bigquery.py"", line 839, in _get_table    table = client.get_table(table_ref)  File ""/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py"", line 1008, in get_table    api_response = self._call_api(  File ""/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py"", line 756, in _call_api    return call()  File ""/usr/local/lib/python3.8/site-packages/google/api_core/retry.py"", line 283, in retry_wrapped_func    return retry_target(  File ""/usr/local/lib/python3.8/site-packages/google/api_core/retry.py"", line 190, in retry_target    return target()  File ""/usr/local/lib/python3.8/site-packages/google/cloud/_http/__init__.py"", line 480, in api_request    raise exceptions.from_http_response(response)google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/xxx_projectId/datasets/INFORMATION_SCHEMA/tables/JOBS_BY_PROJECT?prettyPrint=false: Not found: Table xxx_projectId:INFORMATION_SCHEMA.JOBS_BY_PROJECTDuring handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/usr/local/bin/superset"", line 33, in <module>    sys.exit(load_entry_point('apache-superset', 'console_scripts', 'superset')())  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1128, in __call__    return self.main(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 601, in main    return super().main(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1053, in main    rv = self.invoke(ctx)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1659, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1659, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1395, in invoke    return ctx.invoke(self.callback, **ctx.params)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 754, in invoke    return __callback(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/decorators.py"", line 26, in new_func    return f(get_current_context(), *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 445, in decorator    return __ctx.invoke(f, *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 754, in invoke    return __callback(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask_migrate/cli.py"", line 149, in upgrade    _upgrade(directory, revision, sql, tag, x_arg)  File ""/usr/local/lib/python3.8/site-packages/flask_migrate/__init__.py"", line 98, in wrapped    f(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask_migrate/__init__.py"", line 185, in upgrade    command.upgrade(config, revision, sql=sql, tag=tag)  File ""/usr/local/lib/python3.8/site-packages/alembic/command.py"", line 294, in upgrade    script.run_env()  File ""/usr/local/lib/python3.8/site-packages/alembic/script/base.py"", line 490, in run_env    util.load_python_file(self.dir, ""env.py"")  File ""/usr/local/lib/python3.8/site-packages/alembic/util/pyfiles.py"", line 97, in load_python_file    module = load_module_py(module_id, path)  File ""/usr/local/lib/python3.8/site-packages/alembic/util/compat.py"", line 184, in load_module_py    spec.loader.exec_module(module)  File ""<frozen importlib._bootstrap_external>"", line 843, in exec_module  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed  File ""/app/superset/extensions/../migrations/env.py"", line 126, in <module>    run_migrations_online()  File ""/app/superset/extensions/../migrations/env.py"", line 118, in run_migrations_online    context.run_migrations()  File ""<string>"", line 8, in run_migrations  File ""/usr/local/lib/python3.8/site-packages/alembic/runtime/environment.py"", line 813, in run_migrations    self.get_context().run_migrations(**kw)  File ""/usr/local/lib/python3.8/site-packages/alembic/runtime/migration.py"", line 561, in run_migrations    step.migration_fn(**kw)  File ""/app/superset/migrations/versions/b8d3a24d9131_new_dataset_models.py"", line 624, in upgrade    after_insert(target=dataset)  File ""/app/superset/migrations/versions/b8d3a24d9131_new_dataset_models.py"", line 422, in after_insert    tables = load_or_create_tables(  File ""/app/superset/migrations/versions/b8d3a24d9131_new_dataset_models.py"", line 282, in load_or_create_tables    column_metadata = inspector.get_columns(table.table, schema=table.schema)  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/reflection.py"", line 390, in get_columns    col_defs = self.dialect.get_columns(  File ""/usr/local/lib/python3.8/site-packages/pybigquery/sqlalchemy_bigquery.py"", line 872, in get_columns    table = self._get_table(connection, table_name, schema)  File ""/usr/local/lib/python3.8/site-packages/pybigquery/sqlalchemy_bigquery.py"", line 841, in _get_table    raise NoSuchTableError(table_name)sqlalchemy.exc.NoSuchTableError: JOBS_BY_PROJECT#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):current superset version is helm install lastest version, I think is 1.4.2-rc1- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ y] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ y] I have reproduced the issue with at least the latest released version of superset.- [ y] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19461,1,4905,12,0,1,nigzak,0,"title:Superset does not seem to support refresh token (OpenID Connect with authlib) and I get ""hardly"" kicked out after token expired. description:I am using superset with custom OAUTH configuration which is using a login token which expires after 30m.Until this time is not expired all worksIf the time expires I get error messages, in the logfile in the server is standing 401If I open the main page again (and I am not in some chart) I get a ""login"" page again displayed... this is in case I am modifying some charts very badSuperset 1.4.1 (Docker) with custom security#### How to reproduce the bug1. Login2. Open some charts3. wait until token from OIDC (OpenID Connect) expires4. execute some logic### Expected resultsRefresh token is executed (no visible refreshment for user)### Actual resultsUser login gets invalid and he gets kicked out, all not saved work is lostexample of backend error log ``` [31/Mar/2022:11:51:52 +0000] ""GET /api/v1/chart/_info?q=(keys:!(permissions)) HTTP/1.1"" 401 39 ""https://xxxxxx.com/chart/list/?pageIndex=0&sortColumn=changed_on_delta_humanized&sortOrder=desc&viewMode=table"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36""```### Environment(please complete the following information):Chrome browserSuperset 1.4.1 official docker image with authlib 0.15.5 (1.0.0 is buggy)Dockerfile```FROM apache/superset:1.4.1USER superset:supersetCOPY custom_sso_security_manager.py /app/pythonpath/custom_sso_security_manager.pyCOPY superset_config.py /app/pythonpath/superset_config.pyCOPY rootca.pem /app/pythonpath/rootca.pem  -- <== my database requires a certificate (postgreSQL)USER root:rootRUN apt -y updateRUN apt-get -y --only-upgrade install libsasl2-2  -- <== LIBSASL2 has a open VCE in current image, I update here to fix thisRUN chown superset:superset /app/pythonpath/custom_sso_security_manager.pyRUN chown superset:superset /app/pythonpath/superset_config.pyRUN chown superset:superset /app/pythonpath/rootca.pemRUN chmod +x /app/pythonpath/custom_sso_security_manager.pyRUN chmod +x /app/pythonpath/superset_config.pyRUN pip install authlib==0.15.5  -- <== using V1.0.0 is not working, if you don't type the version V1.0.0 is installedUSER superset:superset```### ChecklistI googled and tried many things but I did not find a working solution### Additional contextHINT: removed the URL and replaced with ""xx""superset_config.py```from flask_appbuilder.security.manager import AUTH_OID,AUTH_REMOTE_USER,AUTH_DB, AUTH_LDAP, AUTH_OAUTHimport osfrom custom_sso_security_manager import CustomSsoSecurityManagerCUSTOM_SECURITY_MANAGER = CustomSsoSecurityManagerbasedir = os.path.abspath(os.path.dirname(__file__))SUPERSET_WORKERS = 4# CRYPTION STUFF -----------------------------------------------------------------------------------SECRET_KEY = os.getenv('SUPERSET_SECRET_KEY')# DATABASE STUFF -----------------------------------------------------------------------------------PSQLHOST=os.getenv('PSQL_HOST')PSQLPORT=os.getenv('PSQL_PORT')PSQLUSER=os.getenv('PSQL_USER')PSQLPASS=os.getenv('PSQL_PASS')PSQLDB=os.getenv('PSQL_DB')PSQLSSLMODE = os.getenv('PSQL_SSL_MODE')PSQLSSLROOTCA = os.getenv('PSQL_SSL_ROOTCA')print (' USING DB FOR SQLALCHEMY ')print ('HOST: ' + str(PSQLHOST))print ('PORT: ' + str(PSQLPORT))print ('SSL_MODE: ' + PSQLSSLMODE)print ('SSL_CA: ' + PSQLSSLROOTCA)if PSQLSSLMODE != None and PSQLSSLMODE != """" and PSQLSSLROOTCA != None and PSQLSSLROOTCA != """":	print('PSQL: SSL MODE USED MODE=' + PSQLSSLMODE + ' CA=' + PSQLSSLROOTCA)	SQLALCHEMY_DATABASE_URI = 'postgresql+psycopg2://' + PSQLUSER + ':' + PSQLPASS + '@' + PSQLHOST + ':' + str(PSQLPORT) + '/' + PSQLDB + '?sslmode=' + PSQLSSLMODE + '&sslrootcert=' + PSQLSSLROOTCA  # PSQL must be parsed to STR, otherwise concatenation fails (INT vs STR)else:	print('PSQL: NO SSL MODE USED')	SQLALCHEMY_DATABASE_URI = 'postgresql+psycopg2://' + PSQLUSER + ':' + PSQLPASS + '@' + PSQLHOST + ':' + str(PSQLPORT) + '/' + PSQLDB # AUTHENTIFICATION STUFF ---------------------------------------------------------------------------OIDCCID=os.getenv('OIDC_CLIENT_ID')OIDCCS=os.getenv('OIDC_CLIENT_SECRET')CSRF_ENABLED = TrueAUTH_TYPE = AUTH_OAUTHAUTH_USER_REGISTRATION = FalseAUTH_ROLES_MAPPING = {    ""X.Y"": [""test""],    ""x.z"": [""Admin""]}AUTH_ROLES_SYNC_AT_LOGIN = TruePERMANENT_SESSION_LIFETIME = 600OAUTH_PROVIDERS = [    {        'name': 'XX',        'icon': 'XX',        'token_key': 'access_token',        'remote_app': {            'client_id': OIDCCID,            'client_secret': OIDCCS,            'api_base_url': 'https://sso.xx.com/as/',            'client_kwargs':{              'scope': 'openid email profile authorization_group entitlement_group scoped_entitlement offline_access'            },            'request_token_url': None,            'access_token_url': 'https://sso.xx.com/as/token.oauth2',			'refresh_token_url' : 'https://sso.xx.com/as/token.oauth2',            'authorize_url': 'https://sso.xx.com/as/authorization.oauth2',			'code_challenge_method':'S256',        }    }]ENABLE_PROXY_FIX = TruePREFERRED_URL_SCHEME = 'https'```custom_sso_security_manager.py```from superset.security import SupersetSecurityManagerimport loggingclass CustomSsoSecurityManager(SupersetSecurityManager):	def oauth_user_info(self, provider, response=None):		access_token = response[""access_token""]		headers = {'Authorization': 'Bearer %s' % (access_token)}		me = self.appbuilder.sm.oauth_remotes[provider].get(""https://sso.xx.com/idp/userinfo.openid"", headers=headers)		data = me.json()		logging.debug(""User info from xx: %s"", data)      		logging.debug(""Entitlements: %s"", data.get(""entitlement_group"", []))		return {            ""username"": data.get(""sub"", """"),            ""first_name"": data.get(""given_name"", """"),            ""last_name"": data.get(""family_name"", """"),            ""email"": data.get(""email"", """"),            ""role_keys"": data.get(""entitlement_group"", []),		}```### HINTit could be that I have some configuration missunderstandings ... if this is the case please let me know how to fix this ...... could it be that I must add refresh_token() in custom security manager also, refer https://docs.authlib.org/en/latest/client/oauth2.html ..? or am I on a badly wrong way?
"
19459,1,0,1,0,0,vdobes,0,"title:SQL Lab - Blank window after selecting Table to query in. description:SQL Lab error when accessing SQL query. There is only a blank white view with no SQL query editor view.#### How to reproduce the bug1. Go to SQL Lab -> SQL Editor2. Select Databse, Scheme, and Table to query### Expected resultsThere should be a Query editor window### Actual resultsThere is only a blank white view with no query editor. You must clear the browser cache, to get working at least the main SQL Lab view.#### ScreenshotsHere is the video of this bug:https://user-images.githubusercontent.com/12327524/161045918-9e92da0d-6a3a-47c2-aea1-aca560dd2fd6.mp4The only error whats dev console shows:![image](https://user-images.githubusercontent.com/12327524/161046370-d4090efa-28d0-464a-b0a5-99c055e7c6d7.png)### Environment- browser type and version: All kind of browsers on latest version- superset version: latest docker-compose version with Redis cache- any feature flags active:    ""DASHBOARD_NATIVE_FILTERS"": True,    ""ENABLE_TEMPLATE_PROCESSING"": True,
"
19449,0,0,0,0,0,PaulKov,0,"title:Error when fetch saved queries. description:#### How to reproduce the bug1. Go to superset/welcome/2. See errorError message:![image](https://user-images.githubusercontent.com/74862786/160931718-07fec5ca-f302-4c98-9fb7-de17e859fbda.png)Failed api request in web developer tools:![image](https://user-images.githubusercontent.com/74862786/160933749-0cbfc4cb-1891-491d-a10f-9c890088945e.png)Response to failed API request: {""message"":""Filter column: owners not allowed to filter""}.### Environment- superset version: apache/superset:latest-dev (installed using docker-compose)- python version: 3.8.12
"
19431,1,423,0,0,0,CFM90,0,"title:German Translation not correctly implemented?. description:The German translation is very much incomplete. But I suspect a bug not an incomplete tanslation per se, because as the screnshots  by @hbruch in [PR17525 ](https://github.com/apache/superset/pull/17525) indicate, the German translation is way more complete compared what I can find on a fresh install. So there may be a good German translation which is not correctly included in superset itself. This would be a pitty for all German users and the creator of the translation.#### How to reproduce the bug1. Install Superset from Scratch following [this](https://superset.apache.org/docs/installation/installing-superset-from-scratch). (so not using docker)2. Add the following to the superset_config:```BABEL_DEFAULT_LOCALE = ""de""BABEL_DEFAULT_FOLDER = ""superset/translations""LANGUAGES = {    'en': {'flag': 'us', 'name': 'English'},    'de': {'flag': 'de', 'name': 'German'}}```### Expected resultsA German translation similar to those visible on the screenshots by @hbruch  in: [PR17525 ](https://github.com/apache/superset/pull/17525 ) ### Actual results & Screenshots![grafik](https://user-images.githubusercontent.com/24831579/160825258-81b93c6f-c8df-44bb-b217-175405c0b951.png)![grafik](https://user-images.githubusercontent.com/24831579/160825354-440fab08-d0bd-4ceb-b7a4-83b6636055ec.png)![grafik](https://user-images.githubusercontent.com/24831579/160825404-3612be18-6994-432f-aecd-56a6a64ea9e8.png)You can see that there are terms which are translated to German and others which are not. The overall impression is very incomplete and incomprehensive. ### Environment- browser type and version: Mozilla Firefox V 98.02- superset version: `1.4.2`, the most recent one- python version: `3.8.10`- node.js version: `v10.19.0`- any feature flags active:```FEATURE_FLAGS = {  ""DASHBOARD_CACHE"": True,  ""ALERT_REPORTS"": True,  ""DASHBOARD_RBAC"": True,    ""LISTVIEWS_DEFAULT_CARD_VIEW"" : True,  ""ENABLE_EXPLORE_DRAG_AND_DROP"": True,  ""OMNIBAR"" : True,  ""CLIENT_CACHE"": True}```### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional InformationI also worked on a translation (because I thought the existing one is just incomplete). I was able to translate more words and terms using the .mo files as seen on the screenshots here from the fresh install. So the translation from the fresh install is not incomplete because the englisch words are not included in the babel process. 
"
19414,1,2639,0,0,0,code23rus,0,"title:OAuth2 - oauth_user_info not worked. description:Hi.We set up oauth2 authorization, it work fine on master branche checkouted 4 months ago. But after update on current version method for getting user information is no longer called.#### How to reproduce the bugsuperset_config.py```from flask_appbuilder.security.manager import AUTH_OAUTHAUTH_TYPE = AUTH_OAUTHOAUTH_PROVIDERS = [    {   'name':'semnext',        'token_key':'access_token', # Name of the token in the response of access_token_url        'icon':'fa-address-card',   # Icon for the provider        'remote_app': {            'client_id':'semnext-superset',  # Client Id (Identify Superset application)            'client_secret':'OUR-SECRET', # Secret for this Client Id (Identify Superset application)            'client_kwargs':{                'scope': 'read'               # Scope for the Authorization            },            'access_token_method':'POST',    # HTTP Method to call access_token_url            'access_token_params':{        # Additional parameters for calls to access_token_url                'client_id':'semnext-superset'            },            'access_token_headers':{    # Additional headers for calls to access_token_url                'Authorization': 'Basic Base64EncodedClientIdAndSecret'            },            'api_base_url':'http://10.3.2.39/sem-restservices/oauth2/',            'access_token_url':'http://10.3.2.39/sem-restservices/oauth2/token',            'authorize_url':'http://10.3.2.39/sem-restservices/oauth2/authorize'        }    }]AUTH_USER_REGISTRATION = TrueAUTH_USER_REGISTRATION_ROLE_JMESPATH = ""username == 'root' && 'Admin' || 'Gamma'""from custom_sso_security_manager import CustomSsoSecurityManagerCUSTOM_SECURITY_MANAGER = CustomSsoSecurityManager```custom_sso_security_manager.py```import loggingfrom superset.security import SupersetSecurityManagerclass CustomSsoSecurityManager(SupersetSecurityManager):    def oauth_user_info(self, provider, response=None):        logging.debug(""Oauth2 provider: {0}."".format(provider))        if provider == 'semnext':            me = self.appbuilder.sm.oauth_remotes[provider].get('userinfo')            logging.info(""'userinfo: {0}"".format(me))            data = me.json()            logging.info(""me.json() %s"", data)            return { 'name' : data['user_name'], 'email' : data['email'], 'id' : data['user_name'], 'username' : data['user_name'], 'first_name': data['first_name'], 'last_name': data['last_name']}```But method GET http://10.3.2.39/sem-restservices/oauth2/userinfo not invoked.In logs we have exception: ```superset_app            | 2022-03-29 14:54:06,569:DEBUG:urllib3.connectionpool:http://10.3.2.38:8080 ""POST /sem-restservices/oauth2/token HTTP/1.1"" 200 246superset_app            | 2022-03-29 14:54:06,571:DEBUG:root:Oauth2 provider: semnext.superset_app            | 2022-03-29 14:54:06,571:ERROR:flask_appbuilder.security.views:Error returning OAuth user info: missing_token:```Method POST /sem-restservices/oauth2/token correctly return access_token. In old version of superset its work fine. But the current version probably doesn't want to use the received token.
"
19396,0,131,1,1,0,MCBoarder289,0,"title:Slack invite link broken in README. description:When trying to join the community Slack linked in the README, you receive a page with the following message:```This link is no longer activeTo join this workspace, you闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸嬫﹢鏌?need to ask the person who originally invited you for a new link.```#### How to reproduce the bug1. Go to 'README.md'2. Click the ""[Join our community's Slack](https://join.slack.com/t/apache-superset/shared_invite/zt-uxbh5g36-AISUtHbzOXcu0BIj7kgUaw)"" link3. See error### Expected resultsGet an invite to the Slack community### Actual resultsGet an inactive link error message### Environment(please complete the following information):- Chrome 99.0.4844.84- superset version: `master` branch- python version: N/A- node.js version: N/A- any feature flags active: no### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextSeems similar to this older issue: https://github.com/apache/superset/issues/8613
"
19391,1,0,0,0,0,Narendra678,0,"title:URL link to column values. description:Hi Team,I have one column with URL values, in superset it is not coming with underline.Please suggest.Requirement: When click it should open with new tab.Regards,Naren
"
19385,1,0,12,0,0,9en9i,0,"title:Frontend cannot be build. description:#### How to reproduce the bug1. Clone master2. Run docker-compose up3. Scroll down container logs superset-node4. See error### Expected resultsFrontend was build### Actual resultsFrontend was not build and container has stopped#### Screenshots<img width=""626"" alt=""image"" src=""https://user-images.githubusercontent.com/44907258/160272319-2d848f78-db27-4259-acb9-6acd14665523.png"">### Environment- os: macos 12.3 (m1)- superset version: `5ae7e549` / `0.0.0dev`- docker version: `Docker version 20.10.13, build a224086`### Checklist- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19367,1,178,0,0,1,icyground,0,"title:User registration not possible for instance deployed via Helm chart. description:Flask-Mail package is not installed but needed to register Users. #### How to reproduce the bug1. deploy superset via Helm Chart with appropriate configuration (including mail-settings)2. try to register a user### Expected resultsThe new user will be registered### Actual resultsUser registration fails.Error message in log:`2022-03-25 10:26:29,778:ERROR:flask_appbuilder.security.registerviews:Install Flask-Mail to use User registration`#### Screenshots<img width=""1298"" alt=""image"" src=""https://user-images.githubusercontent.com/1493116/160104556-318fb9ab-39c6-4c11-833b-49316171ae60.png"">### Environmentdeployed via Helm Chart- browser type and version: `Google Chrome 99.0.4844.83`- superset version: `0.0.0dev`- python version: `Python 3.8.12`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextInstalling the module fixes the problem and users can register.```supersetNode:  command:    - /bin/sh    - -c    - |      pip install Flask-Mail      . {{ .Values.configMountPath }}/superset_bootstrap.sh; /usr/bin/run-server.sh```
"
19360,0,0,20,0,0,cccs-tom,0,"title:Dataset permissions: Users are unable to see the datasets that they create. description:In our deployment, we have a ""sandbox"" database where analysts are free to create and delete schemas and tables at will. In order to support this, we assign them a role that includes the 'can write on Dataset', 'menu access on Upload a CSV' and 'database access on [sandbox]' permissions. The database connection itself is configured to 'Allow DML' and 'Allow data upload'. When a user who has been assigned that roles creates a dataset against a table in that database, they are then unable to see their dataset listed under Datasets. It also does not appear in the drop-down on the Chart creation dialog.#### How to reproduce the bug1. Configure a 'sandbox' Database as described, i.e. Expose the database in SQL Lab, Allow DML and allow it to be explored. Also (under Security) allow data to be uploaded2. Configure a role with 'can write on Dataset', 'menu access on Upload a CSV' and 'database access on [sandbox]' permissions3. Create a user and assign them the Gamma role as well as the role created in step 24. With the new user, create a Dataset in the sandbox database - it can be on an existing table, but I did most of my testing using 'Upload a CSV'. It doesn't seem to matter whether the dataset is physical or virtual.5. Once the dataset is successfully created, go to Data -> Datasets or the Chart creation dialog and try to find it in the list6. Using an Admin user, you should be able to confirm that the dataset was indeed created### Expected resultsI would expect any user who has been assigned the same role (and thus, has database-level permission) to be able to see the dataset and create a chart that uses it. Or at the very least, I would expect the ~creator and any~ Owners of the dataset to see it.### Actual results* The dataset is invisible to the creator / Owners and any user who doesn't have the 'all datasource access on all_datasource_access' permission.* However, the dataset **is not fully inaccessible**. If the user is provided with a direct link (e.g. https://company.com/superset/explore/table/{id}/), then they are able to explore the dataset and run queries against it. Upon debugging this with @villebro, it looks like there are multiple code paths to determine what datasets a user can see and they are inconsistent with each other.### Environment- browser type and version: Doesn't seem to matter, but I have tested with Firefox 91 and Chrome 99.- superset version: 1.4.0- python version: 3.8.12- any feature flags active:  - ""ENABLE_TEMPLATE_PROCESSING"": True,  - ""DASHBOARD_NATIVE_FILTERS"": True,  - ""DASHBOARD_CROSS_FILTERS"": True,  - ""DASHBOARD_NATIVE_FILTERS_SET"": True,  - ""DASHBOARD_RBAC"": True,  - ""ENABLE_EXPLORE_DRAG_AND_DROP"": False,  - ""ENABLE_TEMPLATE_REMOVE_FILTERS"": True,### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context* One work-around we have found for this issue is to add a schema-level permission to the users' role. Unfortunately, this doesn't really scale well since, as mentioned, our analysts are free to create and delete schemas in this database.
"
19349,0,791,30,0,0,Gordonei,0,"title:Custom Javascript editing/parser in deck.gl visualisations seems to be broken. description:Firstly, thanks for such an awesome project!When trying to add Javascript to customise onClick, Tooltips, etc. in the deck.gl visualisations, the text box in which you enter the code text behaves erratically. It is also unclear what is actually persisted onto the visualisation, it doesn't appear to be the code as entered.#### How to reproduce the bug(I've given instructions for the deck.gl Scatterplot, but seems to apply to all deck.gl visualisations)1. Go to Charts, Add new chart2. Select a dataset with spatial attributes, choose deck.gl Scatterplot, click on Create New Chart3. Configure Chart to display some data (i.e. configure the Lat-Long values)4. Under Data configuration pane on left of screen, expand the ""Advanced"" collapse. Attempt to enter text in the ""Javascript Tooltip Generator"". It should enter duplicate values.5. In the browser console, there should be `Uncaught TypeError: (validationErrors || []).forEach is not a function`### Expected resultsText typed in the Javascipt fields in deck.gl visualisations to appear as typed. For the code entered to be executed in the context of the visualisation.### Actual resultsText appearing in field does not match what was typed. Custom JS code doesn't appear to be executed in map.Following error appearing in browser console per character typing:```explore.fd9dbc001a8d2b732fc9.entry.js:624 Uncaught TypeError: (validationErrors || []).forEach is not a function    at Object.SET_FIELD_VALUE (explore.fd9dbc001a8d2b732fc9.entry.js:624:32)    at exploreReducer (explore.fd9dbc001a8d2b732fc9.entry.js:694:39)    at combination (vendors.866d9853ec9ca701f3b8.entry.js:198222:29)    at dispatch (vendors.866d9853ec9ca701f3b8.entry.js:197988:22)    at 3236.54993c7b99382ace8b98.entry.js:242:12    at 1844.8922f8dcb86356245bf9.entry.js:1075:16    at vendors.866d9853ec9ca701f3b8.entry.js:198240:12    at Object.onChange (7173.0ceb268407a17642e1ec.entry.js:12551:61)    at ReactAce.push.93946.ReactAce.onChange (437abb94798b28dd8787.chunk.js:25959:24)    at Editor.EventEmitter._signal (600b0291f89941e46ffa.chunk.js:3870:21)```#### ScreenshotsThis is what appeared after typing a single `d` character:![image](https://user-images.githubusercontent.com/1272984/159888427-0441936c-0b60-4e2a-910b-cf177a508bb7.png)This is after typing `d =>`:![image](https://user-images.githubusercontent.com/1272984/159888547-dc49cfcf-441e-45ea-8d81-9679dae7be89.png)### Environment- browser type and version:  - Mozilla Firefox 98.0 (64-bit)  - Google Chrome Version 99.0.4844.51 (Official Build) (64-bit)(built off `apache/superset:1.4.0` Docker image tag)- superset version: `1.4.0`- python version: `python 3.8.12`- node.js version: *sorry, not sure how to get the node version inside the running docker container*?- any feature flags active:  - `ENABLE_TEMPLATE_PROCESSING`  - `ALERT_REPORTS`  - `THUMBNAILS`  - `LISTVIEWS_DEFAULT_CARD_VIEW`  - `DASHBOARD_NATIVE_FILTERS`  - `ENABLE_JAVASCRIPT_CONTROLS` (in `tooltips` config section) ### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextI'm aware this functionality is fairly old (#4173), so I wonder if maybe a subsequent change has broken the in-browser JS parsing?
"
19347,1,824,10,0,0,kong62,0,"title:can not change redis image. description:A clear and concise description of what the bug is.#### How to reproduce the bug```redis:  master:    image:      #repository: bitnami/redis      repository: harborproxy.hupu.io/proxy/k8s/redis      tag: 6.2.6-debian-10-r120      pullPolicy: IfNotPresent      pullSecrets: nil    persistence:      enabled: false```### Expected results```harborproxy.hupu.io/proxy/k8s/redis:6.2.6-debian-10-r120```### Actual results```# kubectl describe pod superset-redis-master-0 -n superset |grep -i image    Image:         docker.io/bitnami/redis:6.2.6-debian-10-r120    Image ID:      docker-pullable://bitnami/redis@sha256:6a76298b78b9890ddac6010edfbea15545e6a5de20f2710a222cec44900a6e9f```### Environment```# helm search repo supersetNAME                    CHART VERSION   APP VERSION     DESCRIPTION                                       superset/superset       0.5.10          1.0             Apache Superset is a modern, enterprise-ready b...```
"
19345,1,0,0,0,0,hufenfen,0,"title:chart data type bug. description:Hello,I use superset to create a new virtual dataset and create a new column 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墰閸楁氨绱掗埀顒勬儘閻氱nt_name闂? The column's type is String. But then I want to create a new line chart and group by the column  闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墰閸楁氨绱掗埀顒勬儘閻氱nt_name闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墯瀹曟煡鏌熼柇锕€鏋熸い顐ｆ礃缁绘繈寮撮妸锔惧幐 comes out a bug , says ""Column `account_name` is not under aggregate function and not in GROUP BY"". I don闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤鐓庡娴?understand why the line chart  do this 闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟鐑橆殢閺佸棝鏌ｉ敐鍕檮tartOfHour(toDateTime(account_name)) U can see the pictures below.Hope to hear from you ~Thanks![TMnKWJDHrI](https://user-images.githubusercontent.com/94423972/159833507-2707a7e8-70d1-4861-a04e-4773ec67188e.png)![An53pVHvCo](https://user-images.githubusercontent.com/94423972/159833517-a6d482b5-19f4-48e8-9928-abe0ea926f40.png)
"
19306,1,0,0,0,0,samwilkinson-git,0,"title:Generic Install on OpenShift Container - error:superset.views.base:'NoneType' object has no attribute 'id' . description:After a successful installation in Docker using the 'pip install apache-superset'; I've tried running the same install but this time in OpenShift.I have successfully pushed the image into OpenShift, I can access the login page successfully... Expected Results:Should be able to login.Actual Results: **error:superset.views.base:'NoneType' object has no attribute 'id'** Traceback (most recent call last): File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1950, in full_dispatch_request rv = self.dispatch_request() File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1936, in dispatch_request return self.view_functions[rule.endpoint](**req.view_args) File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/views.py"", line 516, in login user = self.appbuilder.sm.auth_user_db( File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/manager.py"", line 874, in auth_user_db self.noop_user_update(first_user) File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/sqla/manager.py"", line 244, in noop_user_update .where(self.user_model.id == user.id)How to reproduce:Follow this guide... https://superset.apache.org/docs/installation/installing-superset-from-scratch PostGres - SetupConfig - SetupAny help would be appreciated.Thanks!
"
19301,1,4896,9,0,0,EinavDanielDX,0,"title:Alerts and reports notification fails due to selenium exception. description:After scheduling a report for either chart of dashboard, using smtp, The report fails to send the message with the following error in worker pod:```[2022-03-21 14:29:00,298: INFO/ForkPoolWorker-15] Init selenium driver/usr/local/lib/python3.8/site-packages/celery/platforms.py:800: RuntimeWarning: You're running the worker with superuser privileges: this isabsolutely not recommended!Please specify a different user using the --uid option.User information: uid=0 euid=0 gid=0 egid=0  warnings.warn(RuntimeWarning(ROOT_DISCOURAGED.format(Scheduling alert my_test eta: 2022-03-21 14:30:00[2022-03-21 14:30:00,102: INFO/ForkPoolWorker-16] Scheduling alert my_test eta: 2022-03-21 14:30:00Report state: Report Schedule is still working, refusing to re-compute.[2022-03-21 14:30:00,293: INFO/ForkPoolWorker-16] Report state: Report Schedule is still working, refusing to re-compute.Selenium timed out requesting url https://my-domain/superset/slice/75/?standalone=true&standalone=3Traceback (most recent call last):  File ""/app/superset/utils/webdriver.py"", line 122, in get_screenshot    element = WebDriverWait(driver, self._screenshot_locate_wait).until(  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/support/wait.py"", line 80, in until    raise TimeoutException(message, screen, stacktrace)selenium.common.exceptions.TimeoutException: Message: [2022-03-21 14:30:45,988: WARNING/ForkPoolWorker-15] Selenium timed out requesting url https://my-domain/superset/slice/75/?standalone=true&standalone=3Traceback (most recent call last):  File ""/app/superset/utils/webdriver.py"", line 122, in get_screenshot    element = WebDriverWait(driver, self._screenshot_locate_wait).until(  File ""/usr/local/lib/python3.8/site-packages/selenium/webdriver/support/wait.py"", line 80, in until    raise TimeoutException(message, screen, stacktrace)selenium.common.exceptions.TimeoutException: Message: Report state: Failed taking a screenshot local variable 'element' referenced before assignment[2022-03-21 14:30:46,136: INFO/ForkPoolWorker-15] Report state: Failed taking a screenshot local variable 'element' referenced before assignmentScheduling alert my_test eta: 2022-03-21 14:31:00```Also, in  under reports -> logs in UI screen i see this error`Failed taking a screenshot local variable 'element' referenced before assignment`#### How to reproduce the bug1 - setup alerts, smtp and google chrome driver for selenium2 - schedule a report 3 - follow logs### Expected resultsAn email with the relevant dashboard/chart should be sent### Actual resultsSelenium fails to take a screenshot fails, I'm getting an email with a failure message as described above#### Screenshots![image](https://user-images.githubusercontent.com/97506919/159427721-7678a22e-b8de-489c-bd39-5a249ed84a33.png)### Environment- browser type and version: `chrome 99.0.4844.51`- superset version: `1.4.1`- python version: `Python 3.8.12`- deployment method: helm chart- any feature flags active:my configuration```      FEATURE_FLAGS = {          ""DYNAMIC_PLUGINS"": True,          ""ENABLE_TEMPLATE_PROCESSING"": True,          ""VERSIONED_EXPORT"": True,          ""ALERT_REPORTS"": True      }      from celery.schedules import crontab      REDIS_HOST = env('REDIS_HOST')      REDIS_PORT = env('REDIS_PORT')      class CeleryConfig:          BROKER_URL = 'redis://%s:%s/0' % (REDIS_HOST, REDIS_PORT)          CELERY_IMPORTS = ('superset.sql_lab', ""superset.tasks"", ""superset.tasks.thumbnails"", )          CELERY_RESULT_BACKEND = 'redis://%s:%s/0' % (REDIS_HOST, REDIS_PORT)          CELERYD_PREFETCH_MULTIPLIER = 10          CELERY_ACKS_LATE = True          CELERY_ANNOTATIONS = {              'sql_lab.get_sql_results': {                  'rate_limit': '100/s',              },              'email_reports.send': {                  'rate_limit': '1/s',                  'time_limit': 600,                  'soft_time_limit': 600,                  'ignore_result': True,              },          }          CELERYBEAT_SCHEDULE = {              'reports.scheduler': {                  'task': 'reports.scheduler',                  'schedule': crontab(minute='*', hour='*'),              },              'reports.prune_log': {                  'task': 'reports.prune_log',                  'schedule': crontab(minute=0, hour=0),              },          }      CELERY_CONFIG = CeleryConfig      SCREENSHOT_LOCATE_WAIT = 100      SCREENSHOT_LOAD_WAIT = 600      # # Slack configuration      # SLACK_API_TOKEN = ""xoxb-""      # Email configuration      THUMBNAIL_SELENIUM_USER = 'admin@mydomain.com'      ENABLE_SCHEDULED_EMAIL_REPORTS = True      SMTP_HOST = env('SMTP_HOST')      SMTP_USER = env('SMTP_USER')      SMTP_PASSWORD = env('SMTP_PASSWORD')      SMTP_PORT = env('SMTP_PORT')       SMTP_SSL = False      SMTP_STARTTLS = True      SMTP_MAIL_FROM = env('SMTP_MAIL_FROM')      # WebDriver configuration      # If you use Firefox, you can stick with default values      # If you use Chrome, then add the following WEBDRIVER_TYPE and WEBDRIVER_OPTION_ARGS      WEBDRIVER_TYPE = ""chrome""      WEBDRIVER_OPTION_ARGS = [          ""--force-device-scale-factor=2.0"",          ""--high-dpi-support=2.0"",          ""--headless"",          ""--disable-gpu"",          ""--disable-dev-shm-usage"",          ""--no-sandbox"",          ""--disable-setuid-sandbox"",          ""--disable-extensions"",      ]      # This is for internal use, you can keep http      WEBDRIVER_BASEURL=env('DASHBOARDS_BASE_URL')      # This is the link sent to the recipient, change to your domain eg. https://superset.mydomain.com      WEBDRIVER_BASEURL_USER_FRIENDLY=env('DASHBOARDS_BASE_URL')```
"
19300,1,284,5,0,0,moathOSA,0,"title:having syntax error when using mysql operators inside jinja. description:i'm getting this errorPlease check your query for syntax errors near ""nullAND deal_growth IN (somthing)```where stores.parent_id is null and cnt is null         {%- if (filter_values('deal_growth') is defined) and filter_values('deal_growth') -%}                AND             deal_growth IN ({{ ""'"" + ""','"".join(filter_values('deal_growth')) + ""'"" }})        {%- endif -%}```superset version 1.4.1### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19299,0,0,0,0,0,fuxiaodun,0,"title:Annotation line chart color cannot be changed . description:When use line chart as an annotation, I cannot set color of the annotation.#### How to reproduce the bug1. Go to Explore Chart, chart type select Time-series line chart2. Click on Annotation Layers3. In Edit Annotation Layer, select Time Series as layer type, Line Chart as Annotation Source, select a Line chart.4. In Display Configuration, choose a color, click Apply and Run Query5. See error, annotation color is not changed### Expected resultsThe annotation color is as you choose### Actual resultsThe color never change to your selected color#### Screenshotshttps://user-images.githubusercontent.com/22674597/159418102-26a02612-932e-4448-803e-fbb478c6a10f.mp4### Environment- browser type and version: Chrome Version 99.0.4844.51 (Official Build) (64-bit)- superset version: 1.4.0
"
19297,0,1367,9,0,0,srinisubramanian,0,"title:Export / Import fails with validation error. description:Export a dashboard with VERSIONED_EXPORT=true.  Try importing on same instance or another instance and it fails with a command validation error.1.  Based on responses to #19268 from @villebro I reset my dev superset instance.  Then created a dashboard from scratch and saved and exported it.  I then tried to reimport it and it fails with a command validation error.2. I then reset the instance again and then tried to reimport the dashboard on a brand new setup. Fails with same error.  The log is set to DEBUG but not very helpful```2022-03-22 10:25:21,789:INFO:werkzeug: * Running on http://127.0.0.1:8088/ (Press CTRL+C to quit)2022-03-22 10:25:29,502:INFO:werkzeug:127.0.0.1 - - [22/Mar/2022 10:25:29] ""GET /dashboard/list/?pageIndex=0&sortColumn=changed_on_delta_humanized&sortOrder=desc&viewMode=table HTTP/1.1"" 200 -2022-03-22 10:25:31,722:INFO:werkzeug:127.0.0.1 - - [22/Mar/2022 10:25:31] ""GET /api/v1/dashboard/_info?q=(keys:!(permissions)) HTTP/1.1"" 200 -2022-03-22 10:25:31,727:INFO:werkzeug:127.0.0.1 - - [22/Mar/2022 10:25:31] ""GET /api/v1/dashboard/?q=(order_column:changed_on_delta_humanized,order_direction:desc,page:0,page_size:25) HTTP/1.1"" 200 -Command failed validation2022-03-22 10:25:42,497:INFO:superset.dashboards.commands.importers.dispatcher:Command failed validationError importing dashboard2022-03-22 10:25:42,498:WARNING:superset.views.base:Error importing dashboard2022-03-22 10:25:42,501:INFO:werkzeug:127.0.0.1 - - [22/Mar/2022 10:25:42] ""POST /api/v1/dashboard/import/ HTTP/1.1"" 422 -Command failed validation2022-03-22 10:25:48,012:INFO:superset.dashboards.commands.importers.dispatcher:Command failed validationError importing dashboard2022-03-22 10:25:48,013:WARNING:superset.views.base:Error importing dashboard2022-03-22 10:25:48,016:INFO:werkzeug:127.0.0.1 - - [22/Mar/2022 10:25:48] ""POST /api/v1/dashboard/import/ HTTP/1.1"" 422 -```Details of dashboard:1.  Linked to 4 datasets (3 tables and a view) on MySQL2. Has 2 tabs3. Has markdown, big number with timeline, area and barcharts v2 with a filterbox#### How to reproduce the bug1. Create a dashboard, save and export it (VERSIONED_EXPORT = true)2. Try to import and fails with a validation error3. The issue is that a simple dashboard with just one or two charts seems to work.  A more involved dashboard such as the one I am building fails### Expected resultsImport should be successful### Actual resultsFails import#### Screenshots### Environment(please complete the following information):- browser type and version: Chrome- superset version: `superset version` 1.4.1- python version: `python --version` 3.8.12- node.js version: `node -v`- any feature flags active: VERSIONED_EXPORT### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextIf required @villebro  please let me know and I can email you an export of the database (data and superset) and a copy of the dashboard zip file
"
19277,1,0,0,0,0,marinej-BR,0,"title:Not possible to configure native filters in 1.4.1 / mapping filters gets lost when editing native filters. description:When native filters are edited, the configuration about mapping filter is removed.#### How to reproduce the bug1. Create a dashboard that includes at least two charts et one filter box. The filter box should only apply to one of the two charts2. Open the native filters properties using the ""Edit"" action3. Make an edit and save4. Reopen the Dashboard### Expected resultsThe filter mapping works normally.### Actual resultsThe configuration about mapping filter is removed.#### Screenshotsnone added### Environment- Browser type and version: Google Chrome Version 99.0.4844.51 (Oficial build) (x86_64)- Superset version: 1.4.1- Python version: 3.8.12- Node.js version: doesn闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?apply, I run on Kubernetes, using gunicorn as server- Source : AWS Athena- Any feature flags active: ALERT_REPORTS, ENABLE_TEMPLATE_PROCESSING, DASHBOARD_NATIVE_FILTERS### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19276,1,0,0,0,0,lazpuzzle,0,"title:Error :  ElasticSearch (OpenDistro SQL). description:I got ErrorElasticSearch (OpenDistro SQL) Errorodelasticsearch error: TransportError(500, 'SearchPhaseExecutionException')When i user sqllab and query is select * from table and set limit is 10000orselect * from table limit more than 7000how can i solve it![image](https://user-images.githubusercontent.com/40905829/159245454-289c43ef-1847-4c45-98f0-c02945d64425.png)
"
19275,1,271,5,0,0,moathOSA,0,"title: when using jinja template with filters that have boolean  values of type int , the filter not working . description:when using a filter that have values like  0 , 1 which is a boolean filter when retrieving the values of this filter in jinja template i faced this error ```sequence item 0: expected str instance, int found```and this is how the filter look like```        {%- if (filter_values('cancelled') is defined) and filter_values('cancelled') -%}            AND            cancelled IN ({{ ""'"" + ""','"".join(filter_values('cancelled')) + ""'"" }})        {%- endif -%}```superset version 1.4.1### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19272,1,0,0,0,0,dineshp89,0,"title:Module  import CacheConfig in config.py. description:Import error in config.py for CacheConfig#### How to reproduce the bug1. Open the config.py2. Go to line number 48  in config.py3. See ""from superset.superset_typing import CacheConfig""4. and try to ""superset db upgrade""### Expected resultsSuccessful superset db upgrade ### Actual resultsGot below error:ModulNotFoundError: No module Named 'superset.superset_typing'#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: `1.4.1- python version: `3.8`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19271,1,2158,5,0,0,moathOSA,0,"title:when using jinja template with filters, the filter applies twice !!. description:![Screenshot 2022-03-21 at 10-03-35 Orders Dashboard](https://user-images.githubusercontent.com/60176683/159217827-9b663270-180f-4add-b4c4-2805a0336078.png)this is the generated query in the dashboard and as you see there is some filters applied twice like Currency* i tried every thing like using the filter name instead of the field name* i tried to make field name diff from the filter namemaking alias for the fields name .... nothing work ! this is the query with filters ```SELECT `orders`.`cancelled` AS `Cancelled`,`orders`.`confirmed` AS `Confirmed`, `orders`.`visible` AS `Visible`, `orders`.`created_at` AS `Created_at`, `orders`.`order_no` AS `Order_No`, `orders`.`amount` AS `Amount`, `orders`.`currency` AS `Currency`, `orders`.`normalized_amount_usd` AS `Normalized_Amount_Usd`, `stores__via__branch_id`.`domain` AS `Branch_Domain`, `orders`.`shipment_type` AS `Shipment_Type`,`Stores`.`deal_growth` AS `Deal_Growth` ,`Stores`.`domain` AS `Stores_Domain`, `Stores`.`template` AS `Stores_Template`, `Stores`.`stage` AS `Stores_Stage`, `Stores`.`country` AS `Stores_Country`, `Stores`.`city` AS `Stores_City` FROM `orders`LEFT JOIN `stores` `Stores` ON `orders`.`store_id` = `Stores`.`id` LEFT JOIN `stores` `stores__via__branch_id` ON `orders`.`branch_id` = `stores__via__branch_id`.`id`        WHERE 'Amount' != 'dumy condition'        {% if from_dttm != None %}	          AND orders.Created_at >= '{{ from_dttm }}' AND orders.Created_at < '{{ to_dttm }}'	      {% endif %}        {%- if (filter_values('Domain') is defined) and filter_values('Domain') -%}            AND            Stores_Domain IN ({{ ""'"" + ""','"".join(filter_values('Domain')) + ""'"" }})        {%- endif -%}        {%- if (filter_values('Country') is defined) and filter_values('Country') -%}            AND            Stores_Country IN ({{ ""'"" + ""','"".join(filter_values('Country')) + ""'"" }})        {%- endif -%}        {%- if (filter_values('Currency') is defined) and filter_values('Currency') -%}            AND            Currency IN ({{ ""'"" + ""','"".join(filter_values('Currency')) + ""'"" }})        {%- endif -%}         {%- if (filter_values('Shipment Type') is defined) and filter_values('Shipment Type') -%}            AND            orders.Shipment_Type IN ({{ ""'"" + ""','"".join(filter_values('Shipment Type')) + ""'"" }})        {%- endif -%}                {%- if (filter_values('Deal Growth') is defined) and filter_values('Deal Growth') -%}            AND            Deal_Growth IN ({{ ""'"" + ""','"".join(filter_values('Deal Growth')) + ""'"" }})        {%- endif -%}        ```*************superset version 1.4.1 i don't see any similar problem to this problem Make sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19268,0,0,9,0,0,srinisubramanian,0,"title:slug is not updated when importing dashboard via API. description:The slug is not set when importing a dashboard#### How to reproduce the bugSet a slug and export a dashboard using the export API.  Import the dashboard using the /import API.  The slug is not set after import### Expected resultsSlug should be set to the value in the json### Actual resultsSlug is not set#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- API superset version 1.4.1- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19264,0,140,64,0,0,zhaoyongjie,1,"title:Native Filter can't work when face NULL value or empty string. description:Native Filter can't work when facing NULL value or an empty string, and this behavior is not consistent with explore page. https://user-images.githubusercontent.com/2016594/159150669-a4cb27cf-9049-4caa-b983-b18ab5d69d1a.mov#### How to reproduce the bug1. make a temporary table with a single text column by database client or SQLLab```SQLcreate table testing_empty_string(  name varchar(255));insert into testing_empty_stringvalues  (null),  (''),  ('foo');```2. create a dataset from above table3. create a chart and dashboard from above dataset4. create a Native Filter from the dashboard 5. got error when select `<NULL>` on dashboard6. got an empty placeholder when select `<empty string>` on dashboard7. got an error when select `<NULL>` on explore### Expected results1. Native filter should work with NULL2. Native filter should show <empty string> when got a empty string3. filter should work with NULL on explore page### Actual resultsNative filter can't work when facing NULL or Empty string### Environment- browser type and version: latest Firefox- superset version:  current master branch(d645579cd)### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19260,0,0,0,0,0,jleute,0,"title:Week-based time grains not working with databricks engine since spark 3.0. description:#### How to reproduce the bug1. Use databricks engine ""Databricks Interactive Cluster"" with Spark 3.0 or larger2. Create Time-series Bar Chart3. Select ""Week"" as Time Grain and run the query4. See the following error:`'*java.lang.IllegalArgumentException:All week-based patterns are unsupported since Spark 3.0, detected: u, Please use the SQL function EXTRACT instead:312:21', `### Environment- browser type and version: not relevant - superset version: docker apache/superset:1.4.1- python version: 3.8.12- node.js version: node:16- any feature flags active: DASHBOARD_CROSS_FILTERS, ENABLE_TEMPLATE_PROCESSING, DASHBOARD_RBAC, VERSIONED_EXPORT### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19253,0,0,0,0,0,wengieeee,0,"title:Python Issue leaks to SQL Lab when querying Clickhouse. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. config database    clickhouse://test:XXXXXXXXXX@127.0.0.1:8123/default2. go to sql_lab3. run a clickhouse sql ![image](https://user-images.githubusercontent.com/16257260/159006975-d3bee7ef-25f9-46ea-bd84-f1b4a69b35f2.png)error log:2022-03-18 20:33:51,425:DEBUG:urllib3.connectionpool:http://180.97.87.196:8070 ""POST /?query_id=77d02bd7-28ad-418f-b23d-6ff575f5e55f&database=default HTTP/1.1"" 200 None2022-03-18 20:33:51,426:DEBUG:superset.stats_logger:[stats_logger] (timing) sqllab.query.time_executing_query | 97.369140625 2022-03-18 20:33:51,428:ERROR:superset.sql_lab:Query 6: <class 'AttributeError'>Traceback (most recent call last):  File ""/Users/test/projects/PycharmProjects/superset/superset/sql_lab.py"", line 248, in execute_sql_statement    db_engine_spec.execute(cursor, sql, async_=True)  File ""/Users/test/projects/PycharmProjects/superset/superset/db_engine_specs/base.py"", line 1098, in execute    raise cls.get_dbapi_mapped_exception(ex)  File ""/Users/test/projects/PycharmProjects/superset/superset/db_engine_specs/base.py"", line 1096, in execute    cursor.execute(query)  File ""/Users/test/sandai/py3env/lib/python3.9/site-packages/clickhouse_sqlalchemy/drivers/http/connector.py"", line 117, in execute    self._process_response(response_gen)  File ""/Users/test/sandai/py3env/lib/python3.9/site-packages/clickhouse_sqlalchemy/drivers/http/connector.py"", line 216, in _process_response    self._columns = next(response, None)  File ""/Users/test/sandai/py3env/lib/python3.9/site-packages/clickhouse_sqlalchemy/drivers/http/transport.py"", line 136, in execute    convs = [_get_type(type_) for type_ in types]  File ""/Users/test/sandai/py3env/lib/python3.9/site-packages/clickhouse_sqlalchemy/drivers/http/transport.py"", line 136, in <listcomp>    convs = [_get_type(type_) for type_ in types]  File ""/Users/test/sandai/py3env/lib/python3.9/site-packages/clickhouse_sqlalchemy/drivers/http/transport.py"", line 81, in _get_type    if type_str.startswith('Decimal'):AttributeError: 'NoneType' object has no attribute 'startswith'2022-03-18 20:33:51,428:DEBUG:superset.sql_lab:Query 6: 'NoneType' object has no attribute 'startswith'2022-03-18 20:33:51,449:WARNING:superset.views.base:[SupersetError(message=""clickhouse error: 'NoneType' object has no attribute 'startswith'"", error_type=<SupersetErrorType.GENERIC_DB_ENGINE_ERROR: 'GENERIC_DB_ENGINE_ERROR'>, level=<ErrorLevel.ERROR: 'error'>, extra={'engine_name': 'ClickHouse', 'issue_codes': [{'code': 1002, 'message': 'Issue 1002 - The database returned an unexpected error.'}]})]### Environment(please complete the following information):- browser type and version: chrom- superset version:  1.4.1- python version: 3.9 3.8- node.js version: 16.9.1### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ Y ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ Y ] I have reproduced the issue with at least the latest released version of superset.- [ Y ] I have checked the issue tracker for the same issue and I haven't found one similar.Others have encountered this question闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟鐑橆殢閺佸棙銇勯敍鍕瘑ps://github.com/apache/superset/issues/15892 闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈惧瘜閺佸﹪鏌熼懡銈団攭s issue was closed闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈鹃檮閸嬧晠鏌ｉ妸銉ㄦ簠 it still occurs in superset 1.4.1 闂?"
19251,0,605,21,0,0,stillya,0,"title:Wrong API definition on /database/available REST in swagger. description:In Superset Swagger API REST for getting available database(/api/v1/database/available/) schema of response look like this:```json[  {    ""available_drivers"": [      ""string""    ],    ""default_driver"": ""string"",    ""engine"": ""string"",    ""name"": ""string"",    ""parameters"": {},    ""preferred"": true,    ""sqlalchemy_uri_placeholder"": ""string""  }]```But actual response is: ```json{    ""databases"": [        {            ""available_drivers"": [                ""string""            ],            ""default_driver"": ""string"",            ""engine"": ""string"",            ""name"": ""string"",            ""parameters"": {},            ""preferred"": true,            ""sqlalchemy_uri_placeholder"": ""string""        }    ]}```
"
19155,0,0,144,0,0,nerdyslacker,0,"title:Tabs got deleted after saving dashboard as copy v1.4. description:I've created a simple dashboard with only 2 tabs, with 1 filter in each. I tried to save it as another copy and the dashboard broke - the tabs got deleted and everything was put in one page. This is a huge problem and it breaks the dashboard with multiple tabs when I ""save as"" another name. I did not have this issue with version 1.3.#### How to reproduce the bug1. Create dashboard with 2 or more tabs 2. Edit dashboard3. Try to save as another copy 4. Tabs are disappeared#### Screenshots1. Original dashboard![image](https://user-images.githubusercontent.com/31778860/158406105-8969010c-e8e3-49fc-8482-fa1847f0f952.png)2. Copy of the same dashboard![image](https://user-images.githubusercontent.com/31778860/158406173-a1455dcb-0dcc-47ad-815f-95340b968fd2.png)### Environment- browser type and version: Brave 1.36.112 (Chromium 99)- superset version: superset 1.4.0 (docker image tag: d29f6614161f3faeced218232d9aa1d0a9422ddb)- python version: python 3.8- any feature flags active:    - ENABLE_TEMPLATE_PROCESSING: ""True""   - DASHBOARD_NATIVE_FILTERS: ""True""   - DASHBOARD_NATIVE_FILTERS_SET: ""True""   - DASHBOARD_RBAC: ""True"" ### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19150,0,0,0,0,0,Jianghaohua,0,"title:ImportError: cannot import name 'soft_unicode' from 'markupsafe' . description:add ""markupsafe=2.0.1"" into setup.py` install_requires=[        ""MarkupSafe==2.0.1"" # add        ""backoff>=1.8.0"",        ""bleach>=3.0.2, <4.0.0"",        ""cachelib>=0.4.1,<0.`
"
19134,1,0,82,0,0,chonyy,0,"title:[Alert] Avoid caching charts when sending as text. description:Hi all, I have set up an alert to send a chart as text. However, the values in the chart, which is the content of the alert, sometimes are cached. It闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?sending the chart value of the previous alert.Is this an expected behavior? Ideally, whenever the alert is triggered, I would like to get the real-time value of the chart. Is there a way to guarantee to get the real-time value for every single alert?After this [PR](https://github.com/apache/superset/pull/18795), I believe we could already bust the cache when alerting the screenshot of the dashboard. I'm looking for a similar feature that will allow the user to bust cache when sending a chart as text when alerting.CC the contributor of the mentioned PR, @hughhhh @betodealmeida . Hope someone could help me look into this. Thanks 婵犵妲呴崑鎾跺緤娴犲鐤い鏍剱閺?
"
19124,1,0,0,0,0,Narendra678,0,"title:Not able to Export Dashboard, . description:Hi Team,I am trying to export dashboard from superset, But one or two reports not importing. Keep on shows processing.![image](https://user-images.githubusercontent.com/88739186/157889335-8280f2b5-e29a-4b83-adb3-2e59c8183c01.png)Regards,Naren
"
19123,1,0,4,0,0,itziarmj,0,"title:Filter chart error when no time column. description:#### How to reproduce the bugCreate a chart type filter with a dataset that has no time column.Uncheck ""date filter"" in data.Time column is empty.When clicking on ""run"", the following error appear:Unexpected errorTime column ""timestamp"" does not exist in dataset### Expected resultsIn previous version, the filter runs without timestamp column### Actual resultsIt returns an error. ### Environment- browser type and version: Chrome Version 99.0.4844.51 (Official Build) (64-bit)Firefox 98.0 (64-bit)- superset version: `superset version` 1.4.1- python version: `python --version` : 3.8.12### Checklist- [ x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x ] I have reproduced the issue with at least the latest released version of superset.- [x ] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19117,1,0,0,0,0,Nithi-1995,0,"title:Module not found: Error: Can't resolve 'mapbox-gl/dist/mapbox-gl.css' in 'C:\Users\Admin\Downloads\LEARNING\SUPER_SET\superset-frontend\plugins\legacy-plugin-chart-map-box\src'. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to '...'2. Click on '....'3. Scroll down to '....'4. See error### Expected resultswhat you expected to happen.### Actual resultswhat actually happens.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19109,1,0,5,0,0,filipposampligo,0,"title:'MSDialect_adodbapi' has no attribute 'dbapi'. description:After connecting Superset to a Trino instance (which in its turn is connected to a remote MongoDB server), I am unable to access the SQL Editor page in Superset SQL Lab.Superset is running from `docker-compose-non-dev.yml` and Trino is running as a separate docker app based on the MongoDB-Trino implementation by [bitsondatadev/trino-getting-started](https://github.com/bitsondatadev/trino-getting-started.git).I have edited requirements-local.txt to include `sqlalchemy-trino`.### Expected resultsI would expect to see the SQL Editor page and be able to query Trino as usual.### Actual resultsI get the following error in the docker-compose logs`superset_app          | Unable to load dialect <class 'sqlalchemy.dialects.mssql.adodbapi.MSDialect_adodbapi'>: type object 'MSDialect_adodbapi' has no attribute 'dbapi'superset_app            | 2022-03-10 18:21:18,084:WARNING:superset.db_engine_specs:Unable to load dialect <class 'sqlalchemy.dialects.mssql.adodbapi.MSDialect_adodbapi'>: type object 'MSDialect_adodbapi' has no attribute 'dbapi'`#### Screenshots<img width=""1680"" alt=""image"" src=""https://user-images.githubusercontent.com/95853439/157730779-a1a60c15-d91c-4614-b8c2-5e5245947a93.png"">### Environment(please complete the following information):- browser type and version: Chromium: 98.0.4758.109 (Official Build) (x86_64)- superset version: `apache/superset:latest`- python version: `3.8.12`- node.js version: `v16`
"
19100,0,11407,15,0,1,maudrid,0,"title:Database error when upgrading from 1.4.1 to master. description:I though to report this so that it could be fixed in the next release.When I upgrade an existing 1.4.1 instance that uses postgreSQL for metadata storage, I get an error and cannot use previously existing dashboards. (sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column dbs.allow_file_upload does not exist)The same error appears in the `supserset init` stage, so I will include the log below/#### How to reproduce the bug1. in my docker-compose file I change from `image: apache/superset:1.4.1` to `image: apache/superset:master`Currently this is the DIGEST:sha256:23094797144b33a717c8d1d950825116bed97c1c4d6342d708b359279a31d83c2. docker-compose down   ->  docker-compose up -d3. docker exec superset-app superset fab create-admin --username user --firstname user --lastname '' --email user@user.user --password pasword4. docker exec superset-app superset db upgrade5. docker exec superset-app superset init### Expected resultsSuperset works as normal### Actual resultsSQL error from the DB and superset dashboards do not work#### Logs```docker exec superset-app superset fab create-admin --username user --firstname user --lastname '' --email user@user.user --password pasword logging was configured successfully 2022-03-10 09:55:37,802:INFO:superset.utils.logging_configurator:logging was configured successfully 2022-03-10 09:55:37,819:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'> ---==== Start loading custom configuration ====--- Loaded your security configuration at [/app/security.py] Loaded your LOCAL configuration at [/app/superset_config.py] Recognized OpenID Authentication. Error! User already exists user /usr/local/lib/python3.8/site-packages/flask_caching/__init__.py:201: UserWarning: Flask-Caching: CACHE_TYPE is set to null, caching is effectively disabled.   warnings.warn(docker exec superset-app superset db upgrade logging was configured successfully 2022-03-10 09:55:46,495:INFO:superset.utils.logging_configurator:logging was configured successfully 2022-03-10 09:55:46,507:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'> /usr/local/lib/python3.8/site-packages/flask_caching/__init__.py:201: UserWarning: Flask-Caching: CACHE_TYPE is set to null, caching is effectively disabled.   warnings.warn( INFO  [alembic.runtime.migration] Context impl PostgresqlImpl. INFO  [alembic.runtime.migration] Will assume transactional DDL. INFO  [alembic.runtime.migration] Running upgrade aea15018d53b -> abe27eaf93db, add_extra_config_column_to_alerts INFO  [alembic.runtime.migration] Running upgrade abe27eaf93db -> 3ba29ecbaac5, Change datatype of type in BaseColumn INFO  [alembic.runtime.migration] Running upgrade 3ba29ecbaac5 -> fe23025b9441, rename_big_viz_total_form_data_fields INFO  [alembic.runtime.migration] Running upgrade fe23025b9441 -> 31bb738bd1d2, move_pivot_table_v2_legacy_order_by_to_timeseries_limit_metric INFO  [alembic.runtime.migration] Running upgrade 31bb738bd1d2 -> bb38f40aa3ff, Add force_screenshot to alerts/reports INFO  [alembic.runtime.migration] Running upgrade bb38f40aa3ff -> c53bae8f08dd, add_saved_query_foreign_key_to_tab_state Revision ID: c53bae8f08dd Revises: bb38f40aa3ff Create Date: 2021-12-15 15:05:21.845777 INFO  [alembic.runtime.migration] Running upgrade c53bae8f08dd -> 5fd49410a97a, Add columns for external management INFO  [alembic.runtime.migration] Running upgrade 5fd49410a97a -> 5afbb1a5849b, add_embedded_dahshoard_table INFO  [alembic.runtime.migration] Running upgrade 5afbb1a5849b -> b8d3a24d9131, New dataset models INFO  [alembic.runtime.migration] Running upgrade b8d3a24d9131 -> b5a422d8e252, fix query and saved_query null schema INFO  [alembic.runtime.migration] Running upgrade b5a422d8e252 -> ab9a9d86e695, deprecate time_range_endpoints INFO  [alembic.runtime.migration] Running upgrade ab9a9d86e695 -> 7293b0ca7944, change_adhoc_filter_b_from_none_to_empty_array ---==== Start loading custom configuration ====--- Loaded your security configuration at [/app/security.py] Loaded your LOCAL configuration at [/app/superset_config.py]docker exec superset-app superset init logging was configured successfully 2022-03-10 09:55:56,873:INFO:superset.utils.logging_configurator:logging was configured successfully 2022-03-10 09:55:56,884:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'> /usr/local/lib/python3.8/site-packages/flask_caching/__init__.py:201: UserWarning: Flask-Caching: CACHE_TYPE is set to null, caching is effectively disabled.   warnings.warn( Syncing role definition 2022-03-10 09:56:02,586:INFO:superset.security.manager:Syncing role definition Syncing Admin perms 2022-03-10 09:56:02,610:INFO:superset.security.manager:Syncing Admin perms Syncing Alpha perms 2022-03-10 09:56:02,852:INFO:superset.security.manager:Syncing Alpha perms Syncing Gamma perms 2022-03-10 09:56:03,073:INFO:superset.security.manager:Syncing Gamma perms Syncing granter perms 2022-03-10 09:56:03,324:INFO:superset.security.manager:Syncing granter perms Syncing sql_lab perms 2022-03-10 09:56:03,564:INFO:superset.security.manager:Syncing sql_lab perms Fetching a set of all perms to lookup which ones are missing 2022-03-10 09:56:03,761:INFO:superset.security.manager:Fetching a set of all perms to lookup which ones are missing Creating missing datasource permissions. 2022-03-10 09:56:03,954:INFO:superset.security.manager:Creating missing datasource permissions. ---==== Start loading custom configuration ====--- Loaded your security configuration at [/app/security.py] Loaded your LOCAL configuration at [/app/superset_config.py] Traceback (most recent call last):   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context     self.dialect.do_execute(   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 608, in do_execute     cursor.execute(statement, parameters) psycopg2.errors.UndefinedColumn: column dbs.allow_file_upload does not exist LINE 1: ...thod, dbs.allow_run_async AS dbs_allow_run_async, dbs.allow_...                                                              ^   The above exception was the direct cause of the following exception:  Traceback (most recent call last):   File ""/usr/local/bin/superset"", line 33, in <module>     sys.exit(load_entry_point('apache-superset', 'console_scripts', 'superset')())   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 829, in __call__     return self.main(*args, **kwargs)   File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 586, in main     return super(FlaskGroup, self).main(*args, **kwargs)   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 782, in main     rv = self.invoke(ctx)   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1259, in invoke     return _process_result(sub_ctx.command.invoke(sub_ctx))   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1066, in invoke     return ctx.invoke(self.callback, **ctx.params)   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 610, in invoke     return callback(*args, **kwargs)   File ""/usr/local/lib/python3.8/site-packages/click/decorators.py"", line 21, in new_func     return f(get_current_context(), *args, **kwargs)   File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 426, in decorator     return __ctx.invoke(f, *args, **kwargs)   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 610, in invoke     return callback(*args, **kwargs)   File ""/usr/local/lib/python3.8/site-packages/click/decorators.py"", line 21, in new_func     return f(get_current_context(), *args, **kwargs)   File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 426, in decorator     return __ctx.invoke(f, *args, **kwargs)   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 610, in invoke     return callback(*args, **kwargs)   File ""/app/superset/cli/main.py"", line 61, in init     security_manager.sync_role_definitions()   File ""/app/superset/security/manager.py"", line 736, in sync_role_definitions     self.create_missing_perms()   File ""/app/superset/security/manager.py"", line 678, in create_missing_perms     merge_pv(""datasource_access"", datasource.get_perm())   File ""/app/superset/connectors/sqla/models.py"", line 633, in get_perm     return f""[{self.database}].[{self.table_name}](id:{self.id})""   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/attributes.py"", line 294, in __get__     return self.impl.get(instance_state(instance), dict_)   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/attributes.py"", line 730, in get     value = self.callable_(state, passive)   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/strategies.py"", line 759, in _load_for_state     return self._emit_lazyload(   File ""<string>"", line 1, in <lambda>   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/strategies.py"", line 847, in _emit_lazyload     q(session)   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/ext/baked.py"", line 615, in _load_on_pk_identity     result = list(bq.for_session(self.session).params(**params))   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/ext/baked.py"", line 444, in __iter__     return q._execute_and_instances(context)   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py"", line 3560, in _execute_and_instances     result = conn.execute(querycontext.statement, self._params)   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1011, in execute     return meth(self, multiparams, params)   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 298, in _execute_on_connection     return connection._execute_clauseelement(self, multiparams, params)   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1124, in _execute_clauseelement     ret = self._execute_context(   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1316, in _execute_context     self._handle_dbapi_exception(   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1510, in _handle_dbapi_exception     util.raise_(   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_     raise exception   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1276, in _execute_context     self.dialect.do_execute(   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 608, in do_execute     cursor.execute(statement, parameters) sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column dbs.allow_file_upload does not exist LINE 1: ...thod, dbs.allow_run_async AS dbs_allow_run_async, dbs.allow_...                                                              ^  [SQL: SELECT dbs.uuid AS dbs_uuid, dbs.created_on AS dbs_created_on, dbs.changed_on AS dbs_changed_on, dbs.id AS dbs_id, dbs.verbose_name AS dbs_verbose_name, dbs.database_name AS dbs_database_name, dbs.sqlalchemy_uri AS dbs_sqlalchemy_uri, dbs.password AS dbs_password, dbs.cache_timeout AS dbs_cache_timeout, dbs.select_as_create_table_as AS dbs_select_as_create_table_as, dbs.expose_in_sqllab AS dbs_expose_in_sqllab, dbs.configuration_method AS dbs_configuration_method, dbs.allow_run_async AS dbs_allow_run_async, dbs.allow_file_upload AS dbs_allow_file_upload, dbs.allow_ctas AS dbs_allow_ctas, dbs.allow_cvas AS dbs_allow_cvas, dbs.allow_dml AS dbs_allow_dml, dbs.force_ctas_schema AS dbs_force_ctas_schema, dbs.allow_multi_schema_metadata_fetch AS dbs_allow_multi_schema_metadata_fetch, dbs.extra AS dbs_extra, dbs.encrypted_extra AS dbs_encrypted_extra, dbs.impersonate_user AS dbs_impersonate_user, dbs.server_cert AS dbs_server_cert, dbs.is_managed_externally AS dbs_is_managed_externally, dbs.external_url AS dbs_external_url, dbs.created_by_fk AS dbs_created_by_fk, dbs.changed_by_fk AS dbs_changed_by_fk  FROM dbs  WHERE dbs.id = %(param_1)s] [parameters: {'param_1': 1}] (Background on this error at: http://sqlalche.me/e/13/f405)```### Environment- browser type and version: Any- superset version: `master`- python version: using the superset docker image- node.js version: using the superset docker image- any feature flags active:FEATURE_FLAGS = {    'ENABLE_TEMPLATE_PROCESSING': True,    'DASHBOARD_RBAC': True,    'DASHBOARD_CROSS_FILTERS': True,    'VERSIONED_EXPORT': True,    'DASHBOARD_NATIVE_FILTERS': True,    'ROW_LEVEL_SECURITY': True,}### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.No this is in master branch. The released version works fine.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19093,1,0,0,0,0,Narendra678,0,"title:Remove 'All' option from Show All,10, 20....200 entries in dashboard.. description:Hi Team,I need to remove All option from Show All,10, 20....200 entries.Reason: As we have lakhs records when select 'All' page is getting stuck.### Expected results![image](https://user-images.githubusercontent.com/88739186/157612819-c47466bd-24d2-4158-908e-b88fc79911c5.png)Appreciate quick response.Regards,Naren
"
19075,1,0,0,0,0,Ankitchandre,0,"title:unable to connect Trino superset after enabling ldap on trino. description:I'm trying to connect my superset to trino. this worked fine, until we had to enable auth in trino and make it available behind a real domain trino.mycompany.com. my connection string looks like this:trino://myuser:mypassword@trino.mycompany.com/catalogError on superset :[SupersetError(message='(builtins.NoneType) None\n(Background on this error at: http://sqlalche.me/e/13/dbapi)', error_type=<SupersetErrorType.GENERIC_DB_ENGINE_ERROR: 'GENERIC_DB_ENGINE_ERROR'>, level=, extra={'engine_name': 'Trino', 'issue_codes': [{'code': 1002, 'message': 'Issue 1002 - The database returned an unexpected error.'}]})]
"
19062,1,0,294,0,0,michael-s-molina,1,"title:The select component is not fetching more pages on scroll after a search has been made. description:#### How to reproduce the bug1. Open the AsyncSelect storybook2. Search for 'Michael'3. Close the Select4. Re-open the Select5. Scroll down to fetch more pages### Expected resultsThe Select fetches the remaining pages.### Actual resultsNo pages are fetched.#### Screenshotshttps://user-images.githubusercontent.com/70410625/157240355-f35e30fa-ae3c-406a-bb87-fef5edc10eeb.mov### Environment- browser type and version: latest Chrome- superset version: master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
19026,0,0,0,0,0,rafalpas,0,"title:Not possible to configure filter scopes in 1.4.1 / existing filter scopes information gets lost when editing Dashboard Properties. description:When dashboard properties are edited using the Dashboard Properties dialog, the information about filter scopes for filter boxes (added in Superset versions prior to 1.4) is removed from JSON Metadata. As a result all filters are applied for all other filters and all charts. This also blocks adding any filter scopes information to a new dashboard in Superset 1.4.1.#### How to reproduce the bug1. Create a dashboard that includes at least one chart and one filter box.2. Open the Dashboard Properties dialog using the ""Edit"" action from dashboard's list.3. Click on ""advanced"" to show the JSON METADATA4. Notice the following section in the content: `""filter_scopes"": {""175"": {""your_filter_name"": {""scope"": [""ROOT_ID""], ""immune"": []}}},` . This section normally allows to configure filter scopes, e.g. adding a chart id in the array under ""immune"" makes this chart immune to that filter.5. Try to do any change (e.g. add the chart id in the array under ""immune""), enter URL SLUG or just click SAVE without any changes6. Reopen the Dashboard Properties panel and examine the JSON METADATA### Expected resultsThe ""filter_scopes"" section in JSON METADATA is as defined by you when clicking ""SAVE""### Actual resultsThe ""filter_scopes"" section is no longer present in JSON METADATA.#### Screenshotsnone added### Environment- browser type and version: Microsoft Edge 98.0.1108.62- superset version: 1.4.1- python version: `python --version`- node.js version: `node -v`- any feature flags active: VERSIONED_EXPORT### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextJust opening Dashboard Properties and clicking SAVE is enough for the ""filter_scopes"" section to disappear. It is no longer possible to configure filter scopes for new dashboards in 1.4.1. It is also not possible to do any changes to dashboard properties for dashboards created in versions prior to 1.4 without losing the filter scopes information.Problem reproduces with DASHBOARD_NATIVE_FILTERS enabled and disabled.
"
19008,0,0,294,0,0,villebro,1,"title:Table name autocomplete broken in SQL Lab. description:Currently table names are not added to autocomplete in SQL Lab#### How to reproduce the bug1. Go to SQL Lab2. Choose the Examples database and related schema (Pubic for Postgres)3. Check a name of a table (""Flights"" should be present)4. Type ""select * from Fli"" in the Editor and notice that ""Flights"" doesn't appear in the dropdown### Expected resultsAll table names should be added to the autocomplete dropdown### Actual resultsNo tables are visible in the autocomplete dropdown#### ScreenshotsIn the database, we see that the table ""Flights"" is present:<img width=""417"" alt=""image"" src=""https://user-images.githubusercontent.com/33317356/156534052-d04dd41f-f8f1-4adc-aa85-93a9b1f67ae4.png""> However, the table isn't available in the autocomplete dropdown:<img width=""1108"" alt=""image"" src=""https://user-images.githubusercontent.com/33317356/156534198-c60f7c62-5289-4d6f-b5cf-013a6dfca074.png"">### Environment(please complete the following information):- browser type and version:- superset version: master- python version: Python 3.8- node.js version: Node 16- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
19000,0,0,40,0,0,jinghua-qa,1,"title:[Native Filter] User can not select <'NULL'> value in single select mode. description:User can not select <'NULL'> value in single select mode#### How to reproduce the buggo to FCC survey dashboard1. create value filter for bootcamp name2. unselect ' Can select multiple values'3. Select <'NULL'> in the bootcamp name### Expected resultsAble to select <'NULL'> in single select mode### Actual resultsNot able to select <'NULL'> in single select mode, <'NULL'> can be selected in multiple select mode#### Screenshotshttps://user-images.githubusercontent.com/81597121/156431962-140a67a5-caeb-4b5d-bfad-854ffbfc6820.movIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: latest master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18995,1,0,10,0,0,loongWoong,0,"title:create table charts from elasticsearch. description:#### How to reproduce the bug1. create a new chart choose dataset elasticsearch data""filebeat-6.8.3-2022.03.02""---elasticsearch version:7.10.12. check ""server pagination"" option selected4. click ""run"" to view the table5. click page 2 is error### Expected resultsthe table show next page### Actual resultstherre is error code put out #### ScreenshotsUnexpected errorError: Error (parsing_exception): {'error': {'root_cause': [{'type': 'parsing_exception', 'reason': ""line 4:1: mismatched input 'OFFSET' expecting <EOF>""}], 'type': 'parsing_exception', 'reason': ""line 4:1: mismatched input 'OFFSET' expecting <EOF>"", 'caused_by': {'type': 'input_mismatch_exception', 'reason': None}}, 'status': 400}### Environment(please complete the following information):- browser type and version: Firefox 79- superset version: `1.4.1`- python version: 3.7- elasticsearch version:7.10.1
"
18980,0,0,5,0,0,codek,0,"title:Export Databases from the CLI does not work. description:As you can see here, you cannot export the dashboards via the ""superset export-dashboards"" commandhttps://stackoverflow.com/questions/69641720/superset-exporting-and-importing-the-dashboards-using-cli-for-versioning-controI have also reproduced this, in a vanilla apache/superset image.I do have the examples deployed, i wonder if it's something in the examples that is breaking it?#### How to reproduce the bug1. bring up the docker superset image2. connect to docker3. execute superset export-databases### Expected resultsa file is generated (?) <-- the doco is unclear whether this is a zip or a json.### Actual resultsit explodes#### Screenshotssee stack trace in stackoverflow link### Environment(please complete the following information):Superset 0.0.0devPython 3.8.12### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.root@a0da58753de3:/app# superset export-dashboards > dashboards.yamllogging was configured successfully2022-03-01 10:02:59,282:INFO:superset.utils.logging_configurator:logging was configured successfully2022-03-01 10:02:59,309:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>/usr/local/lib/python3.8/site-packages/flask_caching/__init__.py:201: UserWarning: Flask-Caching: CACHE_TYPE is set to null, caching is effectively disabled.  warnings.warn(Starting export2022-03-01 10:03:06,558:INFO:superset.utils.dashboard_import_export:Starting exportTraceback (most recent call last):  File ""/usr/local/bin/superset"", line 33, in <module>    sys.exit(load_entry_point('apache-superset', 'console_scripts', 'superset')())  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 829, in __call__    return self.main(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 586, in main    return super(FlaskGroup, self).main(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 782, in main    rv = self.invoke(ctx)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1259, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1066, in invoke    return ctx.invoke(self.callback, **ctx.params)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 610, in invoke    return callback(*args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/decorators.py"", line 21, in new_func    return f(get_current_context(), *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 426, in decorator    return __ctx.invoke(f, *args, **kwargs)  File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 610, in invoke    return callback(*args, **kwargs)  File ""/app/superset/cli/importexport.py"", line 207, in export_dashboards    data = dashboard_import_export.export_dashboards(db.session)  File ""/app/superset/utils/dashboard_import_export.py"", line 33, in export_dashboards    data = Dashboard.export_dashboards(dashboard_ids)  File ""/app/superset/models/dashboard.py"", line 391, in export_dashboards    json_metadata = json.loads(dashboard.json_metadata)  File ""/usr/local/lib/python3.8/json/__init__.py"", line 341, in loads    raise TypeError(f'the JSON object must be str, bytes or bytearray, 'TypeError: the JSON object must be str, bytes or bytearray, not NoneType- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18961,1,338,0,0,0,parker-pu,0,"title:Is Microsoft SQL server supported as the metadata engine. description:#### Error executing ""superset db upgrade""![image](https://user-images.githubusercontent.com/46392095/155974278-bdf71491-583c-4de0-b6ad-5a234dc39d14.png)```sqlalchemy.exc.ProgrammingError: (pymssql._pymssql.ProgrammingError) (208, b""Invalid object name 'alembic_version'.DB-Lib error message 20018, severity 16:\nGeneral SQL Server error: Check messages from the SQL Server\n"")[SQL: UPDATE alembic_version SET version_num='b4456560d4f3' WHERE alembic_version.version_num = 'bb51420eaf83']```
"
18949,0,0,87,0,1,cccs-Dustin,0,"title:The SQL Lab Add Query Buttons Do Not Name New Queries Properly. description:Within the SQL Editor section of SQL Lab, when you select the 闂?闂?icon beside the current tab to create a new query, the name of the query gets increased incrementally (see the image below) [except there is consistently a duplicate name for the first two].![plus button](https://user-images.githubusercontent.com/96579982/155739797-11b0e6cf-fd9f-4b31-ba1f-2b77c87002f9.PNG)However, if you select the 闂?闂?icon on the top right of the web page beside the settings drop down and select 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜鐎电娀鏌曢弽褑鎳€ query闂? the names of the new queries do not increase incrementally. They are all just named ""Untitled Query 2"" (see the images below).![SQL query button](https://user-images.githubusercontent.com/96579982/155739987-1d8b472d-118f-4d1e-8717-8bfe937cc9d9.PNG)![After SQL query button](https://user-images.githubusercontent.com/96579982/155739999-297b9ccd-3ed4-4842-8fd2-a0ba6a24e825.PNG)In the image above, the query tab in the far right was created using the ""SQL query"" button under the 闂?闂?icon drop down on the top right of the page. As you can see, the query name was not increased incrementally. #### How to reproduce the bug1. Go to the SQL Editor page by selecting it from the main menu under the ""SQL Lab"" drop down.2. You can immediately notice one of the bugs that occurs, the first untitled query will always be called ""Untitled Query 2"", never ""Untitled Query 1"".3. Click on the ""+"" button next to the list of query tabs, it should properly increment the query tab names.4. Select the 闂?闂?icon on the top right of the web page beside the settings drop down, and then click ""SQL query""5. You will notice that the name of the newly created query is ""Untitled Query 2"". No matter how many times you complete step 4, it will never increment the new query tab names.### Expected resultsWhen either the ""+"" button next to the query tabs or the ""SQL query"" button from the drop down is selected, they should both increment the name of the untitled query properly. ### Actual resultsWhen the ""SQL query"" button from the drop down is selected, the newly created query tabs are always named ""Untitled Query 2"". Also, the way the code is currently implemented, there will never be an ""Untitled Query 1"".#### ScreenshotsPlease see the main summary for screenshots### Environment- operating system name and version: Ubuntu 20.04- browser type and version: Google Chrome (Version 97.0.4692.71)- superset version: Superset 1.4- python version: Python 3.8.12- node.js version: Node v14.16.1- any feature flags active: N/A### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAlso, since discovering this bug, I have created a fix for it on my local fork. I will create a corresponding PR that fixes this bug (and link it to this issue).- https://github.com/apache/superset/pull/18951
"
18943,1,0,0,0,0,pm20202,0,"title:DB engine Error while performing custom viz plugin in apache superset. description:A clear and concise description of what the bug is.I am trying to install Superset for building custom visualization using the guide at:https://superset.apache.org/docs/contributing/creating-viz-pluginsPlease note that I am attempting it on Ubuntu 20.04 VMs behind a proxy. And I am running superset on http://localhost:9000/(in dev mode)After following all the steps successfully when I run it on 9000 port i am able to see Hello World chart but when I am trying to use this chart on dataset it shows me this error:**DB engine ErrorNo module named 'superset.common.query_context_factory'This may be triggered by:Issue 1011 - Superset encountered an unexpected error.**#### How to reproduce the bug1. Go to '...'2. Click on '....'3. Scroll down to '....'4. See error### Expected resultsHello World chart working on datasets.### Actual resultsAfter able to see Hello World plugin chart when trying to use this chart on dataset showing this error.DB engine ErrorNo module named 'superset.common.query_context_factory'This may be triggered by:Issue 1011 - Superset encountered an unexpected error.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):OS: Ubuntu Server 20.04Python on VM: 3.8.10### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextI have checked issue code 1011 given in apache superset documentation but not able to find my mistake where i am going wrong.
"
18933,0,0,0,0,0,kachely,0,"title:warm up cache does not work. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Start celery2. Start beat3. Start flask4. There is a request from cache_warmup, but data is not be cached.### Expected resultsrequest will be send by this order:   /explore/xxx   -> /explore_json/xxx   or /api/v1/data/xxx### Actual resultsrequest will be sent by this order:  /explore/xxx -> break.#### ScreenshotsI actually setup a cookie in the request to login in with a warmup user. If I do not add this cookie, it will be redirect to login page.![image](https://user-images.githubusercontent.com/20835886/155558889-a2422645-c55c-4dbb-a435-a6f33de1a812.png)here is the code I used in warm_up### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [Y ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [Y ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18919,1,0,0,0,0,aakanshajecrc,0,"title:Registration is  not working in superset (Authentication:Database). description:A clear and concise description of what the bug is.I am trying to do authentiction(database) in superset using the guide at: https://flask-appbuilder.readthedocs.io/en/latest/security.htmlPlease note that I am attempting it on Ubuntu 20.04 VMs behind a proxy. And I am running superset on http://localhost:9000/(in dev mode)  #### How to reproduce the bug1 Clone Superset repository2 cd superset3 docker-compose up4 in another terminal(cd superset/superset-frontend)5 npm run dev-serverwhat you expected to happen.Login Successfully.what actually happens.register is working.but after registration(save)i am getting this type of error:{""errors"": [{""message"": ""<urlopen error [Errno -3] Temporary failure in name resolution>"", ""error_type"": ""GENERIC_BACKEND_ERROR"", ""level"": ""error"", ""extra"": {""issue_codes"": [{""code"": 1011, ""message"": ""Issue 1011 - Superset encountered an unexpected error.""}]}}]}ScreenshotsIf applicable, add screenshots to help explain your problem.### EnvironmentOS: Ubuntu Server 20.04Python on VM: 3.8.10### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18918,1,0,0,0,0,aakanshajecrc,0,"title:With superset installed from git clone unable to find the site-packages?. description:I have superset installed from a git clone.All seems to be working ok but I don't have the site-packages. For example File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"" is missingI have been looking around the official documentation but I cannot  find how.
"
18917,1,0,0,0,0,aakanshajecrc,0,"title:Issue when Configuring superset (config.py) with LDAP. description:A clear and concise description of what the bug is.I am trying to do authentication:LDAP in superset using the guide at: https://flask-appbuilder.readthedocs.io/en/latest/security.htmlPlease note that I am attempting it on Ubuntu 20.04 VMs behind a proxy. And I am running superset on http://localhost:9000/(in dev mode)After following all the steps successfully when I run it on 9000 portI got this error: Invalid login. Please try again#### How to reproduce the bug1 Clone Superset repository2 cd superset3 docker-compose up4 in another terminal(cd superset/superset-frontend)5 npm run dev-server### Expected resultsLogin Successfully.### Actual resultsInvalid login. Please try againmodify config.pyfrom flask_appbuilder.security.manager import AUTH_LDAPAUTH_ROLE_ADMIN = 'Admin'AUTH_USER_REGISTRATION = TrueAUTH_USER_REGISTRATION_ROLE = ""Public""AUTH_TYPE = 2AUTH_LDAP_SERVER = ""ldap://ldapserver.new""AUTH_LDAP_USE_TLS = FalseAUTH_LDAP_SEARCH = ""cn=rrscw,ou=users,dc=ldapserver,dc=new""AUTH_LDAP_UID_FIELD = ""uid""AUTH_LDAP_BIND_USER = ""uid=rrscw,ou=users,dc=ldapserver,dc=new""AUTH_LDAP_BIND_PASSWORD = ""rrscw""#### ScreenshotsIf applicable, add screenshots to help explain your problem.### EnvironmentOS: Ubuntu Server 20.04Python on VM: 3.8.10### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18912,0,0,0,0,0,pm20202,0,"title:Module not found Error Building custom viz plugins in superset. description:A clear and concise description of what the bug is.I am trying to install Superset for building custom visualization using the guide at: https://superset.apache.org/docs/installation/building-custom-viz-plugins/Please note that I am attempting it on Ubuntu 20.04 VMs behind a proxy. And I am running superset on http://localhost:9000/(in dev mode)However, for tinkering with custom visualizations, I need to go https://superset.apache.org/docs/installation/building-custom-viz-plugins/#add-your-plugin-to-superset-with-npm-link. After following all the steps successfully when I run it on 9000 portI got this error. _""Module not found: Error: Can't resolve '@superset-ui/plugin-chart-hello-world' in '/home/rrscw/superset/superset-frontend/src/visualizations/presets''_#### How to reproduce the bug### Expected resultshello world chart plugin visible in superset on port 9000 in dev mode.### Actual resultshttps://superset.apache.org/docs/installation/building-custom-viz-plugins/#add-your-plugin-to-superset-with-npm-linkAfter adding package in package.json using above link and successfully doing changes in MainPreset.js file I got this error: ERROR in ./src/visualizations/presets/MainPreset.js 40:0-74Module not found: Error: Can't resolve '@superset-ui/plugin-chart-hello-world' in '/home/rrscw/superset/superset-frontend/src/visualizations/presets'#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):OS: Ubuntu Server 20.04Python on VM: 3.8.10### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18888,1,0,38,0,0,dat-linux,0,"title:Superset install (pip) fails because of a broken dependency (Linux/Ubuntu). description:#### How to reproduce the bugpython3 -m pip install apache-supersetsuperset db upgradeexport FLASK_APP=supersetsuperset fab create-adminsuperset load_examples**ImportError: cannot import name 'soft_unicode' from 'markupsafe'**It seems latest **markupsafe** pkg broke backwards compatibility by removing the **soft_unicode** module.
"
18887,0,0,228,0,0,jukie,0,"title:Helm repo not found. description:A clear and concise description of what the bug is.#### How to reproduce the bug`$ helm repo add superset https://apache.github.io/superset`Produces a 404 error:`Error: looks like ""https://apache.github.io/superset"" is not a valid chart repository or cannot be reached: failed to fetch https://apache.github.io/superset/index.yaml : 404 Not Found`### Expected resultsRepo should exist, following these docs: https://superset.apache.org/docs/installation/running-on-kubernetes/### Actual resultsRepo and website appears emptyLikely culprit: https://github.com/apache/superset/commit/84f7d6f9005b25146ea26ce100d479a2e2a9f2b9 @srinify
"
18881,1,0,0,0,0,testejaneiro,0,"title:CSS does not working when I open the dashboard. description:A clear and concise description of what the bug is.#### How to reproduce the bug1.Go to 'Any dashboard'2.Click on 'Edit dashboard > Edit CSS'3.Save CSS template4.Refresh browser5.See error### Expected resultsI expected that opens the CSS that i choose ### Environment(please complete the following information):superset version: 0.38.0python version: based on superset version 0.38.0node.js version: based on superset version 0.38.0### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I have found one similar. but does not working - I need more details#10102### Additional contextAdd any other context about the problem here.
"
18875,1,0,13,0,0,virtualarchitectures,0,"title:Documentation - The Superset Documentation Pages are not Scrolling Vertically to the end of the page. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to https://superset.apache.org/docs/api2. Scroll down the page.3. You will see that the page will not scroll to the end. This applies to multiple pages in the documentation.Pressing PgDown on keyboard or using documentation sidebar navigation also fails.### Expected resultsThe user should be able to scroll through the full page of documentation to the end.### Actual resultsThe screen won't scroll vertically below the text that was visible when the page loaded. The visible screen bounces back up to the beginning of the document.  #### ScreenshotsThis is as far as the page scrolls.![image](https://user-images.githubusercontent.com/10799911/155323085-47814de8-e40f-41fe-a965-ccd4c8a1a305.png)### EnvironmentThis has been tested in Chrome and Firefox on Windows 10. 
"
18871,0,0,20,1,0,yeachan153,0,"title:superset sqllab and charts complain about pandas timestamp conversion when the dates exceed pandas timestamp bounds. description:Similar to [13661](https://github.com/apache/superset/issues/13661), [18596](https://github.com/apache/superset/issues/18596), [16487](https://github.com/apache/superset/issues/16487) timestamps older than `1677-09-22 00:12:43.145225` and newer than `2262-04-11 23:47:16.854775807` cannot be converted into pandas timestamp.By the same logic, charts which create a `DTTM_ALIAS` column in the backend query also cannot contain dates older than the range mentioned above, and trigger the same failure. They are coerced as NaNs, so that the data for dates within the range pandas supports can at least be shown without triggering the same error.#### How to reproduce the bug#### Sqllab1. Go to 'Sql Lab'2. Click on 'Sql Editor'3. Try `select TIMESTAMP '2263-02-02 00:00:00'` (this won't work)4. Try `select TIMESTAMP '2262-02-02 00:00:00'` (this will work since it's inside the range pandas can support)#### Charts1. Go to 'Charts'2. Select time series chart3. In the time column, add the date column which has dates outside the ranges mentioned above4. Fill in whatever metrics you want to visualise### Expected resultsReturns the result correctly.### Actual results#### Sqllab:`Casting from timestamp[us] to timestamp[ns] would result in out of bounds timestamp: 9248947200000000`#### Charts:`Out of bounds nanosecond timestamp: 9999-01-01 00:00:00`### Environment- browser type and version: `chrome`- superset version: `latest & 1.4.1`- python version: `3.8.12`- postgres version: `13.4`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.There are some similar issues, but reviewer mentioned to open a new issue as the PR for the issue was already closed: #14006
"
18869,1,445,2,0,0,Z0ltrix,0,"title:Drill Time Range Filter not usable. description:we have a problem with our superset -> drill connection with time range filters.When we filter a dashboard by time range (last week, month, etc.) i get an ```SYSTEM ERROR: ClassCastException: org.apache.drill.exec.expr.holders.NullableTimeStampHolder cannot be cast to org.apache.drill.exec.expr.holders.TimeStampHolder```from drill.#### How to reproduce the bug1. Create a Dataset based on Drill2. Create a Filter Box3. Create a Dashboard4. Make sure everything works 5. Aktivate a Time Range Filter on the Filter Box6. Everything fails with the error in Drill### Expected resultsSuperset should send the following filter:```WHERE `startTime` >= TIMESTAMP '2022-02-14 00:00:00.000000'  AND `startTime` < TIMESTAMP '2022-02-21 00:00:00.000000'ORDER BY `startTime` DESC```### Actual resultsSuperset sends the following to drill:```WHERE `startTime` >= '2022-02-14 00:00:00.000000'  AND `startTime` < '2022-02-21 00:00:00.000000'ORDER BY `startTime` DESC```#### Screenshots![image](https://user-images.githubusercontent.com/14264280/155306427-8cd7c818-1009-41b7-92fc-c087ee9d0c9d.png)![image](https://user-images.githubusercontent.com/14264280/155306488-1ca61a5f-95c6-45e8-9bbf-288d8fc92ae8.png)### Environment(please complete the following information):- browser type and version: Chrome Version 98.0.4758.102- superset version: 1.3.0- python version: 3.8.0### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.- [x] I have discussed the question on dev mailing list### Additional contextAdd any other context about the problem here.
"
18862,1,0,0,0,0,allenzhg,0,"title:charts VISUALIZATION TYPE select Time-series Line Chart dashboard view chart in explore have issue. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to 'charts '2. Click on 'VISUALIZATION TYPE to ""Time-series Line Chart""' 3. Scroll down to 'save'4. Go to 'dashboards -> a dashboard'5. select ""view chart in explore""6. See error### Expected resultswhat you expected to happen.### Actual resultswhat actually happens.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version: chrome 闂傚倸鍊烽懗鍓佸垝椤栫偑鈧啴宕ㄧ€涙ê浜辨繝鐢靛Т閸嬪﹪鎳?96.0.4664.110闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈鹃檮閸嬪鈹戦悩鍙夌ォ闁轰礁妫欑换婵囩節閸屾碍鐏撻梺鎼炲€栧ú鐔兼偂椤愶箑鐐婇柕濠忓椤︺儱顪冮妶蹇曞埌闁靛牊鎮傚濠氭晸閻樻煡鍞跺銈嗗姂閸ㄥ綊鍩涢弴鐘电＝?闂?4 濠电姷鏁搁崑鐘诲箵椤忓棗绶ら柣锝呯灱閻瑩鏌涢弴銊ュ箺妞? superset version: `1.4.1`- python version: `3.8.12`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18859,1,353,0,0,0,fmaritato,0,"title:Upgrading to 1.4.1 PREVIOUS_SECRET_KEY UnicodeDecodeError. description:I am upgrading an existing superset 1.3.2 to 1.4.1 . I did not previously have a SECRET_KEY defined. In reading the Updating.md file it says to set PREVIOUS_SECRET_KEY but if I didnt have one set previously, what do I set this to?I tried PREVIOUS_SECRET_KEY = """" and ran `superset re-encrypt-secrets` but I get an error:```superset.utils.encrypt:Collecting info for re encryptionTraceback (most recent call last):  File ""/usr/local/lib/python3.8/site-packages/sqlalchemy_utils/types/encrypted/encrypted_type.py"", line 128, in decrypt    decrypted = decrypted.decode('utf-8')UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb7 in position 1: invalid start byte```I'm using a postgres database that has data in it that I can't lose, so I'm stuck here. Any help would be appreciated.Is there a specific table/row that I can manually delete to get past this?### EnvironmentI'm using the apache/superset:1.4.1 docker image### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ x ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ x ] I have reproduced the issue with at least the latest released version of superset.- [ x ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18858,1,0,0,0,0,zuzana-vej,0,"title:[Explore] Iterating between chart types in results in broken charts due to unnecessary group by parameters passed. description:Iterating between chart types in explore view results in broken charts due to unnecessary parameters passed to new charts. For example in this case, the group by gets added into the new chart type query, even though the new chart type don't have group by feature, making it basically broken, **preventing users from iterating between chart types - they would have to start creation of new chart from the scratch**. #### How to reproduce the bug1. In Explore create time series line chart, include group by parameters2. Switch to Big number with trendline chart3. Add the metric as necessary4. Click on See SQL Query and you will see it added the group by parameter from the time series line chart, which however doesn't apply to the new chart type### Expected resultsDo not transfer parameter which do not make sense in new chart type### Actual resultsWrongly transferred the group-by parameter#### ScreenshotsStep 1: create time series line chart with a group by parameter<img width=""983"" alt=""Screen Shot 2022-02-22 at 5 11 00 PM"" src=""https://user-images.githubusercontent.com/61221714/155241630-779fde8b-a7a1-4bfa-a37e-b4972d30dcaa.png"">Step 2: Change to big number with trendline<img width=""267"" alt=""Screen Shot 2022-02-22 at 5 12 26 PM"" src=""https://user-images.githubusercontent.com/61221714/155241627-a45c6b44-23c7-4166-b2f0-47007981f647.png"">Step 3: if you click on view query you see the issue it added the group by from previous chart, even though it's not an option to configure on the trendline chart<img width=""983"" alt=""Screen Shot 2022-02-22 at 5 12 48 PM"" src=""https://user-images.githubusercontent.com/61221714/155241620-e7e75ec0-19a7-4f6a-90fe-9abe7aad2eca.png"">### Environment(please complete the following information):- browser type and version: Chrome- superset version: `superset version` latest master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextIssue in latest master version (from 02/17/2022)
"
18841,1,0,2,0,0,ljclour,0,"title:[issue][question]: sqllab errored in the new Superset,but work well in V1.0.1. description:My org want to use RLS so we update a new version,but also keep the old one.The new one use the same config and setting from V1.0.1,but somthing wrong ocurr.In the new one,we can connect the database (DB2),using the chart and dashboard that created in the V1.0.1.While want to write a new sql in sqllab there is an error like the screenshot below.## Screenshots in New Version error sqllab in new version![image](https://user-images.githubusercontent.com/45123712/155058084-e42d21ae-e21e-4560-9b3f-c55e9e0453e6.png)but using chat(explore the dataset) and dashboard is ok ,but also raise message,![image](https://user-images.githubusercontent.com/45123712/155058249-5f2e49a8-9039-422e-9f5c-39708a9bbbb6.png)![image](https://user-images.githubusercontent.com/45123712/155058600-7f80d216-e3b3-47f6-b302-b6b1bf6e9575.png) ### Screenshots in Version V1.0.1sqllab work well and dashboard do not raised message.![image](https://user-images.githubusercontent.com/45123712/155058861-6a3c2f36-bef4-4aae-af15-7e81156e5666.png)
"
18836,1,0,0,0,0,jacobcroope,0,"title:Charts: Custom Calculated Percentage Metrics not behaving as expected in Tables Chart. description:We are interested in calculating a fair share metric which requires dividing two percentages within a table. The percentage metrics correctly calculate a % of what is displayed in a table dynamically with filters which is critical to our application. Here is a screenshot of the type of visualization I am trying to make. I would expect the value to be an index around 1. For Wii Sports with 20.38% of North American Market and 22.39% of Global Market the value should be 91%![image](https://user-images.githubusercontent.com/1770898/154991299-0c189ced-9c83-4f38-9bc1-5306bb1b4072.png)The SQL statement is dividing them before calculating percentages.![image](https://user-images.githubusercontent.com/1770898/154992363-3875c941-da87-41f9-a621-38c7de62732d.png)In PowerBi, Tableu, and Excel there is a way to accomplish this. Is there a way to do this in Superset I am unaware of or is this something that needs to be added to the visualization?Other operations don't provide the expected results either. ![image](https://user-images.githubusercontent.com/1770898/154993162-606a1567-cd41-4470-be64-4d35628d85f7.png)### EnvironmentSuperset - Current as of today. ### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18792,1,0,0,0,0,Narendra678,0,"title:Change language to spanish. description:Hi Team,Can i change language to spanish?![image](https://user-images.githubusercontent.com/88739186/154542898-1db683c1-e440-4363-ba83-e963ff18ee35.png)Regards,Naren
"
18787,0,0,1,0,1,saurabh3091,0,"title:Stop button for queries doesn't work in SQL Lab.. description:The issue concerns hive/spark-thriftserver(maybe also presto but not tested) as the processing engine.When a user runs a query on SQL Lab and later for any reason wants to stop it, it just stops on the frontend as solved [here](https://github.com/apache/superset/pull/4301/files).The query on the processing engines mentioned above still runs.[This](https://github.com/apache/superset/pull/15403) PR aimed to solve the issue for other DBs but not hive. After it [this](https://github.com/apache/superset/pull/15878) PR was added to fix it but it still doesn't worrk.#### How to reproduce the bug1. Run any query in SQL Lab with `hive/spark-thriftserver` as backend processing engine.2. Press `STOP` button on the UI.3. Check the query engine, the query will still be running. You will still get the results on front end when the query finishes.### Expected resultsThe query should be killed on the query processing engine.### Actual resultsQuery keeps running on the processing engine. You will still get the results on the front end when the query finishes.### Environment- browser type and version: `Chrome/Firefox`- superset version: `latest`- python version: `3.8`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18785,1,1399,0,0,0,aryeh98,0,"title:cannot view Dashboards or Charts After Overriding SECRET_KEY with new value.. description:After updating my SECRET_KEY value and changing it from its default value,When I try to navigate to see the a dashboard or a chart,I get an error. It seems like superset isnt fetching any of the data#### How to reproduce the bug1)Update SECRET_KEY value2) Run superset in DEV mode### Expected resultsSuperset will fetch all the charts and dashboards, and Once I click on one of the dashboards or charts ,It will route me to them### Actual resultsWhen I click on a dashboard, it routes me to the dashboard page but it just shows an error message: ***Unexpected error***When I click on a chart it takes me to a blank page with an error message:```{""errors"": [{""message"": ""(sqlite3.OperationalError) no such column: slices.is_managed_externally\n[SQL: SELECT slices.uuid AS slices_uuid, slices.created_on AS slices_created_on, slices.changed_on AS slices_changed_on, slices.id AS slices_id, slices.slice_name AS slices_slice_name, slices.datasource_id AS slices_datasource_id, slices.datasource_type AS slices_datasource_type, slices.datasource_name AS slices_datasource_name, slices.viz_type AS slices_viz_type, slices.params AS slices_params, slices.query_context AS slices_query_context, slices.description AS slices_description, slices.cache_timeout AS slices_cache_timeout, slices.perm AS slices_perm, slices.schema_perm AS slices_schema_perm, slices.last_saved_at AS slices_last_saved_at, slices.last_saved_by_fk AS slices_last_saved_by_fk, slices.certified_by AS slices_certified_by, slices.certification_details AS slices_certification_details, slices.is_managed_externally AS slices_is_managed_externally, slices.external_url AS slices_external_url, slices.created_by_fk AS slices_created_by_fk, slices.changed_by_fk AS slices_changed_by_fk \nFROM slices \nWHERE slices.id = ?]\n[parameters: (130,)]\n(Background on this error at: http://sqlalche.me/e/13/e3q8)"", ""error_type"": ""GENERIC_BACKEND_ERROR"", ""level"": ""error"", ""extra"": {""issue_codes"": [{""code"": 1011, ""message"": ""Issue 1011 - Superset encountered an unexpected error.""}]}}]}```#### Screenshots![superset-error-1](https://user-images.githubusercontent.com/73904529/154503168-15ac250b-60bd-4615-a47f-1fb35928c9f6.png)![superset-error-2](https://user-images.githubusercontent.com/73904529/154503199-ef6952de-3816-4621-ab6c-69ece2019d8e.png)### Environment(please complete the following information):- browser type and version:- superset version: `Superset 0.0.0dev`- python version: `Python 3.8.10`- node.js version: `v16.13.1`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18774,0,0,89,1,0,alexamy,0,"title:'Total' contribution mode for time series chart doesnt work. description:When using 'Total' from 'contribution mode' there is no data.#### How to reproduce the bug1. Create new time series chart 2. Add metrics / group by clause3. Set 'contribution mode' to 'total'4. See no data### Expected resultsExpect to see accumulated data chart.### Actual resultsNo data presented on the chart.#### Screenshots![image](https://user-images.githubusercontent.com/596195/154384939-5d48f851-153b-4543-b844-9c9c09fbfe57.png)Relates to #11792, I've tried to repeat steps in [this video](https://github.com/apache/superset/issues/11792#issuecomment-800051008), and got different results. [My attempt](https://user-images.githubusercontent.com/596195/154355807-1ca34b3e-455d-4a0f-aff9-18b28aeebba0.mp4).### Environment- browser version: Google Chrome 98.0.4758.102 I'm using superset in container from this docker image: `docker pull apache/superset:993278d8ad2d9be90c5484e3cfe61936c22b850d`These commands were runned in the container:- superset version: Superset 0.0.0dev- python version: Python 3.8.12- node.js version: (no executable found in $PATH in container)- any feature flags active: PREVENT_UNSAFE_DB_CONNECTIONS = False### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18757,1,0,0,0,0,shashi5678,0,"title:on successfull redirection from keycloak to superset ,user is not getting auto logged in. description:[](https://stackoverflow.com/posts/71147610/timeline)I tried these steps but on successfull redirection on superset from keycloak , The user is not getting auto logged inhttp://localhost:8088/login/#session_state=19371d8f-1bd6-41cb-840f-2b11ba477a30&code=63c8f86f-146f-41cd-a2b0-8fb70872b70b.19371d8f-1bd6-41cb-840f-2b11ba477a30.c83b9a3c-f556-446c-99ca-fb56cad1c7d2user exist in both keucloak and superset
"
18730,1,0,0,0,0,pm19035,0,"title:Error code ELIFECYCLE while installing Superset behind proxy. description:A clear and concise description of what the bug is.I am trying to install Superset for building custom visualization using the guide at: https://superset.apache.org/docs/installation/building-custom-viz-plugins/Please note that I am attempting it on Ubuntu 20.04 VMs behind a proxy. I am able to install Superset properly in python venv using the guide available at https://superset.apache.org/docs/installation/installing-superset-from-scratch/However, for tinkering with custom visualizations, I need to go the  npm run dev-server way which is causing me issues as it gives me ""npm ERR! code ELIFECYCLEnpm ERR! errno 2"".#### How to reproduce the bugcd superset/superset-frontendnpm installnpm run dev-server### Expected resultsSuccessful installation of Apache Superset### Actual resultsgetting stuck at the npm run dev-server command while the docker-compose up is merrily running its loop.10% building 0/1 entries 0/0 dependencies 0/0 modules[webpack-cli] /home/rrscw/superset/superset-frontend/node_module s/webpack-dev-server/lib/servers/WebsocketServer.js:10static heartbeatInterval = 1000;^SyntaxError: Unexpected token =at new Script (vm.js:83:7)at NativeCompileCache._moduleCompile (/home/rrscw/superset/superset-frontend/node_modules/v8-compile-cache/v8-com pile-cache.js:240:18)at Module._compile (/home/rrscw/superset/superset-frontend/node_modules/v8-compile-cache/v8-compile-cache.js:184: 36)at Object.Module._extensions..js (internal/modules/cjs/loader.js:789:10)at Module.load (internal/modules/cjs/loader.js:653:32)at tryModuleLoad (internal/modules/cjs/loader.js:593:12)at Function.Module._load (internal/modules/cjs/loader.js:585:3)at Module.require (internal/modules/cjs/loader.js:692:17)at require (/home/rrscw/superset/superset-frontend/node_modules/v8-compile-cache/v8-compile-cache.js:159:20)at Server.getServerTransport (/home/rrscw/superset/superset-frontend/node_modules/webpack-dev-server/lib/Server.j s:1009:28)npm ERR! code ELIFECYCLEnpm ERR! errno 2npm ERR! [superset@0.0.0-dev](mailto:superset@0.0.0-dev) dev-server: cross-env NODE_ENV=development BABEL_ENV=development node --max_old_space_si ze=4096 ./node_modules/webpack-dev-server/bin/webpack-dev-server.js --mode=developmentnpm ERR! Exit status 2npm ERR!npm ERR! Failed at the [superset@0.0.0-dev](mailto:superset@0.0.0-dev) dev-server script.npm ERR! This is probably not a problem with npm. There is likely additional logging output above.npm ERR! A complete log of this run can be found in:npm ERR! /root/.npm/_logs/2022-02-13T06_48_45_404Z-debug.logroot@rrscw:/home/rrscw/superset/superset-frontend# node /root/.npm/_logs/2022-02-13T06_48_45_404Z-debug.logThe log file says:0 info it worked if it ends with ok1 verbose cli [ '/usr/bin/node', '/usr/bin/npm', 'run', 'dev-server' ]2 info using npm@6.14.43 info using node@v10.19.04 verbose run-script [ 'predev-server', 'dev-server', 'postdev-server' ]5 info lifecycle [superset@0.0.0-dev](mailto:superset@0.0.0-dev)predev-server: [superset@0.0.0-dev](mailto:superset@0.0.0-dev)6 info lifecycle [superset@0.0.0-dev](mailto:superset@0.0.0-dev)dev-server: [superset@0.0.0-dev](mailto:superset@0.0.0-dev)7 verbose lifecycle [superset@0.0.0-dev](mailto:superset@0.0.0-dev)dev-server: unsafe-perm in lifecycle true8 verbose lifecycle [superset@0.0.0-dev](mailto:superset@0.0.0-dev)dev-server: PATH: /usr/share/npm/node_modules/npm-lifecycle/node-gyp-bin:/home/rrscw/superset/superset-frontend/node_modules/.bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/g>9 verbose lifecycle [superset@0.0.0-dev](mailto:superset@0.0.0-dev)dev-server: CWD: /home/rrscw/superset/superset-frontend10 silly lifecycle [superset@0.0.0-dev](mailto:superset@0.0.0-dev)dev-server: Args: [ '-c',10 silly lifecycle 'cross-env NODE_ENV=development BABEL_ENV=development node --max_old_space_size=4096 ./node_modules/webpack-dev-server/bin/webpack-dev-server.js --mode=development' ]11 silly lifecycle [superset@0.0.0-dev](mailto:superset@0.0.0-dev)dev-server: Returned: code: 2 signal: null12 info lifecycle [superset@0.0.0-dev](mailto:superset@0.0.0-dev)dev-server: Failed to exec dev-server script13 verbose stack Error: [superset@0.0.0-dev](mailto:superset@0.0.0-dev) dev-server: cross-env NODE_ENV=development BABEL_ENV=development node --max_old_space_size=4096 ./node_modules/webpack-dev-server/bin/webpack-dev-server.js --mode=development13 verbose stack Exit status 213 verbose stack at EventEmitter. (/usr/share/npm/node_modules/npm-lifecycle/index.js:332:16)13 verbose stack at EventEmitter.emit (events.js:198:13)13 verbose stack at ChildProcess. (/usr/share/npm/node_modules/npm-lifecycle/lib/spawn.js:55:14)13 verbose stack at ChildProcess.emit (events.js:198:13)13 verbose stack at maybeClose (internal/child_process.js:982:16)13 verbose stack at Process.ChildProcess._handle.onexit (internal/child_process.js:259:5)14 verbose pkgid [superset@0.0.0-dev](mailto:superset@0.0.0-dev)15 verbose cwd /home/rrscw/superset/superset-frontend16 verbose Linux 5.4.0-99-generic17 verbose argv ""/usr/bin/node"" ""/usr/bin/npm"" ""run"" ""dev-server""18 verbose node v10.19.019 verbose npm v6.14.420 error code ELIFECYCLE21 error errno 222 error [superset@0.0.0-dev](mailto:superset@0.0.0-dev) dev-server: cross-env NODE_ENV=development BABEL_ENV=development node --max_old_space_size=4096 ./node_modules/webpack-dev-server/bin/webpack-dev-server.js --mode=development22 error Exit status 223 error Failed at the [superset@0.0.0-dev](mailto:superset@0.0.0-dev) dev-server script.23 error This is probably not a problem with npm. There is likely additional logging output above.24 verbose exit [ 2, true ]I have no clue what is going on at this point.### Environment(please complete the following information):OS: Ubuntu Server 20.04Python on VM: 3.8.10node on VM: 16.9.1npm on VM: 8.1.2### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18726,1,181,9,0,0,bkowshik,0,"title:An error occurred while rendering the visualization: TypeError: Cannot read properties of null (reading 'toString'). description:## Reproduce bugI am running a simple `GROUP BY` query like the one below and then do a Sunburst visualization.```sqlSELECT    DATE_PARSE(yyyymmdd, '%Y%m%d') yyyymmdd,    city_name,    COUNT(*) gross_ordersFROM ordersWHERE    yyyymmdd = '20211012'GROUP BY 1, 2ORDER BY 3 DESC```## Expected resultsI am expecting to see the visualization.## Actual resultsI am seeing the error below.> An error occurred while rendering the visualization: TypeError: Cannot read properties of null (reading 'toString')<img width=""1680"" alt=""Screenshot 2022-02-15 at 6 47 28 AM"" src=""https://user-images.githubusercontent.com/2899501/153974945-b4bc4e17-d13f-4a93-8a95-adc0a0044039.png"">
"
18723,1,0,3,0,0,dataf3l,0,"title:ERROR: flask-appbuilder 3.4.4 has requirement Flask-WTF<0.15.0,>=0.14.2, but you'll have flask-wtf 1.0.0 which is incompatible.. description:A clear and concise description of what the bug is.ERROR: flask-appbuilder 3.4.4 has requirement Flask-WTF<0.15.0,>=0.14.2, but you'll have flask-wtf 1.0.0 which is incompatible.#### How to reproduce the bug1. Go to 'pip install apache-superset'4. See error### Expected resultsno pip error### Actual resultsERROR: flask-appbuilder 3.4.4 has requirement Flask-WTF<0.15.0,>=0.14.2, but you'll have flask-wtf 1.0.0 which is incompatible.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version: Ubuntu 20- superset version: `- superset versionTraceback (most recent call last):  File ""/home/superset/code/venv/bin/superset"", line 8, in <module>    sys.exit(superset())  File ""/home/superset/code/venv/lib/python3.8/site-packages/click/core.py"", line 829, in __call__    return self.main(*args, **kwargs)  File ""/home/superset/code/venv/lib/python3.8/site-packages/flask/cli.py"", line 586, in main    return super(FlaskGroup, self).main(*args, **kwargs)  File ""/home/superset/code/venv/lib/python3.8/site-packages/click/core.py"", line 782, in main    rv = self.invoke(ctx)  File ""/home/superset/code/venv/lib/python3.8/site-packages/click/core.py"", line 1254, in invoke    cmd_name, cmd, args = self.resolve_command(ctx, args)  File ""/home/superset/code/venv/lib/python3.8/site-packages/click/core.py"", line 1297, in resolve_command    cmd = self.get_command(ctx, cmd_name)  File ""/home/superset/code/venv/lib/python3.8/site-packages/flask/cli.py"", line 527, in get_command    self._load_plugin_commands()  File ""/home/superset/code/venv/lib/python3.8/site-packages/flask/cli.py"", line 523, in _load_plugin_commands    self.add_command(ep.load(), ep.name)  File ""/home/superset/code/venv/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 2442, in load    self.require(*args, **kwargs)  File ""/home/superset/code/venv/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 2465, in require    items = working_set.resolve(reqs, env, installer, extras=self.extras)  File ""/home/superset/code/venv/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 791, in resolve    raise VersionConflict(dist, req).with_context(dependent_req)pkg_resources.VersionConflict: (Flask-WTF 1.0.0 (/home/superset/code/venv/lib/python3.8/site-packages), Requirement.parse('Flask-WTF<0.15.0,>=0.14.2'))- - - `- python version: `Python 3.8.10`- node.js version: `-vCommand 'node' not found, but can be installed with:apt install nodejsPlease ask your administrator.`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar. (why would I do that?)### Additional contextAdd any other context about the problem here.
"
18720,1,0,0,0,0,DhirajReddy,0,"title:Export in older version (0.25.2) and import in newer version (1.2) causes errors like 'avg', 'sum' is an invalid keyword argument for TableColumn. description:Export the dashboard in an older version and then import in a newer version. The import leads to errors like1. 'dict' object has no attribute '_sa_instance_state'2. 'sum' is an invalid keyword argument for TableColumn3. 'avg' is an invalid keyword argument for TableColumn#### How to reproduce the bug1. Export dashboard in older version2. Import in newer version3. Error with the aforementioned log 
"
18716,1,0,0,0,0,mchogithub,0,"title:saved queries - schema with null value. description:After saving the queries the schema is not valorized, the null value remains and it is not possible to update it in subsequent saves#### How to reproduce the bug1. Go to SQL Lab > SQL Editor2. Click on Database and select one3. Click on Schema and select one4. Edit and run query4. Click on Save button5. Click on Data > Saved Queries and open the newly saved query6. Click on Run button and the following is shown![image](https://user-images.githubusercontent.com/5494498/153882571-52d4b4f9-5fab-43f1-aef0-d322abfc1009.png)### Expected resultsthe ""Schema"" should remain saved### Actual resultsthe ""Schema"" always remains valued at null, even when a different value is selected from the drop-down menu#### Screenshots![image](https://user-images.githubusercontent.com/5494498/153882443-01dfdcf7-e012-4217-892e-4ff0208a445b.png)### Environment- docker-compose -f docker-compose-non-dev.yml up (1.4.1)- helm chart superset-0.5.8 ### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18713,1,0,0,0,0,Uria55,0,"title:The order by does not work well - Bar graph. description:I want to sort the values by column names 'value_overrides_ration'.The superset thinks it's a string, but it's actually a number.The data view is good but the bar graph doesn't work.### Expected resultsI expected the graph will perform as a table date### Actual resultsThe data in the table show but in graph does not.#### Screenshots![image](https://user-images.githubusercontent.com/99117138/153866327-7a13c7bc-b0c4-4d22-a75a-4525fd9b8a48.png)### Environment- browser type and version:- Chromium: Version 98.0.4758.80 (Official Build) snap (64-bit)
"
18697,1,0,0,0,0,LuPan2015,0,"title:How does superset worker ensure that every task is executed only once闂?""In superset beat. description: the ID of the scheduled task that meets the conditions will be written to redis. If there are multiple workers at the same time"
18256,1,0,0,0,0,manisha-tanwar,0,"title:Web UI doesn't show app version when deployed using Helm chart. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to 'Deploy helm chart using https://github.com/apache/superset/tree/master/helm/superset'2. Click on 'Setting'3. Scroll down to 'About'4. See error : Version as 0.0.0dev### Expected resultsApp version should be v1.4.0/latest tag### Actual resultsApp version shows v0.0.0dev#### Screenshots<img width=""1440"" alt=""Screenshot 2022-02-02 at 14 03 05"" src=""https://user-images.githubusercontent.com/63790657/152168969-e2d914c5-20f1-404f-81e6-b44604b93c52.png"">### Environment(please complete the following information):- browser type and version: Chrome- superset version: `superset version` > Superset 0.0.0dev- python version: `python --version` > Python 3.8.12- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18232,1,479,32,0,0,rumbin,0,"title:[mixed time-series; time-series bar chart v2] Bar chart jumps to very narrow bars in larger time ranges. description:Depending on the displayed time range, the width of the bar-chart bars becomes very narrow, up to the point where the bars become nearly invisible.The effect depends on the selected time grain, but I haven't found a pattern yet.**I can replicate this on both, mixed time-series _and_ time-series bar chart v2.**#### How to reproduce the bug1. Create a diagram of type **mixed time-series** (bar chart here!) or ** time-series bar chart v2**, based on a dataset that has at least 1 year of data in it2. Select a time range of 1 year3. Vary the time grain between weeks and quaters4. Activate _Data Zoom_ and play with it; alternatively reduce the time range gradually### Expected resultsThe bars of the bar chart should continuously be varied according to the time grain and the time rage, so the bar-to-gap ratio is harmonic. The old time-series bar chart may serve as a good example here.### Actual resultsThe width of the bars is harmonically scaled in some time ranges, but when a certain threshold is exceeded, the bar width jumps to nearly invisible vertical lines.The odd thing here is, that I cannot identify a pattern here:* For **weekly** time-grain the jump is at about end of march, when the whole year is displayed.* For **monthly** time-grain the threshold is at the beginning of march. So far so good.* But: for **quaterly** time_grain the bars are _always_ narrow lines, although there is by far enough space now.#### ScreenshotsThe first gif shows that the threshold where the bars jump from narrow to wide and back can be narrowed by both _Data Zoom_ and by changing the time range:![bar_chart_width_jump_weekly](https://user-images.githubusercontent.com/1220356/151816596-109a5d4a-bd2f-417c-81a6-0d89676a9ba0.gif)The second gif shows that the threshold depends on the time grain, where the few quaterly bars behave most erratic:![bar_chart_width_jump_time_grain](https://user-images.githubusercontent.com/1220356/151817428-6caf1947-81ce-485f-81aa-8cdc5650793d.gif)### Environment- browser type and version: Chrome  96.0.4664.93- superset version: 1.4.0- all other versions: as defined in Superset's Docker image- Feature flags:```# stable:      ""THUMBNAILS"": True,      ""SQLLAB_BACKEND_PERSISTENCE"": True,      ""ENABLE_TEMPLATE_PROCESSING"": True,      ""DASHBOARD_CROSS_FILTERS"": True,      # experimental:      ""ALERT_REPORTS"": True,      ""ALERTS_ATTACH_REPORTS"": True,      ""DASHBOARD_NATIVE_FILTERS"": True,      # unclassified:      ""ENABLE_EXPLORE_DRAG_AND_DROP"": True,      ""ENABLE_DND_WITH_CLICK_UX"": True,      # development:      ""DASHBOARD_NATIVE_FILTERS_SET"": True```### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18225,1,0,2,0,0,tenglong3158,0,"title:Attach new report to the dashboard again, but there are no error messages on the page. description:Attach new report to the dashboard again, but there are no error messages on the page.#### How to reproduce the bug1. Select a dashboard with reports and open it;2. Then add a new report to the dashboard;3. At this point, a 409 error will be reported, but there is no prompt on the page.### Expected resultsError message displayed on the page### Actual resultsa 409 error will be reported, but there is no prompt on the page.#### Screenshots![image](https://user-images.githubusercontent.com/20203245/151653714-793284be-8f3a-4aac-ba6a-1f80b920ef55.png)### Environment(please complete the following information):- browser type and version: chrome 97.0.4692.99- superset version: 1.4.0 Source code deployment- python version: Python 3.8.12- node.js version: v14.15.5- any feature flags active:  ""ALERT_REPORTS"": True,
"
18223,0,0,0,0,0,zuzana-vej,0,"title:[dashboard] Scrolling table viz overlaps next chart. description:If you have a chart on dashboard, which isn't fully displayed - e.g. need scrolling to see other records, it overlaps the next item on the dashboard (eg. a title, or another chart). Upon some investigation, we determine it is specifically a bug with chart that have descriptions. If you toggle the chart description off and then on again, all works well, but when you refresh the bug is back.In case the table has pagination, the pagination bar is overflowing - see screenshots.There is a workaround which minimizes the impact when user adds empty row below the chart, but then they see the grey text ""empty row"" so it's still not ideal. (instead of scrolling over chart or title, it's over the grey text""empty row"").#### How to reproduce the bugdescribed above#### Screenshotswithout toggle (correct)<img width=""694"" alt=""Screen Shot 2022-01-28 at 3 59 58 PM"" src=""https://user-images.githubusercontent.com/61221714/151637264-8ee88800-8f2f-45b1-97db-a8101b5d72c9.png"">(with toggle description - overflow)<img width=""682"" alt=""Screen Shot 2022-01-28 at 3 59 49 PM"" src=""https://user-images.githubusercontent.com/61221714/151637265-40cb33ca-65bb-46d1-ab79-72ad589cac4b.png"">Another example of the same issue:<img width=""690"" alt=""Screen Shot 2022-01-28 at 4 01 25 PM"" src=""https://user-images.githubusercontent.com/61221714/151637418-eb2a9b0a-a12d-46c1-bc20-2452272f4897.png"">### Environmentlatest master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18222,1,0,0,0,0,serenajiang,1,"title:Big Number does not handle DECIMAL metrics. description:If the metric for a big number chart has the type DECIMAL, the chart displays an error: `No data after filtering or data is NULL for the latest time record`From inspecting the request result for `/api/v1/chart/data`, it seems like this occurs because the decimal is analyzed as a string.#### How to reproduce the bug1. Run query in sqllab: `SELECT CAST(1 AS DECIMAL) AS x, DATE('2022-01-27') AS ds`2. Explore chart3. Select big number chart, use `SUM(x)` as metric4. Run. ### Expected resultsChart shows big number with value `1`. Data returned from `/api/v1/chart/data` is `[{SUM(x): 1}]`### Actual resultsError is shown. Data returned from `/api/v1/chart/data` is `[{SUM(x): ""1""}]`#### Screenshots![image](https://user-images.githubusercontent.com/14146019/151634523-9cf3780c-babe-4151-89f8-e01ea4864085.png)### EnvironmentUp to date with apache/master as of 2022-01-26.Presto SQL### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context
"
18220,0,0,10,0,0,iercan,0,"title:Save as dashboard with duplicating charts is not working after 1.4.0 upgrade. description:After upgrading to 1.4.0 we are not able to save as a dashboard with duplicate chart option. This is the error shown in the logs. It gives the same error on all dashboards I tried. > superset_1  | 'NoneType' object has no attribute 'roles'superset_1  | Traceback (most recent call last):superset_1  |   File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1950, in full_dispatch_requestsuperset_1  |     rv = self.dispatch_request()superset_1  |   File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1936, in dispatch_requestsuperset_1  |     return self.view_functions[rule.endpoint](**req.view_args)superset_1  |   File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/decorators.py"", line 148, in wrapssuperset_1  |     return f(self, *args, **kwargs)superset_1  |   File ""/app/superset/utils/log.py"", line 240, in wrappersuperset_1  |     value = f(*args, add_extra_log_payload=log, **kwargs)superset_1  |   File ""/app/superset/utils/decorators.py"", line 104, in wrappersuperset_1  |     raise exceptionsuperset_1  |   File ""/app/superset/utils/decorators.py"", line 100, in wrappersuperset_1  |     current_app.appbuilder.sm.raise_for_dashboard_access(dashboard)superset_1  |   File ""/app/superset/security/manager.py"", line 1180, in raise_for_dashboard_accesssuperset_1  |     for dashboard_role in dashboard.rolessuperset_1  | AttributeError: 'NoneType' object has no attribute 'roles'superset_1  | 2022-01-28 21:10:43,139:ERROR:superset.views.base:'NoneType' object has no attribute 'roles'superset_1  | Traceback (most recent call last):superset_1  |   File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1950, in full_dispatch_requestsuperset_1  |     rv = self.dispatch_request()superset_1  |   File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1936, in dispatch_requestsuperset_1  |     return self.view_functions[rule.endpoint](**req.view_args)superset_1  |   File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/decorators.py"", line 148, in wrapssuperset_1  |     return f(self, *args, **kwargs)superset_1  |   File ""/app/superset/utils/log.py"", line 240, in wrappersuperset_1  |     value = f(*args, add_extra_log_payload=log, **kwargs)superset_1  |   File ""/app/superset/utils/decorators.py"", line 104, in wrappersuperset_1  |     raise exceptionsuperset_1  |   File ""/app/superset/utils/decorators.py"", line 100, in wrappersuperset_1  |     current_app.appbuilder.sm.raise_for_dashboard_access(dashboard)superset_1  |   File ""/app/superset/security/manager.py"", line 1180, in raise_for_dashboard_accesssuperset_1  |     for dashboard_role in dashboard.rolessuperset_1  | AttributeError: 'NoneType' object has no attribute 'roles'#### How to reproduce the bug1. Open a dashboard 2. Click save as option3. Choose duplicate charts and save### Expected resultsNew dashboard should be created by duplicating charts ### Actual resultsProcess fails### Environment(please complete the following information):- browser type and version: chrome 97- superset version: 1.4.0 deployed with official image
"
18213,0,0,2,0,0,BeckersJ,0,"title:Blinking Native dashboard filter. description:When I zoom in on any dashboard with native dashboard filter enabled, the #rc-tabs-1-more start to blink at 125% and stop at 150% zoomlevel. See attached video. #### How to reproduce the bug1. Go to any dashboard2. Zoom from 100% to 125%3. See error4. Zoom further to 150% error disappears### Expected resultsNothing, the responsive design should allow the width of the native filter box to be enough to accommodate both the all filter and filter sets tabs. It works fine in 100% zoom and 150% zoom.### Actual resultsThe div with the .ant-tabs-nav-more class starts to blink.#### Screenshotshttps://user-images.githubusercontent.com/96041225/151526792-5067ce37-06f9-4bc5-bb0e-f30b39330097.mp4### Environment(please complete the following information):- browser type and version: Edge (97.0.1072.69 (64-bits)) Chrome (97.0.4692.99 (64-bits))- superset version: `1.4.0`- python version: `3.8`- any feature flags active:  - ""ROW_LEVEL_SECURITY"": True,  - ""ALERT_REPORTS"": True,  - ""THUMBNAILS"": False,  - ""DASHBOARD_NATIVE_FILTERS"": True,  - ""DASHBOARD_CROSS_FILTERS"": True,  - ""DASHBOARD_NATIVE_FILTERS_SET"": True,  - ""ENABLE_TEMPLATE_PROCESSING"": True,  - ""DASHBOARD_RBAC"": True,### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18210,0,0,0,0,0,ramesh2744,0,"title:Unexpected error: ListViewError: Invalid filter config, id is not present in columns. description:Prevent 'undefined' error when viewing the dashboard (or charts) listview in an anonymous mode.#### How to reproduce the bugReproduce the error as follows:Allow anonymous access by setting `PUBLIC_ROLE_LIKE = ""Gamma""`Without logging in, click on dashboards or charts. This error displays:_Unexpected error:ListViewError: Invalid filter config, id is not present in columns_### Expected resultsDashboards/charts must be visible without any issues/errors.### Actual resultThis issue observed when we make upgrade from v1.3 to v1.4#### Screenshots![image](https://user-images.githubusercontent.com/59677029/151490917-7314668d-518b-49d4-9899-7d32909c4e1c.png)### Environment(please complete the following information):- browser type and version: `Chrome Version 97.0.4692.71`- superset version: `1.4`- python version: `Python 3.7.5`- node.js version: `v8.10.0`### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextBrowser console log:_**ListViewError: Invalid filter config, id is not present in columns    at 87c5db28d6d4ce263182.chunk.js:932:15    at Array.forEach (<anonymous>)    at ListView (87c5db28d6d4ce263182.chunk.js:930:13)    at oh (vendors.866d9853ec9ca701f3b8.entry.js:54972:146)    at Rj (vendors.866d9853ec9ca701f3b8.entry.js:55080:496)    at Qj (vendors.866d9853ec9ca701f3b8.entry.js:55065:199)    at Kj (vendors.866d9853ec9ca701f3b8.entry.js:55065:128)    at yj (vendors.866d9853ec9ca701f3b8.entry.js:55058:172)    at vendors.866d9853ec9ca701f3b8.entry.js:54942:115    at exports.unstable_runWithPriority (vendors.866d9853ec9ca701f3b8.entry.js:55173:467)**_        ![image](https://user-images.githubusercontent.com/59677029/151502303-1fe8a756-38ca-4ddd-a1be-2c9d18a48638.png)
"
18203,0,0,0,0,0,igor-lukyanov,0,"title:Field table_columns.type varchar(32) is too short. description:Superset version 1.4.0Particularly in Clickhouse column types may be quite long: 'type': ""ENUM8('V1' = 0, 'V2' = 1, 'V3' = 2, 'V4' = 3, 'V5' = 4, 'V6' = 5, 'V7' = 6, 'V8' = 7)""which leads to `(psycopg2.errors.StringDataRightTruncation) value too long for type character varying(32)` error while creating a new dataset from a table with long enough enums. The solution is to `ALTER TABLE superset.table_columns ALTER COLUMN type TYPE varchar`. Sorry for not submitting a patch, not quite familiar with superset internals.
"
18198,0,0,10,0,0,iercan,0,"title:Unable to use view chart in explore feature on 1.4.0. description:After upgrading to 1.4.0, we are unable to use view chart in explore feature for some charts. When I try to open in explore, I'm getting a blank chart as seen in the picture.Only thing I detected common between these charts is that they all have `../superset/explore/?URL_IS_TOO_LONG_TO_SHARE&...` in their urls. Maybe something wrong with url conversion?#### How to reproduce the bugTry to open chart in explore### Expected resultsCharts need to be opened in explore mode### Actual resultsGetting blank chart#### Screenshots![Screenshot from 2022-01-27 16-22-29](https://user-images.githubusercontent.com/3406152/151367523-6d91d24a-dd4c-498d-baf7-2df2156a5d7a.png)![image](https://user-images.githubusercontent.com/3406152/151366353-ea255643-0583-47a2-804a-2b8148bd3e77.png)### Environment- browser type and version: Chrome 97- superset version: 1.4.0 installed with official docker image.
"
18194,1,0,198,0,0,acirulis,0,"title:""Initial connection"" randomly fails on Edge (Win11, with Docker + WSL2). Works on Firefox.. description:After setting up Superset in WSL2 environment with Docker, everything works as expected on Firefox browser. However, on Edge, it randomly fails to connect with ""Initial connection"" never finishing. I have never had similar problems with Edge before, so I am creating issue here, even it may not be related to Superset.#### How to reproduce the bug1. Install Superset on Windows 11 with latest updates, Docker, WSL2, and Ubuntu distro setup. (from master branch)2. Start Edge browser (latest Version 97.0.1072.69)3. Open http://localhost:80884. Login with admin:admin credentials and start browsing### Expected resultsEverything works### Actual resultsAround 40% (subjective) of network requests fails during ""Initial connection"" phase. Please see screenshot.If I switch to other browser (e.g. Firefox), problem is gone.Nothing in docker logs, as these failed requests don't reach app. Only reason I am creating this issue is because I haven't had similar problems with Edge on any other Docker based projects/environments I am using.#### Screenshots![image](https://user-images.githubusercontent.com/27766961/151327205-1f2ce5ae-7fc3-4ed5-abbf-6b5f81d04bf4.png)### Environment(please complete the following information):- Edge browser (latest Version 97.0.1072.69)- superset version: Docker container reports: `Superset 0.0.0dev`. But I am using image apache/superset  pulled on Jan25`22Launched from docker environment with docker-compose-non-dev.yml### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context
"
18193,1,0,0,0,0,navnathedb,0,"title:Issue with calendar heatmap - a 0 is not getting coloured red. description:We're trying to integrate Github with Superset. In that, we have created some dashboards with charts.We're getting an issue with the calendar heatmap chart -  a 0 is not getting coloured red#### How to reproduce the bug1. Create a calendar heatmap chart from GitHub or any Github sort of data 2. Open chart by clicking in charts tab or even in create chart section 3. There is no actual error but as per chart settings cell data with '0' value should be colored with red but on the chart it's white in color (check the attached screenshot)### Expected resultsData with cell value '0' should be in red colour### Actual resultsIt's white in colour#### Screenshots<img width=""533"" alt=""Screenshot 2022-01-25 at 7 12 52 AM"" src=""https://user-images.githubusercontent.com/47140549/151327834-eb5b9f38-3353-4fa6-b17b-5e6d65660d0e.png"">### Environment(please complete the following information):- browser type and version: Google chrome Version 97.0.4692.71 (Official Build) (x86_64)- superset version: `1.3.2`- python version: `3.8`- any feature flags active: No### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAlso check chat on Slack - https://apache-superset.slack.com/archives/C016B3LG5B4/p1643075312076400
"
18191,1,0,0,0,0,nirajtambat,0,"title:Long Running Queries -  Auto Cancellation/Kill process in superset. description:In superset if there is a long running query running more than 3 mins (for example), is it possible to kill the query automatically and take the next one in the queue. application should auto-cancel the query. Also Query time out option is set but still on backend query is running. It's not cancelling query execution on database server.  Let us know any solution for this.
"
18184,1,0,5,0,0,chris-befoul,0,"title:Seeing 404 Not Found with SQLLAB_BACKEND_PERSISTENCE Enabled. description:Latest Version of Apache Superset from docker image.When the feature flag SQLLAB_BACKEND_PERSISTENCE is set to true in SQL lab upon selecting a schema receiving superset error trouble finding schema.  And seeing this error in logs upon trying to select schema: 404 Not Found: The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.![image](https://user-images.githubusercontent.com/55672717/151259802-d464d044-d809-442e-8728-30004d8a920c.png)The next call where I am still able to select the schema executes no problem with a 200 status and I am able to run a query against it. When SQLLAB_BACKEND_PERSISTENCE is set to false, I am not seeing these errors but will receive the local storage error which I am trying to eliminate.Relevant code: ![image](https://user-images.githubusercontent.com/55672717/151260977-e426601d-e62f-4874-a736-80646bd93471.png)![image](https://user-images.githubusercontent.com/55672717/151261727-acffe3b8-a8ab-4e3a-b736-d06dee48054b.png)Any help would be greatly appreciated!
"
18178,0,0,40,0,0,jinghua-qa,0,"title:[explore][filter] IN filter select box will be loading forever when there is null value in the column. description:IN filter select box will be loading forever when there is null value in the column#### How to reproduce the buguse example data 'Covid Vaccine'1. Go to explore, select chart type 'Big number'2. add Metrics: count, add Filter:  fda_approval_indicators (with all null value)3. select 'IN' for filter type, 4. Observe filter value file and See error### Expected resultsAble to show null for user to select### Actual resultsloading forever#### Screenshots<img width=""1790"" alt=""Screen Shot 2022-01-24 at 8 32 24 PM"" src=""https://user-images.githubusercontent.com/81597121/151215080-87acadbd-8f1d-4dbc-a4f3-2421a7a4cf5c.png"">### Environment(please complete the following information):- browser type and version:- superset version:  master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18172,0,3806,267,0,0,pedro93,0,"title:[Kubernetes] In Superset 1.4 Superset worker /bin/sh: 1: celery: not found. description:Superset worker fails to start using superset oficial helm charts with apache/superset:1.4.0 docker image.This is the log of the worker pod:```闂?kubectl -n dc-superset logs superset-worker-5756d5d664-k29lvCollecting psycopg2-binary==2.9.1  Downloading psycopg2_binary-2.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)Requirement already satisfied: redis==3.5.3 in /usr/local/lib/python3.8/site-packages (3.5.3)Installing collected packages: psycopg2-binary  Attempting uninstall: psycopg2-binary    Found existing installation: psycopg2-binary 2.8.5    Uninstalling psycopg2-binary-2.8.5:      Successfully uninstalled psycopg2-binary-2.8.5Successfully installed psycopg2-binary-2.9.1WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venvWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command./bin/sh: 1: celery: not found```#### How to reproduce the bugDeploy official helm chart (v0.5.4) with the following values.yaml:```superset:  enabled: true  image:    repository: apache/superset    tag: 1.4.0  supersetNode:    command:      - ""/bin/bash""      - ""-c""      - ""{{ .Values.configMountPath }}/superset_bootstrap.sh; /usr/bin/run-server.sh""   # For some reason the apache docker image does not include the script it tries to run...  extraVolumes:    - name: custom-config      configMap:        name: superset-startup-config        defaultMode: 0777        items:          - key: run-server.sh            path: run-server.sh  extraVolumeMounts:    - name: custom-config      mountPath: /usr/bin  postgresql:    # Create postgres locally for development purposes only.    enabled: true```And this template:```apiVersion: v1kind: ConfigMapmetadata:  name: superset-startup-config  labels:    release: ""{{ .Release.Name }}""    heritage: ""{{ .Release.Service }}""data:  run-server.sh: |    #!/usr/bin/env sh    #    # Licensed to the Apache Software Foundation (ASF) under one    # or more contributor license agreements.  See the NOTICE file    # distributed with this work for additional information    # regarding copyright ownership.  The ASF licenses this file    # to you under the Apache License, Version 2.0 (the    # ""License""); you may not use this file except in compliance    # with the License.  You may obtain a copy of the License at    #    # http://www.apache.org/licenses/LICENSE-2.0    #    # Unless required by applicable law or agreed to in writing,    # software distributed under the License is distributed on an    # ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY    # KIND, either express or implied.  See the License for the    # specific language governing permissions and limitations    # under the License.    #    HYPHEN_SYMBOL='-'    gunicorn \        --bind ""${SUPERSET_BIND_ADDRESS:-0.0.0.0}:${SUPERSET_PORT:-8088}"" \        --access-logfile ""${ACCESS_LOG_FILE:-$HYPHEN_SYMBOL}"" \        --error-logfile ""${ERROR_LOG_FILE:-$HYPHEN_SYMBOL}"" \        --workers ${SERVER_WORKER_AMOUNT:-1} \        --worker-class ${SERVER_WORKER_CLASS:-gthread} \        --threads ${SERVER_THREADS_AMOUNT:-20} \        --timeout ${GUNICORN_TIMEOUT:-60} \        --limit-request-line ${SERVER_LIMIT_REQUEST_LINE:-0} \        --limit-request-field_size ${SERVER_LIMIT_REQUEST_FIELD_SIZE:-0} \        ""${FLASK_APP}""---```Execute `kubectl get po` and see that the worker node fails.### Expected resultsSuperset to be deployed and stable.### Actual results```$ kubectl -n dc-superset get poNAME                               READY   STATUS             RESTARTS   AGEsuperset-6d9ff785d7-mczf9          0/1     CrashLoopBackOff   6          7m13ssuperset-redis-master-0            1/1     Running            0          7m13ssuperset-worker-5756d5d664-k29lv   0/1     CrashLoopBackOff   6          7m13s```### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18154,0,0,89,0,0,nytai,0,"title:Copy to clipboard fails in safari . description:For some actions the copy to clipboard action fails in safari. It appears that safari has strict security measures in place for the copy api. The copy api cannot be called from an api response and must be called from a user interaction (a DOM callback event). This is causing actions in superset that follow the pattern of call some api (usually to save some value) then copy the api response to clipboard to fail. The error message that's thrown suggest using `cmd/ctrl + c` to copy the value, however the value is not stored anywhere the user can highlight and copy. #### How to reproduce the bug1. Open Safari browser2. Go to SQL Lab > SQL Editor3. Click ""Copy Link"" button4. See error### Expected resultsResults are copied to clipboard or an acceptable workaround is presented to the user, such as displaying the value that should have been copied so the user can highly and `cmd/ctrl + c` the value.  ### Actual resultsCopy to clipboard fails, an toast is thrown ""Sorry, your browser does not support copying. Use Ctrl / Cmd + C!"", and the user is unable to copy the value to clipboard #### Screenshots<img width=""2542"" alt=""Screen Shot 2022-01-24 at 11 54 04 AM"" src=""https://user-images.githubusercontent.com/10255196/150854768-9425fbc2-1612-410c-bb68-fda03bf44f1a.png"">### Environment(please complete the following information):- browser type and version: Safari (latest)- superset version: `1.4.0`- python version: 3.8.12- node.js version: N/A (using prebuilt assets)- any feature flags active: N/A### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context
"
18149,0,0,164,0,0,geido,1,"title:[dashboard] [native filters] Existing default values get deleted when searching. description:#### How to reproduce the bug1. Go to a Dashboard2. Edit a filter3. Search for a value in ""Default value"" 4. Observe that existing default values get deleted### Expected resultsExisting default values should remain selected### Actual resultsExisting default values get deleted#### Screenshotshttps://user-images.githubusercontent.com/60598000/150779993-ac602f0c-61e4-4064-a9f7-55d41812228e.mp4### Environment(please complete the following information):- browser type and version: Chrome 97.0.4692.71- superset version: `1.4.0rc4`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18147,0,53,64,0,0,zhaoyongjie,0,"title:[explore] Filter unable to select `NULL` and `empty string`. description:I can't select `NULL` and `empty string` in Filter#### How to reproduce the bug1. First of all, let us create a virtual dataset from SQLLab and open this in Explore page.```SELECT '' as nameUNION ALLSELECT null as name```2. I can't get `NULL` and `empty string` in filter.<img width=""924"" alt=""image"" src=""https://user-images.githubusercontent.com/2016594/150731794-ccd0749a-a598-4a43-bb2e-ca2a42685db5.png"">3. I can manually input `<NULL>` and `<empty string>` to filter that.<img width=""1399"" alt=""image"" src=""https://user-images.githubusercontent.com/2016594/150732033-ea7975a8-4242-4c66-9f46-df1db69a089e.png"">### Expected resultsI can select `<NULL>` and `<empty string>` in filter### Environmentlatest master branch### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18129,0,0,4,0,0,D3nn3,0,"title:Time-series Area Chart not showing any filling anymore after update to 1.4.0. description:As the title says, with Superset 1.4.0 Area Charts don't show any filling anymore. The ""Area chart opacity"" also doesn't have any effect anymore.
"
18126,0,0,0,0,0,suraj-12,0,"title:error Unexpected token < in JSON at position 0. description:use case is to embed superset dasboards in a web application as iframe but while doing so on some visualization getting Unexpected token < in JSON at position 0 error. normally in superset application same dashboard is working fine but while sahring as iframe only this issue is coming.superset version 1.32html page content for testing:<html><iframe name=""iframe1"" src=""https://xxxxxxxxxxx-![supersetiframeerror](https://user-images.githubusercontent.com/48901138/150507033-1e215d15-2824-41f8-9e61-6e7834add800.JPG)superset.ad.infosys.com/superset/dashboard/13/"" frameborder=""0""     marginheight=""0""     marginwidth=""0""     width=""100%""     height=""100%""     scrolling=""auto""></iframe></html>
"
18109,0,0,0,0,0,rafalpas,0,"title:Chart IDs not updated in native_filter_configuration when importing dashboard. description:Problem reproduced with Superset 1.4rc4 with VERSIONED_EXPORT and DASHBOARD_NATIVE_FILTERS enabled - both are related to the problem.The native_filter_configuration section in dashboard's json metadata contains two fields that refer to charts with numeric IDs (chartsInScope and scope.excluded). When exporting and then importing a such a dashboard, while charts get new numeric IDs, the IDs are not updated. As a result the filter scoping definitions might be affected.#### How to reproduce the bug1. Install Superset 1.4rc4 with demo dashboards and VERSIONED_EXPORT, DASHBOARD_NATIVE_FILTERS feature flags enabled2. Create a new dashboard3. Add 2 charts (Boys, Girls) to the dashboard4. Add a Tab component5. Add 2 charts (Top 10 Boy Name Share, Top 1-- Girl Name Share) to the Tab component6. Save the dashboard![image](https://user-images.githubusercontent.com/2510246/150337606-057563f2-2b02-4013-ae8a-9eecf29bdf52.png)7. Add a dashboard native filter on dataset ""birth_names"" and column ""state""![image](https://user-images.githubusercontent.com/2510246/150337733-f8e6a0cd-868d-4849-b1a0-ab45b46a98e8.png)8. Alter the scope of the filter to include only ""boys"" and ""Top 10 Girl Name Share"" and save![image](https://user-images.githubusercontent.com/2510246/150337791-0a276bdd-79de-416f-a08f-c4ac1bd17bec.png)The filter is only applied to the desired charts![image](https://user-images.githubusercontent.com/2510246/150337827-0c1129cf-c2b5-4975-9862-3cfb2abe3b51.png)9. Check the dashboard properties JSON METADATA - The native_filter_configuration contains references to numeric IDs of the charts (""chartsInScope"" and ""scope"".""excluded"")![image](https://user-images.githubusercontent.com/2510246/150337895-e1fa12ef-c518-41a6-b51f-7405591051d0.png)10. Export the dashboard.11. Delete all charts and dashboards12. Import the exported dashboard -> notice that the numeric Ids of the 4 charts are now different (133, 134, 135, 136 in my case)13. Open the dashboard and activate the filter### Expected results- The same two charts should be highlighted as after step 8![image](https://user-images.githubusercontent.com/2510246/150337827-0c1129cf-c2b5-4975-9862-3cfb2abe3b51.png)### Actual results- After step 13 all charts are highlighted (are in scope of the filter)![image](https://user-images.githubusercontent.com/2510246/150338638-543d8dd1-e354-4a70-84fa-7183ea489dc1.png)- After checking filter scoping:![image](https://user-images.githubusercontent.com/2510246/150338710-cf2a97fe-97fb-4929-87ae-aab4768d9f43.png)- After checking the JSON METADATA - still old IDs:![image](https://user-images.githubusercontent.com/2510246/150338808-f6ce5f50-3641-474e-b1ab-25cbc632e447.png)#### ScreenshotsAdded in the steps### Environment- browser type and version: Microsoft Edge 96.0.1054.43- superset version: `superset version`: 1.4rc4- python version: `python --version`- node.js version: `node -v`- any feature flags active: VERSIONED_EXPORT, DASHBOARD_NATIVE_FILTERS, DASHBOARD_RBAC### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextThe problem can be partially reproduced with just two charts and without the tab component, but in this situation only one of the two fields with numeric IDs will be present in the dashboard's json metadata. Adding the tab component allows to see also the ""scope"".""excluded"" field.
"
18104,0,0,40,0,0,jinghua-qa,0,"title:[chart viz][Time-series bar chart v2] chart will shrink when input customize X AXIS TITLE MARGIN or Y AXIS TITLE MARGIN. description:chart will shrink when input customize X AXIS TITLE MARGIN#### How to reproduce the bug1, open example chart 'Quarterly Sales' in time-series bart chart v22, go to CUSTOMIZE panel and input X AXIS TITLE3, input customize X AXIS TITLE MARGIN4, Observe error### Expected resultsX AXIS TITLE MARGIN will adjust to customize margin### Actual resultsX AXIS TITLE MARGIN did not adjust to customize margin and the chart shrinkA clear and concise ### Screenshotshttps://user-images.githubusercontent.com/81597121/150295799-9d613653-5171-4467-9418-b711f53adf24.mov### Environment(please complete the following information):- browser type and version:- superset version: superset master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18096,0,0,36,0,0,ktmud,1,"title:[Dashboard Editor] Cmd + Z should not revert layout changes when editing chart title. description:#### How to reproduce the bug1. Go to dashboard edit mode2. Make some layout changes. For example, resize a chart.3. Click on a chart title to edit it:    <img width=""420"" alt=""Xnip2022-01-19_11-40-07"" src=""https://user-images.githubusercontent.com/335541/150202161-a1364779-9442-40b1-8470-1b45fa034a30.png"">4. Enter something and click on Ctr + Z (Windows) or Cmd + Z (macOS)### Expected resultsThe input value revert to previous edits. The layout doesn't change.### Actual resultsThe layout change was reverted but the input value didn't change.#### ScreenshotsN/A### EnvironmentLatest `master` branch### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextN/A
"
18095,0,372,0,0,0,hashbash,0,"title:deck.gl Multiple Layers doesn't work. description:deck.gl Multiple Layers doesn't work#### How to reproduce the bug1. Go to Scatterplot chart from examples2. Change visualisation type to `deck.gl Multiple Layers`2. Select `Screen Grid` chart in menu `DECK.GL CHARTS` and `Run query`4. See error### Expected resultsMap with multiple layers### Actual resultsEmpty screen#### Screenshots![Screen Shot 2022-01-19 at 21 45 40](https://user-images.githubusercontent.com/10183440/150194687-8590f4ac-db9e-4167-aebc-3e2c70e77955.png)![Screen Shot 2022-01-19 at 21 47 21](https://user-images.githubusercontent.com/10183440/150194701-c1f83941-f341-45d1-830a-2bbefdf0cf55.png)### Environmentbrowser type and version: Chrome Version 97.0.4692.71 (Official Build) (x86_64)superset version: 1.4.0python version: Python 3.8.10node.js version: v10.19.0DISTRIB_ID=UbuntuDISTRIB_RELEASE=20.04### Logs```Cache key: None2022-01-19 18:48:59,163:INFO:superset.viz:Cache key: None2022-01-19 18:48:59,182:INFO:werkzeug:89.208.120.68 - - [19/Jan/2022 18:48:59] ""POST /superset/explore_json/?form_data=%7B%22slice_id%22%3A73%7D HTTP/1.1"" 200 -2022-01-19 18:49:00,295:INFO:werkzeug:89.208.120.68 - - [19/Jan/2022 18:49:00] ""POST /superset/log/?explode=events HTTP/1.1"" 200 -```
"
18094,0,0,0,0,0,hashbash,0,"title:Javascript editor duplicate characters. description:Javascript editor duplicate characters#### How to reproduce the bug1. Go to new chart with deck.gl Screen Grid2. Enable ENABLE_JAVASCRIPT_CONTROLS and start input characters into window3. Input ""1234""4. See errorExpected characters in this window ""1234"", actual characters ""1234123121""### Expected results`1234`### Actual results`1234123121`#### Screenshots![image](https://user-images.githubusercontent.com/10183440/150188688-425686ba-fba5-4094-b3a0-50c80987f4ab.png)### Environment- browser type and version: Chrome Version 97.0.4692.71 (Official Build) (x86_64)- superset version: `1.4.0`- python version: `Python 3.8.10`- node.js version: `v10.19.0`DISTRIB_ID=UbuntuDISTRIB_RELEASE=20.04### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [V] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [V] I have reproduced the issue with at least the latest released version of superset.- [V] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18091,1,0,1,0,0,usamaB,0,"title:[dashboard] [native-filter] Unable to view Dashboard Native Filter's UI/Sidepanel with non-admin & non-owners users. description:![Screenshot 2022-01-18 at 17 51 42](https://user-images.githubusercontent.com/13015524/150175847-b34a3a63-8c38-4527-867d-8cd40f25cd44.png)What extra permission(s) is required for a Gamma user with excess to a Dashboard, to view the Dashboard Native Filter UI?Is it only limited to the Owner/Admin?
"
18077,1,7189,0,0,1,curious86,0,"title:Invalid decryption key issue. description:When starting superset using docker-compose up in local, I am seeing the following error:```superset_init            | Loaded your LOCAL configuration at [/app/docker/pythonpath_dev/superset_config.py]superset_init            | Traceback (most recent call last):superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy_utils/types/encrypted/encrypted_type.py"", line 128, in decryptsuperset_init            |     decrypted = decrypted.decode('utf-8')superset_init            | UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb1 in position 0: invalid start bytesuperset_init            | superset_init            | During handling of the above exception, another exception occurred:superset_init            | superset_init            | Traceback (most recent call last):superset_init            |   File ""/usr/local/bin/superset"", line 33, in <module>superset_init            |     sys.exit(load_entry_point('apache-superset', 'console_scripts', 'superset')())superset_init            |   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 829, in __call__superset_init            |     return self.main(*args, **kwargs)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 586, in mainsuperset_init            |     return super(FlaskGroup, self).main(*args, **kwargs)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 782, in mainsuperset_init            |     rv = self.invoke(ctx)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1259, in invokesuperset_init            |     return _process_result(sub_ctx.command.invoke(sub_ctx))superset_init            |   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 1066, in invokesuperset_init            |     return ctx.invoke(self.callback, **ctx.params)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 610, in invokesuperset_init            |     return callback(*args, **kwargs)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/click/decorators.py"", line 21, in new_funcsuperset_init            |     return f(get_current_context(), *args, **kwargs)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 426, in decoratorsuperset_init            |     return __ctx.invoke(f, *args, **kwargs)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 610, in invokesuperset_init            |     return callback(*args, **kwargs)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/click/decorators.py"", line 21, in new_funcsuperset_init            |     return f(get_current_context(), *args, **kwargs)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/flask/cli.py"", line 426, in decoratorsuperset_init            |     return __ctx.invoke(f, *args, **kwargs)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/click/core.py"", line 610, in invokesuperset_init            |     return callback(*args, **kwargs)superset_init            |   File ""/app/superset/cli.py"", line 93, in initsuperset_init            |     security_manager.sync_role_definitions()superset_init            |   File ""/app/superset/security/manager.py"", line 704, in sync_role_definitionssuperset_init            |     self.create_missing_perms()superset_init            |   File ""/app/superset/security/manager.py"", line 646, in create_missing_permssuperset_init            |     merge_pv(""datasource_access"", datasource.get_perm())superset_init            |   File ""/app/superset/connectors/sqla/models.py"", line 636, in get_permsuperset_init            |     return f""[{self.database}].[{self.table_name}](id:{self.id})""superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/attributes.py"", line 294, in __get__superset_init            |     return self.impl.get(instance_state(instance), dict_)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/attributes.py"", line 730, in getsuperset_init            |     value = self.callable_(state, passive)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/strategies.py"", line 759, in _load_for_statesuperset_init            |     return self._emit_lazyload(superset_init            |   File ""<string>"", line 1, in <lambda>superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/strategies.py"", line 847, in _emit_lazyloadsuperset_init            |     q(session)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/ext/baked.py"", line 615, in _load_on_pk_identitysuperset_init            |     result = list(bq.for_session(self.session).params(**params))superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/loading.py"", line 100, in instancessuperset_init            |     cursor.close()superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py"", line 68, in __exit__superset_init            |     compat.raise_(superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_superset_init            |     raise exceptionsuperset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/loading.py"", line 80, in instancessuperset_init            |     rows = [proc(row) for row in fetch]superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/loading.py"", line 80, in <listcomp>superset_init            |     rows = [proc(row) for row in fetch]superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/loading.py"", line 579, in _instancesuperset_init            |     _populate_full(superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/loading.py"", line 725, in _populate_fullsuperset_init            |     dict_[key] = getter(row)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/type_api.py"", line 1278, in processsuperset_init            |     return process_value(impl_processor(value), dialect)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy_utils/types/encrypted/encrypted_type.py"", line 477, in process_result_valuesuperset_init            |     value = super().process_result_value(value=value, dialect=dialect)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy_utils/types/encrypted/encrypted_type.py"", line 422, in process_result_valuesuperset_init            |     decrypted_value = self.engine.decrypt(value)superset_init            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy_utils/types/encrypted/encrypted_type.py"", line 130, in decryptsuperset_init            |     raise ValueError('Invalid decryption key')superset_init            | ValueError: Invalid decryption key```I have no idea what is a decryption key? And why I am getting this:`UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb1 in position 0: invalid start byte`How can I fix it?
"
18076,1,0,64,0,0,zhaoyongjie,0,"title:Unable to edit verbose name of column and description of column in REACT_CRUD_VIEWS mode. description:Unable to edit verbose name of column and description of column in REACT_CRUD_VIEWS mode, but I can edit these fields in legacy mode.#### How to reproduce the bug1. Go to 'Dataset'2. Click on 'column that you want to change'3. edit it### Expected resultsI can edit column when REACT_CRUD_VIEWS is enabled### Actual resultsI can't edit column when REACT_CRUD_VIEWS is enabled#### Screenshotshttps://user-images.githubusercontent.com/2016594/149912989-073e065b-7136-4e42-8e88-b0e611c45414.mov### Environment(please complete the following information):- browser type and version: `Chrome / Firefox`- superset version: `latest commit on master branch`- python version: `3.8.6`- node.js version: `v16.9.1`- any feature flags active: `default config`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18074,1,1543,0,0,0,curious86,0,"title:python-ldap package installation not working for ldap. description:I was trying to set ldap based auth for superset, while running superset in docker. I have updated superset_config.py with the LDAP auth code.  Then ran the following command:`docker-compose -f docker-compose-non-dev.yml up`But got the following error when tried to login:`2022-01-18 08:55:35,505:ERROR:flask_appbuilder.security.manager:python-ldap library is not installed`Can anyone give an example of how to install this package?I have tried various ways to install python-ldap, but nothing seems to work:1. Added following lines in Dockerfile:```RUN apt-get install -y libsasl2-dev python-dev libldap2-dev libssl-devRUN pip install python-ldap```2. Tried the following commands as well:```touch ./requirements/requirements-local.txtecho ""python-ldap"" >> ./requirements/requirements-local.txt```^^trying this above commands and then running docker is throwing the below error for : superset, superset-worker, superset-worker-beat:```AP_R -DLDAPMODULE_VERSION=3.4.0 ""-DLDAPMODULE_AUTHOR=python-ldap project"" ""-DLDAPMODULE_LICENSE=Python style"" -IModules -I/usr/local/include/python3.8 -c Modules/LDAPObject.c -o build/temp.linux-x86_64-3.8/Modules/LDAPObject.osuperset_tests_worker    |   In file included from Modules/LDAPObject.c:3:superset_tests_worker    |   Modules/common.h:15:10: fatal error: lber.h: No such file or directorysuperset_tests_worker    |      15 | #include <lber.h>superset_tests_worker    |         |          ^~~~~~~~superset_tests_worker    |   compilation terminated.superset_tests_worker    |   error: command '/usr/bin/gcc' failed with exit code 1superset_tests_worker    |   ----------------------------------------superset_tests_worker    |   ERROR: Failed building wheel for python-ldapsuperset_tests_worker    | Failed to build python-ldapsuperset_tests_worker    | ERROR: Could not build wheels for python-ldap which use PEP 517 and cannot be installed directlysuperset_tests_worker    | WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.superset_tests_worker    | You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.superset_worker_beat     |   Installing build dependencies: startedsuperset_tests_worker exited with code 1```My mac python version is: Python 3.8.9Please let me know , what is the right way to install the python-ldap package, while running superset in docker??
"
18055,1,0,3,0,0,kvaleev,0,"title:UI texts are truncated after localisation. description:### How to reproduce the bug1. Update translation of one of the locales (Russian) according to instructions: https://github.com/apache/superset/blob/master/CONTRIBUTING.md#translating2. Build and run the services### Expected resultsUI texts are updated according to locale changes.### Actual resultsSome strings are truncated.<img width=""291"" alt=""Screenshot 2022-01-14 at 23 19 08"" src=""https://user-images.githubusercontent.com/3600063/149579985-99a0f44c-bbc4-441c-8f5c-97d822c03c05.png"">
"
18047,0,0,0,0,0,Hammad-Raza,0,"title:Dataset and Chart options vertical scroll not working. description:Vertical scroll stopped working on Chrome.**Steps to Reproduce:**- Go to Create Chart or open the existing chart.- on Chart explorer page, dataset and chart options column vertical scroll is disabledSuperset Version 1.1Browser: Chrome 97.0**Actual Result:**https://user-images.githubusercontent.com/15028724/149542278-dccc1ced-12e9-4556-8ef6-0d74d4e8b9ee.mov**Expected Result:**https://user-images.githubusercontent.com/15028724/149541419-c74088c2-22d3-429b-8e88-b5b5b8c7c801.mov
"
18040,0,0,40,0,0,jinghua-qa,0,"title:[native filter] filters are displayed as out of scope if there are tabs on dashboard. description:filters are displayed as out of scope if there are tabs on dashboard#### How to reproduce the bug1,Open any dashboard with tabs (e.g. use `Sales Dashboard) or use your own2,Create a native filter (e.g. time range) and apply it to all panels3,Save the filter4,Go to the ""Dashboards"" page5,Open the dashboard from step 16,Pay attention to the native filter bar### Expected resultsthe scope of the filters has not changed for dashboard with tabs### Actual resultsfilter is displayed as out of scope on if there are tabs on dashboard (after re-visiting the dashboard), see the video below:#### Screenshotshttps://user-images.githubusercontent.com/81597121/149433547-fcd17a72-866a-4110-8904-c442965efb8e.mp4### Environment(please complete the following information):- browser type and version:- superset version: master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18034,1,0,21,0,0,cesar-loadsmart,0,"title:Dataset fuzzy search in ""Create a new chart"" UI isn't searching all available datasets when there are more than 100 datasets. description:Hey Everyone!Clicking the +CHART on the Charts tab, when selecting the dataset, not all of them are available. From the Charts tab I looked for the **Dataset Bar Limit** and I couldn闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?find it, but when I searched it in the Datasets tab it was available (evidence attached).#### How to reproduce the bug1. Go to Chart Tab2. Click on +CHART button3. Search for a Dataset4. You won't see them allPS: I have almost 600 datasets on my Superset env.### Expected resultsShow all available datasets to be selected before creating the chart.### Actual resultsDisplay only a few datasets.#### ScreenshotsSearching for the dataset on the Charts tab:![image](https://user-images.githubusercontent.com/89807801/149353347-f87f6dee-ed0b-49e7-a8bc-307303590b01.png)When Searching for the dataset on the Datasets tab:![image](https://user-images.githubusercontent.com/89807801/149354542-960cd585-ad25-4e9f-81c3-fe4a4ae68512.png)### Environment- browser type and version: Google Chrome - Version 97.0.4692.71 (Official Build) (x86_64)- superset version: `1.3.2`- python version: `3.8`- node.js version: `node 16`- any feature flags active: ALERT_REPORTS, DASHBOARD_NATIVE_FILTERS, ENABLE_TEMPLATE_PROCESSING- I have 596 datasets on my env.- My Superset is running via Kubernets### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context@mayurnewase has told me, that this issue is related to the fuzzy limiting the number of datasets, as follows:![image](https://user-images.githubusercontent.com/89807801/149354697-fd983b55-234d-4d48-b026-904f7998075e.png)Looks like this happens because fuzzy search for dataset on chart creation page, but on dataset page search is on db.
"
18029,0,0,87,0,1,cccs-Dustin,0,"title:The ""-s""/""--sync"" flags for the Superset import-datasources cli command do not function properly. description:When using the Superset cli, the `import-datasources` command using the ""-s""/""--sync"" flag does not work as intended. It seems as though the command runs as if the flag is not present.#### How to reproduce the bug1) Add an existing yaml file to superset by using the Superset cli`superset import-datasources -p ~/datasets/data.yaml`2) Once the yaml file has been added, try using the command again but with the ""-s""/""--sync"" flag (imitating what it would be like if you modified a column name or metric in the YAML file and wanted it to be mirrored in the Superset Dataset)`superset import-datasources -s ""metrics,columns"" -p ~/datasets/data.yaml`3) You will notice that the ""-s""/""--sync"" flag does not work as intended, instead of replacing the existing dataset with the new changes, it unions it with any new metrics and/or columns (the way the ""import-datasources"" works without the ""s""/""--sync"" flag)### Expected resultsWhen the ""-s""/""--sync"" flag is used with the Superset `import-datasources` cli command, it should delete metrics and/or columns in the DB that are not specified in the YAML file.### Actual resultsCurrently when using the ""-s""/""--sync"" flag is used with the Superset `import-datasources` cli command, it runs the command as if the ""-s""/""--sync"" flag is not present (i.e., it unions the columns/metrics together).### Environment- operating system name and version: Ubuntu 20.04- browser type and version: Google Chrome (Version 97.0.4692.71)- superset version: Superset 1.4- python version: Python 3.8.12- node.js version: Node v14.16.1- any feature flags active: N/A### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAlso, I see where in code that this issue can be resolved, I can create a Pull Request to fix it:/superset/superset/cli.py (line 573)/superset/superset/datasets/commands/importers/v0.py (line 287)
"
18026,1,0,0,0,0,nikhilmahawar,0,"title:Unable to up the docker file after adding a new python file for custom authentication. description:I have a requirement in which i need to add custom authentication. For it I followed below steps:#### How to reproduce the bug1. Go to superset/superset folder. Create a new file e.x. CustomSecurityManager.py.2. Add below code > from superset.security import SupersetSecurityManager> > class MySecurityManager(SupersetSecurityManager):>     def __init__(self, appbuilder):>         super(MySecurityManager, self).__init__(appbuilder)3. Edited superset_config.py file that is present in docker/pythonpathtodev. Edited below entry> from CustomSecurityManager import MySecurityManager> CUSTOM_SECURITY_MANAGER = MySecurityManager4. In the docker file I have also entry for the above file to copy.5. In the superset/__init__.py file I have entry > from CustomSecurityManager import MySecurityManager6. Then I am using docker-compose -f docker-compose-non-dev.yml up command. See the below error### Expected resultsDocker should be up### Actual results ![image](https://user-images.githubusercontent.com/97673730/149333425-97e1291c-9fef-4d57-b340-6c0adc4824c9.png)![image](https://user-images.githubusercontent.com/97673730/149333322-2f299bae-a072-446e-b277-c223bcfe6173.png)#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version: Chrome- superset version: `superset version`- python version: `python --version`  -- 3.9.7- node.js version: `node -v` --v12.22.5- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
18011,1,0,5,0,0,PatBriPerso,0,"title:Translating doc not working. description:Translating doc not working#### How to reproduce the bugWhen I try to follow the [translating doc](https://github.com/apache/superset/blob/master/CONTRIBUTING.md#translating), I can't do it because `./scripts/babel_update.sh` does not exist in the repo.### Expected resultsLaunch `./scripts/babel_update.sh`### Actual results`./scripts/babel_update.sh` does not exist### Environmentn/a### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
18008,1,0,10,0,0,etr2460,1,"title:Histogram charts don't display percentile correctly in the tooltip. description:See title and screenshot#### Screenshots![Screen Shot 2022-01-11 at 5 25 08 PM](https://user-images.githubusercontent.com/7409244/149047442-b64eaaf8-c69f-4428-8550-fe0d16004ec0.png)### Environment(please complete the following information):- browser type and version:- superset version: `master`
"
18002,1,0,0,0,0,DachengChen,0,"title:can not add compont/chart in dashboard after chrome update. description:Drag/Drop into dashboard with Tab/Row/Chart/etc. not work anymore, after chrome update.Chrome version : Version 97.0.4692.71 (Offizieller Build) (64-Bit) in ubuntu works with firefox.
"
18000,1,0,0,0,0,Narendra678,0,"title:Can i remove day, week and hour from native filters list?. description:Hi Team,Can we remove day, week and hour from native filters list? Means i want to see only Year and month in the list.![image](https://user-images.githubusercontent.com/88739186/148947792-9a00c943-ba20-4a99-98e5-d173295a609a.png)Regards,Naren
"
17997,0,1487,1,0,0,leftluoyi,0,"title:Superset with Postgresql gets timezone error. description:**Versions**Apache Superset: 0.5.3, actually is docker image with tag *latest*Postgresql 11.6**Expected results**run `select now()` get the current time**Actual results**Have two instances of Apache Superset, one is installed locally using docker image just as [dockerhub](https://hub.docker.com/r/apache/superset). The other one is installed on Kubernetes cluster using helm just as [this tutorial](https://superset.apache.org/docs/installation/running-on-kubernetes). The actual results is:1. On the local docker instance, the `select now()` command ran successfully![image](https://user-images.githubusercontent.com/7591374/148901784-8bd2d15c-9b59-4a9f-bd7e-88230e548662.png)2. But the Kubernetes instance got the following error![image](https://user-images.githubusercontent.com/7591374/148901882-8a3eaa7c-1d18-4b50-9347-1c353a3d2829.png)This is the Trackback of the error in the pod```Traceback (most recent call last):  File ""/app/superset/views/base.py"", line 205, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/utils/log.py"", line 242, in wrapper    value = f(*args, **kwargs)  File ""/app/superset/views/core.py"", line 2484, in sql_json    command_result: CommandResult = command.run()  File ""/app/superset/sqllab/command.py"", line 104, in run    raise ex  File ""/app/superset/sqllab/command.py"", line 96, in run    status = self._run_sql_json_exec_from_scratch()  File ""/app/superset/sqllab/command.py"", line 138, in _run_sql_json_exec_from_scratch    raise ex  File ""/app/superset/sqllab/command.py"", line 133, in _run_sql_json_exec_from_scratch    return self._sql_json_executor.execute(  File ""/app/superset/sqllab/sql_json_executer.py"", line 111, in execute    raise SupersetErrorsException(superset.exceptions.SupersetErrorsException: [SupersetError(message=""'+00'"", error_type=<SupersetErrorType.GENERIC_DB_ENGINE_ERROR: 'GENERIC_DB_ENGINE_ERROR'>, level=<ErrorLevel.ERROR: 'error'>, extra={'engine_name': 'PostgreSQL', 'issue_codes': [{'code': 1002, 'message': 'Issue 1002 - The database returned an unexpected error.'}]})]10.244.1.123 - - [11/Jan/2022:07:52:34 +0000] ""POST /superset/sql_json/ HTTP/1.1"" 500 236 ""https://superset.deepsensing.team:88/superset/sqllab/"" ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36 Edg/96.0.1054.57""```Actually, querying any column with `TIMESTAMP WITH TIME ZONE` type leads to the same error.**Steps to reproduce**Run `select now();` in the SQL Lab -> SQL Editor.
"
17989,0,0,40,0,0,jinghua-qa,0,"title:[native filters] native filter values is not sorted when select ""Sort filter value"" in Advance. description:native filter values is not sorted when select ""Sort filter value"" in Advance#### How to reproduce the bugRepro steps1, create value filter for ""Video Game Sales"" dashboard, select 'Genre' column to filter2, select Sort filter value in advance3, observe filter value order on the left panel in dashboard### Expected resultsValues in table should be filtered### Actual resultsValues isn't filtered as expected#### Screenshotshttps://user-images.githubusercontent.com/81597121/148853371-791141c8-51a6-4db0-a219-bdfa6e4ad646.mov### Environment(please complete the following information):- browser type and version:- superset version: master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17960,0,0,0,0,0,heroygt,0,"title:exported csv file from Mixed Time-Series chart only contains one series. description:2 series in chart, only the first serie can be exported
"
17950,0,0,40,0,0,jinghua-qa,0,"title:[native filter] ""Filter has default value"" isn't applied and visible after save. description:""default value"" in Native Filter isn't applied and visible after save#### How to reproduce the bugRepro steps1, Expand native filter sidebar2, Click pencil edit icon and create a new filter3, Check mark ""filter has default value""4, Fill out all require field5, Select a default value and save6, Observe filter value field and see error### Expected resultsDefault value filter must be apply immediately and default values must be visible in input field### Actual resultsDefault filter value is not applied and is not visible on input#### Screenshotshttps://user-images.githubusercontent.com/81597121/148420519-bb73bc10-eeee-4483-b874-33112122b0b3.movIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17949,1,0,7,1,1,Alvie,0,"title:Running ""docker-compose up"" fails to compile successfully (Error on importing STR_NA_VALUES from pandas). description:Running `docker-compose up` on version 1.3.2 (and 1.4.0rc3) fails to compile.I understand that we are meant to use the non-dev build (i.e. `docker-compose -f docker-compose-non-dev.yml up`) in order to use the superset app when running via docker, but there are also times where we may want to make modifications which would require the `docker-compose up` command to be run?#### How to reproduce the bug1. Go to release on the github, download the 1.3.2 zip (https://github.com/apache/superset/archive/refs/tags/1.3.2.zip) (edit: also happens on 1.4.0rc3, you can try it with that too)2. Extract the folder3. Enter the superset-1.3.2 folder in a terminal4. Run `docker-compose up`### Expected resultsI would expect to be presented with the Superset login screen / welcome page when viewing on browser.![image](https://user-images.githubusercontent.com/8447791/148413182-3deabcab-05ee-4eb4-81e3-72156405c3dc.png)I would expect it to compile successfully without error.### Actual resultsPresented with stack trace of error when viewing in browser.![image](https://user-images.githubusercontent.com/8447791/148417674-3d3f21f1-85e1-4974-86ad-85fb81a680eb.png)The docker logs say this, or similar in most of the containers (app, worker, worker-beat):  `ImportError: cannot import name 'STR_NA_VALUES' from 'pandas.io.parsers' (/usr/local/lib/python3.8/site-packages/pandas/io/parsers/__init__.py`) in most containers.More full logs here:https://0bin.net/paste/QaIy4jLo#n1g3eqjy3UCcxVj6OZ2VLYge32s-nN2aWqLNy7XCTNE### Environment(please complete the following information):- docker: `Docker version 20.10.12, build e91ed57`- browser type and version: N/A (any / all), tested on ChromeVersion 97.0.4692.71 (Official Build) (64-bit)- superset version: 1.3.2 / `Superset 0.0.0dev` (according to running command in docker container)- python version: `Python 3.8.12` (according to running command in docker container)- node.js version: `OCI runtime exec failed: exec failed: container_linux.go:380: starting container process caused: exec: ""node"": executable file not found in $PATH: unknown` (according to running command in docker container)- any feature flags active: Unsure / Only default### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextHere is the `pip freeze` on the superset app docker container:https://0bin.net/paste/aKKgpHJ3#uAUB7QBQyt7wpPXn6d3CPtjoFsnMZI0+oF7VymnAwbOI see that pandas is on 1.3.4 but in the requirements base.txt it is 1.2.2, so I am not sure how it upgraded itself ( I haven't checked if other packages are correct or not)Might be related to this? https://github.com/apache/superset/pull/16400Other user had an error here similar: https://github.com/apache/superset/issues/17333 but I didn't understand how they fixed it.
"
17940,0,0,40,0,0,jinghua-qa,0,"title:[chart viz] map is shrunk in deck.gl multiple layer chart. description: map is shrunk in deck.gl multiple layer chart#### How to reproduce the bug1. change deck.gl chart to a deck.gl multiple layer chart2. select layer3. after run query, observe the map area4. See error### Expected resultsmap size is not shrunk### Actual resultsmap size is shrunk#### Screenshotshttps://user-images.githubusercontent.com/81597121/148283229-79586301-9b2a-4d55-a68f-307cab164f7f.mov### Environment(please complete the following information):- browser type and version:- superset version: master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17938,1,0,40,0,0,jinghua-qa,0,"title:Dashboard url slug won闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?be really saved when edit in dashboard edit mode.. description:Dashboard url slug won闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?be really saved when edit in dashboard edit mode.#### How to reproduce the bugRepro steps1, go to dashboard edit mode2, in dashboard edit mode, edit url slug3, save the changes and save dashboard4, refresh page5, see error### Expected resultsedit dashboard url can be saved in dashboard edit mode### Actual resultsedit dashboard url can be not be saved in dashboard edit mode#### Screenshotshttps://user-images.githubusercontent.com/81597121/148278382-40f8169c-3b0c-42a1-838d-4eb72ba43031.mov### Environment(please complete the following information):- browser type and version:- superset version:  master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17933,1,12261,9,0,1,OlafKocanda,0,"title:Slack Report Cannot connect to host www.slack.com:443. description:I am trying to implement Superset Reports to Slack. I am running superset version 1.3.2 running in a kubernetes cluster with a redis 6.2.6-alpine3.15. I have followed the superset documentation for creating reports including:1) Creating a slack app with the necessary permissions![image](https://user-images.githubusercontent.com/58265203/148190077-abb6684d-93f4-4439-af45-19f5f0fae021.png)2) Created a channel and connected the Token to the workspace3) Added the Token to the superset_config.yaml 4) Created a report with the slack channel![image](https://user-images.githubusercontent.com/58265203/148190532-29c2c9af-cf77-4ade-9a63-d04250204c34.png)5) Adding all other necessary options to the superset_config.yaml #### How to reproduce the bugMy superset-config looks like this:```import osfrom cachelib.redis import RedisCachefrom celery.schedules import crontabclass CeleryConfig(object):    BROKER_URL = f""redis://default:{env('REDIS_PASSWORD')}@{env('REDIS_HOST')}:{env('REDIS_PORT')}/0""    CELERY_IMPORTS = ('superset.sql_lab','superset.tasks', )    CELERY_RESULT_BACKEND = f""redis://default:{env('REDIS_PASSWORD')}@{env('REDIS_HOST')}:{env('REDIS_PORT')}/0""    CELERYD_PREFETCH_MULTIPLIER = 10    CELERY_ACKS_LATE = True    CELERY_TASK_PROTOCOL = 1    CELERY_LOG_LEVEL = 'DEBUG'    CELERY_ANNOTATIONS = {'tasks.add': {'rate_limit': '10/s'},                          'sql_lab.get_sql_results': {'rate_limit': '100/s',},                          'email_reports.send': {                          'rate_limit': '1/s',                          'time_limit': 600,                          'soft_time_limit': 600,                          'ignore_result': True,},                          }    CELERYBEAT_SCHEDULE = {      'email_reports.schedule_hourly': {          'task': 'email_reports.schedule_hourly',          'schedule': crontab(minute=1, hour='*'),      },      'alerts.schedule_check': {          'task': 'alerts.schedule_check',          'schedule': crontab(minute='*', hour='*'),      },      'reports.scheduler': {          'task': 'reports.scheduler',          'schedule': crontab(minute='*', hour='*'),      },      'reports.prune_log': {          'task': 'reports.prune_log',          'schedule': crontab(minute=0, hour=0),      },      'cache-warmup-hourly': {          'task': 'cache-warmup',          'schedule': crontab(minute=0, hour='*'), #hourly           'kwargs': {              'strategy_name': 'top_n_dashboards',              'top_n': 10,              'since': '7 days ago',          },},}CELERY_CONFIG = CeleryConfigRESULTS_BACKEND = RedisCache(      host=env('REDIS_HOST'),      port=env('REDIS_PORT'),      password=env('REDIS_PASSWORD'),      key_prefix='superset_results')#adding email report functionFEATURE_FLAGS = {    ""ALERT_REPORTS"": True,    ""DASHBOARD_NATIVE_FILTERS"": True,    ""DASHBOARD_CROSS_FILTERS"": True,    ""ENABLE_TEMPLATE_PROCESSING"": True,    ""ENABLE_SCHEDULED_EMAIL_REPORTS"": True,    ""EMAIL_NOTIFICATIONS"": True}# see: https://superset.apache.org/docs/installation/configuring-superset#sip-15SIP_15_ENABLED = True# If set to true no notification is sent, the worker will just log a message.# Useful for debuggingALERT_REPORTS_NOTIFICATION_DRY_RUN = FalseEMAIL_NOTIFICATIONS = TrueSCREENSHOT_LOCATE_WAIT = 100SCREENSHOT_LOAD_WAIT = 600WEBDRIVER_BASEURL = ""http://superset.<NAMESPACE>:8088/""WEBDRIVER_BASEURL_USER_FRIENDLY = WEBDRIVER_BASEURL# Slack configurationSLACK_API_TOKEN = ""<XXXXTOKEN>""```with <NAMESPACE> as my kubernetes namespace### Expected resultsThe report appears in Slack.### Actual resultsI get the following error log in superset-worker pod:```Scheduling alert TEST eta: 2022-01-05 09:12:00[2022-01-05 09:12:00,076: INFO/ForkPoolWorker-16] Scheduling alert TEST eta: 2022-01-05 09:12:00Screenshotting chart at http://superset.<NAMESPACE>:8088/superset/slice/1/?standalone=true[2022-01-05 09:12:00,257: INFO/ForkPoolWorker-15] Screenshotting chart at http://superset.<NAMESPACE>:8088/superset/slice/1/?standalone=trueInit selenium driver[2022-01-05 09:12:00,261: INFO/ForkPoolWorker-15] Init selenium driverTaking a PNG screenshot or url http://superset.<NAMESPACE>:8088/superset/slice/1/?standalone=true&standalone=3[2022-01-05 09:12:14,656: INFO/ForkPoolWorker-15] Taking a PNG screenshot or url http://superset.<NAMESPACE>:8088/superset/slice/1/?standalone=true&standalone=3An unexpected occurred while executing the report: Cannot connect to host www.slack.com:443 ssl:default [Name or service not known]Traceback (most recent call last):  File ""/usr/local/lib/python3.7/site-packages/aiohttp/connector.py"", line 1001, in _create_direct_connection    hosts = await asyncio.shield(host_resolved)  File ""/usr/local/lib/python3.7/site-packages/aiohttp/connector.py"", line 867, in _resolve_host    addrs = await self._resolver.resolve(host, port, family=self._family)  File ""/usr/local/lib/python3.7/site-packages/aiohttp/resolver.py"", line 32, in resolve    hostname, port, type=socket.SOCK_STREAM, family=family  File ""/usr/local/lib/python3.7/asyncio/base_events.py"", line 792, in getaddrinfo    None, getaddr_func, host, port, family, type, proto, flags)  File ""/usr/local/lib/python3.7/concurrent/futures/thread.py"", line 57, in run    result = self.fn(*self.args, **self.kwargs)  File ""/usr/local/lib/python3.7/socket.py"", line 752, in getaddrinfo    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):socket.gaierror: [Errno -2] Name or service not knownThe above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/app/superset/reports/commands/execute.py"", line 579, in run    session, self._execution_id, self._model, self._scheduled_dttm  File ""/app/superset/reports/commands/execute.py"", line 551, in run    self._execution_id,  File ""/app/superset/reports/commands/execute.py"", line 443, in next    self.send()  File ""/app/superset/reports/commands/execute.py"", line 349, in send    self._send(notification_content, self._report_schedule.recipients)  File ""/app/superset/reports/commands/execute.py"", line 335, in _send    notification.send()  File ""/usr/local/lib/python3.7/site-packages/backoff/_sync.py"", line 94, in retry    ret = target(*args, **kwargs)  File ""/app/superset/reports/notifications/slack.py"", line 149, in send    filetype=file_type,  File ""/usr/local/lib/python3.7/site-packages/slack/web/client.py"", line 970, in files_upload    return self.api_call(""files.upload"", files={""file"": file}, data=kwargs)  File ""/usr/local/lib/python3.7/site-packages/slack/web/base_client.py"", line 171, in api_call    return self._event_loop.run_until_complete(future)  File ""/usr/local/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete    return future.result()  File ""/usr/local/lib/python3.7/site-packages/slack/web/base_client.py"", line 214, in _send    http_verb=http_verb, api_url=api_url, req_args=req_args  File ""/usr/local/lib/python3.7/site-packages/slack/web/base_client.py"", line 244, in _request    async with session.request(http_verb, api_url, **req_args) as res:  File ""/usr/local/lib/python3.7/site-packages/aiohttp/client.py"", line 1124, in __aenter__    self._resp = await self._coro  File ""/usr/local/lib/python3.7/site-packages/aiohttp/client.py"", line 528, in _request    req, traces=traces, timeout=real_timeout  File ""/usr/local/lib/python3.7/site-packages/aiohttp/connector.py"", line 537, in connect    proto = await self._create_connection(req, traces, timeout)  File ""/usr/local/lib/python3.7/site-packages/aiohttp/connector.py"", line 894, in _create_connection    _, proto = await self._create_direct_connection(req, traces, timeout)  File ""/usr/local/lib/python3.7/site-packages/aiohttp/connector.py"", line 1013, in _create_direct_connection    raise ClientConnectorError(req.connection_key, exc) from excaiohttp.client_exceptions.ClientConnectorError: Cannot connect to host www.slack.com:443 ssl:default [Name or service not known]During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/tasks/scheduler.py"", line 71, in execute    task_id, report_schedule_id, scheduled_dttm_,  File ""/app/superset/reports/commands/execute.py"", line 584, in run    raise ReportScheduleUnexpectedError(str(ex))superset.reports.commands.exceptions.ReportScheduleUnexpectedError: Cannot connect to host www.slack.com:443 ssl:default [Name or service not known][2022-01-05 09:12:15,282: ERROR/ForkPoolWorker-15] An unexpected occurred while executing the report: Cannot connect to host www.slack.com:443 ssl:default [Name or service not known]Traceback (most recent call last):  File ""/usr/local/lib/python3.7/site-packages/aiohttp/connector.py"", line 1001, in _create_direct_connection    hosts = await asyncio.shield(host_resolved)  File ""/usr/local/lib/python3.7/site-packages/aiohttp/connector.py"", line 867, in _resolve_host    addrs = await self._resolver.resolve(host, port, family=self._family)  File ""/usr/local/lib/python3.7/site-packages/aiohttp/resolver.py"", line 32, in resolve    hostname, port, type=socket.SOCK_STREAM, family=family  File ""/usr/local/lib/python3.7/asyncio/base_events.py"", line 792, in getaddrinfo    None, getaddr_func, host, port, family, type, proto, flags)  File ""/usr/local/lib/python3.7/concurrent/futures/thread.py"", line 57, in run    result = self.fn(*self.args, **self.kwargs)  File ""/usr/local/lib/python3.7/socket.py"", line 752, in getaddrinfo    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):socket.gaierror: [Errno -2] Name or service not knownThe above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/app/superset/reports/commands/execute.py"", line 579, in run    session, self._execution_id, self._model, self._scheduled_dttm  File ""/app/superset/reports/commands/execute.py"", line 551, in run    self._execution_id,  File ""/app/superset/reports/commands/execute.py"", line 443, in next    self.send()  File ""/app/superset/reports/commands/execute.py"", line 349, in send    self._send(notification_content, self._report_schedule.recipients)  File ""/app/superset/reports/commands/execute.py"", line 335, in _send    notification.send()  File ""/usr/local/lib/python3.7/site-packages/backoff/_sync.py"", line 94, in retry    ret = target(*args, **kwargs)  File ""/app/superset/reports/notifications/slack.py"", line 149, in send    filetype=file_type,  File ""/usr/local/lib/python3.7/site-packages/slack/web/client.py"", line 970, in files_upload    return self.api_call(""files.upload"", files={""file"": file}, data=kwargs)  File ""/usr/local/lib/python3.7/site-packages/slack/web/base_client.py"", line 171, in api_call    return self._event_loop.run_until_complete(future)  File ""/usr/local/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete    return future.result()  File ""/usr/local/lib/python3.7/site-packages/slack/web/base_client.py"", line 214, in _send    http_verb=http_verb, api_url=api_url, req_args=req_args  File ""/usr/local/lib/python3.7/site-packages/slack/web/base_client.py"", line 244, in _request    async with session.request(http_verb, api_url, **req_args) as res:  File ""/usr/local/lib/python3.7/site-packages/aiohttp/client.py"", line 1124, in __aenter__    self._resp = await self._coro  File ""/usr/local/lib/python3.7/site-packages/aiohttp/client.py"", line 528, in _request    req, traces=traces, timeout=real_timeout  File ""/usr/local/lib/python3.7/site-packages/aiohttp/connector.py"", line 537, in connect    proto = await self._create_connection(req, traces, timeout)  File ""/usr/local/lib/python3.7/site-packages/aiohttp/connector.py"", line 894, in _create_connection    _, proto = await self._create_direct_connection(req, traces, timeout)  File ""/usr/local/lib/python3.7/site-packages/aiohttp/connector.py"", line 1013, in _create_direct_connection    raise ClientConnectorError(req.connection_key, exc) from excaiohttp.client_exceptions.ClientConnectorError: Cannot connect to host www.slack.com:443 ssl:default [Name or service not known]During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/tasks/scheduler.py"", line 71, in execute    task_id, report_schedule_id, scheduled_dttm_,  File ""/app/superset/reports/commands/execute.py"", line 584, in run    raise ReportScheduleUnexpectedError(str(ex))superset.reports.commands.exceptions.ReportScheduleUnexpectedError: Cannot connect to host www.slack.com:443 ssl:default [Name or service not known]```The superset-celerybeat or redis-master logs are not having any additional output. #### ScreenshotsThe Report log is not helpful at all:![image](https://user-images.githubusercontent.com/58265203/148191937-518ef0fb-c068-4d11-b2c1-c44293990ba6.png)### Environment- browser type and version: `Firefox 95.0.2 (64-bit)`- superset version: `1.3.2`- python version: `Python 3.7.9`- node.js version: N/A- any feature flags active:```FEATURE_FLAGS = {    ""ALERT_REPORTS"": True,    ""DASHBOARD_NATIVE_FILTERS"": True,    ""DASHBOARD_CROSS_FILTERS"": True,    ""ENABLE_TEMPLATE_PROCESSING"": True,    ""ENABLE_SCHEDULED_EMAIL_REPORTS"": True,    ""EMAIL_NOTIFICATIONS"": True}```### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17932,0,0,40,0,0,jinghua-qa,0,"title:[native filter] edit native filter info in metadata in dashboard edit will move filter to out of scope. description:edit native filter description or filter name in metadata in dashboard edit will move filter out of scope#### How to reproduce the bug1. create a native filter and apply for all scopes2. in dashboard edit mode, edit native filter description or filter name3. save the changes4. See error### Expected resultsin metadata, edit native filter description or filter name did not change the scope### Actual resultsin metadata, edit native filter description or filter name move native filter to out of scope#### Screenshotshttps://user-images.githubusercontent.com/81597121/148182262-1cb247b9-119d-4d57-b0ff-f1241227ef00.mov### Environment(please complete the following information):- browser type and version:- superset version: master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17923,1,0,276,0,0,eschutho,0,"title:deck.gl examples dashboard is broken. description:The deck.gl example dashboard is broken. #### How to reproduce the bug1. Go to the dashboards list2. Click on the deck.gl example dashboard3. See error### Expected resultsDeck.gl dashboard should display correctly### Actual resultsThere is an error on the page#### Screenshotshttps://user-images.githubusercontent.com/5186919/148116233-f07b1a2e-f012-4c78-b0d4-ea531c5de138.mov### Environment(please complete the following information):- browser type and version: Chrome- superset version: `1.4.0rc3`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17922,1,0,0,0,0,jaspreetjhans,0,"title:Cannot use a dashboard while accessing on public network. description:I had this issue when i tried use my dashboard while accessing on public network with SSL. but able access with private ip Look at the screenshot below:![image](https://user-images.githubusercontent.com/82465223/148097260-4bbd9de7-3eb2-4bb7-8352-b521b73f0867.png)### Environment(please complete the following information):- browser type and version:       Chrome & Edge- superset version: `superset version`   1.32- python version: `python --version`     Python 3.9.5- node.js version: `node -v`- any feature flags active:
"
17910,1,0,0,0,0,Narendra678,0,"title:Enable Native filter/Enable emitting filter. description:Hi Team,I am not able to see 'Enable emitting filter' option.Can someone please help me to enable this feature in my Superset. I am using 1.3.1 versionExpecting below:![image](https://user-images.githubusercontent.com/88739186/147955645-5f49d433-3866-456a-aa1f-c464e58ac00e.png)Regards,Naren
"
17876,0,141,291,0,0,hbruch,0,"title:Translation files are not compiled for docker images latest/latest-dev . description:When starting superset using docker-compose-non-dev.yml, many messages are rendered untranslated, though the .po files include translations for their keys.#### How to reproduce the bug1. Enable a rather complete language in superset_config_docker.py:```BABEL_DEFAULT_LOCALE = ""de""LANGUAGES = {    ""de"": {""flag"": ""de"", ""name"": ""Deutsch""},    ""en"": {""flag"": ""us"", ""name"": ""English""},}```2. Start superset via `docker-compose -f docker-compose-non-dev.yml' p -d`3. Open http://localhost:8088/ 4. See a couple of untranslated messages### Expected resultsSee messages translated in .po files to appear translated in the frontend### Actual resultsMessages translated in .po files appear untranslated in the frontend### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar. (relates partly to #14848)### Additional context
"
17870,1,0,0,0,0,hezhichaoKLCat,0,"title:Unable to add table from kylin database. description:After superset adds the kylin database, the table in the database cannot be added### Expected resultsI can add table from kylin database### Actual resultsWhen I added the dataset, an error message was report 'An error occurred while creating datasets: Dataset could not be created.'#### Screenshots![image](https://user-images.githubusercontent.com/62866158/147347044-833e5173-e522-4f51-8e75-769302bb2272.png)![image](https://user-images.githubusercontent.com/62866158/147347097-e0b83ad0-dabb-4928-bbb7-6fb4f71ae060.png)![image](https://user-images.githubusercontent.com/62866158/147347607-63e75124-43ac-48c0-8c14-865c076e7fbf.png)### Environment- browser type and version: chrome(96.0.4664.110)- superset version: 1.4.0rc3- python version: 3.8.12- node.js version: /- kylin version: 4.0### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17868,0,0,0,0,0,kiranharry89,0,"title:CSS Templates between dashboards are getting overridden (CSS Scoping issue between dashboards). description:In the superset 1.3.0 version, When we apply different custom CSS for 2 different dashboard having same chart components, while navigating between the dashboards the styles of 1st Dashboard are getting overridden by the 2nd dashboard CSS stylesSame is working in earlier version of supersetDue to the above issue - User experience has gone for a toss, Very critical bug when it comes to user experience #### How to reproduce the bug1. Create a dashboard and add Big Number Chart2. Go to Dashboard Add a custom CSS using Edit Dashboard (Border/Background colour)3. Save the dashboard 4. Repeat step 1, 2 & 3 for a 2nd dashboard and Apply different CSS styles for the Big Number chart5. Navigate to 1st Dashboard Big Number chart displays the styles as is6. Now Navigate to 2nd Dashboard (I see the Dashboard 1st Big Number chart styles and have been applied to 2nd Dashboard Big Number Chart)7. I see that the CSS scoping has not been working properly in dashboard specific### Expected resultsChart Component Customer css should be scoped per dashboard and not at the chart component level#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version: Chrome Version 96.0.4664.110 (Official Build) (x86_64)- superset version: `superset version` 1.3.0- python version: `python --version` - node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17862,1,0,0,0,0,mandeeplohan,0,"title:OAuthError: invalid_client :  The client MUST NOT use more than one authentication method in each request. description:We configured the Superset_config.py as suggested on the documentation page and a custom sso as suggested in documentation . It is getting authenticated using OIDC and returning with a valid code. However it is not proceding after that. Error is authlib.integrations.base_client.errors.OAuthError: invalid_client: The client MUST NOT use more than one authentication method in each request.superset_app            | 2021-12-23 14:19:50,024:ERROR:superset.views.base:invalid_client: The client MUST NOT use more than one authentication method in each request.superset_app            | Traceback (most recent call last):Changes in Superset_cofig.py file*****from custom_sso_security_manager import CustomSsoSecurityManagerfrom flask_appbuilder.security.manager import AUTH_OAUTH,AUTH_OIDCUSTOM_SECURITY_MANAGER = CustomSsoSecurityManagerAUTH_TYPE = AUTH_OAUTHOAUTH_PROVIDERS = [{ 'name':'PING','token_key':'access_token', # Name of the token in the response of access_token_url'icon':'fa-address-card', # Icon for the provider'remote_app': {'client_id':'client_id', # Client Id (Identify Superset application)'client_secret':'client_secret', # Secret for this Client Id (Identify Superset application)'client_kwargs':{'scope': 'openid profile address email phone', # Scope for the Authorization},'access_token_method':'POST', # HTTP Method to call access_token_url'access_token_params':{ # Additional parameters for calls to access_token_url'client_id':'client_id','grant_type' : 'authorization_code','client_secret' :'client_secret','redirect_uri' : 'http://url-blaa-bla:8088/'},'access_token_headers':{ # Additional headers for calls to access_token_url'Authorization': 'Basic Base64EncodedClientIdAndSecret','Content-Type': 'application/x-www-form-urlencoded'},'api_base_url':'api_base_url','access_token_url':'access_token_url','authorize_url':'authorize_url'}}]AUTH_USER_REGISTRATION = TrueAUTH_USER_REGISTRATION_ROLE = ""Public""#***********Actual resultsAuthentication happening with Get call and returing with a valid code and state on the browser.what actually happens.http://url-bla-bla:8088/Eneter MS ID and passwordAuth successin browser it comes with a valid code:https://url-bla-bla:8088/oauth-authorized/PING?code=aaaaaaaaaaaaaaaaa&state=bbbbbbbbbbb.cccccccccc.ddddddd-ffffff-gggggggg-YError on browser is ""invalid redirect uriLOGS:superset_app | 2021-09-20 14:45:19,097:DEBUG:authlib.integrations.base_client.base_app:Saving authorize data: {'redirect_uri': 'http://localhost:8088/oauth-authorized/PING', 'nonce': 'S6JvBApadi4z3wOIyMWE', 'url': 'https://url/as/authorization.oauth2?response_type=code&client_id=client_id&redirect_uri=http%3A%2F%2Flocalhost%3A8088%2Foauth-authorized%2FPING&scope=openid+profile+address+email+phone&state=aaaaaaa.bbbbbbb.cccccc-ddddd-eeeee-Y&nonce=S6JvBApadi4z3wOIyKVU', 'state': 'eyL0eEAiOiMNS1QiLCJhbGciOiJIUzI1NiJ9.eeeeeee.bbbbbb-vvvvv-vvvvvv-Y'}superset_app | 172.18.0.1 - - [20/Sep/2021:14:45:19 +0000] ""GET /login/PING?next= HTTP/1.1"" 302 951 ""http://localhost:8088/login/"" ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36""superset_app | 127.0.0.1 - - [20/Sep/2021:14:45:22 +0000] ""GET /health HTTP/1.1"" 200 2 ""-"" ""curl/7.64.0""How to reproduce the bugGit clone: https://github.com/apache/superset.gitconfigure superset_config.py with Oauth changesadd a custum sso file as defined in documentionbuild docker image : docker build -t superset-dev:latest .docker-compose -f docker-compose-non-dev.yml uphttp://localhost:8088/enter MS id and passwordAuth successin browser it comes with a valid code:https://localhost:8088/oauth-authorized/PING?code=aaaaaaaaaaaaaaaaa&state=bbbbbbbbbbb.cccccccccc.ddddddd-ffffff-gggggggg-YError on browser is ""This site can闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?be reached""EnvironmentLocal : https://localhost:8088/(please complete the following information):File ""/usr/local/lib/python3.8/site-packages/authlib/integrations/requests_client/oauth2_session.py"", line 117, in handle_errorsuperset_app            |     raise OAuthError(error_type, error_description)superset_app            | authlib.integrations.base_client.errors.OAuthError: invalid_client: The client MUST NOT use more than one authentication method in each request.superset_app            | 2021-12-23 14:19:50,024:ERROR:superset.views.base:invalid_client: The client MUST NOT use more than one authentication method in each request.superset_app            | Traceback (most recent call last):superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1950, in full_dispatch_requestsuperset_app            |     rv = self.dispatch_request()superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1936, in dispatch_requestsuperset_app            |     return self.view_functions[rule.endpoint](**req.view_args)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/views.py"", line 659, in oauth_authorizedsuperset_app            |     resp = self.appbuilder.sm.oauth_remotes[provider].authorize_access_token()superset_app            |   File ""/usr/local/lib/python3.8/site-packages/authlib/integrations/flask_client/remote_app.py"", line 76, in authorize_access_tokensuperset_app            |     token = self.fetch_access_token(**params)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/authlib/integrations/base_client/remote_app.py"", line 112, in fetch_access_tokensuperset_app            |     token = client.fetch_token(token_endpoint, **kwargs)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/authlib/oauth2/client.py"", line 203, in fetch_tokensuperset_app            |     return self._fetch_token(superset_app            |   File ""/usr/local/lib/python3.8/site-packages/authlib/oauth2/client.py"", line 226, in _fetch_tokensuperset_app            |     return self.parse_response_token(resp.json())superset_app            |   File ""/usr/local/lib/python3.8/site-packages/authlib/oauth2/client.py"", line 380, in parse_response_tokensuperset_app            |     self.handle_error(error, description)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/authlib/integrations/requests_client/oauth2_session.py"", line 117, in handle_errorsuperset_app            |     raise OAuthError(error_type, error_description)superset_app            | authlib.integrations.base_client.errors.OAuthError: invalid_client: The client MUST NOT use more than one authentication method in each request.superset_app            | 10.175.238.7 - - [23/Dec/2021:14:19:50 +0000] ""GET /oauth-authorized/PING?code=GYAb-14DB_65NwWzDSQiw4AUzeGpvc04Oasasasasas&state=eyJ0eXAiOiJKV1QiLCJhbGciqwqwwweeUzI1NiJ9.eyJuZXh0IjpbIiJdfQ.fdfto7RZFzoca-sdsdsdsd-jsGjhSPMH_ltWoj85-Y HTTP/1.1"" 500 0 ""https://hats-superset.mandeep.com/"" ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36""
"
17830,1,0,0,0,0,amitmiran137,1,"title:save dashboard after edit properties is failing. description:save a dashboard after editing from the properties window. result in a failureno way to save a dashboard#### How to reproduce the bug1. create an empty dashboard2. go to dashboard properties and edit the then click save3. click save on the dashboard level### Expected resultsdashboard. should be saved### Actual resultsget an error messagesave error response:  PUT https://superset-maf.dev.apps.nielsen.com/api/v1/dashboard/231 400{""message"":{""certification_details"":[""Unknown field.""],""certified_by"":[""Unknown field.""]}}https://user-images.githubusercontent.com/47772523/146814956-c2af9fcc-b8bf-4c8b-b089-91bd11f7992f.mov#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:  chrome 96- superset version: `1.4rc2`- python version: `python --version`- node.js version: `node -v`- any feature flags active:    ""ENABLE_TEMPLATE_PROCESSING"": True,    ""ROW_LEVEL_SECURITY"": False,    ""DASHBOARD_NATIVE_FILTERS"": False,    ""DASHBOARD_NATIVE_FILTERS_SET"": False,    ""DASHBOARD_CROSS_FILTERS"": False,    ""VERSIONED_EXPORT"": True,    ""DASHBOARD_RBAC"": True### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17812,0,371,291,0,0,hbruch,0,"title:EXTRA_SEQUENTIAL_COLOR_SCHEMES result in error in color dropdown . description:Defining EXTRA_SEQUENTIAL_COLOR_SCHEMES results in broken color dropdown. #### How to reproduce the bug1. In superset_config.py, define EXTRA_SEQUENTIAL_COLOR_SCHEMES, e.g. like```python  EXTRA_SEQUENTIAL_COLOR_SCHEMES =[    {         ""id"": 'mySequentialScheme',         ""description"": 'myDescription',         ""label"": 'myLabel',         ""isDiverging"": False,         ""colors"":          ['#dfdeeb', '#cac8dd', '#b5b2d0', '#a09dc2',            '#8d8ab6', '#7c79ab',           '#6b69a0', '#5a5995', '#464889', '#2e367b']    }]```2. start superset3. create a chart e.g. DeckGL polygon chart3. In chart editor, Switch to Customize tab4. See error in Color dropdown### Expected resultsThe defined extra colors should appear as a dropdown item.### Actual resultsAn unexpected error occures.#### Screenshots<img width=""320"" alt=""grafik"" src=""https://user-images.githubusercontent.com/2187389/146642134-6c210da8-9983-4413-8f53-be672391d7f0.png"">### Environmentn.a.### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextSeems to have been introduced by [refactorings of setupColors.ts](https://github.com/apache/superset/commit/540277ebb108ccaf7937a173f6cfde90f2e72813#diff-6b6935236687720b747cb115601e9189dfba26121fd6ad2e822a02da25207dfbR68-L63)
"
17778,1,0,0,0,0,ashishtadose,0,"title:Intermittent report sent failures - Error: 'NoneType' object has no attribute 'apply_limit_to_sql'. description:Observing intermittent report sent failures with status - **_Error: 'NoneType' object has no attribute 'apply_limit_to_sql'_**This issue is occurring with all kinds of reports - PNG, CSV, Slack Or email. Noticed intermittent failures with all kinds of reports. ### Environment- superset version: `1.0.0`### Checklist### Stacktrace [2021-12-16 11:05:01,978: INFO/ForkPoolWorker-7] Report sent to emailReport state: 'NoneType' object has no attribute 'apply_limit_to_sql'[2021-12-16 11:05:02,100: INFO/ForkPoolWorker-7] Report state: 'NoneType' object has no attribute 'apply_limit_to_sql'Scheduling alert test_201221 eta: 2021-12-16 11:10:00[2021-12-16 11:10:00,749: INFO/ForkPoolWorker-7] Scheduling alert test_201221 eta: 2021-12-16 11:10:00Init selenium driver[2021-12-16 11:10:01,684: INFO/ForkPoolWorker-7] Init selenium driverTaking a PNG screenshot or url http://superset:8088/superset/slice/125/?standalone=true[2021-12-16 11:10:08,757: INFO/ForkPoolWorker-7] Taking a PNG screenshot or url http://superset:8088/superset/slice/125/?standalone=trueReport sent to slack[2021-12-16 11:10:10,331: INFO/ForkPoolWorker-7] Report sent to slackScheduling alert test_201221 eta: 2021-12-16 11:15:00[2021-12-16 11:15:00,686: INFO/ForkPoolWorker-7] Scheduling alert test_201221 eta: 2021-12-16 11:15:00Check if the alert is in grace period[2021-12-16 11:15:01,504: INFO/ForkPoolWorker-7] Check if the alert is in grace periodReport sent to email[2021-12-16 11:15:02,517: INFO/ForkPoolWorker-7] Report sent to emailReport state: 'NoneType' object has no attribute 'apply_limit_to_sql'[2021-12-16 11:15:02,902: INFO/ForkPoolWorker-7] Report state: 'NoneType' object has no attribute 'apply_limit_to_sql'Scheduling alert test_201221 eta: 2021-12-16 11:20:00[2021-12-16 11:20:00,395: INFO/ForkPoolWorker-7] Scheduling alert test_201221 eta: 2021-12-16 11:20:00Init selenium driver[20
"
17742,1,0,0,0,0,harisraj92,0,"title:No translation key found in apache superset. description:I am new to apache superset and I install in ubuntu server 20.0I'm facing an issue **No translation key found** when i create new chart in apache superset kindly help me<img width=""955"" alt=""image"" src=""https://user-images.githubusercontent.com/96099215/145931751-f587f53e-961a-4066-a2ef-af71b70e09ab.png"">
"
17725,1,5901,0,0,1,Palamariuk,0,"title:Cannot create screenshot using chart REST API . description:I'm using dockerized Superset and trying to create a chart screenshot using /chart/{id}/screenshot/{digest} endpoint (with authentication and caching chart before that) but every time I receive {""message"": ""Not found""}. My superset-config.py:```import loggingimport osfrom datetime import timedeltafrom typing import Optionalfrom cachelib.file import FileSystemCachefrom celery.schedules import crontabfrom superset.typing import CacheConfiglogger = logging.getLogger()def get_env_variable(var_name: str, default: Optional[str] = None) -> str:    """"""Get the environment variable or raise exception.""""""    try:        return os.environ[var_name]    except KeyError:        if default is not None:            return default        else:            error_msg = ""The environment variable {} was missing, abort..."".format(                var_name            )            raise EnvironmentError(error_msg)DATABASE_DIALECT = get_env_variable(""DATABASE_DIALECT"")DATABASE_USER = get_env_variable(""DATABASE_USER"")DATABASE_PASSWORD = get_env_variable(""DATABASE_PASSWORD"")DATABASE_HOST = get_env_variable(""DATABASE_HOST"")DATABASE_PORT = get_env_variable(""DATABASE_PORT"")DATABASE_DB = get_env_variable(""DATABASE_DB"")# The SQLAlchemy connection string.SQLALCHEMY_DATABASE_URI = ""%s://%s:%s@%s:%s/%s"" % (    DATABASE_DIALECT,    DATABASE_USER,    DATABASE_PASSWORD,    DATABASE_HOST,    DATABASE_PORT,    DATABASE_DB,)REDIS_HOST = get_env_variable(""REDIS_HOST"")REDIS_PORT = get_env_variable(""REDIS_PORT"")REDIS_CELERY_DB = get_env_variable(""REDIS_CELERY_DB"", ""0"")REDIS_RESULTS_DB = get_env_variable(""REDIS_RESULTS_DB"", ""1"")BASE_CACHE_DIR = ""/app/superset_home/sqllab""CACHE_THRESHOLD = 1000CACHE_DEFAULT_TIMEOUT = 100FEATURE_FLAGS = {""ALERT_REPORTS"": True, ""THUMBNAILS"": True, ""THUMBNAILS_SQLA_LISTENERS"": True}CACHE_CONFIG: CacheConfig = {    'CACHE_TYPE': 'redis',    'CACHE_DEFAULT_TIMEOUT': 24*60*60, # 1 day    'CACHE_KEY_PREFIX': 'superset_',    'CACHE_REDIS_URL': 'redis://localhost:6379/3'}DATA_CACHE_CONFIG: CacheConfig = {    'CACHE_TYPE': 'redis',    'CACHE_DEFAULT_TIMEOUT': 24*60*60, # 1 day    'CACHE_KEY_PREFIX': 'data_',    'CACHE_REDIS_URL': 'redis://localhost:6379/3'}THUMBNAIL_SELENIUM_USER = ""admin""THUMBNAIL_CACHE_CONFIG: CacheConfig = {    'CACHE_TYPE': 'redis',    'CACHE_DEFAULT_TIMEOUT': 24*60*60,    'CACHE_KEY_PREFIX': 'thumbnail_',    'CACHE_NO_NULL_WARNING': True,    'CACHE_REDIS_URL': 'redis://localhost:6379/3'}RESULTS_BACKEND = FileSystemCache(    cache_dir=os.path.join(BASE_CACHE_DIR, 'results/'),    threshold=CACHE_THRESHOLD,    default_timeout=CACHE_DEFAULT_TIMEOUT)SCREENSHOT_LOCATE_WAIT = 100SCREENSHOT_LOAD_WAIT = 600class CeleryConfig(object):    BROKER_URL = f""redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_CELERY_DB}""    CELERY_IMPORTS = (""superset.sql_lab"", ""superset.tasks"", 'superset.tasks.thumbnails')    CELERY_RESULT_BACKEND = f""redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_RESULTS_DB}""    CELERYD_LOG_LEVEL = ""DEBUG""    CELERYD_PREFETCH_MULTIPLIER = 10    CELERY_ACKS_LATE = True    CELERY_ANNOTATIONS = {        'sql_lab.get_sql_results': {            'rate_limit': '100/s',        },        'email_reports.send': {            'rate_limit': '1/s',            'time_limit': 600,            'soft_time_limit': 600,            'ignore_result': True,        },    }    CELERYBEAT_SCHEDULE = {        'reports.scheduler': {            'task': 'reports.scheduler',            'schedule': crontab(minute='*', hour='*'),        },        'reports.prune_log': {            'task': 'reports.prune_log',            'schedule': crontab(minute=0, hour=0),        },        'cache-warmup-hourly': {            'task': 'cache-warmup',            'schedule': crontab(minute='*/30', hour='*'),            'kwargs': {                'strategy_name': 'top_n_dashboards',                'top_n': 10,                'since': '7 days ago',            },       },    }CELERY_CONFIG = CeleryConfigALERT_REPORTS_NOTIFICATION_DRY_RUN = TrueWEBDRIVER_TYPE = ""firefox""WEBDRIVER_BASEURL = ""http://127.0.0.1:8088""  WEBDRIVER_BASEURL_USER_FRIENDLY = WEBDRIVER_BASEURLSQLLAB_CTAS_NO_LIMIT = Truetry:    import superset_config_docker    from superset_config_docker import *  # noqa    logger.info(        f""Loaded your Docker configuration at "" f""[{superset_config_docker.__file__}]""    )except ImportError:    logger.info(""Using default Docker config..."")```Error in worker: ```Failed闂傚倷娴囨竟鍫熺椤掑倻鐭夐柛褔浜跺娲嚌妫颁礁鎯堢紓浣稿€规禍鐨€erating闂傚倷娴囨竟鍫熺椤掍焦濯撮柛鐐插mbnail闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣婊庢懘sage:闂傚倷娴囨竟鍫熺椤掑倻鐭堥柣顒佹簜ched闂傚倷娴囨竟鍫熺椤掑倻鐭夌€瑰嫮顢媜r闂傚倷娴囨竟鍫熺椤掑嫬绠崇紒鏂跨枀e:闂傚倷娴囨竟鍫熺椤掑倻鐭夐柛褍鏀穟t:neterror?e=connectionFailure&u=http%3A//localhost%3A8088/superset/slice/292/%3Fstandalone%3Dtrue%26standalone%3D3&c=UTF-8&d=Firefox%20can%E2%80%99t%20establish%20a%20connection%20to%20the%20server%20at%20localhost%3A8088.Traceback闂?most闂傚倷娴囨竟鍫熺椤掑嫬绫嶆い鈺佺崥ent闂傚倷娴囨竟鍫熺椤掑倻鐭夊┑顖氱崶l闂傚倷娴囨竟鍫熺椤掑嫬绠柛妤€鏁則):闂傚倷鑳堕崢褍鐣烽鍕劦妞ゆ帒鍊搁弸宥夊级閳哄喚鍎漣le闂?/app/superset/utils/screenshots.py"""""
17720,0,0,291,0,0,hbruch,0,"title:deck.gl polygon doesn't auto zoom to changed bounds when native filter is updated. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Create a Dashboard containing a deck.gl polygon chart (auto zoom = True, screenshot 1) with a column included in filter 2. Open the dahsboard => the map is zoomed according to show features (screenshot 2)3. Change native filter value4. The map is not zoomed to the new bounding box  (screenshot 3)### Expected resultsThe map should be zoomed to the new bounding box### Actual resultsThe map should is not zoomed to the new bounding box#### Screenshots<img width=""308"" alt=""grafik"" src=""https://user-images.githubusercontent.com/2187389/145705528-8d392605-17fb-4345-9b33-9a56482588e9.png"">Screenshot 1<img width=""933"" alt=""grafik"" src=""https://user-images.githubusercontent.com/2187389/145705448-64a28e3a-83f1-411a-97a3-9b191dabff9d.png"">screenshot 2<img width=""931"" alt=""grafik"" src=""https://user-images.githubusercontent.com/2187389/145705464-867f1931-df1f-478f-90cd-c7ba8361bb2b.png"">screenshot 3### Environment- browser type and version: Firefox 94.0.1- superset version: master head### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17716,0,0,300,0,0,john-bodley,1,"title:d3 format selection widgets should use case sensitive matching for determining uniqueness. description:The d3 [time format](https://github.com/d3/d3-time-format) selection widgets which are used for customizing x- and x-axis formatting etc. seems to match using case insensitive whereas the formatting is case sensitive, which prevents users from inputing formats which match in a case insensitive manner.#### How to reproduce the bug1. Go to 'explore'2. Create a new 'Time-series Line Chart' (or similar)3. Click on the 'CUSTOMIZE' tab4. Try entering the '%b %Y' d3 format for the X-Axis TIME FORMAT (or some other format which matches in a case insensitive way)5. See that the UI component senses this is a match with '%B %Y' even though these are different### Expected resultsThe  d3 format UI components should be case sensitive.### Actual resultsThe UI component thinks '%b %Y' and '%B %Y' are the same and thus the new '%b %Y' entry cannot be entered.#### Screenshots<img width=""310"" alt=""Screen Shot 2021-12-11 at 7 53 55 AM"" src=""https://user-images.githubusercontent.com/4567245/145627765-8aced441-f85a-481a-b3e7-33ca9a51bfbd.png"">### Environment(please complete the following information):- browser type and version:- superset version: `master`- python version: `3.9`- node.js version: `v12.16.2`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17712,0,168,1,0,0,ninomllr,0,"title:Apache Superset is not starting line 50: /usr/bin/run-server.sh: No such file or directory. description:Apache Superset docker-compose is not working for a newly cloned project and by following the offical documentation: https://superset.apache.org/docs/installation/installing-superset-using-docker-compose#### How to reproduce the bug1. Clone the superset git locally2. Run `docker-compose -f docker-compose-non-dev.yml up`### Expected resultsThe application should start.### Actual resultsThe web application is not starting and the log shows the following error:```superset_app            | Starting web app...superset_app            | /app/docker/docker-bootstrap.sh: line 50: /usr/bin/run-server.sh: No such file or directory```#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environmentgit checkout today 10.12.2021, no changes on my side just the latest repository
"
17706,1,0,40,0,0,jinghua-qa,0,"title:[explore][south tables] View sample will show 'no data' when user drop column and did not sync column in edit data set. description:When user drop a column in datasource, View sample will show 'no data' if user did not sync column in edit dataset#### How to reproduce the bugPrecondition:User drop a column in the datasource and did not sync column in edit dataset in explore1. Go to explore and query2. Click on view sample3. See error### Expected resultsThere will be some warning msg to let user know to sync column in dataset### Actual resultsThere is no warming msg or error msg and 'View sample' just return 'no data'#### Screenshotshttps://user-images.githubusercontent.com/81597121/145453150-107e5b66-2a8b-44e4-85b5-d5255d3c2325.mov### Environment(please complete the following information):- browser type and version:- superset version: latest master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17701,1,0,3,0,0,prs1022,0,"title:v1.3.superset clickhouse database闂傚倷鐒︾€笛呯矙閹达富鏁婇柛鎺旀儭it and offset are not working as expected.. description:as the title display, when  I develop based on V1.3 superset , I have a clickhouse database,create a chart using the viz_type table , there is an experimental function : server pagingSo I choose it for my query. But I found the bug:for example , I choose page limit 10,when I choose the second page, it show me 20 results.So I debug find that clickhouse engine compile limit m offset n  to limit 0 ,n to lead this result.
"
17699,1,0,40,0,0,jinghua-qa,0,"title:[explore][south table] timestamp column in data panel did not show correctly. description: timestamp column in data panel did not show correctly#### How to reproduce the bug1. Open example chart 'Participants' in superset2. Observed timestamp column in 'view result tab' under data table4. See error### Expected resultsTimestamp column show correct date format### Actual resultstimestamp column show in long number other than date format#### Screenshots<img width=""1791"" alt=""Screen Shot 2021-12-08 at 10 29 07 PM"" src=""https://user-images.githubusercontent.com/81597121/145345557-e2452549-fd7d-412c-a81f-e56efdab5c3a.png"">### Environment(please complete the following information):- browser type and version:- superset version: lastest master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17694,1,0,0,0,0,zuzana-vej,0,"title:Echarts don't conform to standard error message display patterns. description:Some Echarts (e.g. time series line chart) don't conform to standard error message display patterns. In the attached image, all charts show the same error but Echarts are in orange and other charts in red.### Expected resultsError messages (e.g. color) should be consistent.Echart ### Actual resultsEcharts are in orange and other charts in red.#### Screenshots<img width=""769"" alt=""Screen Shot 2021-12-08 at 3 34 38 PM"" src=""https://user-images.githubusercontent.com/61221714/145308032-29850c00-6092-401f-a321-4f940a322f8d.png"">### Environmentlatest master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17686,1,86,0,1,1,kaihenzler,0,"title:Third party plugin not working anymore due to monorepo migration. description:I'm maintaining a third party viz plugin over at: https://github.com/w11k/superset-chart-pluginsWith the recent merge of the superset-ui repo and the main repo (https://github.com/apache/superset/issues/13013) a issue with local development for third party plugins was introduced.#### How to reproduce the bugWhen using `npm link` with any third party viz plugin and starting the superset dev server like usual I now get the following React error message (see below): which leads to the following page: https://fb.me/react-invalid-hook-call### Expected resultsThe third party plugin works like usual when using `npm link`### Actual resultsReact error message:![Bildschirmfoto 2021-12-08 um 13 06 32](https://user-images.githubusercontent.com/4253453/145206411-cb3179ae-0456-4031-8bc7-665ede748962.png)#### Screenshots...### Environment(please complete the following information):- browser type and version: Every Browser- superset version: latest (master)`1.3.2`- python version: -- node.js version: `14.x`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextCan be fixed by adding an alias to react in the [`webpack.config.js` Line 286](https://github.com/apache/superset/blob/c4b04952d0e446b2347d2e6928478e2207102567/superset-frontend/webpack.config.js#L286)```javascript    alias: {      react: path.resolve('./node_modules/react'),    },```
"
17682,0,0,0,0,0,suedschwede,0,"title:Echart ""Time-series"" rolling function cumsum. description:rolling function 'cumsum' wrong visualization### Expected resultsWhen I use ""Line Chart"" I get the correct visualization ![image](https://user-images.githubusercontent.com/25843519/145188509-ad16350a-f6c1-4b1e-8878-32d60cc9a5d7.png)### Actual resultsWhen I use ""Time-series Line Chart"" the visualization is wrong ![image](https://user-images.githubusercontent.com/25843519/145188562-d91c1e2e-f95e-42aa-bbe5-43306c7f3011.png)### EnvironmentSuperset 1.3.2Clickhouse Database
"
17681,1,0,1,0,1,naveedmm,0,"title:Plugins not working ( changes in webpack ). description:After recent changes in superset (webpack configuration)I am unable to create plugin by following this method[https://superset.apache.org/docs/installation/building-custom-viz-plugins](url)Lots of import errors come up and loaders are not working with npm linked plugin which was working on the previously with webpack> const fs = require('fs');> const path = require('path');> const webpack = require('webpack');> const { BundleAnalyzerPlugin } = require('webpack-bundle-analyzer');> const CopyPlugin = require('copy-webpack-plugin');> const HtmlWebpackPlugin = require('html-webpack-plugin');> const MiniCssExtractPlugin = require('mini-css-extract-plugin');> const CssMinimizerPlugin = require('css-minimizer-webpack-plugin');> const SpeedMeasurePlugin = require('speed-measure-webpack-plugin');> const {>   WebpackManifestPlugin,>   getCompilerHooks,> } = require('webpack-manifest-plugin');> const ForkTsCheckerWebpackPlugin = require('fork-ts-checker-webpack-plugin');> const parsedArgs = require('yargs').argv;> const getProxyConfig = require('./webpack.proxy-config');> const packageConfig = require('./package');> > // input dir> const APP_DIR = path.resolve(__dirname, './');> // output dir> const BUILD_DIR = path.resolve(__dirname, '../superset/static/assets');> const ROOT_DIR = path.resolve(__dirname, '..');> > const {>   mode = 'development',>   devserverPort = 9000,>   measure = false,>   analyzeBundle = false,>   analyzerPort = 8888,>   nameChunks = false,> } = parsedArgs;> const isDevMode = mode !== 'production';> const isDevServer = process.argv[1].includes('webpack-dev-server');> const ASSET_BASE_URL = process.env.ASSET_BASE_URL || '';> > const output = {>   path: BUILD_DIR,>   publicPath: `${ASSET_BASE_URL}/static/assets/`,> };> if (isDevMode) {>   output.filename = '[name].[contenthash:8].entry.js';>   output.chunkFilename = '[name].[contenthash:8].chunk.js';> } else if (nameChunks) {>   output.filename = '[name].[chunkhash].entry.js';>   output.chunkFilename = '[name].[chunkhash].chunk.js';> } else {>   output.filename = '[name].[chunkhash].entry.js';>   output.chunkFilename = '[chunkhash].chunk.js';> }> > if (!isDevMode) {>   output.clean = true;> }> > const plugins = [>   new webpack.ProvidePlugin({>     process: 'process/browser',>   }),> >   // creates a manifest.json mapping of name to hashed output used in template files>   new WebpackManifestPlugin({>     publicPath: output.publicPath,>     seed: { app: 'superset' },>     // This enables us to include all relevant files for an entry>     generate: (seed, files, entrypoints) => {>       // Each entrypoint's chunk files in the format of>       // {>       //   entry: {>       //     css: [],>       //     js: []>       //   }>       // }>       const entryFiles = {};>       Object.entries(entrypoints).forEach(([entry, chunks]) => {>         entryFiles[entry] = {>           css: chunks>             .filter(x => x.endsWith('.css'))>             .map(x => path.join(output.publicPath, x)),>           js: chunks>             .filter(x => x.endsWith('.js'))>             .map(x => path.join(output.publicPath, x)),>         };>       });> >       return {>         ...seed,>         entrypoints: entryFiles,>       };>     },>     // Also write maniafest.json to disk when running `npm run dev`.>     // This is required for Flask to work.>     writeToFileEmit: isDevMode && !isDevServer,>   }),> >   // expose mode variable to other modules>   new webpack.DefinePlugin({>     'process.env.WEBPACK_MODE': JSON.stringify(mode),>   }),> >   // runs type checking on a separate process to speed up the build>   // new ForkTsCheckerWebpackPlugin({>   //   eslint: {>   //     files: './src/**/*.{ts,tsx,js,jsx}',>   //     memoryLimit: 4096,>   //   },>   // }),> >   new CopyPlugin({>     patterns: [>       'package.json',>       { from: 'src/assets/images', to: 'images' },>       { from: 'src/assets/stylesheets', to: 'stylesheets' },>     ],>   }),> >   // static pages>   new HtmlWebpackPlugin({>     template: './src/assets/staticPages/404.html',>     inject: true,>     chunks: [],>     filename: '404.html',>   }),>   new HtmlWebpackPlugin({>     template: './src/assets/staticPages/500.html',>     inject: true,>     chunks: [],>     filename: '500.html',>   }),> ];> > if (!process.env.CI) {>   plugins.push(new webpack.ProgressPlugin());> }> > if (!isDevMode) {>   // text loading (webpack 4+)>   plugins.push(>     new MiniCssExtractPlugin({>       filename: '[name].[chunkhash].entry.css',>       chunkFilename: '[name].[chunkhash].chunk.css',>     }),>   );> }> > const PREAMBLE = [path.join(APP_DIR, '/src/preamble.ts')];> if (isDevMode) {>   // A Superset webpage normally includes two JS bundles in dev, `theme.ts` and>   // the main entrypoint. Only the main entry should have the dev server client,>   // otherwise the websocket client will initialize twice, creating two sockets.>   // Ref: https://github.com/gaearon/react-hot-loader/issues/141>   PREAMBLE.unshift(>     `webpack-dev-server/client?http://localhost:${devserverPort}`,>   );> }> > function addPreamble(entry) {>   return PREAMBLE.concat([path.join(APP_DIR, entry)]);> }> > const babelLoader = {>   loader: 'babel-loader',>   options: {>     cacheDirectory: true,>     // disable gzip compression for cache files>     // faster when there are millions of small files>     cacheCompression: false,>     plugins: ['emotion'],>     presets: [>       [>         '@emotion/babel-preset-css-prop',>         {>           autoLabel: 'dev-only',>           labelFormat: '[local]',>         },>       ],>     ],>   },> };> > const config = {>   entry: {>     preamble: PREAMBLE,>     theme: path.join(APP_DIR, '/src/theme.ts'),>     menu: addPreamble('src/views/menu.tsx'),>     spa: addPreamble('/src/views/index.tsx'),>     addSlice: addPreamble('/src/addSlice/index.tsx'),>     explore: addPreamble('/src/explore/index.jsx'),>     sqllab: addPreamble('/src/SqlLab/index.tsx'),>     profile: addPreamble('/src/profile/index.tsx'),>     showSavedQuery: [path.join(APP_DIR, '/src/showSavedQuery/index.jsx')],>   },>   output,>   stats: 'minimal',>   performance: {>     assetFilter(assetFilename) {>       // don't throw size limit warning on geojson and font files>       return !/\.(map|geojson|woff2)$/.test(assetFilename);>     },>   },>   optimization: {>     sideEffects: true,>     splitChunks: {>       chunks: 'all',>       // increase minSize for devMode to 1000kb because of sourcemap>       minSize: isDevMode ? 1000000 : 20000,>       name: nameChunks,>       automaticNameDelimiter: '-',>       minChunks: 2,>       cacheGroups: {>         automaticNamePrefix: 'chunk',>         // basic stable dependencies>         vendors: {>           priority: 50,>           name: 'vendors',>           test: new RegExp(>             `/node_modules/(${[>               'abortcontroller-polyfill',>               'react',>               'react-dom',>               'prop-types',>               'react-prop-types',>               'prop-types-extra',>               'redux',>               'react-redux',>               'react-hot-loader',>               'react-select',>               'react-sortable-hoc',>               'react-virtualized',>               'react-table',>               'react-ace',>               '@hot-loader.*',>               'webpack.*',>               '@?babel.*',>               'lodash.*',>               'antd',>               '@ant-design.*',>               '.*bootstrap',>               'moment',>               'jquery',>               'core-js.*',>               '@emotion.*',>               'd3',>               'd3-(array|color|scale|interpolate|format|selection|collection|time|time-format)',>             ].join('|')})/`,>           ),>         },>         // viz thumbnails are used in `addSlice` and `explore` page>         thumbnail: {>           name: 'thumbnail',>           test: /thumbnail(Large)?\.(png|jpg)/i,>           priority: 20,>           enforce: true,>         },>       },>     },>     usedExports: 'global',>     minimizer: [new CssMinimizerPlugin(), '...'],>   },>   resolve: {>     modules: [APP_DIR, 'node_modules', ROOT_DIR],>     extensions: ['', '.html', '.js', '.json', '.scss', '.css'],>     alias: {>       // Force using absolute import path of some packages in the root node_modules,>       // as they can be dependencies of other packages via `npm link`.>       '@superset-ui/core': path.resolve(>         APP_DIR,>         './node_modules/@superset-ui/core',>       ),>       '@superset-ui/chart-controls': path.resolve(>         APP_DIR,>         './node_modules/@superset-ui/chart-controls',>       ),>       react: path.resolve('./node_modules/react')>     },>     extensions: ['.ts', '.tsx', '.js', '.jsx', '.yml'],>     fallback: {>       fs: false,>       vm: false,>       path: false,>     },>   },>   context: APP_DIR, // to automatically find tsconfig.json> > >   module: {>     rules: [>       {>         test: /datatables\.net.*/,>         loader: 'imports-loader',>         options: {>           additionalCode: 'var define = false;',>         },>       },>       {>         test: /\.tsx?$/,>         exclude: [/\.test.tsx?$/],>         use: [>           'thread-loader',>           babelLoader,>           {>             loader: 'ts-loader',>             options: {>               // transpile only in happyPack mode>               // type checking is done via fork-ts-checker-webpack-plugin>               happyPackMode: true,>               transpileOnly: true,>               // must override compiler options here, even though we have set>               // the same options in `tsconfig.json`, because they may still>               // be overriden by `tsconfig.json` in node_modules subdirectories.>               compilerOptions: {>                 esModuleInterop: false,>                 importHelpers: false,>                 module: 'esnext',>                 target: 'esnext',>               },>             },>           },>         ],>       },>       {>         test: /\.jsx?$/,>         // include source code for plugins, but exclude node_modules and test files within them>         exclude: [/superset-ui.*\/node_modules\//, /\.test.jsx?$/],>         include: [>           new RegExp(`${APP_DIR}/src`),>           /superset-ui.*\/src/,>           new RegExp(`${APP_DIR}/.storybook`),>           /@encodable/,>         ],>         use: [babelLoader],>       },>       {>         test: /\.css$/,>         include: [APP_DIR, /superset-ui.+\/src/, new RegExp(`/superset-ui/plugins/plugin-chart-hello-world/node_modules/leaflet/dist/`)],>         use: [>           isDevMode ? 'style-loader' : MiniCssExtractPlugin.loader,>           {>             loader: 'css-loader',>             options: {>               sourceMap: isDevMode,>             },>           },>         ],>       },>       {>         test: /\.less$/,>         include: APP_DIR,>         use: [>           isDevMode ? 'style-loader' : MiniCssExtractPlugin.loader,>           {>             loader: 'css-loader',>             options: {>               sourceMap: isDevMode,>             },>           },>           {>             loader: 'less-loader',>             options: {>               sourceMap: isDevMode,>               javascriptEnabled: true,>             },>           },>         ],>       },>       /* for css linking images (and viz plugin thumbnails) */>       {>         test: /\.png$/,>         issuer: {>           not: [/\/src\/assets\/staticPages\//],>         },>         type: 'asset',>         generator: {>           filename: '[name].[contenthash:8].[ext]',>         },>       },>       {>         test: /\.png$/,>         issuer: /\/src\/assets\/staticPages\//,>         type: 'asset',>       },>       {>         test: /\.svg(\?v=\d+\.\d+\.\d+)?$/,>         issuer: /\.([jt])sx?$/,>         use: ['@svgr/webpack'],>       },>       {>         test: /\.(jpg|gif)$/,>         type: 'asset/resource',>         generator: {>           filename: '[name].[contenthash:8].[ext]',>         },>       },>       /* for font-awesome */>       {>         test: /\.(woff|woff2|eot|ttf|otf)$/i,>         type: 'asset/resource',>       },>       {>         test: /\.ya?ml$/,>         include: ROOT_DIR,>         loader: 'js-yaml-loader',>       },>     ],>   },>   externals: {>     cheerio: 'window',>     'react/lib/ExecutionEnvironment': true,>     'react/lib/ReactContext': true,>   },>   plugins,>   devtool: false,> };> > let proxyConfig = getProxyConfig();> > if (isDevMode) {>   config.devtool = 'eval-cheap-module-source-map';>   config.devServer = {>     onBeforeSetupMiddleware(devServer) {>       // load proxy config when manifest updates>       const { afterEmit } = getCompilerHooks(devServer.compiler);>       afterEmit.tap('ManifestPlugin', manifest => {>         proxyConfig = getProxyConfig(manifest);>       });>     },>     historyApiFallback: true,>     hot: true,>     port: devserverPort,>     // Only serves bundled files from webpack-dev-server>     // and proxy everything else to Superset backend>     proxy: [>       // functions are called for every request>       () => proxyConfig,>     ],>     client: {>       overlay: { errors: true, warnings: false },>       logging: 'error',>     },>     static: path.join(process.cwd(), '../static/assets'),>   };> >   // make sure to use @emotion/* modules in the root directory>   fs.readdirSync(path.resolve(APP_DIR, './node_modules/@emotion'), pkg => {>     config.resolve.alias[pkg] = path.resolve(>       APP_DIR,>       './node_modules/@emotion',>       pkg,>     );>   });> >   // find all the symlinked plugins and use their source code for imports>   let hasSymlink = false;>   Object.entries(packageConfig.dependencies).forEach(([pkg, version]) => {>     const srcPath = `./node_modules/${pkg}/src`;>     if (/superset-ui/.test(pkg) && fs.existsSync(srcPath)) {>       console.log(>         `[Superset Plugin] Use symlink source for ${pkg} @ ${version}`,>       );>       // only allow exact match so imports like `@superset-ui/plugin-name/lib`>       // and `@superset-ui/plugin-name/esm` can still work.>       config.resolve.alias[`${pkg}$`] = `${pkg}/src`;>       delete config.resolve.alias[pkg];>       hasSymlink = true;>     }>   });>   if (hasSymlink) {>     console.log(''); // pure cosmetic new line>   }> }> > // Bundle analyzer is disabled by default> // Pass flag --analyzeBundle=true to enable> // e.g. npm run build -- --analyzeBundle=true> if (analyzeBundle) {>   config.plugins.push(new BundleAnalyzerPlugin({ analyzerPort }));> }> > // Speed measurement is disabled by default> // Pass flag --measure=true to enable> // e.g. npm run build -- --measure=true> const smp = new SpeedMeasurePlugin({>   disable: !measure,> });> > module.exports = smp.wrap(config);The above shared webpack configuration was workingbut now when I cloned the superset and tried to make my plugin work properlyits causing lots of issues. When creating the build get an error of > [webpack-cli] HookWebpackError: Maximum call stack size exceeded    at makeWebpackError (/home/superset-env/superset/superset-frontend/node_modules/webpack/lib/HookWebpackError.js:48:9)    at /home/superset-env/superset/superset-frontend/node_modules/webpack/lib/Compilation.js:2517:12    at eval (eval at create (/home/superset-env/superset/superset-frontend/node_modules/webpack/node_modules/tapable/lib/HookCodeFactory.js:33:10), <anonymous>:81:1)-- inner error --RangeError: Maximum call stack size exceeded    at String.match (<anonymous>)    at streamChunksOfRawSource (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/helpers/streamChunksOfRawSource.js:14:25)    at module.exports (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/helpers/streamChunksOfRawSource.js:40:5)    at RawSource.streamChunks (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/RawSource.js:56:10)    at module.exports (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/helpers/streamChunks.js:13:17)    at streamAndGetSourceAndMap (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/helpers/streamAndGetSourceAndMap.js:27:53)    at CachedSource.streamChunks (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/CachedSource.js:208:35)    at module.exports (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/helpers/streamChunks.js:13:17)    at ReplaceSource.streamChunks (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/ReplaceSource.js:176:44)    at module.exports (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/helpers/streamChunks.js:13:17)caused by plugins in Compilation.hooks.processAssetsRangeError: Maximum call stack size exceeded    at String.match (<anonymous>)    at streamChunksOfRawSource (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/helpers/streamChunksOfRawSource.js:14:25)    at module.exports (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/helpers/streamChunksOfRawSource.js:40:5)    at RawSource.streamChunks (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/RawSource.js:56:10)    at module.exports (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/helpers/streamChunks.js:13:17)    at streamAndGetSourceAndMap (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/helpers/streamAndGetSourceAndMap.js:27:53)    at CachedSource.streamChunks (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/CachedSource.js:208:35)    at module.exports (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/helpers/streamChunks.js:13:17)    at ReplaceSource.streamChunks (/home/superset-env/superset/superset-frontend/node_modules/webpack-sources/lib/ReplaceSource.js:176:4webpack configuration with which i am getting this error is > const fs = require('fs');> const path = require('path');> const webpack = require('webpack');> const { BundleAnalyzerPlugin } = require('webpack-bundle-analyzer');> const CopyPlugin = require('copy-webpack-plugin');> const HtmlWebpackPlugin = require('html-webpack-plugin');> const MiniCssExtractPlugin = require('mini-css-extract-plugin');> const CssMinimizerPlugin = require('css-minimizer-webpack-plugin');> const SpeedMeasurePlugin = require('speed-measure-webpack-plugin');> const {>   WebpackManifestPlugin,>   getCompilerHooks,> } = require('webpack-manifest-plugin');> const ForkTsCheckerWebpackPlugin = require('fork-ts-checker-webpack-plugin');> const parsedArgs = require('yargs').argv;> const getProxyConfig = require('./webpack.proxy-config');> const packageConfig = require('./package');> > // input dir> const APP_DIR = path.resolve(__dirname, './');> // output dir> const BUILD_DIR = path.resolve(__dirname, '../superset/static/assets');> const ROOT_DIR = path.resolve(__dirname, '..');> > const {>   mode = 'development',>   devserverPort = 9000,>   measure = false,>   analyzeBundle = false,>   analyzerPort = 8888,>   nameChunks = false,> } = parsedArgs;> const isDevMode = mode !== 'production';> const isDevServer = process.argv[1].includes('webpack-dev-server');> const ASSET_BASE_URL = process.env.ASSET_BASE_URL || '';> > const output = {>   path: BUILD_DIR,>   publicPath: `${ASSET_BASE_URL}/static/assets/`,> };> if (isDevMode) {>   output.filename = '[name].[contenthash:8].entry.js';>   output.chunkFilename = '[name].[contenthash:8].chunk.js';> } else if (nameChunks) {>   output.filename = '[name].[chunkhash].entry.js';>   output.chunkFilename = '[name].[chunkhash].chunk.js';> } else {>   output.filename = '[name].[chunkhash].entry.js';>   output.chunkFilename = '[chunkhash].chunk.js';> }> > if (!isDevMode) {>   output.clean = true;> }> > const plugins = [>   new webpack.ProvidePlugin({>     process: 'process/browser',>   }),> >   // creates a manifest.json mapping of name to hashed output used in template files>   new WebpackManifestPlugin({>     publicPath: output.publicPath,>     seed: { app: 'superset' },>     // This enables us to include all relevant files for an entry>     generate: (seed, files, entrypoints) => {>       // Each entrypoint's chunk files in the format of>       // {>       //   entry: {>       //     css: [],>       //     js: []>       //   }>       // }>       const entryFiles = {};>       Object.entries(entrypoints).forEach(([entry, chunks]) => {>         entryFiles[entry] = {>           css: chunks>             .filter(x => x.endsWith('.css'))>             .map(x => path.join(output.publicPath, x)),>           js: chunks>             .filter(x => x.endsWith('.js'))>             .map(x => path.join(output.publicPath, x)),>         };>       });> >       return {>         ...seed,>         entrypoints: entryFiles,>       };>     },>     // Also write maniafest.json to disk when running `npm run dev`.>     // This is required for Flask to work.>     writeToFileEmit: isDevMode && !isDevServer,>   }),> >   // expose mode variable to other modules>   new webpack.DefinePlugin({>     'process.env.WEBPACK_MODE': JSON.stringify(mode),>   }),> >   new CopyPlugin({>     patterns: [>       'package.json',>       { from: 'src/assets/images', to: 'images' },>       { from: 'src/assets/stylesheets', to: 'stylesheets' },>     ],>   }),> >   // static pages>   new HtmlWebpackPlugin({>     template: './src/assets/staticPages/404.html',>     inject: true,>     chunks: [],>     filename: '404.html',>   }),>   new HtmlWebpackPlugin({>     template: './src/assets/staticPages/500.html',>     inject: true,>     chunks: [],>     filename: '500.html',>   }),> ];> > if (!process.env.CI) {>   plugins.push(new webpack.ProgressPlugin());> }> > if (!isDevMode) {>   // text loading (webpack 4+)>   plugins.push(>     new MiniCssExtractPlugin({>       filename: '[name].[chunkhash].entry.css',>       chunkFilename: '[name].[chunkhash].chunk.css',>     }),>   );> >   plugins.push(>     // runs type checking on a separate process to speed up the build>     new ForkTsCheckerWebpackPlugin({>       eslint: {>         files: './{src,packages,plugins}/**/*.{ts,tsx,js,jsx}',>         memoryLimit: 4096,>         options: {>           ignorePath: './.eslintignore',>         },>       },>     }),>   );> }> > const PREAMBLE = [path.join(APP_DIR, '/src/preamble.ts')];> if (isDevMode) {>   // A Superset webpage normally includes two JS bundles in dev, `theme.ts` and>   // the main entrypoint. Only the main entry should have the dev server client,>   // otherwise the websocket client will initialize twice, creating two sockets.>   // Ref: https://github.com/gaearon/react-hot-loader/issues/141>   PREAMBLE.unshift(>     `webpack-dev-server/client?http://localhost:${devserverPort}`,>   );> }> > function addPreamble(entry) {>   return PREAMBLE.concat([path.join(APP_DIR, entry)]);> }> > const babelLoader = {>   loader: 'babel-loader',>   options: {>     cacheDirectory: true,>     // disable gzip compression for cache files>     // faster when there are millions of small files>     cacheCompression: false,>     plugins: ['emotion'],>     presets: [>       [>         '@emotion/babel-preset-css-prop',>         {>           autoLabel: 'dev-only',>           labelFormat: '[local]',>         },>       ],>     ],>   },> };> > const config = {>   entry: {>     preamble: PREAMBLE,>     theme: path.join(APP_DIR, '/src/theme.ts'),>     menu: addPreamble('src/views/menu.tsx'),>     spa: addPreamble('/src/views/index.tsx'),>     addSlice: addPreamble('/src/addSlice/index.tsx'),>     explore: addPreamble('/src/explore/index.jsx'),>     sqllab: addPreamble('/src/SqlLab/index.tsx'),>     profile: addPreamble('/src/profile/index.tsx'),>     showSavedQuery: [path.join(APP_DIR, '/src/showSavedQuery/index.jsx')],>   },>   output,>   stats: 'minimal',>   performance: {>     assetFilter(assetFilename) {>       // don't throw size limit warning on geojson and font files>       return !/\.(map|geojson|woff2)$/.test(assetFilename);>     },>   },>   optimization: {>     sideEffects: true,>     splitChunks: {>       chunks: 'all',>       // increase minSize for devMode to 1000kb because of sourcemap>       minSize: isDevMode ? 1000000 : 20000,>       name: nameChunks,>       automaticNameDelimiter: '-',>       minChunks: 2,>       cacheGroups: {>         automaticNamePrefix: 'chunk',>         // basic stable dependencies>         vendors: {>           priority: 50,>           name: 'vendors',>           test: new RegExp(>             `/node_modules/(${[>               'abortcontroller-polyfill',>               'react',>               'react-dom',>               'prop-types',>               'react-prop-types',>               'prop-types-extra',>               'redux',>               'react-redux',>               'react-hot-loader',>               'react-select',>               'react-sortable-hoc',>               'react-virtualized',>               'react-table',>               'react-ace',>               '@hot-loader.*',>               'webpack.*',>               '@?babel.*',>               'lodash.*',>               'antd',>               '@ant-design.*',>               '.*bootstrap',>               'moment',>               'jquery',>               'core-js.*',>               '@emotion.*',>               'd3',>               'd3-(array|color|scale|interpolate|format|selection|collection|time|time-format)',>             ].join('|')})/`,>           ),>         },>         // viz thumbnails are used in `addSlice` and `explore` page>         thumbnail: {>           name: 'thumbnail',>           test: /thumbnail(Large)?\.(png|jpg)/i,>           priority: 20,>           enforce: true,>         },>       },>     },>     usedExports: 'global',>     minimizer: [new CssMinimizerPlugin(), '...'],>   },>   resolve: {>     modules: [APP_DIR, 'node_modules', ROOT_DIR],>     alias: {},>     extensions: ['.ts', '.tsx', '.js', '.jsx', '.yml'],>     fallback: {>       fs: false,>       vm: false,>       path: false,>     },>   },>   context: APP_DIR, // to automatically find tsconfig.json>   module: {>     rules: [>       {>         test: /datatables\.net.*/,>         loader: 'imports-loader',>         options: {>           additionalCode: 'var define = false;',>         },>       },>       {>         test: /\.tsx?$/,>         exclude: [/\.test.tsx?$/],>         use: [>           'thread-loader',>           babelLoader,>           {>             loader: 'ts-loader',>             options: {>               // transpile only in happyPack mode>               // type checking is done via fork-ts-checker-webpack-plugin>               happyPackMode: true,>               transpileOnly: true,>               // must override compiler options here, even though we have set>               // the same options in `tsconfig.json`, because they may still>               // be overriden by `tsconfig.json` in node_modules subdirectories.>               compilerOptions: {>                 esModuleInterop: false,>                 importHelpers: false,>                 module: 'esnext',>                 target: 'esnext',>               },>             },>           },>         ],>       },>       {>         test: /\.jsx?$/,>         // include source code for plugins, but exclude node_modules and test files within them>         exclude: [/superset-ui.*\/node_modules\//, /\.test.jsx?$/],>         include: [>           new RegExp(`${APP_DIR}/(src|.storybook|plugins|packages)`),>           /@encodable/,>         ],>         use: [babelLoader],>       },>       {>         test: /\.css$/,>         include: [APP_DIR, /superset-ui.+\/src/],>         use: [>           isDevMode ? 'style-loader' : MiniCssExtractPlugin.loader,>           {>             loader: 'css-loader',>             options: {>               sourceMap: isDevMode,>             },>           },>         ],>       },>       {>         test: /\.less$/,>         include: APP_DIR,>         use: [>           isDevMode ? 'style-loader' : MiniCssExtractPlugin.loader,>           {>             loader: 'css-loader',>             options: {>               sourceMap: isDevMode,>             },>           },>           {>             loader: 'less-loader',>             options: {>               sourceMap: isDevMode,>               javascriptEnabled: true,>             },>           },>         ],>       },>       /* for css linking images (and viz plugin thumbnails) */>       {>         test: /\.png$/,>         issuer: {>           not: [/\/src\/assets\/staticPages\//],>         },>         type: 'asset',>         generator: {>           filename: '[name].[contenthash:8].[ext]',>         },>       },>       {>         test: /\.png$/,>         issuer: /\/src\/assets\/staticPages\//,>         type: 'asset',>       },>       {>         test: /\.svg(\?v=\d+\.\d+\.\d+)?$/,>         issuer: /\.([jt])sx?$/,>         use: ['@svgr/webpack'],>       },>       {>         test: /\.(jpg|gif)$/,>         type: 'asset/resource',>         generator: {>           filename: '[name].[contenthash:8].[ext]',>         },>       },>       /* for font-awesome */>       {>         test: /\.(woff|woff2|eot|ttf|otf)$/i,>         type: 'asset/resource',>       },>       {>         test: /\.ya?ml$/,>         include: ROOT_DIR,>         loader: 'js-yaml-loader',>       },>     ],>   },>   externals: {>     cheerio: 'window',>     'react/lib/ExecutionEnvironment': true,>     'react/lib/ReactContext': true,>   },>   plugins,>   devtool: false,> };> > // find all the symlinked plugins and use their source code for imports> Object.entries(packageConfig.dependencies).forEach(([pkg, version]) => {>   const srcPath = `./node_modules/${pkg}/src`;>   if (/^@superset-ui/.test(pkg) && fs.existsSync(srcPath)) {>     console.log(`[Superset Plugin] Use symlink source for ${pkg} @ ${version}`);>     // only allow exact match so imports like `@superset-ui/plugin-name/lib`>     // and `@superset-ui/plugin-name/esm` can still work.>     const pkgDirectory = pkg.split('/').pop();>     if (/^(core|chart-controls)/.test(pkgDirectory)) {>       config.resolve.alias[pkg] = path.resolve(>         APP_DIR,>         `packages/superset-ui-${pkgDirectory}/src`,>       );>     } else {>       config.resolve.alias[pkg] = path.resolve(>         APP_DIR,>         `plugins/${pkgDirectory}/src`,>       );>     }>   }> });> console.log(''); // pure cosmetic new line> > let proxyConfig = getProxyConfig();> > if (isDevMode) {>   config.devtool = 'eval-cheap-module-source-map';>   config.devServer = {>     onBeforeSetupMiddleware(devServer) {>       // load proxy config when manifest updates>       const { afterEmit } = getCompilerHooks(devServer.compiler);>       afterEmit.tap('ManifestPlugin', manifest => {>         proxyConfig = getProxyConfig(manifest);>       });>     },>     historyApiFallback: true,>     hot: true,>     port: devserverPort,>     // Only serves bundled files from webpack-dev-server>     // and proxy everything else to Superset backend>     proxy: [>       // functions are called for every request>       () => proxyConfig,>     ],>     client: {>       overlay: { errors: true, warnings: false },>       logging: 'error',>     },>     static: path.join(process.cwd(), '../static/assets'),>   };> }> > // Bundle analyzer is disabled by default> // Pass flag --analyzeBundle=true to enable> // e.g. npm run build -- --analyzeBundle=true> if (analyzeBundle) {>   config.plugins.push(new BundleAnalyzerPlugin({ analyzerPort }));> }> > // Speed measurement is disabled by default> // Pass flag --measure=true to enable> // e.g. npm run build -- --measure=true> const smp = new SpeedMeasurePlugin({>   disable: !measure,> });> > module.exports = smp.wrap(config);
"
17674,1,0,0,0,0,michellethomas,0,"title:[dragndrop] Clicking ""show all"" on explore left panel freezes page for large dataset. description:If you are creating a chart on dataset with a large number of columns and metrics and you click ""show all"" on the left panel, the page freezes. We have a dataset that is quite large (> 1000 columns) so I'm not sure exactly at what point this happens.#### How to reproduce the bug1. Create a dataset with a large number of columns and metrics.2. Create a chart for that dataset3. Click on ""show all"" on the left panel### Expected resultsLeft panel will show all columns.### Actual resultsPage freezes### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17672,0,0,291,0,0,hbruch,0,"title:babel.cfg omits js and ts files. description:With commit https://github.com/apache/superset/commit/3c41ff68a43b5ab6b871226a73de9f2129d64766 `.js?` and `.ts?`where introduced as glob-patterns that should match `.js`,`.jsx`,`.ts`, and `.tsx` file extensions. However, `?` matches exactly one char, not one or none.#### How to reproduce the bug1. Open https://github.com/apache/superset/blob/master/superset/translations/messages.pot and search for `.js:` => no message from js files is contained in the pot file### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17666,1,0,1,0,0,airbots,0,"title:Dataset not visible to normal user when save it without specifying schema. description:When we use sql editor to create a query and get the derived data. If we want to save it, Superset does not check if schema is not configured or not. It should. If we let be null and click ""save as"", the schema will be null. And non-superuser will never see this dataset anymore when they click the datasets on the navigation  bar and can not create a chart based on the derived data. #### How to reproduce the bug1. Go to '...'2. Click on '....'3. Scroll down to '....'4. See error### Expected resultswhat you expected to happen.### Actual resultswhat actually happens.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17637,1,0,1,0,0,airbots,0,"title:UI blurs for different browsers. description:A clear and concise description of what the bug is.#### How to reproduce the bugJust using Superset 1.1, it blurs the webpage highly suspect it is related to UI ### Expected resultswhat you expected to happen.### Actual resultswhat actually happens.#### ScreenshotsFirefox<img width=""904"" alt=""Screen Shot 2021-12-02 at 4 32 41 PM"" src=""https://user-images.githubusercontent.com/250848/144524702-cb0a669a-1e79-40c9-a75c-ac95efefad34.png"">Chrome<img width=""874"" alt=""Screen Shot 2021-12-02 at 4 36 03 PM"" src=""https://user-images.githubusercontent.com/250848/144524765-4c914b0c-6036-49c5-ab12-bef451017bc7.png"">If applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17632,0,0,0,0,0,Narendra678,0,"title:SQL Query shows 'Offline'. description:A clear and concise description of what the bug is.### Expected resultsWhen i write SQL query it should run and show 'explore' option to save query.This is working fine through Docker-Superset.### Actual resultsShows Offline.This is not working in GCP-Superset.###screnshots![image](https://user-images.githubusercontent.com/88739186/144409527-1b589064-9b11-47d5-8300-a1fec695efef.png)- browser type and version:- superset version: `superset version`: 1.3.1- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17630,0,0,294,0,0,villebro,0,"title:Closing all tabs on SQL Lab leaves the screen blank. description:When closing all tabs on SQL Lab, the whole screen goes blank due to there not being a single open tab left. #### How to reproduce the bug1. Go to SQL Lab2. Close all tabs3. Notice how the whole screen goes blank### Expected resultsA new empty tab should be opened automatically. The same can now be achieved by clicking on SQL Lab in the menu, which correctly opens an empty tab.### Actual resultsThe screen goes blank#### Videohttps://user-images.githubusercontent.com/33317356/144376770-4872c145-5e57-4efc-9862-5e4909d58f4d.mp4### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17629,1,0,1,0,0,yoavo-datricks,0,"title:Superset over Clickhouse doesn't handle well nullable columns. description:When building a chert over a clickhouse dataset with nullable columns all columns are listed as just ""nullable"" without the actual data type.![image](https://user-images.githubusercontent.com/72439961/144375901-b78a1120-128c-4d13-91e7-7c5da71e5f21.png)### Expected resultsThe actual data types - Int, String, Array, etc...### Environment- browser type and version: Chrome- superset version: 1.3.2- clickhouse-alchemy - 0.16This was solved here using the ""get_datatype"" enhancement but was never merged to the clickhouse.py, can it be pushed to 1.4?https://github.com/HeinzMayer/superset/blob/1.0.MIC/superset/db_engine_specs/clickhouse.py
"
17628,1,0,0,0,0,niyouzhu,0,"title:Bug of filter when operating with dremio. description:there is a bug when having a boolean filter be applied in Dremio dataset.after you selected True or False in boolean filter, then click apply button, will throw exception.![image](https://user-images.githubusercontent.com/15760569/144367769-0698fdca-1e7f-470c-888e-3a85939ef2fd.png)![image](https://user-images.githubusercontent.com/15760569/144367811-9ccb7d9a-d7af-42dd-bad4-f8986ef87386.png)A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to '...'2. Click on '....'3. Scroll down to '....'4. See error### Expected resultswhat you expected to happen.### Actual resultswhat actually happens.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17625,1,0,0,0,0,JoaquinPretell92,0,"title:Chart in this dashboard dont refresh. description:Hello,We are using Superset version 1.4.0rc1 and we deploy the next chart in our dashboard, but we saw its not refreshing by itself.![6546546](https://user-images.githubusercontent.com/73810312/144325166-77e98aad-c9c3-4774-a6c9-ecac9d9f6b1b.PNG)As you can see it has a message that its not refreshed by 19 hours, we hit the button but it didnt work the data didnt refresh. it has diferent records when we check the chart on the ""charts section""![6463546346436](https://user-images.githubusercontent.com/73810312/144325342-dd5f0033-d6ef-4d11-8caf-f9cdabd447e6.PNG)We saw there is a sync button now for the dataset on the chart section and when we hit the button the chart on the dashboard get refresh but only work for one day. Today we have the same problem again. ![643634643634](https://user-images.githubusercontent.com/73810312/144325663-ba668892-b4a2-4c7f-bb58-05ea2f3730b1.PNG)We want to know if this is a bug or maybe something change in the configuration between versions.Regards
"
17619,1,0,0,0,0,jaspreetjhans,0,"title:Issue in upgrading apache-superset. description:Hello Teami used below link to install apache-superset, but it installed 0.38 version. how can i upgrade it to latest versionhttps://superset.apache.org/docs/installation/installing-superset-from-scratchThanks 
"
17598,1,0,0,0,0,dneelapareddy,0,"title:Unable to access time_grain in custom SQL. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to 'Create Chart'2. Click on 'METRICS' and select 'Custom SQL' tab### Expected resultsShould be able to access time_grain value#### Screenshots![image](https://user-images.githubusercontent.com/43841180/144085838-774a111b-2b5f-468b-96f2-cb2a799f938f.png)
"
17592,1,0,0,0,0,jafournier,0,"title:`401 Unauthorized` on route `/datasource/external_metadata_by_name/. description:HiI am currently using superset with `gitlab SSO`, everything is working fine with it, EXCEPT while doing a `sync column from source` , trying to sync my dataset (defined in AWS glue datacatalog).The `sync` functionality was working so far.I got a message saying `An error occured`.While trying to see what's going on with api calls I see:`401 Unauthorized` on route `/datasource/external_metadata_by_name/However my user has been granted the `Admin` role.I am using the superset docker image tagged `1.3.2`<img width=""737"" alt=""Screen Shot 2021-11-30 at 11 13 50"" src=""https://user-images.githubusercontent.com/16292862/144028313-673520d9-8d6c-4d31-a1de-b32200e0bfcf.png"">Thanks
"
17586,0,0,0,0,0,kamalkeshavani-aiinside,0,"title:[mixed time-series] Metric name is shown in legend instead of label. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Create a metric with a custom label2. Use this metric in Mixed Time-series Chart### Expected resultsCustom label for metric is shown in legend.### Actual resultsMetric name is shown in legend.#### ScreenshotsIf applicable, add screenshots to help explain your problem.![image](https://user-images.githubusercontent.com/74634977/144000668-24cd3025-4bf1-4ffd-834b-c05cb3e09d5d.png)### Environment(please complete the following information):- browser type and version: Chrome 96- superset version: `master`- python version: `3.9`- node.js version: `14.15.5`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextThis issue is not present in other time-series echarts
"
17574,1,0,0,0,0,jaspreetjhans,0,"title:Error Installation : pip install apache-superset. description:Defaulting to user installation because normal site-packages is not writeableWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:877)'),)': /simple/apache-superset/WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:877)'),)': /simple/apache-superset/WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:877)'),)': /simple/apache-superset/WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:877)'),)': /simple/apache-superset/WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:877)'),)': /simple/apache-superset/Could not fetch URL https://pypi.org/simple/apache-superset/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/apache-superset/ (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:877)'),)) - skippingERROR: Could not find a version that satisfies the requirement apache-superset (from versions: none)ERROR: No matching distribution found for apache-supersetCould not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:877)'),)) - skipping
"
17572,1,0,4,0,0,FeiBa0125,0,"title:user country map,some national maps are rendered in white. description:Try rendering the map of China.data as![image](https://user-images.githubusercontent.com/49543299/143855889-c18ee921-1098-4259-8cab-c5e8c7f69373.png)### Expected resultswhat you expected to happen.such as usa:![image](https://user-images.githubusercontent.com/49543299/143856056-750c323f-d7ba-4630-9d7f-42b24b7d4b80.png)### Actual resultswhat actually happens.![image](https://user-images.githubusercontent.com/49543299/143856128-10634733-64c0-4cfe-9cc2-a98c3c51b6a1.png)#### ScreenshotsIf applicable, add screenshots to help explain your problem.![image](https://user-images.githubusercontent.com/49543299/143856198-396ee208-ef88-4fb2-ae2e-bb748c3076eb.png)All the same data except the iso_code. usa is right.![image](https://user-images.githubusercontent.com/49543299/143856447-1b433b00-fab8-4148-a2c7-515bb2a70922.png)### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.iso files[IP2LOCATION-ISO3166-2.CSV](https://github.com/apache/superset/files/7617721/IP2LOCATION-ISO3166-2.CSV)I hope this problem can be solved闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈惧瘜閺佸﹪鏌熼懡銈夊厴nks
"
17558,1,0,0,0,0,Narendra678,0,"title:Unexpected . description:A clear and concise description of what the bug is.#### How to reproduce the bugGetting Unexpected error as below:<html><head> <meta http-equiv=""content-type"" content=""text/html;charset=utf-8""> <title>500 Server Error</title> </head> <body text=#000000 bgcolor=#ffffff> <h1>Error: Server Error</h1> <h2>The server encountered an error and could not complete your request.<p>Please try again in 30 seconds.</h2> <h2></h2> </body></html>### Expected resultsShould show datawhat you expected to happen.![image](https://user-images.githubusercontent.com/88739186/143541581-711b020e-74c9-4399-94eb-9f6c6a7e0707.png)From past 5 days we are working on this but no luck. And it is happening some times.### Environment(please complete the following information):- browser type and version:- superset version: `superset version`: 1.3.1- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17551,1,10933,11,0,0,sairamkrish,0,"title:Unable to get started with SQLite as Superset metadata database with custom superset_config.py. description:Can't get started with Apache Superset + SQLite as metadata store + custom superset_config.py. **Environment*** Apache superset version 1.3.2* superset_config.py --> this has only one override `SQLALCHEMY_DATABASE_URI`**Steps to reproduce*** Without superset_config.py., if we use the default flow `superset db upgrade`, this issue is not happening. Sqlite db gets created at `~/.superset/superset.db`* Create a custom superset_config.py with content```SQLALCHEMY_DATABASE_URI = 'sqlite:///superset.db'```* Invoke `PYTHONPATH=.:$PYTHONPATH superset db upgrade`* we get following exception```sh(superset-experiment) 闂? superset-experiment git:(main) 闂?PYTHONPATH=.:$PYTHONPATH superset db upgradeLoaded your LOCAL configuration at [/Users/sairam/superset-experiment/superset_config.py]logging was configured successfully2021-11-25 07:28:07,681:INFO:superset.utils.logging_configurator:logging was configured successfully2021-11-25 07:28:07,695:INFO:root:Configured event logger of type <class 'superset.utils.log.DBEventLogger'>/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/flask_caching/__init__.py:201: UserWarning: Flask-Caching: CACHE_TYPE is set to null, caching is effectively disabled.  warnings.warn(No PIL installation found2021-11-25 07:28:07,915:INFO:superset.utils.screenshots:No PIL installation foundWARNI [alembic.env] SQLite Database support for metadata databases will         be removed in a future version of Superset.INFO  [alembic.runtime.migration] Context impl SQLiteImpl.INFO  [alembic.runtime.migration] Will assume transactional DDL.INFO  [alembic.runtime.migration] Running upgrade 12d55656cbca -> 2591d77e9831, user_idTraceback (most recent call last):  File ""/Users/sairam/superset-experiment/.venv/bin/superset"", line 8, in <module>    sys.exit(superset())  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/click/core.py"", line 829, in __call__    return self.main(*args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/flask/cli.py"", line 586, in main    return super(FlaskGroup, self).main(*args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/click/core.py"", line 782, in main    rv = self.invoke(ctx)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/click/core.py"", line 1259, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/click/core.py"", line 1259, in invoke    return _process_result(sub_ctx.command.invoke(sub_ctx))  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/click/core.py"", line 1066, in invoke    return ctx.invoke(self.callback, **ctx.params)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/click/core.py"", line 610, in invoke    return callback(*args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/click/decorators.py"", line 21, in new_func    return f(get_current_context(), *args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/flask/cli.py"", line 426, in decorator    return __ctx.invoke(f, *args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/click/core.py"", line 610, in invoke    return callback(*args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/flask_migrate/cli.py"", line 149, in upgrade    _upgrade(directory, revision, sql, tag, x_arg)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/flask_migrate/__init__.py"", line 98, in wrapped    f(*args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/flask_migrate/__init__.py"", line 185, in upgrade    command.upgrade(config, revision, sql=sql, tag=tag)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/alembic/command.py"", line 320, in upgrade    script.run_env()  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/alembic/script/base.py"", line 563, in run_env    util.load_python_file(self.dir, ""env.py"")  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/alembic/util/pyfiles.py"", line 92, in load_python_file    module = load_module_py(module_id, path)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/alembic/util/pyfiles.py"", line 108, in load_module_py    spec.loader.exec_module(module)  # type: ignore  File ""<frozen importlib._bootstrap_external>"", line 783, in exec_module  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/superset/migrations/env.py"", line 124, in <module>    run_migrations_online()  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/superset/migrations/env.py"", line 116, in run_migrations_online    context.run_migrations()  File ""<string>"", line 8, in run_migrations  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/alembic/runtime/environment.py"", line 851, in run_migrations    self.get_context().run_migrations(**kw)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/alembic/runtime/migration.py"", line 620, in run_migrations    step.migration_fn(**kw)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/superset/migrations/versions/2591d77e9831_user_id.py"", line 36, in upgrade    batch_op.create_foreign_key(""user_id"", ""ab_user"", [""user_id""], [""id""])  File ""/Users/sairam/.pyenv/versions/3.8.1/lib/python3.8/contextlib.py"", line 120, in __exit__    next(self.gen)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/alembic/operations/base.py"", line 374, in batch_alter_table    impl.flush()  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/alembic/operations/batch.py"", line 118, in flush    existing_table = Table(  File ""<string>"", line 2, in __new__  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py"", line 139, in warned    return fn(*args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/sql/schema.py"", line 563, in __new__    metadata._remove_table(name, schema)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py"", line 68, in __exit__    compat.raise_(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/sql/schema.py"", line 558, in __new__    table._init(name, metadata, *args, **kw)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/sql/schema.py"", line 647, in _init    self._autoload(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/sql/schema.py"", line 670, in _autoload    autoload_with.run_callable(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1653, in run_callable    return callable_(self, *args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 484, in reflecttable    return insp.reflecttable(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/engine/reflection.py"", line 684, in reflecttable    self._reflect_fk(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/engine/reflection.py"", line 868, in _reflect_fk    sa_schema.Table(  File ""<string>"", line 2, in __new__  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py"", line 139, in warned    return fn(*args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/sql/schema.py"", line 563, in __new__    metadata._remove_table(name, schema)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py"", line 68, in __exit__    compat.raise_(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/sql/schema.py"", line 558, in __new__    table._init(name, metadata, *args, **kw)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/sql/schema.py"", line 647, in _init    self._autoload(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/sql/schema.py"", line 670, in _autoload    autoload_with.run_callable(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1653, in run_callable    return callable_(self, *args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 484, in reflecttable    return insp.reflecttable(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/engine/reflection.py"", line 684, in reflecttable    self._reflect_fk(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/engine/reflection.py"", line 868, in _reflect_fk    sa_schema.Table(  File ""<string>"", line 2, in __new__  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/util/deprecations.py"", line 139, in warned    return fn(*args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/sql/schema.py"", line 563, in __new__    metadata._remove_table(name, schema)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py"", line 68, in __exit__    compat.raise_(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/sql/schema.py"", line 558, in __new__    table._init(name, metadata, *args, **kw)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/sql/schema.py"", line 647, in _init    self._autoload(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/sql/schema.py"", line 670, in _autoload    autoload_with.run_callable(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/engine/base.py"", line 1653, in run_callable    return callable_(self, *args, **kwargs)  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/engine/default.py"", line 484, in reflecttable    return insp.reflecttable(  File ""/Users/sairam/superset-experiment/.venv/lib/python3.8/site-packages/sqlalchemy/engine/reflection.py"", line 678, in reflecttable    raise exc.NoSuchTableError(table.name)sqlalchemy.exc.NoSuchTableError: ab_user```
"
17550,0,0,0,0,0,kamalkeshavani-aiinside,0,"title:[histogram] percentile value in tooltip shows formula instead of value. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to 'FCC New Coder Survey 2018' sample dashboard.2. Check the tooltip in histogram chart 'Age distribution of respondents'### Expected resultsIn tooltip, percentile value should be shown.### Actual resultsIn tooltip, percentile value formula is shown.#### ScreenshotsIf applicable, add screenshots to help explain your problem.![image](https://user-images.githubusercontent.com/74634977/143344424-bb7f7de8-ee48-40c8-b651-5deb8cc29c7b.png)### Environment(please complete the following information):- browser type and version: Chrome 95.0.4638.69- superset version: `master`- python version: `3.7`- node.js version: `14.15.5`- any feature flags active: default### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.cc: @villebro 
"
17519,1,0,0,0,0,wanwengang,0,"title:for pie chart, api: /superset/explore_json/ return {""error"":""'pie'""}, but for dist_bar chart it works well. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to '...'2. Click on '....'3. Scroll down to '....'4. See error### Expected resultswhat you expected to happen.### Actual resultswhat actually happens.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: 1.0- python version: 3.8.12 - node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17508,1,0,8,0,0,TechAuditBI,0,"title:Filter mapping does not apply when configuring charts on nesting tabs level 3 or more . description:While trying to configure filter mapping on nesting tabs structure everything works perfectly until I try to configure charts on level 3 and more.Superset ver. 1.3.2P.S. I think my description provides enough info for bug understanding, please ask for more details if it does not.
"
17498,1,0,10,0,0,iiicon,0,"title:npm run build fail on macos or linux,  windows is ok. description:### linux![image](https://user-images.githubusercontent.com/19875237/142789315-997ed4c6-1877-4d84-98c5-0bf94245e373.png)#### windows![image](https://user-images.githubusercontent.com/19875237/142789374-e0ced9d9-f6ca-45fa-9f99-8886d1355594.png)
"
17469,0,1657,13,0,0,ganczarek,0,"title:Presto engine: zip argument #1 must support iteration. description:When `PRESTO_EXPAND_DATA` is enabled Superset may try to zip with None object when expanding nested data that contains a NULL.If you run this Presto query:```SELECT CAST(NULL              AS ROW(x ROW(y VARCHAR)))UNIONSELECT CAST(ROW(NULL)         AS ROW(x ROW(y VARCHAR)))```then it fails. However, if you run each subquery separately then it won't.#### How to reproduce the bug1. Set `PRESTO_EXPAND_DATA` flag to `True` in your Superset configuration1. Go to SQL Editor1. Select Presto database1. Run the following query:```SELECT CAST(NULL              AS ROW(x ROW(y VARCHAR)))UNIONSELECT CAST(ROW(NULL)         AS ROW(x ROW(y VARCHAR)))UNION SELECT CAST(ROW(ROW(NULL))    AS ROW(x ROW(y VARCHAR)))UNION SELECT CAST(ROW(ROW('test'))  AS ROW(x ROW(y VARCHAR)))```### Expected resultsData with nulls should be expanded and displayed by Superset### Actual resultsAn error is displayed:```DB engine Errorzip argument #1 must support iterationThis may be triggered by:Issue 1011 - Superset encountered an unexpected error. ```### Environment- superset version: `1.3.1` and `1.3.2`- python version: `3.7.12`- any feature flags active: `PRESTO_EXPAND_DATA=True`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextStack trace:```ERROR:superset.views.base:zip argument #1 must support iterationTraceback (most recent call last):  File ""/opt/superset/flask/app.py"", line 1950, in full_dispatch_request    rv = self.dispatch_request()  File ""/opt/superset/flask/app.py"", line 1936, in dispatch_request    return self.view_functions[rule.endpoint](**req.view_args)  File ""/opt/superset/flask_appbuilder/security/decorators.py"", line 151, in wraps    return f(self, *args, **kwargs)  File ""/opt/superset/superset/utils/log.py"", line 241, in wrapper    value = f(*args, **kwargs)  File ""/opt/superset/superset/views/core.py"", line 2209, in results    return self.results_exec(key)  File ""/opt/superset/superset/views/core.py"", line 2280, in results_exec    payload, query, cast(bool, results_backend_use_msgpack)  File ""/opt/superset/superset/views/utils.py"", line 614, in _deserialize_results_payload    ds_payload[""selected_columns""], ds_payload[""data""]  File ""/opt/superset/superset/db_engine_specs/presto.py"", line 876, in expand_data    for value, col in zip(values, expanded):TypeError: zip argument #1 must support iteration```
"
17467,0,0,0,0,0,imanollew,0,"title:When importing a dashboard, it has no owner. description:When importing a dashboard, it has no owner.#### How to reproduce the bugBy UI:1. Go to dashboards list2. Click on ""import dashboard""3. Select the zip file4. Check the dashboard list again. If you are using an admin user you will be able to see the dashboard. It wont have an owner. If you are not an admin you wont be able to see the dashboard.By CLI:1. superset import-dashboards -p /home/superset/superset-1.3.0/dash_imp/dashboard_export_20211117T190343.zip --username user12. Check the dashboard list. If you are using an admin user you will be able to see the dashboard. It wont have an owner. If you are not an admin you wont be able to see the dashboard.### Expected resultsThe expected result is to have an exported dashboard and it has to have an owner.### Actual resultsThe exported dashboard has no owner.#### ScreenshotsAs you can see in the picture, the dashboard has no owners.![issue3](https://user-images.githubusercontent.com/31854621/142273591-ebf4b8a1-3e69-497c-b6d6-d69c0fbc807f.jpg)###Environment(please complete the following information):    firefox:    superset version: 1.3.0    python version: Python 3.7.11    node.js version: v12.22.2    any feature flags active: ""ALERT_REPORTS"": True,    ""ENABLE_TEMPLATE_PROCESSING"": True,    ""DASHBOARD_NATIVE_FILTERS"": True,    ""VERSIONED_EXPORT"":True,    ""DASHBOARD_RBAC"":True###ChecklistMake sure to follow these steps before submitting your issue - thank you!    [X ] I have checked the superset logs for python stacktraces and included it here as text if there are any.    [X ] I have reproduced the issue with at least the latest released version of superset.    [X ] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17447,1,0,0,0,0,imanollew,0,"title:Changing the language of Superset doesnt change the month's language in a chart. description:Changing the language of Superset doesnt change the months language in a chart#### How to reproduce the bug1. Enable Languages on Superset, by modifying the file ""config.py""; adding LANGUAGES = { ""en"": {""flag"": ""us"", ""name"": ""English""},""es"": {""flag"": ""es"", ""name"": ""Spanish""}}2. Click on the flag, switch the language.3. Now, the whole interface is in the desired language EXCEPT the months on any kind of chart.### Expected resultsThe name of each month should be in my desired language.### Actual resultsThe name of each month is still in english.![ss1](https://user-images.githubusercontent.com/31854621/142002612-90f440da-ca64-4794-86f7-5b9222c198c6.png)### Environment(please complete the following information):- firefox:- superset version: 1.3.0- python version: Python 3.7.11- node.js version: v12.22.2- any feature flags active:  ""ALERT_REPORTS"": True,			               ""ENABLE_TEMPLATE_PROCESSING"": True,			               ""DASHBOARD_NATIVE_FILTERS"": True,                                       ""VERSIONED_EXPORT"":True,			                ""DASHBOARD_RBAC"":True### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X ] I have reproduced the issue with at least the latest released version of superset.- [X ] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17443,1,0,40,0,0,jinghua-qa,0,"title:[color consistency][pie chart] Confused color behavior When #series is one more than #color in pie chart. description:When #series is one more than #color, pie chart has 2 consecutive same color#### How to reproduce the bug1. Go to cleaned sales data2. create a pie chart with Metric for count(*) and group by month3. Select color theme Echart v4.x colors4. Observe the color of the 1st section and last section on pie chart### Expected results1st section and last section in pie chart in different color ### Actual results1st section and last section in pie chart in same color and seem connected #### Screenshots<img width=""1790"" alt=""Screen Shot 2021-11-15 at 6 11 53 PM"" src=""https://user-images.githubusercontent.com/81597121/141883669-94b5d1ab-87fb-48ce-8caa-e0ef95f870da.png"">### Environment(please complete the following information):- browser type and version:- superset version: master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17441,0,0,291,0,0,hbruch,0,"title:German translations missing or wrong. description:Currently, many German translations are missing or wrong.I'm planning to provide a PR contributing PO/JSON files for the `de` locale. Mimicking the good practice of @audour who reported likewise for the French locale in #16550, this issues report serves as announcement so other contributors do not duplicate efforts (or report if they are already working on the same), like #16550 did for the French locale.However, before requesting a PR, I have some questions regarding this contribution:- I planed to work on the master branch, while #16868 is based on 1.3.0 version. What do you prefer?- #16868 did not include an updated `pot` file. I did not check yet, but I assume it's up-to-date for 1.3.0.(?). In case I'd submit a PR for master: should it contain the updated `pot` file and all `po`/`json`files for all locales or just the `de` locale I'm working on?- There a couple of messages, which are not localized yet (e.g. `View all`, `Viewed` in the CRUD welcome tables, `See all` in `EmptyState.tsx`, `settings` in the `MenuRight.tsx`. For those, I'd provide a preceding PR, if I base my contributions on `master`.
"
17421,0,0,0,0,0,LalaGabor,0,"title:HTML not displaying in Markdown when RBAC flag is TRUE. description:#### How to reproduce the bug1. Enable Role based access control2. Create a Dashboard3. Create a markdown Field in the dashboard4. Write in the markdown field: 1235. Result: 123 is displayed in the markdown field6. Write in the markdown Field: <h1>123</h1>### Expected resultsText: 123 is displayed as a header in the markdown field### Actual resultsNo Text is displayed#### Screenshots![image](https://user-images.githubusercontent.com/44199231/141434516-1296b475-2f36-44a1-a00c-6d33150e491f.png)![image](https://user-images.githubusercontent.com/44199231/141434617-480a779a-86f0-4272-bf20-da218990603a.png)### Environment(please complete the following information):- browser type and version: Firefox- superset version: 1.2- any feature flags active: RBAC
"
17418,1,0,0,0,0,qinlz-1,0,"title:can not find 1.0 version. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to '...'2. Click on '....'3. Scroll down to '....'4. See error### Expected resultswhat you expected to happen.### Actual resultswhat actually happens.#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context/usr/local/bin/pip3.6 install apache-superset==Collecting apache-superset==  Could not find a version that satisfies the requirement apache-superset== (from versions: 0.34.0, 0.34.1, 0.35.1, 0.35.2, 0.36.0, 0.37.0, 0.37.1, 0.37.2, 0.38.0, 0.38.1)
"
17401,1,0,0,0,0,code23rus,0,"title:NameError: name 'AUTH_OAUTH' is not defined. description:I want to set up OAuth2 authorization, but it not work.#### How to reproduce the bug1. Install superset according to the instructions: https://superset.apache.org/docs/installation/installing-superset-using-docker-compose2. According documentation https://superset.apache.org/docs/installation/configuring-superset add the lines to the end of the superset_config.py file:	AUTH_TYPE = AUTH_OAUTH	OAUTH_PROVIDERS = [		{   'name':'egaSSO',			'token_key':'access_token',			'icon':'fa-address-card', 			'remote_app': {				'client_id':'myClientId',				'client_secret':'MySecret',				'client_kwargs':{					'scope': 'read'              				},				'access_token_method':'POST', 				'access_token_params':{        					'client_id':'myClientId'				},				'access_token_headers':{   					'Authorization': 'Basic Base64EncodedClientIdAndSecret'				},				'api_base_url':'https://myAuthorizationServer/oauth2AuthorizationServer/',				'access_token_url':'https://myAuthorizationServer/oauth2AuthorizationServer/token',				'authorize_url':'https://myAuthorizationServer/oauth2AuthorizationServer/authorize'			}		}	]	AUTH_USER_REGISTRATION = True	AUTH_USER_REGISTRATION_ROLE = ""Public""3. Restart docker-compose containers4. See error	superset_app            | NameError: name 'AUTH_OAUTH' is not defined	superset_app            | Failed to create app	superset_app            | Traceback (most recent call last):	superset_app            |   File ""/app/superset/app.py"", line 34, in create_app	superset_app            |     app.config.from_object(config_module)	superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask/config.py"", line 174, in from_object	superset_app            |     obj = import_string(obj)	superset_app            |   File ""/usr/local/lib/python3.8/site-packages/werkzeug/utils.py"", line 568, in import_string	superset_app            |     __import__(import_name)	superset_app            |   File ""/app/superset/config.py"", line 1303, in <module>	superset_app            |     import superset_config  # pylint: disable=import-error	superset_app            |   File ""/app/docker/pythonpath_dev/superset_config.py"", line 116, in <module>	superset_app            |     AUTH_TYPE = AUTH_OAUTH	superset_app            | NameError: name 'AUTH_OAUTH' is not defined	superset_app            | [2021-11-11 09:58:28 +0000] [12] [ERROR] Exception in worker process	superset_app            | Traceback (most recent call last):	superset_app            |   File ""/usr/local/lib/python3.8/site-packages/gunicorn/arbiter.py"", line 583, in spawn_worker	superset_app            |     worker.init_process()	superset_app            |   File ""/usr/local/lib/python3.8/site-packages/gunicorn/workers/gthread.py"", line 92, in init_process	superset_app            |     super().init_process()	superset_app            |   File ""/usr/local/lib/python3.8/site-packages/gunicorn/workers/base.py"", line 119, in init_process	superset_app            |     self.load_wsgi()	superset_app            |   File ""/usr/local/lib/python3.8/site-packages/gunicorn/workers/base.py"", line 144, in load_wsgi	superset_app            |     self.wsgi = self.app.wsgi()	superset_app            |   File ""/usr/local/lib/python3.8/site-packages/gunicorn/app/base.py"", line 67, in wsgi	superset_app            |     self.callable = self.load()	superset_app            |   File ""/usr/local/lib/python3.8/site-packages/gunicorn/app/wsgiapp.py"", line 49, in load	superset_app            |     return self.load_wsgiapp()	superset_app            |   File ""/usr/local/lib/python3.8/site-packages/gunicorn/app/wsgiapp.py"", line 39, in load_wsgiapp	superset_app            |     return util.import_app(self.app_uri)	superset_app            |   File ""/usr/local/lib/python3.8/site-packages/gunicorn/util.py"", line 411, in import_app	superset_app            |     app = app(*args, **kwargs)	superset_app            |   File ""/app/superset/app.py"", line 44, in create_app	superset_app            |     raise ex	superset_app            |   File ""/app/superset/app.py"", line 34, in create_app	superset_app            |     app.config.from_object(config_module)	superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask/config.py"", line 174, in from_object	superset_app            |     obj = import_string(obj)	superset_app            |   File ""/usr/local/lib/python3.8/site-packages/werkzeug/utils.py"", line 568, in import_string	superset_app            |     __import__(import_name)	superset_app            |   File ""/app/superset/config.py"", line 1303, in <module>	superset_app            |     import superset_config  # pylint: disable=import-error	superset_app            |   File ""/app/docker/pythonpath_dev/superset_config.py"", line 116, in <module>	superset_app            |     AUTH_TYPE = AUTH_OAUTH	superset_app            | NameError: name 'AUTH_OAUTH' is not defined	superset_app            | [2021-11-11 09:58:28 +0000] [12] [INFO] Worker exiting (pid: 12)	superset_app            | [2021-11-11 09:58:28 +0000] [10] [INFO] Shutting down: Master	superset_app            | [2021-11-11 09:58:28 +0000] [10] [INFO] Reason: Worker failed to boot.### EnvironmentEnvironment latest, according latest docker-compose images.### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17391,1,3142,1,0,1,Pajri,0,"title:NameError: name 'request' is not defined. description:I tried to access url that is not found (ex : /notfoundpage), but it returns internal server error instead of not found page.#### How to reproduce the bug1. Go to ' /notfoundpage' or any path that is not exists2. You see Internal Server Error### Expected resultsShow error not found page### Actual resultsInternal Server Error pageLog : ````[2021-11-10 09:20:26 +0000] [53] [ERROR] Error handling request /favicon.icoTraceback (most recent call last):  File ""/usr/local/lib/python3.7/site-packages/flask/app.py"", line 1950, in full_dispatch_request    rv = self.dispatch_request()  File ""/usr/local/lib/python3.7/site-packages/flask/app.py"", line 1926, in dispatch_request    self.raise_routing_exception(req)  File ""/usr/local/lib/python3.7/site-packages/flask/app.py"", line 1908, in raise_routing_exception    raise request.routing_exception  File ""/usr/local/lib/python3.7/site-packages/flask/ctx.py"", line 350, in match_request    result = self.url_adapter.match(return_rule=True)  File ""/usr/local/lib/python3.7/site-packages/werkzeug/routing.py"", line 1945, in match    raise NotFound()werkzeug.exceptions.NotFound: 404 Not Found: The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/usr/local/lib/python3.7/site-packages/gunicorn/workers/gthread.py"", line 271, in handle    keepalive = self.handle_request(req, conn)  File ""/usr/local/lib/python3.7/site-packages/gunicorn/workers/gthread.py"", line 320, in handle_request    respiter = self.wsgi(environ, resp.start_response)  File ""/usr/local/lib/python3.7/site-packages/flask/app.py"", line 2464, in __call__    return self.wsgi_app(environ, start_response)  File ""/usr/local/lib/python3.7/site-packages/werkzeug/middleware/proxy_fix.py"", line 169, in __call__    return self.app(environ, start_response)  File ""/usr/local/lib/python3.7/site-packages/flask/app.py"", line 2450, in wsgi_app    response = self.handle_exception(e)  File ""/usr/local/lib/python3.7/site-packages/flask_cors/extension.py"", line 165, in wrapped_function    return cors_after_request(app.make_response(f(*args, **kwargs)))  File ""/usr/local/lib/python3.7/site-packages/flask/app.py"", line 1867, in handle_exception    reraise(exc_type, exc_value, tb)  File ""/usr/local/lib/python3.7/site-packages/flask/_compat.py"", line 39, in reraise    raise value  File ""/usr/local/lib/python3.7/site-packages/flask/app.py"", line 2447, in wsgi_app    response = self.full_dispatch_request()  File ""/usr/local/lib/python3.7/site-packages/flask/app.py"", line 1952, in full_dispatch_request    rv = self.handle_user_exception(e)  File ""/usr/local/lib/python3.7/site-packages/flask_cors/extension.py"", line 165, in wrapped_function    return cors_after_request(app.make_response(f(*args, **kwargs)))  File ""/usr/local/lib/python3.7/site-packages/flask/app.py"", line 1816, in handle_user_exception    return self.handle_http_exception(e)  File ""/usr/local/lib/python3.7/site-packages/flask/app.py"", line 1744, in handle_http_exception    return handler(e)  File ""/app/superset/views/base.py"", line 368, in show_http_exception    ""text/html"" in request.accept_mimetypesNameError: name 'request' is not defined10.190.12.34 - - [10/Nov/2021:09:20:26 +0000] ""GET /favicon.ico HTTP/1.1"" 500 0 ""-"" ""-""````#### Screenshots![image](https://user-images.githubusercontent.com/6915392/141088212-7ef98746-0c75-4900-a431-6d3f0ef34f66.png)### Environment(please complete the following information):- python version 3.7.12### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17390,0,0,14,0,0,xingyuli,0,"title:unable to update dataset metric's label via the rest PUT api. description:It's not possible to update dataset metric's label (i.e., verbose_name) via the PUT API.#### How to reproduce the bugVisit the online rest documentation. You could see the payload is not able to receive verbose_name:![image](https://user-images.githubusercontent.com/3337431/141077783-8d93d2cd-c160-4ded-8f9e-e4b41d7bdf81.png)### Expected resultsPossible to update the metric label (verbose_name).### Actual resultsUnable to do so.#### ScreenshotsSee above.### Environment(please complete the following information):- browser type and version:- superset version: 1.1.0(which I'm using), and the latest version from the online rest doc
"
17381,1,0,0,0,0,lukelin780902,0,"title:Got error while exporting csv in dashboards. description:I was trying to export the data from dashboards by clicking Export CSV, like below, but got error saying `{""message"":""Error: Error (planning_exception): {'error': {'root_cause': [{'type': 'planning_exception', 'reason': 'The maximum LIMIT for aggregate sorting is [65536], received [100000]'}], 'type': 'planning_exception', 'reason': 'The maximum LIMIT for aggregate sorting is [65536], received [100000]'}, 'status': 400}""}`![image](https://user-images.githubusercontent.com/85915449/140958516-d8aed43c-b956-45cc-afc4-0c61fbc392cd.png)However, if I go to 'view chart in Explore' and exporting csv by click 'CSV icon', then the whole queried data can be exported successfully. Does anyone know how it was caused and how to solve it?### Expected resultsexport and download CSV from the dashboards tab.### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ V] I have reproduced the issue with at least the latest released version of superset.- [ V] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17373,1,0,0,0,0,JoaquinPretell92,0,"title:Cant Access Superset in local enviroment. description:Hello,I download and run the last superset image on my window docker and i dont get any error in the image pull and run, but when i try to enter the page i get ""ERR_CONNECTION_REFUSED"" error. I dont know if i have to change in any file something to make it work.On the container logs i only get the message in the picture uploaded.127.0.0.1 - - [08/Nov/2021:15:43:19 +0000] ""GET /health HTTP/1.1"" 200 2 ""-"" ""curl/7.74.0""![image](https://user-images.githubusercontent.com/73810312/140772862-96fe0325-4006-45e6-81bc-0d4b78cd8b9f.png)![image](https://user-images.githubusercontent.com/73810312/140772880-a48785d1-3c6f-4eb1-99cf-a87c75eb262a.png)
"
17355,1,390,22,0,0,JPMoresmau,0,"title:500 error while adding connection to ElasticSearch. description:#### How to reproduce the bug1. Go to 'Data -> Databases -> +Database'2. Click on 'Other'3. Enter SQLAlchemy URL: elasticsearch+http://localhost:9200/4. get a 500 error in a popup. Action Log shows test_connection_error.ModuleNotFoundError### Expected resultsA connection to ElasticSearch. If I run superset shell in my docker container I can connect to elastic search so elasticsearch-dbapi is installed and the url is correct### Actual resultsAn error in the UI. I have no log file I can find to provide more. There is no /app/super_home/superset.log file???### Environment(please complete the following information):- browser type and version: Firefox- superset version: Superset 0.0.0dev- python version: Python 3.8.12- node.js version: node: command not found- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any. -> where is the log? I can't find it, There is no /app/super_home/superset.log file, and docker logs gives me nothing- [X] I have reproduced the issue with at least the latest released version of superset. Well I built the docker image as indicated at https://hub.docker.com/r/apache/superset - [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextRunning one docker container, this is my dockerfile:```FROM apache/supersetUSER rootRUN pip install psycopg2-binaryRUN pip install elasticsearch-dbapiUSER supersetRUN superset fab create-admin \               --username admin \               --firstname Superset \               --lastname Admin \               --email admin@superset.com \               --password adminRUN superset db upgradeRUN superset init```
"
17339,1,0,0,0,0,tiexiw,0,"title:An error is reported when querying the SAP HANA database.. description:The SAP HANA database query data reported an error, and the query statement was placed in another ide to return the correct result.#### How to reproduce the bug1. Install the SAP Hana SQLAlchemy driver.2. Configuration data information: hana://HC_DW:XXXXXXXXXX@192.172.1.23:300153. Create data set: An error occurred while creating data set s: Unable to create data set.4. SQL editor query data: hana error:'pyhdbcli.Cursor' object has no attribute'tzinfo_factory'.### Expected resultsReturn a preview of the query data result.### Actual resultsError message is returned.#### Screenshots### Environment(please complete the following information):- browser type and version: Chrome 94.0.4606.61- superset version: `superset 1.3.2`- python version: `python 3.8.5`- node.js version: `node v12.20.0`- any feature flags active:
"
17334,1,0,9,0,0,jordiisidro,0,"title:Fatal error when export dashboards. description:I want to export a dashboard with the api and I have the result ""Fatal error""I try to export the default dashboard: World Bank's Data With the url: http://localhost:8089/api/v1/dashboard/export/?q=[1]It returns the message: ""Fatal error""I have the same result with docker installation or installation from scratch![imatge](https://user-images.githubusercontent.com/19467312/140058144-7a9cbff2-7d37-4ae0-9998-f223739c8b64.png)### Environment- browser type and version: chrome/firefox- superset version: 1.3.1- python version: 3.8.19- node.js version: v.17.0.1
"
17327,1,0,58,0,0,kojiromike,0,"title:Docs Imply Psycopg2 Not Already Installed. description:https://superset.apache.org/docs/databases/installing-database-drivers states> Superset does not ship bundled with connectivity to databases, except for SQLiteLater on in the same doc, it lists `psycopg2` as required for postgresql and various other postgresql-like databases. The thing is, Superset already requires psycopg2 in a lot of contexts. It's included in the requirements/docker.txt and the bootstrapScript for the helm chart.So, what I'm confused about, is do I still need to explicitly install psycopg2 if I'm using docker-compose or helm to run Superset? Either way, could this be made clearer in the documentation?### Environment(please complete the following information):- superset version: master, from bea8502- using the vanilla helm chart from bea8502
"
17324,1,0,0,0,0,graceguo-supercat,0,"title:[explore][time-series chart] Can not see all labels on hover chart. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Make a dataset with high-cardinality.2. create a Time Series chart, and add group by the high-cardinality column. for example, this chart shows population group by country:<img width=""1216"" alt=""Screen Shot 2021-11-02 at 10 48 29 AM"" src=""https://user-images.githubusercontent.com/27990562/139918883-eb8c4cca-3d10-4562-8515-1f35d0f0d96d.png"">3. Hover on the chart, the tooltip can not display all countries, more than half of them are out of visible area. There is no scrollbar in the tooltip, so there is no way for users to see all the values.4. This issue makes this data visualization misleading. People may read hover tooltip to find largest / smallest / etc, value for a given group-by, but we only display half of all the values.### Expected resultsdisplay all the values for the given group-by column.### Environmentlatest master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextcc @junlincc @villebro 
"
17318,0,0,164,0,0,geido,0,"title:[Explore] Linear color scheme options do not work . description:While scrolling the Linear color scheme options, suddenly all the options become the same.#### How to reproduce the bug1. Go to the ""Vaccine Candidates per Country & Stage"" sample Chart2. Click on ""Linear color scheme"" under ""Heatmap options""3. Scroll the options to the bottom and up a few times4. Suddenly all the options become the same### Expected resultsWhile scrolling the color scheme options should not become the same### Actual resultsAll color scheme options suddenly become the same while scrolling#### Screenshotshttps://user-images.githubusercontent.com/60598000/139827865-63f1b97b-96a6-4436-b608-bcfe6fb27575.mp4### Environment(please complete the following information):- browser type and version: Chrome 95.0.4638.54- superset version: master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17317,1,0,0,0,0,suraj-12,0,"title:issue while getting parameter value from url  in superset 1.3. description:I am using superset version 1.3 and not able to fetch parameter value from url which was working earlier in 0.3 version.i am using url_param. query example ex:- CostCenter is not null and CostCenter  IN ({{url_param('costCenter')}})
"
17308,0,0,0,0,0,danisola,0,"title:Visualizations don't load when using keyboard shortcuts. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to explore page and select a few metrics2. Expand the data panel3. Run the query using the keyboard (Ctrl + Enter in a Mac)### Expected resultsThe visualization loads correctly.### Actual resultsData loads but not the visualization:![image](https://user-images.githubusercontent.com/4731758/139708573-0c486530-48ba-4544-88f8-16a6c37b379c.png)### Environment(please complete the following information):- browser type and version: reproduced in current versions of Firefox and Chrome- superset version: `1.3.2`### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17301,0,0,1,0,0,Pajri,0,"title:Unauthorized Page Returns 302 Instead of 403. description:Hi, I tried to remove logmodelview/ access permission in a role. However, when access page /logmodelview/list/, it returns 302 instead of 403.How to handle unauthorized access to a page ?#### How to reproduce the bug1. Remove logmodelview permission in a role (all of them)2. Access logmodelview/list/3. It returns 302 ### Expected resultsIt should return 403### Actual resultsIt returns 302#### Screenshots![image](https://user-images.githubusercontent.com/6915392/139638887-ac8a0b2b-4b9d-4385-81d7-b34b4809ed91.png)### Environment(please complete the following information):- microsoft edge### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17294,0,0,0,0,0,exemplary-citizen,0,"title:insufficient db migration in #16756. description:db migration in #16756 was not suffice. The `dbs.extra` JSON encoded field needs to be updated given that the `schemas_allowed_for_csv_upload` field was renamed to `schemas_allowed_for_file_upload`.cc: @john-bodley 
"
17288,0,0,164,0,0,geido,0,"title:[Lists] Searching for & produces a fatal error in the API. description:Searching for & produces a fatal error in the API#### How to reproduce the bug1. Go to Dashboard lists2. Search for the & character in the search box3. Observe the error### Expected resultsSearching for & should not produce a fatal error### Actual resultsSearching for & produces a fatal error#### Screenshotshttps://user-images.githubusercontent.com/60598000/139466344-d3e3c93e-6d6e-4758-9fbc-ae8345643a04.mp4### Environment- superset version: `master`
"
17272,1,0,0,0,0,jsanko9,0,"title:Conflict between Domain Sharding and Webdriver Configuration. description:Bug happens between two config parameters:WEBDRIVER_BASEURLSUPERSET_WEBSERVER_DOMAINSOnce SUPERSET_WEBSERVER_DOMAINS is set, it is used for resource requests  on ""standalone page"", resulting in timeout by selenium. This seems as logical conflict. Worst part is amount of testing I had to do to find out which interaction was causing problem.**Workaround** is to set WEBDRIVER_BASEURL to same value as WEBDRIVER_BASEURL_USER_FRIENDLY and bypass internal kubernetes service routing.### Expected resultsWEBDRIVER_BASEURL should take precedence by knowing, or notification should be generated that there is logical conflict### Actual resultsSelenium Timed out receiving message from renderer### Environmentsuperset version 1.3.2 chrome driverPython 3.8.12Node 14### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.    -  sorry, already lost them- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17271,1,0,0,0,0,zuzana-vej,0,"title:Metric lingers around after switching chart type from big number with trendline to line chart. description:### Description:When switching from a populated big number with trendline chart to a line chart and choosing a different metric, the old metric will still show in the line chart. This is also valid when switching to time series line chart. If you share the new chart through a link, the old metric goes away. See attachments.### Platform Details:Browser: ChromeDevice: MBP### Steps to Reproduce:Open a big number with trendline chart (possibly also works with big number)Switch the chart type to line chart or time series line chart. The metric box will clear.Add a new metric, different from the previous one.Run the chart.### Result:You will see both the old and new metrics.### Expected Result:Only the new metric should show up.### Environmentlatest master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17267,1,0,1,0,0,mbtronics,0,"title:jinja2 context not working with native filters. description:When using filter_values from the jinja2 context in a dataset, the native filters are not available, only old school filter boxes.Dataset looks like this:select * from searcheswhere timestamp_year=2020and ({% for item in filter_values(""search_term"") %}description ILIKE '{{ ""%"" + item + ""%"" }}'{% if not loop.last %} OR {% endif %}{% endfor %})This works with a filter box (chart), but not with native dashboard filters.Tested on this docker image: https://hub.docker.com/layers/apache/superset/latest/images/sha256-ae79a12a6b679dac1472494be6d8e80a384f1b02a6dc146ed7293a802671d58b?context=explore .If somebody could point where to look for this in the code, I could probably make a merge request for this.
"
17262,0,32257,0,0,1,CodeingBoy,0,"title:Complex query with Hive will cause errors. description:While doing complex query in SQLLab (which will use MapReduce and create tracking url), will cause this error:```Instance <Query at 0x7fdf546d5fd0> is not bound to a Session; attribute refresh operation cannot proceed (Background on this error at: http://sqlalche.me/e/13/bhk3)```#### How to reproduce the bug1. Go to 'SQL Lab'2. Execute some complex query(it should not be simple like `SELECT * FROM table`, that will not use MapReduce)3. See errorHere's a sample data SQL you can reproduce:```CREATE TABLE some_table(    a INT,    b STRING);INSERT INTO some_table(a, b) VALUES (1, '1'), (2, '2'), (3, '3'), (4, '4');```While executing `SELECT a, COUNT(1) AS count FROM some_table GROUP BY a;`, will cause this error. (Screenshot below)### Expected resultsExecute query with no error and display results.### Actual resultsCausing this error:```Database errorInstance <Query at 0x7fdf4c04dd10> is not bound to a Session; attribute refresh operation cannot proceed (Background on this error at: http://sqlalche.me/e/13/bhk3)```Logs will print this stack trace:```Instance <Query at 0x7fdf0c7da990> is not bound to a Session; attribute refresh operation cannot proceed (Background on this error at: http://sqlalche.me/e/13/bhk3)Traceback (most recent call last):  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py"", line 1277, in _execute_context    cursor, statement, parameters, context  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py"", line 593, in do_execute    cursor.execute(statement, parameters)sqlite3.InterfaceError: Error binding parameter 0 - probably unsupported type.The above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/app/superset/sql_lab.py"", line 268, in execute_sql_statement    db_engine_spec.handle_cursor(cursor, query, session)  File ""/app/superset/db_engine_specs/hive.py"", line 376, in handle_cursor    session.commit()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1042, in commit    self.transaction.commit()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 504, in commit    self._prepare_impl()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 483, in _prepare_impl    self.session.flush()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2536, in flush    self._flush(objects)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2678, in _flush    transaction.rollback(_capture_exception=True)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py"", line 70, in __exit__    with_traceback=exc_tb,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2638, in _flush    flush_context.execute()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py"", line 422, in execute    rec.execute(self)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py"", line 589, in execute    uow,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py"", line 236, in save_obj    update,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py"", line 995, in _emit_update_statements    statement, multiparams  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py"", line 1011, in execute    return meth(self, multiparams, params)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py"", line 298, in _execute_on_connection    return connection._execute_clauseelement(self, multiparams, params)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py"", line 1130, in _execute_clauseelement    distilled_params,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py"", line 1317, in _execute_context    e, statement, parameters, cursor, context  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py"", line 1511, in _handle_dbapi_exception    sqlalchemy_exception, with_traceback=exc_info[2], from_=e  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py"", line 1277, in _execute_context    cursor, statement, parameters, context  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py"", line 593, in do_execute    cursor.execute(statement, parameters)sqlalchemy.exc.InterfaceError: (sqlite3.InterfaceError) Error binding parameter 0 - probably unsupported type.[SQL: UPDATE ""query"" SET tracking_url=?, changed_on=? WHERE ""query"".id = ?][parameters: (<function <lambda> at 0x7fdf5959d3b0>, '2021-10-28 02:25:09.432381', 35)](Background on this error at: http://sqlalche.me/e/13/rvf5)During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/sql_lab.py"", line 483, in execute_sql_statements    apply_ctas,  File ""/app/superset/sql_lab.py"", line 298, in execute_sql_statement    session.refresh(query)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1718, in refresh    only_load_props=attribute_names,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py"", line 206, in load_on_ident    identity_token=identity_token,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py"", line 286, in load_on_pk_identity    return q.one()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3490, in one    ret = self.one_or_none()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3459, in one_or_none    ret = list(self)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3535, in __iter__    return self._execute_and_instances(context)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3557, in _execute_and_instances    querycontext, self._connection_from_session, close_with_result=True  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3572, in _get_bind_args    mapper=self._bind_mapper(), clause=querycontext.statement, **kw  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3550, in _connection_from_session    conn = self.session.connection(**kw)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1141, in connection    execution_options=execution_options,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1147, in _connection_for_bind    engine, execution_options  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 409, in _connection_for_bind    self._assert_active()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 296, in _assert_active    code=""7s2a"",sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.InterfaceError) Error binding parameter 0 - probably unsupported type.[SQL: UPDATE ""query"" SET tracking_url=?, changed_on=? WHERE ""query"".id = ?][parameters: (<function <lambda> at 0x7fdf5959d3b0>, '2021-10-28 02:25:09.432381', 35)](Background on this error at: http://sqlalche.me/e/13/rvf5) (Background on this error at: http://sqlalche.me/e/13/7s2a)During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/sql_lab.py"", line 186, in get_sql_results    log_params=log_params,  File ""/app/superset/sql_lab.py"", line 496, in execute_sql_statements    ex, query, session, payload, prefix_message  File ""/app/superset/sql_lab.py"", line 112, in handle_query_error    errors = query.database.db_engine_spec.extract_errors(str(ex))  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 287, in __get__    return self.impl.get(instance_state(instance), dict_)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 723, in get    value = self.callable_(state, passive)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/strategies.py"", line 727, in _load_for_state    session, state, passive  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/strategies.py"", line 775, in _get_ident_for_use_get    for pk in self.mapper.primary_key  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/strategies.py"", line 775, in <listcomp>    for pk in self.mapper.primary_key  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/mapper.py"", line 2845, in _get_state_attr_by_column    return state.manager[prop.key].impl.get(state, dict_, passive=passive)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 718, in get    value = state._load_expired(state, passive)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/state.py"", line 652, in _load_expired    self.manager.deferred_scalar_loader(self, toload)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py"", line 1010, in load_scalar_attributes    only_load_props=attribute_names,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py"", line 206, in load_on_ident    identity_token=identity_token,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py"", line 286, in load_on_pk_identity    return q.one()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3490, in one    ret = self.one_or_none()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3459, in one_or_none    ret = list(self)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3535, in __iter__    return self._execute_and_instances(context)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3557, in _execute_and_instances    querycontext, self._connection_from_session, close_with_result=True  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3572, in _get_bind_args    mapper=self._bind_mapper(), clause=querycontext.statement, **kw  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3550, in _connection_from_session    conn = self.session.connection(**kw)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1141, in connection    execution_options=execution_options,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1147, in _connection_for_bind    engine, execution_options  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 409, in _connection_for_bind    self._assert_active()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 296, in _assert_active    code=""7s2a"",sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.InterfaceError) Error binding parameter 0 - probably unsupported type.[SQL: UPDATE ""query"" SET tracking_url=?, changed_on=? WHERE ""query"".id = ?][parameters: (<function <lambda> at 0x7fdf5959d3b0>, '2021-10-28 02:25:09.432381', 35)](Background on this error at: http://sqlalche.me/e/13/rvf5) (Background on this error at: http://sqlalche.me/e/13/7s2a)During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/sql_lab.py"", line 151, in get_query    return session.query(Query).filter_by(id=query_id).one()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3490, in one    ret = self.one_or_none()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3459, in one_or_none    ret = list(self)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3534, in __iter__    self.session._autoflush()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1618, in _autoflush    self.flush()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2536, in flush    self._flush(objects)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2633, in _flush    subtransactions=True  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 953, in begin    self.transaction = self.transaction._begin(nested=nested)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 317, in _begin    self._assert_active()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 296, in _assert_active    code=""7s2a"",sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.InterfaceError) Error binding parameter 0 - probably unsupported type.[SQL: UPDATE ""query"" SET tracking_url=?, changed_on=? WHERE ""query"".id = ?][parameters: (<function <lambda> at 0x7fdf5959d3b0>, '2021-10-28 02:25:09.432381', 35)](Background on this error at: http://sqlalche.me/e/13/rvf5) (Background on this error at: http://sqlalche.me/e/13/7s2a)During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/usr/local/lib/python3.7/site-packages/backoff/_sync.py"", line 94, in retry    ret = target(*args, **kwargs)  File ""/app/superset/sql_lab.py"", line 153, in get_query    raise SqlLabException(""Failed at getting query"")superset.sql_lab.SqlLabException: Failed at getting queryDuring handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/views/core.py"", line 2534, in _sql_json_sync    log_params=log_params,  File ""/usr/local/lib/python3.7/site-packages/celery/local.py"", line 191, in __call__    return self._get_current_object()(*a, **kw)  File ""/app/superset/initialization/__init__.py"", line 103, in __call__    return task_base.__call__(self, *args, **kwargs)  File ""/usr/local/lib/python3.7/site-packages/celery/app/task.py"", line 393, in __call__    return self.run(*args, **kwargs)  File ""/app/superset/sql_lab.py"", line 191, in get_sql_results    query = get_query(query_id, session)  File ""/usr/local/lib/python3.7/site-packages/backoff/_sync.py"", line 110, in retry    _call_handlers(on_backoff, *details, wait=seconds)  File ""/usr/local/lib/python3.7/site-packages/backoff/_sync.py"", line 20, in _call_handlers    hdlr(details)  File ""/app/superset/sql_lab.py"", line 126, in get_query_backoff_handler    query_id = details[""kwargs""][""query_id""]KeyError: 'query_id'During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/views/base.py"", line 204, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/utils/log.py"", line 241, in wrapper    value = f(*args, **kwargs)  File ""/app/superset/views/core.py"", line 2573, in sql_json    return self.sql_json_exec(request.json, log_params)  File ""/app/superset/views/core.py"", line 2762, in sql_json_exec    session, rendered_query, query, expand_data, log_params  File ""/app/superset/views/core.py"", line 2551, in _sql_json_sync    logger.exception(""Query %i failed unexpectedly"", query.id)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 287, in __get__    return self.impl.get(instance_state(instance), dict_)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 718, in get    value = state._load_expired(state, passive)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/state.py"", line 652, in _load_expired    self.manager.deferred_scalar_loader(self, toload)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py"", line 944, in load_scalar_attributes    ""attribute refresh operation cannot proceed"" % (state_str(state))sqlalchemy.orm.exc.DetachedInstanceError: Instance <Query at 0x7fdf0c7da990> is not bound to a Session; attribute refresh operation cannot proceed (Background on this error at: http://sqlalche.me/e/13/bhk3)2021-10-28 02:25:09,668:ERROR:superset.views.base:Instance <Query at 0x7fdf0c7da990> is not bound to a Session; attribute refresh operation cannot proceed (Background on this error at: http://sqlalche.me/e/13/bhk3)Traceback (most recent call last):  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py"", line 1277, in _execute_context    cursor, statement, parameters, context  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py"", line 593, in do_execute    cursor.execute(statement, parameters)sqlite3.InterfaceError: Error binding parameter 0 - probably unsupported type.The above exception was the direct cause of the following exception:Traceback (most recent call last):  File ""/app/superset/sql_lab.py"", line 268, in execute_sql_statement    db_engine_spec.handle_cursor(cursor, query, session)  File ""/app/superset/db_engine_specs/hive.py"", line 376, in handle_cursor    session.commit()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1042, in commit    self.transaction.commit()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 504, in commit    self._prepare_impl()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 483, in _prepare_impl    self.session.flush()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2536, in flush    self._flush(objects)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2678, in _flush    transaction.rollback(_capture_exception=True)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py"", line 70, in __exit__    with_traceback=exc_tb,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2638, in _flush    flush_context.execute()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py"", line 422, in execute    rec.execute(self)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py"", line 589, in execute    uow,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py"", line 236, in save_obj    update,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py"", line 995, in _emit_update_statements    statement, multiparams  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py"", line 1011, in execute    return meth(self, multiparams, params)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py"", line 298, in _execute_on_connection    return connection._execute_clauseelement(self, multiparams, params)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py"", line 1130, in _execute_clauseelement    distilled_params,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py"", line 1317, in _execute_context    e, statement, parameters, cursor, context  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py"", line 1511, in _handle_dbapi_exception    sqlalchemy_exception, with_traceback=exc_info[2], from_=e  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_    raise exception  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/base.py"", line 1277, in _execute_context    cursor, statement, parameters, context  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/engine/default.py"", line 593, in do_execute    cursor.execute(statement, parameters)sqlalchemy.exc.InterfaceError: (sqlite3.InterfaceError) Error binding parameter 0 - probably unsupported type.[SQL: UPDATE ""query"" SET tracking_url=?, changed_on=? WHERE ""query"".id = ?][parameters: (<function <lambda> at 0x7fdf5959d3b0>, '2021-10-28 02:25:09.432381', 35)](Background on this error at: http://sqlalche.me/e/13/rvf5)During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/sql_lab.py"", line 483, in execute_sql_statements    apply_ctas,  File ""/app/superset/sql_lab.py"", line 298, in execute_sql_statement    session.refresh(query)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1718, in refresh    only_load_props=attribute_names,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py"", line 206, in load_on_ident    identity_token=identity_token,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py"", line 286, in load_on_pk_identity    return q.one()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3490, in one    ret = self.one_or_none()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3459, in one_or_none    ret = list(self)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3535, in __iter__    return self._execute_and_instances(context)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3557, in _execute_and_instances    querycontext, self._connection_from_session, close_with_result=True  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3572, in _get_bind_args    mapper=self._bind_mapper(), clause=querycontext.statement, **kw  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3550, in _connection_from_session    conn = self.session.connection(**kw)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1141, in connection    execution_options=execution_options,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1147, in _connection_for_bind    engine, execution_options  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 409, in _connection_for_bind    self._assert_active()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 296, in _assert_active    code=""7s2a"",sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.InterfaceError) Error binding parameter 0 - probably unsupported type.[SQL: UPDATE ""query"" SET tracking_url=?, changed_on=? WHERE ""query"".id = ?][parameters: (<function <lambda> at 0x7fdf5959d3b0>, '2021-10-28 02:25:09.432381', 35)](Background on this error at: http://sqlalche.me/e/13/rvf5) (Background on this error at: http://sqlalche.me/e/13/7s2a)During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/sql_lab.py"", line 186, in get_sql_results    log_params=log_params,  File ""/app/superset/sql_lab.py"", line 496, in execute_sql_statements    ex, query, session, payload, prefix_message  File ""/app/superset/sql_lab.py"", line 112, in handle_query_error    errors = query.database.db_engine_spec.extract_errors(str(ex))  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 287, in __get__    return self.impl.get(instance_state(instance), dict_)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 723, in get    value = self.callable_(state, passive)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/strategies.py"", line 727, in _load_for_state    session, state, passive  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/strategies.py"", line 775, in _get_ident_for_use_get    for pk in self.mapper.primary_key  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/strategies.py"", line 775, in <listcomp>    for pk in self.mapper.primary_key  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/mapper.py"", line 2845, in _get_state_attr_by_column    return state.manager[prop.key].impl.get(state, dict_, passive=passive)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 718, in get    value = state._load_expired(state, passive)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/state.py"", line 652, in _load_expired    self.manager.deferred_scalar_loader(self, toload)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py"", line 1010, in load_scalar_attributes    only_load_props=attribute_names,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py"", line 206, in load_on_ident    identity_token=identity_token,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py"", line 286, in load_on_pk_identity    return q.one()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3490, in one    ret = self.one_or_none()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3459, in one_or_none    ret = list(self)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3535, in __iter__    return self._execute_and_instances(context)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3557, in _execute_and_instances    querycontext, self._connection_from_session, close_with_result=True  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3572, in _get_bind_args    mapper=self._bind_mapper(), clause=querycontext.statement, **kw  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3550, in _connection_from_session    conn = self.session.connection(**kw)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1141, in connection    execution_options=execution_options,  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1147, in _connection_for_bind    engine, execution_options  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 409, in _connection_for_bind    self._assert_active()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 296, in _assert_active    code=""7s2a"",sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.InterfaceError) Error binding parameter 0 - probably unsupported type.[SQL: UPDATE ""query"" SET tracking_url=?, changed_on=? WHERE ""query"".id = ?][parameters: (<function <lambda> at 0x7fdf5959d3b0>, '2021-10-28 02:25:09.432381', 35)](Background on this error at: http://sqlalche.me/e/13/rvf5) (Background on this error at: http://sqlalche.me/e/13/7s2a)During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/sql_lab.py"", line 151, in get_query    return session.query(Query).filter_by(id=query_id).one()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3490, in one    ret = self.one_or_none()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3459, in one_or_none    ret = list(self)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/query.py"", line 3534, in __iter__    self.session._autoflush()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1618, in _autoflush    self.flush()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2536, in flush    self._flush(objects)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2633, in _flush    subtransactions=True  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 953, in begin    self.transaction = self.transaction._begin(nested=nested)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 317, in _begin    self._assert_active()  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 296, in _assert_active    code=""7s2a"",sqlalchemy.exc.InvalidRequestError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.InterfaceError) Error binding parameter 0 - probably unsupported type.[SQL: UPDATE ""query"" SET tracking_url=?, changed_on=? WHERE ""query"".id = ?][parameters: (<function <lambda> at 0x7fdf5959d3b0>, '2021-10-28 02:25:09.432381', 35)](Background on this error at: http://sqlalche.me/e/13/rvf5) (Background on this error at: http://sqlalche.me/e/13/7s2a)During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/usr/local/lib/python3.7/site-packages/backoff/_sync.py"", line 94, in retry    ret = target(*args, **kwargs)  File ""/app/superset/sql_lab.py"", line 153, in get_query    raise SqlLabException(""Failed at getting query"")superset.sql_lab.SqlLabException: Failed at getting queryDuring handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/views/core.py"", line 2534, in _sql_json_sync    log_params=log_params,  File ""/usr/local/lib/python3.7/site-packages/celery/local.py"", line 191, in __call__    return self._get_current_object()(*a, **kw)  File ""/app/superset/initialization/__init__.py"", line 103, in __call__    return task_base.__call__(self, *args, **kwargs)  File ""/usr/local/lib/python3.7/site-packages/celery/app/task.py"", line 393, in __call__    return self.run(*args, **kwargs)  File ""/app/superset/sql_lab.py"", line 191, in get_sql_results    query = get_query(query_id, session)  File ""/usr/local/lib/python3.7/site-packages/backoff/_sync.py"", line 110, in retry    _call_handlers(on_backoff, *details, wait=seconds)  File ""/usr/local/lib/python3.7/site-packages/backoff/_sync.py"", line 20, in _call_handlers    hdlr(details)  File ""/app/superset/sql_lab.py"", line 126, in get_query_backoff_handler    query_id = details[""kwargs""][""query_id""]KeyError: 'query_id'During handling of the above exception, another exception occurred:Traceback (most recent call last):  File ""/app/superset/views/base.py"", line 204, in wraps    return f(self, *args, **kwargs)  File ""/app/superset/utils/log.py"", line 241, in wrapper    value = f(*args, **kwargs)  File ""/app/superset/views/core.py"", line 2573, in sql_json    return self.sql_json_exec(request.json, log_params)  File ""/app/superset/views/core.py"", line 2762, in sql_json_exec    session, rendered_query, query, expand_data, log_params  File ""/app/superset/views/core.py"", line 2551, in _sql_json_sync    logger.exception(""Query %i failed unexpectedly"", query.id)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 287, in __get__    return self.impl.get(instance_state(instance), dict_)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 718, in get    value = state._load_expired(state, passive)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/state.py"", line 652, in _load_expired    self.manager.deferred_scalar_loader(self, toload)  File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py"", line 944, in load_scalar_attributes    ""attribute refresh operation cannot proceed"" % (state_str(state))sqlalchemy.orm.exc.DetachedInstanceError: Instance <Query at 0x7fdf0c7da990> is not bound to a Session; attribute refresh operation cannot proceed (Background on this error at: http://sqlalche.me/e/13/bhk3)```#### Screenshots![image](https://user-images.githubusercontent.com/5211253/139175658-0c52230e-14c9-436c-98ed-59ea03d2c4b5.png)### Environment- browser type and version: Google Chrome 95.0.4638.54 (Official Build) (64-bit)- superset version: 1.3.1- python version: Python 3.7.9- node.js version: I didn't find this one since running superset in docker- Note: running superset in docker  - Image version:  clone from git tag `1.3.1` and build from it  - Docker version: Docker version 20.10.9, build c2ea9bc- any feature flags active: `{""ALERT_REPORTS"": True}`### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tra"
17248,1,0,0,0,0,volhahedranovich,0,"title:Series limit doesn't work in time-series chart. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to 'Explore'2. Select Time-series bar chart or area chart (probably others fit as well)3. Select Metrics (in my case for ClickHouse query it is uniq(user_id))4. Select Group by some column with high cardinality.5. Select Series limit (5 or 10).6. Chart doesn't change comparing with not selected Series limit. The query also doesn't change.### Expected resultsI expect to see only top 5 or 10 values of the dimension selected in Group by.### Actual resultsI see all the values, but not limited to 5 or 10.#### Screenshots![image](https://user-images.githubusercontent.com/11491329/139078199-58225c88-d446-43cb-ab60-88736eb52042.png)### Environment- browser: Chromium Version 95.0.4638.54 (Official Build) snap (64-bit)- superset version: 1.3.1- python version: No access- node.js version: No access- any feature flags active: No access### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextMoreover, sort descending doesn't work properly as well.
"
17247,1,0,0,0,0,farming4rd,0,"title:Unable to Use Jinja Filters for a Specific Column in k8s with helm template but running well with docker.. description:A clear and concise description of what the bug is.#### How to reproduce the bug1.  clone repository for docker-compose from https://github.com/nielsen-oss/superset and **docker-compose  -f <file.yml> -up** (**with condition setting nginx reversproxy**)2. got to path or cd to helm/superset/ ""https://github.com/nielsen-oss/superset/tree/master/helm/superset"" and **helm install superset helm/superset/**3. Activate your jinja context in superset/docker/pythonpath_dev/superset_config.py by adding ""ENABLE_TEMPLATE_PROCESSING"" : True in dictionary of FEATURE_FLAGS4. Go to sqllab (with condition we have setting datasets our chart)5. Create sql with filters for specific coloumn and save chart6. embed code and adding filter ""**&billing_date=2021-09-15**"" in url exmpl https://IP_URL/superset/explore/?r=57&standalone=1&height=400&billing_date=2021-09-15 and enter7. inspect > network > file **data?form_data=** > preview > drop down tab and look row **query: ""SELECT**### Expected results #### Screenshotsresault inspect browser (**different chart but same query in docker**) from combination\n   where billing_date = '2021-09-15') AS virtual_table\nGROUP BY paid_hour,\n ![result +](https://user-images.githubusercontent.com/55482288/139075652-30395550-b1da-4439-a48b-20b6279b91f9.jpeg)### Actual results#### Screenshots resault inspect browser (**defferent chart but same query in k8s**) from combination) AS virtual_table\nGROUP BY paid_hour,\n![result -](https://user-images.githubusercontent.com/55482288/139075709-b61ed0ec-30ea-46d5-894f-84523f350e94.jpeg)### Environment(please complete the following information):- browser type and version chroome lates- kubernetes version Client Version: version.Info{Major:""1"", Minor:""19"", GitVersion:""v1.19.2"", GitCommit:""f5743093fd1c663cb0cbc89748f730662345d44d"", GitTreeState:""clean"", BuildDate:""2020-09-16T13:41:02Z"", GoVersion:""go1.15"", Compiler:""gc"", Platform:""linux/amd64""}Server Version: version.Info{Major:""1"", Minor:""19"", GitVersion:""v1.19.3"", GitCommit:""1e11e4a2108024935ecfcb2912226cedeafd99df"", GitTreeState:""clean"", BuildDate:""2020-10-14T12:41:49Z"", GoVersion:""go1.15.2"", Compiler:""gc"", Platform:""linux/amd64""}- helm versionversion.BuildInfo{Version:""v3.4.0"", GitCommit:""7090a89efc8a18f3d8178bf47d2462450349a004"", GitTreeState:""clean"", GoVersion:""go1.14.10""}- superset version: `superset 1.3.2`- python version: `Python 3.7.9`- any feature flags active: : /app/pythonpathcreated/superset_config.py created templates/_helpers.tpl- FEATURE_FLAGS = {    ""DYNAMIC_PLUGINS"": True,    ""ENABLE_TEMPLATE_PROCESSING"": True}### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [v] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [v] I have reproduced the issue with at least the latest released version of superset.- [v] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17244,0,0,164,0,0,geido,0,"title:[Explore] The dashboard ID will be lost when refreshing the page. description:#### How to reproduce the bug1. Go to Explore from a Dashboard2. Refresh Explore### Expected resultsThe dashboard id from where the user was coming from should still be available in Explore### Actual resultsThe dashboard id is undefined### Environment- browser type and version: Chrome- superset version: `master`### Additional contextThis problem was discovered while working on the color consistency project https://github.com/apache/superset/pull/17089 as the dashboard id is required to extract information about the metadata of the dashboard related to the current Explore session.
"
17243,0,0,164,0,0,geido,0,"title:[Dashboard] Color scheme won't be discarded when discarding changes. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to a Dashboard2. Click on Edit dashboard properties3. Change the color scheme and click Save4. Without saving the whole dashboard, click on ""Discard changes""5. The page will refresh and the color scheme change hasn't been discarded### Expected resultsSaving changes in the ""Edit dashboard properties"" Modal should only be effective when the whole Dashboard is saved. When discarding the changes, any change should reset.### Actual resultsThe color scheme is not discarded#### Screenshotshttps://user-images.githubusercontent.com/60598000/139059213-79862427-72a5-466d-b4e0-82ae74f00efc.mp4### Environment- browser type and version: Chrome- superset version: `master`
"
17230,1,0,2,0,1,xinjingqing,0,"title:The filter mapping configuration can not be  saved in V1.2.0 +. description:1闂傚倸鍊风欢姘焽瑜嶈灋闁哄啠鍋撶€垫澘瀚伴幃鐐哄箟?the param DASHBOARD_CROSS_FILTERS = True2闂傚倸鍊风欢姘焽瑜嶈灋闁哄啫鐗嗙粻鎺楁煟閻樻妫嘽k ""Edit Dashborad""3闂傚倸鍊风欢姘焽瑜嶈灋闁哄啠鍋撶€垫澘瀚伴幃鐐哄箟?filter mapping4闂傚倸鍊风欢姘焽瑜嶈灋闁哄啫鐗嗙粻鎺楁煟閻樻鐓筬ig filter scopes5闂傚倸鍊风欢姘焽瑜嶈灋闁哄啫鐗嗙粻鎺楁煟閻樻妫嘽k 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墰缁犳棃鏌曢崼鐔恒€俥闂?to save the filter mapping info.6闂傚倸鍊风欢姘焽瑜嶈灋闁哄啫鐗嗙粻鎺楁煟閻樻妫嘽k 闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柤纰卞墰缁犳棃鏌曢崼鐔恒€俥闂?to save the dashboard info.7闂傚倸鍊风欢姘焽瑜嶈灋闁哄啫鍊圭€氬鏌ｉ悩鍨唉esh the current page or relogin the system8闂傚倸鍊风欢姘焽瑜嶈灋闁哄啫鍊绘稉宥夋煙鏉堚晝鍊?filter scopes configured a momen ago are invalid...**I have fixed the BUG...**![1635224579(1)](https://user-images.githubusercontent.com/10738633/138812020-081cae7e-c436-4aef-86b0-e3e4feea891b.png)
"
17206,1,0,0,0,0,LeiZhangImo,0,"title:create dataset api always get 'The CSRF token is missing' error. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to swagger/v1 scroll down to post dataset2. Click on 'Try it out'3. Input following:`{  ""database"": 1,  ""owners"": [    1  ],  ""schema"": ""testschema"",  ""table_name"": ""tenant002""}`4. See an error in the error log`{  ""errors"": [    {      ""message"": ""400 Bad Request: The CSRF token is missing."",      ""error_type"": ""GENERIC_BACKEND_ERROR"",      ""level"": ""error"",      ""extra"": {        ""issue_codes"": [          {            ""code"": 1011,            ""message"": ""Issue 1011 - Superset encountered an unexpected error.""          }        ]      }    }  ]}`### Expected resultsget 200 without error### Environment- browser type and version: Chrome/94.0.4606.61- superset version:  superset docker: apache/superset:1.3.2- python version: Python 3.8.12- node.js version: not know- any feature flags active: connected to aws Anthena### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextI'm using the Admin user, even after this error occurred the GET /dataset API still working.
"
17198,1,0,0,0,0,vivekdixit2510,0,"title:The filter mapping settings are not working . description:The filter mapping settings are not validExpected resultsConfigure filter scopes will take effect after savingActual resultsConfigure filter scopes, unable to save effectively.1. Uncheck first 3 box(scope) and save .![image](https://user-images.githubusercontent.com/80536487/138439865-9e6b3151-3fcf-40f4-8609-b3c036db1747.png)2. Save dashboard![image](https://user-images.githubusercontent.com/80536487/138440129-6e48d560-c069-4b28-a022-8799664cfbd6.png)3. Refresh url闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈惧瘜閺佸﹪鏌熼懡銈団攨 setting is not saved.![image](https://user-images.githubusercontent.com/80536487/138440290-23cdc33b-b9a5-4c84-b69c-323185f295ed.png)How to reproduce the bugSet configure filter scopes and cancel one filter scopesRefresh after savingConfigure filter scopes is still in their original state and has not been saved
"
17188,1,0,0,0,0,professionalgamethrower,0,"title:Dashboard user filter cache resets. description:After applying report filters, the filters are not saved in user cache and there is no wat for users to save the filters. #### How to reproduce the bugCreate a Filter chart. Add the chart to a dashboard, publish the dashboard.Open the dashboard and apply filters to the Filter chart. Close the dashboard.Open the dashboard again. ### Expected resultsLast filters are saved.### Actual resultsLast filters are not saved.### Environmentsuperset v.1.2.0python v.3.7### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ X ] I have reproduced the issue with at least the latest released version of superset.- [ X ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAll caching were disable for real time data retrieval.
"
17186,1,0,1,0,1,jot4p,0,"title:docker documentations. description:Hi, The documentation for integrations with docker is not updated.  Please fix. (broken url for requirements.. etc) I'm trying to use: https://superset.apache.org/docs/databases/dockeradddrivers but this is not ok. Maybe  the best driver is this : https://pypi.org/project/mysql-connector-python/ But I get : mysql+mysqlconnector://root:root@localhost/table""ERROR: (mysql.connector.errors.DatabaseError) 2004 (HY000): Can't create TCP/IP socket (97)(Background on this error at: http://sqlalche.me/e/13/4xp6)"" Can you check ?  
"
17185,1,0,300,0,0,kgabryje,1,"title:[Explore] No results in data table Samples. description:When I open the Samples tab in data table, it show ""No results"" even though the row counter shows that there are rows available to display and inspection of the request in the console shows that data was fetched.I think the bug might have been introduced in PR #16299 - it uses columns from chart query to display data tables Results and Samples, even though Samples might (and usually does) have different columns than Results. It will actually show only those columns from Samples query that are present in current chart query.#### How to reproduce the bug1. Open a chart, for example 'Games per Genre over time'2. Go to Samples tab3. It shows only ""Genre"" column, even though there are many more available.### Expected resultsAll columns of Samples query should be displayed in data table### Actual resultsOnly columns that are present in both Samples query and current chart query are displayed in Samples data table.#### Screenshots![image](https://user-images.githubusercontent.com/15073128/138292711-bb8abda2-909b-4ce1-9378-a13d3d7b469e.png)### EnvironmentLatest master (e32acd)### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.CC @junlincc @AAfghahi 
"
17180,0,0,40,0,0,jinghua-qa,0,"title:[dashboard edit] unexpected error appears when user tries to collapse tab content . description:In dashboard edit, when user tries to collapse outer tab content , unexpected error appear#### How to reproduce the bug1, Go to the ""Dashboards"" page and click the ""+Dashboard"" or open existing2, Click on the ""Pencil"" icon3, Drag&Drop the ""Tabs"" component to the top of the page4, Delete all tabs and leave the component empty5, Click the ""Collapse tab content"" button### Expected resultsTab content collapsed. There is no errors appear### Actual resultsunexpected error appears when user tries to collapse tab content, see the video below:#### Screenshotshttps://user-images.githubusercontent.com/81597121/138228519-dc33ef30-f458-4de2-a395-2b3800305f97.mov### Environment(please complete the following information):- browser type and version:- superset version: `superset version`- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17178,0,0,0,0,0,rosemarie-chiu,0,"title:[Native Filter] Not able to create dashboard native filter with calculated column. description:I want to create native filter with calculated column but getting error#### How to reproduce the bugPre-condition1. Create calculated column in a dataset2. Create chart using this dataset and add to a dashboardSteps (see attached video)1. Go to dashboard, open native filter side bar2. Create a native filter using this calculated field3. Check ""filter has default value"" --> see error4. Uncheck filter has default value, click save filter --> see error### Expected resultsCalculated column should also work for native filter### Actual results<img width=""1279"" alt=""CleanShot 2021-10-21 at 09 07 43@2x"" src=""https://user-images.githubusercontent.com/52086618/138193789-b54d9d76-e129-4d42-8732-105dcdbf385b.png"">https://user-images.githubusercontent.com/52086618/138194028-2a9c2246-2895-4bad-98aa-ade7dc34eb89.mov#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version: chrome- superset version: latest master- any feature flags active: default feature flag combo### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17170,0,0,0,0,0,rosemarie-chiu,0,"title:[Explore] Chart property edit modal is cached when cancel edit. description:Only in Explore, when cancel change on chart property, it is cached. From chart list it is fine.#### How to reproduce the bug1. Explore and chart2. Edit chart property3. Click ""Cancel"" button4. Open chart property edit modal again5. See the change that was ""cancelled""### Expected resultsIf I cancelled changes, it should be cancelled and not show on UI. ### Actual resultsEdit modal shows what I have cancelled, it is confusing#### Screenshots![CleanShot 2021-10-20 at 22 51 04](https://user-images.githubusercontent.com/52086618/138117043-2aa16d35-16f9-4d9e-8101-ca8e32afa108.gif)### Environment(please complete the following information):- browser type and version: Chrome latest- superset version: latest master- any feature flags active: default feature flags combo### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17161,1,0,0,0,0,AndyHou-3D,0,"title:An error occurred, when build superset docker image.. description:docker build --pull --rm -f ""superset\Dockerfile"" -t skyeye-superset:dev ""superset""![image](https://user-images.githubusercontent.com/83389331/138022324-bb05c590-a7a7-4a85-a7ff-52745a2947da.png)
"
17159,1,0,0,0,0,zuzana-vej,0,"title:[EChart] Annotation lines stretch out when hovering. description:When you use annotations on the Time-series Line Chart, there are a few issues:1. Dash style is different for different annotations (I don't think this is intentional)2. When you hover over the chart to get the tooltip, the dashes get longer, and go back to the original width when you hover back out from the chat - see video#### Screenshots![annotation-issue](https://user-images.githubusercontent.com/61221714/138005978-116732d4-8295-4904-8190-533c0765ab38.gif)### Environmentlatest master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17158,0,0,40,0,0,jinghua-qa,0,"title:[dashboard edit mode] The ""add components"" menu is not displayed if the page was scrolled down before clicking the edit button. description:The ""add components"" menu is not displayed if the page was scrolled down before clicking the edit button.#### How to reproduce the bug1闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈鹃檮閸嬨倖鎱?to the ""Dashboards"" page2闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈鹃檮閸嬨倝鏌￠埀顒€鐣￠·锕?on any example dashboard3闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈惧瘜閺佸棝鏌ｅ鍛亾濠曠斀l the dashboard to the end of the page4闂傚倸鍊烽悞锔锯偓绗涘懐鐭欓柟杈鹃檮閸嬨倝鏌￠埀顒€鐣￠·锕?the ""Pencil"" icon### Expected resultsThe ""add components"" menu is displayed even if the page was scrolled down before clicking the edit button.### Actual resultsThe ""add components"" menu is not displayed if the page was scrolled down before clicking the edit button, see the video below:https://user-images.githubusercontent.com/81597121/138003943-b3dd3a52-5104-41ca-a006-4f5043d1aeaa.mp4#### ScreenshotsIf applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version:- superset version: master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17156,0,0,40,0,0,jinghua-qa,0,"title:[dashboard edit] tool menu of row is over-lapping with other tool menu of components. description:When i edit dashboard, tool menu of row is over lapping with other tool menu of components#### How to reproduce the bug1. Go to dashboard edit2. Add a tab component3. In the tab, add a row4. Hover over the row to show the tool menu and see error### Expected resultsUser can be able to tell which tool menu is which### Actual resultsTool menu of row is over-lapping with other components#### Screenshots<img width=""1421"" alt=""Screen Shot 2021-10-19 at 11 17 27 AM"" src=""https://user-images.githubusercontent.com/81597121/137969447-939fcbad-e8a8-4a38-b10f-ff1c55086fa9.png"">### Environment(please complete the following information):- browser type and version:- superset version: master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17150,1,0,0,0,0,JoaquinPretell92,0,"title:Problem pulling image from docker. description:Hello,I'm trying to deploy another superset environment to do some upgrade tests. We use superset 1.0.1.We deploy on GCP and run via his own shell, but when i launch my terraform run, i get and imagepullerror:![image](https://user-images.githubusercontent.com/73810312/137837299-f65e201f-7881-4f69-b313-f0318f71c91f.png)and when i do a describe, i got an unauthorized error:![image](https://user-images.githubusercontent.com/73810312/137837380-338fba00-b3a1-4c9f-839e-e03f5e01ed64.png){""errors"":[{""code"":""UNAUTHORIZED"",""message"":""authentication required"",""detail"":[{""Type"":""repository"",""Class"":"""",""Name"":""apache/superset"",""Action"":""pull""}]}]}![image](https://user-images.githubusercontent.com/73810312/137837404-a97299ad-0278-492f-a0fe-8acb5408a598.png)its weird because if i do a docker pull apache/superset:1.0. we dont get the authentication error.![image](https://user-images.githubusercontent.com/73810312/137837964-a4bd937f-1b58-474e-9b09-16ed2fd05a18.png)i want to know if someone got this error before.Regards
"
17149,1,0,0,0,0,zuzana-vej,0,"title:[ECharts] Color / style of time shift line is confusing. description:A clear and concise description of what the bug is.In current time series chart, the time shift is in dashed line of same color. In e-charts the time shift line is different color, making it appear as a completely different data line. This is confusing to users (and will be especially confusing when there are multiple lines on the chart).#### How to reproduce the bugCreate time shift for time series chart in echarts. ### Expected resultsLines should be same color, one dashed one full line, OR this can be left up to user to configure. Currently it looks like two completely different data point lines.### Actual resultsLines have different colors.#### ScreenshotsFirst image = nvd3 chartsSecond image = e-charts <img width=""348"" alt=""Screen Shot 2021-10-18 at 6 42 48 PM"" src=""https://user-images.githubusercontent.com/61221714/137829920-3983c8d6-398c-4631-be6e-b47df6f334f6.png"">### Environmentlastest master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17144,0,0,294,0,0,michael-s-molina,0,"title:Parent filter is persisting after canceling. description:In native filters, the parent filter is persisting after canceling.@m-ajay @graceguo-supercat @jinghua-qa #### How to reproduce the bug1. Go to the native filters configuration modal2. Set a parent filter3. Cancel the changes4. Reopen the modal5. The parent filter is still there### Expected resultsThe parent filter is not there anymore after canceling.### Actual resultsThe parent filter persists after canceling.#### Screenshotshttps://user-images.githubusercontent.com/70410625/137741804-1b6eaf8f-b397-45cb-8647-3dce95103d23.mov### Environment- browser type and version: Chrome 94.0.4606.81- superset version:  master- any feature flags active: NATIVE_FILTERS### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17143,0,244,0,0,0,oscarostlundgs,0,"title:Presto engine spec broken - Date column mapped to Datetime. description:Presto engine spec seems broken in 1.3.1 as DATE presto types are mapped to DATETIME sqlalchemy types which are not supported by the Presto engine spec. #### How to reproduce the bug1. Install 1.3.12. Sync column tables in Superset for a table that has a DATE column3. Check the Superset type of the column, should be DATETIME### Expected resultsQuerying a Presto table with a time range should work. ### Actual resultsThis will prevent Superset from query the table with time constraints. The query will return `Cannot apply operator: date >= varchar(26)` error. When looking at the generated query, temporal predicates do not get included in date conversion function, i.e.: ```WHERE ""eventdate"" >= '2021-09-18 00:00:00.000000'  AND ""eventdate"" < '2021-10-18 12:35:33.000000'```While it should be - and in prior versions was - : ```WHERE ""eventdate"" >= from_iso8601_date('2021-09-18 00:00:00.000000')  AND ""eventdate"" < from_iso8601_date('2021-10-18 12:35:33.000000')```### Environment- superset version: 1.3.1- Presto version: 343- pyhive version: 0.6.4- python version: 3.7### Additional contextIt seems like the issue comes from the Presto engine spec mapping Dates to Datetime in sqlalchemy ([see this line](https://github.com/apache/superset/blob/master/superset/db_engine_specs/presto.py#L511)) while the `convert_dttm` does not support DATETIME ([see here](https://github.com/apache/superset/blob/master/superset/db_engine_specs/presto.py#L746)). Note that with past versions, DATE presto columns mapped to DATE Sqlalchmy columns. 
"
17139,1,0,70,1,0,jkleinkauff,0,"title:List user own charts + dashboard listing with RBAC. description:#### How to reproduce the bug- give a user `gamma` + `sql_lab`  roles + database access(for SQL lab work properly)- create a chart coming from SQL Lab Explore- Save it, an error will occur but the tip ""Chart xxx saved"" will appear### Expected resultsUser could list the charts he created### Actual resultsUser could not list the charts he createdMaybe related to the error message (??)#### Screenshots![image](https://user-images.githubusercontent.com/58440667/137651453-9a82345d-56c0-4a9f-bb6f-ff9dd3788842.png)### Environment- Chrome Version 94.0.4606.71 (Official Build) (64-bit)- [helm 0.3.10](https://apache.github.io/superset/index.yaml) - 0.0.0dev- Python 3.7.9- any feature flags active: ENABLE_TEMPLATE_PROCESSING, DASHBOARD_NATIVE_FILTERS, DASHBOARD_RBAC- Redshift### Additional contextI think this could be related to https://github.com/apache/superset/issues/12041, https://github.com/apache/superset/issues/8927 but the problem is if I add `'schema access on [database].[schema]'` to a role, in dashboard/list I can see all published dashboards, even if I don't have permissions(role) to the dashboard.While I can see the dashboard on the list, when I try to access it an ""Unexpected error"" occurs. (correct as I don't have permission)
"
17136,0,0,0,0,0,graceguo-supercat,0,"title:[explore][time-series bar] SHOW VALUE issues. description:#### How to reproduce the bug1. Go to Explore view, create a time-series bar chart V2 like this:<img width=""1153"" alt=""Screen Shot 2021-10-15 at 4 26 20 PM"" src=""https://user-images.githubusercontent.com/27990562/137564043-35b7a4e4-426d-4da2-8202-1d09a20be851.png"">2. Add Custom options like this: SHOW VALUE, STACK SERIES, SHOW TOTAL <img width=""318"" alt=""Screen Shot 2021-10-15 at 4 27 07 PM"" src=""https://user-images.githubusercontent.com/27990562/137564070-43f1bde2-fb7b-453c-bc7a-35925f036e31.png"">3. You should see total value on top of each bar4. click `boy` label,  `girl` label, the total value display is not consistentwhen you select boy only: there is no total valuewhen you select girl only: total value show on top of bar. and this total value seems like the value for girl only, this is very misleading. ![pmJMItwCKR](https://user-images.githubusercontent.com/27990562/137564276-86c0456d-e6bd-4462-b27b-66735fede656.gif)### Expected resultsShould not show total value when only girl (or part of data) category is selected.### Environmentlatest master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextcc @junlincc @zuzana-vej 
"
17128,1,0,0,0,0,LalaGabor,0,"title:Mixed Time Series Chart: X-Axis scaling is odd, when adjusting Time Filterbox. description:When I adjust a time Filter the scaling on the X-Axis of my Mixed Time Series Chart is wonky.#### How to reproduce the bug1. Go to a Dashboard with a Mixed Time Series Chart and a Filter Box (Date Filter, or regular filter with Time column)2. My Filter has multiple Options enabled and Required3. Baseline Status: All years (1, 2 & 3) from the time filter are selected4. Select Years 1& 2 only### Expected resultsMixed Time Series Chart X-axis adjust to only show Years 1 & 2### Actual resultsMixed Time Series Chart X-Axis expands to show Years -1, 0, 1, 2, 3, 4#### Screenshots![image](https://user-images.githubusercontent.com/44199231/137463279-5f9e2356-ca6f-4f6b-ba36-4ee0fc8dcc72.png)### Environment(please complete the following information):- browser type and version: Firefox- superset version: `superset version` 1.2- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17116,1,0,0,0,0,xyzamd,0,"title:Connecting deck.gl multiple layers with own Map-Server . description:Hey,We are trying to visualize maps with multiple layers with deck.gl and have only the following parameter to adjust:![Unbenannt](https://user-images.githubusercontent.com/92534590/137351459-4701e51e-274e-48d2-9314-9db0878331cf.PNG)Is it possible to change or to configure the parameters of deck.gl multiple layers maps with something like a link of own map-server and show its maps as a chart in superset?Could we build a frame (custom viz plugin) and visualize our maps from our own map-server on this frame?### Environment- browser type and version: Google Chrome- superset version: `0.0.0dev`Thanks!
"
17110,1,0,5,0,0,Cocktailpy,0,"title:ConnectionRefusedError: [Errno 111] Connection refused. description:superset use this command:gunicorn -w 10  -k gevent --timeout 120 -b  0.0.0.0:16666 --limit-request-line 0 --limit-request-field_size 0 --statsd-host localhost:8125 ""superset.app:create_app()""but get error like this:Traceback (most recent call last):  File ""/usr/local/lib/python3.7/site-packages/gunicorn/instrument/statsd.py"", line 127, in _sock_send    self.sock.send(msg)ConnectionRefusedError: [Errno 111] Connection refused
"
17109,1,0,0,0,0,binxushy,0,"title:Missed one/two records when query raw data in one table (clickhouse database). description:SupserSet: 1.3.0Clickhouse:  amancevice/superset:latest(Docker IMG),  ClickHouse server version 21.9.4 revision 54449. SQL Editor query: If  no data in a table such as pta.s_day_ont:    we run ""select count() from pta.s_day_ont"" in SQL Editor, it show ""The query returned no data"".if there are records in a table such as pta.s_day_ont:the first records will be put as Headers but not data.Charts/table:if I query data by in a Table(Charts),  two records will missed.
"
17107,0,0,2,0,0,yougyoung94,0,"title:auto refresh interval won't be updated. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Click a dashboard2. Set auto refresh interval: check the dashboard is refreshing at the right interval3. Check out to dashboard list4. Go to the dashboard again: check the dashboard won't refresh### Expected resultsWhen you go back to the dashboard, the dashboard should refresh at the right interval### Actual resultsWhen you go back to the dashboard, the dashboard won't refresh at allwhat actually happens.#### Screenshotshttps://user-images.githubusercontent.com/37649640/137244489-5befb964-3c5c-426f-8ba9-df2ac1e48bea.mov### Environment(please complete the following information):- browser type and version: Chrome- superset version: 1.3.1- python version: `python --version` Python 3.7.9- node.js version: `node -v` v16.4.0- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17099,0,2761,0,0,1,a-cid,0,"title:[mixed time series chart] [Global Async Queries] Chart rendering fails. description:The following error is thrown in explore view and in dashboards when reloading a Mixed time-series chart with the Global Async Queries feature turned on:![image](https://user-images.githubusercontent.com/834150/137209186-026387ec-9b44-448e-acf3-12879e2febe2.png)Here's my superset_config_docker.py:```import osfrom typing import Optionaldef get_env_variable(var_name: str, default: Optional[str] = None) -> str:    """"""Get the environment variable or raise exception.""""""    try:        return os.environ[var_name]    except KeyError:        if default is not None:            return default        else:            error_msg = ""The environment variable {} was missing, abort..."".format(                var_name            )            raise EnvironmentError(error_msg)REDIS_HOST = get_env_variable(""REDIS_HOST"")REDIS_PORT = get_env_variable(""REDIS_PORT"")FEATURE_FLAGS = {    ""GLOBAL_ASYNC_QUERIES"": True}GLOBAL_ASYNC_QUERIES_JWT_SECRET = 'v2jHEh8gG2yw56ReLEvGwGTSgETRu26U'GLOBAL_ASYNC_QUERIES_REDIS_CONFIG = {    ""port"": REDIS_PORT,    ""host"": REDIS_HOST,    ""password"": """",    ""db"": 0,    ""ssl"": False,}DATA_CACHE_CONFIG = {    'CACHE_TYPE': 'redis',    'CACHE_DEFAULT_TIMEOUT': 60 * 5, # 5 minutes    'CACHE_KEY_PREFIX': 'superset_results',    'CACHE_REDIS_URL': 'redis://%s:%s/0' % (REDIS_HOST, REDIS_PORT),}CACHE_CONFIG = {    'CACHE_TYPE': 'redis',    'CACHE_DEFAULT_TIMEOUT': 60 * 5, # 5 minutes    'CACHE_KEY_PREFIX': 'superset_cache',    'CACHE_REDIS_URL': 'redis://%s:%s/0' % (REDIS_HOST, REDIS_PORT),}```The following error is raised in the browser console:```TypeError: queriesData[1] is undefined    transformProps transformProps.js:45    processChartProps SuperChartCore.js:37    memoizedResultFunc index.js:70    defaultMemoize index.js:30    selector index.js:84    defaultMemoize index.js:30    renderChart SuperChartCore.js:66    render index.js:241    finishClassComponent react-dom.development.js:17185    updateClassComponent react-dom.development.js:17135    beginWork react-dom.development.js:18654    callCallback react-dom.development.js:189    invokeGuardedCallbackDev react-dom.development.js:238    invokeGuardedCallback react-dom.development.js:293    beginWork$1 react-dom.development.js:23235    performUnitOfWork react-dom.development.js:22189    workLoopSync react-dom.development.js:22162    performSyncWorkOnRoot react-dom.development.js:21788    flushSyncCallbackQueueImpl react-dom.development.js:11112    unstable_runWithPriority scheduler.development.js:653    runWithPriority$1 react-dom.development.js:11062    flushSyncCallbackQueueImpl react-dom.development.js:11107    flushSyncCallbackQueue react-dom.development.js:11095    batchedUpdates$1 react-dom.development.js:21894    Redux 4        notify        notifyNestedSubs        handleChangeWrapper        dispatch    loggerMiddleware loggerMiddleware.js:68    Redux 2        createThunkMiddleware        dispatch    chartDataRequestCaught chartAction.js:437```#### How to reproduce the bug1. Checkout 1.3.12. Fill in superset config cited above.3. Start superset using docker-compose4. Create a mixed time-series chart.5. Run it once to fill cache, then try rerunning the chart.6. See error.### Expected resultsThe chart loads correctly on all runs.### Actual resultsChart fails to load, it appears the data for the second query is missing in the frontend.#### Screenshots![image](https://user-images.githubusercontent.com/834150/137211099-58ed919b-847e-4ff6-b20a-d6d1d06230b5.png)### Environment(please complete the following information):- browser type and version: Firefox 93.0 and Chromium 94.0.4606.81- superset version: 1.3.1- python version: 3.8- node.js version: v14.18.1- any feature flags active: GLOBAL_ASYNC_QUERIES### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextChart was working in 1.2.0
"
17098,0,0,18,0,0,manavjaiswal,0,"title:SQLAlchemy error on exploring virtual dataset. description:#### How to reproduce the bugRan a query (redacted version) in SQL lab:`select xx1, xx2, cast(concat(day, ' ', hour, ':', minute, ':00') as TIMESTAMP) as activity_date from xxxx WHERE xx1 = 'abc' limit 1000;`Clicked on explore and saved it as new dataset. As the the chart creation view opened up with default values filled in for table type chart, I see the following as in the screenshot:![Screen Shot 2021-10-13 at 12 32 17 PM](https://user-images.githubusercontent.com/13721953/137201277-646e19b8-58c5-4de1-be87-cd9b21fdddf9.jpg) I see the following error in the docker logs:`Bind parameter '00' without a renderable value not allowed here.superset_app            | Traceback (most recent call last):superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1950, in full_dispatch_requestsuperset_app            |     rv = self.dispatch_request()superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask/app.py"", line 1936, in dispatch_requestsuperset_app            |     return self.view_functions[rule.endpoint](**req.view_args)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/flask_appbuilder/security/decorators.py"", line 67, in wrapssuperset_app            |     return f(self, *args, **kwargs)superset_app            |   File ""/app/superset/views/base_api.py"", line 85, in wrapssuperset_app            |     raise exsuperset_app            |   File ""/app/superset/views/base_api.py"", line 82, in wrapssuperset_app            |     duration, response = time_function(f, self, *args, **kwargs)superset_app            |   File ""/app/superset/utils/core.py"", line 1461, in time_functionsuperset_app            |     response = func(*args, **kwargs)superset_app            |   File ""/app/superset/utils/log.py"", line 242, in wrappersuperset_app            |     value = f(*args, **kwargs)superset_app            |   File ""/app/superset/charts/api.py"", line 726, in datasuperset_app            |     return self.get_data_response(command)superset_app            |   File ""/app/superset/charts/api.py"", line 537, in get_data_responsesuperset_app            |     result = command.run(force_cached=force_cached)superset_app            |   File ""/app/superset/charts/commands/data.py"", line 50, in runsuperset_app            |     payload = self._query_context.get_payload(superset_app            |   File ""/app/superset/common/query_context.py"", line 305, in get_payloadsuperset_app            |     query_results = [superset_app            |   File ""/app/superset/common/query_context.py"", line 306, in <listcomp>superset_app            |     get_query_results(superset_app            |   File ""/app/superset/common/query_actions.py"", line 183, in get_query_resultssuperset_app            |     return result_func(query_context, query_obj, force_cached)superset_app            |   File ""/app/superset/common/query_actions.py"", line 145, in _get_resultssuperset_app            |     payload = _get_full(query_context, query_obj, force_cached)superset_app            |   File ""/app/superset/common/query_actions.py"", line 98, in _get_fullsuperset_app            |     payload = query_context.get_df_payload(query_obj, force_cached=force_cached)superset_app            |   File ""/app/superset/common/query_context.py"", line 468, in get_df_payloadsuperset_app            |     query_result = self.get_query_result(query_obj)superset_app            |   File ""/app/superset/common/query_context.py"", line 254, in get_query_resultsuperset_app            |     result = self.datasource.query(query_object.to_dict())superset_app            |   File ""/app/superset/connectors/sqla/models.py"", line 1446, in querysuperset_app            |     query_str_ext = self.get_query_str_extended(query_obj)superset_app            |   File ""/app/superset/connectors/sqla/models.py"", line 754, in get_query_str_extendedsuperset_app            |     sql = self.database.compile_sqla_query(sqlaq.sqla_query)superset_app            |   File ""/app/superset/models/core.py"", line 444, in compile_sqla_querysuperset_app            |     sql = str(qry.compile(engine, compile_kwargs={""literal_binds"": True}))superset_app            |   File ""<string>"", line 1, in <lambda>superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 481, in compilesuperset_app            |     return self._compiler(dialect, bind=bind, **kw)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py"", line 487, in _compilersuperset_app            |     return dialect.statement_compiler(dialect, self, **kw)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 592, in __init__superset_app            |     Compiled.__init__(self, dialect, statement, **kwargs)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 322, in __init__superset_app            |     self.string = self.process(self.statement, **compile_kwargs)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 352, in processsuperset_app            |     return obj._compiler_dispatch(self, **kwargs)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/visitors.py"", line 96, in _compiler_dispatchsuperset_app            |     return meth(self, **kw)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 2201, in visit_selectsuperset_app            |     text = self._compose_select_body(superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 2292, in _compose_select_bodysuperset_app            |     [superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 2293, in <listcomp>superset_app            |     f._compiler_dispatch(self, asfrom=True, **kwargs)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/visitors.py"", line 96, in _compiler_dispatchsuperset_app            |     return meth(self, **kw)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 1801, in visit_aliassuperset_app            |     ret = alias.original._compiler_dispatch(superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/visitors.py"", line 96, in _compiler_dispatchsuperset_app            |     return meth(self, **kw)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 1013, in visit_text_as_fromsuperset_app            |     text = self.process(taf.element, **kw)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 352, in processsuperset_app            |     return obj._compiler_dispatch(self, **kwargs)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/visitors.py"", line 96, in _compiler_dispatchsuperset_app            |     return meth(self, **kw)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 981, in visit_textclausesuperset_app            |     BIND_PARAMS.sub(superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 971, in do_bindparamsuperset_app            |     return self.process(textclause._bindparams[name], **kw)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 352, in processsuperset_app            |     return obj._compiler_dispatch(self, **kwargs)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/visitors.py"", line 96, in _compiler_dispatchsuperset_app            |     return meth(self, **kw)superset_app            |   File ""/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/compiler.py"", line 1549, in visit_bindparamsuperset_app            |     raise exc.CompileError(superset_app            | sqlalchemy.exc.CompileError: Bind parameter '00' without a renderable value not allowed here.superset_app            | 2021-10-13 19:14:20,107:ERROR:superset.views.base:Bind parameter '00' without a renderable value not allowed ### Environmentbrowser type and version: Chrome Version 94.0.4606.61 (Official Build) (x86_64)superset version: GIT sha 27a40d2a675fc2f9031eb1c072da046248c069ea Superset 0.0.0devpython version: 3.7.5node.js version: 14.18.0
"
17093,1,6118,13,1,0,ganczarek,0,"title:Can't overwrite an existing dataset. description:Superset fails to overwrite an existing dataset in SQL Editor. Request fails with `Exception: Dataset [examples].[Test] already exists` in `before_update` function.#### How to reproduce the bug1. Go to SQL Editor2. Run `SELECT table_catalog, table_name FROM information_schema.tables`3. Click `Explore`. Enter `Test` in `Save as new` field and click `Save & Explore`4. Go back to SQL Editor5. Run modified query `SELECT table_catalog FROM information_schema.tables` 6. Click `Explore`. Enter `Test` in `Overwrite existing` field and click `Save & Explore`### Expected resultsSuperset overwrites dataset and redirects to Explore view### Actual resultsBrowser calls `PUT http://localhost:8088/api/v1/dataset/1?override_columns=true` with request:```{""sql"":""SELECT table_catalog FROM information_schema.tables"",""columns"":[{""column_name"":""table_catalog""}],""database_id"":1}```and Superset returns 500 Internal Server Error with response:```{""message"":""Fatal error""}``` `Test` dataset SQL query gets updated despite the server error.Exception stacktrace:```superset_app            | 2021-10-13 16:34:08,662:ERROR:root:Dataset [examples].[Test] already existssuperset_app            | Traceback (most recent call last):superset_app            |   File ""/usr/local/lib/python3.7/site-packages/flask_appbuilder/api/__init__.py"", line 85, in wrapssuperset_app            |     return f(self, *args, **kwargs)superset_app            |   File ""/app/superset/views/base_api.py"", line 85, in wrapssuperset_app            |     raise exsuperset_app            |   File ""/app/superset/views/base_api.py"", line 82, in wrapssuperset_app            |     duration, response = time_function(f, self, *args, **kwargs)superset_app            |   File ""/app/superset/utils/core.py"", line 1429, in time_functionsuperset_app            |     response = func(*args, **kwargs)superset_app            |   File ""/app/superset/utils/log.py"", line 241, in wrappersuperset_app            |     value = f(*args, **kwargs)superset_app            |   File ""/app/superset/datasets/api.py"", line 331, in putsuperset_app            |     g.user, pk, item, override_columnssuperset_app            |   File ""/app/superset/datasets/commands/update.py"", line 71, in runsuperset_app            |     override_columns=self.override_columns,superset_app            |   File ""/app/superset/datasets/dao.py"", line 169, in updatesuperset_app            |     super().update(model, properties, commit=commit)superset_app            |   File ""/app/superset/dao/base.py"", line 121, in updatesuperset_app            |     setattr(model, key, value)superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 273, in __set__superset_app            |     instance_state(instance), instance_dict(instance), value, Nonesuperset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 1319, in setsuperset_app            |     old = self.get(state, dict_, passive=PASSIVE_ONLY_PERSISTENT)superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/attributes.py"", line 723, in getsuperset_app            |     value = self.callable_(state, passive)superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/strategies.py"", line 760, in _load_for_statesuperset_app            |     session, state, primary_key_identity, passivesuperset_app            |   File ""<string>"", line 1, in <lambda>superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/strategies.py"", line 902, in _emit_lazyloadsuperset_app            |     .with_post_criteria(set_default_params)superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/ext/baked.py"", line 544, in allsuperset_app            |     return list(self)superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/ext/baked.py"", line 439, in __iter__superset_app            |     self.session._autoflush()superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 1618, in _autoflushsuperset_app            |     self.flush()superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2536, in flushsuperset_app            |     self._flush(objects)superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2678, in _flushsuperset_app            |     transaction.rollback(_capture_exception=True)superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py"", line 70, in __exit__superset_app            |     with_traceback=exc_tb,superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/util/compat.py"", line 182, in raise_superset_app            |     raise exceptionsuperset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/session.py"", line 2638, in _flushsuperset_app            |     flush_context.execute()superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py"", line 422, in executesuperset_app            |     rec.execute(self)superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py"", line 589, in executesuperset_app            |     uow,superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py"", line 213, in save_objsuperset_app            |     ) in _organize_states_for_save(base_mapper, states, uowtransaction):superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py"", line 387, in _organize_states_for_savesuperset_app            |     mapper.dispatch.before_update(mapper, connection, state)superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/event/attr.py"", line 322, in __call__superset_app            |     fn(*args, **kw)superset_app            |   File ""/usr/local/lib/python3.7/site-packages/sqlalchemy/orm/events.py"", line 719, in wrapsuperset_app            |     fn(*arg, **kw)superset_app            |   File ""/app/superset/connectors/sqla/models.py"", line 1669, in before_updatesuperset_app            |     raise Exception(get_dataset_exist_error_msg(target.full_name))superset_app            | Exception: Dataset [examples].[Test] already existssuperset_app            | 192.168.48.1 - - [13/Oct/2021:16:34:08 +0000] ""PUT /api/v1/dataset/1?override_columns=true HTTP/1.1"" 500 26 ""http://localhost:8088/superset/sqllab/"" ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36""```### EnvironmentI experience this issue consistently in AWS running Superset `v1.3.0`. However, I also reproduced it with local Docker containers and `tags/1.3.1`, though it didn't happen the first time I tried, but after Docker containers recreation, so it may require a few tries.```git checkout tags/1.3.1docker build --target lean --tag apache/superset:latest-dev .docker-compose -f docker-compose-non-dev.yml up```- browser type and version: Brave v1.29.79- superset version: `v1.3.1`- python version:  `3.7.9` ### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextI think that https://github.com/apache/superset/pull/16859 might have introduced that issue. https://github.com/apache/superset/issues/16434 is similar, but seems to address something slightly different.
"
17086,0,0,0,0,0,DBouwmans,0,"title:Lots of filters leads to too large url. description:Having too many filters leads to a too long url. I know we have A LOT of filters, we闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸嬫ɑ銇?currently working on that (not our own preference either). However, I don闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?think that superset should be able to create a url longer than a browser can handle. It also shows repetitive patterns.#### How to reproduce the bug1.	Create a dashboard with tabs 2.	Put a different table in your dashboard on every tab (but with a few overlapping columns)3.	Use the filter panel to add a whole lot of filters, some that are for multiple tables and some that are only for 1 tab applicable4.	Save and publish the dashboard5.	Do multiple actions in superset on that dashboard, like ordering/filtering/changing tabs/viewing a chart (table) in explore, etc6.	If you do this long enough/add enough filters, you闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸嬫﹢鏌?get an error (usually 411) URL too large7.	If you close the browser tab and re open superset it will be fine again and you闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸嬫﹢鏌?be able to work again, until you did too many actions again### Expected resultsJust for superset to work with a not-too-long-url. So not an URL longer than a browser can handle. In this case I expected a url of less than 2048 characters (chrome max).### Actual resultsI got an URL of almost 2300 characters. It seems to have a repeating pattern related to the filters: https://oursupersetinstancename/superset/dashboard/3/?native_filters=%28NATIVE_FILTER--UrbBqT5Od%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER--UrbBqT5Od%2CownState%3A%28%29%29%2CNATIVE_FILTER-09LqbeUUx%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-09LqbeUUx%2CownState%3A%28%29%29%2CNATIVE_FILTER-0MYqcKbfQ%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-0MYqcKbfQ%2CownState%3A%28%29%29%2CNATIVE_FILTER-0pc-VGJOT%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-0pc-VGJOT%2CownState%3A%28%29%29%2CNATIVE_FILTER-0qll2j3bRg%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-0qll2j3bRg%2CownState%3A%28%29%29%2CNATIVE_FILTER-14dML-EGr%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-14dML-EGr%2CownState%3A%28%29%29%2CNATIVE_FILTER-1Fm45MEeD%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-1Fm45MEeD%2CownState%3A%28%29%29%2CNATIVE_FILTER-1FyZFC7al6%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-1FyZFC7al6%2CownState%3A%28%29%29%2CNATIVE_FILTER-1gPLh05wr%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-1gPLh05wr%2CownState%3A%28%29%29%2CNATIVE_FILTER-27Ad3rMwl%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-27Ad3rMwl%2CownState%3A%28%29%29%2CNATIVE_FILTER-2TKwfJQKV%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-2TKwfJQKV%2CownState%3A%28%29%29%2CNATIVE_FILTER-3glKDB_BW%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-3glKDB_BW%2CownState%3A%28%29%29%2CNATIVE_FILTER-3vuF5XFwF%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-3vuF5XFwF%2CownState%3A%28%29%29%2CNATIVE_FILTER-4f0HLfLfd%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-4f0HLfLfd%2CownState%3A%28%29%29%2CNATIVE_FILTER-4qdfyyJL16%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-4qdfyyJL16%2CownState%3A%28%29%29%2CNATIVE_FILTER-5U3iToDSN%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-5U3iToDSN%2CownState%3A%28%29%29%2CNATIVE_FILTER-5tH8ayHRA%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-5tH8ayHRA%2CownState%3A%28%29%29%2CNATIVE_FILTER-6DrlPewMc%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-6DrlPewMc%2CownState%3A%28%29%29%2CNATIVE_FILTER-6WMDdf46C%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-6WMDdf46C%2CownState%3A%28%29%29%2CNATIVE_FILTER-6frJZYLWo%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-6frJZYLWo%2CownState%3A%28%29%29%2CNATIVE_FILTER-7EkaO-8H9M%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-7EkaO-8H9M%2CownState%3A%28%29%29%2CNATIVE_FILTER-7VbS9vfkMd%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-7VbS9vfkMd%2CownState%3A%28%29%29%2CNATIVE_FILTER-7XfQSOHj-J%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-7XfQSOHj-J%2CownState%3A%28%29%29%2CNATIVE_FILTER-7ioX66rwY%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-7ioX66rwY%2CownState%3A%28%29%29%2CNATIVE_FILTER-8ASz87UTf%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-8ASz87UTf%2CownState%3A%28%29%29%2CNATIVE_FILTER-9P7RxETL0%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-9P7RxETL0%2CownState%3A%28%29%29%2CNATIVE_FILTER-9TtMx6D38%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-9TtMx6D38%2CownState%3A%28%29%29%2CNATIVE_FILTER-9hm_DISkO%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-9hm_DISkO%2CownState%3A%28%29%29%2CNATIVE_FILTER-9jS-DbcY2%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-9jS-DbcY2%2CownState%3A%28%29%29%2CNATIVE_FILTER-AJq-MAqP9%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-AJq-MAqP9%2CownState%3A%28%29%29%2CNATIVE_FILTER-AlU2_84TJ%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-AlU2_84TJ%2CownState%3A%28%29%29%2CNATIVE_FILTER-B9JV2QZ8qe%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-B9JV2QZ8qe%2CownState%3A%28%29%29%2CNATIVE_FILTER-BLiOJaUbU%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-BLiOJaUbU%2CownState%3A%28%29%29%2CNATIVE_FILTER-BWiMF8thP%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-BWiMF8thP%2CownState%3A%28%29%29%2CNATIVE_FILTER-BitXsz8w7%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-BitXsz8w7%2CownState%3A%28%29%29%2CNATIVE_FILTER-C3PpEIia4%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-C3PpEIia4%2CownState%3A%28%29%29%2CNATIVE_FILTER-C6k4rNExR%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-C6k4rNExR%2CownState%3A%28%29%29%2CNATIVE_FILTER-Chi0V4Qlp%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-Chi0V4Qlp%2CownState%3A%28%29%29%2CNATIVE_FILTER-DHIyUpuCS5%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-DHIyUpuCS5%2CownState%3A%28%29%29%2CNATIVE_FILTER-DYPYWELhC%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-DYPYWELhC%2CownState%3A%28%29%29%2CNATIVE_FILTER-D_qWJffVx%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-D_qWJffVx%2CownState%3A%28%29%29%2CNATIVE_FILTER-De0mQWGgb%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-De0mQWGgb%2CownState%3A%28%29%29%2CNATIVE_FILTER-Dqz5HTu-7%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-Dqz5HTu-7%2CownState%3A%28%29%29%2CNATIVE_FILTER-EC5xBcY04%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-EC5xBcY04%2CownState%3A%28%29%29%2CNATIVE_FILTER-ED0207B__%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-ED0207B__%2CownState%3A%28%29%29%2CNATIVE_FILTER-EEXcE-r6m%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-EEXcE-r6m%2CownState%3A%28%29%29%2CNATIVE_FILTER-EHgOmHlzf%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-EHgOmHlzf%2CownState%3A%28%29%29%2CNATIVE_FILTER-ELMHABRg0%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-ELMHABRg0%2CownState%3A%28%29%29%2CNATIVE_FILTER-Ecj-urJin%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-Ecj-urJin%2CownState%3A%28%29%29%2CNATIVE_FILTER-FH7dKCj0m%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-FH7dKCj0m%2CownState%3A%28%29%29%2CNATIVE_FILTER-HITwMb2zc%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-HITwMb2zc%2CownState%3A%28%29%29%2CNATIVE_FILTER-IA7jul4xz%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-IA7jul4xz%2CownState%3A%28%29%29%2CNATIVE_FILTER-IgjR3FFBT%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-IgjR3FFBT%2CownState%3A%28%29%29%2CNATIVE_FILTER-JZ9mDGUpd%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-JZ9mDGUpd%2CownState%3A%28%29%29%2CNATIVE_FILTER-Jfw2hxOeh%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-Jfw2hxOeh%2CownState%3A%28%29%29%2CNATIVE_FILTER-KJaY4VNDu%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-KJaY4VNDu%2CownState%3A%28%29%29%2CNATIVE_FILTER-KZnI-pvCm%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-KZnI-pvCm%2CownState%3A%28%29%29%2CNATIVE_FILTER-Kb7QqRBji%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-Kb7QqRBji%2CownState%3A%28%29%29%2CNATIVE_FILTER-KpqMEhwaA%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-KpqMEhwaA%2CownState%3A%28%29%29%2CNATIVE_FILTER-KwALTJr6X%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-KwALTJr6X%2CownState%3A%28%29%29%2CNATIVE_FILTER-MIh4LWw-K%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-MIh4LWw-K%2CownState%3A%28%29%29%2CNATIVE_FILTER-MihftSRMs%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-MihftSRMs%2CownState%3A%28%29%29%2CNATIVE_FILTER-OBI_zfno4%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-OBI_zfno4%2CownState%3A%28%29%29%2CNATIVE_FILTER-ODLJq5_YG%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-ODLJq5_YG%2CownState%3A%28%29%29%2CNATIVE_FILTER-P61o6kF-h%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-P61o6kF-h%2CownState%3A%28%29%29%2CNATIVE_FILTER-P6imEZDEs%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-P6imEZDEs%2CownState%3A%28%29%29%2CNATIVE_FILTER-PKdgOnINL%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-PKdgOnINL%2CownState%3A%28%29%29%2CNATIVE_FILTER-Pdh0T1lB-%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-Pdh0T1lB-%2CownState%3A%28%29%29%2CNATIVE_FILTER-PdhdvdNL0%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-PdhdvdNL0%2CownState%3A%28%29%29%2CNATIVE_FILTER-PxQNfFdbS%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-PxQNfFdbS%2CownState%3A%28%29%29%2CNATIVE_FILTER-Q6ZHlE-N2%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-Q6ZHlE-N2%2CownState%3A%28%29%29%2CNATIVE_FILTER-QAmptEk1-P%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-QAmptEk1-P%2CownState%3A%28%29%29%2CNATIVE_FILTER-QHGN6-Nzl%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-QHGN6-Nzl%2CownState%3A%28%29%29%2CNATIVE_FILTER-QUDJmd4k3%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-QUDJmd4k3%2CownState%3A%28%29%29%2CNATIVE_FILTER-RBI57N834%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-RBI57N834%2CownState%3A%28%29%29%2CNATIVE_FILTER-Rvnkf6XpC%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-Rvnkf6XpC%2CownState%3A%28%29%29%2CNATIVE_FILTER-SYE6bfcsb%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-SYE6bfcsb%2CownState%3A%28%29%29%2CNATIVE_FILTER-TP7qXOMN3%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-TP7qXOMN3%2CownState%3A%28%29%29%2CNATIVE_FILTER-TVylh5iXP%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-TVylh5iXP%2CownState%3A%28%29%29%2CNATIVE_FILTER-TjNdLuK4w%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-TjNdLuK4w%2CownState%3A%28%29%29%2CNATIVE_FILTER-U5KmIrTyx%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-U5KmIrTyx%2CownState%3A%28%29%29%2CNATIVE_FILTER-Ui4mqYw_b%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-Ui4mqYw_b%2CownState%3A%28%29%29%2CNATIVE_FILTER-V4qJuEIlL%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-V4qJuEIlL%2CownState%3A%28%29%29%2CNATIVE_FILTER-V8MkmqH4O%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-V8MkmqH4O%2CownState%3A%28%29%29%2CNATIVE_FILTER-VYVvgdu4sM%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-VYVvgdu4sM%2CownState%3A%28%29%29%2CNATIVE_FILTER-W7UDfx1P2p%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-W7UDfx1P2p%2CownState%3A%28%29%29%2CNATIVE_FILTER-WF-L1b1iG%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-WF-L1b1iG%2CownState%3A%28%29%29%2CNATIVE_FILTER-WGIJYyEJL%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-WGIJYyEJL%2CownState%3A%28%29%29%2CNATIVE_FILTER-WWMY-u8EO%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-WWMY-u8EO%2CownState%3A%28%29%29%2CNATIVE_FILTER-X4BPcKdGI%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-X4BPcKdGI%2CownState%3A%28%29%29%2CNATIVE_FILTER-XBgGBGurk%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-XBgGBGurk%2CownState%3A%28%29%29%2CNATIVE_FILTER-XDvmwXz-Ov%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-XDvmwXz-Ov%2CownState%3A%28%29%29%2CNATIVE_FILTER-XKbHi3BHCJ%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-XKbHi3BHCJ%2CownState%3A%28%29%29%2CNATIVE_FILTER-XfhUQIik0W%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-XfhUQIik0W%2CownState%3A%28%29%29%2CNATIVE_FILTER-YQpOGe7Jk%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-YQpOGe7Jk%2CownState%3A%28%29%29%2CNATIVE_FILTER-YeCqMB0iuk%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-YeCqMB0iuk%2CownState%3A%28%29%29%2CNATIVE_FILTER-YhTzWniSU%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-YhTzWniSU%2CownState%3A%28%29%29%2CNATIVE_FILTER-_CXJf6nQP%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-_CXJf6nQP%2CownState%3A%28%29%29%2CNATIVE_FILTER-_JEMd22HC%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-_JEMd22HC%2CownState%3A%28%29%29%2CNATIVE_FILTER-aCdg8nbyp%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-aCdg8nbyp%2CownState%3A%28%29%29%2CNATIVE_FILTER-aEOaMw66O%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-aEOaMw66O%2CownState%3A%28%29%29%2CNATIVE_FILTER-alPDVYWiu%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-alPDVYWiu%2CownState%3A%28%29%29%2CNATIVE_FILTER-az9q_YpVG%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-az9q_YpVG%2CownState%3A%28%29%29%2CNATIVE_FILTER-b5PhDLm_x%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-b5PhDLm_x%2CownState%3A%28%29%29%2CNATIVE_FILTER-bKpGR2lg1%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-bKpGR2lg1%2CownState%3A%28%29%29%2CNATIVE_FILTER-btpQ4gr9M%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-btpQ4gr9M%2CownState%3A%28%29%29%2CNATIVE_FILTER-byHnhIBkG%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-byHnhIBkG%2CownState%3A%28%29%29%2CNATIVE_FILTER-c8Sot368O%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-c8Sot368O%2CownState%3A%28%29%29%2CNATIVE_FILTER-cQEzwzsSf%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-cQEzwzsSf%2CownState%3A%28%29%29%2CNATIVE_FILTER-cQUZHCBwSP%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-cQUZHCBwSP%2CownState%3A%28%29%29%2CNATIVE_FILTER-cWh6UPRE_%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-cWh6UPRE_%2CownState%3A%28%29%29%2CNATIVE_FILTER-cWscLH8dt%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-cWscLH8dt%2CownState%3A%28%29%29%2CNATIVE_FILTER-c_ZqpBcjt%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-c_ZqpBcjt%2CownState%3A%28%29%29%2CNATIVE_FILTER-d0WlmA-LL%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-d0WlmA-LL%2CownState%3A%28%29%29%2CNATIVE_FILTER-ddBClaNIL%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-ddBClaNIL%2CownState%3A%28%29%29%2CNATIVE_FILTER-di_QLjv7d%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-di_QLjv7d%2CownState%3A%28%29%29%2CNATIVE_FILTER-e4og9hYku%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-e4og9hYku%2CownState%3A%28%29%29%2CNATIVE_FILTER-eUuMAeiXb%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-eUuMAeiXb%2CownState%3A%28%29%29%2CNATIVE_FILTER-ef44ZsjRS%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-ef44ZsjRS%2CownState%3A%28%29%29%2CNATIVE_FILTER-egdqIbQsJ%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-egdqIbQsJ%2CownState%3A%28%29%29%2CNATIVE_FILTER-eltTxVAtJ%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-eltTxVAtJ%2CownState%3A%28%29%29%2CNATIVE_FILTER-f4NcnnVAI%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-f4NcnnVAI%2CownState%3A%28%29%29%2CNATIVE_FILTER-f_dh0mdiW%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-f_dh0mdiW%2CownState%3A%28%29%29%2CNATIVE_FILTER-fr3V6NYIW%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-fr3V6NYIW%2CownState%3A%28%29%29%2CNATIVE_FILTER-gLICwPSsV%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-gLICwPSsV%2CownState%3A%28%29%29%2CNATIVE_FILTER-g_ZX5Ezyw%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-g_ZX5Ezyw%2CownState%3A%28%29%29%2CNATIVE_FILTER-ghfkpy6OC%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-ghfkpy6OC%2CownState%3A%28%29%29%2CNATIVE_FILTER-gsaSHBx13%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-gsaSHBx13%2CownState%3A%28%29%29%2CNATIVE_FILTER-gwqzIhNkRI%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-gwqzIhNkRI%2CownState%3A%28%29%29%2CNATIVE_FILTER-hfR7u7DrZ%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-hfR7u7DrZ%2CownState%3A%28%29%29%2CNATIVE_FILTER-ikC78fIZh%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-ikC78fIZh%2CownState%3A%28%29%29%2CNATIVE_FILTER-imow7WtsIR%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-imow7WtsIR%2CownState%3A%28%29%29%2CNATIVE_FILTER-kmhjtDsJW%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-kmhjtDsJW%2CownState%3A%28%29%29%2CNATIVE_FILTER-kq0hrmiNI%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-kq0hrmiNI%2CownState%3A%28%29%29%2CNATIVE_FILTER-kwWL3WRws%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-kwWL3WRws%2CownState%3A%28%29%29%2CNATIVE_FILTER-m1hElT02y%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-m1hElT02y%2CownState%3A%28%29%29%2CNATIVE_FILTER-m72lkKo18%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-m72lkKo18%2CownState%3A%28%29%29%2CNATIVE_FILTER-nexgHxXml%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-nexgHxXml%2CownState%3A%28%29%29%2CNATIVE_FILTER-nw8qNWD9i%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-nw8qNWD9i%2CownState%3A%28%29%29%2CNATIVE_FILTER-oIkNlyNHG%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-oIkNlyNHG%2CownState%3A%28%29%29%2CNATIVE_FILTER-oh4THx62Uu%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-oh4THx62Uu%2CownState%3A%28%29%29%2CNATIVE_FILTER-p0Imlql_C%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-p0Imlql_C%2CownState%3A%28%29%29%2CNATIVE_FILTER-p6FU8xH_y%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-p6FU8xH_y%2CownState%3A%28%29%29%2CNATIVE_FILTER-pLpLQNdXM%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-pLpLQNdXM%2CownState%3A%28%29%29%2CNATIVE_FILTER-pS2U1009j%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-pS2U1009j%2CownState%3A%28%29%29%2CNATIVE_FILTER-pWgQ0_zQg%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-pWgQ0_zQg%2CownState%3A%28%29%29%2CNATIVE_FILTER-pyALU27rSQ%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-pyALU27rSQ%2CownState%3A%28%29%29%2CNATIVE_FILTER-qJFWoyllO%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-qJFWoyllO%2CownState%3A%28%29%29%2CNATIVE_FILTER-qXoLwIc3x%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-qXoLwIc3x%2CownState%3A%28%29%29%2CNATIVE_FILTER-r9YXlUF63%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-r9YXlUF63%2CownState%3A%28%29%29%2CNATIVE_FILTER-rL8SzrjYH%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-rL8SzrjYH%2CownState%3A%28%29%29%2CNATIVE_FILTER-rLRn8wx-C%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-rLRn8wx-C%2CownState%3A%28%29%29%2CNATIVE_FILTER-rW3lu_som%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-rW3lu_som%2CownState%3A%28%29%29%2CNATIVE_FILTER-rmIH_HMrxA%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-rmIH_HMrxA%2CownState%3A%28%29%29%2CNATIVE_FILTER-rpLk6_WQC%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-rpLk6_WQC%2CownState%3A%28%29%29%2CNATIVE_FILTER-ry180UDwq%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-ry180UDwq%2CownState%3A%28%29%29%2CNATIVE_FILTER-s5KjSFsgC%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-s5KjSFsgC%2CownState%3A%28%29%29%2CNATIVE_FILTER-sODE88hkQm%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-sODE88hkQm%2CownState%3A%28%29%29%2CNATIVE_FILTER-u-T1A3MJB%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-u-T1A3MJB%2CownState%3A%28%29%29%2CNATIVE_FILTER-uyTCMYuiH%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-uyTCMYuiH%2CownState%3A%28%29%29%2CNATIVE_FILTER-va2KE6JzN%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-va2KE6JzN%2CownState%3A%28%29%29%2CNATIVE_FILTER-viXXsxlqw%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-viXXsxlqw%2CownState%3A%28%29%29%2CNATIVE_FILTER-wQZRlvHMB%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-wQZRlvHMB%2CownState%3A%28%29%29%2CNATIVE_FILTER-wg6rJiaCp%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-wg6rJiaCp%2CownState%3A%28%29%29%2CNATIVE_FILTER-wpDDWJwqa%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-wpDDWJwqa%2CownState%3A%28%29%29%2CNATIVE_FILTER-x1Q8EbCBM%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-x1Q8EbCBM%2CownState%3A%28%29%29%2CNATIVE_FILTER-xGMGOWjNC%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-xGMGOWjNC%2CownState%3A%28%29%29%2CNATIVE_FILTER-xpQ3DveI_%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-xpQ3DveI_%2CownState%3A%28%29%29%2CNATIVE_FILTER-yPmDFdPXU%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-yPmDFdPXU%2CownState%3A%28%29%29%2CNATIVE_FILTER-yYl4CD4q8%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-yYl4CD4q8%2CownState%3A%28%29%29%2CNATIVE_FILTER-yg1QmoafM%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-yg1QmoafM%2CownState%3A%28%29%29%2CNATIVE_FILTER-yhLoupMVv%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-yhLoupMVv%2CownState%3A%28%29%29%2CNATIVE_FILTER-zDcgo8RFe%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-zDcgo8RFe%2CownState%3A%28%29%29%2CNATIVE_FILTER-zwwE95aA9%3A%28extraFormData%3A%28%29%2CfilterState%3A%28%29%2Cid%3ANATIVE_FILTER-zwwE95aA9%2CownState%3A%28%29%29%29### Environment- browser type and version: google chrome 94.0.4606.81 (Offici濠电姵顔栭崳顖滃緤閹€鏋栧┑?build) (64-bits) on windows 10- superset version: `superset version` apache/superset:6465ee7dbd7d1184f2f21f3611cf985cc84aaa6c - python version: `python --version` 3.7.9- node.js version: `node -v` not applicable- any feature flags active: NATIVE_DASHBOARD_FILTERS### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [x]  I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextPlease let me know if you need any other information regarding this subject
"
17083,1,229,0,0,1,krsnik93,0,"title:Dashboard import fails due to schema mismatch. description:Command `superset import-dashboards` fails because of following schema mismatches:1. `ValidationError({'extra': {'allows_virtual_table_explore': ['Unknown field.']}})` on schema `ImportV1DashboardSchema` in https://github.com/apache/superset/blob/7e4c940314ab6b09a89cb6938b02cf5d3028ad8a/superset/dashboards/schemas.py#L2792. `ValidationError({'query_context': ['Unknown field.']})` on schema `ImportV1ChartSchema` in https://github.com/apache/superset/blob/7e4c940314ab6b09a89cb6938b02cf5d3028ad8a/superset/charts/schemas.py#L1228Removing the fields fixes the import. The archive was created by exporting from another Superset host.#### How to reproduce the bug1. Export dashboards from one Superset host2. Try to import on another Superset host### Expected resultsExpect import to succeed.### Actual resultsImport fails with validation errors as above.### Environment(please complete the following information):- browser type and version:- superset version: 1.3.0 on source host, 1.2.0 on destination host- python version: 3.8.10- any feature flags active:```FEATURE_FLAGS = {    ""DYNAMIC_PLUGINS"": True,    ""ROW_LEVEL_SECURITY"": True,    ""VERSIONED_EXPORT"": True,    ""THUMBNAILS"": True,    ""THUMBNAILS_SQLA_LISTENERS"": True,    ""LISTVIEWS_DEFAULT_CARD_VIEW"": True,}```### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17075,0,0,0,0,0,junlincc,1,"title:[View in Explore]404s when 'View chart in Explore' from Dashboard. description:Users hit a 404 error sometimes when clicking 'View chart in Explore' sometimes. It tends to happens in those complicated dashboards and charts. Suspected cause: un-organized 5 pages long URI  <img width=""614"" alt=""Screen Shot 2021-10-11 at 11 14 12 AM"" src=""https://user-images.githubusercontent.com/67837651/136990833-11d09bfe-a63f-4b8a-a21d-22d784e89934.png"">#### How to reproduce the bug1. Go to 'a rich dashboard'2. Right click on 'View chart in Explore"" from the most complex chart in the dashboard.4. See page crash error### Expected resultsTake users to Explore### Actual resultsError #### Screenshots![image (1)](https://user-images.githubusercontent.com/67837651/136987764-5a7c9dcf-b7b4-4fde-bfe1-2e4ec21749de.png)If applicable, add screenshots to help explain your problem.### Environment(please complete the following information):- browser type and version: chrome- superset version: `superset version` - python version: `python --version`- node.js version: `node -v`- any feature flags active: Drag and drop, native filters. ### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17072,1,0,0,0,0,ul-fra,0,"title:Cannot create two datasets based on tables with the same name. description:I have an AWS Athena/Glue datacatalog. This catalog contains several databases, e.g. db-a and db-b. Both of these two databases contain a table ""te_general"". When I create a dataset for db-a.te_general everything is fine but when I create the second dataset based on db-b.te_general I get the error message ""An error occurred while creating datasets: Dataset could not be created."". In the logs I can find this message: ""(sqlite3.IntegrityError) UNIQUE constraint failed: tables.table_name""So it seems that the table_name seems to be unique. I would expect that the tripple of database-schema-table needs to be unique.#### How to reproduce the bug1. Go to datasets and create a first dataset for schema A and table T2. Go to datasets and create a second dataset for schema B and table T### Expected resultsBoth dataset should be registered.### Actual resultsSecond dataset is not created.#### Screenshots### Environment-     browser type and version: Firefox 88.0-     superset version: Superset 0.0.0dev-     python version: Python 3.8.12-     node.js version: ? (docker exec -it superset node -v --> node not on path)-     any feature flags active: no### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional context
"
17071,1,0,40,0,0,jinghua-qa,0,"title:[chart viz][heatmap] Max and min value in heat map show 100% and 0%. description:Max and min value in heat map show 100% and 0% in heatmap tooltip, which seems in accurate.#### How to reproduce the bug1. Go to cleaned sales data, open in explore2. Select  following for explore options:    viz type: heatmap,    time column: order_date,    X axis: country,     Y axis: year,     Metrics: avg(sales)    3. Select show percentage and legend, leave other option as default.4. Run query and see error### Expected resultsMax and Min value show corresponding percentage in tooltip### Actual resultsMax and Min value show 100% and 0% in tooltip#### Screenshots<img width=""1775"" alt=""Screen Shot 2021-10-12 at 12 49 46 AM"" src=""https://user-images.githubusercontent.com/81597121/136915243-7c554c8c-96e8-4d52-8340-d90fb4a976e4.png""><img width=""1785"" alt=""Screen Shot 2021-10-12 at 12 49 55 AM"" src=""https://user-images.githubusercontent.com/81597121/136915254-f4b01fa2-f3b4-4bb1-97e6-e014fb32d125.png"">Query and data return:<img width=""1792"" alt=""Screen Shot 2021-10-12 at 11 50 16 AM"" src=""https://user-images.githubusercontent.com/81597121/137012606-8053eda3-631d-45a9-a6ac-94583b65ae74.png"">### Environment(please complete the following information):- browser type and version: Chrome- superset version: master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
17070,1,0,0,0,0,qinlz-1,0,"title:safari browser can not open superset web ui. description:#### How to reproduce the bugUse Safari to open the Superset Web UI on iPhone Or Mac### Expected resultsthe superset web is accessible### Actual resultsweb can not open#### Screenshots![IMG_2064 PNG](https://user-images.githubusercontent.com/80371132/136906531-3bb022c2-7358-46a3-8e08-e29da77ccc69.JPG)### Environment(please complete the following information):- browser type and version: safari - superset version: 0.37.2- python version: 3.6- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [y ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ y] I have reproduced the issue with at least the latest released version of superset.- [ y] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17060,0,0,294,0,0,michael-s-molina,0,"title:[native_filter]Filters being put in out of scope when first opening the dashboard. description:### Expected resultsThe scope is calculated correctly when first opening the dashboard.### Actual resultsFilters being put in out of scope when first opening the dashboard.#### Screenshotshttps://user-images.githubusercontent.com/70410625/136839556-57bdeeb4-b3f2-4548-b338-9ec1e1599aa8.mov### Environment- browser type and version: Chrome 94.0.4606.71- superset version: master### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contexthttps://github.com/apache/superset/pull/17007
"
17058,1,0,0,0,0,gregmazur,0,"title:Apache Impala Error is not descreptive enough . description:A clear and concise description of what the bug is.#### How to reproduce the bug1. Go to 'SQL Lab'2. Click on 'Run' for a query that has certain number of rows, usually more then 100 rows3. Scroll down to '....'4. See error`2021-10-11 14:41:41,504 WARNING: superset.views.base: [SupersetError(message='impala error: bytes expected', error_type=<SupersetErrorType.GENERIC_DB_ENGINE_ERROR: 'GENERIC_DB_ENGINE_ERROR'>, level=<ErrorLevel.ERROR: 'error'>, extra={'engine_name': 'Apache Impala', 'issue_codes': [{'code': 1002, 'message': 'Issue 1002 - The database returned an unexpected error.'}]})]Traceback (most recent call last):  File ""/home/superset/venv/lib/python3.7/site-packages/superset/views/base.py"", line 204, in wraps    return f(self, *args, **kwargs)  File ""/home/superset/venv/lib/python3.7/site-packages/superset/utils/log.py"", line 241, in wrapper    value = f(*args, **kwargs)  File ""/home/superset/venv/lib/python3.7/site-packages/superset/views/core.py"", line 2573, in sql_json    return self.sql_json_exec(request.json, log_params)  File ""/home/superset/venv/lib/python3.7/site-packages/superset/views/core.py"", line 2762, in sql_json_exec    session, rendered_query, query, expand_data, log_params  File ""/home/superset/venv/lib/python3.7/site-packages/superset/views/core.py"", line 2558, in _sql_json_sync    [SupersetError(**params) for params in data[""errors""]]superset.exceptions.SupersetErrorsException: [SupersetError(message='impala error: bytes expected', error_type=<SupersetErrorType.GENERIC_DB_ENGINE_ERROR: 'GENERIC_DB_ENGINE_ERROR'>, level=<ErrorLevel.ERROR: 'error'>, extra={'engine_name': 'Apache Impala', 'issue_codes': [{'code': 1002, 'message': 'Issue 1002 - The database returned an unexpected error.'}]})]Triggering query_id: 2447`### Expected resultsresult. Or at least more detail stacktrace to investigate with impyla as there is no exception on Impala log### Actual resultsApache Impala Error#### Screenshots### Environment(please complete the following information):- browser type and version: Chrome- superset version: `superset 1.3.1`- python version: `python -3.7`- any feature flags active: more descriptive stack trace### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contexttrying to connect to Impala Docker image python:3.7.9impyla==0.15.0thrift==0.13.0thrift-sasl==0.4.2thriftpy2==0.4.0
"
17036,1,1510,9,0,0,Dr9vik,0,"title:time series {name} chart and command join . description:this is standart superset time series bar chart:![vivaldi_0MqYMCNKc7](https://user-images.githubusercontent.com/36520921/136579194-d97d2bbd-a971-44d9-bc02-fc982276b61b.png)query:```SELECT DATE(order_date, -strftime('%d', order_date) || ' days', '+1 day') AS __timestamp,       deal_size AS deal_size,       sum(sales) AS ""(Sales)""FROM ""Vehicle Sales""JOIN  (SELECT deal_size AS deal_size__,          sum(sales) AS mme_inner__   FROM ""Vehicle Sales""   WHERE order_date >= '2003-01-01 00:00:00.000000'     AND order_date < '2005-06-01 00:00:00.000000'   GROUP BY deal_size   ORDER BY mme_inner__ DESC   LIMIT 100   OFFSET 0) AS anon_1 ON deal_size = deal_size__WHERE order_date >= '2003-01-01 00:00:00.000000'  AND order_date < '2005-06-01 00:00:00.000000'GROUP BY deal_size,         DATE(order_date, -strftime('%d', order_date) || ' days', '+1 day')ORDER BY ""(Sales)"" DESCLIMIT 50000OFFSET 0;```request that should have been:```SELECT DATE(order_date, -strftime('%d', order_date) || ' days', '+1 day') AS __timestamp,       deal_size AS deal_size,       sum(sales) AS ""(Sales)""FROM ""Vehicle Sales""WHERE order_date >= '2003-01-01 00:00:00.000000'  AND order_date < '2005-06-01 00:00:00.000000'GROUP BY deal_size,         DATE(order_date, -strftime('%d', order_date) || ' days', '+1 day')ORDER BY ""(Sales)"" DESCLIMIT 50000OFFSET 0;```why does superset add this request?```JOIN  (SELECT deal_size AS deal_size__,          sum(sales) AS mme_inner__   FROM ""Vehicle Sales""   WHERE order_date >= '2003-01-01 00:00:00.000000'     AND order_date < '2005-06-01 00:00:00.000000'   GROUP BY deal_size   ORDER BY mme_inner__ DESC   LIMIT 100   OFFSET 0) AS anon_1 ON deal_size = deal_size__```This JOIN increases the data loading timeOld superset works fine
"
17032,1,0,0,0,0,alfmarcua,0,"title:Examples do not have datasource field via API. description:In a fresh install from scratch, after loading superset examples, those examples do not have the field datasource from /api/v1/chart/{id}. If we create a new chart, it appears correctly.### Expected resultsExample's charts should have datasource field when accessing them via API: /api/v1/chart/{id}.### Actual resultsOnly new charts have datasource  field when accessing them via API: /api/v1/chart/{id}.### Environment(please complete the following information):- superset version: 1.3.1- python version: 3.8.5- node.js version: 12.22.6### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
17030,0,0,144,0,1,denbon05,0,"title:In Sql Editor query input disappear, and after selected table schema everything disappear too. description:After added [some permissions](https://drive.google.com/file/d/1Hvxo9vXPiBzPGYWNbBrmK_AOxb6TEc_N/view?usp=sharing) for _Public_ role I noticed that in **Sql Editor** [disappear query input](https://drive.google.com/file/d/1LN4_cHmfkR0L8n-jdRJulpQ4raKJxGkJ/view?usp=sharing) (port 8088), then I selected **table shema** and[ this tab data is gone](https://drive.google.com/file/d/1nGzBSU9yyRGnuhg8f2-i4IMPI8Hmi7rT/view?usp=sharing) I'm not sure that it's happened after added permissionsfor Public role. I use docker-compose but it's no problem with it - I appended the same data, configurations and volume in developer mode and [everything is ok](https://drive.google.com/file/d/1pyVx5tPR8DfVJLBujamyz5HTYVmvqZgD/view?usp=sharing) (port 8099).How can I fix that?
"
17021,1,0,0,0,0,kevinwen2k,0,"title:CLIENT_CACHE flag in superset 1.2 breaks the dataset in explore page. description:Hi guys, I found a bug with the flag CLIENT_CACHE in config.py that break the explore page (/superset/explore/?form_data=%7B""viz_type""%3A""table""%2C""datasource""%3A""281__table""%2C""url_params"" ). Here闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?the step to reproduce:1. In superset/config.y, set the flag to true by ""CLIENT_CACHE"": True, .2. Restart server (superset/gunicorn).3. Go to Dataset list page (/tablemodelview/list/).4. Click on one of the dataset and you will land on the explore page (/superset/explore/).5. Under VISUALIZATION TYPE, change Table to any other type, like Line Chart.6. An error message pops up as screenshot below.We闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸嬫ɑ銇?using superset 1.2 and have the redis server used for caching. It happens on Mac/Linux with both superset and gunicorn.I tracked down a little bit and found out that it闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?because the datasource_id in the url (281__table) can闂傚倸鍊烽懗鍫曞磻閵娾晛纾块柡灞诲劜閸?be captured. Hope the information here is enough for the team to work on. Thanks!![Screen Shot 2021-10-04 at 12 42 53 AM](https://user-images.githubusercontent.com/4207782/136442333-f90f7ba7-ba56-45bd-b403-76921e3e9727.png)
"
17020,0,159,0,1,0,serenajiang,0,"title:New time series charts show all data missing if one part of ""contribution"" is missing. description:When you create a time series viz with a groupby and contribution `Total`, if at least one of the categories is missing a value for the date, no data points for that date are shown.This is sort of reasonable - technically, the data could be missing for the missing category, so it is not clear how to calculate contribution. However, in most cases, the missing data point corresponds to the value 0, and removing all the other data points is very confusing. In older charts (ex. line chart), contribution assumes 0 if data is missing, so we should provide some way to ""fill"" 0 for feature parity.I think there are two ways * Assume 0 whenever data is missing (similar to legacy line chart)* Have users use `resample` to fill missing values with 0. This is not possible yet because resample doesn't work if there's a group by - the error message is: `cannot reindex from a duplicate axis` and occurs [here](https://github.com/apache/superset/blob/fd8461406d62e818c4bc88075ac25ddf44ba9caf/superset/utils/pandas_postprocessing.py#L981)#### How to reproduce the bug1. Go to SQL Lab2. Run query:```sqlSELECT DATE('2021-09-01') AS ds, 'hi' AS xUNION ALL SELECT DATE('2021-09-02') AS ds, 'hi' AS xUNION ALL SELECT DATE('2021-09-01') AS ds, 'whoa' AS x```3. -> explore chart4. Use time series bar chart v2 viz5. Group by `x`, metric `count`, contribution `total`6. Note the missing data point for (`2021-09-02`, `hi`)### Expected resultsTwo bars should be shown for 09-01, one bar should be shown for 09-02### Actual resultsNo bars are shown for 09-02, even though there is a data point![image](https://user-images.githubusercontent.com/14146019/136434143-10bdd24f-82d7-405b-ae5c-25649928c7a0.png)### Environment(please complete the following information):- browser type and version: chrome- superset version: up to date with master as of 2021-10-01- python version: 3.8### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [X] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [X] I have reproduced the issue with at least the latest released version of superset.- [X] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextThis is somewhat related to this issue: https://github.com/apache/superset/issues/15036
"
17012,0,0,0,0,0,ValentinC-BR,0,"title:[KPI with trendline] Time comparison isn't displayed when the value is stable and equal to 0. description:When a KPI is equal to 0 during 2 periods, the time comparison (+ 0%) isn't displayed#### How to reproduce the bug1. Create a KPI with trendline2. Write ""0"" in Metrics / Custom SQL3. Chose time comparison period = 14. Run### Expected results""+ 0%"" (and the subheader !) should be displayed next to the number### Actual resultsThere is no subheader nor time comparison.However, this works with stable trendlines not equal to 0#### Screenshots![image](https://user-images.githubusercontent.com/79460908/136375628-4484b621-13f5-4ab7-bff0-20863a961fdd.png)![image](https://user-images.githubusercontent.com/79460908/136375819-7208f00b-5b08-4c28-9ef5-c3b57ba139b7.png)### Environment(please complete the following information):- browser type and version: Google Chrome Version 94.0.4606.71 (Oficial build) (x86_64)- superset version: 1.3.0- python version: 3.7.9- node.js version: doesn't apply, I run on Kubernetes, using gunicorn as server- source : AWS Athena- any feature flags active: /### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [ ] I have reproduced the issue with at least the latest released version of superset.- [ ] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
16996,0,0,18,0,0,manavjaiswal,0,"title:Sql lab not loading on fresh db init. description:After fresh installation, chose not to load examples and added my own charts and a dashboard to test. Works fine till here. Then click on SQL Editor from under SQL Lab, the page does not load with no api calls as in the screenshot. I only see an error in console ( attached screenshot).#### Screenshots![Screen Shot 2021-10-06 at 1 49 57 PM](https://user-images.githubusercontent.com/13721953/137199274-13bd3d4e-7e80-4aa5-9fd3-2cf5a6a1aca2.jpg)### Environment(please complete the following information): dev- browser type and version: Chrome Version 94.0.4606.61 (Official Build) (x86_64)- superset version: GIT sha 87baac7650bdb6a8f8f82cf4992567a2c5c73cba Superset 0.0.0dev- python version: 3.7.5- node.js version: 14.18.0
"
16995,0,0,40,0,0,jinghua-qa,0,"title:[Explore] Owner can not change the name by just clicking on the title. description:Owner can not click and edit on the chart name when open a saved chart, can only do click edit when creating a new chart.#### How to reproduce the bug1, Explore saved chart own by you2, Hover mouse over to chart's title3, Click on chart title### Expected results1,Should see tooltip ""Click to edit""2,Title is successfully edit and saved### Actual resultsThere is no opportunity to edit chart title by click#### Screenshots![ezgif com-gif-maker (6)](https://user-images.githubusercontent.com/81597121/136271109-a8b5a14d-4ecd-49f3-b319-bee16b1e1fc4.gif)### Environment(please complete the following information):- browser type and version: Chrome- superset version: master- python version: `python --version`- node.js version: `node -v`- any feature flags active:### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [ ] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
16984,0,935,5,0,0,xingyc15,0,"title:JINJA Template does not work with calculated time column. description:Seems that there is a bug in using Jinja template in calculated columns. The scenario is that I set a Jinja template in a **Calculated Columns** and I use this column as the **Time Column** of a time series bar chart (I tried both time series bar chart v1 and v2), in the query, the template is not replaced. But the Jinja template set in calculated columns that are not used as time columns works fine.Here is the case, my calculated column is:```CASE    WHEN '{{time_zone}}' = 'America/Los_Angeles' THEN date_pst    WHEN '{{time_zone}}' = 'Asia/Shanghai' THEN date_cstEND```but the query generated from time series chart is that:```SELECT {CASE            WHEN '{{time_zone}}' = 'America/Los_Angeles' THEN date_pst            WHEN '{{time_zone}}' = 'Asia/Shanghai' THEN date_cst        END}, DISTINCTCOUNT(username)FROM logsWHERE CASE          WHEN 'America/Los_Angeles' = 'America/Los_Angeles' THEN date_pst          WHEN 'America/Los_Angeles' = 'Asia/Shanghai' THEN date_cst      END >= '2021-07-05'  AND CASE          WHEN 'America/Los_Angeles' = 'America/Los_Angeles' THEN date_pst          WHEN 'America/Los_Angeles' = 'Asia/Shanghai' THEN date_cst      END < '2021-10-05'GROUP BY {CASE              WHEN '{{time_zone}}' = 'America/Los_Angeles' THEN date_pst              WHEN '{{time_zone}}' = 'Asia/Shanghai' THEN date_cst          END}ORDER BY DISTINCTCOUNT(username) DESCLIMIT 10000;```#### How to reproduce the bug1. Create a dataset. Setup a calculated column with Jinja template.2. Create a new chart, set the TIME COLUMN using that calculated column.3. Run the chart and the Jinja template is not applied.### Expected resultsThe Jinja template should have applied.### Actual resultsThe template clause is still there.#### Screenshots<img width=""308"" alt=""Screen Shot 2021-10-05 at 2 44 18 PM"" src=""https://user-images.githubusercontent.com/33602700/136107082-da517cc6-7a9e-4d5a-8890-0891621073bb.png"">### Environment- superset version: `1.3.0`### Checklist- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.
"
16983,0,0,0,0,0,rosemarie-chiu,0,"title:[Homepage Favorite tab] When click on ""View all"" from favorite tab, get error. description:When clicking on ""view all"" from homepage favorite tab, getting error#### How to reproduce the bug1. Go to homepage2. Click on favorite tab for dashboard3. click on View All4. See error### Expected resultsIt used to lead user into dashboard list with favorite filter on### Actual resultshttps://user-images.githubusercontent.com/52086618/136100277-17c2d5e0-49b9-4041-ae04-3b5ac2abd4c0.mp4#### Screenshots### Environment(please complete the following information):- browser type and version: chrome Version 94.0.4606.61 - superset version: `latest master`- any feature flags active: default feature flag combo from master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextAdd any other context about the problem here.
"
16981,0,0,0,0,0,graceguo-supercat,0,"title:[dashboard][markdown] User can remove markdown component in dashboard view mode. description:A clear and concise description of what the bug is.#### How to reproduce the bug1. create new dashboard,2. add markdown component3. save dashboard4. Open dashboard, and hover on the markdown component5. you can click trash icon to remove markdown component### Expected results- Only in dashboard edit mode can change dashboard layout and components.- Only dashboard owner can edit dashboard.#### Screenshots![rxSiPpzrw5](https://user-images.githubusercontent.com/27990562/136080928-00310f2a-3e9d-42b9-aa1b-5e7242904f15.gif)### EnvironmentLastest master### ChecklistMake sure to follow these steps before submitting your issue - thank you!- [x] I have checked the superset logs for python stacktraces and included it here as text if there are any.- [x] I have reproduced the issue with at least the latest released version of superset.- [x] I have checked the issue tracker for the same issue and I haven't found one similar.### Additional contextcc @junlincc @jinghua-qa @pkdotson 
"
