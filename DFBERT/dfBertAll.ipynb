{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.0.0+cu118'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device=', device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002B775C5BDF0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/config.json\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([16, 2])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "#加载预训练模型\n",
    "pretrained = BertModel.from_pretrained('bert-base-uncased')\n",
    "#需要移动到cuda上\n",
    "pretrained.to(device)\n",
    "\n",
    "#不训练,不需要计算梯度\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "\n",
    "#定义下游任务模型\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(1,16)\n",
    "        self.linear2 = torch.nn.Linear(1,16)\n",
    "        self.linear3 = torch.nn.Linear(1,16)\n",
    "        self.linear4 = torch.nn.Linear(1,16)\n",
    "\n",
    "        self.fc = torch.nn.Linear(768+3, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, code_len, keyword_num, permission):\n",
    "        with torch.no_grad():\n",
    "            out = pretrained(input_ids=input_ids,\n",
    "                       attention_mask=attention_mask,\n",
    "                       token_type_ids=token_type_ids)\n",
    "        # print(code_len)\n",
    "        # code_len = self.linear1(code_len)\n",
    "        # keyword_num = self.linear2(keyword_num)\n",
    "        # keyword_fix = self.linear3(keyword_fix)\n",
    "        # permission = self.linear4(permission)\n",
    "\n",
    "        # code_len = code_len\n",
    "        # keyword_num = keyword_num.unsqueeze(1)\n",
    "        # keyword_fix = keyword_fix.unsqueeze(1)\n",
    "        # permission = permission.unsqueeze(1)\n",
    "        # code_len = torch.transpose(code_len, 0, 1)\n",
    "        # keyword_num = torch.transpose(keyword_num, 0, 1)\n",
    "        # keyword_fix = torch.transpose(keyword_fix, 0, 1)\n",
    "        # permission = torch.transpose(permission, 0, 1)\n",
    "\n",
    "\n",
    "        concat = torch.cat((out.last_hidden_state[:, 0], code_len, keyword_num, permission), dim=1)\n",
    "        out = self.fc(concat)\n",
    "\n",
    "        out = out.softmax(dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "model = Model()\n",
    "#同样要移动到cuda\n",
    "model.to(device)\n",
    "\n",
    "#虚拟一批数据,需要把所有的数据都移动到cuda上\n",
    "input_ids = torch.ones(16, 100).int().to(device)\n",
    "attention_mask = torch.ones(16, 100).int().to(device)\n",
    "token_type_ids = torch.ones(16, 100).int().to(device)\n",
    "code_len = torch.ones(16,1).float().to(device)\n",
    "keyword_num = torch.ones(16,1).float().to(device)\n",
    "permission = torch.ones(16,1).float().to(device)\n",
    "labels = torch.ones(16,1).float().to(device)\n",
    "\n",
    "#试算\n",
    "model(input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      token_type_ids=token_type_ids,\n",
    "      code_len=code_len,\n",
    "      keyword_num=keyword_num,\n",
    "      permission=permission).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/hananan/.cache/huggingface/datasets/csv/default-cdeb13bd05363744/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9432854b59f742bcadf6bbcf455da958"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['num', 'label', 'code_len', 'con_num', 'keyword_num', 'keyword_fix', 'username', 'permission', 'ds'],\n",
      "    num_rows: 1996\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": "(1996,\n ('title:Killing docker-containerd breaks interaction with containers. description:When killing `docker-containerd`, interacting with containers (`docker exec`, `docker stop`, `docker kill`) fails:```bashdocker kill testingError response from daemon: Cannot kill container: testing: Cannot kill container 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359: connection error: desc = \"transport: dial unix /var/run/docker/containerd/docker-containerd.sock: connect: connection refused\": unknowndocker rm -f lucid_yalowError response from daemon: Could not kill running container 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359, cannot remove - Cannot kill container 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359: connection error: desc = \"transport: dial unix /var/run/docker/containerd/docker-containerd.sock: connect: connection refused\": unknown```But killing `dockerd` (either by `killall -9 dockerd` or a `SIGHUP`; `killall -HUP dockerd`) restores functionality.This problem could explain some reports about \"unkillable\" containers, where everything appears to be running, but interaction is not possible (possibly after `containerd` was OOM killed, but could have different causes).### Steps to reproduce / informationHave docker running, start a container, and check output of `ps auxf`: `docker-containerd` and `docker-containerd-shim` are child-processes of `dockerd`:```root     11468  1.1  3.4 468232 71036 ?        Ssl  11:56   0:01 /usr/bin/dockerd -H fd://root     11473  0.4  1.3 236512 27856 ?        Ssl  11:56   0:00  \\\\_ docker-containerd --config /var/run/docker/containerd/containerd.tomlroot     11918  0.0  0.1   7516  3788 ?        Sl   11:57   0:00      \\\\_ docker-containerd-shim -namespace moby -workdir /var/lib/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359 -address /var/run/docker/containerd/docker-containerd.sock -containerd-binary /usr/bin/docker-containerd -runtime-root /var/run/docker/runtime-runcroot     11933  0.1  0.0   1236     4 pts/0    Ss+  11:57   0:00          \\\\_ sh```Now, kill `docker-containerd` (`killall -9 docker-containerd`).`docker-containerd` is restarted (by `dockerd`); observe that `docker-containerd-shim` and the container process(es) are reparented (I haven\\'t checked what the new parent process is, and if this is relevant). The `docker-containerd-shim` processes are no longer child-process of `docker-containerd`;```root     11468  160  3.6 470984 74664 ?        Ssl  11:56  19:55 /usr/bin/dockerd -H fd://root     11979  0.1  1.2 300992 25980 ?        Ssl  11:58   0:01  \\\\_ docker-containerd --config /var/run/docker/containerd/containerd.tomlroot     11918  0.0  0.2   7516  4688 ?        Sl   11:57   0:00 docker-containerd-shim -namespace moby -workdir /var/lib/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359 -address /var/run/docker/containerd/docker-containerd.sock -containerd-binary /usr/bin/docker-containerd -runtime-root /var/run/docker/runtime-runcroot     11933  0.0  0.0   1236     4 pts/0    Ss+  11:57   0:00  \\\\_ sh```At this point, interacting with containers is now broken..Containers still show up as running:```bashdocker psCONTAINER ID        IMAGE               COMMAND             CREATED              STATUS              PORTS               NAMES9bfdba3fc8ee        busybox             \"sh\"                About a minute ago   Up About a minute                       testing```Inspecting the container still works, and shows the `pid` of the container;```bashdocker inspect --format \\'{{json .State}}\\' testing | jq .{  \"Status\": \"running\",  \"Running\": true,  \"Paused\": false,  \"Restarting\": false,  \"OOMKilled\": false,  \"Dead\": false,  \"Pid\": 11933,  \"ExitCode\": 0,  \"Error\": \"\",  \"StartedAt\": \"2018-01-12T11:57:47.687627373Z\",  \"FinishedAt\": \"0001-01-01T00:00:00Z\"}```But any interaction with the containers is broken;```bashdocker kill testingError response from daemon: Cannot kill container: testing: Cannot kill container 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359: connection error: desc = \"transport: dial unix /var/run/docker/containerd/docker-containerd.sock: connect: connection refused\": unknowndocker rm -f lucid_yalowError response from daemon: Could not kill running container 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359, cannot remove - Cannot kill container 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359: connection error: desc = \"transport: dial unix /var/run/docker/containerd/docker-containerd.sock: connect: connection refused\": unknown```When directly connecting to containerd, containers still show:```bashdocker-containerd-ctr --namespace=moby --address /var/run/docker/containerd/docker-containerd.sock containers lsCONTAINER                                                           IMAGE    RUNTIME                           9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359    -        io.containerd.runtime.v1.linux    ```And can be inspected;```bashdocker-containerd-ctr --namespace=moby --address /var/run/docker/containerd/docker-containerd.sock containers info 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359......```Shims are still up:```netstat -x | grep shimunix  2      [ ]         STREAM     CONNECTED     64641    @/containerd-shim/moby/9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359/shim.sockunix  3      [ ]         STREAM     CONNECTED     64019    @/containerd-shim/moby/9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359/shim.sock``````bashdocker-runc --root /var/run/docker/runtime-runc/moby/ state 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359{  \"ociVersion\": \"1.0.0\",  \"id\": \"9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359\",  \"pid\": 11933,  \"status\": \"running\",  \"bundle\": \"/run/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359\",  \"rootfs\": \"/var/lib/docker/overlay2/9c0e355304db9fb85f7c1281b11008eea23bd4dbb142f11f551066c9fdb2e70e/merged\",  \"created\": \"2018-01-12T11:57:47.631870877Z\",  \"owner\": \"\"}```And the container is still functional, when using `docker-runc`;```bashdocker-runc --root /var/run/docker/runtime-runc/moby/ exec 9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359 ls -latotal 44drwxr-xr-x    1 root     root          4096 Jan 12 11:57 .drwxr-xr-x    1 root     root          4096 Jan 12 11:57 ..-rwxr-xr-x    1 root     root             0 Jan 12 11:57 .dockerenvdrwxr-xr-x    2 root     root         12288 Jan  8 21:14 bindrwxr-xr-x    5 root     root           360 Jan 12 11:57 devdrwxr-xr-x    1 root     root          4096 Jan 12 11:57 etcdrwxr-xr-x    2 nobody   nogroup       4096 Jan  8 21:14 homedr-xr-xr-x  125 root     root             0 Jan 12 11:57 procdrwxr-xr-x    2 root     root          4096 Jan  8 21:14 rootdr-xr-xr-x   13 root     root             0 Jan 12 11:57 sysdrwxrwxrwt    2 root     root          4096 Jan  8 21:14 tmpdrwxr-xr-x    3 root     root          4096 Jan  8 21:14 usrdrwxr-xr-x    4 root     root          4096 Jan  8 21:14 var```### restore functionalityKill `dockerd` (`killall -9 dockerd`) or `SIGHUP` (`killall -HUP dockerd`).Observe that shims are not re-parented (which is probably expected);```root     11918  0.0  0.2   7516  4688 ?        Sl   11:57   0:00 docker-containerd-shim -namespace moby -workdir /var/lib/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/9bfdba3fc8eee79d6ca5773f7caff5dc5a8379037e98b6ded5c8b68df5750359 -address /var/run/docker/containerd/docker-containerd.sock -containerd-binary /usr/bin/docker-contairoot     11933  0.0  0.0   1236     4 pts/0    Ss+  11:57   0:00  \\\\_ shroot     12287  1.1  2.8 446232 57824 ?        Ssl  12:55   0:00 /usr/bin/dockerd -H fd://root     12293  0.7  1.1 300928 22616 ?        Ssl  12:55   0:00  \\\\_ docker-containerd --config /var/run/docker/containerd/containerd.toml```But now it\\'s possible again to interact with them:```docker exec testing ls -latotal 44drwxr-xr-x    1 root     root          4096 Jan 12 11:57 .drwxr-xr-x    1 root     root          4096 Jan 12 11:57 ..-rwxr-xr-x    1 root     root             0 Jan 12 11:57 .dockerenvdrwxr-xr-x    2 root     root         12288 Jan  8 21:14 bindrwxr-xr-x    5 root     root           360 Jan 12 11:57 devdrwxr-xr-x    1 root     root          4096 Jan 12 11:57 etcdrwxr-xr-x    2 nobody   nogroup       4096 Jan  8 21:14 homedr-xr-xr-x  126 root     root             0 Jan 12 11:57 procdrwxr-xr-x    1 root     root          4096 Jan 12 12:58 rootdr-xr-xr-x   13 root     root             0 Jan 12 11:57 sysdrwxrwxrwt    2 root     root          4096 Jan  8 21:14 tmpdrwxr-xr-x    3 root     root          4096 Jan  8 21:14 usrdrwxr-xr-x    4 root     root          4096 Jan  8 21:14 var```## Version of docker and containerdTested on Ubuntu 16.04 on DigitalOcean;```docker-containerd --versioncontainerd github.com/containerd/containerd v1.0.0 89623f28b87a6004d4b785663257362d1658a729``````Client: Version:\\t18.01.0-ce API version:\\t1.35 Go version:\\tgo1.9.2 Git commit:\\t03596f5 Built:\\tWed Jan 10 20:11:05 2018 OS/Arch:\\tlinux/amd64 Experimental:\\tfalse Orchestrator:\\tswarmServer: Engine:  Version:\\t18.01.0-ce  API version:\\t1.35 (minimum version 1.12)  Go version:\\tgo1.9.2  Git commit:\\t03596f5  Built:\\tWed Jan 10 20:09:37 2018  OS/Arch:\\tlinux/amd64  Experimental:\\tfalse``````Containers: 1 Running: 1 Paused: 0 Stopped: 0Images: 2Server Version: 18.01.0-ceStorage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 89623f28b87a6004d4b785663257362d1658a729runc version: b2567b37d7b75eb4cf325b77297b140ea686ce8finit version: 949e6faSecurity Options: apparmor seccomp  Profile: defaultKernel Version: 4.4.0-108-genericOperating System: Ubuntu 16.04.3 LTSOSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.953GiBName: ubuntu-2gb-ams3-01ID: KIY5:X5P2:5FI5:GEPC:Q2OO:XF4P:KFB2:S22T:A76T:DVFV:UIFB:ZATYDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): falseRegistry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseWARNING: No swap limit support```\\r\\n',\n  9141,\n  0,\n  0,\n  0,\n  0),\n 500,\n (\"title:Current implementation only supports equal length strides in the row and column dimensions. description:When I use layers related  to DepthwiseConv2d operation, such as tf.keras.layers.SeparableConv2d, exception occurs like that: 'Current implementation only supports equal length strides in the row and column dimensions. [Op: DepthwiseConv2dNative]'. It means that i cannot use parameter 'strides' like [1, 2], however, that conflicts with the documentation, which allows 'strides'  with list format without mentioning that elements within the list should be the same.I'm using TensorFlow 2.0.0, and I guess this bug exisits in 3D scenariothe and further edition.![1](https://user-images.githubusercontent.com/94270103/141666163-3ba1d244-6efb-49b2-aa49-322d0b4d0889.png)\\r\\n\",\n  0,\n  0,\n  0,\n  0,\n  1))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset1 = load_dataset(path='csv', data_dir='D:\\\\hzrproject\\\\study\\\\n_feature2',data_files='modified_issueDataAll.csv')['train']\n",
    "\n",
    "#train_dataset, test_dataset = dataset1.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "\n",
    "train_ratio = 0.8  # 80% 用于训练，20% 用于测试\n",
    "num_samples = len(dataset1)\n",
    "\n",
    "# 创建一个索引列表，代表数据集的样本\n",
    "sample_indices = list(range(num_samples))\n",
    "\n",
    "# 随机打乱索引列表\n",
    "random.shuffle(sample_indices)\n",
    "\n",
    "# 计算分割点\n",
    "split_index = int(train_ratio * num_samples)\n",
    "\n",
    "# 使用随机抽样来选择训练集和测试集的索引\n",
    "train_indices = sample_indices[:split_index]\n",
    "test_indices = sample_indices[split_index:]\n",
    "\n",
    "# 使用索引来选择子集\n",
    "train_dataset = dataset1.select(train_indices)\n",
    "test_dataset = dataset1.select(test_indices)\n",
    "\n",
    "print(train_dataset)\n",
    "\n",
    "#定义数据集\n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.dataset = train_dataset\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ds = self.dataset[i]['ds']\n",
    "        code_len = self.dataset[i]['code_len']\n",
    "        keyword_num = self.dataset[i]['keyword_num']\n",
    "        keyword_fix = self.dataset[i]['keyword_fix']\n",
    "        permission = self.dataset[i]['permission']\n",
    "        label = self.dataset[i]['label']\n",
    "\n",
    "        return  ds, code_len, keyword_num, keyword_fix, permission, label\n",
    "\n",
    "class Dataset_validation:\n",
    "    def __init__(self):\n",
    "        self.dataset_validation = test_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_validation)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ds = self.dataset_validation[i]['ds']\n",
    "        code_len = self.dataset_validation[i]['code_len']\n",
    "        keyword_num = self.dataset_validation[i]['keyword_num']\n",
    "        keyword_fix = self.dataset_validation[i]['keyword_fix']\n",
    "        permission = self.dataset_validation[i]['permission']\n",
    "        label = self.dataset_validation[i]['label']\n",
    "\n",
    "        return  ds, code_len, keyword_num, keyword_fix, permission, label\n",
    "\n",
    "\n",
    "dataset = Dataset()\n",
    "dataset_validation = Dataset_validation()\n",
    "\n",
    "len(dataset), dataset[0], len(dataset_validation), dataset_validation[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/vocab.txt (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002B8062A4CA0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt\n",
      "'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/added_tokens.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002B77FBB9340>, 'Connection to huggingface.co timed out. (connect timeout=10)'))' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json\n",
      "'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/special_tokens_map.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002B77FBC0610>, 'Connection to huggingface.co timed out. (connect timeout=10)'))' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json\n",
      "'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/tokenizer_config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002B77FBC0C40>, 'Connection to huggingface.co timed out. (connect timeout=10)'))' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'bert-base-uncased'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'bert-base-uncased' is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BertTokenizer\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#加载字典和分词工具\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m token \u001B[38;5;241m=\u001B[39m \u001B[43mBertTokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbert-base-uncased\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcollate_fn\u001B[39m(data):\n\u001B[0;32m      8\u001B[0m     sents \u001B[38;5;241m=\u001B[39m [i[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m data]\n",
      "File \u001B[1;32mD:\\python\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1788\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001B[0m\n\u001B[0;32m   1782\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[0;32m   1783\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt load following files from cache: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00munresolved_files\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and cannot check if these \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1784\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfiles are necessary for the tokenizer to operate.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1785\u001B[0m     )\n\u001B[0;32m   1787\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mall\u001B[39m(full_file_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m full_file_name \u001B[38;5;129;01min\u001B[39;00m resolved_vocab_files\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[1;32m-> 1788\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[0;32m   1789\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt load tokenizer for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. If you were trying to load it from \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1790\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/models\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, make sure you don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt have a local directory with the same name. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1791\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOtherwise, make sure \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpretrained_model_name_or_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is the correct path to a directory \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1792\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontaining all relevant files for a \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m tokenizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1793\u001B[0m     )\n\u001B[0;32m   1795\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file_id, file_path \u001B[38;5;129;01min\u001B[39;00m vocab_files\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m   1796\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m file_id \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m resolved_vocab_files:\n",
      "\u001B[1;31mOSError\u001B[0m: Can't load tokenizer for 'bert-base-uncased'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'bert-base-uncased' is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer."
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "#加载字典和分词工具\n",
    "token = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    sents = [i[0] for i in data]\n",
    "    code_len = [i[1] for i in data]\n",
    "    keyword_num = [i[2] for i in data]\n",
    "    permission = [i[4] for i in data]\n",
    "    labels = [i[5] for i in data]\n",
    "\n",
    "    #编码\n",
    "    data = token.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   max_length=500,\n",
    "                                   return_tensors='pt',\n",
    "                                   return_length=True)\n",
    "\n",
    "    #input_ids:编码之后的数字\n",
    "    #attention_mask:是补零的位置是0,其他位置是1\n",
    "    input_ids = data['input_ids'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "    token_type_ids = data['token_type_ids'].to(device)\n",
    "\n",
    "    code_len = torch.FloatTensor(code_len).to(device)\n",
    "    code_len = code_len.unsqueeze(0).t()\n",
    "\n",
    "    keyword_num = torch.FloatTensor(keyword_num).to(device)\n",
    "    keyword_num = keyword_num.unsqueeze(0).t()\n",
    "\n",
    "    permission = torch.FloatTensor(permission).to(device)\n",
    "    permission = permission.unsqueeze(0).t()\n",
    "\n",
    "    labels = torch.LongTensor(labels).to(device).to(device)\n",
    "\n",
    "    #print(data['length'], data['length'].max())\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, code_len, keyword_num, permission, labels\n",
    "\n",
    "\n",
    "#数据加载器\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=16,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "\n",
    "for i, (input_ids, attention_mask, token_type_ids, code_len, keyword_num, permission,\n",
    "        labels) in enumerate(loader):\n",
    "    break\n",
    "\n",
    "print(len(loader))\n",
    "input_ids.shape, attention_mask.shape, token_type_ids.shape, code_len.shape, keyword_num.shape, permission.shape, labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "0 0.9698920249938965 0.25\n",
      "10 0.9243355393409729 0.3125\n",
      "20 0.8281766176223755 0.5\n",
      "30 0.8890995979309082 0.25\n",
      "40 0.7533174157142639 0.625\n",
      "50 0.8316081762313843 0.375\n",
      "60 0.8855512142181396 0.5\n",
      "70 0.7870410680770874 0.5625\n",
      "80 0.7157672643661499 0.5625\n",
      "90 0.7866870164871216 0.3125\n",
      "100 0.8191074728965759 0.375\n",
      "110 0.7440036535263062 0.5\n",
      "120 0.8365598320960999 0.375\n",
      "0.4230769230769231\n",
      "----------------------\n",
      "epoch: 2\n",
      "0 0.5942975282669067 0.6875\n",
      "10 0.8554688692092896 0.5\n",
      "20 0.8203074932098389 0.5\n",
      "30 0.5759769082069397 0.6875\n",
      "40 0.8705627918243408 0.375\n",
      "50 0.7841891646385193 0.5625\n",
      "60 0.8588594794273376 0.5\n",
      "70 0.7886132001876831 0.5\n",
      "80 0.8531505465507507 0.4375\n",
      "90 0.7988027930259705 0.5\n",
      "100 0.7362814545631409 0.625\n",
      "110 0.8017143607139587 0.5\n",
      "120 0.7278761863708496 0.5\n",
      "0.5288461538461539\n",
      "----------------------\n",
      "epoch: 3\n",
      "0 0.6085062026977539 0.6875\n",
      "10 0.699018657207489 0.625\n",
      "20 0.801583468914032 0.4375\n",
      "30 0.6989946961402893 0.5625\n",
      "40 0.6608951091766357 0.6875\n",
      "50 0.8677161931991577 0.375\n",
      "60 0.8977404236793518 0.4375\n",
      "70 0.6124340891838074 0.6875\n",
      "80 0.7060893774032593 0.625\n",
      "90 0.7086031436920166 0.5625\n",
      "100 0.8795023560523987 0.5\n",
      "110 0.6780720353126526 0.6875\n",
      "120 0.6644376516342163 0.6875\n",
      "0.5817307692307693\n",
      "----------------------\n",
      "epoch: 4\n",
      "0 0.7121464610099792 0.5625\n",
      "10 0.9850271344184875 0.3125\n",
      "20 0.6738378405570984 0.625\n",
      "30 0.6999286413192749 0.5625\n",
      "40 0.7509236335754395 0.5625\n",
      "50 0.8716368675231934 0.375\n",
      "60 0.6315796971321106 0.6875\n",
      "70 0.595017671585083 0.6875\n",
      "80 0.8906689286231995 0.375\n",
      "90 0.7944388389587402 0.5\n",
      "100 0.8060783743858337 0.375\n",
      "110 0.8223405480384827 0.5\n",
      "120 0.9083317518234253 0.375\n",
      "0.5\n",
      "----------------------\n",
      "epoch: 5\n",
      "0 0.6761207580566406 0.625\n",
      "10 0.8547184467315674 0.375\n",
      "20 0.7516508102416992 0.5\n",
      "30 0.7797175049781799 0.5\n",
      "40 0.8269017338752747 0.5\n",
      "50 0.9078379273414612 0.3125\n",
      "60 0.8112621903419495 0.5\n",
      "70 0.7589239478111267 0.5\n",
      "80 0.8067882061004639 0.4375\n",
      "90 0.6859785318374634 0.5625\n",
      "100 0.9352514743804932 0.3125\n",
      "110 0.724280595779419 0.5625\n",
      "120 0.7765800952911377 0.5\n",
      "0.47596153846153844\n",
      "----------------------\n",
      "epoch: 6\n",
      "0 0.814376950263977 0.5\n",
      "10 0.701870858669281 0.625\n",
      "20 0.8528354167938232 0.4375\n",
      "30 0.7128111720085144 0.5625\n",
      "40 0.611436665058136 0.6875\n",
      "50 0.7715190649032593 0.5625\n",
      "60 0.8663734793663025 0.3125\n",
      "70 0.7589401602745056 0.5\n",
      "80 0.5824748277664185 0.6875\n",
      "90 0.8395988941192627 0.4375\n",
      "100 0.7416051626205444 0.625\n",
      "110 0.7460311651229858 0.4375\n",
      "120 0.7343092560768127 0.5\n",
      "0.5288461538461539\n",
      "----------------------\n",
      "epoch: 7\n",
      "0 0.6907290816307068 0.5\n",
      "10 0.5927528738975525 0.75\n",
      "20 0.7887898087501526 0.5\n",
      "30 1.0166088342666626 0.1875\n",
      "40 0.7115253806114197 0.5625\n",
      "50 0.7923814058303833 0.5625\n",
      "60 0.829666793346405 0.5\n",
      "70 0.6769752502441406 0.5625\n",
      "80 0.5751665234565735 0.625\n",
      "90 0.7282477021217346 0.625\n",
      "100 0.6600043773651123 0.625\n",
      "110 0.6584641933441162 0.6875\n",
      "120 0.8015732765197754 0.375\n",
      "0.5432692307692307\n",
      "----------------------\n",
      "epoch: 8\n",
      "0 0.7242463231086731 0.625\n",
      "10 0.7436150312423706 0.5625\n",
      "20 0.5766895413398743 0.75\n",
      "30 0.8827028870582581 0.375\n",
      "40 0.7866886854171753 0.4375\n",
      "50 0.7807109355926514 0.5\n",
      "60 0.9870005249977112 0.3125\n",
      "70 0.8535612225532532 0.4375\n",
      "80 0.7213515043258667 0.6875\n",
      "90 0.8629230260848999 0.375\n",
      "100 0.6348824501037598 0.6875\n",
      "110 0.6629899740219116 0.625\n",
      "120 0.6407366991043091 0.6875\n",
      "0.5432692307692307\n",
      "----------------------\n",
      "epoch: 9\n",
      "0 0.8498656749725342 0.4375\n",
      "10 0.6843316555023193 0.625\n",
      "20 0.791928231716156 0.5\n",
      "30 0.8458738327026367 0.5\n",
      "40 0.6504915356636047 0.625\n",
      "50 0.9184260964393616 0.25\n",
      "60 0.7798063158988953 0.5\n",
      "70 0.6970009207725525 0.5625\n",
      "80 1.0318650007247925 0.3125\n",
      "90 0.6446644067764282 0.625\n",
      "100 0.8561121225357056 0.4375\n",
      "110 0.7103788256645203 0.5625\n",
      "120 0.764836847782135 0.5625\n",
      "0.5\n",
      "----------------------\n",
      "epoch: 10\n",
      "0 0.789649248123169 0.4375\n",
      "10 0.6009911298751831 0.6875\n",
      "20 0.5908746123313904 0.75\n",
      "30 0.6913212537765503 0.625\n",
      "40 0.7362183332443237 0.5625\n",
      "50 0.7127609848976135 0.6875\n",
      "60 0.8313761949539185 0.5\n",
      "70 0.965469241142273 0.375\n",
      "80 0.6855048537254333 0.625\n",
      "90 0.8758214712142944 0.3125\n",
      "100 0.8217551112174988 0.4375\n",
      "110 0.8906095623970032 0.3125\n",
      "120 0.8740271329879761 0.4375\n",
      "0.5192307692307693\n",
      "----------------------\n",
      "epoch: 11\n",
      "0 0.8245218992233276 0.4375\n",
      "10 0.6004895567893982 0.625\n",
      "20 0.7125993967056274 0.5625\n",
      "30 0.9193429350852966 0.375\n",
      "40 0.7751662731170654 0.5\n",
      "50 0.6777300238609314 0.6875\n",
      "60 0.6623187065124512 0.6875\n",
      "70 0.7564263343811035 0.5\n",
      "80 0.7292217016220093 0.5625\n",
      "90 0.6419593691825867 0.6875\n",
      "100 0.9054806232452393 0.4375\n",
      "110 0.7918078303337097 0.5\n",
      "120 0.7349167466163635 0.5625\n",
      "0.5480769230769231\n",
      "----------------------\n",
      "epoch: 12\n",
      "0 0.7741786241531372 0.5\n",
      "10 0.7763211727142334 0.5\n",
      "20 0.7097307443618774 0.4375\n",
      "30 0.6797820925712585 0.625\n",
      "40 0.6551022529602051 0.625\n",
      "50 0.7880879640579224 0.4375\n",
      "60 0.5476005673408508 0.75\n",
      "70 0.898095428943634 0.3125\n",
      "80 0.5593462586402893 0.75\n",
      "90 0.722255289554596 0.5625\n",
      "100 0.7493607401847839 0.5\n",
      "110 0.5973571538925171 0.6875\n",
      "120 0.7323042154312134 0.4375\n",
      "0.5480769230769231\n",
      "----------------------\n",
      "epoch: 13\n",
      "0 0.8285285234451294 0.375\n",
      "10 0.7951076030731201 0.4375\n",
      "20 0.6293324828147888 0.625\n",
      "30 0.7190098762512207 0.625\n",
      "40 0.7381367087364197 0.5\n",
      "50 0.7020037770271301 0.5625\n",
      "60 0.7305111289024353 0.5\n",
      "70 0.5529868006706238 0.8125\n",
      "80 0.676507830619812 0.6875\n",
      "90 0.6632853746414185 0.5625\n",
      "100 0.6323586106300354 0.625\n",
      "110 0.6985635161399841 0.5\n",
      "120 0.620104193687439 0.6875\n",
      "0.5769230769230769\n",
      "----------------------\n",
      "epoch: 14\n",
      "0 0.8204752802848816 0.25\n",
      "10 0.66794353723526 0.625\n",
      "20 0.8344558477401733 0.3125\n",
      "30 0.6710845232009888 0.6875\n",
      "40 0.69023597240448 0.5\n",
      "50 0.6307342052459717 0.5625\n",
      "60 0.6156179308891296 0.6875\n",
      "70 0.6783679127693176 0.5625\n",
      "80 0.7383999228477478 0.5\n",
      "90 0.7989080548286438 0.375\n",
      "100 0.7573239207267761 0.375\n",
      "110 0.650809645652771 0.75\n",
      "120 0.6179400682449341 0.75\n",
      "0.5336538461538461\n",
      "----------------------\n",
      "epoch: 15\n",
      "0 0.6737842559814453 0.75\n",
      "10 0.663249671459198 0.625\n",
      "20 0.6822567582130432 0.375\n",
      "30 0.6323586106300354 0.6875\n",
      "40 0.7930126190185547 0.375\n",
      "50 0.6868323683738708 0.5\n",
      "60 0.6860939860343933 0.5\n",
      "70 0.6908226609230042 0.5\n",
      "80 0.7305651903152466 0.4375\n",
      "90 0.733550488948822 0.5625\n",
      "100 0.6341515183448792 0.625\n",
      "110 0.6985079050064087 0.625\n",
      "120 0.6605376601219177 0.625\n",
      "0.5528846153846154\n",
      "----------------------\n",
      "epoch: 16\n",
      "0 0.6542369723320007 0.6875\n",
      "10 0.6526404023170471 0.5625\n",
      "20 0.8108348250389099 0.3125\n",
      "30 0.6789940595626831 0.625\n",
      "40 0.6594604253768921 0.5625\n",
      "50 0.5979961156845093 0.5625\n",
      "60 0.7142114639282227 0.4375\n",
      "70 0.6744564771652222 0.625\n",
      "80 0.6362951397895813 0.6875\n",
      "90 0.7292996048927307 0.5\n",
      "100 0.5960404872894287 0.8125\n",
      "110 0.7297137379646301 0.5625\n",
      "120 0.6901989579200745 0.5625\n",
      "0.5769230769230769\n",
      "----------------------\n",
      "epoch: 17\n",
      "0 0.7080146670341492 0.625\n",
      "10 0.728360116481781 0.5\n",
      "20 0.6409586668014526 0.625\n",
      "30 0.6483895778656006 0.625\n",
      "40 0.6385825872421265 0.8125\n",
      "50 0.6882341504096985 0.5625\n",
      "60 0.6418871879577637 0.5625\n",
      "70 0.741895854473114 0.3125\n",
      "80 0.6515311002731323 0.625\n",
      "90 0.6788622736930847 0.625\n",
      "100 0.6365716457366943 0.875\n",
      "110 0.6689479947090149 0.625\n",
      "120 0.7026700973510742 0.3125\n",
      "0.5913461538461539\n",
      "----------------------\n",
      "epoch: 18\n",
      "0 0.6734476089477539 0.5\n",
      "10 0.6594558954238892 0.6875\n",
      "20 0.6960467100143433 0.5625\n",
      "30 0.6436421275138855 0.6875\n",
      "40 0.6881470680236816 0.4375\n",
      "50 0.633569598197937 0.6875\n",
      "60 0.7278766632080078 0.375\n",
      "70 0.6839812397956848 0.5625\n",
      "80 0.609239399433136 0.625\n",
      "90 0.7003732323646545 0.5625\n",
      "100 0.6495351791381836 0.5625\n",
      "110 0.6668375134468079 0.6875\n",
      "120 0.6572615504264832 0.6875\n",
      "0.5865384615384616\n",
      "----------------------\n",
      "epoch: 19\n",
      "0 0.6118876338005066 0.875\n",
      "10 0.7248783707618713 0.5\n",
      "20 0.6469023823738098 0.6875\n",
      "30 0.6641350984573364 0.625\n",
      "40 0.6537326574325562 0.75\n",
      "50 0.6384154558181763 0.75\n",
      "60 0.660310685634613 0.625\n",
      "70 0.6707246899604797 0.5625\n",
      "80 0.6563372015953064 0.625\n",
      "90 0.6326768398284912 0.8125\n",
      "100 0.6372733116149902 0.625\n",
      "110 0.6872904896736145 0.5\n",
      "120 0.6351832151412964 0.75\n",
      "0.6682692307692307\n",
      "----------------------\n",
      "epoch: 20\n",
      "0 0.7053536772727966 0.375\n",
      "10 0.6707333922386169 0.625\n",
      "20 0.6283641457557678 0.6875\n",
      "30 0.6691625714302063 0.625\n",
      "40 0.633338212966919 0.5625\n",
      "50 0.6955275535583496 0.625\n",
      "60 0.7460787892341614 0.625\n",
      "70 0.689358651638031 0.5\n",
      "80 0.6663243770599365 0.5625\n",
      "90 0.6023892164230347 0.6875\n",
      "100 0.6687177419662476 0.5\n",
      "110 0.6400974988937378 0.625\n",
      "120 0.7187714576721191 0.5\n",
      "0.5769230769230769\n",
      "----------------------\n",
      "epoch: 21\n",
      "0 0.6246805191040039 0.6875\n",
      "10 0.7106486558914185 0.4375\n",
      "20 0.6433979272842407 0.625\n",
      "30 0.7078574895858765 0.3125\n",
      "40 0.6710432767868042 0.5\n",
      "50 0.6847782731056213 0.5625\n",
      "60 0.6955713629722595 0.4375\n",
      "70 0.633217990398407 0.5625\n",
      "80 0.6607710719108582 0.6875\n",
      "90 0.6546763777732849 0.625\n",
      "100 0.6039575934410095 0.75\n",
      "110 0.5907214879989624 0.9375\n",
      "120 0.6235595941543579 0.75\n",
      "0.6057692307692307\n",
      "----------------------\n",
      "epoch: 22\n",
      "0 0.6321545839309692 0.625\n",
      "10 0.7242547273635864 0.5\n",
      "20 0.6657505631446838 0.6875\n",
      "30 0.6073412299156189 0.75\n",
      "40 0.631516695022583 0.8125\n",
      "50 0.639529824256897 0.6875\n",
      "60 0.7257211804389954 0.4375\n",
      "70 0.6930697560310364 0.4375\n",
      "80 0.6993665099143982 0.5625\n",
      "90 0.6690528392791748 0.5625\n",
      "100 0.6573041081428528 0.5625\n",
      "110 0.6990102529525757 0.4375\n",
      "120 0.6499819755554199 0.625\n",
      "0.5913461538461539\n",
      "----------------------\n",
      "epoch: 23\n",
      "0 0.6576297879219055 0.4375\n",
      "10 0.6202894449234009 0.625\n",
      "20 0.694306492805481 0.5625\n",
      "30 0.6819981336593628 0.6875\n",
      "40 0.684272825717926 0.5625\n",
      "50 0.6764445304870605 0.5625\n",
      "60 0.668574869632721 0.5\n",
      "70 0.6295599937438965 0.5625\n",
      "80 0.6391472220420837 0.8125\n",
      "90 0.677949845790863 0.6875\n",
      "100 0.6521387696266174 0.5\n",
      "110 0.6475638151168823 0.5625\n",
      "120 0.7005910873413086 0.4375\n",
      "0.5769230769230769\n",
      "----------------------\n",
      "epoch: 24\n",
      "0 0.6097433567047119 0.75\n",
      "10 0.5673708915710449 0.8125\n",
      "20 0.6797739863395691 0.5\n",
      "30 0.6742667555809021 0.5\n",
      "40 0.7233753800392151 0.5\n",
      "50 0.6470958590507507 0.625\n",
      "60 0.7027018070220947 0.5625\n",
      "70 0.6670989990234375 0.4375\n",
      "80 0.7002066373825073 0.4375\n",
      "90 0.6460222601890564 0.5\n",
      "100 0.6353314518928528 0.5625\n",
      "110 0.7410800457000732 0.4375\n",
      "120 0.656406581401825 0.6875\n",
      "0.5625\n",
      "----------------------\n",
      "epoch: 25\n",
      "0 0.6865349411964417 0.625\n",
      "10 0.6926882266998291 0.6875\n",
      "20 0.6912141442298889 0.5625\n",
      "30 0.6407271027565002 0.625\n",
      "40 0.6720004081726074 0.625\n",
      "50 0.6511515378952026 0.625\n",
      "60 0.6593675017356873 0.625\n",
      "70 0.6848227381706238 0.625\n",
      "80 0.6331942081451416 0.6875\n",
      "90 0.6645619869232178 0.5\n",
      "100 0.6500257849693298 0.6875\n",
      "110 0.6677626967430115 0.5625\n",
      "120 0.6071683764457703 0.75\n",
      "0.6298076923076923\n",
      "----------------------\n",
      "epoch: 26\n",
      "0 0.6585572361946106 0.5625\n",
      "10 0.5889131426811218 0.75\n",
      "20 0.7175639867782593 0.5625\n",
      "30 0.6373065114021301 0.6875\n",
      "40 0.6478105187416077 0.6875\n",
      "50 0.6307241916656494 0.625\n",
      "60 0.6453112959861755 0.625\n",
      "70 0.7014167904853821 0.4375\n",
      "80 0.6682753562927246 0.625\n",
      "90 0.5804686546325684 0.875\n",
      "100 0.5679793357849121 0.8125\n",
      "110 0.7533891797065735 0.5625\n",
      "120 0.6509222388267517 0.6875\n",
      "0.6538461538461539\n",
      "----------------------\n",
      "epoch: 27\n",
      "0 0.6216421127319336 0.625\n",
      "10 0.6338241696357727 0.6875\n",
      "20 0.591935396194458 0.625\n",
      "30 0.6555048227310181 0.625\n",
      "40 0.6156913042068481 0.625\n",
      "50 0.6457546949386597 0.6875\n",
      "60 0.6602314114570618 0.5\n",
      "70 0.6407899856567383 0.5625\n",
      "80 0.6901546716690063 0.625\n",
      "90 0.7651839256286621 0.4375\n",
      "100 0.6034766435623169 0.75\n",
      "110 0.6589136719703674 0.75\n",
      "120 0.6844984889030457 0.5\n",
      "0.6153846153846154\n",
      "----------------------\n",
      "epoch: 28\n",
      "0 0.6717955470085144 0.5625\n",
      "10 0.6479098200798035 0.8125\n",
      "20 0.6988847255706787 0.4375\n",
      "30 0.6199461221694946 0.75\n",
      "40 0.5863141417503357 0.8125\n",
      "50 0.6485098600387573 0.6875\n",
      "60 0.6299628615379333 0.625\n",
      "70 0.5957140922546387 1.0\n",
      "80 0.7142680287361145 0.3125\n",
      "90 0.729475736618042 0.625\n",
      "100 0.6269989609718323 0.75\n",
      "110 0.735928475856781 0.5\n",
      "120 0.6181984543800354 0.75\n",
      "0.6634615384615384\n",
      "----------------------\n",
      "epoch: 29\n",
      "0 0.6769106984138489 0.625\n",
      "10 0.5858250260353088 0.875\n",
      "20 0.595680832862854 0.875\n",
      "30 0.6213332414627075 0.6875\n",
      "40 0.6566257476806641 0.5625\n",
      "50 0.6458154320716858 0.5625\n",
      "60 0.6311272382736206 0.75\n",
      "70 0.6332800984382629 0.6875\n",
      "80 0.681380033493042 0.5\n",
      "90 0.6503781676292419 0.625\n",
      "100 0.6272152662277222 0.625\n",
      "110 0.6540728807449341 0.75\n",
      "120 0.629209041595459 0.625\n",
      "0.6730769230769231\n",
      "----------------------\n",
      "epoch: 30\n",
      "0 0.6716920733451843 0.625\n",
      "10 0.6732393503189087 0.5\n",
      "20 0.7189065217971802 0.4375\n",
      "30 0.6399441957473755 0.5625\n",
      "40 0.6734543442726135 0.625\n",
      "50 0.6665798425674438 0.6875\n",
      "60 0.6817635297775269 0.625\n",
      "70 0.6488485336303711 0.5625\n",
      "80 0.646174967288971 0.6875\n",
      "90 0.6011185050010681 0.75\n",
      "100 0.6368175148963928 0.5625\n",
      "110 0.6671875715255737 0.375\n",
      "120 0.5905588865280151 0.9375\n",
      "0.6105769230769231\n",
      "----------------------\n",
      "epoch: 31\n",
      "0 0.6848445534706116 0.5625\n",
      "10 0.6412935256958008 0.6875\n",
      "20 0.602514922618866 0.75\n",
      "30 0.6139692068099976 0.75\n",
      "40 0.7111108899116516 0.4375\n",
      "50 0.645646870136261 0.625\n",
      "60 0.6269517540931702 0.75\n",
      "70 0.6301093101501465 0.625\n",
      "80 0.6373701691627502 0.625\n",
      "90 0.6451005339622498 0.625\n",
      "100 0.6586448550224304 0.625\n",
      "110 0.6321872472763062 0.6875\n",
      "120 0.6551623940467834 0.5625\n",
      "0.6394230769230769\n",
      "----------------------\n",
      "epoch: 32\n",
      "0 0.6179004311561584 0.75\n",
      "10 0.6345911026000977 0.6875\n",
      "20 0.6912165880203247 0.625\n",
      "30 0.6536208987236023 0.6875\n",
      "40 0.6408087015151978 0.5\n",
      "50 0.648527204990387 0.6875\n",
      "60 0.6169009208679199 0.75\n",
      "70 0.6257390975952148 0.625\n",
      "80 0.612048864364624 0.8125\n",
      "90 0.6429629325866699 0.6875\n",
      "100 0.6558712720870972 0.5\n",
      "110 0.7240270972251892 0.4375\n",
      "120 0.7355310916900635 0.625\n",
      "0.6442307692307693\n",
      "----------------------\n",
      "epoch: 33\n",
      "0 0.6253756880760193 0.625\n",
      "10 0.6156675815582275 0.6875\n",
      "20 0.6026018857955933 0.8125\n",
      "30 0.6710602641105652 0.6875\n",
      "40 0.6291166543960571 0.6875\n",
      "50 0.6076545715332031 0.75\n",
      "60 0.6997860074043274 0.4375\n",
      "70 0.6205026507377625 0.6875\n",
      "80 0.6950481534004211 0.5625\n",
      "90 0.643826961517334 0.625\n",
      "100 0.7273306846618652 0.25\n",
      "110 0.6874889731407166 0.4375\n",
      "120 0.5599928498268127 0.875\n",
      "0.625\n",
      "----------------------\n",
      "epoch: 34\n",
      "0 0.6374344229698181 0.6875\n",
      "10 0.6242274045944214 0.6875\n",
      "20 0.6470064520835876 0.625\n",
      "30 0.5908534526824951 0.625\n",
      "40 0.7259441614151001 0.4375\n",
      "50 0.6033470630645752 0.6875\n",
      "60 0.6043875217437744 0.75\n",
      "70 0.6151329278945923 0.75\n",
      "80 0.6562790870666504 0.625\n",
      "90 0.6514595746994019 0.625\n",
      "100 0.6618285179138184 0.5625\n",
      "110 0.7139058113098145 0.4375\n",
      "120 0.6011558175086975 0.75\n",
      "0.6346153846153846\n",
      "----------------------\n",
      "epoch: 35\n",
      "0 0.5899518728256226 0.8125\n",
      "10 0.6631877422332764 0.6875\n",
      "20 0.6992433071136475 0.5\n",
      "30 0.6597210764884949 0.625\n",
      "40 0.6532202959060669 0.5625\n",
      "50 0.6793521642684937 0.5\n",
      "60 0.5902280807495117 0.6875\n",
      "70 0.7343834042549133 0.5\n",
      "80 0.6170072555541992 0.5625\n",
      "90 0.6730276942253113 0.5\n",
      "100 0.6653508543968201 0.625\n",
      "110 0.6427066326141357 0.625\n",
      "120 0.6541793346405029 0.6875\n",
      "0.6057692307692307\n",
      "----------------------\n",
      "epoch: 36\n",
      "0 0.6113020181655884 0.6875\n",
      "10 0.6173970103263855 0.8125\n",
      "20 0.604096531867981 0.6875\n",
      "30 0.5869414806365967 0.8125\n",
      "40 0.6610592603683472 0.625\n",
      "50 0.5901210904121399 0.6875\n",
      "60 0.6713671088218689 0.625\n",
      "70 0.634391188621521 0.625\n",
      "80 0.6871704459190369 0.625\n",
      "90 0.5837587118148804 0.75\n",
      "100 0.5836866497993469 0.875\n",
      "110 0.6017340421676636 0.6875\n",
      "120 0.6229202151298523 0.5625\n",
      "0.6971153846153846\n",
      "----------------------\n",
      "epoch: 37\n",
      "0 0.5839797854423523 0.875\n",
      "10 0.7140764594078064 0.5625\n",
      "20 0.7261902689933777 0.4375\n",
      "30 0.6002647280693054 0.75\n",
      "40 0.6913371086120605 0.4375\n",
      "50 0.6708429455757141 0.625\n",
      "60 0.673357367515564 0.625\n",
      "70 0.651813268661499 0.625\n",
      "80 0.5974490642547607 0.75\n",
      "90 0.6414807438850403 0.5\n",
      "100 0.6568295955657959 0.5625\n",
      "110 0.5769153833389282 0.875\n",
      "120 0.5588687658309937 0.9375\n",
      "0.6586538461538461\n",
      "----------------------\n",
      "epoch: 38\n",
      "0 0.6725766658782959 0.5625\n",
      "10 0.649888277053833 0.6875\n",
      "20 0.6251224279403687 0.625\n",
      "30 0.6721384525299072 0.625\n",
      "40 0.6685221791267395 0.625\n",
      "50 0.6360309720039368 0.75\n",
      "60 0.5784527659416199 0.75\n",
      "70 0.673384428024292 0.625\n",
      "80 0.6220057606697083 0.75\n",
      "90 0.653988242149353 0.625\n",
      "100 0.6844182014465332 0.5\n",
      "110 0.6578359007835388 0.5625\n",
      "120 0.6742086410522461 0.5625\n",
      "0.6346153846153846\n",
      "----------------------\n",
      "epoch: 39\n",
      "0 0.6718286275863647 0.5625\n",
      "10 0.6200509667396545 0.875\n",
      "20 0.5706149935722351 0.9375\n",
      "30 0.655465841293335 0.5\n",
      "40 0.6281663775444031 0.75\n",
      "50 0.6181317567825317 0.75\n",
      "60 0.677236020565033 0.625\n",
      "70 0.6611354947090149 0.5625\n",
      "80 0.5957356691360474 0.8125\n",
      "90 0.6870507597923279 0.5\n",
      "100 0.6753795742988586 0.6875\n",
      "110 0.7186552882194519 0.5\n",
      "120 0.6959053874015808 0.625\n",
      "0.6682692307692307\n",
      "----------------------\n",
      "epoch: 40\n",
      "0 0.5813212394714355 0.8125\n",
      "10 0.5858566164970398 0.6875\n",
      "20 0.6236271858215332 0.75\n",
      "30 0.6864433884620667 0.5625\n",
      "40 0.6978573203086853 0.5\n",
      "50 0.628789484500885 0.75\n",
      "60 0.682916522026062 0.5625\n",
      "70 0.7594972252845764 0.4375\n",
      "80 0.5969008803367615 0.8125\n",
      "90 0.6332427859306335 0.625\n",
      "100 0.6503961682319641 0.6875\n",
      "110 0.6374914646148682 0.75\n",
      "120 0.6784105896949768 0.5625\n",
      "0.6538461538461539\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "#训练\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(40):\n",
    "    all_right = 0\n",
    "    all_label = 0\n",
    "    print(f\"epoch: {epoch+1}\")\n",
    "    for i, (input_ids, attention_mask, token_type_ids, code_len, keyword_num, permission,\n",
    "            labels) in enumerate(loader):\n",
    "        out = model(input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    code_len=code_len,\n",
    "                    keyword_num=keyword_num,\n",
    "                    permission=permission)\n",
    "\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "\n",
    "            out = out.argmax(dim=1)\n",
    "            accuracy = (out == labels).sum().item() / len(labels)\n",
    "\n",
    "            all_right = all_right + (out == labels).sum().item()\n",
    "            all_label = all_label + len(labels)\n",
    "            print(i, loss.item(), accuracy)\n",
    "        if i == 1000:\n",
    "            break\n",
    "\n",
    "    print(all_right/all_label)\n",
    "    print(\"----------------------\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Accuracy: 0.622\n",
      "Precision: 0.6301775147928994\n",
      "Recall: 0.7689530685920578\n",
      "F1-score: 0.6926829268292682\n",
      "AUC score: 0.6042074760000647\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=dataset_validation,\n",
    "                                              batch_size=50,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True)\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for i, (input_ids, attention_mask, token_type_ids, code_len, keyword_num, permission,\n",
    "            labels) in enumerate(loader_test):\n",
    "\n",
    "        if i == 20:\n",
    "            break\n",
    "\n",
    "        print(i)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    code_len=code_len,\n",
    "                    keyword_num=keyword_num,\n",
    "                    permission=permission)\n",
    "\n",
    "        out = out.argmax(dim=1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(out.cpu().numpy())\n",
    "\n",
    "        correct += (out == labels).sum().item()\n",
    "        total += len(labels)\n",
    "\n",
    "    # print(y_true)\n",
    "    # print(y_pred)\n",
    "    accuracy = correct / total\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, pos_label=0, average='binary')\n",
    "    auc_score = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1_score}\")\n",
    "    print(f\"AUC score: {auc_score}\")\n",
    "\n",
    "\n",
    "test()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
